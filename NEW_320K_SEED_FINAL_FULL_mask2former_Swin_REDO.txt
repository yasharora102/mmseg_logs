==========================================
SLURM_JOB_ID = 2470937
SLURM_NODELIST = gnode070
SLURM_JOB_GPUS = 0
==========================================
08/06 02:16:35 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.23 (main, Jun  5 2025, 13:40:20) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 268722126
    GPU 0: NVIDIA GeForce RTX 2080 Ti
    CUDA_HOME: /opt/cuda-12.1/
    NVCC: Cuda compilation tools, release 12.1, V12.1.66
    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
    PyTorch: 2.1.2
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 268722126
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

08/06 02:16:36 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=2, enable=False)
backbone_embed_multi = dict(decay_mult=0.0, lr_mult=0.1)
backbone_norm_multi = dict(decay_mult=0.0, lr_mult=0.1)
crop_size = (
    512,
    1024,
)
custom_keys = dict({
    'absolute_pos_embed':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone':
    dict(decay_mult=1.0, lr_mult=0.1),
    'backbone.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.patch_embed.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.2.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.3.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.4.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.5.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'level_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_feat':
    dict(decay_mult=0.0, lr_mult=1.0),
    'relative_position_bias_table':
    dict(decay_mult=0.0, lr_mult=0.1)
})
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        512,
        1024,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    test_cfg=dict(size_divisor=32),
    type='SegDataPreProcessor')
data_root = '/scratch/seg_benchmark/splits_flat/'
dataset_type = 'YourDataset_BIG'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False,
        interval=40000,
        save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'))
default_scope = 'mmseg'
depths = [
    2,
    2,
    6,
    2,
]
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
img_suffix = '.jpg'
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        attn_drop_rate=0.0,
        depths=[
            2,
            2,
            6,
            2,
        ],
        drop_path_rate=0.3,
        drop_rate=0.0,
        embed_dims=96,
        frozen_stages=-1,
        init_cfg=dict(
            checkpoint=
            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth',
            type='Pretrained'),
        mlp_ratio=4,
        num_heads=[
            3,
            6,
            12,
            24,
        ],
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        patch_norm=True,
        qk_scale=None,
        qkv_bias=True,
        type='SwinTransformer',
        window_size=7,
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            1024,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        test_cfg=dict(size_divisor=32),
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            96,
            192,
            384,
            768,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=51,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 51
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict({
            'absolute_pos_embed':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone':
            dict(decay_mult=1.0, lr_mult=0.1),
            'backbone.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.patch_embed.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.2.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.3.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.4.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.5.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'level_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_feat':
            dict(decay_mult=0.0, lr_mult=1.0),
            'relative_position_bias_table':
            dict(decay_mult=0.0, lr_mult=0.1)
        }),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=320000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth'
randomness = dict(seed=268722126)
resume = False
seg_map_suffix = '.png'
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/seg_benchmark/splits_flat/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    classwise=True, iou_metrics=[
        'mIoU',
    ], type='IoUNanAbsent')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2048,
        1024,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(
    max_iters=320000, type='IterBasedTrainLoop', val_interval=40000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        data_prefix=dict(img_path='train/images', seg_map_path='train/masks'),
        data_root='/scratch/seg_benchmark/splits_flat/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                max_size=4096,
                resize_type='ResizeShortestEdge',
                scales=[
                    512,
                    614,
                    716,
                    819,
                    921,
                    1024,
                    1126,
                    1228,
                    1331,
                    1433,
                    1536,
                    1638,
                    1740,
                    1843,
                    1945,
                    2048,
                ],
                type='RandomChoiceResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    512,
                    1024,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        max_size=4096,
        resize_type='ResizeShortestEdge',
        scales=[
            512,
            614,
            716,
            819,
            921,
            1024,
            1126,
            1228,
            1331,
            1433,
            1536,
            1638,
            1740,
            1843,
            1945,
            2048,
        ],
        type='RandomChoiceResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        1024,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/seg_benchmark/splits_flat/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '/scratch/seg_benchmark/NEW/mask2former_swin_T_seed_320K'

08/06 02:16:41 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
08/06 02:16:41 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth
08/06 02:16:47 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
08/06 02:16:47 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
08/06 02:16:47 - mmengine - INFO - Checkpoints will be saved to /scratch/seg_benchmark/NEW/mask2former_swin_T_seed_320K.
/home2/yasharora120/miniconda3/envs/mmseg/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400441250/work/aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
08/06 02:17:16 - mmengine - INFO - Iter(train) [    50/320000]  base_lr: 9.9986e-05 lr: 9.9986e-06  eta: 2 days, 2:50:59  time: 0.4845  data_time: 0.0105  memory: 8941  grad_norm: 242.2523  loss: 103.6889  decode.loss_cls: 4.0523  decode.loss_mask: 2.2177  decode.loss_dice: 4.1183  decode.d0.loss_cls: 7.9803  decode.d0.loss_mask: 2.0244  decode.d0.loss_dice: 3.7734  decode.d1.loss_cls: 3.6009  decode.d1.loss_mask: 2.1517  decode.d1.loss_dice: 3.8214  decode.d2.loss_cls: 3.4406  decode.d2.loss_mask: 2.0439  decode.d2.loss_dice: 3.8323  decode.d3.loss_cls: 3.4915  decode.d3.loss_mask: 2.1331  decode.d3.loss_dice: 3.8770  decode.d4.loss_cls: 3.6622  decode.d4.loss_mask: 2.3944  decode.d4.loss_dice: 3.8287  decode.d5.loss_cls: 3.8721  decode.d5.loss_mask: 2.2988  decode.d5.loss_dice: 3.9699  decode.d6.loss_cls: 3.9998  decode.d6.loss_mask: 2.2680  decode.d6.loss_dice: 4.0648  decode.d7.loss_cls: 4.0605  decode.d7.loss_mask: 2.2993  decode.d7.loss_dice: 4.1341  decode.d8.loss_cls: 4.0652  decode.d8.loss_mask: 2.2002  decode.d8.loss_dice: 4.0121
08/06 02:17:40 - mmengine - INFO - Iter(train) [   100/320000]  base_lr: 9.9972e-05 lr: 9.9972e-06  eta: 1 day, 22:55:14  time: 0.4846  data_time: 0.0105  memory: 5907  grad_norm: 263.2748  loss: 80.5524  decode.loss_cls: 3.3351  decode.loss_mask: 1.7080  decode.loss_dice: 3.3763  decode.d0.loss_cls: 8.0424  decode.d0.loss_mask: 1.4938  decode.d0.loss_dice: 3.0813  decode.d1.loss_cls: 2.9343  decode.d1.loss_mask: 1.5267  decode.d1.loss_dice: 2.9937  decode.d2.loss_cls: 2.6794  decode.d2.loss_mask: 1.5114  decode.d2.loss_dice: 2.9729  decode.d3.loss_cls: 2.7374  decode.d3.loss_mask: 1.5240  decode.d3.loss_dice: 2.9265  decode.d4.loss_cls: 2.7828  decode.d4.loss_mask: 1.5240  decode.d4.loss_dice: 2.9519  decode.d5.loss_cls: 2.7709  decode.d5.loss_mask: 1.5606  decode.d5.loss_dice: 3.0155  decode.d6.loss_cls: 2.8797  decode.d6.loss_mask: 1.5752  decode.d6.loss_dice: 3.0294  decode.d7.loss_cls: 2.9352  decode.d7.loss_mask: 1.5929  decode.d7.loss_dice: 3.1101  decode.d8.loss_cls: 3.1789  decode.d8.loss_mask: 1.5930  decode.d8.loss_dice: 3.2091
08/06 02:18:04 - mmengine - INFO - Iter(train) [   150/320000]  base_lr: 9.9958e-05 lr: 9.9958e-06  eta: 1 day, 21:42:52  time: 0.4859  data_time: 0.0107  memory: 5907  grad_norm: 287.5317  loss: 69.2580  decode.loss_cls: 3.5324  decode.loss_mask: 1.1880  decode.loss_dice: 2.1938  decode.d0.loss_cls: 7.9801  decode.d0.loss_mask: 1.1672  decode.d0.loss_dice: 2.3903  decode.d1.loss_cls: 2.9434  decode.d1.loss_mask: 1.1831  decode.d1.loss_dice: 2.1406  decode.d2.loss_cls: 2.9631  decode.d2.loss_mask: 1.1055  decode.d2.loss_dice: 2.0415  decode.d3.loss_cls: 3.1253  decode.d3.loss_mask: 1.1006  decode.d3.loss_dice: 2.0228  decode.d4.loss_cls: 3.1643  decode.d4.loss_mask: 1.1071  decode.d4.loss_dice: 1.9804  decode.d5.loss_cls: 3.1536  decode.d5.loss_mask: 1.1827  decode.d5.loss_dice: 2.0258  decode.d6.loss_cls: 3.1434  decode.d6.loss_mask: 1.2010  decode.d6.loss_dice: 1.9944  decode.d7.loss_cls: 3.2334  decode.d7.loss_mask: 1.2243  decode.d7.loss_dice: 2.0485  decode.d8.loss_cls: 3.2665  decode.d8.loss_mask: 1.2270  decode.d8.loss_dice: 2.2277
08/06 02:18:29 - mmengine - INFO - Iter(train) [   200/320000]  base_lr: 9.9944e-05 lr: 9.9944e-06  eta: 1 day, 21:05:07  time: 0.4875  data_time: 0.0103  memory: 5892  grad_norm: 317.0971  loss: 59.3301  decode.loss_cls: 2.9295  decode.loss_mask: 1.0901  decode.loss_dice: 1.5771  decode.d0.loss_cls: 7.8814  decode.d0.loss_mask: 1.0306  decode.d0.loss_dice: 1.9160  decode.d1.loss_cls: 2.6320  decode.d1.loss_mask: 1.0930  decode.d1.loss_dice: 1.6858  decode.d2.loss_cls: 2.6536  decode.d2.loss_mask: 1.0715  decode.d2.loss_dice: 1.5597  decode.d3.loss_cls: 2.6742  decode.d3.loss_mask: 1.0058  decode.d3.loss_dice: 1.5378  decode.d4.loss_cls: 2.7574  decode.d4.loss_mask: 1.0522  decode.d4.loss_dice: 1.5276  decode.d5.loss_cls: 2.8573  decode.d5.loss_mask: 1.0071  decode.d5.loss_dice: 1.4765  decode.d6.loss_cls: 2.8859  decode.d6.loss_mask: 0.9804  decode.d6.loss_dice: 1.4453  decode.d7.loss_cls: 2.8742  decode.d7.loss_mask: 1.1039  decode.d7.loss_dice: 1.5080  decode.d8.loss_cls: 2.9062  decode.d8.loss_mask: 1.0772  decode.d8.loss_dice: 1.5326
08/06 02:18:53 - mmengine - INFO - Iter(train) [   250/320000]  base_lr: 9.9930e-05 lr: 9.9930e-06  eta: 1 day, 20:42:55  time: 0.4876  data_time: 0.0101  memory: 5892  grad_norm: 277.7302  loss: 56.1562  decode.loss_cls: 3.0561  decode.loss_mask: 0.8821  decode.loss_dice: 1.3224  decode.d0.loss_cls: 7.7463  decode.d0.loss_mask: 0.8445  decode.d0.loss_dice: 1.8208  decode.d1.loss_cls: 2.9815  decode.d1.loss_mask: 0.7951  decode.d1.loss_dice: 1.4276  decode.d2.loss_cls: 2.9545  decode.d2.loss_mask: 0.7635  decode.d2.loss_dice: 1.2968  decode.d3.loss_cls: 2.9242  decode.d3.loss_mask: 0.7269  decode.d3.loss_dice: 1.2554  decode.d4.loss_cls: 2.9378  decode.d4.loss_mask: 0.7655  decode.d4.loss_dice: 1.2548  decode.d5.loss_cls: 2.9634  decode.d5.loss_mask: 0.7913  decode.d5.loss_dice: 1.2560  decode.d6.loss_cls: 3.0061  decode.d6.loss_mask: 0.7970  decode.d6.loss_dice: 1.2470  decode.d7.loss_cls: 3.0359  decode.d7.loss_mask: 0.8471  decode.d7.loss_dice: 1.2586  decode.d8.loss_cls: 3.0682  decode.d8.loss_mask: 0.8429  decode.d8.loss_dice: 1.2869
08/06 02:19:17 - mmengine - INFO - Iter(train) [   300/320000]  base_lr: 9.9916e-05 lr: 9.9916e-06  eta: 1 day, 20:28:22  time: 0.4881  data_time: 0.0104  memory: 5908  grad_norm: 415.7970  loss: 51.7523  decode.loss_cls: 2.6193  decode.loss_mask: 0.9733  decode.loss_dice: 1.1063  decode.d0.loss_cls: 7.5652  decode.d0.loss_mask: 0.9865  decode.d0.loss_dice: 1.5240  decode.d1.loss_cls: 2.5825  decode.d1.loss_mask: 0.9004  decode.d1.loss_dice: 1.1825  decode.d2.loss_cls: 2.5456  decode.d2.loss_mask: 0.9037  decode.d2.loss_dice: 1.0854  decode.d3.loss_cls: 2.5499  decode.d3.loss_mask: 0.9108  decode.d3.loss_dice: 1.0077  decode.d4.loss_cls: 2.5190  decode.d4.loss_mask: 0.9234  decode.d4.loss_dice: 1.0776  decode.d5.loss_cls: 2.5545  decode.d5.loss_mask: 0.9921  decode.d5.loss_dice: 1.0833  decode.d6.loss_cls: 2.5887  decode.d6.loss_mask: 1.0056  decode.d6.loss_dice: 1.1025  decode.d7.loss_cls: 2.6124  decode.d7.loss_mask: 1.0092  decode.d7.loss_dice: 1.1358  decode.d8.loss_cls: 2.6313  decode.d8.loss_mask: 0.9336  decode.d8.loss_dice: 1.1403
08/06 02:19:42 - mmengine - INFO - Iter(train) [   350/320000]  base_lr: 9.9902e-05 lr: 9.9902e-06  eta: 1 day, 20:18:01  time: 0.4874  data_time: 0.0099  memory: 5892  grad_norm: 271.0692  loss: 52.7456  decode.loss_cls: 2.8952  decode.loss_mask: 0.7999  decode.loss_dice: 1.1294  decode.d0.loss_cls: 7.3801  decode.d0.loss_mask: 0.8319  decode.d0.loss_dice: 1.6631  decode.d1.loss_cls: 2.8838  decode.d1.loss_mask: 0.8329  decode.d1.loss_dice: 1.2252  decode.d2.loss_cls: 2.7671  decode.d2.loss_mask: 0.7858  decode.d2.loss_dice: 1.1238  decode.d3.loss_cls: 2.7711  decode.d3.loss_mask: 0.7354  decode.d3.loss_dice: 1.0614  decode.d4.loss_cls: 2.8564  decode.d4.loss_mask: 0.7468  decode.d4.loss_dice: 1.0768  decode.d5.loss_cls: 2.9050  decode.d5.loss_mask: 0.7446  decode.d5.loss_dice: 1.0583  decode.d6.loss_cls: 2.9378  decode.d6.loss_mask: 0.7354  decode.d6.loss_dice: 1.0622  decode.d7.loss_cls: 2.9581  decode.d7.loss_mask: 0.7761  decode.d7.loss_dice: 1.0783  decode.d8.loss_cls: 2.9781  decode.d8.loss_mask: 0.8120  decode.d8.loss_dice: 1.1335
08/06 02:20:06 - mmengine - INFO - Iter(train) [   400/320000]  base_lr: 9.9888e-05 lr: 9.9888e-06  eta: 1 day, 20:10:52  time: 0.4893  data_time: 0.0103  memory: 5908  grad_norm: 391.0088  loss: 50.4978  decode.loss_cls: 2.7614  decode.loss_mask: 0.7868  decode.loss_dice: 1.1969  decode.d0.loss_cls: 7.2830  decode.d0.loss_mask: 0.8352  decode.d0.loss_dice: 1.4141  decode.d1.loss_cls: 2.7607  decode.d1.loss_mask: 0.7893  decode.d1.loss_dice: 1.1637  decode.d2.loss_cls: 2.6860  decode.d2.loss_mask: 0.7784  decode.d2.loss_dice: 1.0722  decode.d3.loss_cls: 2.6559  decode.d3.loss_mask: 0.7167  decode.d3.loss_dice: 0.9990  decode.d4.loss_cls: 2.6279  decode.d4.loss_mask: 0.7600  decode.d4.loss_dice: 1.0233  decode.d5.loss_cls: 2.6044  decode.d5.loss_mask: 0.8010  decode.d5.loss_dice: 1.0620  decode.d6.loss_cls: 2.6790  decode.d6.loss_mask: 0.7947  decode.d6.loss_dice: 1.0435  decode.d7.loss_cls: 2.6687  decode.d7.loss_mask: 0.8052  decode.d7.loss_dice: 1.0470  decode.d8.loss_cls: 2.7936  decode.d8.loss_mask: 0.8033  decode.d8.loss_dice: 1.0847
08/06 02:20:31 - mmengine - INFO - Iter(train) [   450/320000]  base_lr: 9.9874e-05 lr: 9.9874e-06  eta: 1 day, 20:06:53  time: 0.4873  data_time: 0.0105  memory: 5889  grad_norm: 413.5357  loss: 48.3874  decode.loss_cls: 2.6960  decode.loss_mask: 0.7250  decode.loss_dice: 0.9490  decode.d0.loss_cls: 7.1043  decode.d0.loss_mask: 0.7834  decode.d0.loss_dice: 1.3479  decode.d1.loss_cls: 2.7237  decode.d1.loss_mask: 0.8164  decode.d1.loss_dice: 1.0995  decode.d2.loss_cls: 2.5207  decode.d2.loss_mask: 0.7365  decode.d2.loss_dice: 0.9497  decode.d3.loss_cls: 2.5241  decode.d3.loss_mask: 0.6753  decode.d3.loss_dice: 0.9287  decode.d4.loss_cls: 2.5510  decode.d4.loss_mask: 0.7156  decode.d4.loss_dice: 0.9082  decode.d5.loss_cls: 2.5958  decode.d5.loss_mask: 0.7271  decode.d5.loss_dice: 0.9559  decode.d6.loss_cls: 2.6890  decode.d6.loss_mask: 0.7567  decode.d6.loss_dice: 0.9834  decode.d7.loss_cls: 2.7273  decode.d7.loss_mask: 0.7435  decode.d7.loss_dice: 0.9765  decode.d8.loss_cls: 2.7136  decode.d8.loss_mask: 0.7719  decode.d8.loss_dice: 0.9916
08/06 02:20:55 - mmengine - INFO - Iter(train) [   500/320000]  base_lr: 9.9860e-05 lr: 9.9860e-06  eta: 1 day, 20:01:33  time: 0.4871  data_time: 0.0106  memory: 5892  grad_norm: 405.6812  loss: 43.2560  decode.loss_cls: 2.3091  decode.loss_mask: 0.7682  decode.loss_dice: 0.9339  decode.d0.loss_cls: 6.8611  decode.d0.loss_mask: 0.7456  decode.d0.loss_dice: 1.1298  decode.d1.loss_cls: 2.4066  decode.d1.loss_mask: 0.7118  decode.d1.loss_dice: 0.8424  decode.d2.loss_cls: 2.2475  decode.d2.loss_mask: 0.6453  decode.d2.loss_dice: 0.7410  decode.d3.loss_cls: 2.2708  decode.d3.loss_mask: 0.6737  decode.d3.loss_dice: 0.7866  decode.d4.loss_cls: 2.2946  decode.d4.loss_mask: 0.7223  decode.d4.loss_dice: 0.7949  decode.d5.loss_cls: 2.3750  decode.d5.loss_mask: 0.6635  decode.d5.loss_dice: 0.7985  decode.d6.loss_cls: 2.3616  decode.d6.loss_mask: 0.6676  decode.d6.loss_dice: 0.7947  decode.d7.loss_cls: 2.3253  decode.d7.loss_mask: 0.7134  decode.d7.loss_dice: 0.8332  decode.d8.loss_cls: 2.3707  decode.d8.loss_mask: 0.6568  decode.d8.loss_dice: 0.8103
08/06 02:21:19 - mmengine - INFO - Iter(train) [   550/320000]  base_lr: 9.9846e-05 lr: 9.9846e-06  eta: 1 day, 19:57:14  time: 0.4876  data_time: 0.0102  memory: 5893  grad_norm: 366.8522  loss: 45.3491  decode.loss_cls: 2.7144  decode.loss_mask: 0.6506  decode.loss_dice: 0.7993  decode.d0.loss_cls: 6.7306  decode.d0.loss_mask: 0.6702  decode.d0.loss_dice: 1.0464  decode.d1.loss_cls: 2.7296  decode.d1.loss_mask: 0.7006  decode.d1.loss_dice: 0.7667  decode.d2.loss_cls: 2.6619  decode.d2.loss_mask: 0.5804  decode.d2.loss_dice: 0.7074  decode.d3.loss_cls: 2.7316  decode.d3.loss_mask: 0.5845  decode.d3.loss_dice: 0.6946  decode.d4.loss_cls: 2.6832  decode.d4.loss_mask: 0.6341  decode.d4.loss_dice: 0.7309  decode.d5.loss_cls: 2.6895  decode.d5.loss_mask: 0.6292  decode.d5.loss_dice: 0.7639  decode.d6.loss_cls: 2.6968  decode.d6.loss_mask: 0.6415  decode.d6.loss_dice: 0.7745  decode.d7.loss_cls: 2.6856  decode.d7.loss_mask: 0.6907  decode.d7.loss_dice: 0.7517  decode.d8.loss_cls: 2.7118  decode.d8.loss_mask: 0.6814  decode.d8.loss_dice: 0.8153
08/06 02:21:44 - mmengine - INFO - Iter(train) [   600/320000]  base_lr: 9.9832e-05 lr: 9.9832e-06  eta: 1 day, 19:53:36  time: 0.4872  data_time: 0.0104  memory: 5875  grad_norm: 237.0377  loss: 44.1159  decode.loss_cls: 2.6967  decode.loss_mask: 0.5861  decode.loss_dice: 0.6614  decode.d0.loss_cls: 6.5200  decode.d0.loss_mask: 0.7772  decode.d0.loss_dice: 1.1065  decode.d1.loss_cls: 2.6323  decode.d1.loss_mask: 0.6430  decode.d1.loss_dice: 0.7938  decode.d2.loss_cls: 2.5904  decode.d2.loss_mask: 0.5959  decode.d2.loss_dice: 0.6533  decode.d3.loss_cls: 2.5761  decode.d3.loss_mask: 0.6034  decode.d3.loss_dice: 0.6588  decode.d4.loss_cls: 2.6507  decode.d4.loss_mask: 0.6535  decode.d4.loss_dice: 0.7014  decode.d5.loss_cls: 2.7266  decode.d5.loss_mask: 0.6100  decode.d5.loss_dice: 0.6959  decode.d6.loss_cls: 2.6966  decode.d6.loss_mask: 0.6382  decode.d6.loss_dice: 0.6860  decode.d7.loss_cls: 2.7061  decode.d7.loss_mask: 0.6680  decode.d7.loss_dice: 0.6512  decode.d8.loss_cls: 2.6690  decode.d8.loss_mask: 0.6029  decode.d8.loss_dice: 0.6647
08/06 02:22:08 - mmengine - INFO - Iter(train) [   650/320000]  base_lr: 9.9817e-05 lr: 9.9817e-06  eta: 1 day, 19:50:31  time: 0.4885  data_time: 0.0105  memory: 5908  grad_norm: 225.0499  loss: 41.8999  decode.loss_cls: 2.4333  decode.loss_mask: 0.5828  decode.loss_dice: 0.7398  decode.d0.loss_cls: 6.5042  decode.d0.loss_mask: 0.6534  decode.d0.loss_dice: 1.1760  decode.d1.loss_cls: 2.6164  decode.d1.loss_mask: 0.4899  decode.d1.loss_dice: 0.7665  decode.d2.loss_cls: 2.5133  decode.d2.loss_mask: 0.4754  decode.d2.loss_dice: 0.7050  decode.d3.loss_cls: 2.4627  decode.d3.loss_mask: 0.4654  decode.d3.loss_dice: 0.6817  decode.d4.loss_cls: 2.4429  decode.d4.loss_mask: 0.5098  decode.d4.loss_dice: 0.7220  decode.d5.loss_cls: 2.4748  decode.d5.loss_mask: 0.5109  decode.d5.loss_dice: 0.6988  decode.d6.loss_cls: 2.4530  decode.d6.loss_mask: 0.5329  decode.d6.loss_dice: 0.7287  decode.d7.loss_cls: 2.4236  decode.d7.loss_mask: 0.5581  decode.d7.loss_dice: 0.7437  decode.d8.loss_cls: 2.4718  decode.d8.loss_mask: 0.6202  decode.d8.loss_dice: 0.7429
08/06 02:22:33 - mmengine - INFO - Iter(train) [   700/320000]  base_lr: 9.9803e-05 lr: 9.9803e-06  eta: 1 day, 19:48:01  time: 0.4886  data_time: 0.0104  memory: 5907  grad_norm: 246.2066  loss: 40.5143  decode.loss_cls: 2.2118  decode.loss_mask: 0.7581  decode.loss_dice: 0.7355  decode.d0.loss_cls: 6.5318  decode.d0.loss_mask: 0.7995  decode.d0.loss_dice: 0.9523  decode.d1.loss_cls: 2.2892  decode.d1.loss_mask: 0.6227  decode.d1.loss_dice: 0.6959  decode.d2.loss_cls: 2.0789  decode.d2.loss_mask: 0.7650  decode.d2.loss_dice: 0.6731  decode.d3.loss_cls: 2.1108  decode.d3.loss_mask: 0.7327  decode.d3.loss_dice: 0.6691  decode.d4.loss_cls: 2.1576  decode.d4.loss_mask: 0.6899  decode.d4.loss_dice: 0.6590  decode.d5.loss_cls: 2.2307  decode.d5.loss_mask: 0.6961  decode.d5.loss_dice: 0.6568  decode.d6.loss_cls: 2.2441  decode.d6.loss_mask: 0.7329  decode.d6.loss_dice: 0.6511  decode.d7.loss_cls: 2.1973  decode.d7.loss_mask: 0.7236  decode.d7.loss_dice: 0.6609  decode.d8.loss_cls: 2.1612  decode.d8.loss_mask: 0.7316  decode.d8.loss_dice: 0.6950
08/06 02:22:57 - mmengine - INFO - Iter(train) [   750/320000]  base_lr: 9.9789e-05 lr: 9.9789e-06  eta: 1 day, 19:45:54  time: 0.4894  data_time: 0.0104  memory: 5895  grad_norm: 250.1668  loss: 41.0588  decode.loss_cls: 2.4525  decode.loss_mask: 0.6010  decode.loss_dice: 0.6120  decode.d0.loss_cls: 6.2685  decode.d0.loss_mask: 0.6328  decode.d0.loss_dice: 0.8467  decode.d1.loss_cls: 2.5536  decode.d1.loss_mask: 0.5916  decode.d1.loss_dice: 0.6310  decode.d2.loss_cls: 2.5195  decode.d2.loss_mask: 0.5316  decode.d2.loss_dice: 0.5851  decode.d3.loss_cls: 2.5335  decode.d3.loss_mask: 0.5666  decode.d3.loss_dice: 0.5969  decode.d4.loss_cls: 2.6251  decode.d4.loss_mask: 0.5648  decode.d4.loss_dice: 0.5929  decode.d5.loss_cls: 2.5817  decode.d5.loss_mask: 0.5711  decode.d5.loss_dice: 0.5879  decode.d6.loss_cls: 2.5282  decode.d6.loss_mask: 0.5596  decode.d6.loss_dice: 0.5925  decode.d7.loss_cls: 2.5164  decode.d7.loss_mask: 0.5502  decode.d7.loss_dice: 0.6035  decode.d8.loss_cls: 2.5000  decode.d8.loss_mask: 0.5525  decode.d8.loss_dice: 0.6096
08/06 02:23:22 - mmengine - INFO - Iter(train) [   800/320000]  base_lr: 9.9775e-05 lr: 9.9775e-06  eta: 1 day, 19:43:59  time: 0.4893  data_time: 0.0104  memory: 5908  grad_norm: 216.4431  loss: 39.7185  decode.loss_cls: 2.4368  decode.loss_mask: 0.5482  decode.loss_dice: 0.5996  decode.d0.loss_cls: 6.1644  decode.d0.loss_mask: 0.6357  decode.d0.loss_dice: 0.8880  decode.d1.loss_cls: 2.4653  decode.d1.loss_mask: 0.5779  decode.d1.loss_dice: 0.6441  decode.d2.loss_cls: 2.1859  decode.d2.loss_mask: 0.5707  decode.d2.loss_dice: 0.5971  decode.d3.loss_cls: 2.3101  decode.d3.loss_mask: 0.5514  decode.d3.loss_dice: 0.5804  decode.d4.loss_cls: 2.4249  decode.d4.loss_mask: 0.5560  decode.d4.loss_dice: 0.5890  decode.d5.loss_cls: 2.4791  decode.d5.loss_mask: 0.5126  decode.d5.loss_dice: 0.5886  decode.d6.loss_cls: 2.4992  decode.d6.loss_mask: 0.5241  decode.d6.loss_dice: 0.6234  decode.d7.loss_cls: 2.4811  decode.d7.loss_mask: 0.5257  decode.d7.loss_dice: 0.5869  decode.d8.loss_cls: 2.4357  decode.d8.loss_mask: 0.5265  decode.d8.loss_dice: 0.6102
08/06 02:23:46 - mmengine - INFO - Iter(train) [   850/320000]  base_lr: 9.9761e-05 lr: 9.9761e-06  eta: 1 day, 19:42:07  time: 0.4883  data_time: 0.0103  memory: 5909  grad_norm: 178.9452  loss: 35.1361  decode.loss_cls: 2.0882  decode.loss_mask: 0.4973  decode.loss_dice: 0.5670  decode.d0.loss_cls: 5.9629  decode.d0.loss_mask: 0.5475  decode.d0.loss_dice: 0.8060  decode.d1.loss_cls: 2.0754  decode.d1.loss_mask: 0.5062  decode.d1.loss_dice: 0.5814  decode.d2.loss_cls: 2.0090  decode.d2.loss_mask: 0.4662  decode.d2.loss_dice: 0.5288  decode.d3.loss_cls: 2.0253  decode.d3.loss_mask: 0.4905  decode.d3.loss_dice: 0.5693  decode.d4.loss_cls: 2.1057  decode.d4.loss_mask: 0.4980  decode.d4.loss_dice: 0.5411  decode.d5.loss_cls: 2.0585  decode.d5.loss_mask: 0.4785  decode.d5.loss_dice: 0.5219  decode.d6.loss_cls: 2.0163  decode.d6.loss_mask: 0.5081  decode.d6.loss_dice: 0.5494  decode.d7.loss_cls: 2.0655  decode.d7.loss_mask: 0.4932  decode.d7.loss_dice: 0.5426  decode.d8.loss_cls: 2.0374  decode.d8.loss_mask: 0.4736  decode.d8.loss_dice: 0.5256
08/06 02:24:11 - mmengine - INFO - Iter(train) [   900/320000]  base_lr: 9.9747e-05 lr: 9.9747e-06  eta: 1 day, 19:40:24  time: 0.4883  data_time: 0.0101  memory: 5891  grad_norm: 290.3508  loss: 40.0526  decode.loss_cls: 2.3126  decode.loss_mask: 0.5406  decode.loss_dice: 0.6469  decode.d0.loss_cls: 5.8304  decode.d0.loss_mask: 0.6185  decode.d0.loss_dice: 0.9084  decode.d1.loss_cls: 2.3746  decode.d1.loss_mask: 0.5187  decode.d1.loss_dice: 0.6029  decode.d2.loss_cls: 2.2112  decode.d2.loss_mask: 0.5216  decode.d2.loss_dice: 0.6475  decode.d3.loss_cls: 2.2524  decode.d3.loss_mask: 0.5964  decode.d3.loss_dice: 0.6316  decode.d4.loss_cls: 2.3242  decode.d4.loss_mask: 0.6047  decode.d4.loss_dice: 0.7278  decode.d5.loss_cls: 2.3711  decode.d5.loss_mask: 0.7201  decode.d5.loss_dice: 0.7421  decode.d6.loss_cls: 2.3822  decode.d6.loss_mask: 0.6769  decode.d6.loss_dice: 0.6997  decode.d7.loss_cls: 2.3786  decode.d7.loss_mask: 0.7055  decode.d7.loss_dice: 0.7707  decode.d8.loss_cls: 2.3114  decode.d8.loss_mask: 0.6922  decode.d8.loss_dice: 0.7311
08/06 02:24:35 - mmengine - INFO - Iter(train) [   950/320000]  base_lr: 9.9733e-05 lr: 9.9733e-06  eta: 1 day, 19:38:53  time: 0.4891  data_time: 0.0101  memory: 5892  grad_norm: 225.7848  loss: 38.6572  decode.loss_cls: 2.3905  decode.loss_mask: 0.4106  decode.loss_dice: 0.6143  decode.d0.loss_cls: 5.8775  decode.d0.loss_mask: 0.6128  decode.d0.loss_dice: 0.9543  decode.d1.loss_cls: 2.5394  decode.d1.loss_mask: 0.4147  decode.d1.loss_dice: 0.5682  decode.d2.loss_cls: 2.3573  decode.d2.loss_mask: 0.4588  decode.d2.loss_dice: 0.5590  decode.d3.loss_cls: 2.3555  decode.d3.loss_mask: 0.4476  decode.d3.loss_dice: 0.5877  decode.d4.loss_cls: 2.4236  decode.d4.loss_mask: 0.4397  decode.d4.loss_dice: 0.5684  decode.d5.loss_cls: 2.4321  decode.d5.loss_mask: 0.4594  decode.d5.loss_dice: 0.5907  decode.d6.loss_cls: 2.4162  decode.d6.loss_mask: 0.4266  decode.d6.loss_dice: 0.5958  decode.d7.loss_cls: 2.4809  decode.d7.loss_mask: 0.4738  decode.d7.loss_dice: 0.6490  decode.d8.loss_cls: 2.4861  decode.d8.loss_mask: 0.4517  decode.d8.loss_dice: 0.6153
08/06 02:24:59 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 02:24:59 - mmengine - INFO - Iter(train) [  1000/320000]  base_lr: 9.9719e-05 lr: 9.9719e-06  eta: 1 day, 19:37:23  time: 0.4890  data_time: 0.0105  memory: 5890  grad_norm: 323.4423  loss: 37.2938  decode.loss_cls: 1.9170  decode.loss_mask: 0.6888  decode.loss_dice: 0.6362  decode.d0.loss_cls: 5.6201  decode.d0.loss_mask: 0.8457  decode.d0.loss_dice: 0.9220  decode.d1.loss_cls: 2.1510  decode.d1.loss_mask: 0.6559  decode.d1.loss_dice: 0.6229  decode.d2.loss_cls: 1.8686  decode.d2.loss_mask: 0.7229  decode.d2.loss_dice: 0.6692  decode.d3.loss_cls: 1.9031  decode.d3.loss_mask: 0.7775  decode.d3.loss_dice: 0.6735  decode.d4.loss_cls: 2.0227  decode.d4.loss_mask: 0.6927  decode.d4.loss_dice: 0.6312  decode.d5.loss_cls: 2.0129  decode.d5.loss_mask: 0.6558  decode.d5.loss_dice: 0.6160  decode.d6.loss_cls: 2.0173  decode.d6.loss_mask: 0.6956  decode.d6.loss_dice: 0.6094  decode.d7.loss_cls: 2.0414  decode.d7.loss_mask: 0.7115  decode.d7.loss_dice: 0.6006  decode.d8.loss_cls: 1.9676  decode.d8.loss_mask: 0.7370  decode.d8.loss_dice: 0.6077
08/06 02:25:24 - mmengine - INFO - Iter(train) [  1050/320000]  base_lr: 9.9705e-05 lr: 9.9705e-06  eta: 1 day, 19:36:35  time: 0.4891  data_time: 0.0102  memory: 5874  grad_norm: 272.6884  loss: 41.3524  decode.loss_cls: 2.7107  decode.loss_mask: 0.4627  decode.loss_dice: 0.6077  decode.d0.loss_cls: 5.7560  decode.d0.loss_mask: 0.6544  decode.d0.loss_dice: 1.0534  decode.d1.loss_cls: 2.7219  decode.d1.loss_mask: 0.5185  decode.d1.loss_dice: 0.6792  decode.d2.loss_cls: 2.5514  decode.d2.loss_mask: 0.5190  decode.d2.loss_dice: 0.6183  decode.d3.loss_cls: 2.5494  decode.d3.loss_mask: 0.5231  decode.d3.loss_dice: 0.6311  decode.d4.loss_cls: 2.6876  decode.d4.loss_mask: 0.4980  decode.d4.loss_dice: 0.6137  decode.d5.loss_cls: 2.6125  decode.d5.loss_mask: 0.5025  decode.d5.loss_dice: 0.6077  decode.d6.loss_cls: 2.5930  decode.d6.loss_mask: 0.4933  decode.d6.loss_dice: 0.6292  decode.d7.loss_cls: 2.6067  decode.d7.loss_mask: 0.4879  decode.d7.loss_dice: 0.6501  decode.d8.loss_cls: 2.7193  decode.d8.loss_mask: 0.4844  decode.d8.loss_dice: 0.6099
08/06 02:25:48 - mmengine - INFO - Iter(train) [  1100/320000]  base_lr: 9.9691e-05 lr: 9.9691e-06  eta: 1 day, 19:35:18  time: 0.4883  data_time: 0.0102  memory: 5908  grad_norm: 306.6093  loss: 38.1815  decode.loss_cls: 2.3481  decode.loss_mask: 0.4435  decode.loss_dice: 0.5717  decode.d0.loss_cls: 5.5498  decode.d0.loss_mask: 0.5501  decode.d0.loss_dice: 0.8780  decode.d1.loss_cls: 2.5615  decode.d1.loss_mask: 0.4331  decode.d1.loss_dice: 0.5669  decode.d2.loss_cls: 2.4082  decode.d2.loss_mask: 0.4572  decode.d2.loss_dice: 0.5382  decode.d3.loss_cls: 2.3405  decode.d3.loss_mask: 0.4768  decode.d3.loss_dice: 0.5807  decode.d4.loss_cls: 2.4356  decode.d4.loss_mask: 0.4936  decode.d4.loss_dice: 0.5863  decode.d5.loss_cls: 2.3803  decode.d5.loss_mask: 0.4723  decode.d5.loss_dice: 0.5737  decode.d6.loss_cls: 2.3873  decode.d6.loss_mask: 0.5382  decode.d6.loss_dice: 0.6587  decode.d7.loss_cls: 2.3386  decode.d7.loss_mask: 0.5305  decode.d7.loss_dice: 0.6419  decode.d8.loss_cls: 2.3583  decode.d8.loss_mask: 0.4797  decode.d8.loss_dice: 0.6020
08/06 02:26:13 - mmengine - INFO - Iter(train) [  1150/320000]  base_lr: 9.9677e-05 lr: 9.9677e-06  eta: 1 day, 19:34:04  time: 0.4883  data_time: 0.0104  memory: 5907  grad_norm: 216.6767  loss: 37.3376  decode.loss_cls: 2.3325  decode.loss_mask: 0.3992  decode.loss_dice: 0.6009  decode.d0.loss_cls: 5.3871  decode.d0.loss_mask: 0.5239  decode.d0.loss_dice: 0.8676  decode.d1.loss_cls: 2.5343  decode.d1.loss_mask: 0.4277  decode.d1.loss_dice: 0.5757  decode.d2.loss_cls: 2.3913  decode.d2.loss_mask: 0.3960  decode.d2.loss_dice: 0.5393  decode.d3.loss_cls: 2.3891  decode.d3.loss_mask: 0.4336  decode.d3.loss_dice: 0.5522  decode.d4.loss_cls: 2.3830  decode.d4.loss_mask: 0.4034  decode.d4.loss_dice: 0.5614  decode.d5.loss_cls: 2.3911  decode.d5.loss_mask: 0.4144  decode.d5.loss_dice: 0.5619  decode.d6.loss_cls: 2.3767  decode.d6.loss_mask: 0.4492  decode.d6.loss_dice: 0.6316  decode.d7.loss_cls: 2.3715  decode.d7.loss_mask: 0.4450  decode.d7.loss_dice: 0.6551  decode.d8.loss_cls: 2.3067  decode.d8.loss_mask: 0.4344  decode.d8.loss_dice: 0.6020
08/06 02:26:37 - mmengine - INFO - Iter(train) [  1200/320000]  base_lr: 9.9663e-05 lr: 9.9663e-06  eta: 1 day, 19:32:51  time: 0.4879  data_time: 0.0102  memory: 5980  grad_norm: 231.7685  loss: 37.5549  decode.loss_cls: 2.4574  decode.loss_mask: 0.5408  decode.loss_dice: 0.7007  decode.d0.loss_cls: 5.3364  decode.d0.loss_mask: 0.5818  decode.d0.loss_dice: 0.9579  decode.d1.loss_cls: 2.4401  decode.d1.loss_mask: 0.4106  decode.d1.loss_dice: 0.5789  decode.d2.loss_cls: 2.3416  decode.d2.loss_mask: 0.4120  decode.d2.loss_dice: 0.5679  decode.d3.loss_cls: 2.3085  decode.d3.loss_mask: 0.4351  decode.d3.loss_dice: 0.5722  decode.d4.loss_cls: 2.4113  decode.d4.loss_mask: 0.4275  decode.d4.loss_dice: 0.5703  decode.d5.loss_cls: 2.3162  decode.d5.loss_mask: 0.4471  decode.d5.loss_dice: 0.5776  decode.d6.loss_cls: 2.2839  decode.d6.loss_mask: 0.4009  decode.d6.loss_dice: 0.5581  decode.d7.loss_cls: 2.3500  decode.d7.loss_mask: 0.4277  decode.d7.loss_dice: 0.5632  decode.d8.loss_cls: 2.5113  decode.d8.loss_mask: 0.4616  decode.d8.loss_dice: 0.6061
08/06 02:27:02 - mmengine - INFO - Iter(train) [  1250/320000]  base_lr: 9.9649e-05 lr: 9.9649e-06  eta: 1 day, 19:31:46  time: 0.4875  data_time: 0.0103  memory: 5891  grad_norm: 219.3307  loss: 35.5375  decode.loss_cls: 2.2446  decode.loss_mask: 0.4356  decode.loss_dice: 0.5635  decode.d0.loss_cls: 5.2028  decode.d0.loss_mask: 0.5896  decode.d0.loss_dice: 0.8628  decode.d1.loss_cls: 2.3940  decode.d1.loss_mask: 0.4472  decode.d1.loss_dice: 0.6171  decode.d2.loss_cls: 2.1394  decode.d2.loss_mask: 0.4687  decode.d2.loss_dice: 0.5552  decode.d3.loss_cls: 2.1200  decode.d3.loss_mask: 0.4782  decode.d3.loss_dice: 0.5553  decode.d4.loss_cls: 2.1976  decode.d4.loss_mask: 0.4502  decode.d4.loss_dice: 0.5408  decode.d5.loss_cls: 2.1662  decode.d5.loss_mask: 0.4693  decode.d5.loss_dice: 0.5393  decode.d6.loss_cls: 2.1708  decode.d6.loss_mask: 0.4440  decode.d6.loss_dice: 0.5236  decode.d7.loss_cls: 2.1587  decode.d7.loss_mask: 0.4589  decode.d7.loss_dice: 0.5467  decode.d8.loss_cls: 2.2054  decode.d8.loss_mask: 0.4317  decode.d8.loss_dice: 0.5602
08/06 02:27:26 - mmengine - INFO - Iter(train) [  1300/320000]  base_lr: 9.9635e-05 lr: 9.9635e-06  eta: 1 day, 19:30:38  time: 0.4881  data_time: 0.0105  memory: 5927  grad_norm: 238.6654  loss: 34.9284  decode.loss_cls: 2.2400  decode.loss_mask: 0.4741  decode.loss_dice: 0.5122  decode.d0.loss_cls: 5.1740  decode.d0.loss_mask: 0.5114  decode.d0.loss_dice: 0.7005  decode.d1.loss_cls: 2.3539  decode.d1.loss_mask: 0.4926  decode.d1.loss_dice: 0.5186  decode.d2.loss_cls: 2.0601  decode.d2.loss_mask: 0.4990  decode.d2.loss_dice: 0.4913  decode.d3.loss_cls: 2.1455  decode.d3.loss_mask: 0.4960  decode.d3.loss_dice: 0.5121  decode.d4.loss_cls: 2.2083  decode.d4.loss_mask: 0.4684  decode.d4.loss_dice: 0.5127  decode.d5.loss_cls: 2.1405  decode.d5.loss_mask: 0.4847  decode.d5.loss_dice: 0.5207  decode.d6.loss_cls: 2.2065  decode.d6.loss_mask: 0.4989  decode.d6.loss_dice: 0.4781  decode.d7.loss_cls: 2.1928  decode.d7.loss_mask: 0.4701  decode.d7.loss_dice: 0.5020  decode.d8.loss_cls: 2.1213  decode.d8.loss_mask: 0.4683  decode.d8.loss_dice: 0.4737
08/06 02:27:50 - mmengine - INFO - Iter(train) [  1350/320000]  base_lr: 9.9621e-05 lr: 9.9621e-06  eta: 1 day, 19:29:37  time: 0.4882  data_time: 0.0102  memory: 5966  grad_norm: 409.6792  loss: 36.0220  decode.loss_cls: 2.0659  decode.loss_mask: 0.5092  decode.loss_dice: 0.6153  decode.d0.loss_cls: 4.9405  decode.d0.loss_mask: 0.6814  decode.d0.loss_dice: 0.8842  decode.d1.loss_cls: 2.4116  decode.d1.loss_mask: 0.4967  decode.d1.loss_dice: 0.5814  decode.d2.loss_cls: 2.1820  decode.d2.loss_mask: 0.5042  decode.d2.loss_dice: 0.5679  decode.d3.loss_cls: 2.1828  decode.d3.loss_mask: 0.4983  decode.d3.loss_dice: 0.5681  decode.d4.loss_cls: 2.3041  decode.d4.loss_mask: 0.4956  decode.d4.loss_dice: 0.5541  decode.d5.loss_cls: 2.1768  decode.d5.loss_mask: 0.4662  decode.d5.loss_dice: 0.5956  decode.d6.loss_cls: 2.1384  decode.d6.loss_mask: 0.4736  decode.d6.loss_dice: 0.5733  decode.d7.loss_cls: 2.1744  decode.d7.loss_mask: 0.5269  decode.d7.loss_dice: 0.5758  decode.d8.loss_cls: 2.1745  decode.d8.loss_mask: 0.5231  decode.d8.loss_dice: 0.5798
08/06 02:28:15 - mmengine - INFO - Iter(train) [  1400/320000]  base_lr: 9.9606e-05 lr: 9.9606e-06  eta: 1 day, 19:28:37  time: 0.4887  data_time: 0.0104  memory: 5892  grad_norm: 234.3405  loss: 37.8902  decode.loss_cls: 2.2184  decode.loss_mask: 0.5769  decode.loss_dice: 0.6531  decode.d0.loss_cls: 4.9474  decode.d0.loss_mask: 0.6836  decode.d0.loss_dice: 0.8161  decode.d1.loss_cls: 2.4569  decode.d1.loss_mask: 0.5633  decode.d1.loss_dice: 0.6125  decode.d2.loss_cls: 2.2679  decode.d2.loss_mask: 0.5400  decode.d2.loss_dice: 0.6175  decode.d3.loss_cls: 2.2476  decode.d3.loss_mask: 0.5895  decode.d3.loss_dice: 0.6436  decode.d4.loss_cls: 2.3062  decode.d4.loss_mask: 0.5762  decode.d4.loss_dice: 0.6504  decode.d5.loss_cls: 2.2901  decode.d5.loss_mask: 0.6066  decode.d5.loss_dice: 0.6228  decode.d6.loss_cls: 2.2644  decode.d6.loss_mask: 0.5767  decode.d6.loss_dice: 0.6190  decode.d7.loss_cls: 2.1780  decode.d7.loss_mask: 0.6002  decode.d7.loss_dice: 0.6429  decode.d8.loss_cls: 2.3034  decode.d8.loss_mask: 0.5711  decode.d8.loss_dice: 0.6479
08/06 02:28:39 - mmengine - INFO - Iter(train) [  1450/320000]  base_lr: 9.9592e-05 lr: 9.9592e-06  eta: 1 day, 19:27:43  time: 0.4878  data_time: 0.0101  memory: 5889  grad_norm: 364.3848  loss: 35.3351  decode.loss_cls: 2.1390  decode.loss_mask: 0.4808  decode.loss_dice: 0.6592  decode.d0.loss_cls: 4.7774  decode.d0.loss_mask: 0.6368  decode.d0.loss_dice: 0.9108  decode.d1.loss_cls: 2.2816  decode.d1.loss_mask: 0.4604  decode.d1.loss_dice: 0.6569  decode.d2.loss_cls: 2.0573  decode.d2.loss_mask: 0.4695  decode.d2.loss_dice: 0.5868  decode.d3.loss_cls: 2.0535  decode.d3.loss_mask: 0.4683  decode.d3.loss_dice: 0.5703  decode.d4.loss_cls: 2.1217  decode.d4.loss_mask: 0.4651  decode.d4.loss_dice: 0.6019  decode.d5.loss_cls: 2.0467  decode.d5.loss_mask: 0.4840  decode.d5.loss_dice: 0.6244  decode.d6.loss_cls: 2.0876  decode.d6.loss_mask: 0.4915  decode.d6.loss_dice: 0.6541  decode.d7.loss_cls: 2.1680  decode.d7.loss_mask: 0.4863  decode.d7.loss_dice: 0.6302  decode.d8.loss_cls: 2.1400  decode.d8.loss_mask: 0.5255  decode.d8.loss_dice: 0.5996
08/06 02:29:04 - mmengine - INFO - Iter(train) [  1500/320000]  base_lr: 9.9578e-05 lr: 9.9578e-06  eta: 1 day, 19:26:51  time: 0.4884  data_time: 0.0102  memory: 5895  grad_norm: 195.6342  loss: 31.9688  decode.loss_cls: 1.7743  decode.loss_mask: 0.5449  decode.loss_dice: 0.5877  decode.d0.loss_cls: 4.5485  decode.d0.loss_mask: 0.5042  decode.d0.loss_dice: 0.8218  decode.d1.loss_cls: 1.9831  decode.d1.loss_mask: 0.4367  decode.d1.loss_dice: 0.6290  decode.d2.loss_cls: 1.7671  decode.d2.loss_mask: 0.4445  decode.d2.loss_dice: 0.5894  decode.d3.loss_cls: 1.7953  decode.d3.loss_mask: 0.4236  decode.d3.loss_dice: 0.5437  decode.d4.loss_cls: 1.8815  decode.d4.loss_mask: 0.4187  decode.d4.loss_dice: 0.5764  decode.d5.loss_cls: 1.8100  decode.d5.loss_mask: 0.5345  decode.d5.loss_dice: 0.6223  decode.d6.loss_cls: 1.7723  decode.d6.loss_mask: 0.4836  decode.d6.loss_dice: 0.5948  decode.d7.loss_cls: 1.7340  decode.d7.loss_mask: 0.4943  decode.d7.loss_dice: 0.6373  decode.d8.loss_cls: 1.7803  decode.d8.loss_mask: 0.5965  decode.d8.loss_dice: 0.6387
08/06 02:29:28 - mmengine - INFO - Iter(train) [  1550/320000]  base_lr: 9.9564e-05 lr: 9.9564e-06  eta: 1 day, 19:26:01  time: 0.4883  data_time: 0.0103  memory: 5926  grad_norm: 277.7840  loss: 32.1384  decode.loss_cls: 1.8624  decode.loss_mask: 0.5858  decode.loss_dice: 0.5642  decode.d0.loss_cls: 4.3630  decode.d0.loss_mask: 0.6712  decode.d0.loss_dice: 0.8097  decode.d1.loss_cls: 1.9125  decode.d1.loss_mask: 0.5902  decode.d1.loss_dice: 0.5669  decode.d2.loss_cls: 1.6998  decode.d2.loss_mask: 0.5715  decode.d2.loss_dice: 0.5356  decode.d3.loss_cls: 1.7208  decode.d3.loss_mask: 0.5429  decode.d3.loss_dice: 0.5237  decode.d4.loss_cls: 1.7915  decode.d4.loss_mask: 0.5815  decode.d4.loss_dice: 0.5759  decode.d5.loss_cls: 1.7513  decode.d5.loss_mask: 0.5827  decode.d5.loss_dice: 0.5314  decode.d6.loss_cls: 1.7584  decode.d6.loss_mask: 0.5839  decode.d6.loss_dice: 0.5581  decode.d7.loss_cls: 1.7475  decode.d7.loss_mask: 0.5830  decode.d7.loss_dice: 0.5386  decode.d8.loss_cls: 1.8758  decode.d8.loss_mask: 0.5931  decode.d8.loss_dice: 0.5658
08/06 02:29:53 - mmengine - INFO - Iter(train) [  1600/320000]  base_lr: 9.9550e-05 lr: 9.9550e-06  eta: 1 day, 19:25:36  time: 0.4891  data_time: 0.0105  memory: 5907  grad_norm: 225.1636  loss: 34.6685  decode.loss_cls: 2.0561  decode.loss_mask: 0.4609  decode.loss_dice: 0.5105  decode.d0.loss_cls: 4.5571  decode.d0.loss_mask: 0.6143  decode.d0.loss_dice: 0.7780  decode.d1.loss_cls: 2.3845  decode.d1.loss_mask: 0.4998  decode.d1.loss_dice: 0.5833  decode.d2.loss_cls: 2.1547  decode.d2.loss_mask: 0.4509  decode.d2.loss_dice: 0.5405  decode.d3.loss_cls: 2.1318  decode.d3.loss_mask: 0.4744  decode.d3.loss_dice: 0.5371  decode.d4.loss_cls: 2.1268  decode.d4.loss_mask: 0.4698  decode.d4.loss_dice: 0.5520  decode.d5.loss_cls: 2.1362  decode.d5.loss_mask: 0.5014  decode.d5.loss_dice: 0.5591  decode.d6.loss_cls: 2.0976  decode.d6.loss_mask: 0.5300  decode.d6.loss_dice: 0.5639  decode.d7.loss_cls: 2.1121  decode.d7.loss_mask: 0.4960  decode.d7.loss_dice: 0.5664  decode.d8.loss_cls: 2.2333  decode.d8.loss_mask: 0.4698  decode.d8.loss_dice: 0.5202
08/06 02:30:17 - mmengine - INFO - Iter(train) [  1650/320000]  base_lr: 9.9536e-05 lr: 9.9536e-06  eta: 1 day, 19:24:45  time: 0.4892  data_time: 0.0104  memory: 5907  grad_norm: 293.9070  loss: 35.2359  decode.loss_cls: 1.9432  decode.loss_mask: 0.6408  decode.loss_dice: 0.7154  decode.d0.loss_cls: 4.2475  decode.d0.loss_mask: 0.7785  decode.d0.loss_dice: 0.9739  decode.d1.loss_cls: 2.1085  decode.d1.loss_mask: 0.5817  decode.d1.loss_dice: 0.6301  decode.d2.loss_cls: 1.8672  decode.d2.loss_mask: 0.6251  decode.d2.loss_dice: 0.6396  decode.d3.loss_cls: 1.9264  decode.d3.loss_mask: 0.5432  decode.d3.loss_dice: 0.6275  decode.d4.loss_cls: 1.9608  decode.d4.loss_mask: 0.6152  decode.d4.loss_dice: 0.6798  decode.d5.loss_cls: 1.9589  decode.d5.loss_mask: 0.5875  decode.d5.loss_dice: 0.6794  decode.d6.loss_cls: 1.9657  decode.d6.loss_mask: 0.6298  decode.d6.loss_dice: 0.7323  decode.d7.loss_cls: 1.9283  decode.d7.loss_mask: 0.6733  decode.d7.loss_dice: 0.7398  decode.d8.loss_cls: 2.0081  decode.d8.loss_mask: 0.5758  decode.d8.loss_dice: 0.6528
08/06 02:30:42 - mmengine - INFO - Iter(train) [  1700/320000]  base_lr: 9.9522e-05 lr: 9.9522e-06  eta: 1 day, 19:23:54  time: 0.4887  data_time: 0.0104  memory: 5907  grad_norm: 204.0917  loss: 31.5047  decode.loss_cls: 1.9031  decode.loss_mask: 0.4374  decode.loss_dice: 0.5052  decode.d0.loss_cls: 4.1401  decode.d0.loss_mask: 0.4620  decode.d0.loss_dice: 0.7610  decode.d1.loss_cls: 2.1498  decode.d1.loss_mask: 0.4127  decode.d1.loss_dice: 0.5560  decode.d2.loss_cls: 1.9075  decode.d2.loss_mask: 0.4062  decode.d2.loss_dice: 0.5265  decode.d3.loss_cls: 1.8882  decode.d3.loss_mask: 0.4123  decode.d3.loss_dice: 0.5200  decode.d4.loss_cls: 1.8834  decode.d4.loss_mask: 0.4209  decode.d4.loss_dice: 0.5242  decode.d5.loss_cls: 2.0425  decode.d5.loss_mask: 0.4179  decode.d5.loss_dice: 0.5327  decode.d6.loss_cls: 1.8735  decode.d6.loss_mask: 0.4460  decode.d6.loss_dice: 0.5376  decode.d7.loss_cls: 1.9596  decode.d7.loss_mask: 0.4630  decode.d7.loss_dice: 0.5364  decode.d8.loss_cls: 2.0004  decode.d8.loss_mask: 0.3728  decode.d8.loss_dice: 0.5058
08/06 02:31:06 - mmengine - INFO - Iter(train) [  1750/320000]  base_lr: 9.9508e-05 lr: 9.9508e-06  eta: 1 day, 19:23:07  time: 0.4885  data_time: 0.0104  memory: 5892  grad_norm: 258.3203  loss: 35.7033  decode.loss_cls: 2.1718  decode.loss_mask: 0.4824  decode.loss_dice: 0.6444  decode.d0.loss_cls: 4.1619  decode.d0.loss_mask: 0.5542  decode.d0.loss_dice: 0.8636  decode.d1.loss_cls: 2.3092  decode.d1.loss_mask: 0.4845  decode.d1.loss_dice: 0.6827  decode.d2.loss_cls: 2.2645  decode.d2.loss_mask: 0.5015  decode.d2.loss_dice: 0.6543  decode.d3.loss_cls: 2.1797  decode.d3.loss_mask: 0.4728  decode.d3.loss_dice: 0.6400  decode.d4.loss_cls: 2.1933  decode.d4.loss_mask: 0.4759  decode.d4.loss_dice: 0.6838  decode.d5.loss_cls: 2.1354  decode.d5.loss_mask: 0.4849  decode.d5.loss_dice: 0.6379  decode.d6.loss_cls: 2.0715  decode.d6.loss_mask: 0.5131  decode.d6.loss_dice: 0.6637  decode.d7.loss_cls: 2.1984  decode.d7.loss_mask: 0.5058  decode.d7.loss_dice: 0.7012  decode.d8.loss_cls: 2.2853  decode.d8.loss_mask: 0.4767  decode.d8.loss_dice: 0.6087
08/06 02:31:30 - mmengine - INFO - Iter(train) [  1800/320000]  base_lr: 9.9494e-05 lr: 9.9494e-06  eta: 1 day, 19:22:20  time: 0.4884  data_time: 0.0103  memory: 5907  grad_norm: 196.6094  loss: 31.8284  decode.loss_cls: 1.9827  decode.loss_mask: 0.4696  decode.loss_dice: 0.5454  decode.d0.loss_cls: 4.0943  decode.d0.loss_mask: 0.4858  decode.d0.loss_dice: 0.7593  decode.d1.loss_cls: 2.3427  decode.d1.loss_mask: 0.3435  decode.d1.loss_dice: 0.4617  decode.d2.loss_cls: 2.0776  decode.d2.loss_mask: 0.3662  decode.d2.loss_dice: 0.4904  decode.d3.loss_cls: 1.9627  decode.d3.loss_mask: 0.3464  decode.d3.loss_dice: 0.4953  decode.d4.loss_cls: 2.0722  decode.d4.loss_mask: 0.3791  decode.d4.loss_dice: 0.5177  decode.d5.loss_cls: 2.0450  decode.d5.loss_mask: 0.3666  decode.d5.loss_dice: 0.5284  decode.d6.loss_cls: 1.9036  decode.d6.loss_mask: 0.4148  decode.d6.loss_dice: 0.5148  decode.d7.loss_cls: 1.9699  decode.d7.loss_mask: 0.3840  decode.d7.loss_dice: 0.4742  decode.d8.loss_cls: 2.0735  decode.d8.loss_mask: 0.4413  decode.d8.loss_dice: 0.5196
08/06 02:31:55 - mmengine - INFO - Iter(train) [  1850/320000]  base_lr: 9.9480e-05 lr: 9.9480e-06  eta: 1 day, 19:21:34  time: 0.4882  data_time: 0.0103  memory: 5875  grad_norm: 383.2812  loss: 32.6122  decode.loss_cls: 1.9275  decode.loss_mask: 0.6434  decode.loss_dice: 0.6052  decode.d0.loss_cls: 3.8585  decode.d0.loss_mask: 0.6448  decode.d0.loss_dice: 0.7486  decode.d1.loss_cls: 2.1763  decode.d1.loss_mask: 0.4825  decode.d1.loss_dice: 0.5228  decode.d2.loss_cls: 1.8755  decode.d2.loss_mask: 0.4200  decode.d2.loss_dice: 0.4910  decode.d3.loss_cls: 1.8755  decode.d3.loss_mask: 0.4264  decode.d3.loss_dice: 0.4831  decode.d4.loss_cls: 1.9410  decode.d4.loss_mask: 0.5031  decode.d4.loss_dice: 0.5297  decode.d5.loss_cls: 2.0489  decode.d5.loss_mask: 0.4777  decode.d5.loss_dice: 0.5283  decode.d6.loss_cls: 1.9904  decode.d6.loss_mask: 0.5933  decode.d6.loss_dice: 0.5881  decode.d7.loss_cls: 2.0582  decode.d7.loss_mask: 0.5152  decode.d7.loss_dice: 0.5530  decode.d8.loss_cls: 1.9754  decode.d8.loss_mask: 0.5957  decode.d8.loss_dice: 0.5330
08/06 02:32:19 - mmengine - INFO - Iter(train) [  1900/320000]  base_lr: 9.9466e-05 lr: 9.9466e-06  eta: 1 day, 19:21:25  time: 0.4884  data_time: 0.0105  memory: 5908  grad_norm: 222.3356  loss: 29.1156  decode.loss_cls: 1.7059  decode.loss_mask: 0.4492  decode.loss_dice: 0.5036  decode.d0.loss_cls: 3.6272  decode.d0.loss_mask: 0.6203  decode.d0.loss_dice: 0.7278  decode.d1.loss_cls: 1.7503  decode.d1.loss_mask: 0.5475  decode.d1.loss_dice: 0.5723  decode.d2.loss_cls: 1.7843  decode.d2.loss_mask: 0.4567  decode.d2.loss_dice: 0.4934  decode.d3.loss_cls: 1.6486  decode.d3.loss_mask: 0.4890  decode.d3.loss_dice: 0.5120  decode.d4.loss_cls: 1.7317  decode.d4.loss_mask: 0.4681  decode.d4.loss_dice: 0.4785  decode.d5.loss_cls: 1.7203  decode.d5.loss_mask: 0.4714  decode.d5.loss_dice: 0.4661  decode.d6.loss_cls: 1.6394  decode.d6.loss_mask: 0.4715  decode.d6.loss_dice: 0.5012  decode.d7.loss_cls: 1.6498  decode.d7.loss_mask: 0.4245  decode.d7.loss_dice: 0.4932  decode.d8.loss_cls: 1.7599  decode.d8.loss_mask: 0.4601  decode.d8.loss_dice: 0.4918
08/06 02:32:44 - mmengine - INFO - Iter(train) [  1950/320000]  base_lr: 9.9452e-05 lr: 9.9452e-06  eta: 1 day, 19:20:43  time: 0.4886  data_time: 0.0102  memory: 5895  grad_norm: 225.3153  loss: 32.5571  decode.loss_cls: 2.1256  decode.loss_mask: 0.3976  decode.loss_dice: 0.4872  decode.d0.loss_cls: 3.7132  decode.d0.loss_mask: 0.6171  decode.d0.loss_dice: 0.7891  decode.d1.loss_cls: 2.3185  decode.d1.loss_mask: 0.4352  decode.d1.loss_dice: 0.4896  decode.d2.loss_cls: 2.0644  decode.d2.loss_mask: 0.4050  decode.d2.loss_dice: 0.4671  decode.d3.loss_cls: 1.9817  decode.d3.loss_mask: 0.4217  decode.d3.loss_dice: 0.4774  decode.d4.loss_cls: 2.0368  decode.d4.loss_mask: 0.4983  decode.d4.loss_dice: 0.5410  decode.d5.loss_cls: 2.1682  decode.d5.loss_mask: 0.4441  decode.d5.loss_dice: 0.4966  decode.d6.loss_cls: 2.1436  decode.d6.loss_mask: 0.4260  decode.d6.loss_dice: 0.5198  decode.d7.loss_cls: 2.1098  decode.d7.loss_mask: 0.4286  decode.d7.loss_dice: 0.4992  decode.d8.loss_cls: 2.1362  decode.d8.loss_mask: 0.4228  decode.d8.loss_dice: 0.4956
08/06 02:33:08 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 02:33:08 - mmengine - INFO - Iter(train) [  2000/320000]  base_lr: 9.9438e-05 lr: 9.9438e-06  eta: 1 day, 19:19:59  time: 0.4885  data_time: 0.0102  memory: 5875  grad_norm: 249.8662  loss: 30.3562  decode.loss_cls: 2.1089  decode.loss_mask: 0.3669  decode.loss_dice: 0.4466  decode.d0.loss_cls: 3.5803  decode.d0.loss_mask: 0.4750  decode.d0.loss_dice: 0.6847  decode.d1.loss_cls: 2.0799  decode.d1.loss_mask: 0.3797  decode.d1.loss_dice: 0.4508  decode.d2.loss_cls: 1.9297  decode.d2.loss_mask: 0.3773  decode.d2.loss_dice: 0.4346  decode.d3.loss_cls: 1.9426  decode.d3.loss_mask: 0.3697  decode.d3.loss_dice: 0.4333  decode.d4.loss_cls: 2.0038  decode.d4.loss_mask: 0.4072  decode.d4.loss_dice: 0.4629  decode.d5.loss_cls: 1.9893  decode.d5.loss_mask: 0.3655  decode.d5.loss_dice: 0.4485  decode.d6.loss_cls: 2.0431  decode.d6.loss_mask: 0.3649  decode.d6.loss_dice: 0.4791  decode.d7.loss_cls: 2.0351  decode.d7.loss_mask: 0.3686  decode.d7.loss_dice: 0.4822  decode.d8.loss_cls: 2.0292  decode.d8.loss_mask: 0.3511  decode.d8.loss_dice: 0.4655
08/06 02:33:33 - mmengine - INFO - Iter(train) [  2050/320000]  base_lr: 9.9424e-05 lr: 9.9424e-06  eta: 1 day, 19:19:19  time: 0.4895  data_time: 0.0105  memory: 5908  grad_norm: 344.1642  loss: 28.0715  decode.loss_cls: 1.6682  decode.loss_mask: 0.4827  decode.loss_dice: 0.4657  decode.d0.loss_cls: 3.3062  decode.d0.loss_mask: 0.5719  decode.d0.loss_dice: 0.7362  decode.d1.loss_cls: 1.7834  decode.d1.loss_mask: 0.4933  decode.d1.loss_dice: 0.5070  decode.d2.loss_cls: 1.5930  decode.d2.loss_mask: 0.5165  decode.d2.loss_dice: 0.4768  decode.d3.loss_cls: 1.6333  decode.d3.loss_mask: 0.4674  decode.d3.loss_dice: 0.4938  decode.d4.loss_cls: 1.6054  decode.d4.loss_mask: 0.5239  decode.d4.loss_dice: 0.4896  decode.d5.loss_cls: 1.6494  decode.d5.loss_mask: 0.4626  decode.d5.loss_dice: 0.4677  decode.d6.loss_cls: 1.6140  decode.d6.loss_mask: 0.4494  decode.d6.loss_dice: 0.4175  decode.d7.loss_cls: 1.6478  decode.d7.loss_mask: 0.4417  decode.d7.loss_dice: 0.4245  decode.d8.loss_cls: 1.7273  decode.d8.loss_mask: 0.4853  decode.d8.loss_dice: 0.4700
08/06 02:33:57 - mmengine - INFO - Iter(train) [  2100/320000]  base_lr: 9.9409e-05 lr: 9.9409e-06  eta: 1 day, 19:18:43  time: 0.4891  data_time: 0.0104  memory: 5893  grad_norm: 398.7367  loss: 29.1872  decode.loss_cls: 1.6470  decode.loss_mask: 0.4558  decode.loss_dice: 0.4808  decode.d0.loss_cls: 3.2392  decode.d0.loss_mask: 0.6024  decode.d0.loss_dice: 0.6220  decode.d1.loss_cls: 1.8726  decode.d1.loss_mask: 0.5659  decode.d1.loss_dice: 0.5191  decode.d2.loss_cls: 1.6794  decode.d2.loss_mask: 0.5142  decode.d2.loss_dice: 0.4824  decode.d3.loss_cls: 1.6914  decode.d3.loss_mask: 0.5400  decode.d3.loss_dice: 0.5123  decode.d4.loss_cls: 1.7784  decode.d4.loss_mask: 0.4996  decode.d4.loss_dice: 0.4689  decode.d5.loss_cls: 1.7341  decode.d5.loss_mask: 0.5061  decode.d5.loss_dice: 0.5065  decode.d6.loss_cls: 1.6693  decode.d6.loss_mask: 0.5476  decode.d6.loss_dice: 0.5215  decode.d7.loss_cls: 1.7767  decode.d7.loss_mask: 0.5425  decode.d7.loss_dice: 0.5205  decode.d8.loss_cls: 1.6674  decode.d8.loss_mask: 0.5067  decode.d8.loss_dice: 0.5170
08/06 02:34:22 - mmengine - INFO - Iter(train) [  2150/320000]  base_lr: 9.9395e-05 lr: 9.9395e-06  eta: 1 day, 19:18:05  time: 0.4893  data_time: 0.0105  memory: 5966  grad_norm: 186.3238  loss: 28.1499  decode.loss_cls: 1.6328  decode.loss_mask: 0.4422  decode.loss_dice: 0.4947  decode.d0.loss_cls: 3.1457  decode.d0.loss_mask: 0.5589  decode.d0.loss_dice: 0.6711  decode.d1.loss_cls: 1.7770  decode.d1.loss_mask: 0.4406  decode.d1.loss_dice: 0.5123  decode.d2.loss_cls: 1.6500  decode.d2.loss_mask: 0.4743  decode.d2.loss_dice: 0.4853  decode.d3.loss_cls: 1.6006  decode.d3.loss_mask: 0.4528  decode.d3.loss_dice: 0.4963  decode.d4.loss_cls: 1.6039  decode.d4.loss_mask: 0.4702  decode.d4.loss_dice: 0.5310  decode.d5.loss_cls: 1.7158  decode.d5.loss_mask: 0.4204  decode.d5.loss_dice: 0.4930  decode.d6.loss_cls: 1.7331  decode.d6.loss_mask: 0.4399  decode.d6.loss_dice: 0.4929  decode.d7.loss_cls: 1.6685  decode.d7.loss_mask: 0.4744  decode.d7.loss_dice: 0.5130  decode.d8.loss_cls: 1.7466  decode.d8.loss_mask: 0.5029  decode.d8.loss_dice: 0.5096
08/06 02:34:46 - mmengine - INFO - Iter(train) [  2200/320000]  base_lr: 9.9381e-05 lr: 9.9381e-06  eta: 1 day, 19:17:31  time: 0.4896  data_time: 0.0104  memory: 5926  grad_norm: 204.1623  loss: 33.2008  decode.loss_cls: 2.0349  decode.loss_mask: 0.4823  decode.loss_dice: 0.5788  decode.d0.loss_cls: 3.3705  decode.d0.loss_mask: 0.5263  decode.d0.loss_dice: 0.7822  decode.d1.loss_cls: 2.2752  decode.d1.loss_mask: 0.4679  decode.d1.loss_dice: 0.5749  decode.d2.loss_cls: 2.0728  decode.d2.loss_mask: 0.4868  decode.d2.loss_dice: 0.5728  decode.d3.loss_cls: 2.0758  decode.d3.loss_mask: 0.4901  decode.d3.loss_dice: 0.5505  decode.d4.loss_cls: 2.0727  decode.d4.loss_mask: 0.5303  decode.d4.loss_dice: 0.6824  decode.d5.loss_cls: 2.1544  decode.d5.loss_mask: 0.4860  decode.d5.loss_dice: 0.5479  decode.d6.loss_cls: 2.0172  decode.d6.loss_mask: 0.4847  decode.d6.loss_dice: 0.5688  decode.d7.loss_cls: 2.1362  decode.d7.loss_mask: 0.4516  decode.d7.loss_dice: 0.5860  decode.d8.loss_cls: 2.0816  decode.d8.loss_mask: 0.4765  decode.d8.loss_dice: 0.5828
08/06 02:35:10 - mmengine - INFO - Iter(train) [  2250/320000]  base_lr: 9.9367e-05 lr: 9.9367e-06  eta: 1 day, 19:16:55  time: 0.4889  data_time: 0.0103  memory: 5907  grad_norm: 142.3921  loss: 26.2986  decode.loss_cls: 1.8108  decode.loss_mask: 0.3021  decode.loss_dice: 0.3800  decode.d0.loss_cls: 3.0044  decode.d0.loss_mask: 0.3510  decode.d0.loss_dice: 0.5197  decode.d1.loss_cls: 2.0005  decode.d1.loss_mask: 0.3047  decode.d1.loss_dice: 0.3878  decode.d2.loss_cls: 1.7248  decode.d2.loss_mask: 0.3051  decode.d2.loss_dice: 0.3764  decode.d3.loss_cls: 1.7339  decode.d3.loss_mask: 0.2921  decode.d3.loss_dice: 0.3773  decode.d4.loss_cls: 1.7100  decode.d4.loss_mask: 0.2977  decode.d4.loss_dice: 0.3743  decode.d5.loss_cls: 1.7910  decode.d5.loss_mask: 0.2973  decode.d5.loss_dice: 0.3721  decode.d6.loss_cls: 1.7737  decode.d6.loss_mask: 0.3075  decode.d6.loss_dice: 0.3896  decode.d7.loss_cls: 1.8367  decode.d7.loss_mask: 0.3018  decode.d7.loss_dice: 0.3921  decode.d8.loss_cls: 1.8550  decode.d8.loss_mask: 0.3285  decode.d8.loss_dice: 0.4007
08/06 02:35:35 - mmengine - INFO - Iter(train) [  2300/320000]  base_lr: 9.9353e-05 lr: 9.9353e-06  eta: 1 day, 19:16:17  time: 0.4878  data_time: 0.0102  memory: 5891  grad_norm: 153.0852  loss: 24.7043  decode.loss_cls: 1.5622  decode.loss_mask: 0.3023  decode.loss_dice: 0.4719  decode.d0.loss_cls: 2.8006  decode.d0.loss_mask: 0.3233  decode.d0.loss_dice: 0.5753  decode.d1.loss_cls: 1.6343  decode.d1.loss_mask: 0.3130  decode.d1.loss_dice: 0.4601  decode.d2.loss_cls: 1.5222  decode.d2.loss_mask: 0.3139  decode.d2.loss_dice: 0.4612  decode.d3.loss_cls: 1.5115  decode.d3.loss_mask: 0.3140  decode.d3.loss_dice: 0.4593  decode.d4.loss_cls: 1.5798  decode.d4.loss_mask: 0.2967  decode.d4.loss_dice: 0.4561  decode.d5.loss_cls: 1.6008  decode.d5.loss_mask: 0.2999  decode.d5.loss_dice: 0.4387  decode.d6.loss_cls: 1.5849  decode.d6.loss_mask: 0.3129  decode.d6.loss_dice: 0.4774  decode.d7.loss_cls: 1.5695  decode.d7.loss_mask: 0.3070  decode.d7.loss_dice: 0.4427  decode.d8.loss_cls: 1.5413  decode.d8.loss_mask: 0.3043  decode.d8.loss_dice: 0.4673
08/06 02:35:59 - mmengine - INFO - Iter(train) [  2350/320000]  base_lr: 9.9339e-05 lr: 9.9339e-06  eta: 1 day, 19:15:42  time: 0.4890  data_time: 0.0104  memory: 5966  grad_norm: 152.5126  loss: 25.7805  decode.loss_cls: 1.6825  decode.loss_mask: 0.3206  decode.loss_dice: 0.3610  decode.d0.loss_cls: 2.8596  decode.d0.loss_mask: 0.3930  decode.d0.loss_dice: 0.5111  decode.d1.loss_cls: 2.0085  decode.d1.loss_mask: 0.3287  decode.d1.loss_dice: 0.3719  decode.d2.loss_cls: 1.6679  decode.d2.loss_mask: 0.3302  decode.d2.loss_dice: 0.3553  decode.d3.loss_cls: 1.6844  decode.d3.loss_mask: 0.3241  decode.d3.loss_dice: 0.3607  decode.d4.loss_cls: 1.7159  decode.d4.loss_mask: 0.3271  decode.d4.loss_dice: 0.3773  decode.d5.loss_cls: 1.7857  decode.d5.loss_mask: 0.3348  decode.d5.loss_dice: 0.3639  decode.d6.loss_cls: 1.7198  decode.d6.loss_mask: 0.3437  decode.d6.loss_dice: 0.3849  decode.d7.loss_cls: 1.6592  decode.d7.loss_mask: 0.4116  decode.d7.loss_dice: 0.4007  decode.d8.loss_cls: 1.7012  decode.d8.loss_mask: 0.3284  decode.d8.loss_dice: 0.3665
08/06 02:36:24 - mmengine - INFO - Iter(train) [  2400/320000]  base_lr: 9.9325e-05 lr: 9.9325e-06  eta: 1 day, 19:15:06  time: 0.4891  data_time: 0.0101  memory: 5927  grad_norm: 151.8682  loss: 24.9119  decode.loss_cls: 1.6839  decode.loss_mask: 0.3583  decode.loss_dice: 0.3535  decode.d0.loss_cls: 2.6927  decode.d0.loss_mask: 0.3765  decode.d0.loss_dice: 0.4790  decode.d1.loss_cls: 1.8486  decode.d1.loss_mask: 0.3607  decode.d1.loss_dice: 0.3241  decode.d2.loss_cls: 1.6249  decode.d2.loss_mask: 0.3449  decode.d2.loss_dice: 0.3241  decode.d3.loss_cls: 1.5808  decode.d3.loss_mask: 0.3652  decode.d3.loss_dice: 0.3520  decode.d4.loss_cls: 1.6008  decode.d4.loss_mask: 0.3812  decode.d4.loss_dice: 0.3598  decode.d5.loss_cls: 1.7331  decode.d5.loss_mask: 0.3676  decode.d5.loss_dice: 0.3457  decode.d6.loss_cls: 1.6084  decode.d6.loss_mask: 0.3630  decode.d6.loss_dice: 0.3421  decode.d7.loss_cls: 1.6275  decode.d7.loss_mask: 0.3669  decode.d7.loss_dice: 0.3359  decode.d8.loss_cls: 1.6574  decode.d8.loss_mask: 0.3804  decode.d8.loss_dice: 0.3730
08/06 02:36:48 - mmengine - INFO - Iter(train) [  2450/320000]  base_lr: 9.9311e-05 lr: 9.9311e-06  eta: 1 day, 19:14:32  time: 0.4894  data_time: 0.0103  memory: 5892  grad_norm: 204.1460  loss: 29.6087  decode.loss_cls: 1.8941  decode.loss_mask: 0.3754  decode.loss_dice: 0.5854  decode.d0.loss_cls: 2.8222  decode.d0.loss_mask: 0.4569  decode.d0.loss_dice: 0.7347  decode.d1.loss_cls: 2.0123  decode.d1.loss_mask: 0.3880  decode.d1.loss_dice: 0.6229  decode.d2.loss_cls: 1.8519  decode.d2.loss_mask: 0.3632  decode.d2.loss_dice: 0.5897  decode.d3.loss_cls: 1.7968  decode.d3.loss_mask: 0.3622  decode.d3.loss_dice: 0.5436  decode.d4.loss_cls: 1.9163  decode.d4.loss_mask: 0.3637  decode.d4.loss_dice: 0.5720  decode.d5.loss_cls: 1.8833  decode.d5.loss_mask: 0.3462  decode.d5.loss_dice: 0.5713  decode.d6.loss_cls: 1.8849  decode.d6.loss_mask: 0.3738  decode.d6.loss_dice: 0.5813  decode.d7.loss_cls: 1.8434  decode.d7.loss_mask: 0.3911  decode.d7.loss_dice: 0.5749  decode.d8.loss_cls: 1.8556  decode.d8.loss_mask: 0.4324  decode.d8.loss_dice: 0.6194
08/06 02:37:13 - mmengine - INFO - Iter(train) [  2500/320000]  base_lr: 9.9297e-05 lr: 9.9297e-06  eta: 1 day, 19:14:14  time: 0.4882  data_time: 0.0102  memory: 5908  grad_norm: 191.6516  loss: 24.8897  decode.loss_cls: 1.6500  decode.loss_mask: 0.3660  decode.loss_dice: 0.3511  decode.d0.loss_cls: 2.7112  decode.d0.loss_mask: 0.4084  decode.d0.loss_dice: 0.4600  decode.d1.loss_cls: 1.8302  decode.d1.loss_mask: 0.3739  decode.d1.loss_dice: 0.3470  decode.d2.loss_cls: 1.6212  decode.d2.loss_mask: 0.3741  decode.d2.loss_dice: 0.3578  decode.d3.loss_cls: 1.6711  decode.d3.loss_mask: 0.3626  decode.d3.loss_dice: 0.3246  decode.d4.loss_cls: 1.6100  decode.d4.loss_mask: 0.3600  decode.d4.loss_dice: 0.3263  decode.d5.loss_cls: 1.6386  decode.d5.loss_mask: 0.3673  decode.d5.loss_dice: 0.3591  decode.d6.loss_cls: 1.6316  decode.d6.loss_mask: 0.3585  decode.d6.loss_dice: 0.3308  decode.d7.loss_cls: 1.6094  decode.d7.loss_mask: 0.3638  decode.d7.loss_dice: 0.3392  decode.d8.loss_cls: 1.6556  decode.d8.loss_mask: 0.3817  decode.d8.loss_dice: 0.3488
08/06 02:37:37 - mmengine - INFO - Iter(train) [  2550/320000]  base_lr: 9.9283e-05 lr: 9.9283e-06  eta: 1 day, 19:13:41  time: 0.4893  data_time: 0.0102  memory: 5891  grad_norm: 225.9841  loss: 26.9047  decode.loss_cls: 1.6731  decode.loss_mask: 0.3666  decode.loss_dice: 0.6003  decode.d0.loss_cls: 2.6492  decode.d0.loss_mask: 0.3460  decode.d0.loss_dice: 0.6880  decode.d1.loss_cls: 1.7945  decode.d1.loss_mask: 0.3435  decode.d1.loss_dice: 0.5836  decode.d2.loss_cls: 1.5380  decode.d2.loss_mask: 0.4108  decode.d2.loss_dice: 0.5616  decode.d3.loss_cls: 1.6316  decode.d3.loss_mask: 0.2936  decode.d3.loss_dice: 0.5378  decode.d4.loss_cls: 1.6491  decode.d4.loss_mask: 0.3187  decode.d4.loss_dice: 0.5575  decode.d5.loss_cls: 1.6994  decode.d5.loss_mask: 0.3427  decode.d5.loss_dice: 0.5954  decode.d6.loss_cls: 1.6722  decode.d6.loss_mask: 0.3327  decode.d6.loss_dice: 0.5565  decode.d7.loss_cls: 1.6879  decode.d7.loss_mask: 0.3393  decode.d7.loss_dice: 0.5635  decode.d8.loss_cls: 1.6530  decode.d8.loss_mask: 0.3465  decode.d8.loss_dice: 0.5723
08/06 02:38:02 - mmengine - INFO - Iter(train) [  2600/320000]  base_lr: 9.9269e-05 lr: 9.9269e-06  eta: 1 day, 19:13:10  time: 0.4895  data_time: 0.0102  memory: 5889  grad_norm: 267.8817  loss: 26.4292  decode.loss_cls: 1.6759  decode.loss_mask: 0.3712  decode.loss_dice: 0.4036  decode.d0.loss_cls: 2.7359  decode.d0.loss_mask: 0.4247  decode.d0.loss_dice: 0.5803  decode.d1.loss_cls: 2.1315  decode.d1.loss_mask: 0.3539  decode.d1.loss_dice: 0.4088  decode.d2.loss_cls: 1.7795  decode.d2.loss_mask: 0.3531  decode.d2.loss_dice: 0.4130  decode.d3.loss_cls: 1.7432  decode.d3.loss_mask: 0.3179  decode.d3.loss_dice: 0.3661  decode.d4.loss_cls: 1.7680  decode.d4.loss_mask: 0.3584  decode.d4.loss_dice: 0.3917  decode.d5.loss_cls: 1.7298  decode.d5.loss_mask: 0.3088  decode.d5.loss_dice: 0.3642  decode.d6.loss_cls: 1.7094  decode.d6.loss_mask: 0.3399  decode.d6.loss_dice: 0.3773  decode.d7.loss_cls: 1.7581  decode.d7.loss_mask: 0.3469  decode.d7.loss_dice: 0.3909  decode.d8.loss_cls: 1.7832  decode.d8.loss_mask: 0.3401  decode.d8.loss_dice: 0.4040
08/06 02:38:26 - mmengine - INFO - Iter(train) [  2650/320000]  base_lr: 9.9255e-05 lr: 9.9255e-06  eta: 1 day, 19:12:39  time: 0.4892  data_time: 0.0104  memory: 5907  grad_norm: 315.4468  loss: 26.9368  decode.loss_cls: 1.7116  decode.loss_mask: 0.4258  decode.loss_dice: 0.4693  decode.d0.loss_cls: 2.6809  decode.d0.loss_mask: 0.5490  decode.d0.loss_dice: 0.6185  decode.d1.loss_cls: 1.9337  decode.d1.loss_mask: 0.4138  decode.d1.loss_dice: 0.4560  decode.d2.loss_cls: 1.6801  decode.d2.loss_mask: 0.3903  decode.d2.loss_dice: 0.4097  decode.d3.loss_cls: 1.7547  decode.d3.loss_mask: 0.4545  decode.d3.loss_dice: 0.4339  decode.d4.loss_cls: 1.7224  decode.d4.loss_mask: 0.4015  decode.d4.loss_dice: 0.4205  decode.d5.loss_cls: 1.7593  decode.d5.loss_mask: 0.3969  decode.d5.loss_dice: 0.4249  decode.d6.loss_cls: 1.6570  decode.d6.loss_mask: 0.4000  decode.d6.loss_dice: 0.4264  decode.d7.loss_cls: 1.6240  decode.d7.loss_mask: 0.4143  decode.d7.loss_dice: 0.4272  decode.d8.loss_cls: 1.6949  decode.d8.loss_mask: 0.3764  decode.d8.loss_dice: 0.4093
08/06 02:38:51 - mmengine - INFO - Iter(train) [  2700/320000]  base_lr: 9.9241e-05 lr: 9.9241e-06  eta: 1 day, 19:12:08  time: 0.4883  data_time: 0.0103  memory: 5927  grad_norm: 182.4733  loss: 23.1331  decode.loss_cls: 1.4439  decode.loss_mask: 0.3372  decode.loss_dice: 0.3620  decode.d0.loss_cls: 2.4910  decode.d0.loss_mask: 0.3861  decode.d0.loss_dice: 0.4583  decode.d1.loss_cls: 1.8324  decode.d1.loss_mask: 0.3421  decode.d1.loss_dice: 0.3421  decode.d2.loss_cls: 1.4164  decode.d2.loss_mask: 0.3620  decode.d2.loss_dice: 0.3560  decode.d3.loss_cls: 1.4531  decode.d3.loss_mask: 0.3419  decode.d3.loss_dice: 0.3370  decode.d4.loss_cls: 1.5277  decode.d4.loss_mask: 0.3340  decode.d4.loss_dice: 0.3484  decode.d5.loss_cls: 1.4382  decode.d5.loss_mask: 0.4044  decode.d5.loss_dice: 0.3910  decode.d6.loss_cls: 1.4341  decode.d6.loss_mask: 0.3284  decode.d6.loss_dice: 0.3496  decode.d7.loss_cls: 1.4686  decode.d7.loss_mask: 0.3369  decode.d7.loss_dice: 0.3478  decode.d8.loss_cls: 1.4556  decode.d8.loss_mask: 0.3410  decode.d8.loss_dice: 0.3661
08/06 02:39:15 - mmengine - INFO - Iter(train) [  2750/320000]  base_lr: 9.9227e-05 lr: 9.9227e-06  eta: 1 day, 19:11:38  time: 0.4884  data_time: 0.0105  memory: 5874  grad_norm: 205.6069  loss: 24.9245  decode.loss_cls: 1.3566  decode.loss_mask: 0.5317  decode.loss_dice: 0.5813  decode.d0.loss_cls: 2.3453  decode.d0.loss_mask: 0.4807  decode.d0.loss_dice: 0.5775  decode.d1.loss_cls: 1.6104  decode.d1.loss_mask: 0.3943  decode.d1.loss_dice: 0.4448  decode.d2.loss_cls: 1.3684  decode.d2.loss_mask: 0.4104  decode.d2.loss_dice: 0.4683  decode.d3.loss_cls: 1.3803  decode.d3.loss_mask: 0.4010  decode.d3.loss_dice: 0.4651  decode.d4.loss_cls: 1.4665  decode.d4.loss_mask: 0.4239  decode.d4.loss_dice: 0.5050  decode.d5.loss_cls: 1.3664  decode.d5.loss_mask: 0.4953  decode.d5.loss_dice: 0.5327  decode.d6.loss_cls: 1.3474  decode.d6.loss_mask: 0.5388  decode.d6.loss_dice: 0.5712  decode.d7.loss_cls: 1.4392  decode.d7.loss_mask: 0.4750  decode.d7.loss_dice: 0.5219  decode.d8.loss_cls: 1.3257  decode.d8.loss_mask: 0.5051  decode.d8.loss_dice: 0.5942
08/06 02:39:39 - mmengine - INFO - Iter(train) [  2800/320000]  base_lr: 9.9212e-05 lr: 9.9212e-06  eta: 1 day, 19:11:07  time: 0.4888  data_time: 0.0104  memory: 5890  grad_norm: 224.1415  loss: 24.8726  decode.loss_cls: 1.4115  decode.loss_mask: 0.3711  decode.loss_dice: 0.4606  decode.d0.loss_cls: 2.3020  decode.d0.loss_mask: 0.4164  decode.d0.loss_dice: 0.6206  decode.d1.loss_cls: 1.6876  decode.d1.loss_mask: 0.3929  decode.d1.loss_dice: 0.5164  decode.d2.loss_cls: 1.4811  decode.d2.loss_mask: 0.3810  decode.d2.loss_dice: 0.4869  decode.d3.loss_cls: 1.4861  decode.d3.loss_mask: 0.3865  decode.d3.loss_dice: 0.4884  decode.d4.loss_cls: 1.5641  decode.d4.loss_mask: 0.3977  decode.d4.loss_dice: 0.4953  decode.d5.loss_cls: 1.4526  decode.d5.loss_mask: 0.3819  decode.d5.loss_dice: 0.4895  decode.d6.loss_cls: 1.4583  decode.d6.loss_mask: 0.4105  decode.d6.loss_dice: 0.5010  decode.d7.loss_cls: 1.6014  decode.d7.loss_mask: 0.3752  decode.d7.loss_dice: 0.4690  decode.d8.loss_cls: 1.5258  decode.d8.loss_mask: 0.3780  decode.d8.loss_dice: 0.4832
08/06 02:40:04 - mmengine - INFO - Iter(train) [  2850/320000]  base_lr: 9.9198e-05 lr: 9.9198e-06  eta: 1 day, 19:10:36  time: 0.4889  data_time: 0.0104  memory: 5891  grad_norm: 169.8307  loss: 25.0739  decode.loss_cls: 1.6178  decode.loss_mask: 0.3268  decode.loss_dice: 0.4455  decode.d0.loss_cls: 2.4776  decode.d0.loss_mask: 0.3897  decode.d0.loss_dice: 0.6760  decode.d1.loss_cls: 1.7318  decode.d1.loss_mask: 0.3212  decode.d1.loss_dice: 0.4714  decode.d2.loss_cls: 1.6191  decode.d2.loss_mask: 0.3169  decode.d2.loss_dice: 0.4483  decode.d3.loss_cls: 1.5881  decode.d3.loss_mask: 0.3201  decode.d3.loss_dice: 0.4268  decode.d4.loss_cls: 1.5930  decode.d4.loss_mask: 0.3210  decode.d4.loss_dice: 0.4525  decode.d5.loss_cls: 1.5568  decode.d5.loss_mask: 0.3141  decode.d5.loss_dice: 0.4633  decode.d6.loss_cls: 1.5853  decode.d6.loss_mask: 0.3287  decode.d6.loss_dice: 0.4513  decode.d7.loss_cls: 1.5301  decode.d7.loss_mask: 0.3415  decode.d7.loss_dice: 0.4517  decode.d8.loss_cls: 1.6351  decode.d8.loss_mask: 0.3842  decode.d8.loss_dice: 0.4880
08/06 02:40:28 - mmengine - INFO - Iter(train) [  2900/320000]  base_lr: 9.9184e-05 lr: 9.9184e-06  eta: 1 day, 19:10:07  time: 0.4882  data_time: 0.0105  memory: 5895  grad_norm: 284.8814  loss: 24.3241  decode.loss_cls: 1.3630  decode.loss_mask: 0.5006  decode.loss_dice: 0.4655  decode.d0.loss_cls: 2.3132  decode.d0.loss_mask: 0.4862  decode.d0.loss_dice: 0.5678  decode.d1.loss_cls: 1.6250  decode.d1.loss_mask: 0.5244  decode.d1.loss_dice: 0.4454  decode.d2.loss_cls: 1.3825  decode.d2.loss_mask: 0.4340  decode.d2.loss_dice: 0.4236  decode.d3.loss_cls: 1.3853  decode.d3.loss_mask: 0.4591  decode.d3.loss_dice: 0.4381  decode.d4.loss_cls: 1.4034  decode.d4.loss_mask: 0.4367  decode.d4.loss_dice: 0.4121  decode.d5.loss_cls: 1.3584  decode.d5.loss_mask: 0.4836  decode.d5.loss_dice: 0.4415  decode.d6.loss_cls: 1.3748  decode.d6.loss_mask: 0.4966  decode.d6.loss_dice: 0.4496  decode.d7.loss_cls: 1.3957  decode.d7.loss_mask: 0.4687  decode.d7.loss_dice: 0.4686  decode.d8.loss_cls: 1.3365  decode.d8.loss_mask: 0.5035  decode.d8.loss_dice: 0.4807
08/06 02:40:53 - mmengine - INFO - Iter(train) [  2950/320000]  base_lr: 9.9170e-05 lr: 9.9170e-06  eta: 1 day, 19:09:37  time: 0.4883  data_time: 0.0103  memory: 5908  grad_norm: 220.6300  loss: 23.1652  decode.loss_cls: 1.3440  decode.loss_mask: 0.4137  decode.loss_dice: 0.4278  decode.d0.loss_cls: 2.2879  decode.d0.loss_mask: 0.4081  decode.d0.loss_dice: 0.5833  decode.d1.loss_cls: 1.8299  decode.d1.loss_mask: 0.3356  decode.d1.loss_dice: 0.3718  decode.d2.loss_cls: 1.5195  decode.d2.loss_mask: 0.3036  decode.d2.loss_dice: 0.3587  decode.d3.loss_cls: 1.4843  decode.d3.loss_mask: 0.2892  decode.d3.loss_dice: 0.3694  decode.d4.loss_cls: 1.5354  decode.d4.loss_mask: 0.3228  decode.d4.loss_dice: 0.3782  decode.d5.loss_cls: 1.4137  decode.d5.loss_mask: 0.3044  decode.d5.loss_dice: 0.4060  decode.d6.loss_cls: 1.4357  decode.d6.loss_mask: 0.3309  decode.d6.loss_dice: 0.4296  decode.d7.loss_cls: 1.4161  decode.d7.loss_mask: 0.3153  decode.d7.loss_dice: 0.3833  decode.d8.loss_cls: 1.4419  decode.d8.loss_mask: 0.2997  decode.d8.loss_dice: 0.4255
08/06 02:41:17 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 02:41:17 - mmengine - INFO - Iter(train) [  3000/320000]  base_lr: 9.9156e-05 lr: 9.9156e-06  eta: 1 day, 19:09:16  time: 0.4884  data_time: 0.0101  memory: 5927  grad_norm: 1145.6733  loss: 26.2397  decode.loss_cls: 1.6354  decode.loss_mask: 0.4074  decode.loss_dice: 0.4477  decode.d0.loss_cls: 2.4744  decode.d0.loss_mask: 0.3977  decode.d0.loss_dice: 0.5203  decode.d1.loss_cls: 2.1715  decode.d1.loss_mask: 0.3315  decode.d1.loss_dice: 0.4078  decode.d2.loss_cls: 1.7137  decode.d2.loss_mask: 0.3164  decode.d2.loss_dice: 0.3749  decode.d3.loss_cls: 1.7596  decode.d3.loss_mask: 0.3459  decode.d3.loss_dice: 0.4226  decode.d4.loss_cls: 1.8366  decode.d4.loss_mask: 0.3469  decode.d4.loss_dice: 0.4015  decode.d5.loss_cls: 1.8536  decode.d5.loss_mask: 0.3305  decode.d5.loss_dice: 0.3833  decode.d6.loss_cls: 1.6504  decode.d6.loss_mask: 0.4025  decode.d6.loss_dice: 0.4092  decode.d7.loss_cls: 1.5690  decode.d7.loss_mask: 0.3817  decode.d7.loss_dice: 0.4583  decode.d8.loss_cls: 1.6672  decode.d8.loss_mask: 0.3727  decode.d8.loss_dice: 0.4493
08/06 02:41:42 - mmengine - INFO - Iter(train) [  3050/320000]  base_lr: 9.9142e-05 lr: 9.9142e-06  eta: 1 day, 19:08:44  time: 0.4894  data_time: 0.0104  memory: 5908  grad_norm: 159.0805  loss: 23.2984  decode.loss_cls: 1.4833  decode.loss_mask: 0.3198  decode.loss_dice: 0.3734  decode.d0.loss_cls: 2.4017  decode.d0.loss_mask: 0.3754  decode.d0.loss_dice: 0.5273  decode.d1.loss_cls: 1.8526  decode.d1.loss_mask: 0.3185  decode.d1.loss_dice: 0.3683  decode.d2.loss_cls: 1.5241  decode.d2.loss_mask: 0.3244  decode.d2.loss_dice: 0.3604  decode.d3.loss_cls: 1.5364  decode.d3.loss_mask: 0.2911  decode.d3.loss_dice: 0.3558  decode.d4.loss_cls: 1.5917  decode.d4.loss_mask: 0.3110  decode.d4.loss_dice: 0.3467  decode.d5.loss_cls: 1.5328  decode.d5.loss_mask: 0.3433  decode.d5.loss_dice: 0.3981  decode.d6.loss_cls: 1.4884  decode.d6.loss_mask: 0.2998  decode.d6.loss_dice: 0.3549  decode.d7.loss_cls: 1.4926  decode.d7.loss_mask: 0.3000  decode.d7.loss_dice: 0.3426  decode.d8.loss_cls: 1.4636  decode.d8.loss_mask: 0.2844  decode.d8.loss_dice: 0.3359
08/06 02:42:06 - mmengine - INFO - Iter(train) [  3100/320000]  base_lr: 9.9128e-05 lr: 9.9128e-06  eta: 1 day, 19:08:15  time: 0.4898  data_time: 0.0105  memory: 5890  grad_norm: 218.3266  loss: 23.2232  decode.loss_cls: 1.3029  decode.loss_mask: 0.4024  decode.loss_dice: 0.4316  decode.d0.loss_cls: 2.1680  decode.d0.loss_mask: 0.4297  decode.d0.loss_dice: 0.5438  decode.d1.loss_cls: 1.5117  decode.d1.loss_mask: 0.4608  decode.d1.loss_dice: 0.4558  decode.d2.loss_cls: 1.3194  decode.d2.loss_mask: 0.4262  decode.d2.loss_dice: 0.4488  decode.d3.loss_cls: 1.3444  decode.d3.loss_mask: 0.4154  decode.d3.loss_dice: 0.4464  decode.d4.loss_cls: 1.3803  decode.d4.loss_mask: 0.4236  decode.d4.loss_dice: 0.4840  decode.d5.loss_cls: 1.4205  decode.d5.loss_mask: 0.4056  decode.d5.loss_dice: 0.4670  decode.d6.loss_cls: 1.2756  decode.d6.loss_mask: 0.4024  decode.d6.loss_dice: 0.4558  decode.d7.loss_cls: 1.4403  decode.d7.loss_mask: 0.4029  decode.d7.loss_dice: 0.4364  decode.d8.loss_cls: 1.2792  decode.d8.loss_mask: 0.4085  decode.d8.loss_dice: 0.4336
08/06 02:42:31 - mmengine - INFO - Iter(train) [  3150/320000]  base_lr: 9.9114e-05 lr: 9.9114e-06  eta: 1 day, 19:07:43  time: 0.4879  data_time: 0.0102  memory: 5908  grad_norm: 351.0129  loss: 22.9536  decode.loss_cls: 1.3238  decode.loss_mask: 0.3745  decode.loss_dice: 0.4759  decode.d0.loss_cls: 2.0588  decode.d0.loss_mask: 0.3896  decode.d0.loss_dice: 0.5356  decode.d1.loss_cls: 1.5211  decode.d1.loss_mask: 0.3749  decode.d1.loss_dice: 0.4956  decode.d2.loss_cls: 1.2581  decode.d2.loss_mask: 0.3652  decode.d2.loss_dice: 0.4531  decode.d3.loss_cls: 1.2995  decode.d3.loss_mask: 0.3701  decode.d3.loss_dice: 0.4559  decode.d4.loss_cls: 1.3459  decode.d4.loss_mask: 0.3911  decode.d4.loss_dice: 0.4779  decode.d5.loss_cls: 1.3280  decode.d5.loss_mask: 0.3702  decode.d5.loss_dice: 0.4607  decode.d6.loss_cls: 1.2660  decode.d6.loss_mask: 0.3927  decode.d6.loss_dice: 0.5193  decode.d7.loss_cls: 1.3178  decode.d7.loss_mask: 0.3868  decode.d7.loss_dice: 0.6096  decode.d8.loss_cls: 1.3591  decode.d8.loss_mask: 0.3970  decode.d8.loss_dice: 0.5799
08/06 02:42:34 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 02:42:55 - mmengine - INFO - Iter(train) [  3200/320000]  base_lr: 9.9100e-05 lr: 9.9100e-06  eta: 1 day, 19:07:12  time: 0.4891  data_time: 0.0104  memory: 5890  grad_norm: 181.7991  loss: 25.7094  decode.loss_cls: 1.6149  decode.loss_mask: 0.4206  decode.loss_dice: 0.4325  decode.d0.loss_cls: 2.3439  decode.d0.loss_mask: 0.4386  decode.d0.loss_dice: 0.5393  decode.d1.loss_cls: 1.8374  decode.d1.loss_mask: 0.4291  decode.d1.loss_dice: 0.4912  decode.d2.loss_cls: 1.5371  decode.d2.loss_mask: 0.4296  decode.d2.loss_dice: 0.4651  decode.d3.loss_cls: 1.5923  decode.d3.loss_mask: 0.4165  decode.d3.loss_dice: 0.4781  decode.d4.loss_cls: 1.5525  decode.d4.loss_mask: 0.3975  decode.d4.loss_dice: 0.4390  decode.d5.loss_cls: 1.5752  decode.d5.loss_mask: 0.4154  decode.d5.loss_dice: 0.4685  decode.d6.loss_cls: 1.5030  decode.d6.loss_mask: 0.4595  decode.d6.loss_dice: 0.4909  decode.d7.loss_cls: 1.6275  decode.d7.loss_mask: 0.4010  decode.d7.loss_dice: 0.4567  decode.d8.loss_cls: 1.6237  decode.d8.loss_mask: 0.4131  decode.d8.loss_dice: 0.4198
08/06 02:43:20 - mmengine - INFO - Iter(train) [  3250/320000]  base_lr: 9.9086e-05 lr: 9.9086e-06  eta: 1 day, 19:06:41  time: 0.4892  data_time: 0.0102  memory: 5891  grad_norm: 255.8084  loss: 25.7576  decode.loss_cls: 1.5670  decode.loss_mask: 0.4531  decode.loss_dice: 0.4794  decode.d0.loss_cls: 2.3416  decode.d0.loss_mask: 0.4634  decode.d0.loss_dice: 0.5956  decode.d1.loss_cls: 1.8547  decode.d1.loss_mask: 0.4115  decode.d1.loss_dice: 0.4176  decode.d2.loss_cls: 1.5743  decode.d2.loss_mask: 0.3876  decode.d2.loss_dice: 0.3983  decode.d3.loss_cls: 1.5482  decode.d3.loss_mask: 0.4145  decode.d3.loss_dice: 0.4516  decode.d4.loss_cls: 1.6325  decode.d4.loss_mask: 0.3769  decode.d4.loss_dice: 0.4137  decode.d5.loss_cls: 1.5455  decode.d5.loss_mask: 0.3995  decode.d5.loss_dice: 0.4893  decode.d6.loss_cls: 1.6517  decode.d6.loss_mask: 0.3986  decode.d6.loss_dice: 0.4587  decode.d7.loss_cls: 1.6172  decode.d7.loss_mask: 0.4406  decode.d7.loss_dice: 0.4553  decode.d8.loss_cls: 1.6768  decode.d8.loss_mask: 0.3828  decode.d8.loss_dice: 0.4602
08/06 02:43:44 - mmengine - INFO - Iter(train) [  3300/320000]  base_lr: 9.9072e-05 lr: 9.9072e-06  eta: 1 day, 19:06:30  time: 0.4887  data_time: 0.0104  memory: 5910  grad_norm: 282.3649  loss: 23.1232  decode.loss_cls: 1.3298  decode.loss_mask: 0.3780  decode.loss_dice: 0.4058  decode.d0.loss_cls: 2.1830  decode.d0.loss_mask: 0.4322  decode.d0.loss_dice: 0.6332  decode.d1.loss_cls: 1.7653  decode.d1.loss_mask: 0.4174  decode.d1.loss_dice: 0.4633  decode.d2.loss_cls: 1.3564  decode.d2.loss_mask: 0.4305  decode.d2.loss_dice: 0.4214  decode.d3.loss_cls: 1.3386  decode.d3.loss_mask: 0.4014  decode.d3.loss_dice: 0.3510  decode.d4.loss_cls: 1.3947  decode.d4.loss_mask: 0.3886  decode.d4.loss_dice: 0.3911  decode.d5.loss_cls: 1.3916  decode.d5.loss_mask: 0.3769  decode.d5.loss_dice: 0.3741  decode.d6.loss_cls: 1.3784  decode.d6.loss_mask: 0.3724  decode.d6.loss_dice: 0.3844  decode.d7.loss_cls: 1.3320  decode.d7.loss_mask: 0.3841  decode.d7.loss_dice: 0.4064  decode.d8.loss_cls: 1.4080  decode.d8.loss_mask: 0.4076  decode.d8.loss_dice: 0.4256
08/06 02:44:09 - mmengine - INFO - Iter(train) [  3350/320000]  base_lr: 9.9058e-05 lr: 9.9058e-06  eta: 1 day, 19:06:01  time: 0.4888  data_time: 0.0106  memory: 5964  grad_norm: 344.4395  loss: 23.7475  decode.loss_cls: 1.3452  decode.loss_mask: 0.3946  decode.loss_dice: 0.4006  decode.d0.loss_cls: 2.0759  decode.d0.loss_mask: 0.4882  decode.d0.loss_dice: 0.6126  decode.d1.loss_cls: 1.7139  decode.d1.loss_mask: 0.4273  decode.d1.loss_dice: 0.4884  decode.d2.loss_cls: 1.4516  decode.d2.loss_mask: 0.4114  decode.d2.loss_dice: 0.4544  decode.d3.loss_cls: 1.4170  decode.d3.loss_mask: 0.4082  decode.d3.loss_dice: 0.4548  decode.d4.loss_cls: 1.4159  decode.d4.loss_mask: 0.4043  decode.d4.loss_dice: 0.4296  decode.d5.loss_cls: 1.3531  decode.d5.loss_mask: 0.4320  decode.d5.loss_dice: 0.4620  decode.d6.loss_cls: 1.3393  decode.d6.loss_mask: 0.4138  decode.d6.loss_dice: 0.4398  decode.d7.loss_cls: 1.3371  decode.d7.loss_mask: 0.4258  decode.d7.loss_dice: 0.4521  decode.d8.loss_cls: 1.4481  decode.d8.loss_mask: 0.3927  decode.d8.loss_dice: 0.4579
08/06 02:44:33 - mmengine - INFO - Iter(train) [  3400/320000]  base_lr: 9.9044e-05 lr: 9.9044e-06  eta: 1 day, 19:05:30  time: 0.4883  data_time: 0.0104  memory: 5892  grad_norm: 132.0581  loss: 20.1197  decode.loss_cls: 1.1540  decode.loss_mask: 0.3379  decode.loss_dice: 0.4425  decode.d0.loss_cls: 1.9767  decode.d0.loss_mask: 0.3420  decode.d0.loss_dice: 0.4561  decode.d1.loss_cls: 1.4251  decode.d1.loss_mask: 0.3514  decode.d1.loss_dice: 0.3798  decode.d2.loss_cls: 1.1883  decode.d2.loss_mask: 0.3492  decode.d2.loss_dice: 0.3651  decode.d3.loss_cls: 1.1775  decode.d3.loss_mask: 0.3740  decode.d3.loss_dice: 0.3670  decode.d4.loss_cls: 1.2638  decode.d4.loss_mask: 0.3330  decode.d4.loss_dice: 0.3934  decode.d5.loss_cls: 1.1957  decode.d5.loss_mask: 0.3192  decode.d5.loss_dice: 0.3633  decode.d6.loss_cls: 1.0936  decode.d6.loss_mask: 0.3279  decode.d6.loss_dice: 0.3625  decode.d7.loss_cls: 1.1832  decode.d7.loss_mask: 0.3287  decode.d7.loss_dice: 0.3542  decode.d8.loss_cls: 1.2078  decode.d8.loss_mask: 0.3237  decode.d8.loss_dice: 0.3832
08/06 02:44:58 - mmengine - INFO - Iter(train) [  3450/320000]  base_lr: 9.9029e-05 lr: 9.9029e-06  eta: 1 day, 19:05:00  time: 0.4894  data_time: 0.0104  memory: 5889  grad_norm: 279.4266  loss: 19.2227  decode.loss_cls: 1.0905  decode.loss_mask: 0.3140  decode.loss_dice: 0.3731  decode.d0.loss_cls: 2.0046  decode.d0.loss_mask: 0.3628  decode.d0.loss_dice: 0.5189  decode.d1.loss_cls: 1.4435  decode.d1.loss_mask: 0.3170  decode.d1.loss_dice: 0.3802  decode.d2.loss_cls: 1.1207  decode.d2.loss_mask: 0.3290  decode.d2.loss_dice: 0.3894  decode.d3.loss_cls: 1.0746  decode.d3.loss_mask: 0.3180  decode.d3.loss_dice: 0.3582  decode.d4.loss_cls: 0.9924  decode.d4.loss_mask: 0.3284  decode.d4.loss_dice: 0.4036  decode.d5.loss_cls: 1.0571  decode.d5.loss_mask: 0.3293  decode.d5.loss_dice: 0.3668  decode.d6.loss_cls: 1.0578  decode.d6.loss_mask: 0.3378  decode.d6.loss_dice: 0.3521  decode.d7.loss_cls: 1.0674  decode.d7.loss_mask: 0.3480  decode.d7.loss_dice: 0.3787  decode.d8.loss_cls: 1.0776  decode.d8.loss_mask: 0.3419  decode.d8.loss_dice: 0.3895
08/06 02:45:22 - mmengine - INFO - Iter(train) [  3500/320000]  base_lr: 9.9015e-05 lr: 9.9015e-06  eta: 1 day, 19:04:31  time: 0.4891  data_time: 0.0102  memory: 5966  grad_norm: 165.3104  loss: 21.4818  decode.loss_cls: 1.2454  decode.loss_mask: 0.3148  decode.loss_dice: 0.3705  decode.d0.loss_cls: 2.1193  decode.d0.loss_mask: 0.3617  decode.d0.loss_dice: 0.4722  decode.d1.loss_cls: 1.5773  decode.d1.loss_mask: 0.3045  decode.d1.loss_dice: 0.3481  decode.d2.loss_cls: 1.4195  decode.d2.loss_mask: 0.3055  decode.d2.loss_dice: 0.3647  decode.d3.loss_cls: 1.2987  decode.d3.loss_mask: 0.3051  decode.d3.loss_dice: 0.3675  decode.d4.loss_cls: 1.4490  decode.d4.loss_mask: 0.3162  decode.d4.loss_dice: 0.3462  decode.d5.loss_cls: 1.3985  decode.d5.loss_mask: 0.3035  decode.d5.loss_dice: 0.3577  decode.d6.loss_cls: 1.3869  decode.d6.loss_mask: 0.2829  decode.d6.loss_dice: 0.3442  decode.d7.loss_cls: 1.3883  decode.d7.loss_mask: 0.3198  decode.d7.loss_dice: 0.3822  decode.d8.loss_cls: 1.2869  decode.d8.loss_mask: 0.3533  decode.d8.loss_dice: 0.3910
08/06 02:45:46 - mmengine - INFO - Iter(train) [  3550/320000]  base_lr: 9.9001e-05 lr: 9.9001e-06  eta: 1 day, 19:04:02  time: 0.4891  data_time: 0.0104  memory: 5926  grad_norm: 174.9728  loss: 22.7476  decode.loss_cls: 1.3326  decode.loss_mask: 0.3328  decode.loss_dice: 0.4869  decode.d0.loss_cls: 2.0725  decode.d0.loss_mask: 0.3851  decode.d0.loss_dice: 0.5877  decode.d1.loss_cls: 1.6762  decode.d1.loss_mask: 0.3070  decode.d1.loss_dice: 0.4770  decode.d2.loss_cls: 1.3816  decode.d2.loss_mask: 0.3348  decode.d2.loss_dice: 0.4731  decode.d3.loss_cls: 1.4020  decode.d3.loss_mask: 0.3189  decode.d3.loss_dice: 0.4849  decode.d4.loss_cls: 1.3760  decode.d4.loss_mask: 0.3207  decode.d4.loss_dice: 0.4748  decode.d5.loss_cls: 1.3466  decode.d5.loss_mask: 0.3161  decode.d5.loss_dice: 0.4916  decode.d6.loss_cls: 1.3487  decode.d6.loss_mask: 0.3059  decode.d6.loss_dice: 0.4621  decode.d7.loss_cls: 1.3508  decode.d7.loss_mask: 0.3242  decode.d7.loss_dice: 0.4840  decode.d8.loss_cls: 1.3190  decode.d8.loss_mask: 0.3150  decode.d8.loss_dice: 0.4590
08/06 02:46:11 - mmengine - INFO - Iter(train) [  3600/320000]  base_lr: 9.8987e-05 lr: 9.8987e-06  eta: 1 day, 19:03:31  time: 0.4889  data_time: 0.0104  memory: 5859  grad_norm: 212.5244  loss: 21.9153  decode.loss_cls: 1.2540  decode.loss_mask: 0.4010  decode.loss_dice: 0.4563  decode.d0.loss_cls: 2.0218  decode.d0.loss_mask: 0.4288  decode.d0.loss_dice: 0.4985  decode.d1.loss_cls: 1.5923  decode.d1.loss_mask: 0.4011  decode.d1.loss_dice: 0.4027  decode.d2.loss_cls: 1.3005  decode.d2.loss_mask: 0.3763  decode.d2.loss_dice: 0.3966  decode.d3.loss_cls: 1.2730  decode.d3.loss_mask: 0.3797  decode.d3.loss_dice: 0.3725  decode.d4.loss_cls: 1.2583  decode.d4.loss_mask: 0.3878  decode.d4.loss_dice: 0.4112  decode.d5.loss_cls: 1.2530  decode.d5.loss_mask: 0.3891  decode.d5.loss_dice: 0.4121  decode.d6.loss_cls: 1.2914  decode.d6.loss_mask: 0.3874  decode.d6.loss_dice: 0.3977  decode.d7.loss_cls: 1.3281  decode.d7.loss_mask: 0.4099  decode.d7.loss_dice: 0.3925  decode.d8.loss_cls: 1.2262  decode.d8.loss_mask: 0.4130  decode.d8.loss_dice: 0.4026
08/06 02:46:35 - mmengine - INFO - Iter(train) [  3650/320000]  base_lr: 9.8973e-05 lr: 9.8973e-06  eta: 1 day, 19:03:02  time: 0.4899  data_time: 0.0104  memory: 5926  grad_norm: 177.9080  loss: 22.5298  decode.loss_cls: 1.3364  decode.loss_mask: 0.3362  decode.loss_dice: 0.4238  decode.d0.loss_cls: 2.0390  decode.d0.loss_mask: 0.3706  decode.d0.loss_dice: 0.5510  decode.d1.loss_cls: 1.7035  decode.d1.loss_mask: 0.3730  decode.d1.loss_dice: 0.4126  decode.d2.loss_cls: 1.3892  decode.d2.loss_mask: 0.3225  decode.d2.loss_dice: 0.4507  decode.d3.loss_cls: 1.4410  decode.d3.loss_mask: 0.3078  decode.d3.loss_dice: 0.4139  decode.d4.loss_cls: 1.4338  decode.d4.loss_mask: 0.3450  decode.d4.loss_dice: 0.3949  decode.d5.loss_cls: 1.4217  decode.d5.loss_mask: 0.3266  decode.d5.loss_dice: 0.4178  decode.d6.loss_cls: 1.3381  decode.d6.loss_mask: 0.3244  decode.d6.loss_dice: 0.4146  decode.d7.loss_cls: 1.4184  decode.d7.loss_mask: 0.3265  decode.d7.loss_dice: 0.4242  decode.d8.loss_cls: 1.3073  decode.d8.loss_mask: 0.3398  decode.d8.loss_dice: 0.4254
08/06 02:47:00 - mmengine - INFO - Iter(train) [  3700/320000]  base_lr: 9.8959e-05 lr: 9.8959e-06  eta: 1 day, 19:02:32  time: 0.4895  data_time: 0.0105  memory: 5892  grad_norm: 211.6209  loss: 23.9056  decode.loss_cls: 1.4134  decode.loss_mask: 0.3614  decode.loss_dice: 0.4126  decode.d0.loss_cls: 2.4066  decode.d0.loss_mask: 0.4565  decode.d0.loss_dice: 0.5694  decode.d1.loss_cls: 1.8833  decode.d1.loss_mask: 0.3357  decode.d1.loss_dice: 0.3435  decode.d2.loss_cls: 1.5252  decode.d2.loss_mask: 0.3391  decode.d2.loss_dice: 0.3768  decode.d3.loss_cls: 1.5265  decode.d3.loss_mask: 0.3531  decode.d3.loss_dice: 0.3424  decode.d4.loss_cls: 1.5506  decode.d4.loss_mask: 0.3232  decode.d4.loss_dice: 0.3868  decode.d5.loss_cls: 1.5338  decode.d5.loss_mask: 0.3325  decode.d5.loss_dice: 0.4007  decode.d6.loss_cls: 1.5161  decode.d6.loss_mask: 0.3240  decode.d6.loss_dice: 0.3762  decode.d7.loss_cls: 1.5012  decode.d7.loss_mask: 0.3325  decode.d7.loss_dice: 0.3817  decode.d8.loss_cls: 1.5802  decode.d8.loss_mask: 0.3466  decode.d8.loss_dice: 0.3742
08/06 02:47:24 - mmengine - INFO - Iter(train) [  3750/320000]  base_lr: 9.8945e-05 lr: 9.8945e-06  eta: 1 day, 19:02:03  time: 0.4893  data_time: 0.0104  memory: 5892  grad_norm: 187.6879  loss: 20.6509  decode.loss_cls: 1.1435  decode.loss_mask: 0.3638  decode.loss_dice: 0.3951  decode.d0.loss_cls: 2.0339  decode.d0.loss_mask: 0.3193  decode.d0.loss_dice: 0.4691  decode.d1.loss_cls: 1.5729  decode.d1.loss_mask: 0.3214  decode.d1.loss_dice: 0.4054  decode.d2.loss_cls: 1.2448  decode.d2.loss_mask: 0.3157  decode.d2.loss_dice: 0.3979  decode.d3.loss_cls: 1.1497  decode.d3.loss_mask: 0.3332  decode.d3.loss_dice: 0.3940  decode.d4.loss_cls: 1.2016  decode.d4.loss_mask: 0.3318  decode.d4.loss_dice: 0.4009  decode.d5.loss_cls: 1.2356  decode.d5.loss_mask: 0.3383  decode.d5.loss_dice: 0.3978  decode.d6.loss_cls: 1.1985  decode.d6.loss_mask: 0.3419  decode.d6.loss_dice: 0.3946  decode.d7.loss_cls: 1.2297  decode.d7.loss_mask: 0.3348  decode.d7.loss_dice: 0.3842  decode.d8.loss_cls: 1.2478  decode.d8.loss_mask: 0.3471  decode.d8.loss_dice: 0.4068
08/06 02:47:49 - mmengine - INFO - Iter(train) [  3800/320000]  base_lr: 9.8931e-05 lr: 9.8931e-06  eta: 1 day, 19:01:33  time: 0.4882  data_time: 0.0102  memory: 5926  grad_norm: 273.6805  loss: 21.8865  decode.loss_cls: 1.1884  decode.loss_mask: 0.3679  decode.loss_dice: 0.5250  decode.d0.loss_cls: 2.0408  decode.d0.loss_mask: 0.4546  decode.d0.loss_dice: 0.6149  decode.d1.loss_cls: 1.5985  decode.d1.loss_mask: 0.4323  decode.d1.loss_dice: 0.5305  decode.d2.loss_cls: 1.1800  decode.d2.loss_mask: 0.3763  decode.d2.loss_dice: 0.5062  decode.d3.loss_cls: 1.1517  decode.d3.loss_mask: 0.3838  decode.d3.loss_dice: 0.4686  decode.d4.loss_cls: 1.2857  decode.d4.loss_mask: 0.3547  decode.d4.loss_dice: 0.4838  decode.d5.loss_cls: 1.2056  decode.d5.loss_mask: 0.3292  decode.d5.loss_dice: 0.4878  decode.d6.loss_cls: 1.0971  decode.d6.loss_mask: 0.3240  decode.d6.loss_dice: 0.4527  decode.d7.loss_cls: 1.1842  decode.d7.loss_mask: 0.3544  decode.d7.loss_dice: 0.4839  decode.d8.loss_cls: 1.1962  decode.d8.loss_mask: 0.3595  decode.d8.loss_dice: 0.4681
08/06 02:48:13 - mmengine - INFO - Iter(train) [  3850/320000]  base_lr: 9.8917e-05 lr: 9.8917e-06  eta: 1 day, 19:01:04  time: 0.4884  data_time: 0.0104  memory: 5907  grad_norm: 348.8780  loss: 23.0967  decode.loss_cls: 1.2293  decode.loss_mask: 0.5221  decode.loss_dice: 0.4757  decode.d0.loss_cls: 2.1028  decode.d0.loss_mask: 0.4957  decode.d0.loss_dice: 0.5012  decode.d1.loss_cls: 1.5974  decode.d1.loss_mask: 0.4578  decode.d1.loss_dice: 0.4607  decode.d2.loss_cls: 1.2418  decode.d2.loss_mask: 0.4588  decode.d2.loss_dice: 0.4429  decode.d3.loss_cls: 1.2253  decode.d3.loss_mask: 0.4927  decode.d3.loss_dice: 0.4392  decode.d4.loss_cls: 1.1748  decode.d4.loss_mask: 0.4822  decode.d4.loss_dice: 0.4487  decode.d5.loss_cls: 1.3404  decode.d5.loss_mask: 0.5078  decode.d5.loss_dice: 0.4174  decode.d6.loss_cls: 1.3069  decode.d6.loss_mask: 0.4757  decode.d6.loss_dice: 0.4048  decode.d7.loss_cls: 1.3475  decode.d7.loss_mask: 0.4720  decode.d7.loss_dice: 0.4302  decode.d8.loss_cls: 1.2303  decode.d8.loss_mask: 0.4661  decode.d8.loss_dice: 0.4486
08/06 02:48:38 - mmengine - INFO - Iter(train) [  3900/320000]  base_lr: 9.8903e-05 lr: 9.8903e-06  eta: 1 day, 19:00:45  time: 0.4886  data_time: 0.0104  memory: 5892  grad_norm: 167.2469  loss: 21.0490  decode.loss_cls: 1.1490  decode.loss_mask: 0.3875  decode.loss_dice: 0.5028  decode.d0.loss_cls: 1.8980  decode.d0.loss_mask: 0.3710  decode.d0.loss_dice: 0.5574  decode.d1.loss_cls: 1.4530  decode.d1.loss_mask: 0.3400  decode.d1.loss_dice: 0.4446  decode.d2.loss_cls: 1.1399  decode.d2.loss_mask: 0.3380  decode.d2.loss_dice: 0.4633  decode.d3.loss_cls: 1.1074  decode.d3.loss_mask: 0.3433  decode.d3.loss_dice: 0.4774  decode.d4.loss_cls: 1.1430  decode.d4.loss_mask: 0.3380  decode.d4.loss_dice: 0.4668  decode.d5.loss_cls: 1.1347  decode.d5.loss_mask: 0.3528  decode.d5.loss_dice: 0.4694  decode.d6.loss_cls: 1.2014  decode.d6.loss_mask: 0.3383  decode.d6.loss_dice: 0.4840  decode.d7.loss_cls: 1.2742  decode.d7.loss_mask: 0.3486  decode.d7.loss_dice: 0.4757  decode.d8.loss_cls: 1.1753  decode.d8.loss_mask: 0.3642  decode.d8.loss_dice: 0.5099
08/06 02:49:02 - mmengine - INFO - Iter(train) [  3950/320000]  base_lr: 9.8889e-05 lr: 9.8889e-06  eta: 1 day, 19:00:17  time: 0.4884  data_time: 0.0103  memory: 5892  grad_norm: 183.9543  loss: 20.8069  decode.loss_cls: 1.1854  decode.loss_mask: 0.3228  decode.loss_dice: 0.4176  decode.d0.loss_cls: 2.0883  decode.d0.loss_mask: 0.3590  decode.d0.loss_dice: 0.4975  decode.d1.loss_cls: 1.6328  decode.d1.loss_mask: 0.3343  decode.d1.loss_dice: 0.4536  decode.d2.loss_cls: 1.1820  decode.d2.loss_mask: 0.3162  decode.d2.loss_dice: 0.4087  decode.d3.loss_cls: 1.1665  decode.d3.loss_mask: 0.3169  decode.d3.loss_dice: 0.3890  decode.d4.loss_cls: 1.3273  decode.d4.loss_mask: 0.3244  decode.d4.loss_dice: 0.4101  decode.d5.loss_cls: 1.1980  decode.d5.loss_mask: 0.3278  decode.d5.loss_dice: 0.4146  decode.d6.loss_cls: 1.1495  decode.d6.loss_mask: 0.3406  decode.d6.loss_dice: 0.4232  decode.d7.loss_cls: 1.2115  decode.d7.loss_mask: 0.3185  decode.d7.loss_dice: 0.4140  decode.d8.loss_cls: 1.1384  decode.d8.loss_mask: 0.3301  decode.d8.loss_dice: 0.4083
08/06 02:49:26 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 02:49:26 - mmengine - INFO - Iter(train) [  4000/320000]  base_lr: 9.8875e-05 lr: 9.8875e-06  eta: 1 day, 18:59:48  time: 0.4886  data_time: 0.0103  memory: 5890  grad_norm: 254.1363  loss: 17.2962  decode.loss_cls: 0.8638  decode.loss_mask: 0.3656  decode.loss_dice: 0.3921  decode.d0.loss_cls: 1.7523  decode.d0.loss_mask: 0.3991  decode.d0.loss_dice: 0.4776  decode.d1.loss_cls: 1.1429  decode.d1.loss_mask: 0.3635  decode.d1.loss_dice: 0.4454  decode.d2.loss_cls: 0.8195  decode.d2.loss_mask: 0.3643  decode.d2.loss_dice: 0.4101  decode.d3.loss_cls: 0.8156  decode.d3.loss_mask: 0.3569  decode.d3.loss_dice: 0.4001  decode.d4.loss_cls: 0.8014  decode.d4.loss_mask: 0.3749  decode.d4.loss_dice: 0.4022  decode.d5.loss_cls: 0.8619  decode.d5.loss_mask: 0.3612  decode.d5.loss_dice: 0.3977  decode.d6.loss_cls: 0.7971  decode.d6.loss_mask: 0.3638  decode.d6.loss_dice: 0.4006  decode.d7.loss_cls: 0.7773  decode.d7.loss_mask: 0.3612  decode.d7.loss_dice: 0.4050  decode.d8.loss_cls: 0.8818  decode.d8.loss_mask: 0.3534  decode.d8.loss_dice: 0.3879
08/06 02:49:51 - mmengine - INFO - Iter(train) [  4050/320000]  base_lr: 9.8860e-05 lr: 9.8860e-06  eta: 1 day, 18:59:21  time: 0.4890  data_time: 0.0102  memory: 5890  grad_norm: 182.5730  loss: 21.7382  decode.loss_cls: 1.4039  decode.loss_mask: 0.2578  decode.loss_dice: 0.4254  decode.d0.loss_cls: 2.3054  decode.d0.loss_mask: 0.2931  decode.d0.loss_dice: 0.5088  decode.d1.loss_cls: 1.7507  decode.d1.loss_mask: 0.2587  decode.d1.loss_dice: 0.4192  decode.d2.loss_cls: 1.4147  decode.d2.loss_mask: 0.2410  decode.d2.loss_dice: 0.3900  decode.d3.loss_cls: 1.3119  decode.d3.loss_mask: 0.2438  decode.d3.loss_dice: 0.3730  decode.d4.loss_cls: 1.4439  decode.d4.loss_mask: 0.2391  decode.d4.loss_dice: 0.4052  decode.d5.loss_cls: 1.4338  decode.d5.loss_mask: 0.2326  decode.d5.loss_dice: 0.4080  decode.d6.loss_cls: 1.3453  decode.d6.loss_mask: 0.2356  decode.d6.loss_dice: 0.3944  decode.d7.loss_cls: 1.2949  decode.d7.loss_mask: 0.2348  decode.d7.loss_dice: 0.3934  decode.d8.loss_cls: 1.4285  decode.d8.loss_mask: 0.2525  decode.d8.loss_dice: 0.3984
08/06 02:50:15 - mmengine - INFO - Iter(train) [  4100/320000]  base_lr: 9.8846e-05 lr: 9.8846e-06  eta: 1 day, 18:58:53  time: 0.4885  data_time: 0.0104  memory: 5877  grad_norm: 223.1309  loss: 19.0051  decode.loss_cls: 1.0934  decode.loss_mask: 0.2815  decode.loss_dice: 0.3986  decode.d0.loss_cls: 1.8341  decode.d0.loss_mask: 0.2994  decode.d0.loss_dice: 0.4965  decode.d1.loss_cls: 1.3150  decode.d1.loss_mask: 0.2867  decode.d1.loss_dice: 0.3742  decode.d2.loss_cls: 1.1869  decode.d2.loss_mask: 0.2775  decode.d2.loss_dice: 0.3764  decode.d3.loss_cls: 1.1131  decode.d3.loss_mask: 0.2758  decode.d3.loss_dice: 0.3431  decode.d4.loss_cls: 1.1507  decode.d4.loss_mask: 0.3012  decode.d4.loss_dice: 0.3719  decode.d5.loss_cls: 1.1297  decode.d5.loss_mask: 0.2939  decode.d5.loss_dice: 0.4054  decode.d6.loss_cls: 1.1523  decode.d6.loss_mask: 0.2766  decode.d6.loss_dice: 0.3564  decode.d7.loss_cls: 1.1456  decode.d7.loss_mask: 0.2861  decode.d7.loss_dice: 0.3930  decode.d8.loss_cls: 1.1475  decode.d8.loss_mask: 0.2815  decode.d8.loss_dice: 0.3611
08/06 02:50:40 - mmengine - INFO - Iter(train) [  4150/320000]  base_lr: 9.8832e-05 lr: 9.8832e-06  eta: 1 day, 18:58:27  time: 0.4898  data_time: 0.0102  memory: 5907  grad_norm: 254.7690  loss: 23.2949  decode.loss_cls: 1.1320  decode.loss_mask: 0.4580  decode.loss_dice: 0.5081  decode.d0.loss_cls: 2.1164  decode.d0.loss_mask: 0.5190  decode.d0.loss_dice: 0.6150  decode.d1.loss_cls: 1.4900  decode.d1.loss_mask: 0.4918  decode.d1.loss_dice: 0.5717  decode.d2.loss_cls: 1.2780  decode.d2.loss_mask: 0.4701  decode.d2.loss_dice: 0.5133  decode.d3.loss_cls: 1.1990  decode.d3.loss_mask: 0.4702  decode.d3.loss_dice: 0.5176  decode.d4.loss_cls: 1.1826  decode.d4.loss_mask: 0.4941  decode.d4.loss_dice: 0.5253  decode.d5.loss_cls: 1.1829  decode.d5.loss_mask: 0.5544  decode.d5.loss_dice: 0.5571  decode.d6.loss_cls: 1.1690  decode.d6.loss_mask: 0.4770  decode.d6.loss_dice: 0.5290  decode.d7.loss_cls: 1.1641  decode.d7.loss_mask: 0.4852  decode.d7.loss_dice: 0.5431  decode.d8.loss_cls: 1.1191  decode.d8.loss_mask: 0.4671  decode.d8.loss_dice: 0.4945
08/06 02:51:04 - mmengine - INFO - Iter(train) [  4200/320000]  base_lr: 9.8818e-05 lr: 9.8818e-06  eta: 1 day, 18:58:03  time: 0.4901  data_time: 0.0100  memory: 5908  grad_norm: 212.7129  loss: 17.3343  decode.loss_cls: 0.9642  decode.loss_mask: 0.2706  decode.loss_dice: 0.3651  decode.d0.loss_cls: 1.8688  decode.d0.loss_mask: 0.2628  decode.d0.loss_dice: 0.3483  decode.d1.loss_cls: 1.2089  decode.d1.loss_mask: 0.2947  decode.d1.loss_dice: 0.4069  decode.d2.loss_cls: 0.9150  decode.d2.loss_mask: 0.2858  decode.d2.loss_dice: 0.4144  decode.d3.loss_cls: 0.8531  decode.d3.loss_mask: 0.3317  decode.d3.loss_dice: 0.4161  decode.d4.loss_cls: 0.8912  decode.d4.loss_mask: 0.3080  decode.d4.loss_dice: 0.3922  decode.d5.loss_cls: 0.8923  decode.d5.loss_mask: 0.2945  decode.d5.loss_dice: 0.4058  decode.d6.loss_cls: 0.8617  decode.d6.loss_mask: 0.3187  decode.d6.loss_dice: 0.4487  decode.d7.loss_cls: 0.9104  decode.d7.loss_mask: 0.3372  decode.d7.loss_dice: 0.4751  decode.d8.loss_cls: 0.8950  decode.d8.loss_mask: 0.2914  decode.d8.loss_dice: 0.4055
08/06 02:51:29 - mmengine - INFO - Iter(train) [  4250/320000]  base_lr: 9.8804e-05 lr: 9.8804e-06  eta: 1 day, 18:57:38  time: 0.4893  data_time: 0.0101  memory: 5890  grad_norm: 156.1043  loss: 15.7030  decode.loss_cls: 0.7808  decode.loss_mask: 0.3097  decode.loss_dice: 0.3637  decode.d0.loss_cls: 1.6995  decode.d0.loss_mask: 0.3255  decode.d0.loss_dice: 0.4296  decode.d1.loss_cls: 0.9951  decode.d1.loss_mask: 0.3104  decode.d1.loss_dice: 0.3895  decode.d2.loss_cls: 0.7619  decode.d2.loss_mask: 0.3024  decode.d2.loss_dice: 0.3798  decode.d3.loss_cls: 0.7482  decode.d3.loss_mask: 0.2973  decode.d3.loss_dice: 0.3634  decode.d4.loss_cls: 0.7176  decode.d4.loss_mask: 0.3113  decode.d4.loss_dice: 0.3749  decode.d5.loss_cls: 0.7595  decode.d5.loss_mask: 0.3024  decode.d5.loss_dice: 0.3728  decode.d6.loss_cls: 0.7762  decode.d6.loss_mask: 0.2991  decode.d6.loss_dice: 0.3792  decode.d7.loss_cls: 0.7533  decode.d7.loss_mask: 0.3068  decode.d7.loss_dice: 0.3551  decode.d8.loss_cls: 0.8550  decode.d8.loss_mask: 0.3118  decode.d8.loss_dice: 0.3713
08/06 02:51:53 - mmengine - INFO - Iter(train) [  4300/320000]  base_lr: 9.8790e-05 lr: 9.8790e-06  eta: 1 day, 18:57:13  time: 0.4899  data_time: 0.0101  memory: 5907  grad_norm: 150.5903  loss: 18.8288  decode.loss_cls: 1.1572  decode.loss_mask: 0.2700  decode.loss_dice: 0.3579  decode.d0.loss_cls: 2.0551  decode.d0.loss_mask: 0.2774  decode.d0.loss_dice: 0.3912  decode.d1.loss_cls: 1.5064  decode.d1.loss_mask: 0.2471  decode.d1.loss_dice: 0.3140  decode.d2.loss_cls: 1.1274  decode.d2.loss_mask: 0.2489  decode.d2.loss_dice: 0.3336  decode.d3.loss_cls: 1.1672  decode.d3.loss_mask: 0.2570  decode.d3.loss_dice: 0.3596  decode.d4.loss_cls: 1.1897  decode.d4.loss_mask: 0.2752  decode.d4.loss_dice: 0.3738  decode.d5.loss_cls: 1.1991  decode.d5.loss_mask: 0.2571  decode.d5.loss_dice: 0.3387  decode.d6.loss_cls: 1.0831  decode.d6.loss_mask: 0.2490  decode.d6.loss_dice: 0.3314  decode.d7.loss_cls: 1.0909  decode.d7.loss_mask: 0.2499  decode.d7.loss_dice: 0.3233  decode.d8.loss_cls: 1.2116  decode.d8.loss_mask: 0.2527  decode.d8.loss_dice: 0.3335
08/06 02:52:18 - mmengine - INFO - Iter(train) [  4350/320000]  base_lr: 9.8776e-05 lr: 9.8776e-06  eta: 1 day, 18:56:50  time: 0.4901  data_time: 0.0102  memory: 5908  grad_norm: 220.3416  loss: 18.3608  decode.loss_cls: 0.8806  decode.loss_mask: 0.3748  decode.loss_dice: 0.3817  decode.d0.loss_cls: 1.9430  decode.d0.loss_mask: 0.3974  decode.d0.loss_dice: 0.4729  decode.d1.loss_cls: 1.4616  decode.d1.loss_mask: 0.3560  decode.d1.loss_dice: 0.3988  decode.d2.loss_cls: 1.0640  decode.d2.loss_mask: 0.3574  decode.d2.loss_dice: 0.3556  decode.d3.loss_cls: 0.9464  decode.d3.loss_mask: 0.3411  decode.d3.loss_dice: 0.3446  decode.d4.loss_cls: 0.9097  decode.d4.loss_mask: 0.3548  decode.d4.loss_dice: 0.3625  decode.d5.loss_cls: 0.9255  decode.d5.loss_mask: 0.3658  decode.d5.loss_dice: 0.3849  decode.d6.loss_cls: 0.9074  decode.d6.loss_mask: 0.3425  decode.d6.loss_dice: 0.3533  decode.d7.loss_cls: 0.9097  decode.d7.loss_mask: 0.3512  decode.d7.loss_dice: 0.3729  decode.d8.loss_cls: 0.9656  decode.d8.loss_mask: 0.3921  decode.d8.loss_dice: 0.3869
08/06 02:52:42 - mmengine - INFO - Iter(train) [  4400/320000]  base_lr: 9.8762e-05 lr: 9.8762e-06  eta: 1 day, 18:56:25  time: 0.4900  data_time: 0.0102  memory: 5908  grad_norm: 169.6911  loss: 16.4724  decode.loss_cls: 0.8404  decode.loss_mask: 0.2862  decode.loss_dice: 0.3538  decode.d0.loss_cls: 1.6466  decode.d0.loss_mask: 0.3013  decode.d0.loss_dice: 0.4388  decode.d1.loss_cls: 1.1369  decode.d1.loss_mask: 0.2851  decode.d1.loss_dice: 0.3787  decode.d2.loss_cls: 0.8540  decode.d2.loss_mask: 0.2808  decode.d2.loss_dice: 0.3374  decode.d3.loss_cls: 0.8814  decode.d3.loss_mask: 0.2816  decode.d3.loss_dice: 0.3506  decode.d4.loss_cls: 0.9334  decode.d4.loss_mask: 0.2829  decode.d4.loss_dice: 0.3401  decode.d5.loss_cls: 0.9614  decode.d5.loss_mask: 0.2993  decode.d5.loss_dice: 0.3765  decode.d6.loss_cls: 0.9599  decode.d6.loss_mask: 0.2975  decode.d6.loss_dice: 0.3338  decode.d7.loss_cls: 0.8987  decode.d7.loss_mask: 0.2882  decode.d7.loss_dice: 0.3474  decode.d8.loss_cls: 0.8393  decode.d8.loss_mask: 0.2855  decode.d8.loss_dice: 0.3750
08/06 02:53:07 - mmengine - INFO - Iter(train) [  4450/320000]  base_lr: 9.8748e-05 lr: 9.8748e-06  eta: 1 day, 18:56:07  time: 0.4895  data_time: 0.0101  memory: 5889  grad_norm: 264.8366  loss: 19.6069  decode.loss_cls: 1.1587  decode.loss_mask: 0.2922  decode.loss_dice: 0.3767  decode.d0.loss_cls: 1.9906  decode.d0.loss_mask: 0.3247  decode.d0.loss_dice: 0.4929  decode.d1.loss_cls: 1.2976  decode.d1.loss_mask: 0.3222  decode.d1.loss_dice: 0.4063  decode.d2.loss_cls: 1.1529  decode.d2.loss_mask: 0.3018  decode.d2.loss_dice: 0.3939  decode.d3.loss_cls: 1.1270  decode.d3.loss_mask: 0.2954  decode.d3.loss_dice: 0.4185  decode.d4.loss_cls: 1.2086  decode.d4.loss_mask: 0.2891  decode.d4.loss_dice: 0.4131  decode.d5.loss_cls: 1.1472  decode.d5.loss_mask: 0.3005  decode.d5.loss_dice: 0.4459  decode.d6.loss_cls: 1.0164  decode.d6.loss_mask: 0.3320  decode.d6.loss_dice: 0.4371  decode.d7.loss_cls: 1.0282  decode.d7.loss_mask: 0.3161  decode.d7.loss_dice: 0.4306  decode.d8.loss_cls: 1.1917  decode.d8.loss_mask: 0.2968  decode.d8.loss_dice: 0.4023
08/06 02:53:31 - mmengine - INFO - Iter(train) [  4500/320000]  base_lr: 9.8734e-05 lr: 9.8734e-06  eta: 1 day, 18:55:42  time: 0.4899  data_time: 0.0103  memory: 5891  grad_norm: 260.1581  loss: 18.8040  decode.loss_cls: 0.7978  decode.loss_mask: 0.5880  decode.loss_dice: 0.4195  decode.d0.loss_cls: 1.8369  decode.d0.loss_mask: 0.4980  decode.d0.loss_dice: 0.4473  decode.d1.loss_cls: 1.1467  decode.d1.loss_mask: 0.4600  decode.d1.loss_dice: 0.4219  decode.d2.loss_cls: 0.8010  decode.d2.loss_mask: 0.4646  decode.d2.loss_dice: 0.4261  decode.d3.loss_cls: 0.8671  decode.d3.loss_mask: 0.5005  decode.d3.loss_dice: 0.4237  decode.d4.loss_cls: 0.8487  decode.d4.loss_mask: 0.5106  decode.d4.loss_dice: 0.4299  decode.d5.loss_cls: 0.7593  decode.d5.loss_mask: 0.5195  decode.d5.loss_dice: 0.4452  decode.d6.loss_cls: 0.7581  decode.d6.loss_mask: 0.5526  decode.d6.loss_dice: 0.4353  decode.d7.loss_cls: 0.7857  decode.d7.loss_mask: 0.4845  decode.d7.loss_dice: 0.4433  decode.d8.loss_cls: 0.7884  decode.d8.loss_mask: 0.5069  decode.d8.loss_dice: 0.4369
08/06 02:53:56 - mmengine - INFO - Iter(train) [  4550/320000]  base_lr: 9.8720e-05 lr: 9.8720e-06  eta: 1 day, 18:55:17  time: 0.4901  data_time: 0.0101  memory: 5907  grad_norm: 161.2364  loss: 19.4357  decode.loss_cls: 1.1594  decode.loss_mask: 0.3591  decode.loss_dice: 0.3784  decode.d0.loss_cls: 2.0561  decode.d0.loss_mask: 0.3783  decode.d0.loss_dice: 0.4497  decode.d1.loss_cls: 1.3985  decode.d1.loss_mask: 0.3764  decode.d1.loss_dice: 0.3948  decode.d2.loss_cls: 1.0680  decode.d2.loss_mask: 0.3637  decode.d2.loss_dice: 0.3767  decode.d3.loss_cls: 0.9428  decode.d3.loss_mask: 0.3654  decode.d3.loss_dice: 0.3750  decode.d4.loss_cls: 0.9910  decode.d4.loss_mask: 0.3601  decode.d4.loss_dice: 0.3817  decode.d5.loss_cls: 0.9597  decode.d5.loss_mask: 0.3775  decode.d5.loss_dice: 0.3938  decode.d6.loss_cls: 0.9676  decode.d6.loss_mask: 0.3860  decode.d6.loss_dice: 0.3977  decode.d7.loss_cls: 1.0714  decode.d7.loss_mask: 0.3979  decode.d7.loss_dice: 0.4050  decode.d8.loss_cls: 1.1205  decode.d8.loss_mask: 0.3883  decode.d8.loss_dice: 0.3954
08/06 02:54:20 - mmengine - INFO - Iter(train) [  4600/320000]  base_lr: 9.8706e-05 lr: 9.8706e-06  eta: 1 day, 18:54:53  time: 0.4908  data_time: 0.0102  memory: 5877  grad_norm: 177.0326  loss: 17.6579  decode.loss_cls: 0.9346  decode.loss_mask: 0.2935  decode.loss_dice: 0.3408  decode.d0.loss_cls: 2.0105  decode.d0.loss_mask: 0.3445  decode.d0.loss_dice: 0.4644  decode.d1.loss_cls: 1.2639  decode.d1.loss_mask: 0.2804  decode.d1.loss_dice: 0.3704  decode.d2.loss_cls: 0.9914  decode.d2.loss_mask: 0.2828  decode.d2.loss_dice: 0.3320  decode.d3.loss_cls: 0.9758  decode.d3.loss_mask: 0.2682  decode.d3.loss_dice: 0.3276  decode.d4.loss_cls: 0.9673  decode.d4.loss_mask: 0.2872  decode.d4.loss_dice: 0.3384  decode.d5.loss_cls: 1.0163  decode.d5.loss_mask: 0.2921  decode.d5.loss_dice: 0.3442  decode.d6.loss_cls: 1.0108  decode.d6.loss_mask: 0.2917  decode.d6.loss_dice: 0.3442  decode.d7.loss_cls: 1.0166  decode.d7.loss_mask: 0.3021  decode.d7.loss_dice: 0.3545  decode.d8.loss_cls: 0.9668  decode.d8.loss_mask: 0.2973  decode.d8.loss_dice: 0.3474
08/06 02:54:45 - mmengine - INFO - Iter(train) [  4650/320000]  base_lr: 9.8692e-05 lr: 9.8692e-06  eta: 1 day, 18:54:28  time: 0.4897  data_time: 0.0103  memory: 5907  grad_norm: 254.0864  loss: 17.7275  decode.loss_cls: 0.8828  decode.loss_mask: 0.3431  decode.loss_dice: 0.3731  decode.d0.loss_cls: 1.8403  decode.d0.loss_mask: 0.3768  decode.d0.loss_dice: 0.4558  decode.d1.loss_cls: 1.2082  decode.d1.loss_mask: 0.3585  decode.d1.loss_dice: 0.4144  decode.d2.loss_cls: 0.8753  decode.d2.loss_mask: 0.3657  decode.d2.loss_dice: 0.4137  decode.d3.loss_cls: 0.8423  decode.d3.loss_mask: 0.3908  decode.d3.loss_dice: 0.4038  decode.d4.loss_cls: 0.8821  decode.d4.loss_mask: 0.3601  decode.d4.loss_dice: 0.4114  decode.d5.loss_cls: 0.8514  decode.d5.loss_mask: 0.3354  decode.d5.loss_dice: 0.3849  decode.d6.loss_cls: 0.8528  decode.d6.loss_mask: 0.3678  decode.d6.loss_dice: 0.4096  decode.d7.loss_cls: 0.8648  decode.d7.loss_mask: 0.3870  decode.d7.loss_dice: 0.3896  decode.d8.loss_cls: 0.9020  decode.d8.loss_mask: 0.3819  decode.d8.loss_dice: 0.4021
08/06 02:55:09 - mmengine - INFO - Iter(train) [  4700/320000]  base_lr: 9.8677e-05 lr: 9.8677e-06  eta: 1 day, 18:54:05  time: 0.4900  data_time: 0.0102  memory: 5908  grad_norm: 196.4633  loss: 18.6348  decode.loss_cls: 0.9906  decode.loss_mask: 0.3206  decode.loss_dice: 0.3585  decode.d0.loss_cls: 1.8901  decode.d0.loss_mask: 0.3433  decode.d0.loss_dice: 0.4469  decode.d1.loss_cls: 1.4390  decode.d1.loss_mask: 0.3376  decode.d1.loss_dice: 0.3863  decode.d2.loss_cls: 1.0733  decode.d2.loss_mask: 0.3273  decode.d2.loss_dice: 0.3698  decode.d3.loss_cls: 1.0044  decode.d3.loss_mask: 0.3310  decode.d3.loss_dice: 0.3515  decode.d4.loss_cls: 0.9895  decode.d4.loss_mask: 0.3196  decode.d4.loss_dice: 0.3664  decode.d5.loss_cls: 0.9905  decode.d5.loss_mask: 0.3540  decode.d5.loss_dice: 0.3879  decode.d6.loss_cls: 1.0955  decode.d6.loss_mask: 0.3213  decode.d6.loss_dice: 0.3603  decode.d7.loss_cls: 1.0674  decode.d7.loss_mask: 0.3238  decode.d7.loss_dice: 0.3598  decode.d8.loss_cls: 1.0496  decode.d8.loss_mask: 0.3200  decode.d8.loss_dice: 0.3590
08/06 02:55:34 - mmengine - INFO - Iter(train) [  4750/320000]  base_lr: 9.8663e-05 lr: 9.8663e-06  eta: 1 day, 18:53:51  time: 0.4890  data_time: 0.0103  memory: 5907  grad_norm: 253.7505  loss: 16.8476  decode.loss_cls: 0.7306  decode.loss_mask: 0.4112  decode.loss_dice: 0.4056  decode.d0.loss_cls: 1.5090  decode.d0.loss_mask: 0.4583  decode.d0.loss_dice: 0.4453  decode.d1.loss_cls: 0.9684  decode.d1.loss_mask: 0.4327  decode.d1.loss_dice: 0.3660  decode.d2.loss_cls: 0.7965  decode.d2.loss_mask: 0.4000  decode.d2.loss_dice: 0.3515  decode.d3.loss_cls: 0.8094  decode.d3.loss_mask: 0.4369  decode.d3.loss_dice: 0.3882  decode.d4.loss_cls: 0.7754  decode.d4.loss_mask: 0.4204  decode.d4.loss_dice: 0.3920  decode.d5.loss_cls: 0.8354  decode.d5.loss_mask: 0.4268  decode.d5.loss_dice: 0.3952  decode.d6.loss_cls: 0.8003  decode.d6.loss_mask: 0.4088  decode.d6.loss_dice: 0.3914  decode.d7.loss_cls: 0.7398  decode.d7.loss_mask: 0.4043  decode.d7.loss_dice: 0.3696  decode.d8.loss_cls: 0.7805  decode.d8.loss_mask: 0.4134  decode.d8.loss_dice: 0.3848
08/06 02:55:59 - mmengine - INFO - Iter(train) [  4800/320000]  base_lr: 9.8649e-05 lr: 9.8649e-06  eta: 1 day, 18:53:27  time: 0.4902  data_time: 0.0102  memory: 5891  grad_norm: 226.2338  loss: 17.7687  decode.loss_cls: 0.9927  decode.loss_mask: 0.2863  decode.loss_dice: 0.3615  decode.d0.loss_cls: 1.9284  decode.d0.loss_mask: 0.3095  decode.d0.loss_dice: 0.4119  decode.d1.loss_cls: 1.1912  decode.d1.loss_mask: 0.2915  decode.d1.loss_dice: 0.3787  decode.d2.loss_cls: 0.8962  decode.d2.loss_mask: 0.2996  decode.d2.loss_dice: 0.3795  decode.d3.loss_cls: 0.9247  decode.d3.loss_mask: 0.3112  decode.d3.loss_dice: 0.3916  decode.d4.loss_cls: 1.0137  decode.d4.loss_mask: 0.3122  decode.d4.loss_dice: 0.3668  decode.d5.loss_cls: 1.0043  decode.d5.loss_mask: 0.2993  decode.d5.loss_dice: 0.3809  decode.d6.loss_cls: 0.9340  decode.d6.loss_mask: 0.3039  decode.d6.loss_dice: 0.3948  decode.d7.loss_cls: 1.0210  decode.d7.loss_mask: 0.2896  decode.d7.loss_dice: 0.3857  decode.d8.loss_cls: 1.0486  decode.d8.loss_mask: 0.2889  decode.d8.loss_dice: 0.3705
08/06 02:56:23 - mmengine - INFO - Iter(train) [  4850/320000]  base_lr: 9.8635e-05 lr: 9.8635e-06  eta: 1 day, 18:53:04  time: 0.4903  data_time: 0.0100  memory: 5909  grad_norm: 196.6021  loss: 15.1370  decode.loss_cls: 0.7429  decode.loss_mask: 0.3320  decode.loss_dice: 0.3529  decode.d0.loss_cls: 1.5905  decode.d0.loss_mask: 0.3213  decode.d0.loss_dice: 0.3766  decode.d1.loss_cls: 0.9279  decode.d1.loss_mask: 0.3341  decode.d1.loss_dice: 0.3696  decode.d2.loss_cls: 0.7215  decode.d2.loss_mask: 0.3255  decode.d2.loss_dice: 0.3641  decode.d3.loss_cls: 0.7488  decode.d3.loss_mask: 0.3207  decode.d3.loss_dice: 0.3395  decode.d4.loss_cls: 0.7735  decode.d4.loss_mask: 0.3203  decode.d4.loss_dice: 0.3509  decode.d5.loss_cls: 0.7349  decode.d5.loss_mask: 0.3221  decode.d5.loss_dice: 0.3588  decode.d6.loss_cls: 0.6400  decode.d6.loss_mask: 0.3292  decode.d6.loss_dice: 0.3542  decode.d7.loss_cls: 0.6687  decode.d7.loss_mask: 0.3372  decode.d7.loss_dice: 0.3749  decode.d8.loss_cls: 0.7244  decode.d8.loss_mask: 0.3320  decode.d8.loss_dice: 0.3476
08/06 02:56:48 - mmengine - INFO - Iter(train) [  4900/320000]  base_lr: 9.8621e-05 lr: 9.8621e-06  eta: 1 day, 18:52:39  time: 0.4904  data_time: 0.0104  memory: 5875  grad_norm: 307.1407  loss: 17.1016  decode.loss_cls: 0.7750  decode.loss_mask: 0.4007  decode.loss_dice: 0.4596  decode.d0.loss_cls: 1.5783  decode.d0.loss_mask: 0.4710  decode.d0.loss_dice: 0.5764  decode.d1.loss_cls: 0.9552  decode.d1.loss_mask: 0.3932  decode.d1.loss_dice: 0.4566  decode.d2.loss_cls: 0.6916  decode.d2.loss_mask: 0.4089  decode.d2.loss_dice: 0.4265  decode.d3.loss_cls: 0.7111  decode.d3.loss_mask: 0.3948  decode.d3.loss_dice: 0.4528  decode.d4.loss_cls: 0.7789  decode.d4.loss_mask: 0.4127  decode.d4.loss_dice: 0.4423  decode.d5.loss_cls: 0.6972  decode.d5.loss_mask: 0.3939  decode.d5.loss_dice: 0.4432  decode.d6.loss_cls: 0.7258  decode.d6.loss_mask: 0.4051  decode.d6.loss_dice: 0.4648  decode.d7.loss_cls: 0.6837  decode.d7.loss_mask: 0.4229  decode.d7.loss_dice: 0.4541  decode.d8.loss_cls: 0.7659  decode.d8.loss_mask: 0.4107  decode.d8.loss_dice: 0.4489
08/06 02:57:12 - mmengine - INFO - Iter(train) [  4950/320000]  base_lr: 9.8607e-05 lr: 9.8607e-06  eta: 1 day, 18:52:15  time: 0.4897  data_time: 0.0104  memory: 5891  grad_norm: 326.6244  loss: 17.1715  decode.loss_cls: 0.7719  decode.loss_mask: 0.3385  decode.loss_dice: 0.4282  decode.d0.loss_cls: 1.6233  decode.d0.loss_mask: 0.3635  decode.d0.loss_dice: 0.4852  decode.d1.loss_cls: 1.0472  decode.d1.loss_mask: 0.4036  decode.d1.loss_dice: 0.5093  decode.d2.loss_cls: 0.8178  decode.d2.loss_mask: 0.3993  decode.d2.loss_dice: 0.4602  decode.d3.loss_cls: 0.7118  decode.d3.loss_mask: 0.3515  decode.d3.loss_dice: 0.4277  decode.d4.loss_cls: 0.8067  decode.d4.loss_mask: 0.3913  decode.d4.loss_dice: 0.4519  decode.d5.loss_cls: 0.8324  decode.d5.loss_mask: 0.3739  decode.d5.loss_dice: 0.4263  decode.d6.loss_cls: 0.7145  decode.d6.loss_mask: 0.3761  decode.d6.loss_dice: 0.4270  decode.d7.loss_cls: 0.8642  decode.d7.loss_mask: 0.3634  decode.d7.loss_dice: 0.4011  decode.d8.loss_cls: 0.8689  decode.d8.loss_mask: 0.3426  decode.d8.loss_dice: 0.3921
08/06 02:57:37 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 02:57:37 - mmengine - INFO - Iter(train) [  5000/320000]  base_lr: 9.8593e-05 lr: 9.8593e-06  eta: 1 day, 18:51:52  time: 0.4905  data_time: 0.0101  memory: 5891  grad_norm: 274.2921  loss: 19.7972  decode.loss_cls: 1.0292  decode.loss_mask: 0.4419  decode.loss_dice: 0.4520  decode.d0.loss_cls: 1.9349  decode.d0.loss_mask: 0.4150  decode.d0.loss_dice: 0.4773  decode.d1.loss_cls: 1.4807  decode.d1.loss_mask: 0.3555  decode.d1.loss_dice: 0.4000  decode.d2.loss_cls: 1.0878  decode.d2.loss_mask: 0.3471  decode.d2.loss_dice: 0.3531  decode.d3.loss_cls: 1.0730  decode.d3.loss_mask: 0.3474  decode.d3.loss_dice: 0.3705  decode.d4.loss_cls: 1.0701  decode.d4.loss_mask: 0.3477  decode.d4.loss_dice: 0.3814  decode.d5.loss_cls: 1.1139  decode.d5.loss_mask: 0.3609  decode.d5.loss_dice: 0.3858  decode.d6.loss_cls: 1.1093  decode.d6.loss_mask: 0.3537  decode.d6.loss_dice: 0.3769  decode.d7.loss_cls: 1.0700  decode.d7.loss_mask: 0.3736  decode.d7.loss_dice: 0.3844  decode.d8.loss_cls: 1.0166  decode.d8.loss_mask: 0.4489  decode.d8.loss_dice: 0.4388
08/06 02:58:01 - mmengine - INFO - Iter(train) [  5050/320000]  base_lr: 9.8579e-05 lr: 9.8579e-06  eta: 1 day, 18:51:27  time: 0.4894  data_time: 0.0102  memory: 5907  grad_norm: 193.7817  loss: 16.4934  decode.loss_cls: 0.7940  decode.loss_mask: 0.3377  decode.loss_dice: 0.3485  decode.d0.loss_cls: 1.7725  decode.d0.loss_mask: 0.3935  decode.d0.loss_dice: 0.4330  decode.d1.loss_cls: 1.0360  decode.d1.loss_mask: 0.3273  decode.d1.loss_dice: 0.3316  decode.d2.loss_cls: 0.8173  decode.d2.loss_mask: 0.3143  decode.d2.loss_dice: 0.3272  decode.d3.loss_cls: 0.8315  decode.d3.loss_mask: 0.3416  decode.d3.loss_dice: 0.3882  decode.d4.loss_cls: 0.8199  decode.d4.loss_mask: 0.3527  decode.d4.loss_dice: 0.3596  decode.d5.loss_cls: 0.8954  decode.d5.loss_mask: 0.3332  decode.d5.loss_dice: 0.3191  decode.d6.loss_cls: 0.8435  decode.d6.loss_mask: 0.3343  decode.d6.loss_dice: 0.3324  decode.d7.loss_cls: 0.9021  decode.d7.loss_mask: 0.3148  decode.d7.loss_dice: 0.3218  decode.d8.loss_cls: 0.8761  decode.d8.loss_mask: 0.3373  decode.d8.loss_dice: 0.3569
08/06 02:58:26 - mmengine - INFO - Iter(train) [  5100/320000]  base_lr: 9.8565e-05 lr: 9.8565e-06  eta: 1 day, 18:51:03  time: 0.4895  data_time: 0.0099  memory: 5889  grad_norm: 166.0307  loss: 17.7460  decode.loss_cls: 1.0422  decode.loss_mask: 0.2417  decode.loss_dice: 0.3306  decode.d0.loss_cls: 1.8940  decode.d0.loss_mask: 0.2715  decode.d0.loss_dice: 0.4244  decode.d1.loss_cls: 1.2471  decode.d1.loss_mask: 0.2669  decode.d1.loss_dice: 0.3803  decode.d2.loss_cls: 1.0762  decode.d2.loss_mask: 0.2521  decode.d2.loss_dice: 0.3703  decode.d3.loss_cls: 1.0668  decode.d3.loss_mask: 0.2379  decode.d3.loss_dice: 0.3396  decode.d4.loss_cls: 1.1532  decode.d4.loss_mask: 0.2364  decode.d4.loss_dice: 0.3159  decode.d5.loss_cls: 1.0961  decode.d5.loss_mask: 0.2477  decode.d5.loss_dice: 0.3305  decode.d6.loss_cls: 1.0769  decode.d6.loss_mask: 0.2408  decode.d6.loss_dice: 0.3434  decode.d7.loss_cls: 1.0675  decode.d7.loss_mask: 0.2402  decode.d7.loss_dice: 0.3395  decode.d8.loss_cls: 1.0663  decode.d8.loss_mask: 0.2357  decode.d8.loss_dice: 0.3142
08/06 02:58:50 - mmengine - INFO - Iter(train) [  5150/320000]  base_lr: 9.8551e-05 lr: 9.8551e-06  eta: 1 day, 18:50:40  time: 0.4901  data_time: 0.0101  memory: 5927  grad_norm: 139.0070  loss: 13.8380  decode.loss_cls: 0.7384  decode.loss_mask: 0.2640  decode.loss_dice: 0.2847  decode.d0.loss_cls: 1.7080  decode.d0.loss_mask: 0.2824  decode.d0.loss_dice: 0.3507  decode.d1.loss_cls: 1.0311  decode.d1.loss_mask: 0.2558  decode.d1.loss_dice: 0.3008  decode.d2.loss_cls: 0.7723  decode.d2.loss_mask: 0.2461  decode.d2.loss_dice: 0.2787  decode.d3.loss_cls: 0.6465  decode.d3.loss_mask: 0.2559  decode.d3.loss_dice: 0.2884  decode.d4.loss_cls: 0.6657  decode.d4.loss_mask: 0.2405  decode.d4.loss_dice: 0.2891  decode.d5.loss_cls: 0.6533  decode.d5.loss_mask: 0.2545  decode.d5.loss_dice: 0.2958  decode.d6.loss_cls: 0.6744  decode.d6.loss_mask: 0.2666  decode.d6.loss_dice: 0.2895  decode.d7.loss_cls: 0.7586  decode.d7.loss_mask: 0.2442  decode.d7.loss_dice: 0.2877  decode.d8.loss_cls: 0.6571  decode.d8.loss_mask: 0.2534  decode.d8.loss_dice: 0.3038
08/06 02:59:15 - mmengine - INFO - Iter(train) [  5200/320000]  base_lr: 9.8537e-05 lr: 9.8537e-06  eta: 1 day, 18:50:16  time: 0.4901  data_time: 0.0103  memory: 5907  grad_norm: 194.0533  loss: 15.0843  decode.loss_cls: 0.8378  decode.loss_mask: 0.2749  decode.loss_dice: 0.3367  decode.d0.loss_cls: 1.6839  decode.d0.loss_mask: 0.2973  decode.d0.loss_dice: 0.4509  decode.d1.loss_cls: 0.9490  decode.d1.loss_mask: 0.2903  decode.d1.loss_dice: 0.3572  decode.d2.loss_cls: 0.7403  decode.d2.loss_mask: 0.3016  decode.d2.loss_dice: 0.3420  decode.d3.loss_cls: 0.7240  decode.d3.loss_mask: 0.2899  decode.d3.loss_dice: 0.3349  decode.d4.loss_cls: 0.7207  decode.d4.loss_mask: 0.2809  decode.d4.loss_dice: 0.3414  decode.d5.loss_cls: 0.7287  decode.d5.loss_mask: 0.2825  decode.d5.loss_dice: 0.3550  decode.d6.loss_cls: 0.7964  decode.d6.loss_mask: 0.2774  decode.d6.loss_dice: 0.3335  decode.d7.loss_cls: 0.7521  decode.d7.loss_mask: 0.2775  decode.d7.loss_dice: 0.3517  decode.d8.loss_cls: 0.7006  decode.d8.loss_mask: 0.2898  decode.d8.loss_dice: 0.3857
08/06 02:59:39 - mmengine - INFO - Iter(train) [  5250/320000]  base_lr: 9.8522e-05 lr: 9.8522e-06  eta: 1 day, 18:49:51  time: 0.4892  data_time: 0.0102  memory: 5908  grad_norm: 261.8311  loss: 17.6156  decode.loss_cls: 0.8570  decode.loss_mask: 0.3295  decode.loss_dice: 0.3913  decode.d0.loss_cls: 1.9231  decode.d0.loss_mask: 0.3745  decode.d0.loss_dice: 0.4784  decode.d1.loss_cls: 1.2413  decode.d1.loss_mask: 0.3196  decode.d1.loss_dice: 0.3834  decode.d2.loss_cls: 0.9964  decode.d2.loss_mask: 0.3138  decode.d2.loss_dice: 0.3471  decode.d3.loss_cls: 0.9335  decode.d3.loss_mask: 0.3174  decode.d3.loss_dice: 0.3327  decode.d4.loss_cls: 0.9300  decode.d4.loss_mask: 0.3170  decode.d4.loss_dice: 0.3745  decode.d5.loss_cls: 0.9072  decode.d5.loss_mask: 0.3436  decode.d5.loss_dice: 0.4069  decode.d6.loss_cls: 0.9113  decode.d6.loss_mask: 0.3169  decode.d6.loss_dice: 0.4008  decode.d7.loss_cls: 0.8869  decode.d7.loss_mask: 0.3069  decode.d7.loss_dice: 0.3785  decode.d8.loss_cls: 0.8912  decode.d8.loss_mask: 0.3234  decode.d8.loss_dice: 0.3814
08/06 03:00:04 - mmengine - INFO - Iter(train) [  5300/320000]  base_lr: 9.8508e-05 lr: 9.8508e-06  eta: 1 day, 18:49:26  time: 0.4903  data_time: 0.0102  memory: 5874  grad_norm: 211.3751  loss: 15.8853  decode.loss_cls: 0.6287  decode.loss_mask: 0.4323  decode.loss_dice: 0.3928  decode.d0.loss_cls: 1.5822  decode.d0.loss_mask: 0.3985  decode.d0.loss_dice: 0.4276  decode.d1.loss_cls: 0.9375  decode.d1.loss_mask: 0.4111  decode.d1.loss_dice: 0.4053  decode.d2.loss_cls: 0.6565  decode.d2.loss_mask: 0.4064  decode.d2.loss_dice: 0.3567  decode.d3.loss_cls: 0.6387  decode.d3.loss_mask: 0.4029  decode.d3.loss_dice: 0.3716  decode.d4.loss_cls: 0.7169  decode.d4.loss_mask: 0.3810  decode.d4.loss_dice: 0.3675  decode.d5.loss_cls: 0.6824  decode.d5.loss_mask: 0.4072  decode.d5.loss_dice: 0.3964  decode.d6.loss_cls: 0.6652  decode.d6.loss_mask: 0.4034  decode.d6.loss_dice: 0.3869  decode.d7.loss_cls: 0.6809  decode.d7.loss_mask: 0.4085  decode.d7.loss_dice: 0.4001  decode.d8.loss_cls: 0.7363  decode.d8.loss_mask: 0.4169  decode.d8.loss_dice: 0.3871
08/06 03:00:28 - mmengine - INFO - Iter(train) [  5350/320000]  base_lr: 9.8494e-05 lr: 9.8494e-06  eta: 1 day, 18:49:07  time: 0.4891  data_time: 0.0101  memory: 5908  grad_norm: 831.6546  loss: 16.6242  decode.loss_cls: 0.6387  decode.loss_mask: 0.4097  decode.loss_dice: 0.3987  decode.d0.loss_cls: 1.6730  decode.d0.loss_mask: 0.4678  decode.d0.loss_dice: 0.5102  decode.d1.loss_cls: 0.9870  decode.d1.loss_mask: 0.4569  decode.d1.loss_dice: 0.4182  decode.d2.loss_cls: 0.7093  decode.d2.loss_mask: 0.4355  decode.d2.loss_dice: 0.3787  decode.d3.loss_cls: 0.6750  decode.d3.loss_mask: 0.4205  decode.d3.loss_dice: 0.3918  decode.d4.loss_cls: 0.6977  decode.d4.loss_mask: 0.4279  decode.d4.loss_dice: 0.3810  decode.d5.loss_cls: 0.7239  decode.d5.loss_mask: 0.4249  decode.d5.loss_dice: 0.4039  decode.d6.loss_cls: 0.7177  decode.d6.loss_mask: 0.4285  decode.d6.loss_dice: 0.4215  decode.d7.loss_cls: 0.6680  decode.d7.loss_mask: 0.4330  decode.d7.loss_dice: 0.4132  decode.d8.loss_cls: 0.6692  decode.d8.loss_mask: 0.4380  decode.d8.loss_dice: 0.4047
08/06 03:00:53 - mmengine - INFO - Iter(train) [  5400/320000]  base_lr: 9.8480e-05 lr: 9.8480e-06  eta: 1 day, 18:48:41  time: 0.4891  data_time: 0.0102  memory: 5891  grad_norm: 199.0452  loss: 16.2163  decode.loss_cls: 0.7880  decode.loss_mask: 0.3268  decode.loss_dice: 0.4001  decode.d0.loss_cls: 1.5944  decode.d0.loss_mask: 0.3428  decode.d0.loss_dice: 0.4748  decode.d1.loss_cls: 0.8933  decode.d1.loss_mask: 0.3216  decode.d1.loss_dice: 0.4271  decode.d2.loss_cls: 0.7352  decode.d2.loss_mask: 0.3132  decode.d2.loss_dice: 0.4145  decode.d3.loss_cls: 0.7513  decode.d3.loss_mask: 0.3235  decode.d3.loss_dice: 0.4297  decode.d4.loss_cls: 0.8313  decode.d4.loss_mask: 0.3170  decode.d4.loss_dice: 0.4164  decode.d5.loss_cls: 0.8508  decode.d5.loss_mask: 0.3257  decode.d5.loss_dice: 0.4069  decode.d6.loss_cls: 0.8111  decode.d6.loss_mask: 0.3215  decode.d6.loss_dice: 0.4096  decode.d7.loss_cls: 0.7978  decode.d7.loss_mask: 0.3226  decode.d7.loss_dice: 0.4113  decode.d8.loss_cls: 0.7308  decode.d8.loss_mask: 0.3263  decode.d8.loss_dice: 0.4009
08/06 03:01:17 - mmengine - INFO - Iter(train) [  5450/320000]  base_lr: 9.8466e-05 lr: 9.8466e-06  eta: 1 day, 18:48:17  time: 0.4901  data_time: 0.0102  memory: 5907  grad_norm: 210.0767  loss: 18.2156  decode.loss_cls: 0.9257  decode.loss_mask: 0.3364  decode.loss_dice: 0.4838  decode.d0.loss_cls: 1.7927  decode.d0.loss_mask: 0.4024  decode.d0.loss_dice: 0.5612  decode.d1.loss_cls: 1.0023  decode.d1.loss_mask: 0.3598  decode.d1.loss_dice: 0.4947  decode.d2.loss_cls: 0.8909  decode.d2.loss_mask: 0.3433  decode.d2.loss_dice: 0.4385  decode.d3.loss_cls: 0.8563  decode.d3.loss_mask: 0.3175  decode.d3.loss_dice: 0.4421  decode.d4.loss_cls: 0.8447  decode.d4.loss_mask: 0.3182  decode.d4.loss_dice: 0.4710  decode.d5.loss_cls: 0.9490  decode.d5.loss_mask: 0.3349  decode.d5.loss_dice: 0.5166  decode.d6.loss_cls: 0.8588  decode.d6.loss_mask: 0.3567  decode.d6.loss_dice: 0.5043  decode.d7.loss_cls: 0.8519  decode.d7.loss_mask: 0.3549  decode.d7.loss_dice: 0.5131  decode.d8.loss_cls: 0.8826  decode.d8.loss_mask: 0.3150  decode.d8.loss_dice: 0.4959
08/06 03:01:42 - mmengine - INFO - Iter(train) [  5500/320000]  base_lr: 9.8452e-05 lr: 9.8452e-06  eta: 1 day, 18:47:53  time: 0.4891  data_time: 0.0102  memory: 5890  grad_norm: 298.7262  loss: 18.7464  decode.loss_cls: 0.8030  decode.loss_mask: 0.4337  decode.loss_dice: 0.5259  decode.d0.loss_cls: 1.6683  decode.d0.loss_mask: 0.4878  decode.d0.loss_dice: 0.5979  decode.d1.loss_cls: 1.0246  decode.d1.loss_mask: 0.3955  decode.d1.loss_dice: 0.5066  decode.d2.loss_cls: 0.9434  decode.d2.loss_mask: 0.3855  decode.d2.loss_dice: 0.4704  decode.d3.loss_cls: 0.8419  decode.d3.loss_mask: 0.4018  decode.d3.loss_dice: 0.4825  decode.d4.loss_cls: 0.7971  decode.d4.loss_mask: 0.4406  decode.d4.loss_dice: 0.4969  decode.d5.loss_cls: 0.8199  decode.d5.loss_mask: 0.4287  decode.d5.loss_dice: 0.4941  decode.d6.loss_cls: 0.7942  decode.d6.loss_mask: 0.4579  decode.d6.loss_dice: 0.5177  decode.d7.loss_cls: 0.8538  decode.d7.loss_mask: 0.4040  decode.d7.loss_dice: 0.5188  decode.d8.loss_cls: 0.8565  decode.d8.loss_mask: 0.4244  decode.d8.loss_dice: 0.4730
08/06 03:02:06 - mmengine - INFO - Iter(train) [  5550/320000]  base_lr: 9.8438e-05 lr: 9.8438e-06  eta: 1 day, 18:47:30  time: 0.4901  data_time: 0.0102  memory: 5908  grad_norm: 210.1048  loss: 18.2314  decode.loss_cls: 1.0057  decode.loss_mask: 0.3358  decode.loss_dice: 0.4247  decode.d0.loss_cls: 1.9339  decode.d0.loss_mask: 0.3966  decode.d0.loss_dice: 0.5592  decode.d1.loss_cls: 1.2571  decode.d1.loss_mask: 0.3271  decode.d1.loss_dice: 0.3943  decode.d2.loss_cls: 0.8280  decode.d2.loss_mask: 0.3619  decode.d2.loss_dice: 0.4365  decode.d3.loss_cls: 0.8481  decode.d3.loss_mask: 0.3546  decode.d3.loss_dice: 0.4562  decode.d4.loss_cls: 0.9098  decode.d4.loss_mask: 0.3445  decode.d4.loss_dice: 0.4263  decode.d5.loss_cls: 0.8948  decode.d5.loss_mask: 0.3387  decode.d5.loss_dice: 0.4108  decode.d6.loss_cls: 0.8710  decode.d6.loss_mask: 0.3441  decode.d6.loss_dice: 0.4342  decode.d7.loss_cls: 0.8572  decode.d7.loss_mask: 0.3507  decode.d7.loss_dice: 0.4255  decode.d8.loss_cls: 0.9432  decode.d8.loss_mask: 0.3432  decode.d8.loss_dice: 0.4175
08/06 03:02:31 - mmengine - INFO - Iter(train) [  5600/320000]  base_lr: 9.8424e-05 lr: 9.8424e-06  eta: 1 day, 18:47:06  time: 0.4909  data_time: 0.0103  memory: 5891  grad_norm: 157.8341  loss: 14.4390  decode.loss_cls: 0.5659  decode.loss_mask: 0.3003  decode.loss_dice: 0.3560  decode.d0.loss_cls: 1.4966  decode.d0.loss_mask: 0.3507  decode.d0.loss_dice: 0.4495  decode.d1.loss_cls: 0.9147  decode.d1.loss_mask: 0.3217  decode.d1.loss_dice: 0.4048  decode.d2.loss_cls: 0.7046  decode.d2.loss_mask: 0.3140  decode.d2.loss_dice: 0.3896  decode.d3.loss_cls: 0.6879  decode.d3.loss_mask: 0.3179  decode.d3.loss_dice: 0.3826  decode.d4.loss_cls: 0.6727  decode.d4.loss_mask: 0.3070  decode.d4.loss_dice: 0.3862  decode.d5.loss_cls: 0.7010  decode.d5.loss_mask: 0.3040  decode.d5.loss_dice: 0.3638  decode.d6.loss_cls: 0.5702  decode.d6.loss_mask: 0.2997  decode.d6.loss_dice: 0.3546  decode.d7.loss_cls: 0.5923  decode.d7.loss_mask: 0.3008  decode.d7.loss_dice: 0.3812  decode.d8.loss_cls: 0.6165  decode.d8.loss_mask: 0.2972  decode.d8.loss_dice: 0.3351
08/06 03:02:55 - mmengine - INFO - Iter(train) [  5650/320000]  base_lr: 9.8410e-05 lr: 9.8410e-06  eta: 1 day, 18:46:42  time: 0.4903  data_time: 0.0103  memory: 5907  grad_norm: 257.4526  loss: 17.1195  decode.loss_cls: 0.8301  decode.loss_mask: 0.3599  decode.loss_dice: 0.4066  decode.d0.loss_cls: 1.7303  decode.d0.loss_mask: 0.4214  decode.d0.loss_dice: 0.5112  decode.d1.loss_cls: 1.1109  decode.d1.loss_mask: 0.3479  decode.d1.loss_dice: 0.4190  decode.d2.loss_cls: 0.9453  decode.d2.loss_mask: 0.3108  decode.d2.loss_dice: 0.3698  decode.d3.loss_cls: 0.8636  decode.d3.loss_mask: 0.3193  decode.d3.loss_dice: 0.3795  decode.d4.loss_cls: 0.8110  decode.d4.loss_mask: 0.3777  decode.d4.loss_dice: 0.3928  decode.d5.loss_cls: 0.8214  decode.d5.loss_mask: 0.4009  decode.d5.loss_dice: 0.4216  decode.d6.loss_cls: 0.7685  decode.d6.loss_mask: 0.3396  decode.d6.loss_dice: 0.4047  decode.d7.loss_cls: 0.8057  decode.d7.loss_mask: 0.3300  decode.d7.loss_dice: 0.4316  decode.d8.loss_cls: 0.8046  decode.d8.loss_mask: 0.3171  decode.d8.loss_dice: 0.3667
08/06 03:03:20 - mmengine - INFO - Iter(train) [  5700/320000]  base_lr: 9.8396e-05 lr: 9.8396e-06  eta: 1 day, 18:46:16  time: 0.4892  data_time: 0.0102  memory: 5907  grad_norm: 180.5857  loss: 16.5158  decode.loss_cls: 0.7868  decode.loss_mask: 0.3025  decode.loss_dice: 0.4559  decode.d0.loss_cls: 1.7733  decode.d0.loss_mask: 0.3620  decode.d0.loss_dice: 0.4667  decode.d1.loss_cls: 1.0731  decode.d1.loss_mask: 0.2751  decode.d1.loss_dice: 0.3917  decode.d2.loss_cls: 0.8681  decode.d2.loss_mask: 0.2732  decode.d2.loss_dice: 0.3655  decode.d3.loss_cls: 0.8823  decode.d3.loss_mask: 0.2896  decode.d3.loss_dice: 0.3735  decode.d4.loss_cls: 0.8449  decode.d4.loss_mask: 0.3083  decode.d4.loss_dice: 0.3992  decode.d5.loss_cls: 0.8509  decode.d5.loss_mask: 0.2739  decode.d5.loss_dice: 0.3871  decode.d6.loss_cls: 0.7802  decode.d6.loss_mask: 0.2769  decode.d6.loss_dice: 0.3802  decode.d7.loss_cls: 0.8109  decode.d7.loss_mask: 0.3167  decode.d7.loss_dice: 0.4340  decode.d8.loss_cls: 0.7629  decode.d8.loss_mask: 0.3024  decode.d8.loss_dice: 0.4480
08/06 03:03:44 - mmengine - INFO - Iter(train) [  5750/320000]  base_lr: 9.8382e-05 lr: 9.8382e-06  eta: 1 day, 18:45:50  time: 0.4882  data_time: 0.0103  memory: 5892  grad_norm: 173.3674  loss: 12.7926  decode.loss_cls: 0.4393  decode.loss_mask: 0.4478  decode.loss_dice: 0.3445  decode.d0.loss_cls: 1.3416  decode.d0.loss_mask: 0.3699  decode.d0.loss_dice: 0.3355  decode.d1.loss_cls: 0.6732  decode.d1.loss_mask: 0.3445  decode.d1.loss_dice: 0.2957  decode.d2.loss_cls: 0.4691  decode.d2.loss_mask: 0.3321  decode.d2.loss_dice: 0.2953  decode.d3.loss_cls: 0.4465  decode.d3.loss_mask: 0.3329  decode.d3.loss_dice: 0.3048  decode.d4.loss_cls: 0.5002  decode.d4.loss_mask: 0.3683  decode.d4.loss_dice: 0.2983  decode.d5.loss_cls: 0.4494  decode.d5.loss_mask: 0.3662  decode.d5.loss_dice: 0.3220  decode.d6.loss_cls: 0.4918  decode.d6.loss_mask: 0.4026  decode.d6.loss_dice: 0.3354  decode.d7.loss_cls: 0.5268  decode.d7.loss_mask: 0.4076  decode.d7.loss_dice: 0.3257  decode.d8.loss_cls: 0.4634  decode.d8.loss_mask: 0.4392  decode.d8.loss_dice: 0.3234
08/06 03:04:09 - mmengine - INFO - Iter(train) [  5800/320000]  base_lr: 9.8368e-05 lr: 9.8368e-06  eta: 1 day, 18:45:25  time: 0.4904  data_time: 0.0104  memory: 5910  grad_norm: 189.3755  loss: 15.7713  decode.loss_cls: 0.6470  decode.loss_mask: 0.4283  decode.loss_dice: 0.4310  decode.d0.loss_cls: 1.5535  decode.d0.loss_mask: 0.4654  decode.d0.loss_dice: 0.5123  decode.d1.loss_cls: 0.8091  decode.d1.loss_mask: 0.3831  decode.d1.loss_dice: 0.4334  decode.d2.loss_cls: 0.6000  decode.d2.loss_mask: 0.3809  decode.d2.loss_dice: 0.4401  decode.d3.loss_cls: 0.5861  decode.d3.loss_mask: 0.4009  decode.d3.loss_dice: 0.4247  decode.d4.loss_cls: 0.6347  decode.d4.loss_mask: 0.3996  decode.d4.loss_dice: 0.4208  decode.d5.loss_cls: 0.6236  decode.d5.loss_mask: 0.3917  decode.d5.loss_dice: 0.4072  decode.d6.loss_cls: 0.5825  decode.d6.loss_mask: 0.4108  decode.d6.loss_dice: 0.4278  decode.d7.loss_cls: 0.6218  decode.d7.loss_mask: 0.4128  decode.d7.loss_dice: 0.4213  decode.d8.loss_cls: 0.6731  decode.d8.loss_mask: 0.4253  decode.d8.loss_dice: 0.4227
08/06 03:04:33 - mmengine - INFO - Iter(train) [  5850/320000]  base_lr: 9.8353e-05 lr: 9.8353e-06  eta: 1 day, 18:45:04  time: 0.4903  data_time: 0.0100  memory: 5892  grad_norm: 188.8806  loss: 18.6416  decode.loss_cls: 1.0059  decode.loss_mask: 0.3041  decode.loss_dice: 0.4488  decode.d0.loss_cls: 1.7776  decode.d0.loss_mask: 0.3525  decode.d0.loss_dice: 0.5196  decode.d1.loss_cls: 1.2048  decode.d1.loss_mask: 0.2904  decode.d1.loss_dice: 0.4244  decode.d2.loss_cls: 1.0625  decode.d2.loss_mask: 0.3010  decode.d2.loss_dice: 0.4579  decode.d3.loss_cls: 0.8878  decode.d3.loss_mask: 0.3182  decode.d3.loss_dice: 0.4551  decode.d4.loss_cls: 1.0509  decode.d4.loss_mask: 0.3119  decode.d4.loss_dice: 0.4435  decode.d5.loss_cls: 1.0851  decode.d5.loss_mask: 0.2954  decode.d5.loss_dice: 0.4162  decode.d6.loss_cls: 1.0041  decode.d6.loss_mask: 0.2870  decode.d6.loss_dice: 0.4215  decode.d7.loss_cls: 1.0246  decode.d7.loss_mask: 0.3056  decode.d7.loss_dice: 0.4352  decode.d8.loss_cls: 0.9959  decode.d8.loss_mask: 0.3110  decode.d8.loss_dice: 0.4430
08/06 03:04:58 - mmengine - INFO - Iter(train) [  5900/320000]  base_lr: 9.8339e-05 lr: 9.8339e-06  eta: 1 day, 18:44:39  time: 0.4899  data_time: 0.0102  memory: 5908  grad_norm: 145.2628  loss: 13.7920  decode.loss_cls: 0.5581  decode.loss_mask: 0.3455  decode.loss_dice: 0.3188  decode.d0.loss_cls: 1.5155  decode.d0.loss_mask: 0.3343  decode.d0.loss_dice: 0.3626  decode.d1.loss_cls: 0.7299  decode.d1.loss_mask: 0.3443  decode.d1.loss_dice: 0.3421  decode.d2.loss_cls: 0.5483  decode.d2.loss_mask: 0.3532  decode.d2.loss_dice: 0.3355  decode.d3.loss_cls: 0.6182  decode.d3.loss_mask: 0.3384  decode.d3.loss_dice: 0.3106  decode.d4.loss_cls: 0.6734  decode.d4.loss_mask: 0.3375  decode.d4.loss_dice: 0.3113  decode.d5.loss_cls: 0.6258  decode.d5.loss_mask: 0.3420  decode.d5.loss_dice: 0.3351  decode.d6.loss_cls: 0.6111  decode.d6.loss_mask: 0.3389  decode.d6.loss_dice: 0.3183  decode.d7.loss_cls: 0.6193  decode.d7.loss_mask: 0.3473  decode.d7.loss_dice: 0.3186  decode.d8.loss_cls: 0.5813  decode.d8.loss_mask: 0.3485  decode.d8.loss_dice: 0.3280
08/06 03:05:22 - mmengine - INFO - Iter(train) [  5950/320000]  base_lr: 9.8325e-05 lr: 9.8325e-06  eta: 1 day, 18:44:15  time: 0.4903  data_time: 0.0102  memory: 5891  grad_norm: 105.4127  loss: 13.4848  decode.loss_cls: 0.5984  decode.loss_mask: 0.2712  decode.loss_dice: 0.3095  decode.d0.loss_cls: 1.7220  decode.d0.loss_mask: 0.2767  decode.d0.loss_dice: 0.3708  decode.d1.loss_cls: 0.8406  decode.d1.loss_mask: 0.2797  decode.d1.loss_dice: 0.3297  decode.d2.loss_cls: 0.6219  decode.d2.loss_mask: 0.2805  decode.d2.loss_dice: 0.3046  decode.d3.loss_cls: 0.5956  decode.d3.loss_mask: 0.2814  decode.d3.loss_dice: 0.3068  decode.d4.loss_cls: 0.7105  decode.d4.loss_mask: 0.2915  decode.d4.loss_dice: 0.3206  decode.d5.loss_cls: 0.6734  decode.d5.loss_mask: 0.2766  decode.d5.loss_dice: 0.3072  decode.d6.loss_cls: 0.5856  decode.d6.loss_mask: 0.2739  decode.d6.loss_dice: 0.3048  decode.d7.loss_cls: 0.5671  decode.d7.loss_mask: 0.2728  decode.d7.loss_dice: 0.3175  decode.d8.loss_cls: 0.5946  decode.d8.loss_mask: 0.2749  decode.d8.loss_dice: 0.3244
08/06 03:05:47 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 03:05:47 - mmengine - INFO - Iter(train) [  6000/320000]  base_lr: 9.8311e-05 lr: 9.8311e-06  eta: 1 day, 18:43:50  time: 0.4902  data_time: 0.0101  memory: 5907  grad_norm: 199.8696  loss: 13.9089  decode.loss_cls: 0.6440  decode.loss_mask: 0.2651  decode.loss_dice: 0.3461  decode.d0.loss_cls: 1.6699  decode.d0.loss_mask: 0.2765  decode.d0.loss_dice: 0.3665  decode.d1.loss_cls: 0.8030  decode.d1.loss_mask: 0.2790  decode.d1.loss_dice: 0.3211  decode.d2.loss_cls: 0.6414  decode.d2.loss_mask: 0.2630  decode.d2.loss_dice: 0.3108  decode.d3.loss_cls: 0.6822  decode.d3.loss_mask: 0.2656  decode.d3.loss_dice: 0.3292  decode.d4.loss_cls: 0.6390  decode.d4.loss_mask: 0.2745  decode.d4.loss_dice: 0.3104  decode.d5.loss_cls: 0.6549  decode.d5.loss_mask: 0.2801  decode.d5.loss_dice: 0.3231  decode.d6.loss_cls: 0.6883  decode.d6.loss_mask: 0.2752  decode.d6.loss_dice: 0.3451  decode.d7.loss_cls: 0.7369  decode.d7.loss_mask: 0.2869  decode.d7.loss_dice: 0.3538  decode.d8.loss_cls: 0.6381  decode.d8.loss_mask: 0.2821  decode.d8.loss_dice: 0.3570
08/06 03:06:11 - mmengine - INFO - Iter(train) [  6050/320000]  base_lr: 9.8297e-05 lr: 9.8297e-06  eta: 1 day, 18:43:25  time: 0.4898  data_time: 0.0101  memory: 5891  grad_norm: 186.5623  loss: 15.0276  decode.loss_cls: 0.6410  decode.loss_mask: 0.3333  decode.loss_dice: 0.4006  decode.d0.loss_cls: 1.4675  decode.d0.loss_mask: 0.3163  decode.d0.loss_dice: 0.3755  decode.d1.loss_cls: 0.8791  decode.d1.loss_mask: 0.3636  decode.d1.loss_dice: 0.3542  decode.d2.loss_cls: 0.6871  decode.d2.loss_mask: 0.3062  decode.d2.loss_dice: 0.3447  decode.d3.loss_cls: 0.6423  decode.d3.loss_mask: 0.2832  decode.d3.loss_dice: 0.3237  decode.d4.loss_cls: 0.5971  decode.d4.loss_mask: 0.3979  decode.d4.loss_dice: 0.3639  decode.d5.loss_cls: 0.5608  decode.d5.loss_mask: 0.4759  decode.d5.loss_dice: 0.3501  decode.d6.loss_cls: 0.6498  decode.d6.loss_mask: 0.4599  decode.d6.loss_dice: 0.3618  decode.d7.loss_cls: 0.6786  decode.d7.loss_mask: 0.4476  decode.d7.loss_dice: 0.3649  decode.d8.loss_cls: 0.7300  decode.d8.loss_mask: 0.5035  decode.d8.loss_dice: 0.3676
08/06 03:06:36 - mmengine - INFO - Iter(train) [  6100/320000]  base_lr: 9.8283e-05 lr: 9.8283e-06  eta: 1 day, 18:43:01  time: 0.4912  data_time: 0.0105  memory: 5877  grad_norm: 199.2255  loss: 15.9399  decode.loss_cls: 0.7783  decode.loss_mask: 0.3336  decode.loss_dice: 0.4412  decode.d0.loss_cls: 1.4695  decode.d0.loss_mask: 0.3526  decode.d0.loss_dice: 0.5320  decode.d1.loss_cls: 0.9179  decode.d1.loss_mask: 0.3547  decode.d1.loss_dice: 0.4589  decode.d2.loss_cls: 0.7635  decode.d2.loss_mask: 0.3379  decode.d2.loss_dice: 0.4396  decode.d3.loss_cls: 0.5995  decode.d3.loss_mask: 0.3643  decode.d3.loss_dice: 0.4792  decode.d4.loss_cls: 0.6660  decode.d4.loss_mask: 0.3416  decode.d4.loss_dice: 0.4536  decode.d5.loss_cls: 0.6626  decode.d5.loss_mask: 0.3363  decode.d5.loss_dice: 0.4470  decode.d6.loss_cls: 0.6685  decode.d6.loss_mask: 0.3502  decode.d6.loss_dice: 0.4805  decode.d7.loss_cls: 0.6670  decode.d7.loss_mask: 0.3365  decode.d7.loss_dice: 0.4455  decode.d8.loss_cls: 0.7046  decode.d8.loss_mask: 0.3388  decode.d8.loss_dice: 0.4183
08/06 03:07:00 - mmengine - INFO - Iter(train) [  6150/320000]  base_lr: 9.8269e-05 lr: 9.8269e-06  eta: 1 day, 18:42:44  time: 0.4902  data_time: 0.0103  memory: 5875  grad_norm: 282.5012  loss: 17.7189  decode.loss_cls: 0.8671  decode.loss_mask: 0.4482  decode.loss_dice: 0.4279  decode.d0.loss_cls: 1.7270  decode.d0.loss_mask: 0.4065  decode.d0.loss_dice: 0.4482  decode.d1.loss_cls: 0.9266  decode.d1.loss_mask: 0.5120  decode.d1.loss_dice: 0.4668  decode.d2.loss_cls: 0.8369  decode.d2.loss_mask: 0.4125  decode.d2.loss_dice: 0.4098  decode.d3.loss_cls: 0.8677  decode.d3.loss_mask: 0.3781  decode.d3.loss_dice: 0.4214  decode.d4.loss_cls: 0.8144  decode.d4.loss_mask: 0.4008  decode.d4.loss_dice: 0.4026  decode.d5.loss_cls: 0.8063  decode.d5.loss_mask: 0.4050  decode.d5.loss_dice: 0.4179  decode.d6.loss_cls: 0.7710  decode.d6.loss_mask: 0.3767  decode.d6.loss_dice: 0.4121  decode.d7.loss_cls: 0.7916  decode.d7.loss_mask: 0.3556  decode.d7.loss_dice: 0.4354  decode.d8.loss_cls: 0.8923  decode.d8.loss_mask: 0.4430  decode.d8.loss_dice: 0.4375
08/06 03:07:25 - mmengine - INFO - Iter(train) [  6200/320000]  base_lr: 9.8255e-05 lr: 9.8255e-06  eta: 1 day, 18:42:19  time: 0.4896  data_time: 0.0101  memory: 5892  grad_norm: 388.7559  loss: 16.6966  decode.loss_cls: 0.7743  decode.loss_mask: 0.3787  decode.loss_dice: 0.4700  decode.d0.loss_cls: 1.7441  decode.d0.loss_mask: 0.3647  decode.d0.loss_dice: 0.4352  decode.d1.loss_cls: 0.9345  decode.d1.loss_mask: 0.3721  decode.d1.loss_dice: 0.4076  decode.d2.loss_cls: 0.8272  decode.d2.loss_mask: 0.3497  decode.d2.loss_dice: 0.3737  decode.d3.loss_cls: 0.7147  decode.d3.loss_mask: 0.3523  decode.d3.loss_dice: 0.3812  decode.d4.loss_cls: 0.7572  decode.d4.loss_mask: 0.3808  decode.d4.loss_dice: 0.4194  decode.d5.loss_cls: 0.6917  decode.d5.loss_mask: 0.3634  decode.d5.loss_dice: 0.4224  decode.d6.loss_cls: 0.6635  decode.d6.loss_mask: 0.3758  decode.d6.loss_dice: 0.4474  decode.d7.loss_cls: 0.6881  decode.d7.loss_mask: 0.4449  decode.d7.loss_dice: 0.5092  decode.d8.loss_cls: 0.8115  decode.d8.loss_mask: 0.3813  decode.d8.loss_dice: 0.4600
08/06 03:07:49 - mmengine - INFO - Iter(train) [  6250/320000]  base_lr: 9.8241e-05 lr: 9.8241e-06  eta: 1 day, 18:41:55  time: 0.4909  data_time: 0.0103  memory: 5910  grad_norm: 137.4566  loss: 12.2888  decode.loss_cls: 0.5049  decode.loss_mask: 0.2598  decode.loss_dice: 0.2887  decode.d0.loss_cls: 1.5997  decode.d0.loss_mask: 0.2555  decode.d0.loss_dice: 0.3172  decode.d1.loss_cls: 0.7625  decode.d1.loss_mask: 0.2650  decode.d1.loss_dice: 0.2992  decode.d2.loss_cls: 0.5778  decode.d2.loss_mask: 0.2562  decode.d2.loss_dice: 0.2969  decode.d3.loss_cls: 0.5459  decode.d3.loss_mask: 0.2611  decode.d3.loss_dice: 0.3134  decode.d4.loss_cls: 0.5780  decode.d4.loss_mask: 0.2622  decode.d4.loss_dice: 0.3111  decode.d5.loss_cls: 0.5051  decode.d5.loss_mask: 0.2612  decode.d5.loss_dice: 0.2947  decode.d6.loss_cls: 0.5025  decode.d6.loss_mask: 0.2566  decode.d6.loss_dice: 0.2877  decode.d7.loss_cls: 0.5470  decode.d7.loss_mask: 0.2587  decode.d7.loss_dice: 0.2880  decode.d8.loss_cls: 0.5608  decode.d8.loss_mask: 0.2614  decode.d8.loss_dice: 0.3100
08/06 03:08:14 - mmengine - INFO - Iter(train) [  6300/320000]  base_lr: 9.8227e-05 lr: 9.8227e-06  eta: 1 day, 18:41:30  time: 0.4903  data_time: 0.0104  memory: 5892  grad_norm: 179.3900  loss: 15.6589  decode.loss_cls: 0.7488  decode.loss_mask: 0.3541  decode.loss_dice: 0.3873  decode.d0.loss_cls: 1.7329  decode.d0.loss_mask: 0.3304  decode.d0.loss_dice: 0.4475  decode.d1.loss_cls: 0.7593  decode.d1.loss_mask: 0.3315  decode.d1.loss_dice: 0.4480  decode.d2.loss_cls: 0.6530  decode.d2.loss_mask: 0.3534  decode.d2.loss_dice: 0.3900  decode.d3.loss_cls: 0.6142  decode.d3.loss_mask: 0.3571  decode.d3.loss_dice: 0.3940  decode.d4.loss_cls: 0.6618  decode.d4.loss_mask: 0.3655  decode.d4.loss_dice: 0.3932  decode.d5.loss_cls: 0.7121  decode.d5.loss_mask: 0.3499  decode.d5.loss_dice: 0.4060  decode.d6.loss_cls: 0.7204  decode.d6.loss_mask: 0.3465  decode.d6.loss_dice: 0.3909  decode.d7.loss_cls: 0.7087  decode.d7.loss_mask: 0.3626  decode.d7.loss_dice: 0.4159  decode.d8.loss_cls: 0.7729  decode.d8.loss_mask: 0.3565  decode.d8.loss_dice: 0.3943
08/06 03:08:38 - mmengine - INFO - Iter(train) [  6350/320000]  base_lr: 9.8213e-05 lr: 9.8213e-06  eta: 1 day, 18:41:06  time: 0.4894  data_time: 0.0103  memory: 5891  grad_norm: 288.1376  loss: 16.2071  decode.loss_cls: 0.6674  decode.loss_mask: 0.3692  decode.loss_dice: 0.3937  decode.d0.loss_cls: 1.7198  decode.d0.loss_mask: 0.4088  decode.d0.loss_dice: 0.4342  decode.d1.loss_cls: 0.9692  decode.d1.loss_mask: 0.3684  decode.d1.loss_dice: 0.3964  decode.d2.loss_cls: 0.6372  decode.d2.loss_mask: 0.4292  decode.d2.loss_dice: 0.3995  decode.d3.loss_cls: 0.6463  decode.d3.loss_mask: 0.4298  decode.d3.loss_dice: 0.3660  decode.d4.loss_cls: 0.6924  decode.d4.loss_mask: 0.3849  decode.d4.loss_dice: 0.3826  decode.d5.loss_cls: 0.8077  decode.d5.loss_mask: 0.3724  decode.d5.loss_dice: 0.4084  decode.d6.loss_cls: 0.7253  decode.d6.loss_mask: 0.4044  decode.d6.loss_dice: 0.4080  decode.d7.loss_cls: 0.7231  decode.d7.loss_mask: 0.3720  decode.d7.loss_dice: 0.3877  decode.d8.loss_cls: 0.7011  decode.d8.loss_mask: 0.3986  decode.d8.loss_dice: 0.4034
08/06 03:09:03 - mmengine - INFO - Iter(train) [  6400/320000]  base_lr: 9.8198e-05 lr: 9.8198e-06  eta: 1 day, 18:40:42  time: 0.4895  data_time: 0.0102  memory: 5910  grad_norm: 156.0204  loss: 12.6339  decode.loss_cls: 0.5462  decode.loss_mask: 0.3070  decode.loss_dice: 0.3724  decode.d0.loss_cls: 1.3163  decode.d0.loss_mask: 0.3280  decode.d0.loss_dice: 0.4268  decode.d1.loss_cls: 0.6734  decode.d1.loss_mask: 0.3022  decode.d1.loss_dice: 0.3498  decode.d2.loss_cls: 0.4651  decode.d2.loss_mask: 0.2836  decode.d2.loss_dice: 0.3480  decode.d3.loss_cls: 0.4862  decode.d3.loss_mask: 0.3067  decode.d3.loss_dice: 0.3853  decode.d4.loss_cls: 0.5324  decode.d4.loss_mask: 0.2967  decode.d4.loss_dice: 0.3617  decode.d5.loss_cls: 0.5174  decode.d5.loss_mask: 0.2959  decode.d5.loss_dice: 0.3614  decode.d6.loss_cls: 0.4658  decode.d6.loss_mask: 0.2872  decode.d6.loss_dice: 0.3533  decode.d7.loss_cls: 0.4504  decode.d7.loss_mask: 0.2914  decode.d7.loss_dice: 0.3580  decode.d8.loss_cls: 0.4717  decode.d8.loss_mask: 0.2982  decode.d8.loss_dice: 0.3952
08/06 03:09:27 - mmengine - INFO - Iter(train) [  6450/320000]  base_lr: 9.8184e-05 lr: 9.8184e-06  eta: 1 day, 18:40:17  time: 0.4900  data_time: 0.0103  memory: 5907  grad_norm: 145.8460  loss: 13.9070  decode.loss_cls: 0.5601  decode.loss_mask: 0.3442  decode.loss_dice: 0.3345  decode.d0.loss_cls: 1.4002  decode.d0.loss_mask: 0.3498  decode.d0.loss_dice: 0.4109  decode.d1.loss_cls: 0.6789  decode.d1.loss_mask: 0.3658  decode.d1.loss_dice: 0.3626  decode.d2.loss_cls: 0.5708  decode.d2.loss_mask: 0.3739  decode.d2.loss_dice: 0.3415  decode.d3.loss_cls: 0.5753  decode.d3.loss_mask: 0.3526  decode.d3.loss_dice: 0.3339  decode.d4.loss_cls: 0.5790  decode.d4.loss_mask: 0.3666  decode.d4.loss_dice: 0.3777  decode.d5.loss_cls: 0.6398  decode.d5.loss_mask: 0.3570  decode.d5.loss_dice: 0.3491  decode.d6.loss_cls: 0.5806  decode.d6.loss_mask: 0.3511  decode.d6.loss_dice: 0.3445  decode.d7.loss_cls: 0.6157  decode.d7.loss_mask: 0.3398  decode.d7.loss_dice: 0.3303  decode.d8.loss_cls: 0.6544  decode.d8.loss_mask: 0.3366  decode.d8.loss_dice: 0.3299
08/06 03:09:52 - mmengine - INFO - Iter(train) [  6500/320000]  base_lr: 9.8170e-05 lr: 9.8170e-06  eta: 1 day, 18:39:53  time: 0.4907  data_time: 0.0101  memory: 5875  grad_norm: 236.0399  loss: 14.9793  decode.loss_cls: 0.6538  decode.loss_mask: 0.2958  decode.loss_dice: 0.3697  decode.d0.loss_cls: 1.6756  decode.d0.loss_mask: 0.2902  decode.d0.loss_dice: 0.4497  decode.d1.loss_cls: 0.9813  decode.d1.loss_mask: 0.2850  decode.d1.loss_dice: 0.4061  decode.d2.loss_cls: 0.8139  decode.d2.loss_mask: 0.3263  decode.d2.loss_dice: 0.4038  decode.d3.loss_cls: 0.7140  decode.d3.loss_mask: 0.3063  decode.d3.loss_dice: 0.3564  decode.d4.loss_cls: 0.6990  decode.d4.loss_mask: 0.2927  decode.d4.loss_dice: 0.3734  decode.d5.loss_cls: 0.6027  decode.d5.loss_mask: 0.3094  decode.d5.loss_dice: 0.3807  decode.d6.loss_cls: 0.6408  decode.d6.loss_mask: 0.3014  decode.d6.loss_dice: 0.3528  decode.d7.loss_cls: 0.6782  decode.d7.loss_mask: 0.2830  decode.d7.loss_dice: 0.3659  decode.d8.loss_cls: 0.6839  decode.d8.loss_mask: 0.3139  decode.d8.loss_dice: 0.3738
08/06 03:10:16 - mmengine - INFO - Iter(train) [  6550/320000]  base_lr: 9.8156e-05 lr: 9.8156e-06  eta: 1 day, 18:39:30  time: 0.4910  data_time: 0.0101  memory: 5929  grad_norm: 193.5854  loss: 10.7738  decode.loss_cls: 0.4602  decode.loss_mask: 0.2317  decode.loss_dice: 0.2593  decode.d0.loss_cls: 1.4225  decode.d0.loss_mask: 0.2490  decode.d0.loss_dice: 0.3110  decode.d1.loss_cls: 0.5837  decode.d1.loss_mask: 0.2603  decode.d1.loss_dice: 0.3194  decode.d2.loss_cls: 0.4520  decode.d2.loss_mask: 0.2470  decode.d2.loss_dice: 0.3005  decode.d3.loss_cls: 0.3874  decode.d3.loss_mask: 0.2496  decode.d3.loss_dice: 0.2843  decode.d4.loss_cls: 0.4487  decode.d4.loss_mask: 0.2366  decode.d4.loss_dice: 0.2819  decode.d5.loss_cls: 0.4570  decode.d5.loss_mask: 0.2324  decode.d5.loss_dice: 0.2713  decode.d6.loss_cls: 0.4439  decode.d6.loss_mask: 0.2302  decode.d6.loss_dice: 0.2721  decode.d7.loss_cls: 0.4217  decode.d7.loss_mask: 0.2353  decode.d7.loss_dice: 0.2613  decode.d8.loss_cls: 0.4223  decode.d8.loss_mask: 0.2439  decode.d8.loss_dice: 0.2970
08/06 03:10:41 - mmengine - INFO - Iter(train) [  6600/320000]  base_lr: 9.8142e-05 lr: 9.8142e-06  eta: 1 day, 18:39:07  time: 0.4907  data_time: 0.0103  memory: 5893  grad_norm: 195.2357  loss: 15.0898  decode.loss_cls: 0.6685  decode.loss_mask: 0.3600  decode.loss_dice: 0.3607  decode.d0.loss_cls: 1.7691  decode.d0.loss_mask: 0.3316  decode.d0.loss_dice: 0.4607  decode.d1.loss_cls: 0.8681  decode.d1.loss_mask: 0.3319  decode.d1.loss_dice: 0.3706  decode.d2.loss_cls: 0.5849  decode.d2.loss_mask: 0.3298  decode.d2.loss_dice: 0.3756  decode.d3.loss_cls: 0.6847  decode.d3.loss_mask: 0.3064  decode.d3.loss_dice: 0.3708  decode.d4.loss_cls: 0.6303  decode.d4.loss_mask: 0.3427  decode.d4.loss_dice: 0.3848  decode.d5.loss_cls: 0.6347  decode.d5.loss_mask: 0.3329  decode.d5.loss_dice: 0.3869  decode.d6.loss_cls: 0.6239  decode.d6.loss_mask: 0.3546  decode.d6.loss_dice: 0.3829  decode.d7.loss_cls: 0.6938  decode.d7.loss_mask: 0.3449  decode.d7.loss_dice: 0.3680  decode.d8.loss_cls: 0.7156  decode.d8.loss_mask: 0.3417  decode.d8.loss_dice: 0.3785
08/06 03:11:05 - mmengine - INFO - Iter(train) [  6650/320000]  base_lr: 9.8128e-05 lr: 9.8128e-06  eta: 1 day, 18:38:43  time: 0.4895  data_time: 0.0103  memory: 5926  grad_norm: 189.5407  loss: 13.3445  decode.loss_cls: 0.5748  decode.loss_mask: 0.3205  decode.loss_dice: 0.3375  decode.d0.loss_cls: 1.4141  decode.d0.loss_mask: 0.3368  decode.d0.loss_dice: 0.4146  decode.d1.loss_cls: 0.6383  decode.d1.loss_mask: 0.3375  decode.d1.loss_dice: 0.3739  decode.d2.loss_cls: 0.4759  decode.d2.loss_mask: 0.3373  decode.d2.loss_dice: 0.3706  decode.d3.loss_cls: 0.5151  decode.d3.loss_mask: 0.3327  decode.d3.loss_dice: 0.3724  decode.d4.loss_cls: 0.5797  decode.d4.loss_mask: 0.3239  decode.d4.loss_dice: 0.3712  decode.d5.loss_cls: 0.5019  decode.d5.loss_mask: 0.3272  decode.d5.loss_dice: 0.3808  decode.d6.loss_cls: 0.4336  decode.d6.loss_mask: 0.3698  decode.d6.loss_dice: 0.3927  decode.d7.loss_cls: 0.5412  decode.d7.loss_mask: 0.3674  decode.d7.loss_dice: 0.4069  decode.d8.loss_cls: 0.4700  decode.d8.loss_mask: 0.3520  decode.d8.loss_dice: 0.3743
08/06 03:11:30 - mmengine - INFO - Iter(train) [  6700/320000]  base_lr: 9.8114e-05 lr: 9.8114e-06  eta: 1 day, 18:38:19  time: 0.4896  data_time: 0.0102  memory: 5926  grad_norm: 145.3046  loss: 12.6334  decode.loss_cls: 0.3969  decode.loss_mask: 0.3454  decode.loss_dice: 0.3917  decode.d0.loss_cls: 1.4034  decode.d0.loss_mask: 0.3337  decode.d0.loss_dice: 0.3887  decode.d1.loss_cls: 0.5210  decode.d1.loss_mask: 0.3583  decode.d1.loss_dice: 0.3762  decode.d2.loss_cls: 0.4751  decode.d2.loss_mask: 0.3367  decode.d2.loss_dice: 0.3626  decode.d3.loss_cls: 0.5592  decode.d3.loss_mask: 0.3295  decode.d3.loss_dice: 0.3516  decode.d4.loss_cls: 0.4535  decode.d4.loss_mask: 0.3311  decode.d4.loss_dice: 0.3816  decode.d5.loss_cls: 0.4271  decode.d5.loss_mask: 0.3317  decode.d5.loss_dice: 0.3690  decode.d6.loss_cls: 0.3682  decode.d6.loss_mask: 0.3527  decode.d6.loss_dice: 0.3839  decode.d7.loss_cls: 0.3549  decode.d7.loss_mask: 0.3522  decode.d7.loss_dice: 0.3757  decode.d8.loss_cls: 0.4875  decode.d8.loss_mask: 0.3422  decode.d8.loss_dice: 0.3921
08/06 03:11:54 - mmengine - INFO - Iter(train) [  6750/320000]  base_lr: 9.8100e-05 lr: 9.8100e-06  eta: 1 day, 18:38:00  time: 0.4905  data_time: 0.0103  memory: 5907  grad_norm: 245.6760  loss: 15.7460  decode.loss_cls: 0.6438  decode.loss_mask: 0.3364  decode.loss_dice: 0.4779  decode.d0.loss_cls: 1.6556  decode.d0.loss_mask: 0.3486  decode.d0.loss_dice: 0.5532  decode.d1.loss_cls: 0.8713  decode.d1.loss_mask: 0.3409  decode.d1.loss_dice: 0.4549  decode.d2.loss_cls: 0.6300  decode.d2.loss_mask: 0.3361  decode.d2.loss_dice: 0.4409  decode.d3.loss_cls: 0.5932  decode.d3.loss_mask: 0.3241  decode.d3.loss_dice: 0.4423  decode.d4.loss_cls: 0.5669  decode.d4.loss_mask: 0.3477  decode.d4.loss_dice: 0.4473  decode.d5.loss_cls: 0.7062  decode.d5.loss_mask: 0.3524  decode.d5.loss_dice: 0.4726  decode.d6.loss_cls: 0.6515  decode.d6.loss_mask: 0.3431  decode.d6.loss_dice: 0.4758  decode.d7.loss_cls: 0.6587  decode.d7.loss_mask: 0.3262  decode.d7.loss_dice: 0.4517  decode.d8.loss_cls: 0.6431  decode.d8.loss_mask: 0.3486  decode.d8.loss_dice: 0.5049
08/06 03:12:19 - mmengine - INFO - Iter(train) [  6800/320000]  base_lr: 9.8086e-05 lr: 9.8086e-06  eta: 1 day, 18:37:35  time: 0.4893  data_time: 0.0104  memory: 5908  grad_norm: 168.1637  loss: 14.0295  decode.loss_cls: 0.5022  decode.loss_mask: 0.4501  decode.loss_dice: 0.3507  decode.d0.loss_cls: 1.4966  decode.d0.loss_mask: 0.4609  decode.d0.loss_dice: 0.3947  decode.d1.loss_cls: 0.6151  decode.d1.loss_mask: 0.4546  decode.d1.loss_dice: 0.3687  decode.d2.loss_cls: 0.5434  decode.d2.loss_mask: 0.4331  decode.d2.loss_dice: 0.3367  decode.d3.loss_cls: 0.4794  decode.d3.loss_mask: 0.4406  decode.d3.loss_dice: 0.3519  decode.d4.loss_cls: 0.5154  decode.d4.loss_mask: 0.4422  decode.d4.loss_dice: 0.3289  decode.d5.loss_cls: 0.4620  decode.d5.loss_mask: 0.4391  decode.d5.loss_dice: 0.3303  decode.d6.loss_cls: 0.5050  decode.d6.loss_mask: 0.4349  decode.d6.loss_dice: 0.3421  decode.d7.loss_cls: 0.4858  decode.d7.loss_mask: 0.4313  decode.d7.loss_dice: 0.3397  decode.d8.loss_cls: 0.5065  decode.d8.loss_mask: 0.4407  decode.d8.loss_dice: 0.3468
08/06 03:12:43 - mmengine - INFO - Iter(train) [  6850/320000]  base_lr: 9.8072e-05 lr: 9.8072e-06  eta: 1 day, 18:37:11  time: 0.4894  data_time: 0.0103  memory: 5892  grad_norm: 280.4967  loss: 14.5356  decode.loss_cls: 0.5110  decode.loss_mask: 0.3952  decode.loss_dice: 0.3775  decode.d0.loss_cls: 1.5458  decode.d0.loss_mask: 0.4665  decode.d0.loss_dice: 0.4533  decode.d1.loss_cls: 0.6839  decode.d1.loss_mask: 0.3991  decode.d1.loss_dice: 0.3740  decode.d2.loss_cls: 0.5600  decode.d2.loss_mask: 0.3688  decode.d2.loss_dice: 0.3799  decode.d3.loss_cls: 0.5178  decode.d3.loss_mask: 0.3655  decode.d3.loss_dice: 0.3576  decode.d4.loss_cls: 0.5434  decode.d4.loss_mask: 0.3584  decode.d4.loss_dice: 0.3610  decode.d5.loss_cls: 0.5646  decode.d5.loss_mask: 0.4101  decode.d5.loss_dice: 0.4117  decode.d6.loss_cls: 0.5674  decode.d6.loss_mask: 0.3885  decode.d6.loss_dice: 0.4038  decode.d7.loss_cls: 0.5734  decode.d7.loss_mask: 0.3824  decode.d7.loss_dice: 0.4004  decode.d8.loss_cls: 0.6187  decode.d8.loss_mask: 0.3986  decode.d8.loss_dice: 0.3975
08/06 03:13:08 - mmengine - INFO - Iter(train) [  6900/320000]  base_lr: 9.8058e-05 lr: 9.8058e-06  eta: 1 day, 18:36:47  time: 0.4897  data_time: 0.0103  memory: 5907  grad_norm: 214.6954  loss: 15.1212  decode.loss_cls: 0.5968  decode.loss_mask: 0.3530  decode.loss_dice: 0.4255  decode.d0.loss_cls: 1.6504  decode.d0.loss_mask: 0.4272  decode.d0.loss_dice: 0.4810  decode.d1.loss_cls: 0.6491  decode.d1.loss_mask: 0.3143  decode.d1.loss_dice: 0.3985  decode.d2.loss_cls: 0.5833  decode.d2.loss_mask: 0.3616  decode.d2.loss_dice: 0.4308  decode.d3.loss_cls: 0.6216  decode.d3.loss_mask: 0.3323  decode.d3.loss_dice: 0.4203  decode.d4.loss_cls: 0.5904  decode.d4.loss_mask: 0.3120  decode.d4.loss_dice: 0.4223  decode.d5.loss_cls: 0.6387  decode.d5.loss_mask: 0.3295  decode.d5.loss_dice: 0.4246  decode.d6.loss_cls: 0.6348  decode.d6.loss_mask: 0.3734  decode.d6.loss_dice: 0.4445  decode.d7.loss_cls: 0.6445  decode.d7.loss_mask: 0.3684  decode.d7.loss_dice: 0.4290  decode.d8.loss_cls: 0.6943  decode.d8.loss_mask: 0.3442  decode.d8.loss_dice: 0.4250
08/06 03:13:32 - mmengine - INFO - Iter(train) [  6950/320000]  base_lr: 9.8043e-05 lr: 9.8043e-06  eta: 1 day, 18:36:22  time: 0.4895  data_time: 0.0104  memory: 5892  grad_norm: 224.7657  loss: 16.0634  decode.loss_cls: 0.5726  decode.loss_mask: 0.3866  decode.loss_dice: 0.5293  decode.d0.loss_cls: 1.5319  decode.d0.loss_mask: 0.3858  decode.d0.loss_dice: 0.5491  decode.d1.loss_cls: 0.7036  decode.d1.loss_mask: 0.3922  decode.d1.loss_dice: 0.5036  decode.d2.loss_cls: 0.6626  decode.d2.loss_mask: 0.3773  decode.d2.loss_dice: 0.4700  decode.d3.loss_cls: 0.6664  decode.d3.loss_mask: 0.3937  decode.d3.loss_dice: 0.5280  decode.d4.loss_cls: 0.6202  decode.d4.loss_mask: 0.3894  decode.d4.loss_dice: 0.4860  decode.d5.loss_cls: 0.6490  decode.d5.loss_mask: 0.3855  decode.d5.loss_dice: 0.4791  decode.d6.loss_cls: 0.5874  decode.d6.loss_mask: 0.3923  decode.d6.loss_dice: 0.4976  decode.d7.loss_cls: 0.6216  decode.d7.loss_mask: 0.3700  decode.d7.loss_dice: 0.4721  decode.d8.loss_cls: 0.6031  decode.d8.loss_mask: 0.3623  decode.d8.loss_dice: 0.4949
08/06 03:13:57 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 03:13:57 - mmengine - INFO - Iter(train) [  7000/320000]  base_lr: 9.8029e-05 lr: 9.8029e-06  eta: 1 day, 18:35:58  time: 0.4908  data_time: 0.0103  memory: 5908  grad_norm: 191.4843  loss: 15.3784  decode.loss_cls: 0.6698  decode.loss_mask: 0.3775  decode.loss_dice: 0.4019  decode.d0.loss_cls: 1.6373  decode.d0.loss_mask: 0.3804  decode.d0.loss_dice: 0.4444  decode.d1.loss_cls: 0.7355  decode.d1.loss_mask: 0.3977  decode.d1.loss_dice: 0.4276  decode.d2.loss_cls: 0.6219  decode.d2.loss_mask: 0.3616  decode.d2.loss_dice: 0.4007  decode.d3.loss_cls: 0.6612  decode.d3.loss_mask: 0.3638  decode.d3.loss_dice: 0.4156  decode.d4.loss_cls: 0.6567  decode.d4.loss_mask: 0.3715  decode.d4.loss_dice: 0.4018  decode.d5.loss_cls: 0.6453  decode.d5.loss_mask: 0.3655  decode.d5.loss_dice: 0.4092  decode.d6.loss_cls: 0.6007  decode.d6.loss_mask: 0.3597  decode.d6.loss_dice: 0.4330  decode.d7.loss_cls: 0.6394  decode.d7.loss_mask: 0.3680  decode.d7.loss_dice: 0.4077  decode.d8.loss_cls: 0.6495  decode.d8.loss_mask: 0.3610  decode.d8.loss_dice: 0.4124
08/06 03:14:21 - mmengine - INFO - Iter(train) [  7050/320000]  base_lr: 9.8015e-05 lr: 9.8015e-06  eta: 1 day, 18:35:34  time: 0.4891  data_time: 0.0103  memory: 5907  grad_norm: 154.7193  loss: 10.7780  decode.loss_cls: 0.3374  decode.loss_mask: 0.3009  decode.loss_dice: 0.3007  decode.d0.loss_cls: 1.3064  decode.d0.loss_mask: 0.3145  decode.d0.loss_dice: 0.3389  decode.d1.loss_cls: 0.4139  decode.d1.loss_mask: 0.3060  decode.d1.loss_dice: 0.3121  decode.d2.loss_cls: 0.3398  decode.d2.loss_mask: 0.2993  decode.d2.loss_dice: 0.2943  decode.d3.loss_cls: 0.3641  decode.d3.loss_mask: 0.3174  decode.d3.loss_dice: 0.3157  decode.d4.loss_cls: 0.3621  decode.d4.loss_mask: 0.3123  decode.d4.loss_dice: 0.3075  decode.d5.loss_cls: 0.3244  decode.d5.loss_mask: 0.3075  decode.d5.loss_dice: 0.3223  decode.d6.loss_cls: 0.3210  decode.d6.loss_mask: 0.3090  decode.d6.loss_dice: 0.3228  decode.d7.loss_cls: 0.3816  decode.d7.loss_mask: 0.3163  decode.d7.loss_dice: 0.3222  decode.d8.loss_cls: 0.3915  decode.d8.loss_mask: 0.2945  decode.d8.loss_dice: 0.3217
08/06 03:14:46 - mmengine - INFO - Iter(train) [  7100/320000]  base_lr: 9.8001e-05 lr: 9.8001e-06  eta: 1 day, 18:35:10  time: 0.4918  data_time: 0.0104  memory: 5908  grad_norm: 234.8767  loss: 15.5790  decode.loss_cls: 0.7450  decode.loss_mask: 0.3365  decode.loss_dice: 0.4031  decode.d0.loss_cls: 1.9003  decode.d0.loss_mask: 0.3377  decode.d0.loss_dice: 0.4262  decode.d1.loss_cls: 0.8630  decode.d1.loss_mask: 0.3238  decode.d1.loss_dice: 0.3794  decode.d2.loss_cls: 0.7262  decode.d2.loss_mask: 0.3272  decode.d2.loss_dice: 0.3812  decode.d3.loss_cls: 0.7212  decode.d3.loss_mask: 0.3658  decode.d3.loss_dice: 0.3822  decode.d4.loss_cls: 0.6578  decode.d4.loss_mask: 0.3498  decode.d4.loss_dice: 0.3703  decode.d5.loss_cls: 0.7270  decode.d5.loss_mask: 0.3392  decode.d5.loss_dice: 0.3617  decode.d6.loss_cls: 0.6123  decode.d6.loss_mask: 0.3464  decode.d6.loss_dice: 0.3825  decode.d7.loss_cls: 0.6791  decode.d7.loss_mask: 0.3464  decode.d7.loss_dice: 0.3714  decode.d8.loss_cls: 0.6919  decode.d8.loss_mask: 0.3352  decode.d8.loss_dice: 0.3893
08/06 03:15:10 - mmengine - INFO - Iter(train) [  7150/320000]  base_lr: 9.7987e-05 lr: 9.7987e-06  eta: 1 day, 18:34:47  time: 0.4896  data_time: 0.0103  memory: 5908  grad_norm: 293.9490  loss: 14.8237  decode.loss_cls: 0.5785  decode.loss_mask: 0.3436  decode.loss_dice: 0.4019  decode.d0.loss_cls: 1.4968  decode.d0.loss_mask: 0.3358  decode.d0.loss_dice: 0.4580  decode.d1.loss_cls: 0.7128  decode.d1.loss_mask: 0.3790  decode.d1.loss_dice: 0.4284  decode.d2.loss_cls: 0.5643  decode.d2.loss_mask: 0.3623  decode.d2.loss_dice: 0.4493  decode.d3.loss_cls: 0.6615  decode.d3.loss_mask: 0.3314  decode.d3.loss_dice: 0.4064  decode.d4.loss_cls: 0.6475  decode.d4.loss_mask: 0.3402  decode.d4.loss_dice: 0.4173  decode.d5.loss_cls: 0.6166  decode.d5.loss_mask: 0.3370  decode.d5.loss_dice: 0.4442  decode.d6.loss_cls: 0.5999  decode.d6.loss_mask: 0.3335  decode.d6.loss_dice: 0.4332  decode.d7.loss_cls: 0.6005  decode.d7.loss_mask: 0.3287  decode.d7.loss_dice: 0.4086  decode.d8.loss_cls: 0.6460  decode.d8.loss_mask: 0.3342  decode.d8.loss_dice: 0.4265
08/06 03:15:35 - mmengine - INFO - Iter(train) [  7200/320000]  base_lr: 9.7973e-05 lr: 9.7973e-06  eta: 1 day, 18:34:24  time: 0.4908  data_time: 0.0102  memory: 5888  grad_norm: 210.1869  loss: 13.6074  decode.loss_cls: 0.6173  decode.loss_mask: 0.2837  decode.loss_dice: 0.3679  decode.d0.loss_cls: 1.7389  decode.d0.loss_mask: 0.3417  decode.d0.loss_dice: 0.4398  decode.d1.loss_cls: 0.6749  decode.d1.loss_mask: 0.3097  decode.d1.loss_dice: 0.3991  decode.d2.loss_cls: 0.5712  decode.d2.loss_mask: 0.2928  decode.d2.loss_dice: 0.3816  decode.d3.loss_cls: 0.4918  decode.d3.loss_mask: 0.3032  decode.d3.loss_dice: 0.3662  decode.d4.loss_cls: 0.5135  decode.d4.loss_mask: 0.3151  decode.d4.loss_dice: 0.3793  decode.d5.loss_cls: 0.5569  decode.d5.loss_mask: 0.2801  decode.d5.loss_dice: 0.3807  decode.d6.loss_cls: 0.5228  decode.d6.loss_mask: 0.3004  decode.d6.loss_dice: 0.3686  decode.d7.loss_cls: 0.5201  decode.d7.loss_mask: 0.2928  decode.d7.loss_dice: 0.3681  decode.d8.loss_cls: 0.5692  decode.d8.loss_mask: 0.2814  decode.d8.loss_dice: 0.3788
08/06 03:16:00 - mmengine - INFO - Iter(train) [  7250/320000]  base_lr: 9.7959e-05 lr: 9.7959e-06  eta: 1 day, 18:34:01  time: 0.4911  data_time: 0.0105  memory: 5892  grad_norm: 172.8656  loss: 13.4762  decode.loss_cls: 0.5759  decode.loss_mask: 0.4385  decode.loss_dice: 0.3181  decode.d0.loss_cls: 1.3097  decode.d0.loss_mask: 0.4902  decode.d0.loss_dice: 0.3939  decode.d1.loss_cls: 0.6479  decode.d1.loss_mask: 0.4522  decode.d1.loss_dice: 0.3390  decode.d2.loss_cls: 0.4730  decode.d2.loss_mask: 0.4511  decode.d2.loss_dice: 0.3774  decode.d3.loss_cls: 0.4314  decode.d3.loss_mask: 0.4374  decode.d3.loss_dice: 0.3345  decode.d4.loss_cls: 0.4254  decode.d4.loss_mask: 0.4260  decode.d4.loss_dice: 0.3291  decode.d5.loss_cls: 0.4012  decode.d5.loss_mask: 0.4268  decode.d5.loss_dice: 0.3434  decode.d6.loss_cls: 0.4163  decode.d6.loss_mask: 0.4292  decode.d6.loss_dice: 0.3458  decode.d7.loss_cls: 0.4414  decode.d7.loss_mask: 0.4328  decode.d7.loss_dice: 0.3270  decode.d8.loss_cls: 0.5205  decode.d8.loss_mask: 0.4333  decode.d8.loss_dice: 0.3076
08/06 03:16:24 - mmengine - INFO - Iter(train) [  7300/320000]  base_lr: 9.7945e-05 lr: 9.7945e-06  eta: 1 day, 18:33:40  time: 0.4903  data_time: 0.0101  memory: 5907  grad_norm: 142.0080  loss: 10.9155  decode.loss_cls: 0.3568  decode.loss_mask: 0.2502  decode.loss_dice: 0.3269  decode.d0.loss_cls: 1.4649  decode.d0.loss_mask: 0.2546  decode.d0.loss_dice: 0.3679  decode.d1.loss_cls: 0.4714  decode.d1.loss_mask: 0.2818  decode.d1.loss_dice: 0.3602  decode.d2.loss_cls: 0.4677  decode.d2.loss_mask: 0.2518  decode.d2.loss_dice: 0.3328  decode.d3.loss_cls: 0.3843  decode.d3.loss_mask: 0.2470  decode.d3.loss_dice: 0.3303  decode.d4.loss_cls: 0.3772  decode.d4.loss_mask: 0.2567  decode.d4.loss_dice: 0.3584  decode.d5.loss_cls: 0.4083  decode.d5.loss_mask: 0.2498  decode.d5.loss_dice: 0.3511  decode.d6.loss_cls: 0.3866  decode.d6.loss_mask: 0.2331  decode.d6.loss_dice: 0.3143  decode.d7.loss_cls: 0.3254  decode.d7.loss_mask: 0.2439  decode.d7.loss_dice: 0.3251  decode.d8.loss_cls: 0.3631  decode.d8.loss_mask: 0.2400  decode.d8.loss_dice: 0.3340
08/06 03:16:49 - mmengine - INFO - Iter(train) [  7350/320000]  base_lr: 9.7931e-05 lr: 9.7931e-06  eta: 1 day, 18:33:16  time: 0.4896  data_time: 0.0102  memory: 5908  grad_norm: 140.5413  loss: 13.0571  decode.loss_cls: 0.4919  decode.loss_mask: 0.2975  decode.loss_dice: 0.3870  decode.d0.loss_cls: 1.2881  decode.d0.loss_mask: 0.3087  decode.d0.loss_dice: 0.4512  decode.d1.loss_cls: 0.7245  decode.d1.loss_mask: 0.3171  decode.d1.loss_dice: 0.4144  decode.d2.loss_cls: 0.5324  decode.d2.loss_mask: 0.3075  decode.d2.loss_dice: 0.3537  decode.d3.loss_cls: 0.5523  decode.d3.loss_mask: 0.3032  decode.d3.loss_dice: 0.3548  decode.d4.loss_cls: 0.5504  decode.d4.loss_mask: 0.3017  decode.d4.loss_dice: 0.3768  decode.d5.loss_cls: 0.4774  decode.d5.loss_mask: 0.3151  decode.d5.loss_dice: 0.3879  decode.d6.loss_cls: 0.4775  decode.d6.loss_mask: 0.3010  decode.d6.loss_dice: 0.3917  decode.d7.loss_cls: 0.5431  decode.d7.loss_mask: 0.2998  decode.d7.loss_dice: 0.3925  decode.d8.loss_cls: 0.4525  decode.d8.loss_mask: 0.3069  decode.d8.loss_dice: 0.3984
08/06 03:17:13 - mmengine - INFO - Iter(train) [  7400/320000]  base_lr: 9.7917e-05 lr: 9.7917e-06  eta: 1 day, 18:32:53  time: 0.4908  data_time: 0.0104  memory: 5890  grad_norm: 216.7616  loss: 14.2077  decode.loss_cls: 0.4580  decode.loss_mask: 0.3929  decode.loss_dice: 0.4168  decode.d0.loss_cls: 1.5072  decode.d0.loss_mask: 0.3820  decode.d0.loss_dice: 0.4471  decode.d1.loss_cls: 0.7525  decode.d1.loss_mask: 0.4069  decode.d1.loss_dice: 0.3969  decode.d2.loss_cls: 0.5056  decode.d2.loss_mask: 0.4220  decode.d2.loss_dice: 0.4570  decode.d3.loss_cls: 0.4947  decode.d3.loss_mask: 0.4061  decode.d3.loss_dice: 0.4313  decode.d4.loss_cls: 0.4970  decode.d4.loss_mask: 0.4055  decode.d4.loss_dice: 0.4187  decode.d5.loss_cls: 0.4666  decode.d5.loss_mask: 0.3928  decode.d5.loss_dice: 0.4021  decode.d6.loss_cls: 0.4330  decode.d6.loss_mask: 0.3958  decode.d6.loss_dice: 0.4081  decode.d7.loss_cls: 0.4716  decode.d7.loss_mask: 0.3894  decode.d7.loss_dice: 0.3961  decode.d8.loss_cls: 0.4648  decode.d8.loss_mask: 0.3888  decode.d8.loss_dice: 0.4006
08/06 03:17:38 - mmengine - INFO - Iter(train) [  7450/320000]  base_lr: 9.7903e-05 lr: 9.7903e-06  eta: 1 day, 18:32:30  time: 0.4909  data_time: 0.0103  memory: 5889  grad_norm: 188.0593  loss: 14.1967  decode.loss_cls: 0.5723  decode.loss_mask: 0.3261  decode.loss_dice: 0.3751  decode.d0.loss_cls: 1.5387  decode.d0.loss_mask: 0.3623  decode.d0.loss_dice: 0.4462  decode.d1.loss_cls: 0.6485  decode.d1.loss_mask: 0.3752  decode.d1.loss_dice: 0.4138  decode.d2.loss_cls: 0.6084  decode.d2.loss_mask: 0.3501  decode.d2.loss_dice: 0.3808  decode.d3.loss_cls: 0.5469  decode.d3.loss_mask: 0.3358  decode.d3.loss_dice: 0.3639  decode.d4.loss_cls: 0.6288  decode.d4.loss_mask: 0.3397  decode.d4.loss_dice: 0.3755  decode.d5.loss_cls: 0.6163  decode.d5.loss_mask: 0.3317  decode.d5.loss_dice: 0.3754  decode.d6.loss_cls: 0.5654  decode.d6.loss_mask: 0.3282  decode.d6.loss_dice: 0.3655  decode.d7.loss_cls: 0.5623  decode.d7.loss_mask: 0.3395  decode.d7.loss_dice: 0.3874  decode.d8.loss_cls: 0.5990  decode.d8.loss_mask: 0.3442  decode.d8.loss_dice: 0.3935
08/06 03:18:02 - mmengine - INFO - Iter(train) [  7500/320000]  base_lr: 9.7888e-05 lr: 9.7888e-06  eta: 1 day, 18:32:06  time: 0.4900  data_time: 0.0102  memory: 5893  grad_norm: 100.4353  loss: 13.4771  decode.loss_cls: 0.5515  decode.loss_mask: 0.3326  decode.loss_dice: 0.3382  decode.d0.loss_cls: 1.5216  decode.d0.loss_mask: 0.3331  decode.d0.loss_dice: 0.4207  decode.d1.loss_cls: 0.6815  decode.d1.loss_mask: 0.3203  decode.d1.loss_dice: 0.3700  decode.d2.loss_cls: 0.6606  decode.d2.loss_mask: 0.3258  decode.d2.loss_dice: 0.3279  decode.d3.loss_cls: 0.5016  decode.d3.loss_mask: 0.3239  decode.d3.loss_dice: 0.3408  decode.d4.loss_cls: 0.5833  decode.d4.loss_mask: 0.3333  decode.d4.loss_dice: 0.3657  decode.d5.loss_cls: 0.5399  decode.d5.loss_mask: 0.3278  decode.d5.loss_dice: 0.3726  decode.d6.loss_cls: 0.4900  decode.d6.loss_mask: 0.3255  decode.d6.loss_dice: 0.3436  decode.d7.loss_cls: 0.5331  decode.d7.loss_mask: 0.3252  decode.d7.loss_dice: 0.3386  decode.d8.loss_cls: 0.5806  decode.d8.loss_mask: 0.3279  decode.d8.loss_dice: 0.3398
08/06 03:18:27 - mmengine - INFO - Iter(train) [  7550/320000]  base_lr: 9.7874e-05 lr: 9.7874e-06  eta: 1 day, 18:31:43  time: 0.4908  data_time: 0.0103  memory: 5892  grad_norm: 194.3450  loss: 16.4498  decode.loss_cls: 0.8113  decode.loss_mask: 0.3628  decode.loss_dice: 0.5360  decode.d0.loss_cls: 1.4794  decode.d0.loss_mask: 0.3345  decode.d0.loss_dice: 0.5053  decode.d1.loss_cls: 0.8800  decode.d1.loss_mask: 0.3474  decode.d1.loss_dice: 0.5036  decode.d2.loss_cls: 0.7481  decode.d2.loss_mask: 0.3439  decode.d2.loss_dice: 0.4450  decode.d3.loss_cls: 0.7267  decode.d3.loss_mask: 0.3392  decode.d3.loss_dice: 0.4315  decode.d4.loss_cls: 0.7717  decode.d4.loss_mask: 0.3389  decode.d4.loss_dice: 0.4700  decode.d5.loss_cls: 0.6355  decode.d5.loss_mask: 0.3366  decode.d5.loss_dice: 0.4435  decode.d6.loss_cls: 0.7065  decode.d6.loss_mask: 0.3635  decode.d6.loss_dice: 0.4707  decode.d7.loss_cls: 0.7279  decode.d7.loss_mask: 0.3674  decode.d7.loss_dice: 0.4923  decode.d8.loss_cls: 0.6658  decode.d8.loss_mask: 0.3760  decode.d8.loss_dice: 0.4890
08/06 03:18:51 - mmengine - INFO - Iter(train) [  7600/320000]  base_lr: 9.7860e-05 lr: 9.7860e-06  eta: 1 day, 18:31:25  time: 0.4887  data_time: 0.0102  memory: 5926  grad_norm: 327.5481  loss: 13.7907  decode.loss_cls: 0.5212  decode.loss_mask: 0.3288  decode.loss_dice: 0.4377  decode.d0.loss_cls: 1.3579  decode.d0.loss_mask: 0.3464  decode.d0.loss_dice: 0.4744  decode.d1.loss_cls: 0.5802  decode.d1.loss_mask: 0.3371  decode.d1.loss_dice: 0.4531  decode.d2.loss_cls: 0.5389  decode.d2.loss_mask: 0.3384  decode.d2.loss_dice: 0.4210  decode.d3.loss_cls: 0.4856  decode.d3.loss_mask: 0.3450  decode.d3.loss_dice: 0.4328  decode.d4.loss_cls: 0.4798  decode.d4.loss_mask: 0.3404  decode.d4.loss_dice: 0.4287  decode.d5.loss_cls: 0.4920  decode.d5.loss_mask: 0.3475  decode.d5.loss_dice: 0.4603  decode.d6.loss_cls: 0.4999  decode.d6.loss_mask: 0.3255  decode.d6.loss_dice: 0.4271  decode.d7.loss_cls: 0.5263  decode.d7.loss_mask: 0.3316  decode.d7.loss_dice: 0.4297  decode.d8.loss_cls: 0.5014  decode.d8.loss_mask: 0.3332  decode.d8.loss_dice: 0.4691
08/06 03:19:16 - mmengine - INFO - Iter(train) [  7650/320000]  base_lr: 9.7846e-05 lr: 9.7846e-06  eta: 1 day, 18:31:01  time: 0.4900  data_time: 0.0102  memory: 5910  grad_norm: 202.5709  loss: 13.0334  decode.loss_cls: 0.5475  decode.loss_mask: 0.2596  decode.loss_dice: 0.3891  decode.d0.loss_cls: 1.3739  decode.d0.loss_mask: 0.2909  decode.d0.loss_dice: 0.4113  decode.d1.loss_cls: 0.6696  decode.d1.loss_mask: 0.2695  decode.d1.loss_dice: 0.3785  decode.d2.loss_cls: 0.5085  decode.d2.loss_mask: 0.2621  decode.d2.loss_dice: 0.3352  decode.d3.loss_cls: 0.5567  decode.d3.loss_mask: 0.2665  decode.d3.loss_dice: 0.3644  decode.d4.loss_cls: 0.5570  decode.d4.loss_mask: 0.2757  decode.d4.loss_dice: 0.3635  decode.d5.loss_cls: 0.6001  decode.d5.loss_mask: 0.2643  decode.d5.loss_dice: 0.3552  decode.d6.loss_cls: 0.6677  decode.d6.loss_mask: 0.2553  decode.d6.loss_dice: 0.3609  decode.d7.loss_cls: 0.5683  decode.d7.loss_mask: 0.2662  decode.d7.loss_dice: 0.4203  decode.d8.loss_cls: 0.5260  decode.d8.loss_mask: 0.2629  decode.d8.loss_dice: 0.4069
08/06 03:19:40 - mmengine - INFO - Iter(train) [  7700/320000]  base_lr: 9.7832e-05 lr: 9.7832e-06  eta: 1 day, 18:30:37  time: 0.4894  data_time: 0.0102  memory: 5892  grad_norm: 151.7691  loss: 11.0118  decode.loss_cls: 0.4360  decode.loss_mask: 0.2908  decode.loss_dice: 0.3061  decode.d0.loss_cls: 1.2278  decode.d0.loss_mask: 0.2905  decode.d0.loss_dice: 0.3195  decode.d1.loss_cls: 0.5709  decode.d1.loss_mask: 0.2854  decode.d1.loss_dice: 0.2931  decode.d2.loss_cls: 0.5017  decode.d2.loss_mask: 0.2772  decode.d2.loss_dice: 0.2954  decode.d3.loss_cls: 0.3720  decode.d3.loss_mask: 0.2735  decode.d3.loss_dice: 0.2941  decode.d4.loss_cls: 0.4023  decode.d4.loss_mask: 0.2689  decode.d4.loss_dice: 0.2866  decode.d5.loss_cls: 0.3972  decode.d5.loss_mask: 0.2680  decode.d5.loss_dice: 0.2941  decode.d6.loss_cls: 0.4453  decode.d6.loss_mask: 0.2679  decode.d6.loss_dice: 0.3002  decode.d7.loss_cls: 0.4190  decode.d7.loss_mask: 0.2712  decode.d7.loss_dice: 0.3080  decode.d8.loss_cls: 0.4734  decode.d8.loss_mask: 0.2761  decode.d8.loss_dice: 0.2995
08/06 03:20:05 - mmengine - INFO - Iter(train) [  7750/320000]  base_lr: 9.7818e-05 lr: 9.7818e-06  eta: 1 day, 18:30:13  time: 0.4897  data_time: 0.0104  memory: 5891  grad_norm: 197.0111  loss: 13.0939  decode.loss_cls: 0.4773  decode.loss_mask: 0.3607  decode.loss_dice: 0.4211  decode.d0.loss_cls: 1.3849  decode.d0.loss_mask: 0.3421  decode.d0.loss_dice: 0.4104  decode.d1.loss_cls: 0.5836  decode.d1.loss_mask: 0.3600  decode.d1.loss_dice: 0.4361  decode.d2.loss_cls: 0.4549  decode.d2.loss_mask: 0.3525  decode.d2.loss_dice: 0.4148  decode.d3.loss_cls: 0.4064  decode.d3.loss_mask: 0.3406  decode.d3.loss_dice: 0.4214  decode.d4.loss_cls: 0.3789  decode.d4.loss_mask: 0.3522  decode.d4.loss_dice: 0.4369  decode.d5.loss_cls: 0.3638  decode.d5.loss_mask: 0.3515  decode.d5.loss_dice: 0.4400  decode.d6.loss_cls: 0.3965  decode.d6.loss_mask: 0.3572  decode.d6.loss_dice: 0.4426  decode.d7.loss_cls: 0.3748  decode.d7.loss_mask: 0.3616  decode.d7.loss_dice: 0.4370  decode.d8.loss_cls: 0.4423  decode.d8.loss_mask: 0.3538  decode.d8.loss_dice: 0.4383
08/06 03:20:30 - mmengine - INFO - Iter(train) [  7800/320000]  base_lr: 9.7804e-05 lr: 9.7804e-06  eta: 1 day, 18:29:49  time: 0.4904  data_time: 0.0102  memory: 5891  grad_norm: 188.2666  loss: 14.5765  decode.loss_cls: 0.6937  decode.loss_mask: 0.3345  decode.loss_dice: 0.3788  decode.d0.loss_cls: 1.5504  decode.d0.loss_mask: 0.3380  decode.d0.loss_dice: 0.4213  decode.d1.loss_cls: 0.6191  decode.d1.loss_mask: 0.3439  decode.d1.loss_dice: 0.3794  decode.d2.loss_cls: 0.5936  decode.d2.loss_mask: 0.3344  decode.d2.loss_dice: 0.3868  decode.d3.loss_cls: 0.6161  decode.d3.loss_mask: 0.3333  decode.d3.loss_dice: 0.3722  decode.d4.loss_cls: 0.6463  decode.d4.loss_mask: 0.3742  decode.d4.loss_dice: 0.3272  decode.d5.loss_cls: 0.6563  decode.d5.loss_mask: 0.3787  decode.d5.loss_dice: 0.3386  decode.d6.loss_cls: 0.7225  decode.d6.loss_mask: 0.3472  decode.d6.loss_dice: 0.3264  decode.d7.loss_cls: 0.6358  decode.d7.loss_mask: 0.3645  decode.d7.loss_dice: 0.3890  decode.d8.loss_cls: 0.6632  decode.d8.loss_mask: 0.3399  decode.d8.loss_dice: 0.3710
08/06 03:20:54 - mmengine - INFO - Iter(train) [  7850/320000]  base_lr: 9.7790e-05 lr: 9.7790e-06  eta: 1 day, 18:29:25  time: 0.4898  data_time: 0.0102  memory: 5908  grad_norm: 303.9677  loss: 14.4579  decode.loss_cls: 0.7128  decode.loss_mask: 0.2865  decode.loss_dice: 0.4305  decode.d0.loss_cls: 1.4814  decode.d0.loss_mask: 0.2692  decode.d0.loss_dice: 0.4771  decode.d1.loss_cls: 0.6725  decode.d1.loss_mask: 0.3101  decode.d1.loss_dice: 0.4886  decode.d2.loss_cls: 0.5859  decode.d2.loss_mask: 0.2788  decode.d2.loss_dice: 0.4313  decode.d3.loss_cls: 0.6013  decode.d3.loss_mask: 0.2912  decode.d3.loss_dice: 0.4520  decode.d4.loss_cls: 0.5783  decode.d4.loss_mask: 0.2976  decode.d4.loss_dice: 0.4580  decode.d5.loss_cls: 0.5792  decode.d5.loss_mask: 0.2992  decode.d5.loss_dice: 0.4454  decode.d6.loss_cls: 0.6040  decode.d6.loss_mask: 0.2869  decode.d6.loss_dice: 0.4132  decode.d7.loss_cls: 0.6306  decode.d7.loss_mask: 0.2765  decode.d7.loss_dice: 0.4294  decode.d8.loss_cls: 0.6479  decode.d8.loss_mask: 0.2919  decode.d8.loss_dice: 0.4508
08/06 03:21:19 - mmengine - INFO - Iter(train) [  7900/320000]  base_lr: 9.7776e-05 lr: 9.7776e-06  eta: 1 day, 18:29:01  time: 0.4900  data_time: 0.0103  memory: 5890  grad_norm: 204.9538  loss: 13.0903  decode.loss_cls: 0.4758  decode.loss_mask: 0.3691  decode.loss_dice: 0.3876  decode.d0.loss_cls: 1.3766  decode.d0.loss_mask: 0.3210  decode.d0.loss_dice: 0.4075  decode.d1.loss_cls: 0.6067  decode.d1.loss_mask: 0.3215  decode.d1.loss_dice: 0.4044  decode.d2.loss_cls: 0.5141  decode.d2.loss_mask: 0.3249  decode.d2.loss_dice: 0.3665  decode.d3.loss_cls: 0.4088  decode.d3.loss_mask: 0.3190  decode.d3.loss_dice: 0.3708  decode.d4.loss_cls: 0.4918  decode.d4.loss_mask: 0.3247  decode.d4.loss_dice: 0.3976  decode.d5.loss_cls: 0.4909  decode.d5.loss_mask: 0.3228  decode.d5.loss_dice: 0.4066  decode.d6.loss_cls: 0.4918  decode.d6.loss_mask: 0.3274  decode.d6.loss_dice: 0.3984  decode.d7.loss_cls: 0.4316  decode.d7.loss_mask: 0.3548  decode.d7.loss_dice: 0.4074  decode.d8.loss_cls: 0.5096  decode.d8.loss_mask: 0.3660  decode.d8.loss_dice: 0.3945
08/06 03:21:43 - mmengine - INFO - Iter(train) [  7950/320000]  base_lr: 9.7762e-05 lr: 9.7762e-06  eta: 1 day, 18:28:38  time: 0.4918  data_time: 0.0103  memory: 5876  grad_norm: 219.1592  loss: 13.8670  decode.loss_cls: 0.4683  decode.loss_mask: 0.3063  decode.loss_dice: 0.4685  decode.d0.loss_cls: 1.3260  decode.d0.loss_mask: 0.3089  decode.d0.loss_dice: 0.5322  decode.d1.loss_cls: 0.5688  decode.d1.loss_mask: 0.3078  decode.d1.loss_dice: 0.4783  decode.d2.loss_cls: 0.4869  decode.d2.loss_mask: 0.3047  decode.d2.loss_dice: 0.4498  decode.d3.loss_cls: 0.5473  decode.d3.loss_mask: 0.3220  decode.d3.loss_dice: 0.4711  decode.d4.loss_cls: 0.5265  decode.d4.loss_mask: 0.3122  decode.d4.loss_dice: 0.4607  decode.d5.loss_cls: 0.5282  decode.d5.loss_mask: 0.3203  decode.d5.loss_dice: 0.4529  decode.d6.loss_cls: 0.4306  decode.d6.loss_mask: 0.3285  decode.d6.loss_dice: 0.4617  decode.d7.loss_cls: 0.5279  decode.d7.loss_mask: 0.3184  decode.d7.loss_dice: 0.4914  decode.d8.loss_cls: 0.6149  decode.d8.loss_mask: 0.3142  decode.d8.loss_dice: 0.4317
08/06 03:22:08 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 03:22:08 - mmengine - INFO - Iter(train) [  8000/320000]  base_lr: 9.7747e-05 lr: 9.7747e-06  eta: 1 day, 18:28:15  time: 0.4903  data_time: 0.0104  memory: 5875  grad_norm: 308.6475  loss: 16.5927  decode.loss_cls: 0.7108  decode.loss_mask: 0.4667  decode.loss_dice: 0.4020  decode.d0.loss_cls: 1.4699  decode.d0.loss_mask: 0.4479  decode.d0.loss_dice: 0.4065  decode.d1.loss_cls: 0.9524  decode.d1.loss_mask: 0.4706  decode.d1.loss_dice: 0.3805  decode.d2.loss_cls: 0.8055  decode.d2.loss_mask: 0.4310  decode.d2.loss_dice: 0.3914  decode.d3.loss_cls: 0.7718  decode.d3.loss_mask: 0.4249  decode.d3.loss_dice: 0.4141  decode.d4.loss_cls: 0.7390  decode.d4.loss_mask: 0.4096  decode.d4.loss_dice: 0.3755  decode.d5.loss_cls: 0.7151  decode.d5.loss_mask: 0.4469  decode.d5.loss_dice: 0.3767  decode.d6.loss_cls: 0.7129  decode.d6.loss_mask: 0.4356  decode.d6.loss_dice: 0.3637  decode.d7.loss_cls: 0.7529  decode.d7.loss_mask: 0.4518  decode.d7.loss_dice: 0.3527  decode.d8.loss_cls: 0.6787  decode.d8.loss_mask: 0.4500  decode.d8.loss_dice: 0.3859
08/06 03:22:32 - mmengine - INFO - Iter(train) [  8050/320000]  base_lr: 9.7733e-05 lr: 9.7733e-06  eta: 1 day, 18:27:51  time: 0.4906  data_time: 0.0103  memory: 5907  grad_norm: 289.4053  loss: 11.2435  decode.loss_cls: 0.3853  decode.loss_mask: 0.3203  decode.loss_dice: 0.2892  decode.d0.loss_cls: 1.2327  decode.d0.loss_mask: 0.3311  decode.d0.loss_dice: 0.3343  decode.d1.loss_cls: 0.5280  decode.d1.loss_mask: 0.3258  decode.d1.loss_dice: 0.2970  decode.d2.loss_cls: 0.4863  decode.d2.loss_mask: 0.3043  decode.d2.loss_dice: 0.2890  decode.d3.loss_cls: 0.5134  decode.d3.loss_mask: 0.3092  decode.d3.loss_dice: 0.2814  decode.d4.loss_cls: 0.3748  decode.d4.loss_mask: 0.3151  decode.d4.loss_dice: 0.3035  decode.d5.loss_cls: 0.4084  decode.d5.loss_mask: 0.3120  decode.d5.loss_dice: 0.2920  decode.d6.loss_cls: 0.4165  decode.d6.loss_mask: 0.3053  decode.d6.loss_dice: 0.2785  decode.d7.loss_cls: 0.3452  decode.d7.loss_mask: 0.3247  decode.d7.loss_dice: 0.2959  decode.d8.loss_cls: 0.4370  decode.d8.loss_mask: 0.3218  decode.d8.loss_dice: 0.2855
08/06 03:22:57 - mmengine - INFO - Iter(train) [  8100/320000]  base_lr: 9.7719e-05 lr: 9.7719e-06  eta: 1 day, 18:27:28  time: 0.4913  data_time: 0.0102  memory: 5892  grad_norm: 161.6028  loss: 10.5405  decode.loss_cls: 0.3741  decode.loss_mask: 0.2564  decode.loss_dice: 0.3049  decode.d0.loss_cls: 1.2385  decode.d0.loss_mask: 0.2767  decode.d0.loss_dice: 0.3524  decode.d1.loss_cls: 0.5352  decode.d1.loss_mask: 0.2604  decode.d1.loss_dice: 0.3040  decode.d2.loss_cls: 0.4128  decode.d2.loss_mask: 0.2641  decode.d2.loss_dice: 0.2988  decode.d3.loss_cls: 0.4364  decode.d3.loss_mask: 0.2583  decode.d3.loss_dice: 0.2882  decode.d4.loss_cls: 0.3608  decode.d4.loss_mask: 0.2575  decode.d4.loss_dice: 0.2975  decode.d5.loss_cls: 0.3210  decode.d5.loss_mask: 0.2622  decode.d5.loss_dice: 0.3134  decode.d6.loss_cls: 0.3747  decode.d6.loss_mask: 0.2547  decode.d6.loss_dice: 0.3194  decode.d7.loss_cls: 0.4043  decode.d7.loss_mask: 0.2527  decode.d7.loss_dice: 0.3114  decode.d8.loss_cls: 0.3802  decode.d8.loss_mask: 0.2548  decode.d8.loss_dice: 0.3145
08/06 03:23:21 - mmengine - INFO - Iter(train) [  8150/320000]  base_lr: 9.7705e-05 lr: 9.7705e-06  eta: 1 day, 18:27:04  time: 0.4897  data_time: 0.0103  memory: 5891  grad_norm: 317.6501  loss: 13.0067  decode.loss_cls: 0.3592  decode.loss_mask: 0.4341  decode.loss_dice: 0.4078  decode.d0.loss_cls: 1.5417  decode.d0.loss_mask: 0.3968  decode.d0.loss_dice: 0.4095  decode.d1.loss_cls: 0.6044  decode.d1.loss_mask: 0.3464  decode.d1.loss_dice: 0.3216  decode.d2.loss_cls: 0.3931  decode.d2.loss_mask: 0.3489  decode.d2.loss_dice: 0.3210  decode.d3.loss_cls: 0.3843  decode.d3.loss_mask: 0.3558  decode.d3.loss_dice: 0.3273  decode.d4.loss_cls: 0.4642  decode.d4.loss_mask: 0.3380  decode.d4.loss_dice: 0.3117  decode.d5.loss_cls: 0.4902  decode.d5.loss_mask: 0.3696  decode.d5.loss_dice: 0.3732  decode.d6.loss_cls: 0.4382  decode.d6.loss_mask: 0.3702  decode.d6.loss_dice: 0.3517  decode.d7.loss_cls: 0.5000  decode.d7.loss_mask: 0.3911  decode.d7.loss_dice: 0.4020  decode.d8.loss_cls: 0.4432  decode.d8.loss_mask: 0.4067  decode.d8.loss_dice: 0.4048
08/06 03:23:46 - mmengine - INFO - Iter(train) [  8200/320000]  base_lr: 9.7691e-05 lr: 9.7691e-06  eta: 1 day, 18:26:44  time: 0.4908  data_time: 0.0101  memory: 5892  grad_norm: 125.1990  loss: 10.3099  decode.loss_cls: 0.3689  decode.loss_mask: 0.2205  decode.loss_dice: 0.3005  decode.d0.loss_cls: 1.2138  decode.d0.loss_mask: 0.2248  decode.d0.loss_dice: 0.3580  decode.d1.loss_cls: 0.4910  decode.d1.loss_mask: 0.2244  decode.d1.loss_dice: 0.3322  decode.d2.loss_cls: 0.4689  decode.d2.loss_mask: 0.2209  decode.d2.loss_dice: 0.2974  decode.d3.loss_cls: 0.4519  decode.d3.loss_mask: 0.2169  decode.d3.loss_dice: 0.3059  decode.d4.loss_cls: 0.4392  decode.d4.loss_mask: 0.2094  decode.d4.loss_dice: 0.2918  decode.d5.loss_cls: 0.4004  decode.d5.loss_mask: 0.2134  decode.d5.loss_dice: 0.3062  decode.d6.loss_cls: 0.3921  decode.d6.loss_mask: 0.2146  decode.d6.loss_dice: 0.3198  decode.d7.loss_cls: 0.3731  decode.d7.loss_mask: 0.2175  decode.d7.loss_dice: 0.3168  decode.d8.loss_cls: 0.4045  decode.d8.loss_mask: 0.2079  decode.d8.loss_dice: 0.3073
08/06 03:24:10 - mmengine - INFO - Iter(train) [  8250/320000]  base_lr: 9.7677e-05 lr: 9.7677e-06  eta: 1 day, 18:26:21  time: 0.4915  data_time: 0.0104  memory: 5910  grad_norm: 156.9001  loss: 10.6815  decode.loss_cls: 0.3250  decode.loss_mask: 0.3081  decode.loss_dice: 0.3170  decode.d0.loss_cls: 1.3901  decode.d0.loss_mask: 0.3140  decode.d0.loss_dice: 0.3661  decode.d1.loss_cls: 0.4238  decode.d1.loss_mask: 0.3075  decode.d1.loss_dice: 0.3294  decode.d2.loss_cls: 0.3359  decode.d2.loss_mask: 0.2988  decode.d2.loss_dice: 0.2904  decode.d3.loss_cls: 0.2866  decode.d3.loss_mask: 0.3132  decode.d3.loss_dice: 0.3319  decode.d4.loss_cls: 0.3329  decode.d4.loss_mask: 0.3104  decode.d4.loss_dice: 0.2939  decode.d5.loss_cls: 0.3281  decode.d5.loss_mask: 0.3127  decode.d5.loss_dice: 0.3162  decode.d6.loss_cls: 0.3090  decode.d6.loss_mask: 0.3066  decode.d6.loss_dice: 0.2938  decode.d7.loss_cls: 0.3197  decode.d7.loss_mask: 0.3112  decode.d7.loss_dice: 0.3255  decode.d8.loss_cls: 0.3413  decode.d8.loss_mask: 0.3073  decode.d8.loss_dice: 0.3350
08/06 03:24:35 - mmengine - INFO - Iter(train) [  8300/320000]  base_lr: 9.7663e-05 lr: 9.7663e-06  eta: 1 day, 18:25:58  time: 0.4905  data_time: 0.0102  memory: 5908  grad_norm: 166.1754  loss: 13.6110  decode.loss_cls: 0.5084  decode.loss_mask: 0.3364  decode.loss_dice: 0.3528  decode.d0.loss_cls: 1.4388  decode.d0.loss_mask: 0.3591  decode.d0.loss_dice: 0.4517  decode.d1.loss_cls: 0.7040  decode.d1.loss_mask: 0.3453  decode.d1.loss_dice: 0.3859  decode.d2.loss_cls: 0.5807  decode.d2.loss_mask: 0.3386  decode.d2.loss_dice: 0.3694  decode.d3.loss_cls: 0.5583  decode.d3.loss_mask: 0.3375  decode.d3.loss_dice: 0.3653  decode.d4.loss_cls: 0.5631  decode.d4.loss_mask: 0.3271  decode.d4.loss_dice: 0.3546  decode.d5.loss_cls: 0.5333  decode.d5.loss_mask: 0.3310  decode.d5.loss_dice: 0.3823  decode.d6.loss_cls: 0.5704  decode.d6.loss_mask: 0.3264  decode.d6.loss_dice: 0.3639  decode.d7.loss_cls: 0.5256  decode.d7.loss_mask: 0.3265  decode.d7.loss_dice: 0.3574  decode.d8.loss_cls: 0.5320  decode.d8.loss_mask: 0.3304  decode.d8.loss_dice: 0.3548
08/06 03:24:59 - mmengine - INFO - Iter(train) [  8350/320000]  base_lr: 9.7649e-05 lr: 9.7649e-06  eta: 1 day, 18:25:33  time: 0.4901  data_time: 0.0102  memory: 5907  grad_norm: 247.5689  loss: 11.9936  decode.loss_cls: 0.4973  decode.loss_mask: 0.3539  decode.loss_dice: 0.2817  decode.d0.loss_cls: 1.2444  decode.d0.loss_mask: 0.4321  decode.d0.loss_dice: 0.3483  decode.d1.loss_cls: 0.4716  decode.d1.loss_mask: 0.3579  decode.d1.loss_dice: 0.2960  decode.d2.loss_cls: 0.3622  decode.d2.loss_mask: 0.3706  decode.d2.loss_dice: 0.3068  decode.d3.loss_cls: 0.2463  decode.d3.loss_mask: 0.4794  decode.d3.loss_dice: 0.3189  decode.d4.loss_cls: 0.3535  decode.d4.loss_mask: 0.4657  decode.d4.loss_dice: 0.3069  decode.d5.loss_cls: 0.3327  decode.d5.loss_mask: 0.4578  decode.d5.loss_dice: 0.3176  decode.d6.loss_cls: 0.3131  decode.d6.loss_mask: 0.4719  decode.d6.loss_dice: 0.3313  decode.d7.loss_cls: 0.4188  decode.d7.loss_mask: 0.4276  decode.d7.loss_dice: 0.3322  decode.d8.loss_cls: 0.3823  decode.d8.loss_mask: 0.3862  decode.d8.loss_dice: 0.3284
08/06 03:25:24 - mmengine - INFO - Iter(train) [  8400/320000]  base_lr: 9.7635e-05 lr: 9.7635e-06  eta: 1 day, 18:25:10  time: 0.4901  data_time: 0.0102  memory: 5908  grad_norm: 145.1847  loss: 12.2717  decode.loss_cls: 0.4585  decode.loss_mask: 0.2932  decode.loss_dice: 0.3815  decode.d0.loss_cls: 1.2373  decode.d0.loss_mask: 0.2819  decode.d0.loss_dice: 0.3720  decode.d1.loss_cls: 0.5102  decode.d1.loss_mask: 0.2906  decode.d1.loss_dice: 0.3828  decode.d2.loss_cls: 0.4585  decode.d2.loss_mask: 0.2910  decode.d2.loss_dice: 0.3779  decode.d3.loss_cls: 0.5206  decode.d3.loss_mask: 0.2879  decode.d3.loss_dice: 0.3856  decode.d4.loss_cls: 0.4230  decode.d4.loss_mask: 0.2910  decode.d4.loss_dice: 0.3795  decode.d5.loss_cls: 0.4815  decode.d5.loss_mask: 0.2898  decode.d5.loss_dice: 0.3787  decode.d6.loss_cls: 0.4979  decode.d6.loss_mask: 0.2875  decode.d6.loss_dice: 0.3742  decode.d7.loss_cls: 0.4772  decode.d7.loss_mask: 0.2900  decode.d7.loss_dice: 0.3847  decode.d8.loss_cls: 0.4814  decode.d8.loss_mask: 0.2954  decode.d8.loss_dice: 0.4105
08/06 03:25:48 - mmengine - INFO - Iter(train) [  8450/320000]  base_lr: 9.7621e-05 lr: 9.7621e-06  eta: 1 day, 18:24:47  time: 0.4901  data_time: 0.0102  memory: 5875  grad_norm: 141.1894  loss: 9.2514  decode.loss_cls: 0.2677  decode.loss_mask: 0.2547  decode.loss_dice: 0.2918  decode.d0.loss_cls: 1.1337  decode.d0.loss_mask: 0.2645  decode.d0.loss_dice: 0.3010  decode.d1.loss_cls: 0.3889  decode.d1.loss_mask: 0.2567  decode.d1.loss_dice: 0.2873  decode.d2.loss_cls: 0.3278  decode.d2.loss_mask: 0.2625  decode.d2.loss_dice: 0.2887  decode.d3.loss_cls: 0.2612  decode.d3.loss_mask: 0.2500  decode.d3.loss_dice: 0.2867  decode.d4.loss_cls: 0.2423  decode.d4.loss_mask: 0.2538  decode.d4.loss_dice: 0.2925  decode.d5.loss_cls: 0.3075  decode.d5.loss_mask: 0.2500  decode.d5.loss_dice: 0.2877  decode.d6.loss_cls: 0.2466  decode.d6.loss_mask: 0.2515  decode.d6.loss_dice: 0.2869  decode.d7.loss_cls: 0.2560  decode.d7.loss_mask: 0.2615  decode.d7.loss_dice: 0.2871  decode.d8.loss_cls: 0.3617  decode.d8.loss_mask: 0.2525  decode.d8.loss_dice: 0.2906
08/06 03:26:13 - mmengine - INFO - Iter(train) [  8500/320000]  base_lr: 9.7606e-05 lr: 9.7606e-06  eta: 1 day, 18:24:24  time: 0.4914  data_time: 0.0104  memory: 5890  grad_norm: 174.7944  loss: 9.9002  decode.loss_cls: 0.3502  decode.loss_mask: 0.2760  decode.loss_dice: 0.3011  decode.d0.loss_cls: 1.2181  decode.d0.loss_mask: 0.2846  decode.d0.loss_dice: 0.3271  decode.d1.loss_cls: 0.3797  decode.d1.loss_mask: 0.2824  decode.d1.loss_dice: 0.3058  decode.d2.loss_cls: 0.3113  decode.d2.loss_mask: 0.2791  decode.d2.loss_dice: 0.2968  decode.d3.loss_cls: 0.2530  decode.d3.loss_mask: 0.2817  decode.d3.loss_dice: 0.3037  decode.d4.loss_cls: 0.3053  decode.d4.loss_mask: 0.2748  decode.d4.loss_dice: 0.2947  decode.d5.loss_cls: 0.3502  decode.d5.loss_mask: 0.2760  decode.d5.loss_dice: 0.2947  decode.d6.loss_cls: 0.3623  decode.d6.loss_mask: 0.2747  decode.d6.loss_dice: 0.2865  decode.d7.loss_cls: 0.2893  decode.d7.loss_mask: 0.2734  decode.d7.loss_dice: 0.2954  decode.d8.loss_cls: 0.3062  decode.d8.loss_mask: 0.2750  decode.d8.loss_dice: 0.2912
08/06 03:26:38 - mmengine - INFO - Iter(train) [  8550/320000]  base_lr: 9.7592e-05 lr: 9.7592e-06  eta: 1 day, 18:24:00  time: 0.4897  data_time: 0.0102  memory: 5908  grad_norm: 236.4343  loss: 11.4115  decode.loss_cls: 0.3799  decode.loss_mask: 0.3395  decode.loss_dice: 0.3707  decode.d0.loss_cls: 1.2025  decode.d0.loss_mask: 0.3594  decode.d0.loss_dice: 0.3992  decode.d1.loss_cls: 0.3982  decode.d1.loss_mask: 0.3513  decode.d1.loss_dice: 0.3660  decode.d2.loss_cls: 0.2868  decode.d2.loss_mask: 0.3417  decode.d2.loss_dice: 0.3872  decode.d3.loss_cls: 0.2994  decode.d3.loss_mask: 0.3361  decode.d3.loss_dice: 0.3610  decode.d4.loss_cls: 0.3129  decode.d4.loss_mask: 0.3531  decode.d4.loss_dice: 0.3713  decode.d5.loss_cls: 0.2790  decode.d5.loss_mask: 0.3534  decode.d5.loss_dice: 0.3834  decode.d6.loss_cls: 0.3580  decode.d6.loss_mask: 0.3156  decode.d6.loss_dice: 0.3596  decode.d7.loss_cls: 0.3297  decode.d7.loss_mask: 0.3655  decode.d7.loss_dice: 0.3802  decode.d8.loss_cls: 0.3200  decode.d8.loss_mask: 0.3648  decode.d8.loss_dice: 0.3861
08/06 03:27:02 - mmengine - INFO - Iter(train) [  8600/320000]  base_lr: 9.7578e-05 lr: 9.7578e-06  eta: 1 day, 18:23:37  time: 0.4916  data_time: 0.0102  memory: 5892  grad_norm: 137.7553  loss: 10.8141  decode.loss_cls: 0.4455  decode.loss_mask: 0.2702  decode.loss_dice: 0.3257  decode.d0.loss_cls: 1.4215  decode.d0.loss_mask: 0.2541  decode.d0.loss_dice: 0.3577  decode.d1.loss_cls: 0.5614  decode.d1.loss_mask: 0.2544  decode.d1.loss_dice: 0.3284  decode.d2.loss_cls: 0.3781  decode.d2.loss_mask: 0.2499  decode.d2.loss_dice: 0.3052  decode.d3.loss_cls: 0.3875  decode.d3.loss_mask: 0.2465  decode.d3.loss_dice: 0.2932  decode.d4.loss_cls: 0.3512  decode.d4.loss_mask: 0.2528  decode.d4.loss_dice: 0.3166  decode.d5.loss_cls: 0.3619  decode.d5.loss_mask: 0.2492  decode.d5.loss_dice: 0.3060  decode.d6.loss_cls: 0.3743  decode.d6.loss_mask: 0.2519  decode.d6.loss_dice: 0.3078  decode.d7.loss_cls: 0.3507  decode.d7.loss_mask: 0.2576  decode.d7.loss_dice: 0.3132  decode.d8.loss_cls: 0.4436  decode.d8.loss_mask: 0.2759  decode.d8.loss_dice: 0.3221
08/06 03:27:27 - mmengine - INFO - Iter(train) [  8650/320000]  base_lr: 9.7564e-05 lr: 9.7564e-06  eta: 1 day, 18:23:14  time: 0.4908  data_time: 0.0102  memory: 5908  grad_norm: 209.6499  loss: 10.0382  decode.loss_cls: 0.2965  decode.loss_mask: 0.2762  decode.loss_dice: 0.3068  decode.d0.loss_cls: 1.2487  decode.d0.loss_mask: 0.2746  decode.d0.loss_dice: 0.3477  decode.d1.loss_cls: 0.3866  decode.d1.loss_mask: 0.2717  decode.d1.loss_dice: 0.3094  decode.d2.loss_cls: 0.3879  decode.d2.loss_mask: 0.2687  decode.d2.loss_dice: 0.3033  decode.d3.loss_cls: 0.3754  decode.d3.loss_mask: 0.2685  decode.d3.loss_dice: 0.3039  decode.d4.loss_cls: 0.3192  decode.d4.loss_mask: 0.2633  decode.d4.loss_dice: 0.2913  decode.d5.loss_cls: 0.3218  decode.d5.loss_mask: 0.2627  decode.d5.loss_dice: 0.3006  decode.d6.loss_cls: 0.3224  decode.d6.loss_mask: 0.2719  decode.d6.loss_dice: 0.3051  decode.d7.loss_cls: 0.2960  decode.d7.loss_mask: 0.2669  decode.d7.loss_dice: 0.3031  decode.d8.loss_cls: 0.3191  decode.d8.loss_mask: 0.2681  decode.d8.loss_dice: 0.3003
08/06 03:27:51 - mmengine - INFO - Iter(train) [  8700/320000]  base_lr: 9.7550e-05 lr: 9.7550e-06  eta: 1 day, 18:22:54  time: 0.4909  data_time: 0.0103  memory: 5907  grad_norm: 170.1613  loss: 13.0807  decode.loss_cls: 0.3873  decode.loss_mask: 0.3273  decode.loss_dice: 0.4211  decode.d0.loss_cls: 1.5342  decode.d0.loss_mask: 0.3136  decode.d0.loss_dice: 0.4606  decode.d1.loss_cls: 0.6689  decode.d1.loss_mask: 0.3192  decode.d1.loss_dice: 0.4119  decode.d2.loss_cls: 0.5465  decode.d2.loss_mask: 0.3058  decode.d2.loss_dice: 0.4250  decode.d3.loss_cls: 0.4834  decode.d3.loss_mask: 0.3076  decode.d3.loss_dice: 0.4060  decode.d4.loss_cls: 0.4422  decode.d4.loss_mask: 0.3290  decode.d4.loss_dice: 0.4183  decode.d5.loss_cls: 0.4452  decode.d5.loss_mask: 0.3035  decode.d5.loss_dice: 0.4124  decode.d6.loss_cls: 0.4483  decode.d6.loss_mask: 0.2771  decode.d6.loss_dice: 0.3788  decode.d7.loss_cls: 0.4431  decode.d7.loss_mask: 0.3154  decode.d7.loss_dice: 0.4083  decode.d8.loss_cls: 0.4411  decode.d8.loss_mask: 0.3035  decode.d8.loss_dice: 0.3963
08/06 03:28:16 - mmengine - INFO - Iter(train) [  8750/320000]  base_lr: 9.7536e-05 lr: 9.7536e-06  eta: 1 day, 18:22:30  time: 0.4909  data_time: 0.0103  memory: 5892  grad_norm: 208.6349  loss: 11.4681  decode.loss_cls: 0.4202  decode.loss_mask: 0.2523  decode.loss_dice: 0.3311  decode.d0.loss_cls: 1.2089  decode.d0.loss_mask: 0.2402  decode.d0.loss_dice: 0.4173  decode.d1.loss_cls: 0.6093  decode.d1.loss_mask: 0.2532  decode.d1.loss_dice: 0.3468  decode.d2.loss_cls: 0.4696  decode.d2.loss_mask: 0.2667  decode.d2.loss_dice: 0.3554  decode.d3.loss_cls: 0.4636  decode.d3.loss_mask: 0.2518  decode.d3.loss_dice: 0.3366  decode.d4.loss_cls: 0.4625  decode.d4.loss_mask: 0.2582  decode.d4.loss_dice: 0.3522  decode.d5.loss_cls: 0.4254  decode.d5.loss_mask: 0.2530  decode.d5.loss_dice: 0.3714  decode.d6.loss_cls: 0.4686  decode.d6.loss_mask: 0.2471  decode.d6.loss_dice: 0.3414  decode.d7.loss_cls: 0.4588  decode.d7.loss_mask: 0.2411  decode.d7.loss_dice: 0.3370  decode.d8.loss_cls: 0.4431  decode.d8.loss_mask: 0.2436  decode.d8.loss_dice: 0.3416
08/06 03:28:40 - mmengine - INFO - Iter(train) [  8800/320000]  base_lr: 9.7522e-05 lr: 9.7522e-06  eta: 1 day, 18:22:06  time: 0.4902  data_time: 0.0104  memory: 5907  grad_norm: 143.1192  loss: 9.3681  decode.loss_cls: 0.2089  decode.loss_mask: 0.2847  decode.loss_dice: 0.3407  decode.d0.loss_cls: 1.2159  decode.d0.loss_mask: 0.3111  decode.d0.loss_dice: 0.3693  decode.d1.loss_cls: 0.3853  decode.d1.loss_mask: 0.2832  decode.d1.loss_dice: 0.3478  decode.d2.loss_cls: 0.2123  decode.d2.loss_mask: 0.2807  decode.d2.loss_dice: 0.3348  decode.d3.loss_cls: 0.1737  decode.d3.loss_mask: 0.2773  decode.d3.loss_dice: 0.3325  decode.d4.loss_cls: 0.1810  decode.d4.loss_mask: 0.2763  decode.d4.loss_dice: 0.3334  decode.d5.loss_cls: 0.1787  decode.d5.loss_mask: 0.2777  decode.d5.loss_dice: 0.3321  decode.d6.loss_cls: 0.1779  decode.d6.loss_mask: 0.2815  decode.d6.loss_dice: 0.3228  decode.d7.loss_cls: 0.1839  decode.d7.loss_mask: 0.2803  decode.d7.loss_dice: 0.3396  decode.d8.loss_cls: 0.2008  decode.d8.loss_mask: 0.2853  decode.d8.loss_dice: 0.3584
08/06 03:29:05 - mmengine - INFO - Iter(train) [  8850/320000]  base_lr: 9.7508e-05 lr: 9.7508e-06  eta: 1 day, 18:21:42  time: 0.4909  data_time: 0.0104  memory: 5892  grad_norm: 247.4777  loss: 14.6181  decode.loss_cls: 0.5951  decode.loss_mask: 0.3964  decode.loss_dice: 0.3517  decode.d0.loss_cls: 1.4766  decode.d0.loss_mask: 0.3668  decode.d0.loss_dice: 0.4466  decode.d1.loss_cls: 0.6731  decode.d1.loss_mask: 0.3457  decode.d1.loss_dice: 0.4485  decode.d2.loss_cls: 0.6147  decode.d2.loss_mask: 0.3329  decode.d2.loss_dice: 0.3670  decode.d3.loss_cls: 0.6189  decode.d3.loss_mask: 0.3529  decode.d3.loss_dice: 0.4162  decode.d4.loss_cls: 0.5733  decode.d4.loss_mask: 0.3638  decode.d4.loss_dice: 0.4537  decode.d5.loss_cls: 0.5863  decode.d5.loss_mask: 0.3553  decode.d5.loss_dice: 0.3899  decode.d6.loss_cls: 0.5965  decode.d6.loss_mask: 0.3674  decode.d6.loss_dice: 0.4135  decode.d7.loss_cls: 0.5567  decode.d7.loss_mask: 0.3877  decode.d7.loss_dice: 0.4197  decode.d8.loss_cls: 0.5365  decode.d8.loss_mask: 0.3918  decode.d8.loss_dice: 0.4228
08/06 03:29:29 - mmengine - INFO - Iter(train) [  8900/320000]  base_lr: 9.7494e-05 lr: 9.7494e-06  eta: 1 day, 18:21:18  time: 0.4900  data_time: 0.0100  memory: 5890  grad_norm: 185.6856  loss: 12.4849  decode.loss_cls: 0.4004  decode.loss_mask: 0.2781  decode.loss_dice: 0.4303  decode.d0.loss_cls: 1.2394  decode.d0.loss_mask: 0.2926  decode.d0.loss_dice: 0.4755  decode.d1.loss_cls: 0.5736  decode.d1.loss_mask: 0.2818  decode.d1.loss_dice: 0.4515  decode.d2.loss_cls: 0.4531  decode.d2.loss_mask: 0.2752  decode.d2.loss_dice: 0.4305  decode.d3.loss_cls: 0.4317  decode.d3.loss_mask: 0.2800  decode.d3.loss_dice: 0.4673  decode.d4.loss_cls: 0.3878  decode.d4.loss_mask: 0.2878  decode.d4.loss_dice: 0.4673  decode.d5.loss_cls: 0.4079  decode.d5.loss_mask: 0.2787  decode.d5.loss_dice: 0.4723  decode.d6.loss_cls: 0.4096  decode.d6.loss_mask: 0.2755  decode.d6.loss_dice: 0.4623  decode.d7.loss_cls: 0.3774  decode.d7.loss_mask: 0.2886  decode.d7.loss_dice: 0.4624  decode.d8.loss_cls: 0.3990  decode.d8.loss_mask: 0.2831  decode.d8.loss_dice: 0.4640
08/06 03:29:54 - mmengine - INFO - Iter(train) [  8950/320000]  base_lr: 9.7480e-05 lr: 9.7480e-06  eta: 1 day, 18:20:54  time: 0.4904  data_time: 0.0102  memory: 5908  grad_norm: 296.5033  loss: 10.9712  decode.loss_cls: 0.2880  decode.loss_mask: 0.3184  decode.loss_dice: 0.3124  decode.d0.loss_cls: 1.4092  decode.d0.loss_mask: 0.3723  decode.d0.loss_dice: 0.3805  decode.d1.loss_cls: 0.5432  decode.d1.loss_mask: 0.3427  decode.d1.loss_dice: 0.3149  decode.d2.loss_cls: 0.3024  decode.d2.loss_mask: 0.3406  decode.d2.loss_dice: 0.3293  decode.d3.loss_cls: 0.2870  decode.d3.loss_mask: 0.3431  decode.d3.loss_dice: 0.3394  decode.d4.loss_cls: 0.3458  decode.d4.loss_mask: 0.3283  decode.d4.loss_dice: 0.3286  decode.d5.loss_cls: 0.2758  decode.d5.loss_mask: 0.3267  decode.d5.loss_dice: 0.3274  decode.d6.loss_cls: 0.2742  decode.d6.loss_mask: 0.3314  decode.d6.loss_dice: 0.3211  decode.d7.loss_cls: 0.2566  decode.d7.loss_mask: 0.3364  decode.d7.loss_dice: 0.3361  decode.d8.loss_cls: 0.3180  decode.d8.loss_mask: 0.3256  decode.d8.loss_dice: 0.3157
08/06 03:30:19 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 03:30:19 - mmengine - INFO - Iter(train) [  9000/320000]  base_lr: 9.7465e-05 lr: 9.7465e-06  eta: 1 day, 18:20:36  time: 0.4906  data_time: 0.0101  memory: 5895  grad_norm: 214.1926  loss: 12.7092  decode.loss_cls: 0.4878  decode.loss_mask: 0.3004  decode.loss_dice: 0.3690  decode.d0.loss_cls: 1.3382  decode.d0.loss_mask: 0.2938  decode.d0.loss_dice: 0.3856  decode.d1.loss_cls: 0.6129  decode.d1.loss_mask: 0.3197  decode.d1.loss_dice: 0.3933  decode.d2.loss_cls: 0.4764  decode.d2.loss_mask: 0.3044  decode.d2.loss_dice: 0.3914  decode.d3.loss_cls: 0.6126  decode.d3.loss_mask: 0.2849  decode.d3.loss_dice: 0.3617  decode.d4.loss_cls: 0.4898  decode.d4.loss_mask: 0.2896  decode.d4.loss_dice: 0.3729  decode.d5.loss_cls: 0.4871  decode.d5.loss_mask: 0.2853  decode.d5.loss_dice: 0.3522  decode.d6.loss_cls: 0.5052  decode.d6.loss_mask: 0.3247  decode.d6.loss_dice: 0.3649  decode.d7.loss_cls: 0.5345  decode.d7.loss_mask: 0.3102  decode.d7.loss_dice: 0.3541  decode.d8.loss_cls: 0.4397  decode.d8.loss_mask: 0.2912  decode.d8.loss_dice: 0.3758
08/06 03:30:43 - mmengine - INFO - Iter(train) [  9050/320000]  base_lr: 9.7451e-05 lr: 9.7451e-06  eta: 1 day, 18:20:13  time: 0.4912  data_time: 0.0104  memory: 5907  grad_norm: 207.7003  loss: 12.6100  decode.loss_cls: 0.4980  decode.loss_mask: 0.2709  decode.loss_dice: 0.3881  decode.d0.loss_cls: 1.3714  decode.d0.loss_mask: 0.2711  decode.d0.loss_dice: 0.3862  decode.d1.loss_cls: 0.5808  decode.d1.loss_mask: 0.2807  decode.d1.loss_dice: 0.3798  decode.d2.loss_cls: 0.5679  decode.d2.loss_mask: 0.2690  decode.d2.loss_dice: 0.3422  decode.d3.loss_cls: 0.4615  decode.d3.loss_mask: 0.2799  decode.d3.loss_dice: 0.3735  decode.d4.loss_cls: 0.4641  decode.d4.loss_mask: 0.2862  decode.d4.loss_dice: 0.3769  decode.d5.loss_cls: 0.5178  decode.d5.loss_mask: 0.2927  decode.d5.loss_dice: 0.4065  decode.d6.loss_cls: 0.5435  decode.d6.loss_mask: 0.2666  decode.d6.loss_dice: 0.3582  decode.d7.loss_cls: 0.4905  decode.d7.loss_mask: 0.2850  decode.d7.loss_dice: 0.3967  decode.d8.loss_cls: 0.5498  decode.d8.loss_mask: 0.2775  decode.d8.loss_dice: 0.3768
08/06 03:31:08 - mmengine - INFO - Iter(train) [  9100/320000]  base_lr: 9.7437e-05 lr: 9.7437e-06  eta: 1 day, 18:19:49  time: 0.4906  data_time: 0.0105  memory: 5892  grad_norm: 434.3613  loss: 13.3855  decode.loss_cls: 0.5124  decode.loss_mask: 0.2523  decode.loss_dice: 0.4278  decode.d0.loss_cls: 1.4450  decode.d0.loss_mask: 0.2783  decode.d0.loss_dice: 0.4499  decode.d1.loss_cls: 0.7112  decode.d1.loss_mask: 0.2562  decode.d1.loss_dice: 0.4598  decode.d2.loss_cls: 0.6019  decode.d2.loss_mask: 0.2472  decode.d2.loss_dice: 0.3904  decode.d3.loss_cls: 0.6409  decode.d3.loss_mask: 0.2428  decode.d3.loss_dice: 0.4314  decode.d4.loss_cls: 0.6780  decode.d4.loss_mask: 0.2371  decode.d4.loss_dice: 0.4294  decode.d5.loss_cls: 0.5198  decode.d5.loss_mask: 0.2533  decode.d5.loss_dice: 0.4390  decode.d6.loss_cls: 0.5133  decode.d6.loss_mask: 0.2627  decode.d6.loss_dice: 0.4437  decode.d7.loss_cls: 0.4565  decode.d7.loss_mask: 0.2580  decode.d7.loss_dice: 0.4219  decode.d8.loss_cls: 0.4073  decode.d8.loss_mask: 0.2681  decode.d8.loss_dice: 0.4501
08/06 03:31:32 - mmengine - INFO - Iter(train) [  9150/320000]  base_lr: 9.7423e-05 lr: 9.7423e-06  eta: 1 day, 18:19:25  time: 0.4905  data_time: 0.0102  memory: 5893  grad_norm: 141.0023  loss: 12.6808  decode.loss_cls: 0.4962  decode.loss_mask: 0.2699  decode.loss_dice: 0.3445  decode.d0.loss_cls: 1.4596  decode.d0.loss_mask: 0.2710  decode.d0.loss_dice: 0.3840  decode.d1.loss_cls: 0.6103  decode.d1.loss_mask: 0.2995  decode.d1.loss_dice: 0.4555  decode.d2.loss_cls: 0.5171  decode.d2.loss_mask: 0.2877  decode.d2.loss_dice: 0.3731  decode.d3.loss_cls: 0.5714  decode.d3.loss_mask: 0.2618  decode.d3.loss_dice: 0.3617  decode.d4.loss_cls: 0.5071  decode.d4.loss_mask: 0.2564  decode.d4.loss_dice: 0.3428  decode.d5.loss_cls: 0.5746  decode.d5.loss_mask: 0.2676  decode.d5.loss_dice: 0.3416  decode.d6.loss_cls: 0.6144  decode.d6.loss_mask: 0.2456  decode.d6.loss_dice: 0.3197  decode.d7.loss_cls: 0.5387  decode.d7.loss_mask: 0.2549  decode.d7.loss_dice: 0.3247  decode.d8.loss_cls: 0.5510  decode.d8.loss_mask: 0.2618  decode.d8.loss_dice: 0.3165
08/06 03:31:57 - mmengine - INFO - Iter(train) [  9200/320000]  base_lr: 9.7409e-05 lr: 9.7409e-06  eta: 1 day, 18:19:00  time: 0.4910  data_time: 0.0102  memory: 5875  grad_norm: 126.6804  loss: 10.3395  decode.loss_cls: 0.3361  decode.loss_mask: 0.2428  decode.loss_dice: 0.3067  decode.d0.loss_cls: 1.3654  decode.d0.loss_mask: 0.2855  decode.d0.loss_dice: 0.3757  decode.d1.loss_cls: 0.4721  decode.d1.loss_mask: 0.2278  decode.d1.loss_dice: 0.3560  decode.d2.loss_cls: 0.4595  decode.d2.loss_mask: 0.2351  decode.d2.loss_dice: 0.3105  decode.d3.loss_cls: 0.4044  decode.d3.loss_mask: 0.2410  decode.d3.loss_dice: 0.3150  decode.d4.loss_cls: 0.3334  decode.d4.loss_mask: 0.2257  decode.d4.loss_dice: 0.3146  decode.d5.loss_cls: 0.3669  decode.d5.loss_mask: 0.2243  decode.d5.loss_dice: 0.3065  decode.d6.loss_cls: 0.3163  decode.d6.loss_mask: 0.2245  decode.d6.loss_dice: 0.3224  decode.d7.loss_cls: 0.3646  decode.d7.loss_mask: 0.2225  decode.d7.loss_dice: 0.3345  decode.d8.loss_cls: 0.3227  decode.d8.loss_mask: 0.2223  decode.d8.loss_dice: 0.3046
08/06 03:32:21 - mmengine - INFO - Iter(train) [  9250/320000]  base_lr: 9.7395e-05 lr: 9.7395e-06  eta: 1 day, 18:18:37  time: 0.4899  data_time: 0.0103  memory: 5889  grad_norm: 181.2685  loss: 10.1393  decode.loss_cls: 0.2892  decode.loss_mask: 0.2940  decode.loss_dice: 0.3224  decode.d0.loss_cls: 1.1034  decode.d0.loss_mask: 0.3076  decode.d0.loss_dice: 0.3264  decode.d1.loss_cls: 0.3508  decode.d1.loss_mask: 0.3083  decode.d1.loss_dice: 0.3246  decode.d2.loss_cls: 0.2963  decode.d2.loss_mask: 0.2989  decode.d2.loss_dice: 0.2927  decode.d3.loss_cls: 0.3001  decode.d3.loss_mask: 0.2993  decode.d3.loss_dice: 0.3077  decode.d4.loss_cls: 0.3456  decode.d4.loss_mask: 0.3042  decode.d4.loss_dice: 0.3097  decode.d5.loss_cls: 0.3654  decode.d5.loss_mask: 0.2956  decode.d5.loss_dice: 0.3017  decode.d6.loss_cls: 0.3329  decode.d6.loss_mask: 0.2974  decode.d6.loss_dice: 0.3152  decode.d7.loss_cls: 0.2949  decode.d7.loss_mask: 0.3023  decode.d7.loss_dice: 0.3084  decode.d8.loss_cls: 0.3275  decode.d8.loss_mask: 0.3016  decode.d8.loss_dice: 0.3152
08/06 03:32:46 - mmengine - INFO - Iter(train) [  9300/320000]  base_lr: 9.7381e-05 lr: 9.7381e-06  eta: 1 day, 18:18:13  time: 0.4902  data_time: 0.0101  memory: 5908  grad_norm: 645.7767  loss: 10.5960  decode.loss_cls: 0.3219  decode.loss_mask: 0.2921  decode.loss_dice: 0.3399  decode.d0.loss_cls: 1.2048  decode.d0.loss_mask: 0.2948  decode.d0.loss_dice: 0.3535  decode.d1.loss_cls: 0.4029  decode.d1.loss_mask: 0.2836  decode.d1.loss_dice: 0.3542  decode.d2.loss_cls: 0.3497  decode.d2.loss_mask: 0.2636  decode.d2.loss_dice: 0.3188  decode.d3.loss_cls: 0.3707  decode.d3.loss_mask: 0.2767  decode.d3.loss_dice: 0.3112  decode.d4.loss_cls: 0.3950  decode.d4.loss_mask: 0.2877  decode.d4.loss_dice: 0.3238  decode.d5.loss_cls: 0.3601  decode.d5.loss_mask: 0.2882  decode.d5.loss_dice: 0.3214  decode.d6.loss_cls: 0.3946  decode.d6.loss_mask: 0.2715  decode.d6.loss_dice: 0.3197  decode.d7.loss_cls: 0.3524  decode.d7.loss_mask: 0.2718  decode.d7.loss_dice: 0.3257  decode.d8.loss_cls: 0.3444  decode.d8.loss_mask: 0.2732  decode.d8.loss_dice: 0.3281
08/06 03:33:10 - mmengine - INFO - Iter(train) [  9350/320000]  base_lr: 9.7367e-05 lr: 9.7367e-06  eta: 1 day, 18:17:49  time: 0.4908  data_time: 0.0102  memory: 5875  grad_norm: 188.1533  loss: 12.2213  decode.loss_cls: 0.3901  decode.loss_mask: 0.4224  decode.loss_dice: 0.3793  decode.d0.loss_cls: 1.4374  decode.d0.loss_mask: 0.3776  decode.d0.loss_dice: 0.3700  decode.d1.loss_cls: 0.6250  decode.d1.loss_mask: 0.3611  decode.d1.loss_dice: 0.3444  decode.d2.loss_cls: 0.4529  decode.d2.loss_mask: 0.3339  decode.d2.loss_dice: 0.3256  decode.d3.loss_cls: 0.3892  decode.d3.loss_mask: 0.3529  decode.d3.loss_dice: 0.3242  decode.d4.loss_cls: 0.3871  decode.d4.loss_mask: 0.3694  decode.d4.loss_dice: 0.3478  decode.d5.loss_cls: 0.3585  decode.d5.loss_mask: 0.3545  decode.d5.loss_dice: 0.3462  decode.d6.loss_cls: 0.3331  decode.d6.loss_mask: 0.3408  decode.d6.loss_dice: 0.3458  decode.d7.loss_cls: 0.4001  decode.d7.loss_mask: 0.3402  decode.d7.loss_dice: 0.3426  decode.d8.loss_cls: 0.3671  decode.d8.loss_mask: 0.3609  decode.d8.loss_dice: 0.3411
08/06 03:33:35 - mmengine - INFO - Iter(train) [  9400/320000]  base_lr: 9.7353e-05 lr: 9.7353e-06  eta: 1 day, 18:17:27  time: 0.4918  data_time: 0.0100  memory: 5907  grad_norm: 134.5311  loss: 11.1443  decode.loss_cls: 0.3977  decode.loss_mask: 0.2543  decode.loss_dice: 0.3280  decode.d0.loss_cls: 1.4650  decode.d0.loss_mask: 0.2512  decode.d0.loss_dice: 0.3449  decode.d1.loss_cls: 0.4065  decode.d1.loss_mask: 0.2626  decode.d1.loss_dice: 0.3698  decode.d2.loss_cls: 0.4058  decode.d2.loss_mask: 0.2546  decode.d2.loss_dice: 0.3520  decode.d3.loss_cls: 0.4151  decode.d3.loss_mask: 0.2540  decode.d3.loss_dice: 0.3270  decode.d4.loss_cls: 0.4343  decode.d4.loss_mask: 0.2533  decode.d4.loss_dice: 0.3329  decode.d5.loss_cls: 0.4243  decode.d5.loss_mask: 0.2509  decode.d5.loss_dice: 0.3317  decode.d6.loss_cls: 0.4159  decode.d6.loss_mask: 0.2531  decode.d6.loss_dice: 0.3365  decode.d7.loss_cls: 0.4306  decode.d7.loss_mask: 0.2526  decode.d7.loss_dice: 0.3311  decode.d8.loss_cls: 0.4114  decode.d8.loss_mask: 0.2556  decode.d8.loss_dice: 0.3419
08/06 03:33:59 - mmengine - INFO - Iter(train) [  9450/320000]  base_lr: 9.7338e-05 lr: 9.7338e-06  eta: 1 day, 18:17:03  time: 0.4904  data_time: 0.0100  memory: 5908  grad_norm: 252.6571  loss: 12.4406  decode.loss_cls: 0.4859  decode.loss_mask: 0.3141  decode.loss_dice: 0.3840  decode.d0.loss_cls: 1.1735  decode.d0.loss_mask: 0.3584  decode.d0.loss_dice: 0.4055  decode.d1.loss_cls: 0.5489  decode.d1.loss_mask: 0.3520  decode.d1.loss_dice: 0.3801  decode.d2.loss_cls: 0.4533  decode.d2.loss_mask: 0.3374  decode.d2.loss_dice: 0.3833  decode.d3.loss_cls: 0.4711  decode.d3.loss_mask: 0.3094  decode.d3.loss_dice: 0.3609  decode.d4.loss_cls: 0.4471  decode.d4.loss_mask: 0.3095  decode.d4.loss_dice: 0.3498  decode.d5.loss_cls: 0.4656  decode.d5.loss_mask: 0.3079  decode.d5.loss_dice: 0.3506  decode.d6.loss_cls: 0.4472  decode.d6.loss_mask: 0.3160  decode.d6.loss_dice: 0.3754  decode.d7.loss_cls: 0.4720  decode.d7.loss_mask: 0.3148  decode.d7.loss_dice: 0.3853  decode.d8.loss_cls: 0.4720  decode.d8.loss_mask: 0.3175  decode.d8.loss_dice: 0.3922
08/06 03:34:24 - mmengine - INFO - Iter(train) [  9500/320000]  base_lr: 9.7324e-05 lr: 9.7324e-06  eta: 1 day, 18:16:38  time: 0.4903  data_time: 0.0101  memory: 5892  grad_norm: 331.6978  loss: 12.4497  decode.loss_cls: 0.4113  decode.loss_mask: 0.3210  decode.loss_dice: 0.3873  decode.d0.loss_cls: 1.1781  decode.d0.loss_mask: 0.3781  decode.d0.loss_dice: 0.4442  decode.d1.loss_cls: 0.5183  decode.d1.loss_mask: 0.3360  decode.d1.loss_dice: 0.4107  decode.d2.loss_cls: 0.4329  decode.d2.loss_mask: 0.3403  decode.d2.loss_dice: 0.4024  decode.d3.loss_cls: 0.4688  decode.d3.loss_mask: 0.3276  decode.d3.loss_dice: 0.4170  decode.d4.loss_cls: 0.4157  decode.d4.loss_mask: 0.3549  decode.d4.loss_dice: 0.4103  decode.d5.loss_cls: 0.3906  decode.d5.loss_mask: 0.3406  decode.d5.loss_dice: 0.4224  decode.d6.loss_cls: 0.3545  decode.d6.loss_mask: 0.3387  decode.d6.loss_dice: 0.3978  decode.d7.loss_cls: 0.3668  decode.d7.loss_mask: 0.3310  decode.d7.loss_dice: 0.3923  decode.d8.loss_cls: 0.4340  decode.d8.loss_mask: 0.3358  decode.d8.loss_dice: 0.3904
08/06 03:34:48 - mmengine - INFO - Iter(train) [  9550/320000]  base_lr: 9.7310e-05 lr: 9.7310e-06  eta: 1 day, 18:16:15  time: 0.4909  data_time: 0.0103  memory: 5907  grad_norm: 135.7227  loss: 10.7678  decode.loss_cls: 0.3944  decode.loss_mask: 0.2968  decode.loss_dice: 0.3437  decode.d0.loss_cls: 1.1487  decode.d0.loss_mask: 0.2982  decode.d0.loss_dice: 0.3403  decode.d1.loss_cls: 0.5029  decode.d1.loss_mask: 0.2894  decode.d1.loss_dice: 0.2935  decode.d2.loss_cls: 0.4097  decode.d2.loss_mask: 0.2831  decode.d2.loss_dice: 0.3043  decode.d3.loss_cls: 0.4308  decode.d3.loss_mask: 0.2835  decode.d3.loss_dice: 0.2909  decode.d4.loss_cls: 0.3711  decode.d4.loss_mask: 0.2953  decode.d4.loss_dice: 0.3143  decode.d5.loss_cls: 0.3839  decode.d5.loss_mask: 0.2991  decode.d5.loss_dice: 0.2866  decode.d6.loss_cls: 0.3555  decode.d6.loss_mask: 0.2920  decode.d6.loss_dice: 0.2939  decode.d7.loss_cls: 0.3875  decode.d7.loss_mask: 0.2943  decode.d7.loss_dice: 0.2812  decode.d8.loss_cls: 0.4096  decode.d8.loss_mask: 0.2838  decode.d8.loss_dice: 0.3095
08/06 03:35:13 - mmengine - INFO - Iter(train) [  9600/320000]  base_lr: 9.7296e-05 lr: 9.7296e-06  eta: 1 day, 18:15:54  time: 0.4912  data_time: 0.0100  memory: 5908  grad_norm: 173.3155  loss: 8.7506  decode.loss_cls: 0.2015  decode.loss_mask: 0.2419  decode.loss_dice: 0.3325  decode.d0.loss_cls: 1.1221  decode.d0.loss_mask: 0.2577  decode.d0.loss_dice: 0.3775  decode.d1.loss_cls: 0.3178  decode.d1.loss_mask: 0.2437  decode.d1.loss_dice: 0.3402  decode.d2.loss_cls: 0.2178  decode.d2.loss_mask: 0.2524  decode.d2.loss_dice: 0.3347  decode.d3.loss_cls: 0.1721  decode.d3.loss_mask: 0.2448  decode.d3.loss_dice: 0.3234  decode.d4.loss_cls: 0.1953  decode.d4.loss_mask: 0.2498  decode.d4.loss_dice: 0.3266  decode.d5.loss_cls: 0.1495  decode.d5.loss_mask: 0.2459  decode.d5.loss_dice: 0.3402  decode.d6.loss_cls: 0.1918  decode.d6.loss_mask: 0.2407  decode.d6.loss_dice: 0.3332  decode.d7.loss_cls: 0.1689  decode.d7.loss_mask: 0.2446  decode.d7.loss_dice: 0.3400  decode.d8.loss_cls: 0.1694  decode.d8.loss_mask: 0.2402  decode.d8.loss_dice: 0.3345
08/06 03:35:38 - mmengine - INFO - Iter(train) [  9650/320000]  base_lr: 9.7282e-05 lr: 9.7282e-06  eta: 1 day, 18:15:31  time: 0.4911  data_time: 0.0103  memory: 5926  grad_norm: 240.5395  loss: 12.1256  decode.loss_cls: 0.4257  decode.loss_mask: 0.2965  decode.loss_dice: 0.3739  decode.d0.loss_cls: 1.4468  decode.d0.loss_mask: 0.3043  decode.d0.loss_dice: 0.4069  decode.d1.loss_cls: 0.4429  decode.d1.loss_mask: 0.2944  decode.d1.loss_dice: 0.3781  decode.d2.loss_cls: 0.3418  decode.d2.loss_mask: 0.2773  decode.d2.loss_dice: 0.3525  decode.d3.loss_cls: 0.4261  decode.d3.loss_mask: 0.2849  decode.d3.loss_dice: 0.3582  decode.d4.loss_cls: 0.3808  decode.d4.loss_mask: 0.3593  decode.d4.loss_dice: 0.3766  decode.d5.loss_cls: 0.4045  decode.d5.loss_mask: 0.3377  decode.d5.loss_dice: 0.3821  decode.d6.loss_cls: 0.4569  decode.d6.loss_mask: 0.3394  decode.d6.loss_dice: 0.3766  decode.d7.loss_cls: 0.4469  decode.d7.loss_mask: 0.3563  decode.d7.loss_dice: 0.3855  decode.d8.loss_cls: 0.3822  decode.d8.loss_mask: 0.3468  decode.d8.loss_dice: 0.3834
08/06 03:36:02 - mmengine - INFO - Iter(train) [  9700/320000]  base_lr: 9.7268e-05 lr: 9.7268e-06  eta: 1 day, 18:15:07  time: 0.4906  data_time: 0.0103  memory: 5892  grad_norm: 559.5118  loss: 10.9666  decode.loss_cls: 0.2891  decode.loss_mask: 0.3508  decode.loss_dice: 0.3231  decode.d0.loss_cls: 1.1391  decode.d0.loss_mask: 0.4293  decode.d0.loss_dice: 0.3753  decode.d1.loss_cls: 0.4302  decode.d1.loss_mask: 0.3836  decode.d1.loss_dice: 0.3489  decode.d2.loss_cls: 0.2938  decode.d2.loss_mask: 0.3606  decode.d2.loss_dice: 0.3323  decode.d3.loss_cls: 0.2611  decode.d3.loss_mask: 0.3694  decode.d3.loss_dice: 0.3391  decode.d4.loss_cls: 0.2574  decode.d4.loss_mask: 0.3672  decode.d4.loss_dice: 0.3367  decode.d5.loss_cls: 0.3072  decode.d5.loss_mask: 0.3701  decode.d5.loss_dice: 0.3267  decode.d6.loss_cls: 0.3035  decode.d6.loss_mask: 0.3640  decode.d6.loss_dice: 0.3260  decode.d7.loss_cls: 0.3108  decode.d7.loss_mask: 0.3659  decode.d7.loss_dice: 0.3433  decode.d8.loss_cls: 0.2622  decode.d8.loss_mask: 0.3486  decode.d8.loss_dice: 0.3514
08/06 03:36:27 - mmengine - INFO - Iter(train) [  9750/320000]  base_lr: 9.7254e-05 lr: 9.7254e-06  eta: 1 day, 18:14:43  time: 0.4893  data_time: 0.0102  memory: 5928  grad_norm: 140.7236  loss: 10.8678  decode.loss_cls: 0.3395  decode.loss_mask: 0.3286  decode.loss_dice: 0.3398  decode.d0.loss_cls: 1.2426  decode.d0.loss_mask: 0.3044  decode.d0.loss_dice: 0.3457  decode.d1.loss_cls: 0.4133  decode.d1.loss_mask: 0.3260  decode.d1.loss_dice: 0.3453  decode.d2.loss_cls: 0.3246  decode.d2.loss_mask: 0.3102  decode.d2.loss_dice: 0.3362  decode.d3.loss_cls: 0.3286  decode.d3.loss_mask: 0.3207  decode.d3.loss_dice: 0.3444  decode.d4.loss_cls: 0.2504  decode.d4.loss_mask: 0.3177  decode.d4.loss_dice: 0.3457  decode.d5.loss_cls: 0.2808  decode.d5.loss_mask: 0.3164  decode.d5.loss_dice: 0.3831  decode.d6.loss_cls: 0.2860  decode.d6.loss_mask: 0.3931  decode.d6.loss_dice: 0.4059  decode.d7.loss_cls: 0.2733  decode.d7.loss_mask: 0.3106  decode.d7.loss_dice: 0.3590  decode.d8.loss_cls: 0.3255  decode.d8.loss_mask: 0.3229  decode.d8.loss_dice: 0.3474
08/06 03:36:51 - mmengine - INFO - Iter(train) [  9800/320000]  base_lr: 9.7240e-05 lr: 9.7240e-06  eta: 1 day, 18:14:20  time: 0.4908  data_time: 0.0104  memory: 5907  grad_norm: 131.1251  loss: 9.3354  decode.loss_cls: 0.2536  decode.loss_mask: 0.2951  decode.loss_dice: 0.3002  decode.d0.loss_cls: 1.1156  decode.d0.loss_mask: 0.2807  decode.d0.loss_dice: 0.3306  decode.d1.loss_cls: 0.4016  decode.d1.loss_mask: 0.2973  decode.d1.loss_dice: 0.3054  decode.d2.loss_cls: 0.2749  decode.d2.loss_mask: 0.2680  decode.d2.loss_dice: 0.2979  decode.d3.loss_cls: 0.2661  decode.d3.loss_mask: 0.2546  decode.d3.loss_dice: 0.2735  decode.d4.loss_cls: 0.2437  decode.d4.loss_mask: 0.2593  decode.d4.loss_dice: 0.2768  decode.d5.loss_cls: 0.2941  decode.d5.loss_mask: 0.2648  decode.d5.loss_dice: 0.2947  decode.d6.loss_cls: 0.2875  decode.d6.loss_mask: 0.2625  decode.d6.loss_dice: 0.2802  decode.d7.loss_cls: 0.2710  decode.d7.loss_mask: 0.2754  decode.d7.loss_dice: 0.2941  decode.d8.loss_cls: 0.2609  decode.d8.loss_mask: 0.2616  decode.d8.loss_dice: 0.2935
08/06 03:37:16 - mmengine - INFO - Iter(train) [  9850/320000]  base_lr: 9.7226e-05 lr: 9.7226e-06  eta: 1 day, 18:13:56  time: 0.4908  data_time: 0.0104  memory: 5892  grad_norm: 380.5848  loss: 10.9883  decode.loss_cls: 0.3765  decode.loss_mask: 0.2899  decode.loss_dice: 0.3217  decode.d0.loss_cls: 1.2396  decode.d0.loss_mask: 0.2887  decode.d0.loss_dice: 0.3236  decode.d1.loss_cls: 0.3953  decode.d1.loss_mask: 0.2810  decode.d1.loss_dice: 0.2889  decode.d2.loss_cls: 0.3947  decode.d2.loss_mask: 0.3713  decode.d2.loss_dice: 0.3723  decode.d3.loss_cls: 0.4066  decode.d3.loss_mask: 0.3259  decode.d3.loss_dice: 0.3576  decode.d4.loss_cls: 0.3447  decode.d4.loss_mask: 0.3404  decode.d4.loss_dice: 0.3688  decode.d5.loss_cls: 0.3465  decode.d5.loss_mask: 0.3220  decode.d5.loss_dice: 0.3446  decode.d6.loss_cls: 0.3265  decode.d6.loss_mask: 0.2933  decode.d6.loss_dice: 0.3245  decode.d7.loss_cls: 0.3528  decode.d7.loss_mask: 0.2892  decode.d7.loss_dice: 0.3096  decode.d8.loss_cls: 0.3524  decode.d8.loss_mask: 0.2918  decode.d8.loss_dice: 0.3476
08/06 03:37:40 - mmengine - INFO - Iter(train) [  9900/320000]  base_lr: 9.7212e-05 lr: 9.7212e-06  eta: 1 day, 18:13:33  time: 0.4910  data_time: 0.0103  memory: 5907  grad_norm: 129.6295  loss: 10.1910  decode.loss_cls: 0.3972  decode.loss_mask: 0.2185  decode.loss_dice: 0.3083  decode.d0.loss_cls: 1.1638  decode.d0.loss_mask: 0.2265  decode.d0.loss_dice: 0.3354  decode.d1.loss_cls: 0.4660  decode.d1.loss_mask: 0.2243  decode.d1.loss_dice: 0.3134  decode.d2.loss_cls: 0.4541  decode.d2.loss_mask: 0.2189  decode.d2.loss_dice: 0.3056  decode.d3.loss_cls: 0.4114  decode.d3.loss_mask: 0.2176  decode.d3.loss_dice: 0.3090  decode.d4.loss_cls: 0.3875  decode.d4.loss_mask: 0.2213  decode.d4.loss_dice: 0.3050  decode.d5.loss_cls: 0.4155  decode.d5.loss_mask: 0.2209  decode.d5.loss_dice: 0.3045  decode.d6.loss_cls: 0.3757  decode.d6.loss_mask: 0.2186  decode.d6.loss_dice: 0.2929  decode.d7.loss_cls: 0.3747  decode.d7.loss_mask: 0.2173  decode.d7.loss_dice: 0.3280  decode.d8.loss_cls: 0.4299  decode.d8.loss_mask: 0.2218  decode.d8.loss_dice: 0.3073
08/06 03:38:05 - mmengine - INFO - Iter(train) [  9950/320000]  base_lr: 9.7197e-05 lr: 9.7197e-06  eta: 1 day, 18:13:10  time: 0.4918  data_time: 0.0103  memory: 5927  grad_norm: 194.6681  loss: 10.9587  decode.loss_cls: 0.3906  decode.loss_mask: 0.2916  decode.loss_dice: 0.3135  decode.d0.loss_cls: 1.2058  decode.d0.loss_mask: 0.2717  decode.d0.loss_dice: 0.3186  decode.d1.loss_cls: 0.4666  decode.d1.loss_mask: 0.2765  decode.d1.loss_dice: 0.3394  decode.d2.loss_cls: 0.4287  decode.d2.loss_mask: 0.2728  decode.d2.loss_dice: 0.3075  decode.d3.loss_cls: 0.4274  decode.d3.loss_mask: 0.2696  decode.d3.loss_dice: 0.2886  decode.d4.loss_cls: 0.4114  decode.d4.loss_mask: 0.2760  decode.d4.loss_dice: 0.3125  decode.d5.loss_cls: 0.4098  decode.d5.loss_mask: 0.2755  decode.d5.loss_dice: 0.3072  decode.d6.loss_cls: 0.4591  decode.d6.loss_mask: 0.2754  decode.d6.loss_dice: 0.3008  decode.d7.loss_cls: 0.4223  decode.d7.loss_mask: 0.2799  decode.d7.loss_dice: 0.3170  decode.d8.loss_cls: 0.4460  decode.d8.loss_mask: 0.2779  decode.d8.loss_dice: 0.3190
08/06 03:38:29 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 03:38:29 - mmengine - INFO - Iter(train) [ 10000/320000]  base_lr: 9.7183e-05 lr: 9.7183e-06  eta: 1 day, 18:12:46  time: 0.4908  data_time: 0.0104  memory: 5892  grad_norm: 240.8277  loss: 13.9690  decode.loss_cls: 0.3640  decode.loss_mask: 0.3884  decode.loss_dice: 0.4520  decode.d0.loss_cls: 1.3247  decode.d0.loss_mask: 0.4239  decode.d0.loss_dice: 0.4871  decode.d1.loss_cls: 0.5998  decode.d1.loss_mask: 0.4038  decode.d1.loss_dice: 0.4425  decode.d2.loss_cls: 0.5321  decode.d2.loss_mask: 0.3827  decode.d2.loss_dice: 0.4119  decode.d3.loss_cls: 0.5355  decode.d3.loss_mask: 0.3782  decode.d3.loss_dice: 0.3990  decode.d4.loss_cls: 0.4126  decode.d4.loss_mask: 0.4171  decode.d4.loss_dice: 0.4738  decode.d5.loss_cls: 0.4798  decode.d5.loss_mask: 0.4032  decode.d5.loss_dice: 0.4736  decode.d6.loss_cls: 0.3714  decode.d6.loss_mask: 0.3857  decode.d6.loss_dice: 0.4593  decode.d7.loss_cls: 0.4221  decode.d7.loss_mask: 0.3991  decode.d7.loss_dice: 0.4749  decode.d8.loss_cls: 0.3969  decode.d8.loss_mask: 0.4063  decode.d8.loss_dice: 0.4677
08/06 03:38:54 - mmengine - INFO - Iter(train) [ 10050/320000]  base_lr: 9.7169e-05 lr: 9.7169e-06  eta: 1 day, 18:12:21  time: 0.4900  data_time: 0.0104  memory: 5877  grad_norm: 268.1468  loss: 13.7457  decode.loss_cls: 0.5398  decode.loss_mask: 0.3376  decode.loss_dice: 0.4381  decode.d0.loss_cls: 1.3080  decode.d0.loss_mask: 0.3573  decode.d0.loss_dice: 0.4626  decode.d1.loss_cls: 0.5017  decode.d1.loss_mask: 0.3368  decode.d1.loss_dice: 0.4218  decode.d2.loss_cls: 0.4935  decode.d2.loss_mask: 0.3349  decode.d2.loss_dice: 0.4165  decode.d3.loss_cls: 0.5380  decode.d3.loss_mask: 0.3291  decode.d3.loss_dice: 0.4191  decode.d4.loss_cls: 0.4771  decode.d4.loss_mask: 0.3282  decode.d4.loss_dice: 0.4075  decode.d5.loss_cls: 0.5248  decode.d5.loss_mask: 0.3480  decode.d5.loss_dice: 0.4534  decode.d6.loss_cls: 0.5942  decode.d6.loss_mask: 0.3290  decode.d6.loss_dice: 0.4589  decode.d7.loss_cls: 0.5166  decode.d7.loss_mask: 0.3191  decode.d7.loss_dice: 0.4215  decode.d8.loss_cls: 0.5346  decode.d8.loss_mask: 0.3589  decode.d8.loss_dice: 0.4392
08/06 03:39:18 - mmengine - INFO - Iter(train) [ 10100/320000]  base_lr: 9.7155e-05 lr: 9.7155e-06  eta: 1 day, 18:11:57  time: 0.4904  data_time: 0.0100  memory: 5926  grad_norm: 167.3974  loss: 11.2399  decode.loss_cls: 0.3839  decode.loss_mask: 0.2759  decode.loss_dice: 0.3682  decode.d0.loss_cls: 1.2317  decode.d0.loss_mask: 0.2660  decode.d0.loss_dice: 0.3514  decode.d1.loss_cls: 0.5020  decode.d1.loss_mask: 0.2608  decode.d1.loss_dice: 0.3651  decode.d2.loss_cls: 0.5361  decode.d2.loss_mask: 0.2582  decode.d2.loss_dice: 0.3468  decode.d3.loss_cls: 0.3254  decode.d3.loss_mask: 0.2703  decode.d3.loss_dice: 0.3788  decode.d4.loss_cls: 0.3784  decode.d4.loss_mask: 0.2651  decode.d4.loss_dice: 0.3784  decode.d5.loss_cls: 0.3706  decode.d5.loss_mask: 0.2757  decode.d5.loss_dice: 0.3832  decode.d6.loss_cls: 0.3468  decode.d6.loss_mask: 0.2601  decode.d6.loss_dice: 0.3485  decode.d7.loss_cls: 0.3947  decode.d7.loss_mask: 0.2735  decode.d7.loss_dice: 0.3425  decode.d8.loss_cls: 0.4359  decode.d8.loss_mask: 0.2747  decode.d8.loss_dice: 0.3912
08/06 03:39:43 - mmengine - INFO - Iter(train) [ 10150/320000]  base_lr: 9.7141e-05 lr: 9.7141e-06  eta: 1 day, 18:11:36  time: 0.4903  data_time: 0.0104  memory: 5890  grad_norm: 143.9217  loss: 12.7270  decode.loss_cls: 0.4981  decode.loss_mask: 0.3407  decode.loss_dice: 0.4139  decode.d0.loss_cls: 1.1803  decode.d0.loss_mask: 0.3634  decode.d0.loss_dice: 0.3979  decode.d1.loss_cls: 0.4329  decode.d1.loss_mask: 0.3593  decode.d1.loss_dice: 0.4336  decode.d2.loss_cls: 0.4321  decode.d2.loss_mask: 0.3540  decode.d2.loss_dice: 0.3957  decode.d3.loss_cls: 0.3494  decode.d3.loss_mask: 0.3484  decode.d3.loss_dice: 0.3870  decode.d4.loss_cls: 0.3888  decode.d4.loss_mask: 0.3550  decode.d4.loss_dice: 0.3998  decode.d5.loss_cls: 0.4565  decode.d5.loss_mask: 0.3474  decode.d5.loss_dice: 0.4120  decode.d6.loss_cls: 0.4355  decode.d6.loss_mask: 0.3438  decode.d6.loss_dice: 0.4028  decode.d7.loss_cls: 0.4984  decode.d7.loss_mask: 0.3473  decode.d7.loss_dice: 0.3876  decode.d8.loss_cls: 0.5263  decode.d8.loss_mask: 0.3453  decode.d8.loss_dice: 0.3937
08/06 03:40:08 - mmengine - INFO - Iter(train) [ 10200/320000]  base_lr: 9.7127e-05 lr: 9.7127e-06  eta: 1 day, 18:11:12  time: 0.4898  data_time: 0.0104  memory: 5890  grad_norm: 227.0243  loss: 9.9595  decode.loss_cls: 0.2369  decode.loss_mask: 0.3539  decode.loss_dice: 0.2922  decode.d0.loss_cls: 1.1204  decode.d0.loss_mask: 0.3450  decode.d0.loss_dice: 0.3266  decode.d1.loss_cls: 0.3061  decode.d1.loss_mask: 0.3415  decode.d1.loss_dice: 0.3179  decode.d2.loss_cls: 0.2518  decode.d2.loss_mask: 0.3321  decode.d2.loss_dice: 0.2835  decode.d3.loss_cls: 0.2508  decode.d3.loss_mask: 0.3311  decode.d3.loss_dice: 0.2820  decode.d4.loss_cls: 0.2750  decode.d4.loss_mask: 0.3377  decode.d4.loss_dice: 0.2883  decode.d5.loss_cls: 0.2453  decode.d5.loss_mask: 0.3346  decode.d5.loss_dice: 0.2897  decode.d6.loss_cls: 0.2892  decode.d6.loss_mask: 0.3290  decode.d6.loss_dice: 0.2801  decode.d7.loss_cls: 0.2505  decode.d7.loss_mask: 0.3735  decode.d7.loss_dice: 0.3150  decode.d8.loss_cls: 0.3012  decode.d8.loss_mask: 0.3602  decode.d8.loss_dice: 0.3184
08/06 03:40:32 - mmengine - INFO - Iter(train) [ 10250/320000]  base_lr: 9.7113e-05 lr: 9.7113e-06  eta: 1 day, 18:10:48  time: 0.4915  data_time: 0.0105  memory: 5926  grad_norm: 130.4409  loss: 8.4476  decode.loss_cls: 0.2307  decode.loss_mask: 0.2390  decode.loss_dice: 0.3112  decode.d0.loss_cls: 1.1584  decode.d0.loss_mask: 0.2496  decode.d0.loss_dice: 0.3507  decode.d1.loss_cls: 0.2353  decode.d1.loss_mask: 0.2304  decode.d1.loss_dice: 0.3039  decode.d2.loss_cls: 0.2045  decode.d2.loss_mask: 0.2199  decode.d2.loss_dice: 0.2740  decode.d3.loss_cls: 0.2156  decode.d3.loss_mask: 0.2206  decode.d3.loss_dice: 0.2786  decode.d4.loss_cls: 0.2186  decode.d4.loss_mask: 0.2212  decode.d4.loss_dice: 0.2932  decode.d5.loss_cls: 0.1742  decode.d5.loss_mask: 0.2578  decode.d5.loss_dice: 0.3137  decode.d6.loss_cls: 0.2282  decode.d6.loss_mask: 0.2443  decode.d6.loss_dice: 0.2919  decode.d7.loss_cls: 0.2005  decode.d7.loss_mask: 0.2403  decode.d7.loss_dice: 0.2901  decode.d8.loss_cls: 0.1991  decode.d8.loss_mask: 0.2512  decode.d8.loss_dice: 0.3008
08/06 03:40:57 - mmengine - INFO - Iter(train) [ 10300/320000]  base_lr: 9.7099e-05 lr: 9.7099e-06  eta: 1 day, 18:10:24  time: 0.4906  data_time: 0.0104  memory: 5892  grad_norm: 157.5294  loss: 11.4961  decode.loss_cls: 0.3140  decode.loss_mask: 0.3754  decode.loss_dice: 0.3554  decode.d0.loss_cls: 1.2841  decode.d0.loss_mask: 0.3258  decode.d0.loss_dice: 0.4123  decode.d1.loss_cls: 0.3512  decode.d1.loss_mask: 0.3284  decode.d1.loss_dice: 0.3765  decode.d2.loss_cls: 0.2918  decode.d2.loss_mask: 0.3405  decode.d2.loss_dice: 0.3973  decode.d3.loss_cls: 0.3392  decode.d3.loss_mask: 0.3602  decode.d3.loss_dice: 0.3433  decode.d4.loss_cls: 0.3429  decode.d4.loss_mask: 0.3513  decode.d4.loss_dice: 0.3394  decode.d5.loss_cls: 0.3107  decode.d5.loss_mask: 0.3347  decode.d5.loss_dice: 0.3626  decode.d6.loss_cls: 0.3372  decode.d6.loss_mask: 0.3476  decode.d6.loss_dice: 0.3696  decode.d7.loss_cls: 0.4050  decode.d7.loss_mask: 0.3374  decode.d7.loss_dice: 0.3664  decode.d8.loss_cls: 0.4039  decode.d8.loss_mask: 0.3529  decode.d8.loss_dice: 0.3391
08/06 03:41:21 - mmengine - INFO - Iter(train) [ 10350/320000]  base_lr: 9.7085e-05 lr: 9.7085e-06  eta: 1 day, 18:10:00  time: 0.4900  data_time: 0.0103  memory: 5908  grad_norm: 142.1896  loss: 10.5783  decode.loss_cls: 0.4102  decode.loss_mask: 0.2800  decode.loss_dice: 0.3114  decode.d0.loss_cls: 1.0799  decode.d0.loss_mask: 0.2921  decode.d0.loss_dice: 0.3350  decode.d1.loss_cls: 0.4237  decode.d1.loss_mask: 0.2897  decode.d1.loss_dice: 0.3013  decode.d2.loss_cls: 0.3941  decode.d2.loss_mask: 0.2857  decode.d2.loss_dice: 0.3137  decode.d3.loss_cls: 0.3265  decode.d3.loss_mask: 0.2996  decode.d3.loss_dice: 0.3101  decode.d4.loss_cls: 0.3454  decode.d4.loss_mask: 0.2996  decode.d4.loss_dice: 0.3100  decode.d5.loss_cls: 0.3532  decode.d5.loss_mask: 0.2998  decode.d5.loss_dice: 0.3390  decode.d6.loss_cls: 0.3717  decode.d6.loss_mask: 0.2997  decode.d6.loss_dice: 0.3131  decode.d7.loss_cls: 0.4019  decode.d7.loss_mask: 0.2816  decode.d7.loss_dice: 0.2996  decode.d8.loss_cls: 0.4149  decode.d8.loss_mask: 0.2857  decode.d8.loss_dice: 0.3100
08/06 03:41:46 - mmengine - INFO - Iter(train) [ 10400/320000]  base_lr: 9.7070e-05 lr: 9.7070e-06  eta: 1 day, 18:09:36  time: 0.4912  data_time: 0.0103  memory: 5890  grad_norm: 375.4067  loss: 11.7631  decode.loss_cls: 0.2872  decode.loss_mask: 0.3828  decode.loss_dice: 0.3493  decode.d0.loss_cls: 1.2610  decode.d0.loss_mask: 0.3847  decode.d0.loss_dice: 0.3970  decode.d1.loss_cls: 0.4913  decode.d1.loss_mask: 0.3869  decode.d1.loss_dice: 0.3584  decode.d2.loss_cls: 0.3501  decode.d2.loss_mask: 0.3776  decode.d2.loss_dice: 0.3429  decode.d3.loss_cls: 0.3485  decode.d3.loss_mask: 0.3833  decode.d3.loss_dice: 0.3420  decode.d4.loss_cls: 0.3229  decode.d4.loss_mask: 0.3918  decode.d4.loss_dice: 0.3551  decode.d5.loss_cls: 0.3519  decode.d5.loss_mask: 0.3909  decode.d5.loss_dice: 0.3505  decode.d6.loss_cls: 0.2992  decode.d6.loss_mask: 0.3862  decode.d6.loss_dice: 0.3531  decode.d7.loss_cls: 0.3563  decode.d7.loss_mask: 0.3770  decode.d7.loss_dice: 0.3331  decode.d8.loss_cls: 0.3056  decode.d8.loss_mask: 0.3899  decode.d8.loss_dice: 0.3566
08/06 03:42:10 - mmengine - INFO - Iter(train) [ 10450/320000]  base_lr: 9.7056e-05 lr: 9.7056e-06  eta: 1 day, 18:09:17  time: 0.4915  data_time: 0.0103  memory: 5891  grad_norm: 134.0193  loss: 8.6443  decode.loss_cls: 0.1477  decode.loss_mask: 0.2850  decode.loss_dice: 0.2787  decode.d0.loss_cls: 1.2816  decode.d0.loss_mask: 0.3221  decode.d0.loss_dice: 0.3265  decode.d1.loss_cls: 0.2472  decode.d1.loss_mask: 0.3019  decode.d1.loss_dice: 0.2893  decode.d2.loss_cls: 0.1685  decode.d2.loss_mask: 0.3002  decode.d2.loss_dice: 0.2894  decode.d3.loss_cls: 0.1637  decode.d3.loss_mask: 0.2954  decode.d3.loss_dice: 0.2877  decode.d4.loss_cls: 0.1072  decode.d4.loss_mask: 0.3031  decode.d4.loss_dice: 0.3066  decode.d5.loss_cls: 0.1547  decode.d5.loss_mask: 0.2925  decode.d5.loss_dice: 0.2823  decode.d6.loss_cls: 0.1593  decode.d6.loss_mask: 0.2977  decode.d6.loss_dice: 0.2844  decode.d7.loss_cls: 0.1851  decode.d7.loss_mask: 0.2871  decode.d7.loss_dice: 0.2902  decode.d8.loss_cls: 0.1368  decode.d8.loss_mask: 0.2887  decode.d8.loss_dice: 0.2836
08/06 03:42:35 - mmengine - INFO - Iter(train) [ 10500/320000]  base_lr: 9.7042e-05 lr: 9.7042e-06  eta: 1 day, 18:08:52  time: 0.4896  data_time: 0.0102  memory: 5908  grad_norm: 242.8335  loss: 11.5280  decode.loss_cls: 0.4134  decode.loss_mask: 0.3199  decode.loss_dice: 0.3514  decode.d0.loss_cls: 1.2060  decode.d0.loss_mask: 0.2921  decode.d0.loss_dice: 0.3792  decode.d1.loss_cls: 0.3703  decode.d1.loss_mask: 0.2824  decode.d1.loss_dice: 0.3435  decode.d2.loss_cls: 0.4848  decode.d2.loss_mask: 0.2730  decode.d2.loss_dice: 0.3266  decode.d3.loss_cls: 0.4418  decode.d3.loss_mask: 0.2781  decode.d3.loss_dice: 0.3258  decode.d4.loss_cls: 0.4640  decode.d4.loss_mask: 0.2793  decode.d4.loss_dice: 0.3246  decode.d5.loss_cls: 0.4495  decode.d5.loss_mask: 0.2781  decode.d5.loss_dice: 0.3439  decode.d6.loss_cls: 0.4959  decode.d6.loss_mask: 0.2705  decode.d6.loss_dice: 0.3396  decode.d7.loss_cls: 0.4664  decode.d7.loss_mask: 0.2763  decode.d7.loss_dice: 0.3350  decode.d8.loss_cls: 0.5019  decode.d8.loss_mask: 0.2788  decode.d8.loss_dice: 0.3358
08/06 03:42:59 - mmengine - INFO - Iter(train) [ 10550/320000]  base_lr: 9.7028e-05 lr: 9.7028e-06  eta: 1 day, 18:08:29  time: 0.4915  data_time: 0.0103  memory: 5907  grad_norm: 151.9888  loss: 10.9462  decode.loss_cls: 0.2945  decode.loss_mask: 0.2825  decode.loss_dice: 0.3931  decode.d0.loss_cls: 1.1941  decode.d0.loss_mask: 0.3017  decode.d0.loss_dice: 0.4180  decode.d1.loss_cls: 0.5897  decode.d1.loss_mask: 0.2891  decode.d1.loss_dice: 0.3891  decode.d2.loss_cls: 0.3084  decode.d2.loss_mask: 0.2863  decode.d2.loss_dice: 0.3987  decode.d3.loss_cls: 0.2776  decode.d3.loss_mask: 0.2775  decode.d3.loss_dice: 0.3941  decode.d4.loss_cls: 0.3345  decode.d4.loss_mask: 0.2776  decode.d4.loss_dice: 0.3977  decode.d5.loss_cls: 0.2593  decode.d5.loss_mask: 0.2745  decode.d5.loss_dice: 0.3949  decode.d6.loss_cls: 0.2899  decode.d6.loss_mask: 0.2703  decode.d6.loss_dice: 0.3789  decode.d7.loss_cls: 0.3322  decode.d7.loss_mask: 0.2689  decode.d7.loss_dice: 0.3769  decode.d8.loss_cls: 0.3219  decode.d8.loss_mask: 0.2816  decode.d8.loss_dice: 0.3926
08/06 03:43:24 - mmengine - INFO - Iter(train) [ 10600/320000]  base_lr: 9.7014e-05 lr: 9.7014e-06  eta: 1 day, 18:08:06  time: 0.4914  data_time: 0.0105  memory: 5875  grad_norm: 163.6088  loss: 10.7163  decode.loss_cls: 0.2604  decode.loss_mask: 0.3164  decode.loss_dice: 0.3819  decode.d0.loss_cls: 1.0992  decode.d0.loss_mask: 0.3158  decode.d0.loss_dice: 0.4130  decode.d1.loss_cls: 0.5261  decode.d1.loss_mask: 0.3035  decode.d1.loss_dice: 0.3867  decode.d2.loss_cls: 0.4084  decode.d2.loss_mask: 0.3193  decode.d2.loss_dice: 0.3798  decode.d3.loss_cls: 0.2366  decode.d3.loss_mask: 0.3213  decode.d3.loss_dice: 0.3903  decode.d4.loss_cls: 0.1728  decode.d4.loss_mask: 0.3240  decode.d4.loss_dice: 0.3992  decode.d5.loss_cls: 0.1967  decode.d5.loss_mask: 0.3285  decode.d5.loss_dice: 0.4039  decode.d6.loss_cls: 0.2332  decode.d6.loss_mask: 0.3134  decode.d6.loss_dice: 0.3796  decode.d7.loss_cls: 0.2504  decode.d7.loss_mask: 0.3139  decode.d7.loss_dice: 0.3794  decode.d8.loss_cls: 0.2814  decode.d8.loss_mask: 0.3160  decode.d8.loss_dice: 0.3653
08/06 03:43:49 - mmengine - INFO - Iter(train) [ 10650/320000]  base_lr: 9.7000e-05 lr: 9.7000e-06  eta: 1 day, 18:07:41  time: 0.4915  data_time: 0.0102  memory: 5908  grad_norm: 134.3538  loss: 9.2487  decode.loss_cls: 0.1751  decode.loss_mask: 0.2735  decode.loss_dice: 0.3316  decode.d0.loss_cls: 1.4731  decode.d0.loss_mask: 0.2962  decode.d0.loss_dice: 0.3598  decode.d1.loss_cls: 0.2982  decode.d1.loss_mask: 0.2711  decode.d1.loss_dice: 0.3367  decode.d2.loss_cls: 0.1756  decode.d2.loss_mask: 0.2665  decode.d2.loss_dice: 0.3248  decode.d3.loss_cls: 0.2126  decode.d3.loss_mask: 0.2684  decode.d3.loss_dice: 0.3186  decode.d4.loss_cls: 0.1787  decode.d4.loss_mask: 0.2755  decode.d4.loss_dice: 0.3316  decode.d5.loss_cls: 0.2023  decode.d5.loss_mask: 0.2683  decode.d5.loss_dice: 0.3250  decode.d6.loss_cls: 0.1745  decode.d6.loss_mask: 0.2685  decode.d6.loss_dice: 0.3197  decode.d7.loss_cls: 0.1670  decode.d7.loss_mask: 0.2672  decode.d7.loss_dice: 0.3144  decode.d8.loss_cls: 0.1724  decode.d8.loss_mask: 0.2821  decode.d8.loss_dice: 0.3195
08/06 03:44:13 - mmengine - INFO - Iter(train) [ 10700/320000]  base_lr: 9.6986e-05 lr: 9.6986e-06  eta: 1 day, 18:07:18  time: 0.4899  data_time: 0.0103  memory: 5909  grad_norm: 159.3847  loss: 10.5903  decode.loss_cls: 0.2773  decode.loss_mask: 0.3238  decode.loss_dice: 0.3620  decode.d0.loss_cls: 0.9552  decode.d0.loss_mask: 0.3074  decode.d0.loss_dice: 0.3888  decode.d1.loss_cls: 0.2939  decode.d1.loss_mask: 0.2973  decode.d1.loss_dice: 0.3616  decode.d2.loss_cls: 0.3774  decode.d2.loss_mask: 0.2957  decode.d2.loss_dice: 0.3565  decode.d3.loss_cls: 0.3407  decode.d3.loss_mask: 0.2888  decode.d3.loss_dice: 0.3310  decode.d4.loss_cls: 0.3496  decode.d4.loss_mask: 0.2890  decode.d4.loss_dice: 0.3322  decode.d5.loss_cls: 0.3657  decode.d5.loss_mask: 0.2965  decode.d5.loss_dice: 0.3440  decode.d6.loss_cls: 0.4014  decode.d6.loss_mask: 0.2847  decode.d6.loss_dice: 0.3447  decode.d7.loss_cls: 0.3692  decode.d7.loss_mask: 0.2988  decode.d7.loss_dice: 0.3604  decode.d8.loss_cls: 0.3258  decode.d8.loss_mask: 0.3053  decode.d8.loss_dice: 0.3656
08/06 03:44:38 - mmengine - INFO - Iter(train) [ 10750/320000]  base_lr: 9.6972e-05 lr: 9.6972e-06  eta: 1 day, 18:06:54  time: 0.4904  data_time: 0.0100  memory: 5964  grad_norm: 194.2326  loss: 8.9192  decode.loss_cls: 0.2456  decode.loss_mask: 0.2587  decode.loss_dice: 0.2931  decode.d0.loss_cls: 1.0807  decode.d0.loss_mask: 0.2657  decode.d0.loss_dice: 0.3385  decode.d1.loss_cls: 0.2721  decode.d1.loss_mask: 0.2626  decode.d1.loss_dice: 0.3186  decode.d2.loss_cls: 0.2261  decode.d2.loss_mask: 0.2590  decode.d2.loss_dice: 0.2928  decode.d3.loss_cls: 0.2684  decode.d3.loss_mask: 0.2532  decode.d3.loss_dice: 0.3012  decode.d4.loss_cls: 0.2689  decode.d4.loss_mask: 0.2555  decode.d4.loss_dice: 0.2935  decode.d5.loss_cls: 0.2652  decode.d5.loss_mask: 0.2574  decode.d5.loss_dice: 0.3034  decode.d6.loss_cls: 0.2061  decode.d6.loss_mask: 0.2570  decode.d6.loss_dice: 0.2859  decode.d7.loss_cls: 0.2448  decode.d7.loss_mask: 0.2553  decode.d7.loss_dice: 0.2770  decode.d8.loss_cls: 0.2603  decode.d8.loss_mask: 0.2542  decode.d8.loss_dice: 0.2983
08/06 03:45:02 - mmengine - INFO - Iter(train) [ 10800/320000]  base_lr: 9.6958e-05 lr: 9.6958e-06  eta: 1 day, 18:06:30  time: 0.4907  data_time: 0.0103  memory: 5891  grad_norm: 202.8818  loss: 11.3631  decode.loss_cls: 0.4251  decode.loss_mask: 0.2709  decode.loss_dice: 0.3128  decode.d0.loss_cls: 1.0816  decode.d0.loss_mask: 0.2982  decode.d0.loss_dice: 0.3990  decode.d1.loss_cls: 0.5564  decode.d1.loss_mask: 0.2723  decode.d1.loss_dice: 0.3382  decode.d2.loss_cls: 0.4731  decode.d2.loss_mask: 0.2694  decode.d2.loss_dice: 0.3349  decode.d3.loss_cls: 0.4607  decode.d3.loss_mask: 0.2675  decode.d3.loss_dice: 0.3305  decode.d4.loss_cls: 0.5200  decode.d4.loss_mask: 0.2622  decode.d4.loss_dice: 0.3223  decode.d5.loss_cls: 0.4510  decode.d5.loss_mask: 0.2706  decode.d5.loss_dice: 0.3243  decode.d6.loss_cls: 0.4048  decode.d6.loss_mask: 0.2728  decode.d6.loss_dice: 0.3255  decode.d7.loss_cls: 0.4368  decode.d7.loss_mask: 0.2786  decode.d7.loss_dice: 0.3331  decode.d8.loss_cls: 0.4796  decode.d8.loss_mask: 0.2598  decode.d8.loss_dice: 0.3311
08/06 03:45:27 - mmengine - INFO - Iter(train) [ 10850/320000]  base_lr: 9.6943e-05 lr: 9.6943e-06  eta: 1 day, 18:06:06  time: 0.4912  data_time: 0.0106  memory: 5893  grad_norm: 277.5866  loss: 11.8153  decode.loss_cls: 0.3656  decode.loss_mask: 0.3681  decode.loss_dice: 0.3973  decode.d0.loss_cls: 1.2203  decode.d0.loss_mask: 0.4101  decode.d0.loss_dice: 0.4521  decode.d1.loss_cls: 0.4526  decode.d1.loss_mask: 0.3600  decode.d1.loss_dice: 0.3750  decode.d2.loss_cls: 0.3996  decode.d2.loss_mask: 0.3337  decode.d2.loss_dice: 0.3886  decode.d3.loss_cls: 0.3311  decode.d3.loss_mask: 0.3352  decode.d3.loss_dice: 0.3661  decode.d4.loss_cls: 0.3835  decode.d4.loss_mask: 0.3254  decode.d4.loss_dice: 0.3479  decode.d5.loss_cls: 0.3611  decode.d5.loss_mask: 0.3373  decode.d5.loss_dice: 0.3725  decode.d6.loss_cls: 0.3530  decode.d6.loss_mask: 0.3260  decode.d6.loss_dice: 0.3547  decode.d7.loss_cls: 0.2971  decode.d7.loss_mask: 0.3343  decode.d7.loss_dice: 0.3670  decode.d8.loss_cls: 0.3457  decode.d8.loss_mask: 0.3624  decode.d8.loss_dice: 0.3919
08/06 03:45:51 - mmengine - INFO - Iter(train) [ 10900/320000]  base_lr: 9.6929e-05 lr: 9.6929e-06  eta: 1 day, 18:05:42  time: 0.4897  data_time: 0.0104  memory: 5892  grad_norm: 172.1037  loss: 11.6395  decode.loss_cls: 0.3380  decode.loss_mask: 0.3610  decode.loss_dice: 0.3921  decode.d0.loss_cls: 1.0644  decode.d0.loss_mask: 0.3778  decode.d0.loss_dice: 0.3861  decode.d1.loss_cls: 0.3732  decode.d1.loss_mask: 0.3695  decode.d1.loss_dice: 0.3888  decode.d2.loss_cls: 0.3344  decode.d2.loss_mask: 0.3710  decode.d2.loss_dice: 0.3892  decode.d3.loss_cls: 0.3246  decode.d3.loss_mask: 0.3576  decode.d3.loss_dice: 0.3777  decode.d4.loss_cls: 0.3811  decode.d4.loss_mask: 0.3507  decode.d4.loss_dice: 0.3768  decode.d5.loss_cls: 0.3204  decode.d5.loss_mask: 0.3562  decode.d5.loss_dice: 0.3852  decode.d6.loss_cls: 0.2667  decode.d6.loss_mask: 0.3561  decode.d6.loss_dice: 0.3804  decode.d7.loss_cls: 0.3647  decode.d7.loss_mask: 0.3697  decode.d7.loss_dice: 0.3968  decode.d8.loss_cls: 0.3752  decode.d8.loss_mask: 0.3649  decode.d8.loss_dice: 0.3889
08/06 03:46:16 - mmengine - INFO - Iter(train) [ 10950/320000]  base_lr: 9.6915e-05 lr: 9.6915e-06  eta: 1 day, 18:05:18  time: 0.4898  data_time: 0.0102  memory: 5895  grad_norm: 163.2441  loss: 8.5598  decode.loss_cls: 0.1761  decode.loss_mask: 0.2923  decode.loss_dice: 0.2686  decode.d0.loss_cls: 1.0714  decode.d0.loss_mask: 0.3200  decode.d0.loss_dice: 0.3110  decode.d1.loss_cls: 0.3160  decode.d1.loss_mask: 0.3061  decode.d1.loss_dice: 0.2858  decode.d2.loss_cls: 0.1658  decode.d2.loss_mask: 0.3073  decode.d2.loss_dice: 0.2996  decode.d3.loss_cls: 0.1847  decode.d3.loss_mask: 0.2943  decode.d3.loss_dice: 0.2627  decode.d4.loss_cls: 0.1642  decode.d4.loss_mask: 0.3116  decode.d4.loss_dice: 0.2864  decode.d5.loss_cls: 0.1726  decode.d5.loss_mask: 0.2983  decode.d5.loss_dice: 0.2842  decode.d6.loss_cls: 0.1725  decode.d6.loss_mask: 0.2923  decode.d6.loss_dice: 0.2743  decode.d7.loss_cls: 0.1418  decode.d7.loss_mask: 0.3085  decode.d7.loss_dice: 0.2908  decode.d8.loss_cls: 0.1510  decode.d8.loss_mask: 0.2878  decode.d8.loss_dice: 0.2615
08/06 03:46:40 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 03:46:40 - mmengine - INFO - Iter(train) [ 11000/320000]  base_lr: 9.6901e-05 lr: 9.6901e-06  eta: 1 day, 18:04:54  time: 0.4921  data_time: 0.0102  memory: 5907  grad_norm: 129.5545  loss: 10.4903  decode.loss_cls: 0.3457  decode.loss_mask: 0.2684  decode.loss_dice: 0.4010  decode.d0.loss_cls: 1.1878  decode.d0.loss_mask: 0.2461  decode.d0.loss_dice: 0.4491  decode.d1.loss_cls: 0.5049  decode.d1.loss_mask: 0.2549  decode.d1.loss_dice: 0.3909  decode.d2.loss_cls: 0.3678  decode.d2.loss_mask: 0.2371  decode.d2.loss_dice: 0.3754  decode.d3.loss_cls: 0.3640  decode.d3.loss_mask: 0.2320  decode.d3.loss_dice: 0.3520  decode.d4.loss_cls: 0.3086  decode.d4.loss_mask: 0.2430  decode.d4.loss_dice: 0.3387  decode.d5.loss_cls: 0.3276  decode.d5.loss_mask: 0.2352  decode.d5.loss_dice: 0.3442  decode.d6.loss_cls: 0.3013  decode.d6.loss_mask: 0.2618  decode.d6.loss_dice: 0.3892  decode.d7.loss_cls: 0.3029  decode.d7.loss_mask: 0.2412  decode.d7.loss_dice: 0.3264  decode.d8.loss_cls: 0.2847  decode.d8.loss_mask: 0.2444  decode.d8.loss_dice: 0.3639
08/06 03:47:05 - mmengine - INFO - Iter(train) [ 11050/320000]  base_lr: 9.6887e-05 lr: 9.6887e-06  eta: 1 day, 18:04:33  time: 0.4910  data_time: 0.0104  memory: 5892  grad_norm: 143.0251  loss: 11.8592  decode.loss_cls: 0.3443  decode.loss_mask: 0.3085  decode.loss_dice: 0.4055  decode.d0.loss_cls: 1.3117  decode.d0.loss_mask: 0.3396  decode.d0.loss_dice: 0.4466  decode.d1.loss_cls: 0.3777  decode.d1.loss_mask: 0.3314  decode.d1.loss_dice: 0.4143  decode.d2.loss_cls: 0.3492  decode.d2.loss_mask: 0.3253  decode.d2.loss_dice: 0.4188  decode.d3.loss_cls: 0.2577  decode.d3.loss_mask: 0.3228  decode.d3.loss_dice: 0.4045  decode.d4.loss_cls: 0.3510  decode.d4.loss_mask: 0.3378  decode.d4.loss_dice: 0.4312  decode.d5.loss_cls: 0.3594  decode.d5.loss_mask: 0.3228  decode.d5.loss_dice: 0.4016  decode.d6.loss_cls: 0.3497  decode.d6.loss_mask: 0.3122  decode.d6.loss_dice: 0.4225  decode.d7.loss_cls: 0.3766  decode.d7.loss_mask: 0.3162  decode.d7.loss_dice: 0.4360  decode.d8.loss_cls: 0.3441  decode.d8.loss_mask: 0.3185  decode.d8.loss_dice: 0.4219
08/06 03:47:29 - mmengine - INFO - Iter(train) [ 11100/320000]  base_lr: 9.6873e-05 lr: 9.6873e-06  eta: 1 day, 18:04:08  time: 0.4911  data_time: 0.0103  memory: 5891  grad_norm: 175.5544  loss: 13.6995  decode.loss_cls: 0.4040  decode.loss_mask: 0.4593  decode.loss_dice: 0.4064  decode.d0.loss_cls: 1.2046  decode.d0.loss_mask: 0.4623  decode.d0.loss_dice: 0.5008  decode.d1.loss_cls: 0.4198  decode.d1.loss_mask: 0.4630  decode.d1.loss_dice: 0.4297  decode.d2.loss_cls: 0.4507  decode.d2.loss_mask: 0.4694  decode.d2.loss_dice: 0.4105  decode.d3.loss_cls: 0.4702  decode.d3.loss_mask: 0.4397  decode.d3.loss_dice: 0.3990  decode.d4.loss_cls: 0.4127  decode.d4.loss_mask: 0.4610  decode.d4.loss_dice: 0.4103  decode.d5.loss_cls: 0.4337  decode.d5.loss_mask: 0.4603  decode.d5.loss_dice: 0.4176  decode.d6.loss_cls: 0.4114  decode.d6.loss_mask: 0.4488  decode.d6.loss_dice: 0.3885  decode.d7.loss_cls: 0.3564  decode.d7.loss_mask: 0.4555  decode.d7.loss_dice: 0.3902  decode.d8.loss_cls: 0.3890  decode.d8.loss_mask: 0.4652  decode.d8.loss_dice: 0.4094
08/06 03:47:54 - mmengine - INFO - Iter(train) [ 11150/320000]  base_lr: 9.6859e-05 lr: 9.6859e-06  eta: 1 day, 18:03:44  time: 0.4903  data_time: 0.0102  memory: 5907  grad_norm: 144.4174  loss: 9.7378  decode.loss_cls: 0.2854  decode.loss_mask: 0.2807  decode.loss_dice: 0.2673  decode.d0.loss_cls: 1.1327  decode.d0.loss_mask: 0.2934  decode.d0.loss_dice: 0.3292  decode.d1.loss_cls: 0.3805  decode.d1.loss_mask: 0.2900  decode.d1.loss_dice: 0.2670  decode.d2.loss_cls: 0.3303  decode.d2.loss_mask: 0.2854  decode.d2.loss_dice: 0.2731  decode.d3.loss_cls: 0.3310  decode.d3.loss_mask: 0.2795  decode.d3.loss_dice: 0.2908  decode.d4.loss_cls: 0.3510  decode.d4.loss_mask: 0.2838  decode.d4.loss_dice: 0.2699  decode.d5.loss_cls: 0.3557  decode.d5.loss_mask: 0.2958  decode.d5.loss_dice: 0.2800  decode.d6.loss_cls: 0.2840  decode.d6.loss_mask: 0.2810  decode.d6.loss_dice: 0.2789  decode.d7.loss_cls: 0.3257  decode.d7.loss_mask: 0.2843  decode.d7.loss_dice: 0.2775  decode.d8.loss_cls: 0.3024  decode.d8.loss_mask: 0.2806  decode.d8.loss_dice: 0.2708
08/06 03:48:19 - mmengine - INFO - Iter(train) [ 11200/320000]  base_lr: 9.6845e-05 lr: 9.6845e-06  eta: 1 day, 18:03:20  time: 0.4903  data_time: 0.0102  memory: 5908  grad_norm: 165.5435  loss: 10.3719  decode.loss_cls: 0.3454  decode.loss_mask: 0.3507  decode.loss_dice: 0.3177  decode.d0.loss_cls: 1.3579  decode.d0.loss_mask: 0.3590  decode.d0.loss_dice: 0.3531  decode.d1.loss_cls: 0.2778  decode.d1.loss_mask: 0.3545  decode.d1.loss_dice: 0.3052  decode.d2.loss_cls: 0.2546  decode.d2.loss_mask: 0.3371  decode.d2.loss_dice: 0.2963  decode.d3.loss_cls: 0.2720  decode.d3.loss_mask: 0.3314  decode.d3.loss_dice: 0.2898  decode.d4.loss_cls: 0.3039  decode.d4.loss_mask: 0.3264  decode.d4.loss_dice: 0.2810  decode.d5.loss_cls: 0.2823  decode.d5.loss_mask: 0.3267  decode.d5.loss_dice: 0.2867  decode.d6.loss_cls: 0.3281  decode.d6.loss_mask: 0.3260  decode.d6.loss_dice: 0.2861  decode.d7.loss_cls: 0.2902  decode.d7.loss_mask: 0.3325  decode.d7.loss_dice: 0.2857  decode.d8.loss_cls: 0.2786  decode.d8.loss_mask: 0.3448  decode.d8.loss_dice: 0.2906
08/06 03:48:43 - mmengine - INFO - Iter(train) [ 11250/320000]  base_lr: 9.6831e-05 lr: 9.6831e-06  eta: 1 day, 18:02:56  time: 0.4907  data_time: 0.0101  memory: 5909  grad_norm: 122.2916  loss: 9.4639  decode.loss_cls: 0.2403  decode.loss_mask: 0.2323  decode.loss_dice: 0.2873  decode.d0.loss_cls: 1.2257  decode.d0.loss_mask: 0.2538  decode.d0.loss_dice: 0.3256  decode.d1.loss_cls: 0.4522  decode.d1.loss_mask: 0.2206  decode.d1.loss_dice: 0.3013  decode.d2.loss_cls: 0.4570  decode.d2.loss_mask: 0.2269  decode.d2.loss_dice: 0.2780  decode.d3.loss_cls: 0.3623  decode.d3.loss_mask: 0.2366  decode.d3.loss_dice: 0.3016  decode.d4.loss_cls: 0.3563  decode.d4.loss_mask: 0.2351  decode.d4.loss_dice: 0.2918  decode.d5.loss_cls: 0.2650  decode.d5.loss_mask: 0.2383  decode.d5.loss_dice: 0.2984  decode.d6.loss_cls: 0.2804  decode.d6.loss_mask: 0.2275  decode.d6.loss_dice: 0.2866  decode.d7.loss_cls: 0.2640  decode.d7.loss_mask: 0.2244  decode.d7.loss_dice: 0.2784  decode.d8.loss_cls: 0.2987  decode.d8.loss_mask: 0.2268  decode.d8.loss_dice: 0.2907
08/06 03:49:08 - mmengine - INFO - Iter(train) [ 11300/320000]  base_lr: 9.6816e-05 lr: 9.6816e-06  eta: 1 day, 18:02:31  time: 0.4897  data_time: 0.0104  memory: 5910  grad_norm: 135.4231  loss: 10.1271  decode.loss_cls: 0.2875  decode.loss_mask: 0.2609  decode.loss_dice: 0.3262  decode.d0.loss_cls: 1.0889  decode.d0.loss_mask: 0.2675  decode.d0.loss_dice: 0.3661  decode.d1.loss_cls: 0.4261  decode.d1.loss_mask: 0.2652  decode.d1.loss_dice: 0.3528  decode.d2.loss_cls: 0.3918  decode.d2.loss_mask: 0.2629  decode.d2.loss_dice: 0.3322  decode.d3.loss_cls: 0.3238  decode.d3.loss_mask: 0.2624  decode.d3.loss_dice: 0.3447  decode.d4.loss_cls: 0.3237  decode.d4.loss_mask: 0.2636  decode.d4.loss_dice: 0.3436  decode.d5.loss_cls: 0.3430  decode.d5.loss_mask: 0.2541  decode.d5.loss_dice: 0.3295  decode.d6.loss_cls: 0.3166  decode.d6.loss_mask: 0.2648  decode.d6.loss_dice: 0.3183  decode.d7.loss_cls: 0.3309  decode.d7.loss_mask: 0.2595  decode.d7.loss_dice: 0.3315  decode.d8.loss_cls: 0.3036  decode.d8.loss_mask: 0.2652  decode.d8.loss_dice: 0.3203
08/06 03:49:32 - mmengine - INFO - Iter(train) [ 11350/320000]  base_lr: 9.6802e-05 lr: 9.6802e-06  eta: 1 day, 18:02:06  time: 0.4913  data_time: 0.0105  memory: 5891  grad_norm: 155.1386  loss: 9.0819  decode.loss_cls: 0.2128  decode.loss_mask: 0.2413  decode.loss_dice: 0.3253  decode.d0.loss_cls: 1.1119  decode.d0.loss_mask: 0.2614  decode.d0.loss_dice: 0.3752  decode.d1.loss_cls: 0.3217  decode.d1.loss_mask: 0.2465  decode.d1.loss_dice: 0.3385  decode.d2.loss_cls: 0.1889  decode.d2.loss_mask: 0.2461  decode.d2.loss_dice: 0.3186  decode.d3.loss_cls: 0.2475  decode.d3.loss_mask: 0.2473  decode.d3.loss_dice: 0.3239  decode.d4.loss_cls: 0.2391  decode.d4.loss_mask: 0.2417  decode.d4.loss_dice: 0.3296  decode.d5.loss_cls: 0.3119  decode.d5.loss_mask: 0.2407  decode.d5.loss_dice: 0.3347  decode.d6.loss_cls: 0.2152  decode.d6.loss_mask: 0.2471  decode.d6.loss_dice: 0.3441  decode.d7.loss_cls: 0.2331  decode.d7.loss_mask: 0.2460  decode.d7.loss_dice: 0.3354  decode.d8.loss_cls: 0.1918  decode.d8.loss_mask: 0.2398  decode.d8.loss_dice: 0.3250
08/06 03:49:57 - mmengine - INFO - Iter(train) [ 11400/320000]  base_lr: 9.6788e-05 lr: 9.6788e-06  eta: 1 day, 18:01:41  time: 0.4906  data_time: 0.0105  memory: 5891  grad_norm: 187.2502  loss: 9.3412  decode.loss_cls: 0.2297  decode.loss_mask: 0.3218  decode.loss_dice: 0.2902  decode.d0.loss_cls: 0.9795  decode.d0.loss_mask: 0.3126  decode.d0.loss_dice: 0.3119  decode.d1.loss_cls: 0.2719  decode.d1.loss_mask: 0.3322  decode.d1.loss_dice: 0.2979  decode.d2.loss_cls: 0.2212  decode.d2.loss_mask: 0.3267  decode.d2.loss_dice: 0.2805  decode.d3.loss_cls: 0.2528  decode.d3.loss_mask: 0.3246  decode.d3.loss_dice: 0.2905  decode.d4.loss_cls: 0.2588  decode.d4.loss_mask: 0.3279  decode.d4.loss_dice: 0.2794  decode.d5.loss_cls: 0.2710  decode.d5.loss_mask: 0.3250  decode.d5.loss_dice: 0.2727  decode.d6.loss_cls: 0.2420  decode.d6.loss_mask: 0.3226  decode.d6.loss_dice: 0.3077  decode.d7.loss_cls: 0.2390  decode.d7.loss_mask: 0.3302  decode.d7.loss_dice: 0.2920  decode.d8.loss_cls: 0.2209  decode.d8.loss_mask: 0.3318  decode.d8.loss_dice: 0.2764
08/06 03:50:21 - mmengine - INFO - Iter(train) [ 11450/320000]  base_lr: 9.6774e-05 lr: 9.6774e-06  eta: 1 day, 18:01:16  time: 0.4902  data_time: 0.0105  memory: 5890  grad_norm: 199.4536  loss: 11.2766  decode.loss_cls: 0.3566  decode.loss_mask: 0.3213  decode.loss_dice: 0.3678  decode.d0.loss_cls: 1.2902  decode.d0.loss_mask: 0.3357  decode.d0.loss_dice: 0.4057  decode.d1.loss_cls: 0.4337  decode.d1.loss_mask: 0.3256  decode.d1.loss_dice: 0.3702  decode.d2.loss_cls: 0.3313  decode.d2.loss_mask: 0.3220  decode.d2.loss_dice: 0.3718  decode.d3.loss_cls: 0.3574  decode.d3.loss_mask: 0.3198  decode.d3.loss_dice: 0.3689  decode.d4.loss_cls: 0.3305  decode.d4.loss_mask: 0.3266  decode.d4.loss_dice: 0.3783  decode.d5.loss_cls: 0.2752  decode.d5.loss_mask: 0.3400  decode.d5.loss_dice: 0.3936  decode.d6.loss_cls: 0.3106  decode.d6.loss_mask: 0.3203  decode.d6.loss_dice: 0.3781  decode.d7.loss_cls: 0.2808  decode.d7.loss_mask: 0.3300  decode.d7.loss_dice: 0.3859  decode.d8.loss_cls: 0.2277  decode.d8.loss_mask: 0.3402  decode.d8.loss_dice: 0.3808
08/06 03:50:46 - mmengine - INFO - Iter(train) [ 11500/320000]  base_lr: 9.6760e-05 lr: 9.6760e-06  eta: 1 day, 18:00:51  time: 0.4899  data_time: 0.0103  memory: 5892  grad_norm: 326.8863  loss: 11.8314  decode.loss_cls: 0.4557  decode.loss_mask: 0.2723  decode.loss_dice: 0.3727  decode.d0.loss_cls: 1.2367  decode.d0.loss_mask: 0.2789  decode.d0.loss_dice: 0.4232  decode.d1.loss_cls: 0.5079  decode.d1.loss_mask: 0.3144  decode.d1.loss_dice: 0.3562  decode.d2.loss_cls: 0.3488  decode.d2.loss_mask: 0.2924  decode.d2.loss_dice: 0.4061  decode.d3.loss_cls: 0.5040  decode.d3.loss_mask: 0.2709  decode.d3.loss_dice: 0.3771  decode.d4.loss_cls: 0.4563  decode.d4.loss_mask: 0.2775  decode.d4.loss_dice: 0.3667  decode.d5.loss_cls: 0.3809  decode.d5.loss_mask: 0.2801  decode.d5.loss_dice: 0.3889  decode.d6.loss_cls: 0.4074  decode.d6.loss_mask: 0.2993  decode.d6.loss_dice: 0.4092  decode.d7.loss_cls: 0.3775  decode.d7.loss_mask: 0.3017  decode.d7.loss_dice: 0.4004  decode.d8.loss_cls: 0.3745  decode.d8.loss_mask: 0.3070  decode.d8.loss_dice: 0.3868
08/06 03:51:10 - mmengine - INFO - Iter(train) [ 11550/320000]  base_lr: 9.6746e-05 lr: 9.6746e-06  eta: 1 day, 18:00:30  time: 0.4906  data_time: 0.0105  memory: 5908  grad_norm: 83.2070  loss: 8.6645  decode.loss_cls: 0.2261  decode.loss_mask: 0.2871  decode.loss_dice: 0.2907  decode.d0.loss_cls: 0.9759  decode.d0.loss_mask: 0.2829  decode.d0.loss_dice: 0.3015  decode.d1.loss_cls: 0.1874  decode.d1.loss_mask: 0.2869  decode.d1.loss_dice: 0.2815  decode.d2.loss_cls: 0.1720  decode.d2.loss_mask: 0.2767  decode.d2.loss_dice: 0.2730  decode.d3.loss_cls: 0.2227  decode.d3.loss_mask: 0.2819  decode.d3.loss_dice: 0.2574  decode.d4.loss_cls: 0.2358  decode.d4.loss_mask: 0.2919  decode.d4.loss_dice: 0.2739  decode.d5.loss_cls: 0.2451  decode.d5.loss_mask: 0.2876  decode.d5.loss_dice: 0.2659  decode.d6.loss_cls: 0.2750  decode.d6.loss_mask: 0.2863  decode.d6.loss_dice: 0.2887  decode.d7.loss_cls: 0.2525  decode.d7.loss_mask: 0.2875  decode.d7.loss_dice: 0.2657  decode.d8.loss_cls: 0.2515  decode.d8.loss_mask: 0.2866  decode.d8.loss_dice: 0.2669
08/06 03:51:35 - mmengine - INFO - Iter(train) [ 11600/320000]  base_lr: 9.6732e-05 lr: 9.6732e-06  eta: 1 day, 18:00:06  time: 0.4898  data_time: 0.0106  memory: 5907  grad_norm: 170.7210  loss: 11.6816  decode.loss_cls: 0.2852  decode.loss_mask: 0.3554  decode.loss_dice: 0.3999  decode.d0.loss_cls: 1.0290  decode.d0.loss_mask: 0.3707  decode.d0.loss_dice: 0.4176  decode.d1.loss_cls: 0.4384  decode.d1.loss_mask: 0.3601  decode.d1.loss_dice: 0.3818  decode.d2.loss_cls: 0.4138  decode.d2.loss_mask: 0.3533  decode.d2.loss_dice: 0.3617  decode.d3.loss_cls: 0.3904  decode.d3.loss_mask: 0.3547  decode.d3.loss_dice: 0.3753  decode.d4.loss_cls: 0.3945  decode.d4.loss_mask: 0.3544  decode.d4.loss_dice: 0.3871  decode.d5.loss_cls: 0.3683  decode.d5.loss_mask: 0.3486  decode.d5.loss_dice: 0.3652  decode.d6.loss_cls: 0.2806  decode.d6.loss_mask: 0.3524  decode.d6.loss_dice: 0.4040  decode.d7.loss_cls: 0.2680  decode.d7.loss_mask: 0.3561  decode.d7.loss_dice: 0.4058  decode.d8.loss_cls: 0.3529  decode.d8.loss_mask: 0.3531  decode.d8.loss_dice: 0.4034
08/06 03:51:59 - mmengine - INFO - Iter(train) [ 11650/320000]  base_lr: 9.6718e-05 lr: 9.6718e-06  eta: 1 day, 17:59:41  time: 0.4904  data_time: 0.0103  memory: 5909  grad_norm: 297.4102  loss: 8.4552  decode.loss_cls: 0.2205  decode.loss_mask: 0.2383  decode.loss_dice: 0.2370  decode.d0.loss_cls: 1.1996  decode.d0.loss_mask: 0.2656  decode.d0.loss_dice: 0.3225  decode.d1.loss_cls: 0.3004  decode.d1.loss_mask: 0.2481  decode.d1.loss_dice: 0.2492  decode.d2.loss_cls: 0.2174  decode.d2.loss_mask: 0.2464  decode.d2.loss_dice: 0.2735  decode.d3.loss_cls: 0.2504  decode.d3.loss_mask: 0.2469  decode.d3.loss_dice: 0.2507  decode.d4.loss_cls: 0.2655  decode.d4.loss_mask: 0.2473  decode.d4.loss_dice: 0.2473  decode.d5.loss_cls: 0.2540  decode.d5.loss_mask: 0.2451  decode.d5.loss_dice: 0.2335  decode.d6.loss_cls: 0.2437  decode.d6.loss_mask: 0.2474  decode.d6.loss_dice: 0.2239  decode.d7.loss_cls: 0.2360  decode.d7.loss_mask: 0.2413  decode.d7.loss_dice: 0.2463  decode.d8.loss_cls: 0.2575  decode.d8.loss_mask: 0.2430  decode.d8.loss_dice: 0.2567
08/06 03:52:24 - mmengine - INFO - Iter(train) [ 11700/320000]  base_lr: 9.6704e-05 lr: 9.6704e-06  eta: 1 day, 17:59:18  time: 0.4916  data_time: 0.0104  memory: 5875  grad_norm: 194.9893  loss: 11.0351  decode.loss_cls: 0.3825  decode.loss_mask: 0.2630  decode.loss_dice: 0.3563  decode.d0.loss_cls: 1.2124  decode.d0.loss_mask: 0.2667  decode.d0.loss_dice: 0.4257  decode.d1.loss_cls: 0.4325  decode.d1.loss_mask: 0.2683  decode.d1.loss_dice: 0.3884  decode.d2.loss_cls: 0.3329  decode.d2.loss_mask: 0.2553  decode.d2.loss_dice: 0.3472  decode.d3.loss_cls: 0.3175  decode.d3.loss_mask: 0.2636  decode.d3.loss_dice: 0.3687  decode.d4.loss_cls: 0.3952  decode.d4.loss_mask: 0.2592  decode.d4.loss_dice: 0.3590  decode.d5.loss_cls: 0.3769  decode.d5.loss_mask: 0.2674  decode.d5.loss_dice: 0.3810  decode.d6.loss_cls: 0.3989  decode.d6.loss_mask: 0.2753  decode.d6.loss_dice: 0.3719  decode.d7.loss_cls: 0.4119  decode.d7.loss_mask: 0.2566  decode.d7.loss_dice: 0.3550  decode.d8.loss_cls: 0.4128  decode.d8.loss_mask: 0.2578  decode.d8.loss_dice: 0.3752
08/06 03:52:48 - mmengine - INFO - Iter(train) [ 11750/320000]  base_lr: 9.6689e-05 lr: 9.6689e-06  eta: 1 day, 17:58:55  time: 0.4914  data_time: 0.0105  memory: 5964  grad_norm: 324.4787  loss: 13.2207  decode.loss_cls: 0.3319  decode.loss_mask: 0.3997  decode.loss_dice: 0.4536  decode.d0.loss_cls: 1.1358  decode.d0.loss_mask: 0.4720  decode.d0.loss_dice: 0.5483  decode.d1.loss_cls: 0.5152  decode.d1.loss_mask: 0.4171  decode.d1.loss_dice: 0.4690  decode.d2.loss_cls: 0.4874  decode.d2.loss_mask: 0.3977  decode.d2.loss_dice: 0.4685  decode.d3.loss_cls: 0.3563  decode.d3.loss_mask: 0.3994  decode.d3.loss_dice: 0.4586  decode.d4.loss_cls: 0.3443  decode.d4.loss_mask: 0.3761  decode.d4.loss_dice: 0.4164  decode.d5.loss_cls: 0.3478  decode.d5.loss_mask: 0.3886  decode.d5.loss_dice: 0.4280  decode.d6.loss_cls: 0.3472  decode.d6.loss_mask: 0.3995  decode.d6.loss_dice: 0.4484  decode.d7.loss_cls: 0.3567  decode.d7.loss_mask: 0.3861  decode.d7.loss_dice: 0.4382  decode.d8.loss_cls: 0.3564  decode.d8.loss_mask: 0.3984  decode.d8.loss_dice: 0.4783
08/06 03:53:13 - mmengine - INFO - Iter(train) [ 11800/320000]  base_lr: 9.6675e-05 lr: 9.6675e-06  eta: 1 day, 17:58:31  time: 0.4900  data_time: 0.0103  memory: 5927  grad_norm: 151.2965  loss: 11.0774  decode.loss_cls: 0.3577  decode.loss_mask: 0.2541  decode.loss_dice: 0.3682  decode.d0.loss_cls: 1.2738  decode.d0.loss_mask: 0.2603  decode.d0.loss_dice: 0.4044  decode.d1.loss_cls: 0.4173  decode.d1.loss_mask: 0.2633  decode.d1.loss_dice: 0.3972  decode.d2.loss_cls: 0.4734  decode.d2.loss_mask: 0.2554  decode.d2.loss_dice: 0.3657  decode.d3.loss_cls: 0.4182  decode.d3.loss_mask: 0.2554  decode.d3.loss_dice: 0.3577  decode.d4.loss_cls: 0.3728  decode.d4.loss_mask: 0.2568  decode.d4.loss_dice: 0.3724  decode.d5.loss_cls: 0.3714  decode.d5.loss_mask: 0.2567  decode.d5.loss_dice: 0.3678  decode.d6.loss_cls: 0.4066  decode.d6.loss_mask: 0.2568  decode.d6.loss_dice: 0.3388  decode.d7.loss_cls: 0.3898  decode.d7.loss_mask: 0.2616  decode.d7.loss_dice: 0.3569  decode.d8.loss_cls: 0.3368  decode.d8.loss_mask: 0.2602  decode.d8.loss_dice: 0.3497
08/06 03:53:38 - mmengine - INFO - Iter(train) [ 11850/320000]  base_lr: 9.6661e-05 lr: 9.6661e-06  eta: 1 day, 17:58:12  time: 0.4915  data_time: 0.0104  memory: 5892  grad_norm: 150.2486  loss: 11.5374  decode.loss_cls: 0.4296  decode.loss_mask: 0.3348  decode.loss_dice: 0.3539  decode.d0.loss_cls: 1.2373  decode.d0.loss_mask: 0.3492  decode.d0.loss_dice: 0.4228  decode.d1.loss_cls: 0.4018  decode.d1.loss_mask: 0.3425  decode.d1.loss_dice: 0.3953  decode.d2.loss_cls: 0.3787  decode.d2.loss_mask: 0.3352  decode.d2.loss_dice: 0.3659  decode.d3.loss_cls: 0.2958  decode.d3.loss_mask: 0.3474  decode.d3.loss_dice: 0.3672  decode.d4.loss_cls: 0.2648  decode.d4.loss_mask: 0.3494  decode.d4.loss_dice: 0.3742  decode.d5.loss_cls: 0.3045  decode.d5.loss_mask: 0.3429  decode.d5.loss_dice: 0.3822  decode.d6.loss_cls: 0.3003  decode.d6.loss_mask: 0.3351  decode.d6.loss_dice: 0.3776  decode.d7.loss_cls: 0.3154  decode.d7.loss_mask: 0.3290  decode.d7.loss_dice: 0.3791  decode.d8.loss_cls: 0.4389  decode.d8.loss_mask: 0.3273  decode.d8.loss_dice: 0.3590
08/06 03:54:02 - mmengine - INFO - Iter(train) [ 11900/320000]  base_lr: 9.6647e-05 lr: 9.6647e-06  eta: 1 day, 17:57:48  time: 0.4916  data_time: 0.0103  memory: 5893  grad_norm: 242.6191  loss: 9.4606  decode.loss_cls: 0.2867  decode.loss_mask: 0.2511  decode.loss_dice: 0.2736  decode.d0.loss_cls: 0.8663  decode.d0.loss_mask: 0.2596  decode.d0.loss_dice: 0.3477  decode.d1.loss_cls: 0.3732  decode.d1.loss_mask: 0.3121  decode.d1.loss_dice: 0.3317  decode.d2.loss_cls: 0.3314  decode.d2.loss_mask: 0.2564  decode.d2.loss_dice: 0.3124  decode.d3.loss_cls: 0.2658  decode.d3.loss_mask: 0.2583  decode.d3.loss_dice: 0.2949  decode.d4.loss_cls: 0.3227  decode.d4.loss_mask: 0.2509  decode.d4.loss_dice: 0.2993  decode.d5.loss_cls: 0.3512  decode.d5.loss_mask: 0.2526  decode.d5.loss_dice: 0.2857  decode.d6.loss_cls: 0.3408  decode.d6.loss_mask: 0.2488  decode.d6.loss_dice: 0.2904  decode.d7.loss_cls: 0.3897  decode.d7.loss_mask: 0.2506  decode.d7.loss_dice: 0.3000  decode.d8.loss_cls: 0.3032  decode.d8.loss_mask: 0.2579  decode.d8.loss_dice: 0.2955
08/06 03:54:27 - mmengine - INFO - Iter(train) [ 11950/320000]  base_lr: 9.6633e-05 lr: 9.6633e-06  eta: 1 day, 17:57:23  time: 0.4905  data_time: 0.0103  memory: 5891  grad_norm: 141.7994  loss: 8.6744  decode.loss_cls: 0.2007  decode.loss_mask: 0.2745  decode.loss_dice: 0.2697  decode.d0.loss_cls: 1.0386  decode.d0.loss_mask: 0.2857  decode.d0.loss_dice: 0.3027  decode.d1.loss_cls: 0.2783  decode.d1.loss_mask: 0.2910  decode.d1.loss_dice: 0.3037  decode.d2.loss_cls: 0.2455  decode.d2.loss_mask: 0.2769  decode.d2.loss_dice: 0.2797  decode.d3.loss_cls: 0.1946  decode.d3.loss_mask: 0.2784  decode.d3.loss_dice: 0.2727  decode.d4.loss_cls: 0.2602  decode.d4.loss_mask: 0.2726  decode.d4.loss_dice: 0.2717  decode.d5.loss_cls: 0.2060  decode.d5.loss_mask: 0.2846  decode.d5.loss_dice: 0.2780  decode.d6.loss_cls: 0.2022  decode.d6.loss_mask: 0.2849  decode.d6.loss_dice: 0.2663  decode.d7.loss_cls: 0.2112  decode.d7.loss_mask: 0.2774  decode.d7.loss_dice: 0.2763  decode.d8.loss_cls: 0.2366  decode.d8.loss_mask: 0.2743  decode.d8.loss_dice: 0.2794
08/06 03:54:51 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 03:54:51 - mmengine - INFO - Iter(train) [ 12000/320000]  base_lr: 9.6619e-05 lr: 9.6619e-06  eta: 1 day, 17:56:59  time: 0.4906  data_time: 0.0103  memory: 5964  grad_norm: 139.8817  loss: 9.7710  decode.loss_cls: 0.2598  decode.loss_mask: 0.2400  decode.loss_dice: 0.3159  decode.d0.loss_cls: 1.0868  decode.d0.loss_mask: 0.2451  decode.d0.loss_dice: 0.3749  decode.d1.loss_cls: 0.4398  decode.d1.loss_mask: 0.2470  decode.d1.loss_dice: 0.3865  decode.d2.loss_cls: 0.3417  decode.d2.loss_mask: 0.2359  decode.d2.loss_dice: 0.3272  decode.d3.loss_cls: 0.2639  decode.d3.loss_mask: 0.2358  decode.d3.loss_dice: 0.3563  decode.d4.loss_cls: 0.3122  decode.d4.loss_mask: 0.2366  decode.d4.loss_dice: 0.3238  decode.d5.loss_cls: 0.3212  decode.d5.loss_mask: 0.2383  decode.d5.loss_dice: 0.3253  decode.d6.loss_cls: 0.3332  decode.d6.loss_mask: 0.2380  decode.d6.loss_dice: 0.3247  decode.d7.loss_cls: 0.3033  decode.d7.loss_mask: 0.2448  decode.d7.loss_dice: 0.3344  decode.d8.loss_cls: 0.3004  decode.d8.loss_mask: 0.2413  decode.d8.loss_dice: 0.3367
08/06 03:55:16 - mmengine - INFO - Iter(train) [ 12050/320000]  base_lr: 9.6605e-05 lr: 9.6605e-06  eta: 1 day, 17:56:36  time: 0.4905  data_time: 0.0102  memory: 5908  grad_norm: 129.7191  loss: 9.0932  decode.loss_cls: 0.1485  decode.loss_mask: 0.3688  decode.loss_dice: 0.2882  decode.d0.loss_cls: 0.9023  decode.d0.loss_mask: 0.4052  decode.d0.loss_dice: 0.3535  decode.d1.loss_cls: 0.1940  decode.d1.loss_mask: 0.3812  decode.d1.loss_dice: 0.3075  decode.d2.loss_cls: 0.1466  decode.d2.loss_mask: 0.3754  decode.d2.loss_dice: 0.3064  decode.d3.loss_cls: 0.1450  decode.d3.loss_mask: 0.3716  decode.d3.loss_dice: 0.2814  decode.d4.loss_cls: 0.1604  decode.d4.loss_mask: 0.3758  decode.d4.loss_dice: 0.2886  decode.d5.loss_cls: 0.1582  decode.d5.loss_mask: 0.3837  decode.d5.loss_dice: 0.2955  decode.d6.loss_cls: 0.1197  decode.d6.loss_mask: 0.3828  decode.d6.loss_dice: 0.2919  decode.d7.loss_cls: 0.1481  decode.d7.loss_mask: 0.3837  decode.d7.loss_dice: 0.2947  decode.d8.loss_cls: 0.1528  decode.d8.loss_mask: 0.3798  decode.d8.loss_dice: 0.3021
08/06 03:55:40 - mmengine - INFO - Iter(train) [ 12100/320000]  base_lr: 9.6591e-05 lr: 9.6591e-06  eta: 1 day, 17:56:12  time: 0.4912  data_time: 0.0103  memory: 5893  grad_norm: 152.3067  loss: 8.8327  decode.loss_cls: 0.1989  decode.loss_mask: 0.2823  decode.loss_dice: 0.3147  decode.d0.loss_cls: 1.0539  decode.d0.loss_mask: 0.2926  decode.d0.loss_dice: 0.3585  decode.d1.loss_cls: 0.2590  decode.d1.loss_mask: 0.2828  decode.d1.loss_dice: 0.3104  decode.d2.loss_cls: 0.1879  decode.d2.loss_mask: 0.2789  decode.d2.loss_dice: 0.3281  decode.d3.loss_cls: 0.1749  decode.d3.loss_mask: 0.2862  decode.d3.loss_dice: 0.3266  decode.d4.loss_cls: 0.2037  decode.d4.loss_mask: 0.2874  decode.d4.loss_dice: 0.3202  decode.d5.loss_cls: 0.1731  decode.d5.loss_mask: 0.2832  decode.d5.loss_dice: 0.3259  decode.d6.loss_cls: 0.1537  decode.d6.loss_mask: 0.2806  decode.d6.loss_dice: 0.3269  decode.d7.loss_cls: 0.1503  decode.d7.loss_mask: 0.2796  decode.d7.loss_dice: 0.3322  decode.d8.loss_cls: 0.1727  decode.d8.loss_mask: 0.2838  decode.d8.loss_dice: 0.3242
08/06 03:56:05 - mmengine - INFO - Iter(train) [ 12150/320000]  base_lr: 9.6577e-05 lr: 9.6577e-06  eta: 1 day, 17:55:48  time: 0.4911  data_time: 0.0103  memory: 5908  grad_norm: 183.4953  loss: 11.1405  decode.loss_cls: 0.4388  decode.loss_mask: 0.2698  decode.loss_dice: 0.3170  decode.d0.loss_cls: 1.2510  decode.d0.loss_mask: 0.2865  decode.d0.loss_dice: 0.3482  decode.d1.loss_cls: 0.4810  decode.d1.loss_mask: 0.2682  decode.d1.loss_dice: 0.3267  decode.d2.loss_cls: 0.4760  decode.d2.loss_mask: 0.2710  decode.d2.loss_dice: 0.3360  decode.d3.loss_cls: 0.4542  decode.d3.loss_mask: 0.2684  decode.d3.loss_dice: 0.3104  decode.d4.loss_cls: 0.4327  decode.d4.loss_mask: 0.2699  decode.d4.loss_dice: 0.3198  decode.d5.loss_cls: 0.4236  decode.d5.loss_mask: 0.2719  decode.d5.loss_dice: 0.3042  decode.d6.loss_cls: 0.4176  decode.d6.loss_mask: 0.2681  decode.d6.loss_dice: 0.3259  decode.d7.loss_cls: 0.3879  decode.d7.loss_mask: 0.2734  decode.d7.loss_dice: 0.3031  decode.d8.loss_cls: 0.4141  decode.d8.loss_mask: 0.2807  decode.d8.loss_dice: 0.3444
08/06 03:56:29 - mmengine - INFO - Iter(train) [ 12200/320000]  base_lr: 9.6562e-05 lr: 9.6562e-06  eta: 1 day, 17:55:24  time: 0.4903  data_time: 0.0102  memory: 5876  grad_norm: 198.8734  loss: 9.1576  decode.loss_cls: 0.2925  decode.loss_mask: 0.2363  decode.loss_dice: 0.2715  decode.d0.loss_cls: 1.0049  decode.d0.loss_mask: 0.2428  decode.d0.loss_dice: 0.3140  decode.d1.loss_cls: 0.3469  decode.d1.loss_mask: 0.2376  decode.d1.loss_dice: 0.2840  decode.d2.loss_cls: 0.3591  decode.d2.loss_mask: 0.2314  decode.d2.loss_dice: 0.2829  decode.d3.loss_cls: 0.3839  decode.d3.loss_mask: 0.2368  decode.d3.loss_dice: 0.2772  decode.d4.loss_cls: 0.3930  decode.d4.loss_mask: 0.2338  decode.d4.loss_dice: 0.2657  decode.d5.loss_cls: 0.3885  decode.d5.loss_mask: 0.2357  decode.d5.loss_dice: 0.2673  decode.d6.loss_cls: 0.2834  decode.d6.loss_mask: 0.2361  decode.d6.loss_dice: 0.2730  decode.d7.loss_cls: 0.2785  decode.d7.loss_mask: 0.2376  decode.d7.loss_dice: 0.2829  decode.d8.loss_cls: 0.2694  decode.d8.loss_mask: 0.2366  decode.d8.loss_dice: 0.2743
08/06 03:56:54 - mmengine - INFO - Iter(train) [ 12250/320000]  base_lr: 9.6548e-05 lr: 9.6548e-06  eta: 1 day, 17:55:00  time: 0.4903  data_time: 0.0102  memory: 5908  grad_norm: 299.6761  loss: 11.0153  decode.loss_cls: 0.3883  decode.loss_mask: 0.2945  decode.loss_dice: 0.3467  decode.d0.loss_cls: 1.1843  decode.d0.loss_mask: 0.2975  decode.d0.loss_dice: 0.3636  decode.d1.loss_cls: 0.4661  decode.d1.loss_mask: 0.2974  decode.d1.loss_dice: 0.3420  decode.d2.loss_cls: 0.3426  decode.d2.loss_mask: 0.3428  decode.d2.loss_dice: 0.3487  decode.d3.loss_cls: 0.3275  decode.d3.loss_mask: 0.3524  decode.d3.loss_dice: 0.3724  decode.d4.loss_cls: 0.3509  decode.d4.loss_mask: 0.3141  decode.d4.loss_dice: 0.3667  decode.d5.loss_cls: 0.2726  decode.d5.loss_mask: 0.3351  decode.d5.loss_dice: 0.3609  decode.d6.loss_cls: 0.3355  decode.d6.loss_mask: 0.3368  decode.d6.loss_dice: 0.3664  decode.d7.loss_cls: 0.2601  decode.d7.loss_mask: 0.3661  decode.d7.loss_dice: 0.3461  decode.d8.loss_cls: 0.2619  decode.d8.loss_mask: 0.3203  decode.d8.loss_dice: 0.3550
08/06 03:57:18 - mmengine - INFO - Iter(train) [ 12300/320000]  base_lr: 9.6534e-05 lr: 9.6534e-06  eta: 1 day, 17:54:36  time: 0.4910  data_time: 0.0100  memory: 5908  grad_norm: 131.1414  loss: 9.1001  decode.loss_cls: 0.2411  decode.loss_mask: 0.2613  decode.loss_dice: 0.2964  decode.d0.loss_cls: 1.2613  decode.d0.loss_mask: 0.2796  decode.d0.loss_dice: 0.3198  decode.d1.loss_cls: 0.3831  decode.d1.loss_mask: 0.2769  decode.d1.loss_dice: 0.3119  decode.d2.loss_cls: 0.2317  decode.d2.loss_mask: 0.2593  decode.d2.loss_dice: 0.2751  decode.d3.loss_cls: 0.2005  decode.d3.loss_mask: 0.2646  decode.d3.loss_dice: 0.2930  decode.d4.loss_cls: 0.2842  decode.d4.loss_mask: 0.2584  decode.d4.loss_dice: 0.2753  decode.d5.loss_cls: 0.2011  decode.d5.loss_mask: 0.2616  decode.d5.loss_dice: 0.2990  decode.d6.loss_cls: 0.2351  decode.d6.loss_mask: 0.2580  decode.d6.loss_dice: 0.3093  decode.d7.loss_cls: 0.2443  decode.d7.loss_mask: 0.2568  decode.d7.loss_dice: 0.2966  decode.d8.loss_cls: 0.2333  decode.d8.loss_mask: 0.2507  decode.d8.loss_dice: 0.2807
08/06 03:57:43 - mmengine - INFO - Iter(train) [ 12350/320000]  base_lr: 9.6520e-05 lr: 9.6520e-06  eta: 1 day, 17:54:12  time: 0.4905  data_time: 0.0101  memory: 5907  grad_norm: 223.9155  loss: 10.5675  decode.loss_cls: 0.3138  decode.loss_mask: 0.2668  decode.loss_dice: 0.3451  decode.d0.loss_cls: 1.0993  decode.d0.loss_mask: 0.2763  decode.d0.loss_dice: 0.3573  decode.d1.loss_cls: 0.4423  decode.d1.loss_mask: 0.2808  decode.d1.loss_dice: 0.3609  decode.d2.loss_cls: 0.3400  decode.d2.loss_mask: 0.2724  decode.d2.loss_dice: 0.3313  decode.d3.loss_cls: 0.3645  decode.d3.loss_mask: 0.2800  decode.d3.loss_dice: 0.3539  decode.d4.loss_cls: 0.4230  decode.d4.loss_mask: 0.2682  decode.d4.loss_dice: 0.3280  decode.d5.loss_cls: 0.3581  decode.d5.loss_mask: 0.2780  decode.d5.loss_dice: 0.3449  decode.d6.loss_cls: 0.3323  decode.d6.loss_mask: 0.2854  decode.d6.loss_dice: 0.3447  decode.d7.loss_cls: 0.3374  decode.d7.loss_mask: 0.2908  decode.d7.loss_dice: 0.3408  decode.d8.loss_cls: 0.3286  decode.d8.loss_mask: 0.2842  decode.d8.loss_dice: 0.3384
08/06 03:58:08 - mmengine - INFO - Iter(train) [ 12400/320000]  base_lr: 9.6506e-05 lr: 9.6506e-06  eta: 1 day, 17:53:48  time: 0.4915  data_time: 0.0102  memory: 5875  grad_norm: 159.3665  loss: 9.6824  decode.loss_cls: 0.2659  decode.loss_mask: 0.2900  decode.loss_dice: 0.3360  decode.d0.loss_cls: 1.0691  decode.d0.loss_mask: 0.2715  decode.d0.loss_dice: 0.3551  decode.d1.loss_cls: 0.2653  decode.d1.loss_mask: 0.2900  decode.d1.loss_dice: 0.3335  decode.d2.loss_cls: 0.1569  decode.d2.loss_mask: 0.3172  decode.d2.loss_dice: 0.3529  decode.d3.loss_cls: 0.2489  decode.d3.loss_mask: 0.3064  decode.d3.loss_dice: 0.3377  decode.d4.loss_cls: 0.1637  decode.d4.loss_mask: 0.3427  decode.d4.loss_dice: 0.3614  decode.d5.loss_cls: 0.2345  decode.d5.loss_mask: 0.3646  decode.d5.loss_dice: 0.3589  decode.d6.loss_cls: 0.2230  decode.d6.loss_mask: 0.3213  decode.d6.loss_dice: 0.3473  decode.d7.loss_cls: 0.2128  decode.d7.loss_mask: 0.3069  decode.d7.loss_dice: 0.3521  decode.d8.loss_cls: 0.2783  decode.d8.loss_mask: 0.2872  decode.d8.loss_dice: 0.3313
08/06 03:58:32 - mmengine - INFO - Iter(train) [ 12450/320000]  base_lr: 9.6492e-05 lr: 9.6492e-06  eta: 1 day, 17:53:27  time: 0.4912  data_time: 0.0101  memory: 5908  grad_norm: 195.1050  loss: 10.8969  decode.loss_cls: 0.3621  decode.loss_mask: 0.2596  decode.loss_dice: 0.4077  decode.d0.loss_cls: 1.1684  decode.d0.loss_mask: 0.2708  decode.d0.loss_dice: 0.4011  decode.d1.loss_cls: 0.3161  decode.d1.loss_mask: 0.2515  decode.d1.loss_dice: 0.3683  decode.d2.loss_cls: 0.3511  decode.d2.loss_mask: 0.2516  decode.d2.loss_dice: 0.3961  decode.d3.loss_cls: 0.3378  decode.d3.loss_mask: 0.2480  decode.d3.loss_dice: 0.3641  decode.d4.loss_cls: 0.4055  decode.d4.loss_mask: 0.2570  decode.d4.loss_dice: 0.3689  decode.d5.loss_cls: 0.3211  decode.d5.loss_mask: 0.2710  decode.d5.loss_dice: 0.4066  decode.d6.loss_cls: 0.3793  decode.d6.loss_mask: 0.2619  decode.d6.loss_dice: 0.4019  decode.d7.loss_cls: 0.3300  decode.d7.loss_mask: 0.2792  decode.d7.loss_dice: 0.4065  decode.d8.loss_cls: 0.3839  decode.d8.loss_mask: 0.2725  decode.d8.loss_dice: 0.3974
08/06 03:58:57 - mmengine - INFO - Iter(train) [ 12500/320000]  base_lr: 9.6478e-05 lr: 9.6478e-06  eta: 1 day, 17:53:03  time: 0.4904  data_time: 0.0103  memory: 5907  grad_norm: 165.0392  loss: 10.1405  decode.loss_cls: 0.4229  decode.loss_mask: 0.2317  decode.loss_dice: 0.3222  decode.d0.loss_cls: 1.1309  decode.d0.loss_mask: 0.2786  decode.d0.loss_dice: 0.3495  decode.d1.loss_cls: 0.3629  decode.d1.loss_mask: 0.2400  decode.d1.loss_dice: 0.3047  decode.d2.loss_cls: 0.3893  decode.d2.loss_mask: 0.2339  decode.d2.loss_dice: 0.3152  decode.d3.loss_cls: 0.4072  decode.d3.loss_mask: 0.2314  decode.d3.loss_dice: 0.3117  decode.d4.loss_cls: 0.3802  decode.d4.loss_mask: 0.2388  decode.d4.loss_dice: 0.3108  decode.d5.loss_cls: 0.3659  decode.d5.loss_mask: 0.2405  decode.d5.loss_dice: 0.3051  decode.d6.loss_cls: 0.3693  decode.d6.loss_mask: 0.2352  decode.d6.loss_dice: 0.3085  decode.d7.loss_cls: 0.3852  decode.d7.loss_mask: 0.2371  decode.d7.loss_dice: 0.3201  decode.d8.loss_cls: 0.3481  decode.d8.loss_mask: 0.2496  decode.d8.loss_dice: 0.3142
08/06 03:59:21 - mmengine - INFO - Iter(train) [ 12550/320000]  base_lr: 9.6464e-05 lr: 9.6464e-06  eta: 1 day, 17:52:40  time: 0.4921  data_time: 0.0105  memory: 5892  grad_norm: 192.9941  loss: 9.6925  decode.loss_cls: 0.3111  decode.loss_mask: 0.2583  decode.loss_dice: 0.2934  decode.d0.loss_cls: 1.0833  decode.d0.loss_mask: 0.2655  decode.d0.loss_dice: 0.3311  decode.d1.loss_cls: 0.4827  decode.d1.loss_mask: 0.2676  decode.d1.loss_dice: 0.3181  decode.d2.loss_cls: 0.3396  decode.d2.loss_mask: 0.2638  decode.d2.loss_dice: 0.3143  decode.d3.loss_cls: 0.2953  decode.d3.loss_mask: 0.2586  decode.d3.loss_dice: 0.2887  decode.d4.loss_cls: 0.3358  decode.d4.loss_mask: 0.2574  decode.d4.loss_dice: 0.2907  decode.d5.loss_cls: 0.2601  decode.d5.loss_mask: 0.2647  decode.d5.loss_dice: 0.3103  decode.d6.loss_cls: 0.2851  decode.d6.loss_mask: 0.2598  decode.d6.loss_dice: 0.2840  decode.d7.loss_cls: 0.3612  decode.d7.loss_mask: 0.2633  decode.d7.loss_dice: 0.3035  decode.d8.loss_cls: 0.2626  decode.d8.loss_mask: 0.2683  decode.d8.loss_dice: 0.3145
08/06 03:59:46 - mmengine - INFO - Iter(train) [ 12600/320000]  base_lr: 9.6449e-05 lr: 9.6449e-06  eta: 1 day, 17:52:16  time: 0.4906  data_time: 0.0103  memory: 5891  grad_norm: 125.4699  loss: 8.0398  decode.loss_cls: 0.1932  decode.loss_mask: 0.2391  decode.loss_dice: 0.2631  decode.d0.loss_cls: 0.9860  decode.d0.loss_mask: 0.2347  decode.d0.loss_dice: 0.2647  decode.d1.loss_cls: 0.2582  decode.d1.loss_mask: 0.2515  decode.d1.loss_dice: 0.2976  decode.d2.loss_cls: 0.2598  decode.d2.loss_mask: 0.2363  decode.d2.loss_dice: 0.2723  decode.d3.loss_cls: 0.2033  decode.d3.loss_mask: 0.2494  decode.d3.loss_dice: 0.2613  decode.d4.loss_cls: 0.1985  decode.d4.loss_mask: 0.2546  decode.d4.loss_dice: 0.2540  decode.d5.loss_cls: 0.1964  decode.d5.loss_mask: 0.2561  decode.d5.loss_dice: 0.2708  decode.d6.loss_cls: 0.2186  decode.d6.loss_mask: 0.2459  decode.d6.loss_dice: 0.2678  decode.d7.loss_cls: 0.1584  decode.d7.loss_mask: 0.2588  decode.d7.loss_dice: 0.2768  decode.d8.loss_cls: 0.2170  decode.d8.loss_mask: 0.2407  decode.d8.loss_dice: 0.2549
08/06 04:00:10 - mmengine - INFO - Iter(train) [ 12650/320000]  base_lr: 9.6435e-05 lr: 9.6435e-06  eta: 1 day, 17:51:52  time: 0.4905  data_time: 0.0104  memory: 5893  grad_norm: 167.8721  loss: 8.2791  decode.loss_cls: 0.2100  decode.loss_mask: 0.2844  decode.loss_dice: 0.2875  decode.d0.loss_cls: 0.8850  decode.d0.loss_mask: 0.3094  decode.d0.loss_dice: 0.3282  decode.d1.loss_cls: 0.1703  decode.d1.loss_mask: 0.2895  decode.d1.loss_dice: 0.2993  decode.d2.loss_cls: 0.1249  decode.d2.loss_mask: 0.2817  decode.d2.loss_dice: 0.2971  decode.d3.loss_cls: 0.1529  decode.d3.loss_mask: 0.2875  decode.d3.loss_dice: 0.2913  decode.d4.loss_cls: 0.1336  decode.d4.loss_mask: 0.2898  decode.d4.loss_dice: 0.2919  decode.d5.loss_cls: 0.1260  decode.d5.loss_mask: 0.2892  decode.d5.loss_dice: 0.2944  decode.d6.loss_cls: 0.1475  decode.d6.loss_mask: 0.2896  decode.d6.loss_dice: 0.3020  decode.d7.loss_cls: 0.2151  decode.d7.loss_mask: 0.2900  decode.d7.loss_dice: 0.3024  decode.d8.loss_cls: 0.2231  decode.d8.loss_mask: 0.2876  decode.d8.loss_dice: 0.2979
08/06 04:00:35 - mmengine - INFO - Iter(train) [ 12700/320000]  base_lr: 9.6421e-05 lr: 9.6421e-06  eta: 1 day, 17:51:28  time: 0.4904  data_time: 0.0102  memory: 5892  grad_norm: 175.2658  loss: 9.9991  decode.loss_cls: 0.3958  decode.loss_mask: 0.2267  decode.loss_dice: 0.3166  decode.d0.loss_cls: 1.2310  decode.d0.loss_mask: 0.2268  decode.d0.loss_dice: 0.3141  decode.d1.loss_cls: 0.3569  decode.d1.loss_mask: 0.2282  decode.d1.loss_dice: 0.2873  decode.d2.loss_cls: 0.3443  decode.d2.loss_mask: 0.2274  decode.d2.loss_dice: 0.2905  decode.d3.loss_cls: 0.3783  decode.d3.loss_mask: 0.2240  decode.d3.loss_dice: 0.2941  decode.d4.loss_cls: 0.3939  decode.d4.loss_mask: 0.2225  decode.d4.loss_dice: 0.3002  decode.d5.loss_cls: 0.3676  decode.d5.loss_mask: 0.2240  decode.d5.loss_dice: 0.2994  decode.d6.loss_cls: 0.3925  decode.d6.loss_mask: 0.2278  decode.d6.loss_dice: 0.3043  decode.d7.loss_cls: 0.4064  decode.d7.loss_mask: 0.2297  decode.d7.loss_dice: 0.3147  decode.d8.loss_cls: 0.4218  decode.d8.loss_mask: 0.2245  decode.d8.loss_dice: 0.3276
08/06 04:01:00 - mmengine - INFO - Iter(train) [ 12750/320000]  base_lr: 9.6407e-05 lr: 9.6407e-06  eta: 1 day, 17:51:04  time: 0.4912  data_time: 0.0104  memory: 5907  grad_norm: 149.3220  loss: 8.9814  decode.loss_cls: 0.1726  decode.loss_mask: 0.2681  decode.loss_dice: 0.3073  decode.d0.loss_cls: 1.1727  decode.d0.loss_mask: 0.2758  decode.d0.loss_dice: 0.3595  decode.d1.loss_cls: 0.2921  decode.d1.loss_mask: 0.2762  decode.d1.loss_dice: 0.3214  decode.d2.loss_cls: 0.1852  decode.d2.loss_mask: 0.2768  decode.d2.loss_dice: 0.3147  decode.d3.loss_cls: 0.1453  decode.d3.loss_mask: 0.2804  decode.d3.loss_dice: 0.3070  decode.d4.loss_cls: 0.1477  decode.d4.loss_mask: 0.2801  decode.d4.loss_dice: 0.3145  decode.d5.loss_cls: 0.2770  decode.d5.loss_mask: 0.2784  decode.d5.loss_dice: 0.3126  decode.d6.loss_cls: 0.1515  decode.d6.loss_mask: 0.2800  decode.d6.loss_dice: 0.3075  decode.d7.loss_cls: 0.2412  decode.d7.loss_mask: 0.2736  decode.d7.loss_dice: 0.3200  decode.d8.loss_cls: 0.2542  decode.d8.loss_mask: 0.2780  decode.d8.loss_dice: 0.3101
08/06 04:01:24 - mmengine - INFO - Iter(train) [ 12800/320000]  base_lr: 9.6393e-05 lr: 9.6393e-06  eta: 1 day, 17:50:40  time: 0.4915  data_time: 0.0103  memory: 5890  grad_norm: 134.9562  loss: 11.1925  decode.loss_cls: 0.3691  decode.loss_mask: 0.2636  decode.loss_dice: 0.3117  decode.d0.loss_cls: 1.2954  decode.d0.loss_mask: 0.2425  decode.d0.loss_dice: 0.3269  decode.d1.loss_cls: 0.5816  decode.d1.loss_mask: 0.2492  decode.d1.loss_dice: 0.2986  decode.d2.loss_cls: 0.5637  decode.d2.loss_mask: 0.2524  decode.d2.loss_dice: 0.3396  decode.d3.loss_cls: 0.4485  decode.d3.loss_mask: 0.2500  decode.d3.loss_dice: 0.3031  decode.d4.loss_cls: 0.4530  decode.d4.loss_mask: 0.2442  decode.d4.loss_dice: 0.3078  decode.d5.loss_cls: 0.4182  decode.d5.loss_mask: 0.2512  decode.d5.loss_dice: 0.3030  decode.d6.loss_cls: 0.5043  decode.d6.loss_mask: 0.2413  decode.d6.loss_dice: 0.3007  decode.d7.loss_cls: 0.4604  decode.d7.loss_mask: 0.2854  decode.d7.loss_dice: 0.3226  decode.d8.loss_cls: 0.3892  decode.d8.loss_mask: 0.2741  decode.d8.loss_dice: 0.3411
08/06 04:01:49 - mmengine - INFO - Iter(train) [ 12850/320000]  base_lr: 9.6379e-05 lr: 9.6379e-06  eta: 1 day, 17:50:16  time: 0.4914  data_time: 0.0103  memory: 5926  grad_norm: 206.3772  loss: 11.2174  decode.loss_cls: 0.3664  decode.loss_mask: 0.2429  decode.loss_dice: 0.3903  decode.d0.loss_cls: 1.3070  decode.d0.loss_mask: 0.2637  decode.d0.loss_dice: 0.4790  decode.d1.loss_cls: 0.3303  decode.d1.loss_mask: 0.2468  decode.d1.loss_dice: 0.4364  decode.d2.loss_cls: 0.3214  decode.d2.loss_mask: 0.2379  decode.d2.loss_dice: 0.4317  decode.d3.loss_cls: 0.3427  decode.d3.loss_mask: 0.2401  decode.d3.loss_dice: 0.4042  decode.d4.loss_cls: 0.3606  decode.d4.loss_mask: 0.2383  decode.d4.loss_dice: 0.4099  decode.d5.loss_cls: 0.3407  decode.d5.loss_mask: 0.2384  decode.d5.loss_dice: 0.3992  decode.d6.loss_cls: 0.4077  decode.d6.loss_mask: 0.2396  decode.d6.loss_dice: 0.3858  decode.d7.loss_cls: 0.3758  decode.d7.loss_mask: 0.3044  decode.d7.loss_dice: 0.4169  decode.d8.loss_cls: 0.3156  decode.d8.loss_mask: 0.3143  decode.d8.loss_dice: 0.4294
08/06 04:02:13 - mmengine - INFO - Iter(train) [ 12900/320000]  base_lr: 9.6365e-05 lr: 9.6365e-06  eta: 1 day, 17:49:52  time: 0.4912  data_time: 0.0105  memory: 5892  grad_norm: 241.1287  loss: 11.2241  decode.loss_cls: 0.3939  decode.loss_mask: 0.3256  decode.loss_dice: 0.3222  decode.d0.loss_cls: 1.1710  decode.d0.loss_mask: 0.3301  decode.d0.loss_dice: 0.3656  decode.d1.loss_cls: 0.4301  decode.d1.loss_mask: 0.3321  decode.d1.loss_dice: 0.3323  decode.d2.loss_cls: 0.3857  decode.d2.loss_mask: 0.3224  decode.d2.loss_dice: 0.3253  decode.d3.loss_cls: 0.3860  decode.d3.loss_mask: 0.3286  decode.d3.loss_dice: 0.3308  decode.d4.loss_cls: 0.3902  decode.d4.loss_mask: 0.3263  decode.d4.loss_dice: 0.3213  decode.d5.loss_cls: 0.3734  decode.d5.loss_mask: 0.3324  decode.d5.loss_dice: 0.3349  decode.d6.loss_cls: 0.3665  decode.d6.loss_mask: 0.3268  decode.d6.loss_dice: 0.3217  decode.d7.loss_cls: 0.3620  decode.d7.loss_mask: 0.3291  decode.d7.loss_dice: 0.3275  decode.d8.loss_cls: 0.3495  decode.d8.loss_mask: 0.3351  decode.d8.loss_dice: 0.3455
08/06 04:02:38 - mmengine - INFO - Iter(train) [ 12950/320000]  base_lr: 9.6351e-05 lr: 9.6351e-06  eta: 1 day, 17:49:28  time: 0.4895  data_time: 0.0103  memory: 5907  grad_norm: 655.4365  loss: 10.2837  decode.loss_cls: 0.3069  decode.loss_mask: 0.3559  decode.loss_dice: 0.2894  decode.d0.loss_cls: 0.9315  decode.d0.loss_mask: 0.3765  decode.d0.loss_dice: 0.3385  decode.d1.loss_cls: 0.3076  decode.d1.loss_mask: 0.3826  decode.d1.loss_dice: 0.2875  decode.d2.loss_cls: 0.3264  decode.d2.loss_mask: 0.3615  decode.d2.loss_dice: 0.2931  decode.d3.loss_cls: 0.2899  decode.d3.loss_mask: 0.3510  decode.d3.loss_dice: 0.2959  decode.d4.loss_cls: 0.2632  decode.d4.loss_mask: 0.3551  decode.d4.loss_dice: 0.3110  decode.d5.loss_cls: 0.3226  decode.d5.loss_mask: 0.3537  decode.d5.loss_dice: 0.3152  decode.d6.loss_cls: 0.2917  decode.d6.loss_mask: 0.3551  decode.d6.loss_dice: 0.3008  decode.d7.loss_cls: 0.2905  decode.d7.loss_mask: 0.3627  decode.d7.loss_dice: 0.2943  decode.d8.loss_cls: 0.3304  decode.d8.loss_mask: 0.3558  decode.d8.loss_dice: 0.2877
08/06 04:03:02 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 04:03:02 - mmengine - INFO - Iter(train) [ 13000/320000]  base_lr: 9.6336e-05 lr: 9.6336e-06  eta: 1 day, 17:49:06  time: 0.4918  data_time: 0.0102  memory: 5908  grad_norm: 150.4788  loss: 8.6694  decode.loss_cls: 0.1502  decode.loss_mask: 0.2606  decode.loss_dice: 0.3301  decode.d0.loss_cls: 0.9214  decode.d0.loss_mask: 0.2920  decode.d0.loss_dice: 0.3678  decode.d1.loss_cls: 0.4051  decode.d1.loss_mask: 0.2657  decode.d1.loss_dice: 0.3115  decode.d2.loss_cls: 0.2701  decode.d2.loss_mask: 0.2650  decode.d2.loss_dice: 0.3198  decode.d3.loss_cls: 0.2119  decode.d3.loss_mask: 0.2571  decode.d3.loss_dice: 0.3159  decode.d4.loss_cls: 0.2000  decode.d4.loss_mask: 0.2630  decode.d4.loss_dice: 0.3130  decode.d5.loss_cls: 0.1441  decode.d5.loss_mask: 0.2642  decode.d5.loss_dice: 0.3208  decode.d6.loss_cls: 0.1689  decode.d6.loss_mask: 0.2619  decode.d6.loss_dice: 0.3116  decode.d7.loss_cls: 0.1580  decode.d7.loss_mask: 0.2596  decode.d7.loss_dice: 0.3152  decode.d8.loss_cls: 0.1609  decode.d8.loss_mask: 0.2616  decode.d8.loss_dice: 0.3224
08/06 04:03:27 - mmengine - INFO - Iter(train) [ 13050/320000]  base_lr: 9.6322e-05 lr: 9.6322e-06  eta: 1 day, 17:48:43  time: 0.4910  data_time: 0.0104  memory: 5907  grad_norm: 181.0147  loss: 12.5169  decode.loss_cls: 0.3349  decode.loss_mask: 0.3882  decode.loss_dice: 0.3752  decode.d0.loss_cls: 1.0950  decode.d0.loss_mask: 0.3790  decode.d0.loss_dice: 0.4164  decode.d1.loss_cls: 0.3779  decode.d1.loss_mask: 0.3396  decode.d1.loss_dice: 0.3920  decode.d2.loss_cls: 0.3280  decode.d2.loss_mask: 0.3551  decode.d2.loss_dice: 0.4148  decode.d3.loss_cls: 0.4430  decode.d3.loss_mask: 0.3775  decode.d3.loss_dice: 0.4304  decode.d4.loss_cls: 0.4395  decode.d4.loss_mask: 0.4020  decode.d4.loss_dice: 0.4528  decode.d5.loss_cls: 0.4416  decode.d5.loss_mask: 0.4069  decode.d5.loss_dice: 0.3534  decode.d6.loss_cls: 0.4398  decode.d6.loss_mask: 0.4175  decode.d6.loss_dice: 0.3767  decode.d7.loss_cls: 0.3874  decode.d7.loss_mask: 0.4598  decode.d7.loss_dice: 0.4202  decode.d8.loss_cls: 0.2950  decode.d8.loss_mask: 0.4150  decode.d8.loss_dice: 0.3623
08/06 04:03:51 - mmengine - INFO - Iter(train) [ 13100/320000]  base_lr: 9.6308e-05 lr: 9.6308e-06  eta: 1 day, 17:48:20  time: 0.4913  data_time: 0.0104  memory: 5908  grad_norm: 281.3044  loss: 10.1325  decode.loss_cls: 0.3432  decode.loss_mask: 0.2968  decode.loss_dice: 0.2879  decode.d0.loss_cls: 0.9871  decode.d0.loss_mask: 0.3113  decode.d0.loss_dice: 0.3681  decode.d1.loss_cls: 0.4189  decode.d1.loss_mask: 0.3018  decode.d1.loss_dice: 0.3296  decode.d2.loss_cls: 0.3276  decode.d2.loss_mask: 0.2935  decode.d2.loss_dice: 0.2909  decode.d3.loss_cls: 0.3350  decode.d3.loss_mask: 0.2903  decode.d3.loss_dice: 0.2774  decode.d4.loss_cls: 0.3340  decode.d4.loss_mask: 0.2950  decode.d4.loss_dice: 0.3043  decode.d5.loss_cls: 0.3022  decode.d5.loss_mask: 0.2933  decode.d5.loss_dice: 0.2895  decode.d6.loss_cls: 0.3624  decode.d6.loss_mask: 0.2962  decode.d6.loss_dice: 0.3053  decode.d7.loss_cls: 0.3155  decode.d7.loss_mask: 0.2946  decode.d7.loss_dice: 0.2996  decode.d8.loss_cls: 0.3840  decode.d8.loss_mask: 0.2979  decode.d8.loss_dice: 0.2994
08/06 04:04:16 - mmengine - INFO - Iter(train) [ 13150/320000]  base_lr: 9.6294e-05 lr: 9.6294e-06  eta: 1 day, 17:47:56  time: 0.4914  data_time: 0.0104  memory: 5890  grad_norm: 91.2063  loss: 8.4866  decode.loss_cls: 0.1732  decode.loss_mask: 0.3127  decode.loss_dice: 0.2796  decode.d0.loss_cls: 0.8750  decode.d0.loss_mask: 0.3187  decode.d0.loss_dice: 0.2974  decode.d1.loss_cls: 0.2450  decode.d1.loss_mask: 0.3141  decode.d1.loss_dice: 0.2924  decode.d2.loss_cls: 0.1288  decode.d2.loss_mask: 0.3154  decode.d2.loss_dice: 0.2781  decode.d3.loss_cls: 0.1311  decode.d3.loss_mask: 0.3141  decode.d3.loss_dice: 0.2805  decode.d4.loss_cls: 0.2158  decode.d4.loss_mask: 0.3063  decode.d4.loss_dice: 0.2873  decode.d5.loss_cls: 0.1981  decode.d5.loss_mask: 0.3064  decode.d5.loss_dice: 0.2839  decode.d6.loss_cls: 0.1875  decode.d6.loss_mask: 0.3060  decode.d6.loss_dice: 0.2862  decode.d7.loss_cls: 0.1994  decode.d7.loss_mask: 0.3078  decode.d7.loss_dice: 0.2903  decode.d8.loss_cls: 0.1481  decode.d8.loss_mask: 0.3108  decode.d8.loss_dice: 0.2965
08/06 04:04:41 - mmengine - INFO - Iter(train) [ 13200/320000]  base_lr: 9.6280e-05 lr: 9.6280e-06  eta: 1 day, 17:47:32  time: 0.4917  data_time: 0.0103  memory: 5875  grad_norm: 172.2837  loss: 10.5557  decode.loss_cls: 0.1928  decode.loss_mask: 0.3765  decode.loss_dice: 0.3625  decode.d0.loss_cls: 1.1592  decode.d0.loss_mask: 0.3886  decode.d0.loss_dice: 0.3806  decode.d1.loss_cls: 0.4447  decode.d1.loss_mask: 0.3437  decode.d1.loss_dice: 0.3607  decode.d2.loss_cls: 0.2753  decode.d2.loss_mask: 0.3488  decode.d2.loss_dice: 0.3560  decode.d3.loss_cls: 0.1848  decode.d3.loss_mask: 0.3578  decode.d3.loss_dice: 0.3625  decode.d4.loss_cls: 0.2160  decode.d4.loss_mask: 0.3709  decode.d4.loss_dice: 0.3604  decode.d5.loss_cls: 0.1960  decode.d5.loss_mask: 0.3605  decode.d5.loss_dice: 0.3561  decode.d6.loss_cls: 0.1922  decode.d6.loss_mask: 0.3746  decode.d6.loss_dice: 0.3584  decode.d7.loss_cls: 0.1818  decode.d7.loss_mask: 0.3903  decode.d7.loss_dice: 0.3567  decode.d8.loss_cls: 0.2009  decode.d8.loss_mask: 0.3804  decode.d8.loss_dice: 0.3659
08/06 04:05:05 - mmengine - INFO - Iter(train) [ 13250/320000]  base_lr: 9.6266e-05 lr: 9.6266e-06  eta: 1 day, 17:47:09  time: 0.4910  data_time: 0.0103  memory: 5908  grad_norm: 135.4220  loss: 10.7731  decode.loss_cls: 0.3805  decode.loss_mask: 0.3222  decode.loss_dice: 0.3375  decode.d0.loss_cls: 1.1183  decode.d0.loss_mask: 0.3254  decode.d0.loss_dice: 0.3623  decode.d1.loss_cls: 0.3540  decode.d1.loss_mask: 0.3362  decode.d1.loss_dice: 0.3202  decode.d2.loss_cls: 0.4053  decode.d2.loss_mask: 0.3096  decode.d2.loss_dice: 0.3287  decode.d3.loss_cls: 0.3875  decode.d3.loss_mask: 0.3064  decode.d3.loss_dice: 0.3419  decode.d4.loss_cls: 0.3496  decode.d4.loss_mask: 0.3104  decode.d4.loss_dice: 0.3157  decode.d5.loss_cls: 0.3303  decode.d5.loss_mask: 0.3099  decode.d5.loss_dice: 0.3210  decode.d6.loss_cls: 0.3156  decode.d6.loss_mask: 0.3127  decode.d6.loss_dice: 0.3094  decode.d7.loss_cls: 0.3333  decode.d7.loss_mask: 0.3068  decode.d7.loss_dice: 0.3338  decode.d8.loss_cls: 0.3564  decode.d8.loss_mask: 0.3090  decode.d8.loss_dice: 0.3230
08/06 04:05:30 - mmengine - INFO - Iter(train) [ 13300/320000]  base_lr: 9.6252e-05 lr: 9.6252e-06  eta: 1 day, 17:46:49  time: 0.4910  data_time: 0.0103  memory: 5876  grad_norm: 133.2691  loss: 7.9162  decode.loss_cls: 0.1108  decode.loss_mask: 0.2504  decode.loss_dice: 0.2923  decode.d0.loss_cls: 1.0243  decode.d0.loss_mask: 0.2520  decode.d0.loss_dice: 0.2912  decode.d1.loss_cls: 0.2137  decode.d1.loss_mask: 0.2465  decode.d1.loss_dice: 0.3185  decode.d2.loss_cls: 0.1733  decode.d2.loss_mask: 0.2544  decode.d2.loss_dice: 0.2824  decode.d3.loss_cls: 0.1795  decode.d3.loss_mask: 0.2528  decode.d3.loss_dice: 0.2864  decode.d4.loss_cls: 0.2107  decode.d4.loss_mask: 0.2552  decode.d4.loss_dice: 0.2885  decode.d5.loss_cls: 0.1626  decode.d5.loss_mask: 0.2630  decode.d5.loss_dice: 0.2908  decode.d6.loss_cls: 0.1122  decode.d6.loss_mask: 0.2594  decode.d6.loss_dice: 0.3036  decode.d7.loss_cls: 0.0999  decode.d7.loss_mask: 0.2580  decode.d7.loss_dice: 0.2935  decode.d8.loss_cls: 0.1304  decode.d8.loss_mask: 0.2550  decode.d8.loss_dice: 0.3046
08/06 04:05:54 - mmengine - INFO - Iter(train) [ 13350/320000]  base_lr: 9.6238e-05 lr: 9.6238e-06  eta: 1 day, 17:46:26  time: 0.4907  data_time: 0.0102  memory: 5891  grad_norm: 162.1217  loss: 10.1600  decode.loss_cls: 0.2433  decode.loss_mask: 0.3039  decode.loss_dice: 0.3877  decode.d0.loss_cls: 1.1517  decode.d0.loss_mask: 0.3024  decode.d0.loss_dice: 0.3625  decode.d1.loss_cls: 0.3348  decode.d1.loss_mask: 0.3057  decode.d1.loss_dice: 0.3703  decode.d2.loss_cls: 0.2313  decode.d2.loss_mask: 0.2951  decode.d2.loss_dice: 0.3560  decode.d3.loss_cls: 0.2700  decode.d3.loss_mask: 0.2951  decode.d3.loss_dice: 0.3480  decode.d4.loss_cls: 0.3099  decode.d4.loss_mask: 0.2962  decode.d4.loss_dice: 0.3540  decode.d5.loss_cls: 0.1866  decode.d5.loss_mask: 0.3059  decode.d5.loss_dice: 0.3871  decode.d6.loss_cls: 0.2418  decode.d6.loss_mask: 0.2935  decode.d6.loss_dice: 0.3786  decode.d7.loss_cls: 0.2954  decode.d7.loss_mask: 0.3001  decode.d7.loss_dice: 0.3566  decode.d8.loss_cls: 0.2035  decode.d8.loss_mask: 0.3008  decode.d8.loss_dice: 0.3924
08/06 04:06:19 - mmengine - INFO - Iter(train) [ 13400/320000]  base_lr: 9.6224e-05 lr: 9.6224e-06  eta: 1 day, 17:46:02  time: 0.4911  data_time: 0.0105  memory: 5889  grad_norm: 91.8216  loss: 8.7927  decode.loss_cls: 0.2143  decode.loss_mask: 0.2636  decode.loss_dice: 0.3039  decode.d0.loss_cls: 1.0392  decode.d0.loss_mask: 0.2568  decode.d0.loss_dice: 0.3360  decode.d1.loss_cls: 0.2499  decode.d1.loss_mask: 0.2674  decode.d1.loss_dice: 0.3518  decode.d2.loss_cls: 0.2094  decode.d2.loss_mask: 0.2695  decode.d2.loss_dice: 0.3036  decode.d3.loss_cls: 0.2190  decode.d3.loss_mask: 0.2659  decode.d3.loss_dice: 0.2989  decode.d4.loss_cls: 0.1800  decode.d4.loss_mask: 0.2697  decode.d4.loss_dice: 0.3211  decode.d5.loss_cls: 0.2530  decode.d5.loss_mask: 0.2670  decode.d5.loss_dice: 0.3020  decode.d6.loss_cls: 0.2153  decode.d6.loss_mask: 0.2627  decode.d6.loss_dice: 0.3148  decode.d7.loss_cls: 0.2038  decode.d7.loss_mask: 0.2630  decode.d7.loss_dice: 0.2987  decode.d8.loss_cls: 0.2283  decode.d8.loss_mask: 0.2636  decode.d8.loss_dice: 0.3001
08/06 04:06:44 - mmengine - INFO - Iter(train) [ 13450/320000]  base_lr: 9.6209e-05 lr: 9.6209e-06  eta: 1 day, 17:45:38  time: 0.4907  data_time: 0.0102  memory: 5907  grad_norm: 251.6235  loss: 11.2609  decode.loss_cls: 0.3014  decode.loss_mask: 0.3863  decode.loss_dice: 0.3490  decode.d0.loss_cls: 1.2260  decode.d0.loss_mask: 0.3780  decode.d0.loss_dice: 0.3937  decode.d1.loss_cls: 0.3916  decode.d1.loss_mask: 0.3802  decode.d1.loss_dice: 0.3553  decode.d2.loss_cls: 0.3546  decode.d2.loss_mask: 0.3799  decode.d2.loss_dice: 0.3747  decode.d3.loss_cls: 0.3391  decode.d3.loss_mask: 0.3582  decode.d3.loss_dice: 0.3389  decode.d4.loss_cls: 0.2038  decode.d4.loss_mask: 0.3722  decode.d4.loss_dice: 0.3407  decode.d5.loss_cls: 0.3185  decode.d5.loss_mask: 0.3755  decode.d5.loss_dice: 0.3416  decode.d6.loss_cls: 0.3018  decode.d6.loss_mask: 0.3686  decode.d6.loss_dice: 0.3406  decode.d7.loss_cls: 0.2838  decode.d7.loss_mask: 0.3609  decode.d7.loss_dice: 0.3419  decode.d8.loss_cls: 0.3194  decode.d8.loss_mask: 0.3637  decode.d8.loss_dice: 0.3210
08/06 04:07:08 - mmengine - INFO - Iter(train) [ 13500/320000]  base_lr: 9.6195e-05 lr: 9.6195e-06  eta: 1 day, 17:45:15  time: 0.4904  data_time: 0.0102  memory: 5890  grad_norm: 143.7465  loss: 7.5294  decode.loss_cls: 0.0831  decode.loss_mask: 0.2610  decode.loss_dice: 0.2991  decode.d0.loss_cls: 0.9054  decode.d0.loss_mask: 0.2665  decode.d0.loss_dice: 0.3372  decode.d1.loss_cls: 0.1492  decode.d1.loss_mask: 0.2630  decode.d1.loss_dice: 0.3084  decode.d2.loss_cls: 0.1396  decode.d2.loss_mask: 0.2609  decode.d2.loss_dice: 0.3029  decode.d3.loss_cls: 0.1067  decode.d3.loss_mask: 0.2606  decode.d3.loss_dice: 0.3017  decode.d4.loss_cls: 0.0931  decode.d4.loss_mask: 0.2646  decode.d4.loss_dice: 0.2918  decode.d5.loss_cls: 0.1224  decode.d5.loss_mask: 0.2628  decode.d5.loss_dice: 0.2950  decode.d6.loss_cls: 0.0957  decode.d6.loss_mask: 0.2628  decode.d6.loss_dice: 0.2987  decode.d7.loss_cls: 0.0725  decode.d7.loss_mask: 0.2639  decode.d7.loss_dice: 0.3071  decode.d8.loss_cls: 0.0887  decode.d8.loss_mask: 0.2657  decode.d8.loss_dice: 0.2995
08/06 04:07:33 - mmengine - INFO - Iter(train) [ 13550/320000]  base_lr: 9.6181e-05 lr: 9.6181e-06  eta: 1 day, 17:44:51  time: 0.4905  data_time: 0.0103  memory: 5893  grad_norm: 84.1299  loss: 7.5896  decode.loss_cls: 0.1320  decode.loss_mask: 0.2338  decode.loss_dice: 0.2853  decode.d0.loss_cls: 0.8184  decode.d0.loss_mask: 0.2391  decode.d0.loss_dice: 0.3011  decode.d1.loss_cls: 0.1923  decode.d1.loss_mask: 0.2396  decode.d1.loss_dice: 0.2873  decode.d2.loss_cls: 0.1572  decode.d2.loss_mask: 0.2417  decode.d2.loss_dice: 0.2799  decode.d3.loss_cls: 0.1680  decode.d3.loss_mask: 0.2374  decode.d3.loss_dice: 0.2776  decode.d4.loss_cls: 0.1941  decode.d4.loss_mask: 0.2439  decode.d4.loss_dice: 0.2882  decode.d5.loss_cls: 0.1730  decode.d5.loss_mask: 0.2391  decode.d5.loss_dice: 0.2854  decode.d6.loss_cls: 0.1749  decode.d6.loss_mask: 0.2378  decode.d6.loss_dice: 0.2896  decode.d7.loss_cls: 0.1644  decode.d7.loss_mask: 0.2388  decode.d7.loss_dice: 0.2822  decode.d8.loss_cls: 0.1570  decode.d8.loss_mask: 0.2381  decode.d8.loss_dice: 0.2926
08/06 04:07:57 - mmengine - INFO - Iter(train) [ 13600/320000]  base_lr: 9.6167e-05 lr: 9.6167e-06  eta: 1 day, 17:44:27  time: 0.4920  data_time: 0.0102  memory: 5908  grad_norm: 127.7151  loss: 10.5766  decode.loss_cls: 0.3971  decode.loss_mask: 0.2298  decode.loss_dice: 0.3898  decode.d0.loss_cls: 1.0272  decode.d0.loss_mask: 0.2417  decode.d0.loss_dice: 0.3909  decode.d1.loss_cls: 0.4039  decode.d1.loss_mask: 0.2439  decode.d1.loss_dice: 0.3705  decode.d2.loss_cls: 0.3018  decode.d2.loss_mask: 0.2473  decode.d2.loss_dice: 0.3674  decode.d3.loss_cls: 0.3886  decode.d3.loss_mask: 0.2426  decode.d3.loss_dice: 0.3884  decode.d4.loss_cls: 0.4092  decode.d4.loss_mask: 0.2332  decode.d4.loss_dice: 0.3870  decode.d5.loss_cls: 0.3754  decode.d5.loss_mask: 0.2348  decode.d5.loss_dice: 0.3471  decode.d6.loss_cls: 0.3863  decode.d6.loss_mask: 0.2366  decode.d6.loss_dice: 0.3605  decode.d7.loss_cls: 0.3989  decode.d7.loss_mask: 0.2342  decode.d7.loss_dice: 0.3623  decode.d8.loss_cls: 0.3761  decode.d8.loss_mask: 0.2348  decode.d8.loss_dice: 0.3693
08/06 04:08:22 - mmengine - INFO - Iter(train) [ 13650/320000]  base_lr: 9.6153e-05 lr: 9.6153e-06  eta: 1 day, 17:44:04  time: 0.4927  data_time: 0.0104  memory: 5907  grad_norm: 143.6847  loss: 8.5415  decode.loss_cls: 0.2211  decode.loss_mask: 0.2344  decode.loss_dice: 0.2663  decode.d0.loss_cls: 1.1562  decode.d0.loss_mask: 0.2474  decode.d0.loss_dice: 0.3045  decode.d1.loss_cls: 0.3383  decode.d1.loss_mask: 0.2352  decode.d1.loss_dice: 0.2860  decode.d2.loss_cls: 0.2438  decode.d2.loss_mask: 0.2329  decode.d2.loss_dice: 0.2848  decode.d3.loss_cls: 0.2725  decode.d3.loss_mask: 0.2323  decode.d3.loss_dice: 0.2671  decode.d4.loss_cls: 0.2288  decode.d4.loss_mask: 0.2287  decode.d4.loss_dice: 0.2748  decode.d5.loss_cls: 0.2402  decode.d5.loss_mask: 0.2252  decode.d5.loss_dice: 0.2854  decode.d6.loss_cls: 0.1998  decode.d6.loss_mask: 0.2318  decode.d6.loss_dice: 0.2656  decode.d7.loss_cls: 0.2392  decode.d7.loss_mask: 0.2331  decode.d7.loss_dice: 0.2730  decode.d8.loss_cls: 0.2862  decode.d8.loss_mask: 0.2322  decode.d8.loss_dice: 0.2750
08/06 04:08:46 - mmengine - INFO - Iter(train) [ 13700/320000]  base_lr: 9.6139e-05 lr: 9.6139e-06  eta: 1 day, 17:43:41  time: 0.4909  data_time: 0.0103  memory: 5891  grad_norm: 235.8359  loss: 9.9798  decode.loss_cls: 0.2284  decode.loss_mask: 0.2604  decode.loss_dice: 0.3481  decode.d0.loss_cls: 1.0942  decode.d0.loss_mask: 0.2675  decode.d0.loss_dice: 0.3713  decode.d1.loss_cls: 0.3561  decode.d1.loss_mask: 0.2742  decode.d1.loss_dice: 0.3569  decode.d2.loss_cls: 0.3920  decode.d2.loss_mask: 0.2498  decode.d2.loss_dice: 0.3362  decode.d3.loss_cls: 0.3402  decode.d3.loss_mask: 0.2610  decode.d3.loss_dice: 0.3263  decode.d4.loss_cls: 0.3608  decode.d4.loss_mask: 0.2809  decode.d4.loss_dice: 0.3337  decode.d5.loss_cls: 0.3309  decode.d5.loss_mask: 0.2715  decode.d5.loss_dice: 0.3358  decode.d6.loss_cls: 0.2830  decode.d6.loss_mask: 0.2629  decode.d6.loss_dice: 0.3209  decode.d7.loss_cls: 0.2998  decode.d7.loss_mask: 0.2606  decode.d7.loss_dice: 0.3199  decode.d8.loss_cls: 0.2369  decode.d8.loss_mask: 0.2673  decode.d8.loss_dice: 0.3523
08/06 04:09:11 - mmengine - INFO - Iter(train) [ 13750/320000]  base_lr: 9.6125e-05 lr: 9.6125e-06  eta: 1 day, 17:43:17  time: 0.4905  data_time: 0.0102  memory: 5859  grad_norm: 196.5941  loss: 11.0256  decode.loss_cls: 0.3474  decode.loss_mask: 0.2952  decode.loss_dice: 0.3466  decode.d0.loss_cls: 1.2071  decode.d0.loss_mask: 0.3162  decode.d0.loss_dice: 0.4102  decode.d1.loss_cls: 0.4732  decode.d1.loss_mask: 0.2925  decode.d1.loss_dice: 0.3490  decode.d2.loss_cls: 0.3788  decode.d2.loss_mask: 0.2907  decode.d2.loss_dice: 0.3639  decode.d3.loss_cls: 0.3987  decode.d3.loss_mask: 0.2845  decode.d3.loss_dice: 0.3607  decode.d4.loss_cls: 0.3229  decode.d4.loss_mask: 0.2934  decode.d4.loss_dice: 0.3530  decode.d5.loss_cls: 0.3835  decode.d5.loss_mask: 0.2868  decode.d5.loss_dice: 0.3593  decode.d6.loss_cls: 0.3488  decode.d6.loss_mask: 0.2871  decode.d6.loss_dice: 0.3503  decode.d7.loss_cls: 0.2916  decode.d7.loss_mask: 0.2940  decode.d7.loss_dice: 0.3512  decode.d8.loss_cls: 0.3381  decode.d8.loss_mask: 0.2940  decode.d8.loss_dice: 0.3566
08/06 04:09:36 - mmengine - INFO - Iter(train) [ 13800/320000]  base_lr: 9.6111e-05 lr: 9.6111e-06  eta: 1 day, 17:42:53  time: 0.4906  data_time: 0.0101  memory: 5890  grad_norm: 98.6803  loss: 7.1801  decode.loss_cls: 0.2087  decode.loss_mask: 0.2047  decode.loss_dice: 0.2461  decode.d0.loss_cls: 0.9893  decode.d0.loss_mask: 0.2034  decode.d0.loss_dice: 0.2423  decode.d1.loss_cls: 0.2115  decode.d1.loss_mask: 0.2053  decode.d1.loss_dice: 0.2294  decode.d2.loss_cls: 0.2063  decode.d2.loss_mask: 0.1979  decode.d2.loss_dice: 0.2372  decode.d3.loss_cls: 0.2248  decode.d3.loss_mask: 0.1976  decode.d3.loss_dice: 0.2297  decode.d4.loss_cls: 0.2139  decode.d4.loss_mask: 0.1964  decode.d4.loss_dice: 0.2301  decode.d5.loss_cls: 0.1984  decode.d5.loss_mask: 0.1992  decode.d5.loss_dice: 0.2358  decode.d6.loss_cls: 0.1943  decode.d6.loss_mask: 0.1984  decode.d6.loss_dice: 0.2209  decode.d7.loss_cls: 0.1910  decode.d7.loss_mask: 0.1954  decode.d7.loss_dice: 0.2441  decode.d8.loss_cls: 0.2072  decode.d8.loss_mask: 0.1979  decode.d8.loss_dice: 0.2226
08/06 04:10:00 - mmengine - INFO - Iter(train) [ 13850/320000]  base_lr: 9.6096e-05 lr: 9.6096e-06  eta: 1 day, 17:42:29  time: 0.4916  data_time: 0.0104  memory: 5908  grad_norm: 221.4418  loss: 10.5240  decode.loss_cls: 0.2628  decode.loss_mask: 0.3703  decode.loss_dice: 0.3830  decode.d0.loss_cls: 1.0758  decode.d0.loss_mask: 0.3413  decode.d0.loss_dice: 0.3824  decode.d1.loss_cls: 0.3710  decode.d1.loss_mask: 0.3377  decode.d1.loss_dice: 0.3499  decode.d2.loss_cls: 0.3084  decode.d2.loss_mask: 0.3299  decode.d2.loss_dice: 0.3456  decode.d3.loss_cls: 0.2810  decode.d3.loss_mask: 0.3377  decode.d3.loss_dice: 0.3403  decode.d4.loss_cls: 0.2422  decode.d4.loss_mask: 0.3405  decode.d4.loss_dice: 0.3395  decode.d5.loss_cls: 0.2006  decode.d5.loss_mask: 0.3401  decode.d5.loss_dice: 0.3701  decode.d6.loss_cls: 0.2661  decode.d6.loss_mask: 0.3347  decode.d6.loss_dice: 0.3733  decode.d7.loss_cls: 0.2611  decode.d7.loss_mask: 0.3421  decode.d7.loss_dice: 0.3349  decode.d8.loss_cls: 0.2485  decode.d8.loss_mask: 0.3541  decode.d8.loss_dice: 0.3589
08/06 04:10:25 - mmengine - INFO - Iter(train) [ 13900/320000]  base_lr: 9.6082e-05 lr: 9.6082e-06  eta: 1 day, 17:42:08  time: 0.4909  data_time: 0.0100  memory: 5895  grad_norm: 136.6485  loss: 7.6672  decode.loss_cls: 0.1404  decode.loss_mask: 0.2149  decode.loss_dice: 0.2911  decode.d0.loss_cls: 1.0636  decode.d0.loss_mask: 0.2266  decode.d0.loss_dice: 0.3119  decode.d1.loss_cls: 0.3105  decode.d1.loss_mask: 0.2115  decode.d1.loss_dice: 0.2665  decode.d2.loss_cls: 0.1784  decode.d2.loss_mask: 0.2038  decode.d2.loss_dice: 0.2738  decode.d3.loss_cls: 0.2047  decode.d3.loss_mask: 0.2050  decode.d3.loss_dice: 0.2796  decode.d4.loss_cls: 0.2148  decode.d4.loss_mask: 0.2022  decode.d4.loss_dice: 0.2758  decode.d5.loss_cls: 0.2075  decode.d5.loss_mask: 0.2017  decode.d5.loss_dice: 0.2659  decode.d6.loss_cls: 0.1227  decode.d6.loss_mask: 0.2040  decode.d6.loss_dice: 0.2830  decode.d7.loss_cls: 0.1356  decode.d7.loss_mask: 0.2059  decode.d7.loss_dice: 0.2870  decode.d8.loss_cls: 0.1654  decode.d8.loss_mask: 0.2145  decode.d8.loss_dice: 0.2989
08/06 04:10:49 - mmengine - INFO - Iter(train) [ 13950/320000]  base_lr: 9.6068e-05 lr: 9.6068e-06  eta: 1 day, 17:41:44  time: 0.4903  data_time: 0.0102  memory: 5875  grad_norm: 144.0262  loss: 9.6042  decode.loss_cls: 0.3260  decode.loss_mask: 0.2574  decode.loss_dice: 0.3232  decode.d0.loss_cls: 1.0748  decode.d0.loss_mask: 0.2748  decode.d0.loss_dice: 0.3067  decode.d1.loss_cls: 0.3375  decode.d1.loss_mask: 0.2607  decode.d1.loss_dice: 0.3192  decode.d2.loss_cls: 0.3264  decode.d2.loss_mask: 0.2632  decode.d2.loss_dice: 0.3055  decode.d3.loss_cls: 0.3055  decode.d3.loss_mask: 0.2745  decode.d3.loss_dice: 0.2811  decode.d4.loss_cls: 0.2975  decode.d4.loss_mask: 0.2589  decode.d4.loss_dice: 0.3041  decode.d5.loss_cls: 0.3577  decode.d5.loss_mask: 0.2596  decode.d5.loss_dice: 0.2942  decode.d6.loss_cls: 0.2924  decode.d6.loss_mask: 0.2611  decode.d6.loss_dice: 0.2889  decode.d7.loss_cls: 0.3060  decode.d7.loss_mask: 0.2642  decode.d7.loss_dice: 0.2900  decode.d8.loss_cls: 0.3366  decode.d8.loss_mask: 0.2595  decode.d8.loss_dice: 0.2970
08/06 04:11:14 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 04:11:14 - mmengine - INFO - Iter(train) [ 14000/320000]  base_lr: 9.6054e-05 lr: 9.6054e-06  eta: 1 day, 17:41:21  time: 0.4914  data_time: 0.0105  memory: 5875  grad_norm: 206.5437  loss: 11.3751  decode.loss_cls: 0.3724  decode.loss_mask: 0.3160  decode.loss_dice: 0.4415  decode.d0.loss_cls: 1.0295  decode.d0.loss_mask: 0.2878  decode.d0.loss_dice: 0.4160  decode.d1.loss_cls: 0.3899  decode.d1.loss_mask: 0.3035  decode.d1.loss_dice: 0.4265  decode.d2.loss_cls: 0.3271  decode.d2.loss_mask: 0.2951  decode.d2.loss_dice: 0.4023  decode.d3.loss_cls: 0.3792  decode.d3.loss_mask: 0.2957  decode.d3.loss_dice: 0.4030  decode.d4.loss_cls: 0.3642  decode.d4.loss_mask: 0.3032  decode.d4.loss_dice: 0.4306  decode.d5.loss_cls: 0.3179  decode.d5.loss_mask: 0.2932  decode.d5.loss_dice: 0.3815  decode.d6.loss_cls: 0.3486  decode.d6.loss_mask: 0.2879  decode.d6.loss_dice: 0.4104  decode.d7.loss_cls: 0.3597  decode.d7.loss_mask: 0.2969  decode.d7.loss_dice: 0.3954  decode.d8.loss_cls: 0.3742  decode.d8.loss_mask: 0.2951  decode.d8.loss_dice: 0.4308
08/06 04:11:38 - mmengine - INFO - Iter(train) [ 14050/320000]  base_lr: 9.6040e-05 lr: 9.6040e-06  eta: 1 day, 17:40:58  time: 0.4917  data_time: 0.0105  memory: 5910  grad_norm: 148.0372  loss: 7.5473  decode.loss_cls: 0.1595  decode.loss_mask: 0.2123  decode.loss_dice: 0.2346  decode.d0.loss_cls: 1.1657  decode.d0.loss_mask: 0.2462  decode.d0.loss_dice: 0.2863  decode.d1.loss_cls: 0.2262  decode.d1.loss_mask: 0.2238  decode.d1.loss_dice: 0.2689  decode.d2.loss_cls: 0.2314  decode.d2.loss_mask: 0.2164  decode.d2.loss_dice: 0.2475  decode.d3.loss_cls: 0.1918  decode.d3.loss_mask: 0.2159  decode.d3.loss_dice: 0.2585  decode.d4.loss_cls: 0.1881  decode.d4.loss_mask: 0.2153  decode.d4.loss_dice: 0.2253  decode.d5.loss_cls: 0.1788  decode.d5.loss_mask: 0.2101  decode.d5.loss_dice: 0.2432  decode.d6.loss_cls: 0.1657  decode.d6.loss_mask: 0.2100  decode.d6.loss_dice: 0.2468  decode.d7.loss_cls: 0.1558  decode.d7.loss_mask: 0.2196  decode.d7.loss_dice: 0.2519  decode.d8.loss_cls: 0.1655  decode.d8.loss_mask: 0.2243  decode.d8.loss_dice: 0.2619
08/06 04:12:03 - mmengine - INFO - Iter(train) [ 14100/320000]  base_lr: 9.6026e-05 lr: 9.6026e-06  eta: 1 day, 17:40:34  time: 0.4913  data_time: 0.0103  memory: 5890  grad_norm: 251.7614  loss: 10.6092  decode.loss_cls: 0.3343  decode.loss_mask: 0.3074  decode.loss_dice: 0.3073  decode.d0.loss_cls: 1.1121  decode.d0.loss_mask: 0.3188  decode.d0.loss_dice: 0.3174  decode.d1.loss_cls: 0.4518  decode.d1.loss_mask: 0.2437  decode.d1.loss_dice: 0.3062  decode.d2.loss_cls: 0.3861  decode.d2.loss_mask: 0.3234  decode.d2.loss_dice: 0.3219  decode.d3.loss_cls: 0.3730  decode.d3.loss_mask: 0.3293  decode.d3.loss_dice: 0.3089  decode.d4.loss_cls: 0.3607  decode.d4.loss_mask: 0.3224  decode.d4.loss_dice: 0.3224  decode.d5.loss_cls: 0.3152  decode.d5.loss_mask: 0.3108  decode.d5.loss_dice: 0.3226  decode.d6.loss_cls: 0.3349  decode.d6.loss_mask: 0.3255  decode.d6.loss_dice: 0.3368  decode.d7.loss_cls: 0.3374  decode.d7.loss_mask: 0.3417  decode.d7.loss_dice: 0.3056  decode.d8.loss_cls: 0.3089  decode.d8.loss_mask: 0.3178  decode.d8.loss_dice: 0.3048
08/06 04:12:28 - mmengine - INFO - Iter(train) [ 14150/320000]  base_lr: 9.6012e-05 lr: 9.6012e-06  eta: 1 day, 17:40:11  time: 0.4916  data_time: 0.0103  memory: 5908  grad_norm: 198.8179  loss: 10.0961  decode.loss_cls: 0.3266  decode.loss_mask: 0.2642  decode.loss_dice: 0.3570  decode.d0.loss_cls: 1.0930  decode.d0.loss_mask: 0.2741  decode.d0.loss_dice: 0.4015  decode.d1.loss_cls: 0.2455  decode.d1.loss_mask: 0.2719  decode.d1.loss_dice: 0.4033  decode.d2.loss_cls: 0.3173  decode.d2.loss_mask: 0.2619  decode.d2.loss_dice: 0.3558  decode.d3.loss_cls: 0.3483  decode.d3.loss_mask: 0.2642  decode.d3.loss_dice: 0.3643  decode.d4.loss_cls: 0.3302  decode.d4.loss_mask: 0.2657  decode.d4.loss_dice: 0.3389  decode.d5.loss_cls: 0.2940  decode.d5.loss_mask: 0.2681  decode.d5.loss_dice: 0.3646  decode.d6.loss_cls: 0.2827  decode.d6.loss_mask: 0.2607  decode.d6.loss_dice: 0.3429  decode.d7.loss_cls: 0.2669  decode.d7.loss_mask: 0.2662  decode.d7.loss_dice: 0.3488  decode.d8.loss_cls: 0.2961  decode.d8.loss_mask: 0.2643  decode.d8.loss_dice: 0.3571
08/06 04:12:52 - mmengine - INFO - Iter(train) [ 14200/320000]  base_lr: 9.5998e-05 lr: 9.5998e-06  eta: 1 day, 17:39:48  time: 0.4911  data_time: 0.0103  memory: 5891  grad_norm: 131.2748  loss: 9.1584  decode.loss_cls: 0.2620  decode.loss_mask: 0.3283  decode.loss_dice: 0.3006  decode.d0.loss_cls: 0.8636  decode.d0.loss_mask: 0.3020  decode.d0.loss_dice: 0.2839  decode.d1.loss_cls: 0.2621  decode.d1.loss_mask: 0.3038  decode.d1.loss_dice: 0.2928  decode.d2.loss_cls: 0.2144  decode.d2.loss_mask: 0.3058  decode.d2.loss_dice: 0.2852  decode.d3.loss_cls: 0.2358  decode.d3.loss_mask: 0.3460  decode.d3.loss_dice: 0.2922  decode.d4.loss_cls: 0.2274  decode.d4.loss_mask: 0.3166  decode.d4.loss_dice: 0.3023  decode.d5.loss_cls: 0.2420  decode.d5.loss_mask: 0.2930  decode.d5.loss_dice: 0.2970  decode.d6.loss_cls: 0.2115  decode.d6.loss_mask: 0.3218  decode.d6.loss_dice: 0.3029  decode.d7.loss_cls: 0.2549  decode.d7.loss_mask: 0.3110  decode.d7.loss_dice: 0.3057  decode.d8.loss_cls: 0.2753  decode.d8.loss_mask: 0.3121  decode.d8.loss_dice: 0.3065
08/06 04:13:17 - mmengine - INFO - Iter(train) [ 14250/320000]  base_lr: 9.5983e-05 lr: 9.5983e-06  eta: 1 day, 17:39:25  time: 0.4911  data_time: 0.0104  memory: 5909  grad_norm: 121.0540  loss: 11.3513  decode.loss_cls: 0.3187  decode.loss_mask: 0.3612  decode.loss_dice: 0.3293  decode.d0.loss_cls: 1.1553  decode.d0.loss_mask: 0.3489  decode.d0.loss_dice: 0.3629  decode.d1.loss_cls: 0.4491  decode.d1.loss_mask: 0.3892  decode.d1.loss_dice: 0.3685  decode.d2.loss_cls: 0.3644  decode.d2.loss_mask: 0.3429  decode.d2.loss_dice: 0.3420  decode.d3.loss_cls: 0.3449  decode.d3.loss_mask: 0.3646  decode.d3.loss_dice: 0.3376  decode.d4.loss_cls: 0.3759  decode.d4.loss_mask: 0.3518  decode.d4.loss_dice: 0.3237  decode.d5.loss_cls: 0.3763  decode.d5.loss_mask: 0.3485  decode.d5.loss_dice: 0.3281  decode.d6.loss_cls: 0.3234  decode.d6.loss_mask: 0.3575  decode.d6.loss_dice: 0.3255  decode.d7.loss_cls: 0.3435  decode.d7.loss_mask: 0.3538  decode.d7.loss_dice: 0.3280  decode.d8.loss_cls: 0.3220  decode.d8.loss_mask: 0.3596  decode.d8.loss_dice: 0.3542
08/06 04:13:41 - mmengine - INFO - Iter(train) [ 14300/320000]  base_lr: 9.5969e-05 lr: 9.5969e-06  eta: 1 day, 17:39:01  time: 0.4913  data_time: 0.0104  memory: 5889  grad_norm: 108.9766  loss: 9.2682  decode.loss_cls: 0.2415  decode.loss_mask: 0.2882  decode.loss_dice: 0.3656  decode.d0.loss_cls: 0.8897  decode.d0.loss_mask: 0.2917  decode.d0.loss_dice: 0.3465  decode.d1.loss_cls: 0.3608  decode.d1.loss_mask: 0.2846  decode.d1.loss_dice: 0.3171  decode.d2.loss_cls: 0.2359  decode.d2.loss_mask: 0.2848  decode.d2.loss_dice: 0.3299  decode.d3.loss_cls: 0.2204  decode.d3.loss_mask: 0.2813  decode.d3.loss_dice: 0.3249  decode.d4.loss_cls: 0.2135  decode.d4.loss_mask: 0.2842  decode.d4.loss_dice: 0.3188  decode.d5.loss_cls: 0.2562  decode.d5.loss_mask: 0.2871  decode.d5.loss_dice: 0.3465  decode.d6.loss_cls: 0.2099  decode.d6.loss_mask: 0.2824  decode.d6.loss_dice: 0.3308  decode.d7.loss_cls: 0.2378  decode.d7.loss_mask: 0.2815  decode.d7.loss_dice: 0.3285  decode.d8.loss_cls: 0.2167  decode.d8.loss_mask: 0.2836  decode.d8.loss_dice: 0.3278
08/06 04:14:06 - mmengine - INFO - Iter(train) [ 14350/320000]  base_lr: 9.5955e-05 lr: 9.5955e-06  eta: 1 day, 17:38:38  time: 0.4906  data_time: 0.0103  memory: 5892  grad_norm: 118.8321  loss: 10.9922  decode.loss_cls: 0.2281  decode.loss_mask: 0.3222  decode.loss_dice: 0.4000  decode.d0.loss_cls: 1.0412  decode.d0.loss_mask: 0.3459  decode.d0.loss_dice: 0.4547  decode.d1.loss_cls: 0.3320  decode.d1.loss_mask: 0.3315  decode.d1.loss_dice: 0.3902  decode.d2.loss_cls: 0.3081  decode.d2.loss_mask: 0.3219  decode.d2.loss_dice: 0.3927  decode.d3.loss_cls: 0.2945  decode.d3.loss_mask: 0.3238  decode.d3.loss_dice: 0.3714  decode.d4.loss_cls: 0.3279  decode.d4.loss_mask: 0.3300  decode.d4.loss_dice: 0.3831  decode.d5.loss_cls: 0.3694  decode.d5.loss_mask: 0.3246  decode.d5.loss_dice: 0.3946  decode.d6.loss_cls: 0.2636  decode.d6.loss_mask: 0.3298  decode.d6.loss_dice: 0.3998  decode.d7.loss_cls: 0.3113  decode.d7.loss_mask: 0.3275  decode.d7.loss_dice: 0.4015  decode.d8.loss_cls: 0.2626  decode.d8.loss_mask: 0.3238  decode.d8.loss_dice: 0.3845
08/06 04:14:31 - mmengine - INFO - Iter(train) [ 14400/320000]  base_lr: 9.5941e-05 lr: 9.5941e-06  eta: 1 day, 17:38:17  time: 0.4925  data_time: 0.0103  memory: 5892  grad_norm: 183.3221  loss: 11.0750  decode.loss_cls: 0.3595  decode.loss_mask: 0.3281  decode.loss_dice: 0.3292  decode.d0.loss_cls: 1.2736  decode.d0.loss_mask: 0.3074  decode.d0.loss_dice: 0.3824  decode.d1.loss_cls: 0.4431  decode.d1.loss_mask: 0.2815  decode.d1.loss_dice: 0.3421  decode.d2.loss_cls: 0.3906  decode.d2.loss_mask: 0.3249  decode.d2.loss_dice: 0.3261  decode.d3.loss_cls: 0.3379  decode.d3.loss_mask: 0.2867  decode.d3.loss_dice: 0.3116  decode.d4.loss_cls: 0.3624  decode.d4.loss_mask: 0.2931  decode.d4.loss_dice: 0.3181  decode.d5.loss_cls: 0.3309  decode.d5.loss_mask: 0.3269  decode.d5.loss_dice: 0.3192  decode.d6.loss_cls: 0.3104  decode.d6.loss_mask: 0.3642  decode.d6.loss_dice: 0.3258  decode.d7.loss_cls: 0.3685  decode.d7.loss_mask: 0.3715  decode.d7.loss_dice: 0.3299  decode.d8.loss_cls: 0.3632  decode.d8.loss_mask: 0.3353  decode.d8.loss_dice: 0.3309
08/06 04:14:55 - mmengine - INFO - Iter(train) [ 14450/320000]  base_lr: 9.5927e-05 lr: 9.5927e-06  eta: 1 day, 17:37:54  time: 0.4919  data_time: 0.0105  memory: 5908  grad_norm: 154.7654  loss: 9.9378  decode.loss_cls: 0.2244  decode.loss_mask: 0.3395  decode.loss_dice: 0.3073  decode.d0.loss_cls: 1.0733  decode.d0.loss_mask: 0.3525  decode.d0.loss_dice: 0.3398  decode.d1.loss_cls: 0.2590  decode.d1.loss_mask: 0.3551  decode.d1.loss_dice: 0.3152  decode.d2.loss_cls: 0.1509  decode.d2.loss_mask: 0.3695  decode.d2.loss_dice: 0.3355  decode.d3.loss_cls: 0.2597  decode.d3.loss_mask: 0.3758  decode.d3.loss_dice: 0.3294  decode.d4.loss_cls: 0.2424  decode.d4.loss_mask: 0.3530  decode.d4.loss_dice: 0.3164  decode.d5.loss_cls: 0.2711  decode.d5.loss_mask: 0.3387  decode.d5.loss_dice: 0.3156  decode.d6.loss_cls: 0.2179  decode.d6.loss_mask: 0.3404  decode.d6.loss_dice: 0.3122  decode.d7.loss_cls: 0.2811  decode.d7.loss_mask: 0.3438  decode.d7.loss_dice: 0.3179  decode.d8.loss_cls: 0.2552  decode.d8.loss_mask: 0.3362  decode.d8.loss_dice: 0.3092
08/06 04:15:20 - mmengine - INFO - Iter(train) [ 14500/320000]  base_lr: 9.5913e-05 lr: 9.5913e-06  eta: 1 day, 17:37:31  time: 0.4913  data_time: 0.0105  memory: 5908  grad_norm: 229.7507  loss: 9.0506  decode.loss_cls: 0.1394  decode.loss_mask: 0.3469  decode.loss_dice: 0.3323  decode.d0.loss_cls: 0.9047  decode.d0.loss_mask: 0.3665  decode.d0.loss_dice: 0.3741  decode.d1.loss_cls: 0.1706  decode.d1.loss_mask: 0.3533  decode.d1.loss_dice: 0.3391  decode.d2.loss_cls: 0.1238  decode.d2.loss_mask: 0.3510  decode.d2.loss_dice: 0.3287  decode.d3.loss_cls: 0.1444  decode.d3.loss_mask: 0.3507  decode.d3.loss_dice: 0.3339  decode.d4.loss_cls: 0.1682  decode.d4.loss_mask: 0.3471  decode.d4.loss_dice: 0.3108  decode.d5.loss_cls: 0.1354  decode.d5.loss_mask: 0.3518  decode.d5.loss_dice: 0.3253  decode.d6.loss_cls: 0.1645  decode.d6.loss_mask: 0.3495  decode.d6.loss_dice: 0.3134  decode.d7.loss_cls: 0.1174  decode.d7.loss_mask: 0.3520  decode.d7.loss_dice: 0.3319  decode.d8.loss_cls: 0.1340  decode.d8.loss_mask: 0.3539  decode.d8.loss_dice: 0.3358
08/06 04:15:44 - mmengine - INFO - Iter(train) [ 14550/320000]  base_lr: 9.5899e-05 lr: 9.5899e-06  eta: 1 day, 17:37:08  time: 0.4905  data_time: 0.0103  memory: 5928  grad_norm: 123.0440  loss: 10.0383  decode.loss_cls: 0.3112  decode.loss_mask: 0.2440  decode.loss_dice: 0.3690  decode.d0.loss_cls: 1.1808  decode.d0.loss_mask: 0.2502  decode.d0.loss_dice: 0.3980  decode.d1.loss_cls: 0.3546  decode.d1.loss_mask: 0.2555  decode.d1.loss_dice: 0.3776  decode.d2.loss_cls: 0.2634  decode.d2.loss_mask: 0.2431  decode.d2.loss_dice: 0.3872  decode.d3.loss_cls: 0.2596  decode.d3.loss_mask: 0.2422  decode.d3.loss_dice: 0.3561  decode.d4.loss_cls: 0.2992  decode.d4.loss_mask: 0.2447  decode.d4.loss_dice: 0.3513  decode.d5.loss_cls: 0.2779  decode.d5.loss_mask: 0.2411  decode.d5.loss_dice: 0.3668  decode.d6.loss_cls: 0.3236  decode.d6.loss_mask: 0.2459  decode.d6.loss_dice: 0.3592  decode.d7.loss_cls: 0.2649  decode.d7.loss_mask: 0.2424  decode.d7.loss_dice: 0.3637  decode.d8.loss_cls: 0.3719  decode.d8.loss_mask: 0.2379  decode.d8.loss_dice: 0.3552
08/06 04:16:09 - mmengine - INFO - Iter(train) [ 14600/320000]  base_lr: 9.5884e-05 lr: 9.5884e-06  eta: 1 day, 17:36:44  time: 0.4907  data_time: 0.0101  memory: 5875  grad_norm: 168.7204  loss: 7.0663  decode.loss_cls: 0.1064  decode.loss_mask: 0.2389  decode.loss_dice: 0.2439  decode.d0.loss_cls: 0.8709  decode.d0.loss_mask: 0.2496  decode.d0.loss_dice: 0.2641  decode.d1.loss_cls: 0.1329  decode.d1.loss_mask: 0.2437  decode.d1.loss_dice: 0.2609  decode.d2.loss_cls: 0.1109  decode.d2.loss_mask: 0.2467  decode.d2.loss_dice: 0.2647  decode.d3.loss_cls: 0.1185  decode.d3.loss_mask: 0.2461  decode.d3.loss_dice: 0.2589  decode.d4.loss_cls: 0.1246  decode.d4.loss_mask: 0.2570  decode.d4.loss_dice: 0.2659  decode.d5.loss_cls: 0.1375  decode.d5.loss_mask: 0.2491  decode.d5.loss_dice: 0.2642  decode.d6.loss_cls: 0.1297  decode.d6.loss_mask: 0.2529  decode.d6.loss_dice: 0.2644  decode.d7.loss_cls: 0.1163  decode.d7.loss_mask: 0.2541  decode.d7.loss_dice: 0.2547  decode.d8.loss_cls: 0.1521  decode.d8.loss_mask: 0.2408  decode.d8.loss_dice: 0.2457
08/06 04:16:34 - mmengine - INFO - Iter(train) [ 14650/320000]  base_lr: 9.5870e-05 lr: 9.5870e-06  eta: 1 day, 17:36:20  time: 0.4915  data_time: 0.0102  memory: 5908  grad_norm: 196.1754  loss: 10.8335  decode.loss_cls: 0.2709  decode.loss_mask: 0.2919  decode.loss_dice: 0.3785  decode.d0.loss_cls: 1.0172  decode.d0.loss_mask: 0.2790  decode.d0.loss_dice: 0.4163  decode.d1.loss_cls: 0.4444  decode.d1.loss_mask: 0.3018  decode.d1.loss_dice: 0.3880  decode.d2.loss_cls: 0.3692  decode.d2.loss_mask: 0.2739  decode.d2.loss_dice: 0.3766  decode.d3.loss_cls: 0.3599  decode.d3.loss_mask: 0.2880  decode.d3.loss_dice: 0.3823  decode.d4.loss_cls: 0.3914  decode.d4.loss_mask: 0.2835  decode.d4.loss_dice: 0.3743  decode.d5.loss_cls: 0.3265  decode.d5.loss_mask: 0.2871  decode.d5.loss_dice: 0.3709  decode.d6.loss_cls: 0.3067  decode.d6.loss_mask: 0.2890  decode.d6.loss_dice: 0.3937  decode.d7.loss_cls: 0.3084  decode.d7.loss_mask: 0.2942  decode.d7.loss_dice: 0.3766  decode.d8.loss_cls: 0.3096  decode.d8.loss_mask: 0.2992  decode.d8.loss_dice: 0.3845
08/06 04:16:58 - mmengine - INFO - Iter(train) [ 14700/320000]  base_lr: 9.5856e-05 lr: 9.5856e-06  eta: 1 day, 17:36:00  time: 0.4902  data_time: 0.0102  memory: 5892  grad_norm: 156.0396  loss: 9.3265  decode.loss_cls: 0.2554  decode.loss_mask: 0.2837  decode.loss_dice: 0.3509  decode.d0.loss_cls: 0.9526  decode.d0.loss_mask: 0.3009  decode.d0.loss_dice: 0.3647  decode.d1.loss_cls: 0.2266  decode.d1.loss_mask: 0.2985  decode.d1.loss_dice: 0.3695  decode.d2.loss_cls: 0.1997  decode.d2.loss_mask: 0.2876  decode.d2.loss_dice: 0.3351  decode.d3.loss_cls: 0.2023  decode.d3.loss_mask: 0.2848  decode.d3.loss_dice: 0.3306  decode.d4.loss_cls: 0.1984  decode.d4.loss_mask: 0.2873  decode.d4.loss_dice: 0.3412  decode.d5.loss_cls: 0.2118  decode.d5.loss_mask: 0.2873  decode.d5.loss_dice: 0.3617  decode.d6.loss_cls: 0.2504  decode.d6.loss_mask: 0.2796  decode.d6.loss_dice: 0.3223  decode.d7.loss_cls: 0.2324  decode.d7.loss_mask: 0.2825  decode.d7.loss_dice: 0.3523  decode.d8.loss_cls: 0.2392  decode.d8.loss_mask: 0.2841  decode.d8.loss_dice: 0.3530
08/06 04:17:23 - mmengine - INFO - Iter(train) [ 14750/320000]  base_lr: 9.5842e-05 lr: 9.5842e-06  eta: 1 day, 17:35:36  time: 0.4896  data_time: 0.0104  memory: 5859  grad_norm: 241.1206  loss: 9.2489  decode.loss_cls: 0.1949  decode.loss_mask: 0.3039  decode.loss_dice: 0.2798  decode.d0.loss_cls: 1.0261  decode.d0.loss_mask: 0.2798  decode.d0.loss_dice: 0.3060  decode.d1.loss_cls: 0.3194  decode.d1.loss_mask: 0.2984  decode.d1.loss_dice: 0.2958  decode.d2.loss_cls: 0.2980  decode.d2.loss_mask: 0.2932  decode.d2.loss_dice: 0.3128  decode.d3.loss_cls: 0.3090  decode.d3.loss_mask: 0.2962  decode.d3.loss_dice: 0.3094  decode.d4.loss_cls: 0.2606  decode.d4.loss_mask: 0.2999  decode.d4.loss_dice: 0.2850  decode.d5.loss_cls: 0.2526  decode.d5.loss_mask: 0.2966  decode.d5.loss_dice: 0.3020  decode.d6.loss_cls: 0.2355  decode.d6.loss_mask: 0.2886  decode.d6.loss_dice: 0.2849  decode.d7.loss_cls: 0.2457  decode.d7.loss_mask: 0.3004  decode.d7.loss_dice: 0.2739  decode.d8.loss_cls: 0.2077  decode.d8.loss_mask: 0.2977  decode.d8.loss_dice: 0.2952
08/06 04:17:47 - mmengine - INFO - Iter(train) [ 14800/320000]  base_lr: 9.5828e-05 lr: 9.5828e-06  eta: 1 day, 17:35:13  time: 0.4917  data_time: 0.0103  memory: 5907  grad_norm: 339.3310  loss: 9.7377  decode.loss_cls: 0.2705  decode.loss_mask: 0.2526  decode.loss_dice: 0.2956  decode.d0.loss_cls: 1.1887  decode.d0.loss_mask: 0.2718  decode.d0.loss_dice: 0.3177  decode.d1.loss_cls: 0.4624  decode.d1.loss_mask: 0.2798  decode.d1.loss_dice: 0.3243  decode.d2.loss_cls: 0.4203  decode.d2.loss_mask: 0.2628  decode.d2.loss_dice: 0.2865  decode.d3.loss_cls: 0.2872  decode.d3.loss_mask: 0.2627  decode.d3.loss_dice: 0.3155  decode.d4.loss_cls: 0.3450  decode.d4.loss_mask: 0.2625  decode.d4.loss_dice: 0.3138  decode.d5.loss_cls: 0.2422  decode.d5.loss_mask: 0.2605  decode.d5.loss_dice: 0.3065  decode.d6.loss_cls: 0.2475  decode.d6.loss_mask: 0.2760  decode.d6.loss_dice: 0.3213  decode.d7.loss_cls: 0.2854  decode.d7.loss_mask: 0.2525  decode.d7.loss_dice: 0.2986  decode.d8.loss_cls: 0.2661  decode.d8.loss_mask: 0.2563  decode.d8.loss_dice: 0.3050
08/06 04:18:12 - mmengine - INFO - Iter(train) [ 14850/320000]  base_lr: 9.5814e-05 lr: 9.5814e-06  eta: 1 day, 17:34:49  time: 0.4924  data_time: 0.0104  memory: 5909  grad_norm: 109.7954  loss: 9.2707  decode.loss_cls: 0.2191  decode.loss_mask: 0.2707  decode.loss_dice: 0.3163  decode.d0.loss_cls: 1.0466  decode.d0.loss_mask: 0.2850  decode.d0.loss_dice: 0.3251  decode.d1.loss_cls: 0.2184  decode.d1.loss_mask: 0.2438  decode.d1.loss_dice: 0.3065  decode.d2.loss_cls: 0.2720  decode.d2.loss_mask: 0.2571  decode.d2.loss_dice: 0.3182  decode.d3.loss_cls: 0.1988  decode.d3.loss_mask: 0.2566  decode.d3.loss_dice: 0.3198  decode.d4.loss_cls: 0.2822  decode.d4.loss_mask: 0.2989  decode.d4.loss_dice: 0.3333  decode.d5.loss_cls: 0.2394  decode.d5.loss_mask: 0.2991  decode.d5.loss_dice: 0.3487  decode.d6.loss_cls: 0.2759  decode.d6.loss_mask: 0.2745  decode.d6.loss_dice: 0.3010  decode.d7.loss_cls: 0.2472  decode.d7.loss_mask: 0.3130  decode.d7.loss_dice: 0.3307  decode.d8.loss_cls: 0.2838  decode.d8.loss_mask: 0.2636  decode.d8.loss_dice: 0.3256
08/06 04:18:37 - mmengine - INFO - Iter(train) [ 14900/320000]  base_lr: 9.5800e-05 lr: 9.5800e-06  eta: 1 day, 17:34:25  time: 0.4910  data_time: 0.0103  memory: 5910  grad_norm: 481.5722  loss: 9.1914  decode.loss_cls: 0.2384  decode.loss_mask: 0.3558  decode.loss_dice: 0.2918  decode.d0.loss_cls: 1.1960  decode.d0.loss_mask: 0.3036  decode.d0.loss_dice: 0.2859  decode.d1.loss_cls: 0.3134  decode.d1.loss_mask: 0.3172  decode.d1.loss_dice: 0.2627  decode.d2.loss_cls: 0.1374  decode.d2.loss_mask: 0.3045  decode.d2.loss_dice: 0.2628  decode.d3.loss_cls: 0.1687  decode.d3.loss_mask: 0.3015  decode.d3.loss_dice: 0.2731  decode.d4.loss_cls: 0.1583  decode.d4.loss_mask: 0.3169  decode.d4.loss_dice: 0.2769  decode.d5.loss_cls: 0.1922  decode.d5.loss_mask: 0.3707  decode.d5.loss_dice: 0.2921  decode.d6.loss_cls: 0.1861  decode.d6.loss_mask: 0.3174  decode.d6.loss_dice: 0.2558  decode.d7.loss_cls: 0.2972  decode.d7.loss_mask: 0.3761  decode.d7.loss_dice: 0.2892  decode.d8.loss_cls: 0.1968  decode.d8.loss_mask: 0.3620  decode.d8.loss_dice: 0.2910
08/06 04:19:01 - mmengine - INFO - Iter(train) [ 14950/320000]  base_lr: 9.5786e-05 lr: 9.5786e-06  eta: 1 day, 17:34:01  time: 0.4903  data_time: 0.0105  memory: 5926  grad_norm: 178.8461  loss: 10.1184  decode.loss_cls: 0.2365  decode.loss_mask: 0.3491  decode.loss_dice: 0.3504  decode.d0.loss_cls: 0.8941  decode.d0.loss_mask: 0.3400  decode.d0.loss_dice: 0.3655  decode.d1.loss_cls: 0.2648  decode.d1.loss_mask: 0.3284  decode.d1.loss_dice: 0.3641  decode.d2.loss_cls: 0.2960  decode.d2.loss_mask: 0.3358  decode.d2.loss_dice: 0.3579  decode.d3.loss_cls: 0.2823  decode.d3.loss_mask: 0.3441  decode.d3.loss_dice: 0.3770  decode.d4.loss_cls: 0.2686  decode.d4.loss_mask: 0.3346  decode.d4.loss_dice: 0.3394  decode.d5.loss_cls: 0.2773  decode.d5.loss_mask: 0.3258  decode.d5.loss_dice: 0.3617  decode.d6.loss_cls: 0.1965  decode.d6.loss_mask: 0.3495  decode.d6.loss_dice: 0.3351  decode.d7.loss_cls: 0.2523  decode.d7.loss_mask: 0.3579  decode.d7.loss_dice: 0.3657  decode.d8.loss_cls: 0.1669  decode.d8.loss_mask: 0.3491  decode.d8.loss_dice: 0.3518
08/06 04:19:26 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 04:19:26 - mmengine - INFO - Iter(train) [ 15000/320000]  base_lr: 9.5771e-05 lr: 9.5771e-06  eta: 1 day, 17:33:37  time: 0.4899  data_time: 0.0105  memory: 5891  grad_norm: 142.1169  loss: 10.3415  decode.loss_cls: 0.2919  decode.loss_mask: 0.2471  decode.loss_dice: 0.3740  decode.d0.loss_cls: 1.0477  decode.d0.loss_mask: 0.2438  decode.d0.loss_dice: 0.4037  decode.d1.loss_cls: 0.4103  decode.d1.loss_mask: 0.2407  decode.d1.loss_dice: 0.3408  decode.d2.loss_cls: 0.3555  decode.d2.loss_mask: 0.2396  decode.d2.loss_dice: 0.3454  decode.d3.loss_cls: 0.3447  decode.d3.loss_mask: 0.2448  decode.d3.loss_dice: 0.4111  decode.d4.loss_cls: 0.3314  decode.d4.loss_mask: 0.2436  decode.d4.loss_dice: 0.3790  decode.d5.loss_cls: 0.3897  decode.d5.loss_mask: 0.2451  decode.d5.loss_dice: 0.3757  decode.d6.loss_cls: 0.3329  decode.d6.loss_mask: 0.2447  decode.d6.loss_dice: 0.3868  decode.d7.loss_cls: 0.2665  decode.d7.loss_mask: 0.2446  decode.d7.loss_dice: 0.3892  decode.d8.loss_cls: 0.3464  decode.d8.loss_mask: 0.2436  decode.d8.loss_dice: 0.3809
08/06 04:19:50 - mmengine - INFO - Iter(train) [ 15050/320000]  base_lr: 9.5757e-05 lr: 9.5757e-06  eta: 1 day, 17:33:13  time: 0.4910  data_time: 0.0107  memory: 5874  grad_norm: 235.6469  loss: 8.6521  decode.loss_cls: 0.1060  decode.loss_mask: 0.2977  decode.loss_dice: 0.2935  decode.d0.loss_cls: 0.9862  decode.d0.loss_mask: 0.2974  decode.d0.loss_dice: 0.3398  decode.d1.loss_cls: 0.3147  decode.d1.loss_mask: 0.2957  decode.d1.loss_dice: 0.3130  decode.d2.loss_cls: 0.2612  decode.d2.loss_mask: 0.2842  decode.d2.loss_dice: 0.3181  decode.d3.loss_cls: 0.1982  decode.d3.loss_mask: 0.2839  decode.d3.loss_dice: 0.3164  decode.d4.loss_cls: 0.2413  decode.d4.loss_mask: 0.2789  decode.d4.loss_dice: 0.2988  decode.d5.loss_cls: 0.1589  decode.d5.loss_mask: 0.2844  decode.d5.loss_dice: 0.3131  decode.d6.loss_cls: 0.1622  decode.d6.loss_mask: 0.2840  decode.d6.loss_dice: 0.3033  decode.d7.loss_cls: 0.1364  decode.d7.loss_mask: 0.2932  decode.d7.loss_dice: 0.3179  decode.d8.loss_cls: 0.0945  decode.d8.loss_mask: 0.2911  decode.d8.loss_dice: 0.2882
08/06 04:20:15 - mmengine - INFO - Iter(train) [ 15100/320000]  base_lr: 9.5743e-05 lr: 9.5743e-06  eta: 1 day, 17:32:49  time: 0.4908  data_time: 0.0105  memory: 5908  grad_norm: 158.7740  loss: 9.6223  decode.loss_cls: 0.1876  decode.loss_mask: 0.2799  decode.loss_dice: 0.3602  decode.d0.loss_cls: 1.0850  decode.d0.loss_mask: 0.2558  decode.d0.loss_dice: 0.3524  decode.d1.loss_cls: 0.2791  decode.d1.loss_mask: 0.2712  decode.d1.loss_dice: 0.3694  decode.d2.loss_cls: 0.2687  decode.d2.loss_mask: 0.2617  decode.d2.loss_dice: 0.3434  decode.d3.loss_cls: 0.2183  decode.d3.loss_mask: 0.2761  decode.d3.loss_dice: 0.3610  decode.d4.loss_cls: 0.2995  decode.d4.loss_mask: 0.2597  decode.d4.loss_dice: 0.3362  decode.d5.loss_cls: 0.3648  decode.d5.loss_mask: 0.2574  decode.d5.loss_dice: 0.3281  decode.d6.loss_cls: 0.2279  decode.d6.loss_mask: 0.2727  decode.d6.loss_dice: 0.3628  decode.d7.loss_cls: 0.2696  decode.d7.loss_mask: 0.2755  decode.d7.loss_dice: 0.3504  decode.d8.loss_cls: 0.2143  decode.d8.loss_mask: 0.2675  decode.d8.loss_dice: 0.3662
08/06 04:20:39 - mmengine - INFO - Iter(train) [ 15150/320000]  base_lr: 9.5729e-05 lr: 9.5729e-06  eta: 1 day, 17:32:25  time: 0.4910  data_time: 0.0105  memory: 5927  grad_norm: 161.1223  loss: 6.9120  decode.loss_cls: 0.0547  decode.loss_mask: 0.2635  decode.loss_dice: 0.2359  decode.d0.loss_cls: 1.0396  decode.d0.loss_mask: 0.2670  decode.d0.loss_dice: 0.2635  decode.d1.loss_cls: 0.1064  decode.d1.loss_mask: 0.2783  decode.d1.loss_dice: 0.2571  decode.d2.loss_cls: 0.0955  decode.d2.loss_mask: 0.2652  decode.d2.loss_dice: 0.2407  decode.d3.loss_cls: 0.1151  decode.d3.loss_mask: 0.2591  decode.d3.loss_dice: 0.2413  decode.d4.loss_cls: 0.0874  decode.d4.loss_mask: 0.2617  decode.d4.loss_dice: 0.2393  decode.d5.loss_cls: 0.1055  decode.d5.loss_mask: 0.2608  decode.d5.loss_dice: 0.2388  decode.d6.loss_cls: 0.0885  decode.d6.loss_mask: 0.2586  decode.d6.loss_dice: 0.2432  decode.d7.loss_cls: 0.0737  decode.d7.loss_mask: 0.2636  decode.d7.loss_dice: 0.2459  decode.d8.loss_cls: 0.0641  decode.d8.loss_mask: 0.2631  decode.d8.loss_dice: 0.2348
08/06 04:21:04 - mmengine - INFO - Iter(train) [ 15200/320000]  base_lr: 9.5715e-05 lr: 9.5715e-06  eta: 1 day, 17:32:01  time: 0.4898  data_time: 0.0104  memory: 5926  grad_norm: 294.2753  loss: 9.9042  decode.loss_cls: 0.3619  decode.loss_mask: 0.2988  decode.loss_dice: 0.3330  decode.d0.loss_cls: 1.0890  decode.d0.loss_mask: 0.3160  decode.d0.loss_dice: 0.3897  decode.d1.loss_cls: 0.4404  decode.d1.loss_mask: 0.2980  decode.d1.loss_dice: 0.2794  decode.d2.loss_cls: 0.2602  decode.d2.loss_mask: 0.2999  decode.d2.loss_dice: 0.3379  decode.d3.loss_cls: 0.2516  decode.d3.loss_mask: 0.3089  decode.d3.loss_dice: 0.3257  decode.d4.loss_cls: 0.2461  decode.d4.loss_mask: 0.3086  decode.d4.loss_dice: 0.3204  decode.d5.loss_cls: 0.2213  decode.d5.loss_mask: 0.3152  decode.d5.loss_dice: 0.3450  decode.d6.loss_cls: 0.2152  decode.d6.loss_mask: 0.3071  decode.d6.loss_dice: 0.3235  decode.d7.loss_cls: 0.2207  decode.d7.loss_mask: 0.2955  decode.d7.loss_dice: 0.2995  decode.d8.loss_cls: 0.2519  decode.d8.loss_mask: 0.3049  decode.d8.loss_dice: 0.3388
08/06 04:21:28 - mmengine - INFO - Iter(train) [ 15250/320000]  base_lr: 9.5701e-05 lr: 9.5701e-06  eta: 1 day, 17:31:37  time: 0.4908  data_time: 0.0103  memory: 5891  grad_norm: 202.8258  loss: 7.5945  decode.loss_cls: 0.2149  decode.loss_mask: 0.2164  decode.loss_dice: 0.2573  decode.d0.loss_cls: 0.9763  decode.d0.loss_mask: 0.2343  decode.d0.loss_dice: 0.3213  decode.d1.loss_cls: 0.3461  decode.d1.loss_mask: 0.2451  decode.d1.loss_dice: 0.2838  decode.d2.loss_cls: 0.1369  decode.d2.loss_mask: 0.2200  decode.d2.loss_dice: 0.2705  decode.d3.loss_cls: 0.1324  decode.d3.loss_mask: 0.2133  decode.d3.loss_dice: 0.2620  decode.d4.loss_cls: 0.1655  decode.d4.loss_mask: 0.2082  decode.d4.loss_dice: 0.2642  decode.d5.loss_cls: 0.1546  decode.d5.loss_mask: 0.2123  decode.d5.loss_dice: 0.2662  decode.d6.loss_cls: 0.1814  decode.d6.loss_mask: 0.2084  decode.d6.loss_dice: 0.2660  decode.d7.loss_cls: 0.1909  decode.d7.loss_mask: 0.2124  decode.d7.loss_dice: 0.2660  decode.d8.loss_cls: 0.1823  decode.d8.loss_mask: 0.2109  decode.d8.loss_dice: 0.2747
08/06 04:21:53 - mmengine - INFO - Iter(train) [ 15300/320000]  base_lr: 9.5687e-05 lr: 9.5687e-06  eta: 1 day, 17:31:15  time: 0.4912  data_time: 0.0107  memory: 5877  grad_norm: 156.0731  loss: 8.5482  decode.loss_cls: 0.2478  decode.loss_mask: 0.2447  decode.loss_dice: 0.2887  decode.d0.loss_cls: 0.9831  decode.d0.loss_mask: 0.2425  decode.d0.loss_dice: 0.3135  decode.d1.loss_cls: 0.2056  decode.d1.loss_mask: 0.2529  decode.d1.loss_dice: 0.3005  decode.d2.loss_cls: 0.2123  decode.d2.loss_mask: 0.2525  decode.d2.loss_dice: 0.3100  decode.d3.loss_cls: 0.2485  decode.d3.loss_mask: 0.2483  decode.d3.loss_dice: 0.3008  decode.d4.loss_cls: 0.2641  decode.d4.loss_mask: 0.2548  decode.d4.loss_dice: 0.2983  decode.d5.loss_cls: 0.2189  decode.d5.loss_mask: 0.2506  decode.d5.loss_dice: 0.3109  decode.d6.loss_cls: 0.1701  decode.d6.loss_mask: 0.2437  decode.d6.loss_dice: 0.2903  decode.d7.loss_cls: 0.2630  decode.d7.loss_mask: 0.2467  decode.d7.loss_dice: 0.2639  decode.d8.loss_cls: 0.3023  decode.d8.loss_mask: 0.2411  decode.d8.loss_dice: 0.2779
08/06 04:22:18 - mmengine - INFO - Iter(train) [ 15350/320000]  base_lr: 9.5673e-05 lr: 9.5673e-06  eta: 1 day, 17:30:51  time: 0.4909  data_time: 0.0106  memory: 5875  grad_norm: 218.9224  loss: 11.5692  decode.loss_cls: 0.2254  decode.loss_mask: 0.4712  decode.loss_dice: 0.3879  decode.d0.loss_cls: 1.2940  decode.d0.loss_mask: 0.3522  decode.d0.loss_dice: 0.4632  decode.d1.loss_cls: 0.3268  decode.d1.loss_mask: 0.3573  decode.d1.loss_dice: 0.4185  decode.d2.loss_cls: 0.3604  decode.d2.loss_mask: 0.3205  decode.d2.loss_dice: 0.3542  decode.d3.loss_cls: 0.2675  decode.d3.loss_mask: 0.3610  decode.d3.loss_dice: 0.4068  decode.d4.loss_cls: 0.2421  decode.d4.loss_mask: 0.4189  decode.d4.loss_dice: 0.3916  decode.d5.loss_cls: 0.2558  decode.d5.loss_mask: 0.3733  decode.d5.loss_dice: 0.3924  decode.d6.loss_cls: 0.2377  decode.d6.loss_mask: 0.3533  decode.d6.loss_dice: 0.4063  decode.d7.loss_cls: 0.2389  decode.d7.loss_mask: 0.3476  decode.d7.loss_dice: 0.3954  decode.d8.loss_cls: 0.3680  decode.d8.loss_mask: 0.3852  decode.d8.loss_dice: 0.3960
08/06 04:22:42 - mmengine - INFO - Iter(train) [ 15400/320000]  base_lr: 9.5658e-05 lr: 9.5658e-06  eta: 1 day, 17:30:27  time: 0.4909  data_time: 0.0104  memory: 5926  grad_norm: 84.6836  loss: 9.4895  decode.loss_cls: 0.3719  decode.loss_mask: 0.2200  decode.loss_dice: 0.3349  decode.d0.loss_cls: 1.0202  decode.d0.loss_mask: 0.2440  decode.d0.loss_dice: 0.3329  decode.d1.loss_cls: 0.3749  decode.d1.loss_mask: 0.2153  decode.d1.loss_dice: 0.2752  decode.d2.loss_cls: 0.3507  decode.d2.loss_mask: 0.2139  decode.d2.loss_dice: 0.3036  decode.d3.loss_cls: 0.3300  decode.d3.loss_mask: 0.2163  decode.d3.loss_dice: 0.3049  decode.d4.loss_cls: 0.3642  decode.d4.loss_mask: 0.2226  decode.d4.loss_dice: 0.3281  decode.d5.loss_cls: 0.3206  decode.d5.loss_mask: 0.2344  decode.d5.loss_dice: 0.3217  decode.d6.loss_cls: 0.3205  decode.d6.loss_mask: 0.2148  decode.d6.loss_dice: 0.3151  decode.d7.loss_cls: 0.3240  decode.d7.loss_mask: 0.2143  decode.d7.loss_dice: 0.3355  decode.d8.loss_cls: 0.3402  decode.d8.loss_mask: 0.2228  decode.d8.loss_dice: 0.3019
08/06 04:23:07 - mmengine - INFO - Iter(train) [ 15450/320000]  base_lr: 9.5644e-05 lr: 9.5644e-06  eta: 1 day, 17:30:02  time: 0.4901  data_time: 0.0107  memory: 5895  grad_norm: 172.5418  loss: 9.6718  decode.loss_cls: 0.2653  decode.loss_mask: 0.2601  decode.loss_dice: 0.2824  decode.d0.loss_cls: 1.1092  decode.d0.loss_mask: 0.2825  decode.d0.loss_dice: 0.3406  decode.d1.loss_cls: 0.3515  decode.d1.loss_mask: 0.2751  decode.d1.loss_dice: 0.3229  decode.d2.loss_cls: 0.2525  decode.d2.loss_mask: 0.2745  decode.d2.loss_dice: 0.3026  decode.d3.loss_cls: 0.3425  decode.d3.loss_mask: 0.2654  decode.d3.loss_dice: 0.3095  decode.d4.loss_cls: 0.3590  decode.d4.loss_mask: 0.2663  decode.d4.loss_dice: 0.2925  decode.d5.loss_cls: 0.2967  decode.d5.loss_mask: 0.2652  decode.d5.loss_dice: 0.3129  decode.d6.loss_cls: 0.2842  decode.d6.loss_mask: 0.2686  decode.d6.loss_dice: 0.2920  decode.d7.loss_cls: 0.3152  decode.d7.loss_mask: 0.2701  decode.d7.loss_dice: 0.3125  decode.d8.loss_cls: 0.3501  decode.d8.loss_mask: 0.2649  decode.d8.loss_dice: 0.2851
08/06 04:23:31 - mmengine - INFO - Iter(train) [ 15500/320000]  base_lr: 9.5630e-05 lr: 9.5630e-06  eta: 1 day, 17:29:38  time: 0.4916  data_time: 0.0103  memory: 5908  grad_norm: 196.7934  loss: 10.2653  decode.loss_cls: 0.3455  decode.loss_mask: 0.2049  decode.loss_dice: 0.3511  decode.d0.loss_cls: 1.0217  decode.d0.loss_mask: 0.2148  decode.d0.loss_dice: 0.4190  decode.d1.loss_cls: 0.3996  decode.d1.loss_mask: 0.2089  decode.d1.loss_dice: 0.4010  decode.d2.loss_cls: 0.3567  decode.d2.loss_mask: 0.2045  decode.d2.loss_dice: 0.3899  decode.d3.loss_cls: 0.3927  decode.d3.loss_mask: 0.2087  decode.d3.loss_dice: 0.3721  decode.d4.loss_cls: 0.3796  decode.d4.loss_mask: 0.2466  decode.d4.loss_dice: 0.4007  decode.d5.loss_cls: 0.3746  decode.d5.loss_mask: 0.2048  decode.d5.loss_dice: 0.3766  decode.d6.loss_cls: 0.3230  decode.d6.loss_mask: 0.2015  decode.d6.loss_dice: 0.3554  decode.d7.loss_cls: 0.3423  decode.d7.loss_mask: 0.2077  decode.d7.loss_dice: 0.3800  decode.d8.loss_cls: 0.3774  decode.d8.loss_mask: 0.2211  decode.d8.loss_dice: 0.3830
08/06 04:23:56 - mmengine - INFO - Iter(train) [ 15550/320000]  base_lr: 9.5616e-05 lr: 9.5616e-06  eta: 1 day, 17:29:14  time: 0.4896  data_time: 0.0106  memory: 5907  grad_norm: 142.2583  loss: 10.7959  decode.loss_cls: 0.3116  decode.loss_mask: 0.3253  decode.loss_dice: 0.3413  decode.d0.loss_cls: 1.1800  decode.d0.loss_mask: 0.3313  decode.d0.loss_dice: 0.3680  decode.d1.loss_cls: 0.4188  decode.d1.loss_mask: 0.3249  decode.d1.loss_dice: 0.3543  decode.d2.loss_cls: 0.2691  decode.d2.loss_mask: 0.3173  decode.d2.loss_dice: 0.3569  decode.d3.loss_cls: 0.3098  decode.d3.loss_mask: 0.3202  decode.d3.loss_dice: 0.3426  decode.d4.loss_cls: 0.3011  decode.d4.loss_mask: 0.3098  decode.d4.loss_dice: 0.3497  decode.d5.loss_cls: 0.3500  decode.d5.loss_mask: 0.3133  decode.d5.loss_dice: 0.3535  decode.d6.loss_cls: 0.3140  decode.d6.loss_mask: 0.3120  decode.d6.loss_dice: 0.3269  decode.d7.loss_cls: 0.3181  decode.d7.loss_mask: 0.3198  decode.d7.loss_dice: 0.3751  decode.d8.loss_cls: 0.3061  decode.d8.loss_mask: 0.3273  decode.d8.loss_dice: 0.3478
08/06 04:24:20 - mmengine - INFO - Iter(train) [ 15600/320000]  base_lr: 9.5602e-05 lr: 9.5602e-06  eta: 1 day, 17:28:49  time: 0.4910  data_time: 0.0106  memory: 5890  grad_norm: 375.0683  loss: 9.4082  decode.loss_cls: 0.3621  decode.loss_mask: 0.2397  decode.loss_dice: 0.3290  decode.d0.loss_cls: 0.9681  decode.d0.loss_mask: 0.2538  decode.d0.loss_dice: 0.3760  decode.d1.loss_cls: 0.3098  decode.d1.loss_mask: 0.2467  decode.d1.loss_dice: 0.3395  decode.d2.loss_cls: 0.2861  decode.d2.loss_mask: 0.2441  decode.d2.loss_dice: 0.3359  decode.d3.loss_cls: 0.2984  decode.d3.loss_mask: 0.2389  decode.d3.loss_dice: 0.3466  decode.d4.loss_cls: 0.2721  decode.d4.loss_mask: 0.2445  decode.d4.loss_dice: 0.3224  decode.d5.loss_cls: 0.2184  decode.d5.loss_mask: 0.2346  decode.d5.loss_dice: 0.3305  decode.d6.loss_cls: 0.2609  decode.d6.loss_mask: 0.2417  decode.d6.loss_dice: 0.3449  decode.d7.loss_cls: 0.2726  decode.d7.loss_mask: 0.2398  decode.d7.loss_dice: 0.3496  decode.d8.loss_cls: 0.3404  decode.d8.loss_mask: 0.2378  decode.d8.loss_dice: 0.3233
08/06 04:24:45 - mmengine - INFO - Iter(train) [ 15650/320000]  base_lr: 9.5588e-05 lr: 9.5588e-06  eta: 1 day, 17:28:25  time: 0.4905  data_time: 0.0106  memory: 5927  grad_norm: 234.4050  loss: 10.2436  decode.loss_cls: 0.3247  decode.loss_mask: 0.3536  decode.loss_dice: 0.2928  decode.d0.loss_cls: 1.0141  decode.d0.loss_mask: 0.3723  decode.d0.loss_dice: 0.3406  decode.d1.loss_cls: 0.2793  decode.d1.loss_mask: 0.3582  decode.d1.loss_dice: 0.3359  decode.d2.loss_cls: 0.1755  decode.d2.loss_mask: 0.3478  decode.d2.loss_dice: 0.3169  decode.d3.loss_cls: 0.2146  decode.d3.loss_mask: 0.3609  decode.d3.loss_dice: 0.3089  decode.d4.loss_cls: 0.2358  decode.d4.loss_mask: 0.3548  decode.d4.loss_dice: 0.3142  decode.d5.loss_cls: 0.2886  decode.d5.loss_mask: 0.3596  decode.d5.loss_dice: 0.3106  decode.d6.loss_cls: 0.2549  decode.d6.loss_mask: 0.3506  decode.d6.loss_dice: 0.3187  decode.d7.loss_cls: 0.3183  decode.d7.loss_mask: 0.3694  decode.d7.loss_dice: 0.3390  decode.d8.loss_cls: 0.3638  decode.d8.loss_mask: 0.3596  decode.d8.loss_dice: 0.3096
08/06 04:25:10 - mmengine - INFO - Iter(train) [ 15700/320000]  base_lr: 9.5574e-05 lr: 9.5574e-06  eta: 1 day, 17:28:01  time: 0.4902  data_time: 0.0105  memory: 5907  grad_norm: 224.6662  loss: 8.2813  decode.loss_cls: 0.1704  decode.loss_mask: 0.2629  decode.loss_dice: 0.2560  decode.d0.loss_cls: 0.9387  decode.d0.loss_mask: 0.2759  decode.d0.loss_dice: 0.2978  decode.d1.loss_cls: 0.3285  decode.d1.loss_mask: 0.2704  decode.d1.loss_dice: 0.2711  decode.d2.loss_cls: 0.1748  decode.d2.loss_mask: 0.2744  decode.d2.loss_dice: 0.2856  decode.d3.loss_cls: 0.2708  decode.d3.loss_mask: 0.2722  decode.d3.loss_dice: 0.2918  decode.d4.loss_cls: 0.2145  decode.d4.loss_mask: 0.2795  decode.d4.loss_dice: 0.2706  decode.d5.loss_cls: 0.1950  decode.d5.loss_mask: 0.2609  decode.d5.loss_dice: 0.2821  decode.d6.loss_cls: 0.1715  decode.d6.loss_mask: 0.2635  decode.d6.loss_dice: 0.2720  decode.d7.loss_cls: 0.1651  decode.d7.loss_mask: 0.2616  decode.d7.loss_dice: 0.2562  decode.d8.loss_cls: 0.1704  decode.d8.loss_mask: 0.2751  decode.d8.loss_dice: 0.3020
08/06 04:25:34 - mmengine - INFO - Iter(train) [ 15750/320000]  base_lr: 9.5559e-05 lr: 9.5559e-06  eta: 1 day, 17:27:37  time: 0.4922  data_time: 0.0108  memory: 5892  grad_norm: 128.5081  loss: 10.4501  decode.loss_cls: 0.1803  decode.loss_mask: 0.3284  decode.loss_dice: 0.3398  decode.d0.loss_cls: 1.3261  decode.d0.loss_mask: 0.3297  decode.d0.loss_dice: 0.3653  decode.d1.loss_cls: 0.3989  decode.d1.loss_mask: 0.3234  decode.d1.loss_dice: 0.3344  decode.d2.loss_cls: 0.3205  decode.d2.loss_mask: 0.3299  decode.d2.loss_dice: 0.3251  decode.d3.loss_cls: 0.2640  decode.d3.loss_mask: 0.3264  decode.d3.loss_dice: 0.3454  decode.d4.loss_cls: 0.2695  decode.d4.loss_mask: 0.3132  decode.d4.loss_dice: 0.3183  decode.d5.loss_cls: 0.2485  decode.d5.loss_mask: 0.3183  decode.d5.loss_dice: 0.3265  decode.d6.loss_cls: 0.2554  decode.d6.loss_mask: 0.3199  decode.d6.loss_dice: 0.3498  decode.d7.loss_cls: 0.3345  decode.d7.loss_mask: 0.3169  decode.d7.loss_dice: 0.3364  decode.d8.loss_cls: 0.2462  decode.d8.loss_mask: 0.3252  decode.d8.loss_dice: 0.3341
08/06 04:25:59 - mmengine - INFO - Iter(train) [ 15800/320000]  base_lr: 9.5545e-05 lr: 9.5545e-06  eta: 1 day, 17:27:14  time: 0.4915  data_time: 0.0106  memory: 5908  grad_norm: 142.1876  loss: 8.4049  decode.loss_cls: 0.1949  decode.loss_mask: 0.2618  decode.loss_dice: 0.2842  decode.d0.loss_cls: 0.9458  decode.d0.loss_mask: 0.3020  decode.d0.loss_dice: 0.3527  decode.d1.loss_cls: 0.2109  decode.d1.loss_mask: 0.2792  decode.d1.loss_dice: 0.3136  decode.d2.loss_cls: 0.2063  decode.d2.loss_mask: 0.2529  decode.d2.loss_dice: 0.2745  decode.d3.loss_cls: 0.1835  decode.d3.loss_mask: 0.2601  decode.d3.loss_dice: 0.2893  decode.d4.loss_cls: 0.2270  decode.d4.loss_mask: 0.2542  decode.d4.loss_dice: 0.2832  decode.d5.loss_cls: 0.2302  decode.d5.loss_mask: 0.2516  decode.d5.loss_dice: 0.2777  decode.d6.loss_cls: 0.1840  decode.d6.loss_mask: 0.2574  decode.d6.loss_dice: 0.2897  decode.d7.loss_cls: 0.2402  decode.d7.loss_mask: 0.2592  decode.d7.loss_dice: 0.2734  decode.d8.loss_cls: 0.2244  decode.d8.loss_mask: 0.2600  decode.d8.loss_dice: 0.2810
08/06 04:26:23 - mmengine - INFO - Iter(train) [ 15850/320000]  base_lr: 9.5531e-05 lr: 9.5531e-06  eta: 1 day, 17:26:52  time: 0.4915  data_time: 0.0104  memory: 5907  grad_norm: 113.2906  loss: 7.6893  decode.loss_cls: 0.1514  decode.loss_mask: 0.1846  decode.loss_dice: 0.3150  decode.d0.loss_cls: 1.0605  decode.d0.loss_mask: 0.1897  decode.d0.loss_dice: 0.3327  decode.d1.loss_cls: 0.2852  decode.d1.loss_mask: 0.1863  decode.d1.loss_dice: 0.3100  decode.d2.loss_cls: 0.1818  decode.d2.loss_mask: 0.1884  decode.d2.loss_dice: 0.2998  decode.d3.loss_cls: 0.2142  decode.d3.loss_mask: 0.1863  decode.d3.loss_dice: 0.3124  decode.d4.loss_cls: 0.1619  decode.d4.loss_mask: 0.1875  decode.d4.loss_dice: 0.3073  decode.d5.loss_cls: 0.1661  decode.d5.loss_mask: 0.1897  decode.d5.loss_dice: 0.3153  decode.d6.loss_cls: 0.1638  decode.d6.loss_mask: 0.1860  decode.d6.loss_dice: 0.3143  decode.d7.loss_cls: 0.1696  decode.d7.loss_mask: 0.1873  decode.d7.loss_dice: 0.3110  decode.d8.loss_cls: 0.1458  decode.d8.loss_mask: 0.1813  decode.d8.loss_dice: 0.3039
08/06 04:26:48 - mmengine - INFO - Iter(train) [ 15900/320000]  base_lr: 9.5517e-05 lr: 9.5517e-06  eta: 1 day, 17:26:28  time: 0.4905  data_time: 0.0105  memory: 5907  grad_norm: 73.3581  loss: 7.4368  decode.loss_cls: 0.1598  decode.loss_mask: 0.2411  decode.loss_dice: 0.2521  decode.d0.loss_cls: 0.9140  decode.d0.loss_mask: 0.2508  decode.d0.loss_dice: 0.2834  decode.d1.loss_cls: 0.1316  decode.d1.loss_mask: 0.2454  decode.d1.loss_dice: 0.2640  decode.d2.loss_cls: 0.1126  decode.d2.loss_mask: 0.2404  decode.d2.loss_dice: 0.2690  decode.d3.loss_cls: 0.1543  decode.d3.loss_mask: 0.2402  decode.d3.loss_dice: 0.2588  decode.d4.loss_cls: 0.1832  decode.d4.loss_mask: 0.2471  decode.d4.loss_dice: 0.2876  decode.d5.loss_cls: 0.1363  decode.d5.loss_mask: 0.2419  decode.d5.loss_dice: 0.2680  decode.d6.loss_cls: 0.1726  decode.d6.loss_mask: 0.2440  decode.d6.loss_dice: 0.2801  decode.d7.loss_cls: 0.1629  decode.d7.loss_mask: 0.2446  decode.d7.loss_dice: 0.2599  decode.d8.loss_cls: 0.1787  decode.d8.loss_mask: 0.2420  decode.d8.loss_dice: 0.2706
08/06 04:27:12 - mmengine - INFO - Iter(train) [ 15950/320000]  base_lr: 9.5503e-05 lr: 9.5503e-06  eta: 1 day, 17:26:04  time: 0.4909  data_time: 0.0107  memory: 5891  grad_norm: 143.6259  loss: 6.8331  decode.loss_cls: 0.0393  decode.loss_mask: 0.2693  decode.loss_dice: 0.2647  decode.d0.loss_cls: 0.9045  decode.d0.loss_mask: 0.2753  decode.d0.loss_dice: 0.2946  decode.d1.loss_cls: 0.1241  decode.d1.loss_mask: 0.2708  decode.d1.loss_dice: 0.2723  decode.d2.loss_cls: 0.0731  decode.d2.loss_mask: 0.2632  decode.d2.loss_dice: 0.2646  decode.d3.loss_cls: 0.0603  decode.d3.loss_mask: 0.2624  decode.d3.loss_dice: 0.2747  decode.d4.loss_cls: 0.0523  decode.d4.loss_mask: 0.2653  decode.d4.loss_dice: 0.2618  decode.d5.loss_cls: 0.0465  decode.d5.loss_mask: 0.2607  decode.d5.loss_dice: 0.2685  decode.d6.loss_cls: 0.0438  decode.d6.loss_mask: 0.2671  decode.d6.loss_dice: 0.2768  decode.d7.loss_cls: 0.0439  decode.d7.loss_mask: 0.2678  decode.d7.loss_dice: 0.2754  decode.d8.loss_cls: 0.0513  decode.d8.loss_mask: 0.2710  decode.d8.loss_dice: 0.2674
08/06 04:27:37 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 04:27:37 - mmengine - INFO - Iter(train) [ 16000/320000]  base_lr: 9.5489e-05 lr: 9.5489e-06  eta: 1 day, 17:25:40  time: 0.4919  data_time: 0.0106  memory: 5927  grad_norm: 129.6368  loss: 8.4887  decode.loss_cls: 0.3035  decode.loss_mask: 0.2346  decode.loss_dice: 0.2500  decode.d0.loss_cls: 1.1056  decode.d0.loss_mask: 0.2396  decode.d0.loss_dice: 0.2974  decode.d1.loss_cls: 0.2900  decode.d1.loss_mask: 0.2313  decode.d1.loss_dice: 0.2674  decode.d2.loss_cls: 0.3306  decode.d2.loss_mask: 0.2289  decode.d2.loss_dice: 0.2575  decode.d3.loss_cls: 0.1885  decode.d3.loss_mask: 0.2358  decode.d3.loss_dice: 0.2559  decode.d4.loss_cls: 0.2832  decode.d4.loss_mask: 0.2313  decode.d4.loss_dice: 0.2512  decode.d5.loss_cls: 0.2253  decode.d5.loss_mask: 0.2304  decode.d5.loss_dice: 0.2767  decode.d6.loss_cls: 0.2501  decode.d6.loss_mask: 0.2331  decode.d6.loss_dice: 0.2559  decode.d7.loss_cls: 0.2782  decode.d7.loss_mask: 0.2295  decode.d7.loss_dice: 0.2517  decode.d8.loss_cls: 0.2849  decode.d8.loss_mask: 0.2320  decode.d8.loss_dice: 0.2587
08/06 04:28:02 - mmengine - INFO - Iter(train) [ 16050/320000]  base_lr: 9.5475e-05 lr: 9.5475e-06  eta: 1 day, 17:25:17  time: 0.4932  data_time: 0.0101  memory: 5909  grad_norm: 81.4205  loss: 7.7681  decode.loss_cls: 0.1845  decode.loss_mask: 0.1882  decode.loss_dice: 0.2973  decode.d0.loss_cls: 1.0564  decode.d0.loss_mask: 0.1951  decode.d0.loss_dice: 0.3099  decode.d1.loss_cls: 0.2281  decode.d1.loss_mask: 0.1938  decode.d1.loss_dice: 0.2983  decode.d2.loss_cls: 0.2017  decode.d2.loss_mask: 0.1914  decode.d2.loss_dice: 0.2897  decode.d3.loss_cls: 0.2075  decode.d3.loss_mask: 0.1941  decode.d3.loss_dice: 0.3270  decode.d4.loss_cls: 0.2095  decode.d4.loss_mask: 0.1931  decode.d4.loss_dice: 0.2857  decode.d5.loss_cls: 0.2192  decode.d5.loss_mask: 0.1914  decode.d5.loss_dice: 0.3001  decode.d6.loss_cls: 0.2214  decode.d6.loss_mask: 0.1905  decode.d6.loss_dice: 0.2953  decode.d7.loss_cls: 0.1259  decode.d7.loss_mask: 0.1915  decode.d7.loss_dice: 0.3022  decode.d8.loss_cls: 0.1945  decode.d8.loss_mask: 0.1924  decode.d8.loss_dice: 0.2921
08/06 04:28:26 - mmengine - INFO - Iter(train) [ 16100/320000]  base_lr: 9.5461e-05 lr: 9.5461e-06  eta: 1 day, 17:24:54  time: 0.4915  data_time: 0.0105  memory: 5891  grad_norm: 143.6518  loss: 8.2271  decode.loss_cls: 0.1257  decode.loss_mask: 0.2341  decode.loss_dice: 0.3568  decode.d0.loss_cls: 0.9646  decode.d0.loss_mask: 0.2491  decode.d0.loss_dice: 0.3753  decode.d1.loss_cls: 0.2752  decode.d1.loss_mask: 0.2363  decode.d1.loss_dice: 0.3989  decode.d2.loss_cls: 0.1713  decode.d2.loss_mask: 0.2310  decode.d2.loss_dice: 0.3548  decode.d3.loss_cls: 0.1798  decode.d3.loss_mask: 0.2285  decode.d3.loss_dice: 0.3330  decode.d4.loss_cls: 0.1514  decode.d4.loss_mask: 0.2291  decode.d4.loss_dice: 0.3629  decode.d5.loss_cls: 0.1117  decode.d5.loss_mask: 0.2297  decode.d5.loss_dice: 0.3584  decode.d6.loss_cls: 0.1187  decode.d6.loss_mask: 0.2300  decode.d6.loss_dice: 0.3695  decode.d7.loss_cls: 0.0991  decode.d7.loss_mask: 0.2236  decode.d7.loss_dice: 0.3643  decode.d8.loss_cls: 0.1002  decode.d8.loss_mask: 0.2272  decode.d8.loss_dice: 0.3367
08/06 04:28:51 - mmengine - INFO - Iter(train) [ 16150/320000]  base_lr: 9.5446e-05 lr: 9.5446e-06  eta: 1 day, 17:24:34  time: 0.4920  data_time: 0.0103  memory: 5908  grad_norm: 218.0208  loss: 7.3849  decode.loss_cls: 0.2524  decode.loss_mask: 0.1891  decode.loss_dice: 0.2364  decode.d0.loss_cls: 0.9683  decode.d0.loss_mask: 0.2033  decode.d0.loss_dice: 0.2816  decode.d1.loss_cls: 0.2533  decode.d1.loss_mask: 0.1896  decode.d1.loss_dice: 0.2436  decode.d2.loss_cls: 0.2884  decode.d2.loss_mask: 0.1910  decode.d2.loss_dice: 0.2431  decode.d3.loss_cls: 0.2038  decode.d3.loss_mask: 0.1987  decode.d3.loss_dice: 0.2541  decode.d4.loss_cls: 0.1938  decode.d4.loss_mask: 0.1915  decode.d4.loss_dice: 0.2411  decode.d5.loss_cls: 0.2010  decode.d5.loss_mask: 0.1939  decode.d5.loss_dice: 0.2614  decode.d6.loss_cls: 0.1661  decode.d6.loss_mask: 0.1907  decode.d6.loss_dice: 0.2593  decode.d7.loss_cls: 0.1627  decode.d7.loss_mask: 0.1965  decode.d7.loss_dice: 0.2670  decode.d8.loss_cls: 0.2330  decode.d8.loss_mask: 0.1920  decode.d8.loss_dice: 0.2381
08/06 04:29:16 - mmengine - INFO - Iter(train) [ 16200/320000]  base_lr: 9.5432e-05 lr: 9.5432e-06  eta: 1 day, 17:24:10  time: 0.4921  data_time: 0.0105  memory: 5890  grad_norm: 178.4319  loss: 8.0369  decode.loss_cls: 0.1620  decode.loss_mask: 0.2139  decode.loss_dice: 0.2789  decode.d0.loss_cls: 1.1995  decode.d0.loss_mask: 0.2121  decode.d0.loss_dice: 0.2888  decode.d1.loss_cls: 0.3156  decode.d1.loss_mask: 0.2193  decode.d1.loss_dice: 0.2929  decode.d2.loss_cls: 0.2111  decode.d2.loss_mask: 0.2130  decode.d2.loss_dice: 0.2886  decode.d3.loss_cls: 0.1688  decode.d3.loss_mask: 0.2306  decode.d3.loss_dice: 0.3036  decode.d4.loss_cls: 0.1569  decode.d4.loss_mask: 0.2133  decode.d4.loss_dice: 0.2998  decode.d5.loss_cls: 0.1677  decode.d5.loss_mask: 0.2112  decode.d5.loss_dice: 0.3123  decode.d6.loss_cls: 0.1940  decode.d6.loss_mask: 0.2153  decode.d6.loss_dice: 0.3060  decode.d7.loss_cls: 0.2126  decode.d7.loss_mask: 0.2089  decode.d7.loss_dice: 0.2738  decode.d8.loss_cls: 0.1676  decode.d8.loss_mask: 0.2132  decode.d8.loss_dice: 0.2855
08/06 04:29:40 - mmengine - INFO - Iter(train) [ 16250/320000]  base_lr: 9.5418e-05 lr: 9.5418e-06  eta: 1 day, 17:23:47  time: 0.4921  data_time: 0.0104  memory: 5908  grad_norm: 153.9851  loss: 10.0288  decode.loss_cls: 0.2541  decode.loss_mask: 0.3050  decode.loss_dice: 0.3227  decode.d0.loss_cls: 1.1216  decode.d0.loss_mask: 0.3197  decode.d0.loss_dice: 0.3573  decode.d1.loss_cls: 0.3177  decode.d1.loss_mask: 0.3173  decode.d1.loss_dice: 0.3623  decode.d2.loss_cls: 0.2988  decode.d2.loss_mask: 0.3122  decode.d2.loss_dice: 0.3144  decode.d3.loss_cls: 0.3498  decode.d3.loss_mask: 0.3095  decode.d3.loss_dice: 0.3116  decode.d4.loss_cls: 0.2575  decode.d4.loss_mask: 0.3085  decode.d4.loss_dice: 0.3127  decode.d5.loss_cls: 0.2760  decode.d5.loss_mask: 0.3220  decode.d5.loss_dice: 0.3440  decode.d6.loss_cls: 0.2424  decode.d6.loss_mask: 0.3068  decode.d6.loss_dice: 0.3296  decode.d7.loss_cls: 0.2399  decode.d7.loss_mask: 0.3138  decode.d7.loss_dice: 0.3278  decode.d8.loss_cls: 0.2477  decode.d8.loss_mask: 0.3088  decode.d8.loss_dice: 0.3173
08/06 04:30:05 - mmengine - INFO - Iter(train) [ 16300/320000]  base_lr: 9.5404e-05 lr: 9.5404e-06  eta: 1 day, 17:23:23  time: 0.4910  data_time: 0.0103  memory: 5891  grad_norm: 100.9452  loss: 8.6235  decode.loss_cls: 0.1989  decode.loss_mask: 0.2662  decode.loss_dice: 0.3116  decode.d0.loss_cls: 0.9414  decode.d0.loss_mask: 0.2828  decode.d0.loss_dice: 0.3474  decode.d1.loss_cls: 0.2963  decode.d1.loss_mask: 0.2595  decode.d1.loss_dice: 0.2948  decode.d2.loss_cls: 0.2304  decode.d2.loss_mask: 0.2670  decode.d2.loss_dice: 0.3181  decode.d3.loss_cls: 0.2337  decode.d3.loss_mask: 0.2691  decode.d3.loss_dice: 0.3239  decode.d4.loss_cls: 0.1959  decode.d4.loss_mask: 0.2708  decode.d4.loss_dice: 0.3224  decode.d5.loss_cls: 0.1898  decode.d5.loss_mask: 0.2715  decode.d5.loss_dice: 0.3149  decode.d6.loss_cls: 0.1784  decode.d6.loss_mask: 0.2737  decode.d6.loss_dice: 0.3039  decode.d7.loss_cls: 0.1575  decode.d7.loss_mask: 0.2754  decode.d7.loss_dice: 0.3131  decode.d8.loss_cls: 0.1370  decode.d8.loss_mask: 0.2750  decode.d8.loss_dice: 0.3033
08/06 04:30:29 - mmengine - INFO - Iter(train) [ 16350/320000]  base_lr: 9.5390e-05 lr: 9.5390e-06  eta: 1 day, 17:23:00  time: 0.4919  data_time: 0.0103  memory: 5908  grad_norm: 114.5007  loss: 9.9192  decode.loss_cls: 0.3100  decode.loss_mask: 0.2712  decode.loss_dice: 0.3180  decode.d0.loss_cls: 1.1757  decode.d0.loss_mask: 0.2841  decode.d0.loss_dice: 0.3915  decode.d1.loss_cls: 0.3803  decode.d1.loss_mask: 0.2676  decode.d1.loss_dice: 0.3441  decode.d2.loss_cls: 0.3526  decode.d2.loss_mask: 0.2640  decode.d2.loss_dice: 0.3087  decode.d3.loss_cls: 0.3006  decode.d3.loss_mask: 0.2705  decode.d3.loss_dice: 0.3160  decode.d4.loss_cls: 0.2661  decode.d4.loss_mask: 0.2628  decode.d4.loss_dice: 0.3199  decode.d5.loss_cls: 0.3076  decode.d5.loss_mask: 0.2674  decode.d5.loss_dice: 0.3173  decode.d6.loss_cls: 0.3106  decode.d6.loss_mask: 0.2691  decode.d6.loss_dice: 0.3081  decode.d7.loss_cls: 0.2584  decode.d7.loss_mask: 0.2726  decode.d7.loss_dice: 0.3120  decode.d8.loss_cls: 0.3145  decode.d8.loss_mask: 0.2729  decode.d8.loss_dice: 0.3051
08/06 04:30:54 - mmengine - INFO - Iter(train) [ 16400/320000]  base_lr: 9.5376e-05 lr: 9.5376e-06  eta: 1 day, 17:22:37  time: 0.4917  data_time: 0.0103  memory: 5891  grad_norm: 254.6492  loss: 9.5453  decode.loss_cls: 0.1867  decode.loss_mask: 0.3783  decode.loss_dice: 0.2753  decode.d0.loss_cls: 1.0259  decode.d0.loss_mask: 0.3583  decode.d0.loss_dice: 0.2979  decode.d1.loss_cls: 0.2954  decode.d1.loss_mask: 0.3537  decode.d1.loss_dice: 0.2747  decode.d2.loss_cls: 0.1855  decode.d2.loss_mask: 0.3781  decode.d2.loss_dice: 0.2833  decode.d3.loss_cls: 0.2528  decode.d3.loss_mask: 0.3542  decode.d3.loss_dice: 0.2793  decode.d4.loss_cls: 0.2173  decode.d4.loss_mask: 0.3747  decode.d4.loss_dice: 0.2834  decode.d5.loss_cls: 0.1974  decode.d5.loss_mask: 0.3811  decode.d5.loss_dice: 0.2749  decode.d6.loss_cls: 0.1953  decode.d6.loss_mask: 0.3885  decode.d6.loss_dice: 0.2801  decode.d7.loss_cls: 0.2920  decode.d7.loss_mask: 0.3597  decode.d7.loss_dice: 0.2779  decode.d8.loss_cls: 0.1862  decode.d8.loss_mask: 0.3790  decode.d8.loss_dice: 0.2782
08/06 04:31:19 - mmengine - INFO - Iter(train) [ 16450/320000]  base_lr: 9.5362e-05 lr: 9.5362e-06  eta: 1 day, 17:22:13  time: 0.4929  data_time: 0.0105  memory: 5892  grad_norm: 92.6487  loss: 10.8540  decode.loss_cls: 0.3651  decode.loss_mask: 0.2365  decode.loss_dice: 0.3739  decode.d0.loss_cls: 1.1356  decode.d0.loss_mask: 0.2462  decode.d0.loss_dice: 0.4177  decode.d1.loss_cls: 0.4109  decode.d1.loss_mask: 0.2405  decode.d1.loss_dice: 0.3344  decode.d2.loss_cls: 0.4048  decode.d2.loss_mask: 0.2432  decode.d2.loss_dice: 0.3906  decode.d3.loss_cls: 0.3865  decode.d3.loss_mask: 0.2444  decode.d3.loss_dice: 0.3697  decode.d4.loss_cls: 0.3746  decode.d4.loss_mask: 0.2399  decode.d4.loss_dice: 0.3768  decode.d5.loss_cls: 0.4030  decode.d5.loss_mask: 0.2432  decode.d5.loss_dice: 0.3739  decode.d6.loss_cls: 0.4015  decode.d6.loss_mask: 0.2420  decode.d6.loss_dice: 0.3575  decode.d7.loss_cls: 0.4100  decode.d7.loss_mask: 0.2382  decode.d7.loss_dice: 0.3637  decode.d8.loss_cls: 0.3779  decode.d8.loss_mask: 0.2401  decode.d8.loss_dice: 0.4117
08/06 04:31:43 - mmengine - INFO - Iter(train) [ 16500/320000]  base_lr: 9.5347e-05 lr: 9.5347e-06  eta: 1 day, 17:21:50  time: 0.4930  data_time: 0.0106  memory: 5875  grad_norm: 121.3094  loss: 9.6455  decode.loss_cls: 0.2892  decode.loss_mask: 0.2635  decode.loss_dice: 0.3141  decode.d0.loss_cls: 1.1348  decode.d0.loss_mask: 0.2758  decode.d0.loss_dice: 0.3722  decode.d1.loss_cls: 0.2849  decode.d1.loss_mask: 0.2786  decode.d1.loss_dice: 0.3588  decode.d2.loss_cls: 0.2397  decode.d2.loss_mask: 0.2798  decode.d2.loss_dice: 0.3514  decode.d3.loss_cls: 0.2365  decode.d3.loss_mask: 0.2689  decode.d3.loss_dice: 0.3281  decode.d4.loss_cls: 0.2510  decode.d4.loss_mask: 0.2619  decode.d4.loss_dice: 0.2976  decode.d5.loss_cls: 0.2663  decode.d5.loss_mask: 0.2676  decode.d5.loss_dice: 0.3168  decode.d6.loss_cls: 0.3446  decode.d6.loss_mask: 0.2675  decode.d6.loss_dice: 0.3221  decode.d7.loss_cls: 0.2819  decode.d7.loss_mask: 0.2656  decode.d7.loss_dice: 0.3408  decode.d8.loss_cls: 0.2784  decode.d8.loss_mask: 0.2666  decode.d8.loss_dice: 0.3403
08/06 04:32:08 - mmengine - INFO - Iter(train) [ 16550/320000]  base_lr: 9.5333e-05 lr: 9.5333e-06  eta: 1 day, 17:21:27  time: 0.4909  data_time: 0.0103  memory: 5877  grad_norm: 87.5656  loss: 7.6338  decode.loss_cls: 0.1365  decode.loss_mask: 0.2343  decode.loss_dice: 0.2486  decode.d0.loss_cls: 0.8547  decode.d0.loss_mask: 0.2359  decode.d0.loss_dice: 0.2661  decode.d1.loss_cls: 0.2376  decode.d1.loss_mask: 0.2409  decode.d1.loss_dice: 0.2623  decode.d2.loss_cls: 0.1932  decode.d2.loss_mask: 0.2453  decode.d2.loss_dice: 0.2440  decode.d3.loss_cls: 0.1957  decode.d3.loss_mask: 0.2350  decode.d3.loss_dice: 0.2352  decode.d4.loss_cls: 0.2501  decode.d4.loss_mask: 0.2325  decode.d4.loss_dice: 0.2546  decode.d5.loss_cls: 0.2153  decode.d5.loss_mask: 0.2329  decode.d5.loss_dice: 0.2577  decode.d6.loss_cls: 0.2147  decode.d6.loss_mask: 0.2347  decode.d6.loss_dice: 0.2478  decode.d7.loss_cls: 0.2028  decode.d7.loss_mask: 0.2365  decode.d7.loss_dice: 0.2633  decode.d8.loss_cls: 0.2350  decode.d8.loss_mask: 0.2363  decode.d8.loss_dice: 0.2545
08/06 04:32:32 - mmengine - INFO - Iter(train) [ 16600/320000]  base_lr: 9.5319e-05 lr: 9.5319e-06  eta: 1 day, 17:21:03  time: 0.4908  data_time: 0.0104  memory: 5891  grad_norm: 270.7640  loss: 8.7495  decode.loss_cls: 0.1362  decode.loss_mask: 0.2943  decode.loss_dice: 0.3217  decode.d0.loss_cls: 0.8606  decode.d0.loss_mask: 0.2720  decode.d0.loss_dice: 0.3529  decode.d1.loss_cls: 0.3287  decode.d1.loss_mask: 0.2650  decode.d1.loss_dice: 0.3140  decode.d2.loss_cls: 0.2245  decode.d2.loss_mask: 0.2959  decode.d2.loss_dice: 0.3629  decode.d3.loss_cls: 0.1621  decode.d3.loss_mask: 0.3168  decode.d3.loss_dice: 0.3357  decode.d4.loss_cls: 0.1803  decode.d4.loss_mask: 0.3140  decode.d4.loss_dice: 0.3510  decode.d5.loss_cls: 0.1843  decode.d5.loss_mask: 0.3083  decode.d5.loss_dice: 0.3300  decode.d6.loss_cls: 0.2133  decode.d6.loss_mask: 0.2660  decode.d6.loss_dice: 0.2917  decode.d7.loss_cls: 0.1452  decode.d7.loss_mask: 0.2871  decode.d7.loss_dice: 0.3172  decode.d8.loss_cls: 0.1364  decode.d8.loss_mask: 0.2785  decode.d8.loss_dice: 0.3030
08/06 04:32:57 - mmengine - INFO - Iter(train) [ 16650/320000]  base_lr: 9.5305e-05 lr: 9.5305e-06  eta: 1 day, 17:20:39  time: 0.4910  data_time: 0.0105  memory: 5875  grad_norm: 220.3236  loss: 9.9788  decode.loss_cls: 0.2516  decode.loss_mask: 0.3112  decode.loss_dice: 0.3108  decode.d0.loss_cls: 1.0103  decode.d0.loss_mask: 0.3304  decode.d0.loss_dice: 0.3188  decode.d1.loss_cls: 0.4148  decode.d1.loss_mask: 0.3393  decode.d1.loss_dice: 0.3188  decode.d2.loss_cls: 0.2986  decode.d2.loss_mask: 0.3118  decode.d2.loss_dice: 0.3073  decode.d3.loss_cls: 0.2646  decode.d3.loss_mask: 0.3169  decode.d3.loss_dice: 0.3125  decode.d4.loss_cls: 0.2489  decode.d4.loss_mask: 0.3129  decode.d4.loss_dice: 0.2992  decode.d5.loss_cls: 0.3330  decode.d5.loss_mask: 0.3109  decode.d5.loss_dice: 0.3170  decode.d6.loss_cls: 0.3161  decode.d6.loss_mask: 0.3084  decode.d6.loss_dice: 0.3109  decode.d7.loss_cls: 0.2995  decode.d7.loss_mask: 0.3105  decode.d7.loss_dice: 0.3120  decode.d8.loss_cls: 0.2582  decode.d8.loss_mask: 0.3181  decode.d8.loss_dice: 0.3054
08/06 04:33:21 - mmengine - INFO - Iter(train) [ 16700/320000]  base_lr: 9.5291e-05 lr: 9.5291e-06  eta: 1 day, 17:20:15  time: 0.4915  data_time: 0.0105  memory: 5875  grad_norm: 196.0119  loss: 8.9103  decode.loss_cls: 0.1815  decode.loss_mask: 0.3170  decode.loss_dice: 0.2763  decode.d0.loss_cls: 0.8962  decode.d0.loss_mask: 0.3247  decode.d0.loss_dice: 0.2966  decode.d1.loss_cls: 0.2735  decode.d1.loss_mask: 0.3186  decode.d1.loss_dice: 0.2874  decode.d2.loss_cls: 0.1880  decode.d2.loss_mask: 0.3187  decode.d2.loss_dice: 0.2893  decode.d3.loss_cls: 0.2152  decode.d3.loss_mask: 0.3154  decode.d3.loss_dice: 0.2756  decode.d4.loss_cls: 0.1626  decode.d4.loss_mask: 0.3213  decode.d4.loss_dice: 0.2992  decode.d5.loss_cls: 0.1831  decode.d5.loss_mask: 0.3229  decode.d5.loss_dice: 0.3151  decode.d6.loss_cls: 0.2424  decode.d6.loss_mask: 0.3144  decode.d6.loss_dice: 0.2920  decode.d7.loss_cls: 0.2634  decode.d7.loss_mask: 0.3136  decode.d7.loss_dice: 0.3076  decode.d8.loss_cls: 0.1734  decode.d8.loss_mask: 0.3243  decode.d8.loss_dice: 0.3009
08/06 04:33:46 - mmengine - INFO - Iter(train) [ 16750/320000]  base_lr: 9.5277e-05 lr: 9.5277e-06  eta: 1 day, 17:19:52  time: 0.4905  data_time: 0.0103  memory: 5907  grad_norm: 70.4276  loss: 7.2058  decode.loss_cls: 0.1381  decode.loss_mask: 0.2399  decode.loss_dice: 0.2514  decode.d0.loss_cls: 0.9563  decode.d0.loss_mask: 0.2460  decode.d0.loss_dice: 0.2716  decode.d1.loss_cls: 0.1834  decode.d1.loss_mask: 0.2429  decode.d1.loss_dice: 0.2621  decode.d2.loss_cls: 0.1310  decode.d2.loss_mask: 0.2409  decode.d2.loss_dice: 0.2525  decode.d3.loss_cls: 0.1172  decode.d3.loss_mask: 0.2376  decode.d3.loss_dice: 0.2559  decode.d4.loss_cls: 0.1317  decode.d4.loss_mask: 0.2427  decode.d4.loss_dice: 0.2527  decode.d5.loss_cls: 0.1556  decode.d5.loss_mask: 0.2419  decode.d5.loss_dice: 0.2611  decode.d6.loss_cls: 0.1535  decode.d6.loss_mask: 0.2421  decode.d6.loss_dice: 0.2566  decode.d7.loss_cls: 0.1417  decode.d7.loss_mask: 0.2373  decode.d7.loss_dice: 0.2489  decode.d8.loss_cls: 0.1245  decode.d8.loss_mask: 0.2385  decode.d8.loss_dice: 0.2505
08/06 04:34:11 - mmengine - INFO - Iter(train) [ 16800/320000]  base_lr: 9.5263e-05 lr: 9.5263e-06  eta: 1 day, 17:19:29  time: 0.4913  data_time: 0.0104  memory: 5877  grad_norm: 126.3997  loss: 8.9141  decode.loss_cls: 0.1367  decode.loss_mask: 0.3105  decode.loss_dice: 0.2964  decode.d0.loss_cls: 1.1110  decode.d0.loss_mask: 0.3262  decode.d0.loss_dice: 0.3359  decode.d1.loss_cls: 0.1692  decode.d1.loss_mask: 0.3175  decode.d1.loss_dice: 0.2945  decode.d2.loss_cls: 0.1914  decode.d2.loss_mask: 0.3153  decode.d2.loss_dice: 0.3087  decode.d3.loss_cls: 0.1625  decode.d3.loss_mask: 0.3206  decode.d3.loss_dice: 0.3068  decode.d4.loss_cls: 0.2001  decode.d4.loss_mask: 0.3166  decode.d4.loss_dice: 0.2911  decode.d5.loss_cls: 0.2262  decode.d5.loss_mask: 0.3193  decode.d5.loss_dice: 0.3321  decode.d6.loss_cls: 0.1461  decode.d6.loss_mask: 0.3130  decode.d6.loss_dice: 0.2987  decode.d7.loss_cls: 0.1216  decode.d7.loss_mask: 0.3157  decode.d7.loss_dice: 0.3041  decode.d8.loss_cls: 0.2056  decode.d8.loss_mask: 0.3165  decode.d8.loss_dice: 0.3043
08/06 04:34:35 - mmengine - INFO - Iter(train) [ 16850/320000]  base_lr: 9.5248e-05 lr: 9.5248e-06  eta: 1 day, 17:19:05  time: 0.4919  data_time: 0.0103  memory: 5890  grad_norm: 101.2713  loss: 6.4632  decode.loss_cls: 0.0798  decode.loss_mask: 0.2102  decode.loss_dice: 0.2457  decode.d0.loss_cls: 0.8518  decode.d0.loss_mask: 0.2188  decode.d0.loss_dice: 0.2696  decode.d1.loss_cls: 0.1828  decode.d1.loss_mask: 0.2092  decode.d1.loss_dice: 0.2552  decode.d2.loss_cls: 0.1081  decode.d2.loss_mask: 0.2117  decode.d2.loss_dice: 0.2495  decode.d3.loss_cls: 0.1633  decode.d3.loss_mask: 0.2125  decode.d3.loss_dice: 0.2508  decode.d4.loss_cls: 0.0928  decode.d4.loss_mask: 0.2072  decode.d4.loss_dice: 0.2575  decode.d5.loss_cls: 0.1170  decode.d5.loss_mask: 0.2082  decode.d5.loss_dice: 0.2551  decode.d6.loss_cls: 0.0716  decode.d6.loss_mask: 0.2110  decode.d6.loss_dice: 0.2557  decode.d7.loss_cls: 0.0613  decode.d7.loss_mask: 0.2109  decode.d7.loss_dice: 0.2525  decode.d8.loss_cls: 0.0724  decode.d8.loss_mask: 0.2107  decode.d8.loss_dice: 0.2603
08/06 04:35:00 - mmengine - INFO - Iter(train) [ 16900/320000]  base_lr: 9.5234e-05 lr: 9.5234e-06  eta: 1 day, 17:18:41  time: 0.4918  data_time: 0.0105  memory: 5907  grad_norm: 144.1164  loss: 10.3158  decode.loss_cls: 0.2628  decode.loss_mask: 0.3017  decode.loss_dice: 0.3241  decode.d0.loss_cls: 1.2215  decode.d0.loss_mask: 0.3048  decode.d0.loss_dice: 0.3611  decode.d1.loss_cls: 0.4332  decode.d1.loss_mask: 0.3065  decode.d1.loss_dice: 0.3536  decode.d2.loss_cls: 0.3618  decode.d2.loss_mask: 0.3219  decode.d2.loss_dice: 0.3370  decode.d3.loss_cls: 0.2700  decode.d3.loss_mask: 0.3078  decode.d3.loss_dice: 0.3152  decode.d4.loss_cls: 0.2578  decode.d4.loss_mask: 0.3070  decode.d4.loss_dice: 0.3121  decode.d5.loss_cls: 0.3022  decode.d5.loss_mask: 0.3110  decode.d5.loss_dice: 0.3404  decode.d6.loss_cls: 0.2556  decode.d6.loss_mask: 0.3012  decode.d6.loss_dice: 0.3107  decode.d7.loss_cls: 0.2768  decode.d7.loss_mask: 0.3030  decode.d7.loss_dice: 0.3206  decode.d8.loss_cls: 0.2597  decode.d8.loss_mask: 0.3123  decode.d8.loss_dice: 0.3623
08/06 04:35:24 - mmengine - INFO - Iter(train) [ 16950/320000]  base_lr: 9.5220e-05 lr: 9.5220e-06  eta: 1 day, 17:18:18  time: 0.4927  data_time: 0.0106  memory: 5892  grad_norm: 218.6572  loss: 9.4210  decode.loss_cls: 0.2219  decode.loss_mask: 0.2861  decode.loss_dice: 0.3298  decode.d0.loss_cls: 1.2567  decode.d0.loss_mask: 0.2982  decode.d0.loss_dice: 0.3757  decode.d1.loss_cls: 0.2653  decode.d1.loss_mask: 0.2858  decode.d1.loss_dice: 0.3372  decode.d2.loss_cls: 0.2465  decode.d2.loss_mask: 0.2893  decode.d2.loss_dice: 0.3309  decode.d3.loss_cls: 0.2340  decode.d3.loss_mask: 0.2827  decode.d3.loss_dice: 0.3250  decode.d4.loss_cls: 0.1915  decode.d4.loss_mask: 0.2846  decode.d4.loss_dice: 0.3171  decode.d5.loss_cls: 0.2000  decode.d5.loss_mask: 0.2796  decode.d5.loss_dice: 0.3276  decode.d6.loss_cls: 0.2225  decode.d6.loss_mask: 0.2785  decode.d6.loss_dice: 0.3214  decode.d7.loss_cls: 0.2026  decode.d7.loss_mask: 0.2860  decode.d7.loss_dice: 0.3260  decode.d8.loss_cls: 0.2106  decode.d8.loss_mask: 0.2821  decode.d8.loss_dice: 0.3256
08/06 04:35:49 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 04:35:49 - mmengine - INFO - Iter(train) [ 17000/320000]  base_lr: 9.5206e-05 lr: 9.5206e-06  eta: 1 day, 17:17:55  time: 0.4914  data_time: 0.0104  memory: 5927  grad_norm: 104.7687  loss: 7.3524  decode.loss_cls: 0.0930  decode.loss_mask: 0.2548  decode.loss_dice: 0.2831  decode.d0.loss_cls: 0.8585  decode.d0.loss_mask: 0.2754  decode.d0.loss_dice: 0.3210  decode.d1.loss_cls: 0.1045  decode.d1.loss_mask: 0.2627  decode.d1.loss_dice: 0.2866  decode.d2.loss_cls: 0.1187  decode.d2.loss_mask: 0.2588  decode.d2.loss_dice: 0.2767  decode.d3.loss_cls: 0.1355  decode.d3.loss_mask: 0.2544  decode.d3.loss_dice: 0.2972  decode.d4.loss_cls: 0.1129  decode.d4.loss_mask: 0.2629  decode.d4.loss_dice: 0.2971  decode.d5.loss_cls: 0.1353  decode.d5.loss_mask: 0.2503  decode.d5.loss_dice: 0.2851  decode.d6.loss_cls: 0.1108  decode.d6.loss_mask: 0.2524  decode.d6.loss_dice: 0.2822  decode.d7.loss_cls: 0.1021  decode.d7.loss_mask: 0.2556  decode.d7.loss_dice: 0.2955  decode.d8.loss_cls: 0.1017  decode.d8.loss_mask: 0.2511  decode.d8.loss_dice: 0.2765
08/06 04:36:14 - mmengine - INFO - Iter(train) [ 17050/320000]  base_lr: 9.5192e-05 lr: 9.5192e-06  eta: 1 day, 17:17:31  time: 0.4911  data_time: 0.0103  memory: 5874  grad_norm: 135.4669  loss: 8.7396  decode.loss_cls: 0.1241  decode.loss_mask: 0.2984  decode.loss_dice: 0.3610  decode.d0.loss_cls: 0.9152  decode.d0.loss_mask: 0.3221  decode.d0.loss_dice: 0.3964  decode.d1.loss_cls: 0.1571  decode.d1.loss_mask: 0.3157  decode.d1.loss_dice: 0.3986  decode.d2.loss_cls: 0.1240  decode.d2.loss_mask: 0.3056  decode.d2.loss_dice: 0.3807  decode.d3.loss_cls: 0.1493  decode.d3.loss_mask: 0.2941  decode.d3.loss_dice: 0.3540  decode.d4.loss_cls: 0.1156  decode.d4.loss_mask: 0.2950  decode.d4.loss_dice: 0.3487  decode.d5.loss_cls: 0.1163  decode.d5.loss_mask: 0.3015  decode.d5.loss_dice: 0.3481  decode.d6.loss_cls: 0.1404  decode.d6.loss_mask: 0.2974  decode.d6.loss_dice: 0.3475  decode.d7.loss_cls: 0.1299  decode.d7.loss_mask: 0.2950  decode.d7.loss_dice: 0.3407  decode.d8.loss_cls: 0.1213  decode.d8.loss_mask: 0.3004  decode.d8.loss_dice: 0.3453
08/06 04:36:38 - mmengine - INFO - Iter(train) [ 17100/320000]  base_lr: 9.5178e-05 lr: 9.5178e-06  eta: 1 day, 17:17:07  time: 0.4904  data_time: 0.0104  memory: 5891  grad_norm: 244.0476  loss: 10.2202  decode.loss_cls: 0.2493  decode.loss_mask: 0.3932  decode.loss_dice: 0.2776  decode.d0.loss_cls: 0.8927  decode.d0.loss_mask: 0.4343  decode.d0.loss_dice: 0.3276  decode.d1.loss_cls: 0.3202  decode.d1.loss_mask: 0.3926  decode.d1.loss_dice: 0.3004  decode.d2.loss_cls: 0.2842  decode.d2.loss_mask: 0.3761  decode.d2.loss_dice: 0.2913  decode.d3.loss_cls: 0.2585  decode.d3.loss_mask: 0.3772  decode.d3.loss_dice: 0.2926  decode.d4.loss_cls: 0.2903  decode.d4.loss_mask: 0.3886  decode.d4.loss_dice: 0.2888  decode.d5.loss_cls: 0.2679  decode.d5.loss_mask: 0.3732  decode.d5.loss_dice: 0.2684  decode.d6.loss_cls: 0.2423  decode.d6.loss_mask: 0.4000  decode.d6.loss_dice: 0.2934  decode.d7.loss_cls: 0.2493  decode.d7.loss_mask: 0.3966  decode.d7.loss_dice: 0.2991  decode.d8.loss_cls: 0.2830  decode.d8.loss_mask: 0.4031  decode.d8.loss_dice: 0.3085
08/06 04:37:03 - mmengine - INFO - Iter(train) [ 17150/320000]  base_lr: 9.5164e-05 lr: 9.5164e-06  eta: 1 day, 17:16:43  time: 0.4918  data_time: 0.0105  memory: 5891  grad_norm: 85.7890  loss: 7.0373  decode.loss_cls: 0.1216  decode.loss_mask: 0.1946  decode.loss_dice: 0.2868  decode.d0.loss_cls: 0.9085  decode.d0.loss_mask: 0.1965  decode.d0.loss_dice: 0.3235  decode.d1.loss_cls: 0.2074  decode.d1.loss_mask: 0.1959  decode.d1.loss_dice: 0.2789  decode.d2.loss_cls: 0.1235  decode.d2.loss_mask: 0.1956  decode.d2.loss_dice: 0.2931  decode.d3.loss_cls: 0.2025  decode.d3.loss_mask: 0.1940  decode.d3.loss_dice: 0.2685  decode.d4.loss_cls: 0.1399  decode.d4.loss_mask: 0.1936  decode.d4.loss_dice: 0.2574  decode.d5.loss_cls: 0.1433  decode.d5.loss_mask: 0.1951  decode.d5.loss_dice: 0.2762  decode.d6.loss_cls: 0.1406  decode.d6.loss_mask: 0.1974  decode.d6.loss_dice: 0.2882  decode.d7.loss_cls: 0.1209  decode.d7.loss_mask: 0.1990  decode.d7.loss_dice: 0.3072  decode.d8.loss_cls: 0.1263  decode.d8.loss_mask: 0.1976  decode.d8.loss_dice: 0.2637
08/06 04:37:27 - mmengine - INFO - Iter(train) [ 17200/320000]  base_lr: 9.5150e-05 lr: 9.5150e-06  eta: 1 day, 17:16:19  time: 0.4899  data_time: 0.0104  memory: 5907  grad_norm: 292.5125  loss: 10.3608  decode.loss_cls: 0.2225  decode.loss_mask: 0.3591  decode.loss_dice: 0.2898  decode.d0.loss_cls: 1.1153  decode.d0.loss_mask: 0.3397  decode.d0.loss_dice: 0.2893  decode.d1.loss_cls: 0.3123  decode.d1.loss_mask: 0.3620  decode.d1.loss_dice: 0.2990  decode.d2.loss_cls: 0.2874  decode.d2.loss_mask: 0.3550  decode.d2.loss_dice: 0.2792  decode.d3.loss_cls: 0.3001  decode.d3.loss_mask: 0.3798  decode.d3.loss_dice: 0.3174  decode.d4.loss_cls: 0.2968  decode.d4.loss_mask: 0.3860  decode.d4.loss_dice: 0.3248  decode.d5.loss_cls: 0.3043  decode.d5.loss_mask: 0.3676  decode.d5.loss_dice: 0.3140  decode.d6.loss_cls: 0.2851  decode.d6.loss_mask: 0.3863  decode.d6.loss_dice: 0.3608  decode.d7.loss_cls: 0.2559  decode.d7.loss_mask: 0.3638  decode.d7.loss_dice: 0.3246  decode.d8.loss_cls: 0.2329  decode.d8.loss_mask: 0.3521  decode.d8.loss_dice: 0.2978
08/06 04:37:52 - mmengine - INFO - Iter(train) [ 17250/320000]  base_lr: 9.5135e-05 lr: 9.5135e-06  eta: 1 day, 17:15:57  time: 0.4912  data_time: 0.0106  memory: 5892  grad_norm: 114.4552  loss: 7.4328  decode.loss_cls: 0.0862  decode.loss_mask: 0.2589  decode.loss_dice: 0.2585  decode.d0.loss_cls: 1.0688  decode.d0.loss_mask: 0.2656  decode.d0.loss_dice: 0.2826  decode.d1.loss_cls: 0.1648  decode.d1.loss_mask: 0.2659  decode.d1.loss_dice: 0.2538  decode.d2.loss_cls: 0.1471  decode.d2.loss_mask: 0.2554  decode.d2.loss_dice: 0.2561  decode.d3.loss_cls: 0.1159  decode.d3.loss_mask: 0.2548  decode.d3.loss_dice: 0.2619  decode.d4.loss_cls: 0.1544  decode.d4.loss_mask: 0.2520  decode.d4.loss_dice: 0.2633  decode.d5.loss_cls: 0.1261  decode.d5.loss_mask: 0.2591  decode.d5.loss_dice: 0.2640  decode.d6.loss_cls: 0.1575  decode.d6.loss_mask: 0.2585  decode.d6.loss_dice: 0.2581  decode.d7.loss_cls: 0.0976  decode.d7.loss_mask: 0.2619  decode.d7.loss_dice: 0.2564  decode.d8.loss_cls: 0.0994  decode.d8.loss_mask: 0.2649  decode.d8.loss_dice: 0.2635
08/06 04:38:17 - mmengine - INFO - Iter(train) [ 17300/320000]  base_lr: 9.5121e-05 lr: 9.5121e-06  eta: 1 day, 17:15:33  time: 0.4905  data_time: 0.0105  memory: 5890  grad_norm: 173.7775  loss: 9.8282  decode.loss_cls: 0.2187  decode.loss_mask: 0.3300  decode.loss_dice: 0.3355  decode.d0.loss_cls: 1.0111  decode.d0.loss_mask: 0.3265  decode.d0.loss_dice: 0.3343  decode.d1.loss_cls: 0.3101  decode.d1.loss_mask: 0.3075  decode.d1.loss_dice: 0.3275  decode.d2.loss_cls: 0.2017  decode.d2.loss_mask: 0.3386  decode.d2.loss_dice: 0.3618  decode.d3.loss_cls: 0.2334  decode.d3.loss_mask: 0.3315  decode.d3.loss_dice: 0.3131  decode.d4.loss_cls: 0.2531  decode.d4.loss_mask: 0.3179  decode.d4.loss_dice: 0.3457  decode.d5.loss_cls: 0.3399  decode.d5.loss_mask: 0.3017  decode.d5.loss_dice: 0.3280  decode.d6.loss_cls: 0.2077  decode.d6.loss_mask: 0.3104  decode.d6.loss_dice: 0.3446  decode.d7.loss_cls: 0.3133  decode.d7.loss_mask: 0.2986  decode.d7.loss_dice: 0.3262  decode.d8.loss_cls: 0.2315  decode.d8.loss_mask: 0.3209  decode.d8.loss_dice: 0.3070
08/06 04:38:41 - mmengine - INFO - Iter(train) [ 17350/320000]  base_lr: 9.5107e-05 lr: 9.5107e-06  eta: 1 day, 17:15:09  time: 0.4904  data_time: 0.0104  memory: 5892  grad_norm: 322.4177  loss: 8.4819  decode.loss_cls: 0.2723  decode.loss_mask: 0.2363  decode.loss_dice: 0.2584  decode.d0.loss_cls: 1.1326  decode.d0.loss_mask: 0.2335  decode.d0.loss_dice: 0.2814  decode.d1.loss_cls: 0.2481  decode.d1.loss_mask: 0.2420  decode.d1.loss_dice: 0.2967  decode.d2.loss_cls: 0.2361  decode.d2.loss_mask: 0.2374  decode.d2.loss_dice: 0.2625  decode.d3.loss_cls: 0.2141  decode.d3.loss_mask: 0.2428  decode.d3.loss_dice: 0.2618  decode.d4.loss_cls: 0.2372  decode.d4.loss_mask: 0.2399  decode.d4.loss_dice: 0.2762  decode.d5.loss_cls: 0.2765  decode.d5.loss_mask: 0.2424  decode.d5.loss_dice: 0.2705  decode.d6.loss_cls: 0.2468  decode.d6.loss_mask: 0.2411  decode.d6.loss_dice: 0.2787  decode.d7.loss_cls: 0.2491  decode.d7.loss_mask: 0.2389  decode.d7.loss_dice: 0.2767  decode.d8.loss_cls: 0.2223  decode.d8.loss_mask: 0.2369  decode.d8.loss_dice: 0.2928
08/06 04:39:06 - mmengine - INFO - Iter(train) [ 17400/320000]  base_lr: 9.5093e-05 lr: 9.5093e-06  eta: 1 day, 17:14:45  time: 0.4917  data_time: 0.0107  memory: 5908  grad_norm: 143.8487  loss: 9.4547  decode.loss_cls: 0.3174  decode.loss_mask: 0.2630  decode.loss_dice: 0.2859  decode.d0.loss_cls: 1.1903  decode.d0.loss_mask: 0.2712  decode.d0.loss_dice: 0.3105  decode.d1.loss_cls: 0.3141  decode.d1.loss_mask: 0.2815  decode.d1.loss_dice: 0.2685  decode.d2.loss_cls: 0.3292  decode.d2.loss_mask: 0.2715  decode.d2.loss_dice: 0.2764  decode.d3.loss_cls: 0.2953  decode.d3.loss_mask: 0.2741  decode.d3.loss_dice: 0.2770  decode.d4.loss_cls: 0.2734  decode.d4.loss_mask: 0.2696  decode.d4.loss_dice: 0.2863  decode.d5.loss_cls: 0.3178  decode.d5.loss_mask: 0.2695  decode.d5.loss_dice: 0.2799  decode.d6.loss_cls: 0.2913  decode.d6.loss_mask: 0.2689  decode.d6.loss_dice: 0.2921  decode.d7.loss_cls: 0.2787  decode.d7.loss_mask: 0.2670  decode.d7.loss_dice: 0.2794  decode.d8.loss_cls: 0.2949  decode.d8.loss_mask: 0.2672  decode.d8.loss_dice: 0.2930
08/06 04:39:30 - mmengine - INFO - Iter(train) [ 17450/320000]  base_lr: 9.5079e-05 lr: 9.5079e-06  eta: 1 day, 17:14:21  time: 0.4911  data_time: 0.0105  memory: 5890  grad_norm: 158.0997  loss: 9.1202  decode.loss_cls: 0.2086  decode.loss_mask: 0.3103  decode.loss_dice: 0.3200  decode.d0.loss_cls: 0.9752  decode.d0.loss_mask: 0.3199  decode.d0.loss_dice: 0.3397  decode.d1.loss_cls: 0.2205  decode.d1.loss_mask: 0.3140  decode.d1.loss_dice: 0.3100  decode.d2.loss_cls: 0.2044  decode.d2.loss_mask: 0.3090  decode.d2.loss_dice: 0.3193  decode.d3.loss_cls: 0.2312  decode.d3.loss_mask: 0.3096  decode.d3.loss_dice: 0.3134  decode.d4.loss_cls: 0.1932  decode.d4.loss_mask: 0.3136  decode.d4.loss_dice: 0.3106  decode.d5.loss_cls: 0.2101  decode.d5.loss_mask: 0.3117  decode.d5.loss_dice: 0.3239  decode.d6.loss_cls: 0.1914  decode.d6.loss_mask: 0.3118  decode.d6.loss_dice: 0.3226  decode.d7.loss_cls: 0.2047  decode.d7.loss_mask: 0.3151  decode.d7.loss_dice: 0.3139  decode.d8.loss_cls: 0.1747  decode.d8.loss_mask: 0.3142  decode.d8.loss_dice: 0.3036
08/06 04:39:55 - mmengine - INFO - Iter(train) [ 17500/320000]  base_lr: 9.5065e-05 lr: 9.5065e-06  eta: 1 day, 17:13:56  time: 0.4908  data_time: 0.0106  memory: 5891  grad_norm: 92.6735  loss: 8.9001  decode.loss_cls: 0.1839  decode.loss_mask: 0.2459  decode.loss_dice: 0.2856  decode.d0.loss_cls: 0.8818  decode.d0.loss_mask: 0.2115  decode.d0.loss_dice: 0.3729  decode.d1.loss_cls: 0.3358  decode.d1.loss_mask: 0.1952  decode.d1.loss_dice: 0.3186  decode.d2.loss_cls: 0.3180  decode.d2.loss_mask: 0.1940  decode.d2.loss_dice: 0.3063  decode.d3.loss_cls: 0.2518  decode.d3.loss_mask: 0.2321  decode.d3.loss_dice: 0.3300  decode.d4.loss_cls: 0.2537  decode.d4.loss_mask: 0.2463  decode.d4.loss_dice: 0.3357  decode.d5.loss_cls: 0.3305  decode.d5.loss_mask: 0.2333  decode.d5.loss_dice: 0.3297  decode.d6.loss_cls: 0.2892  decode.d6.loss_mask: 0.2353  decode.d6.loss_dice: 0.3221  decode.d7.loss_cls: 0.2768  decode.d7.loss_mask: 0.2372  decode.d7.loss_dice: 0.3251  decode.d8.loss_cls: 0.2343  decode.d8.loss_mask: 0.2413  decode.d8.loss_dice: 0.3462
08/06 04:40:20 - mmengine - INFO - Iter(train) [ 17550/320000]  base_lr: 9.5051e-05 lr: 9.5051e-06  eta: 1 day, 17:13:36  time: 0.4913  data_time: 0.0107  memory: 5907  grad_norm: 245.3947  loss: 8.6224  decode.loss_cls: 0.2416  decode.loss_mask: 0.2414  decode.loss_dice: 0.2698  decode.d0.loss_cls: 1.0422  decode.d0.loss_mask: 0.2406  decode.d0.loss_dice: 0.3227  decode.d1.loss_cls: 0.2481  decode.d1.loss_mask: 0.2369  decode.d1.loss_dice: 0.2750  decode.d2.loss_cls: 0.4217  decode.d2.loss_mask: 0.2391  decode.d2.loss_dice: 0.2633  decode.d3.loss_cls: 0.3095  decode.d3.loss_mask: 0.2592  decode.d3.loss_dice: 0.3108  decode.d4.loss_cls: 0.2191  decode.d4.loss_mask: 0.2376  decode.d4.loss_dice: 0.2824  decode.d5.loss_cls: 0.2390  decode.d5.loss_mask: 0.2317  decode.d5.loss_dice: 0.2637  decode.d6.loss_cls: 0.2255  decode.d6.loss_mask: 0.2334  decode.d6.loss_dice: 0.2667  decode.d7.loss_cls: 0.2619  decode.d7.loss_mask: 0.2331  decode.d7.loss_dice: 0.2649  decode.d8.loss_cls: 0.2365  decode.d8.loss_mask: 0.2353  decode.d8.loss_dice: 0.2698
08/06 04:40:44 - mmengine - INFO - Iter(train) [ 17600/320000]  base_lr: 9.5036e-05 lr: 9.5036e-06  eta: 1 day, 17:13:11  time: 0.4910  data_time: 0.0107  memory: 5909  grad_norm: 171.9998  loss: 9.6587  decode.loss_cls: 0.2794  decode.loss_mask: 0.2868  decode.loss_dice: 0.3214  decode.d0.loss_cls: 0.9293  decode.d0.loss_mask: 0.3041  decode.d0.loss_dice: 0.3358  decode.d1.loss_cls: 0.3207  decode.d1.loss_mask: 0.2872  decode.d1.loss_dice: 0.3034  decode.d2.loss_cls: 0.3106  decode.d2.loss_mask: 0.2834  decode.d2.loss_dice: 0.3013  decode.d3.loss_cls: 0.2443  decode.d3.loss_mask: 0.2896  decode.d3.loss_dice: 0.3419  decode.d4.loss_cls: 0.2804  decode.d4.loss_mask: 0.2802  decode.d4.loss_dice: 0.3081  decode.d5.loss_cls: 0.3270  decode.d5.loss_mask: 0.2880  decode.d5.loss_dice: 0.3234  decode.d6.loss_cls: 0.3375  decode.d6.loss_mask: 0.2819  decode.d6.loss_dice: 0.2978  decode.d7.loss_cls: 0.3030  decode.d7.loss_mask: 0.2924  decode.d7.loss_dice: 0.3264  decode.d8.loss_cls: 0.2598  decode.d8.loss_mask: 0.2858  decode.d8.loss_dice: 0.3278
08/06 04:41:09 - mmengine - INFO - Iter(train) [ 17650/320000]  base_lr: 9.5022e-05 lr: 9.5022e-06  eta: 1 day, 17:12:47  time: 0.4914  data_time: 0.0107  memory: 5890  grad_norm: 131.1358  loss: 9.9684  decode.loss_cls: 0.2941  decode.loss_mask: 0.2969  decode.loss_dice: 0.3668  decode.d0.loss_cls: 0.9709  decode.d0.loss_mask: 0.2988  decode.d0.loss_dice: 0.3465  decode.d1.loss_cls: 0.2461  decode.d1.loss_mask: 0.2917  decode.d1.loss_dice: 0.3706  decode.d2.loss_cls: 0.2259  decode.d2.loss_mask: 0.2912  decode.d2.loss_dice: 0.3549  decode.d3.loss_cls: 0.2071  decode.d3.loss_mask: 0.2994  decode.d3.loss_dice: 0.3674  decode.d4.loss_cls: 0.2546  decode.d4.loss_mask: 0.3002  decode.d4.loss_dice: 0.3725  decode.d5.loss_cls: 0.2532  decode.d5.loss_mask: 0.2935  decode.d5.loss_dice: 0.3594  decode.d6.loss_cls: 0.2918  decode.d6.loss_mask: 0.2933  decode.d6.loss_dice: 0.3525  decode.d7.loss_cls: 0.2801  decode.d7.loss_mask: 0.2958  decode.d7.loss_dice: 0.3630  decode.d8.loss_cls: 0.3715  decode.d8.loss_mask: 0.2976  decode.d8.loss_dice: 0.3611
08/06 04:41:33 - mmengine - INFO - Iter(train) [ 17700/320000]  base_lr: 9.5008e-05 lr: 9.5008e-06  eta: 1 day, 17:12:22  time: 0.4911  data_time: 0.0105  memory: 5927  grad_norm: 184.0334  loss: 9.4206  decode.loss_cls: 0.2341  decode.loss_mask: 0.3045  decode.loss_dice: 0.3332  decode.d0.loss_cls: 0.9652  decode.d0.loss_mask: 0.3006  decode.d0.loss_dice: 0.3511  decode.d1.loss_cls: 0.2405  decode.d1.loss_mask: 0.3102  decode.d1.loss_dice: 0.3525  decode.d2.loss_cls: 0.1600  decode.d2.loss_mask: 0.3135  decode.d2.loss_dice: 0.3469  decode.d3.loss_cls: 0.1930  decode.d3.loss_mask: 0.3100  decode.d3.loss_dice: 0.3544  decode.d4.loss_cls: 0.2243  decode.d4.loss_mask: 0.3093  decode.d4.loss_dice: 0.3633  decode.d5.loss_cls: 0.1944  decode.d5.loss_mask: 0.3056  decode.d5.loss_dice: 0.3445  decode.d6.loss_cls: 0.2036  decode.d6.loss_mask: 0.3062  decode.d6.loss_dice: 0.3562  decode.d7.loss_cls: 0.2605  decode.d7.loss_mask: 0.2957  decode.d7.loss_dice: 0.3294  decode.d8.loss_cls: 0.2189  decode.d8.loss_mask: 0.3130  decode.d8.loss_dice: 0.3263
08/06 04:41:58 - mmengine - INFO - Iter(train) [ 17750/320000]  base_lr: 9.4994e-05 lr: 9.4994e-06  eta: 1 day, 17:11:57  time: 0.4901  data_time: 0.0106  memory: 5890  grad_norm: 195.2355  loss: 10.6077  decode.loss_cls: 0.3397  decode.loss_mask: 0.3241  decode.loss_dice: 0.3673  decode.d0.loss_cls: 0.9433  decode.d0.loss_mask: 0.3094  decode.d0.loss_dice: 0.3468  decode.d1.loss_cls: 0.2925  decode.d1.loss_mask: 0.3061  decode.d1.loss_dice: 0.3429  decode.d2.loss_cls: 0.3696  decode.d2.loss_mask: 0.3021  decode.d2.loss_dice: 0.3368  decode.d3.loss_cls: 0.3421  decode.d3.loss_mask: 0.3278  decode.d3.loss_dice: 0.3496  decode.d4.loss_cls: 0.2891  decode.d4.loss_mask: 0.3219  decode.d4.loss_dice: 0.3561  decode.d5.loss_cls: 0.3300  decode.d5.loss_mask: 0.3199  decode.d5.loss_dice: 0.3661  decode.d6.loss_cls: 0.3318  decode.d6.loss_mask: 0.3076  decode.d6.loss_dice: 0.3542  decode.d7.loss_cls: 0.3243  decode.d7.loss_mask: 0.3133  decode.d7.loss_dice: 0.3885  decode.d8.loss_cls: 0.3075  decode.d8.loss_mask: 0.3166  decode.d8.loss_dice: 0.3806
08/06 04:42:22 - mmengine - INFO - Iter(train) [ 17800/320000]  base_lr: 9.4980e-05 lr: 9.4980e-06  eta: 1 day, 17:11:33  time: 0.4909  data_time: 0.0108  memory: 5889  grad_norm: 191.6892  loss: 8.3481  decode.loss_cls: 0.1248  decode.loss_mask: 0.2997  decode.loss_dice: 0.2807  decode.d0.loss_cls: 0.9567  decode.d0.loss_mask: 0.3230  decode.d0.loss_dice: 0.3125  decode.d1.loss_cls: 0.2005  decode.d1.loss_mask: 0.3130  decode.d1.loss_dice: 0.3154  decode.d2.loss_cls: 0.1881  decode.d2.loss_mask: 0.3013  decode.d2.loss_dice: 0.2870  decode.d3.loss_cls: 0.1874  decode.d3.loss_mask: 0.3019  decode.d3.loss_dice: 0.2931  decode.d4.loss_cls: 0.1635  decode.d4.loss_mask: 0.3003  decode.d4.loss_dice: 0.2909  decode.d5.loss_cls: 0.1461  decode.d5.loss_mask: 0.3002  decode.d5.loss_dice: 0.2872  decode.d6.loss_cls: 0.1572  decode.d6.loss_mask: 0.2994  decode.d6.loss_dice: 0.2801  decode.d7.loss_cls: 0.1504  decode.d7.loss_mask: 0.3007  decode.d7.loss_dice: 0.2819  decode.d8.loss_cls: 0.1144  decode.d8.loss_mask: 0.3037  decode.d8.loss_dice: 0.2871
08/06 04:42:47 - mmengine - INFO - Iter(train) [ 17850/320000]  base_lr: 9.4966e-05 lr: 9.4966e-06  eta: 1 day, 17:11:09  time: 0.4908  data_time: 0.0107  memory: 5892  grad_norm: 134.6654  loss: 7.0391  decode.loss_cls: 0.0493  decode.loss_mask: 0.2718  decode.loss_dice: 0.2887  decode.d0.loss_cls: 0.7500  decode.d0.loss_mask: 0.2836  decode.d0.loss_dice: 0.3040  decode.d1.loss_cls: 0.0921  decode.d1.loss_mask: 0.2778  decode.d1.loss_dice: 0.2885  decode.d2.loss_cls: 0.0563  decode.d2.loss_mask: 0.2700  decode.d2.loss_dice: 0.2832  decode.d3.loss_cls: 0.0673  decode.d3.loss_mask: 0.2716  decode.d3.loss_dice: 0.2998  decode.d4.loss_cls: 0.1074  decode.d4.loss_mask: 0.2741  decode.d4.loss_dice: 0.2891  decode.d5.loss_cls: 0.0929  decode.d5.loss_mask: 0.2708  decode.d5.loss_dice: 0.2902  decode.d6.loss_cls: 0.0512  decode.d6.loss_mask: 0.2742  decode.d6.loss_dice: 0.2924  decode.d7.loss_cls: 0.0581  decode.d7.loss_mask: 0.2717  decode.d7.loss_dice: 0.2967  decode.d8.loss_cls: 0.0562  decode.d8.loss_mask: 0.2744  decode.d8.loss_dice: 0.2858
08/06 04:43:11 - mmengine - INFO - Iter(train) [ 17900/320000]  base_lr: 9.4952e-05 lr: 9.4952e-06  eta: 1 day, 17:10:44  time: 0.4914  data_time: 0.0107  memory: 5909  grad_norm: 156.1902  loss: 9.7809  decode.loss_cls: 0.2280  decode.loss_mask: 0.2965  decode.loss_dice: 0.3298  decode.d0.loss_cls: 1.1877  decode.d0.loss_mask: 0.3086  decode.d0.loss_dice: 0.3527  decode.d1.loss_cls: 0.3275  decode.d1.loss_mask: 0.2869  decode.d1.loss_dice: 0.3234  decode.d2.loss_cls: 0.2702  decode.d2.loss_mask: 0.2859  decode.d2.loss_dice: 0.3157  decode.d3.loss_cls: 0.2589  decode.d3.loss_mask: 0.2761  decode.d3.loss_dice: 0.3187  decode.d4.loss_cls: 0.2875  decode.d4.loss_mask: 0.2793  decode.d4.loss_dice: 0.3069  decode.d5.loss_cls: 0.3045  decode.d5.loss_mask: 0.2961  decode.d5.loss_dice: 0.3247  decode.d6.loss_cls: 0.2320  decode.d6.loss_mask: 0.3028  decode.d6.loss_dice: 0.3203  decode.d7.loss_cls: 0.2373  decode.d7.loss_mask: 0.2853  decode.d7.loss_dice: 0.3429  decode.d8.loss_cls: 0.2725  decode.d8.loss_mask: 0.2938  decode.d8.loss_dice: 0.3288
08/06 04:43:36 - mmengine - INFO - Iter(train) [ 17950/320000]  base_lr: 9.4937e-05 lr: 9.4937e-06  eta: 1 day, 17:10:20  time: 0.4912  data_time: 0.0107  memory: 5968  grad_norm: 304.1537  loss: 10.5526  decode.loss_cls: 0.2488  decode.loss_mask: 0.3283  decode.loss_dice: 0.3873  decode.d0.loss_cls: 0.9445  decode.d0.loss_mask: 0.4038  decode.d0.loss_dice: 0.4314  decode.d1.loss_cls: 0.3445  decode.d1.loss_mask: 0.3237  decode.d1.loss_dice: 0.3459  decode.d2.loss_cls: 0.2313  decode.d2.loss_mask: 0.3560  decode.d2.loss_dice: 0.3725  decode.d3.loss_cls: 0.2698  decode.d3.loss_mask: 0.3248  decode.d3.loss_dice: 0.3649  decode.d4.loss_cls: 0.2151  decode.d4.loss_mask: 0.3761  decode.d4.loss_dice: 0.3693  decode.d5.loss_cls: 0.3300  decode.d5.loss_mask: 0.3180  decode.d5.loss_dice: 0.3650  decode.d6.loss_cls: 0.2386  decode.d6.loss_mask: 0.3587  decode.d6.loss_dice: 0.3735  decode.d7.loss_cls: 0.2733  decode.d7.loss_mask: 0.3175  decode.d7.loss_dice: 0.3688  decode.d8.loss_cls: 0.2967  decode.d8.loss_mask: 0.3168  decode.d8.loss_dice: 0.3576
08/06 04:44:01 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 04:44:01 - mmengine - INFO - Iter(train) [ 18000/320000]  base_lr: 9.4923e-05 lr: 9.4923e-06  eta: 1 day, 17:09:56  time: 0.4907  data_time: 0.0106  memory: 5907  grad_norm: 163.4796  loss: 9.6980  decode.loss_cls: 0.3399  decode.loss_mask: 0.2448  decode.loss_dice: 0.3050  decode.d0.loss_cls: 0.9573  decode.d0.loss_mask: 0.2617  decode.d0.loss_dice: 0.3029  decode.d1.loss_cls: 0.3555  decode.d1.loss_mask: 0.2660  decode.d1.loss_dice: 0.3089  decode.d2.loss_cls: 0.3863  decode.d2.loss_mask: 0.2485  decode.d2.loss_dice: 0.2733  decode.d3.loss_cls: 0.4144  decode.d3.loss_mask: 0.2500  decode.d3.loss_dice: 0.2686  decode.d4.loss_cls: 0.3810  decode.d4.loss_mask: 0.2431  decode.d4.loss_dice: 0.2702  decode.d5.loss_cls: 0.3845  decode.d5.loss_mask: 0.2463  decode.d5.loss_dice: 0.2858  decode.d6.loss_cls: 0.4116  decode.d6.loss_mask: 0.2544  decode.d6.loss_dice: 0.2878  decode.d7.loss_cls: 0.3634  decode.d7.loss_mask: 0.2484  decode.d7.loss_dice: 0.2913  decode.d8.loss_cls: 0.3087  decode.d8.loss_mask: 0.2449  decode.d8.loss_dice: 0.2935
08/06 04:44:25 - mmengine - INFO - Iter(train) [ 18050/320000]  base_lr: 9.4909e-05 lr: 9.4909e-06  eta: 1 day, 17:09:32  time: 0.4918  data_time: 0.0106  memory: 5875  grad_norm: 174.7495  loss: 7.9474  decode.loss_cls: 0.1671  decode.loss_mask: 0.2660  decode.loss_dice: 0.2844  decode.d0.loss_cls: 0.9309  decode.d0.loss_mask: 0.2888  decode.d0.loss_dice: 0.3109  decode.d1.loss_cls: 0.2177  decode.d1.loss_mask: 0.2797  decode.d1.loss_dice: 0.2826  decode.d2.loss_cls: 0.1794  decode.d2.loss_mask: 0.2690  decode.d2.loss_dice: 0.2774  decode.d3.loss_cls: 0.1479  decode.d3.loss_mask: 0.2593  decode.d3.loss_dice: 0.2725  decode.d4.loss_cls: 0.1609  decode.d4.loss_mask: 0.2546  decode.d4.loss_dice: 0.2649  decode.d5.loss_cls: 0.1765  decode.d5.loss_mask: 0.2639  decode.d5.loss_dice: 0.2814  decode.d6.loss_cls: 0.1350  decode.d6.loss_mask: 0.2666  decode.d6.loss_dice: 0.2812  decode.d7.loss_cls: 0.1399  decode.d7.loss_mask: 0.2686  decode.d7.loss_dice: 0.2799  decode.d8.loss_cls: 0.1850  decode.d8.loss_mask: 0.2698  decode.d8.loss_dice: 0.2857
08/06 04:44:50 - mmengine - INFO - Iter(train) [ 18100/320000]  base_lr: 9.4895e-05 lr: 9.4895e-06  eta: 1 day, 17:09:09  time: 0.4937  data_time: 0.0103  memory: 5910  grad_norm: 127.5075  loss: 9.4439  decode.loss_cls: 0.3084  decode.loss_mask: 0.2480  decode.loss_dice: 0.2783  decode.d0.loss_cls: 1.0082  decode.d0.loss_mask: 0.3151  decode.d0.loss_dice: 0.3351  decode.d1.loss_cls: 0.4236  decode.d1.loss_mask: 0.2708  decode.d1.loss_dice: 0.3146  decode.d2.loss_cls: 0.2814  decode.d2.loss_mask: 0.2729  decode.d2.loss_dice: 0.3015  decode.d3.loss_cls: 0.3940  decode.d3.loss_mask: 0.2719  decode.d3.loss_dice: 0.3151  decode.d4.loss_cls: 0.3908  decode.d4.loss_mask: 0.2552  decode.d4.loss_dice: 0.3077  decode.d5.loss_cls: 0.2558  decode.d5.loss_mask: 0.2427  decode.d5.loss_dice: 0.2914  decode.d6.loss_cls: 0.2788  decode.d6.loss_mask: 0.2408  decode.d6.loss_dice: 0.2731  decode.d7.loss_cls: 0.2857  decode.d7.loss_mask: 0.2336  decode.d7.loss_dice: 0.2832  decode.d8.loss_cls: 0.2401  decode.d8.loss_mask: 0.2456  decode.d8.loss_dice: 0.2805
08/06 04:45:15 - mmengine - INFO - Iter(train) [ 18150/320000]  base_lr: 9.4881e-05 lr: 9.4881e-06  eta: 1 day, 17:08:48  time: 0.4927  data_time: 0.0104  memory: 5890  grad_norm: 158.9407  loss: 8.6718  decode.loss_cls: 0.3007  decode.loss_mask: 0.2295  decode.loss_dice: 0.2947  decode.d0.loss_cls: 0.9505  decode.d0.loss_mask: 0.2389  decode.d0.loss_dice: 0.3240  decode.d1.loss_cls: 0.2832  decode.d1.loss_mask: 0.2303  decode.d1.loss_dice: 0.2732  decode.d2.loss_cls: 0.1801  decode.d2.loss_mask: 0.2293  decode.d2.loss_dice: 0.2878  decode.d3.loss_cls: 0.2241  decode.d3.loss_mask: 0.2310  decode.d3.loss_dice: 0.2925  decode.d4.loss_cls: 0.3321  decode.d4.loss_mask: 0.2279  decode.d4.loss_dice: 0.2961  decode.d5.loss_cls: 0.3076  decode.d5.loss_mask: 0.2398  decode.d5.loss_dice: 0.2871  decode.d6.loss_cls: 0.2763  decode.d6.loss_mask: 0.2309  decode.d6.loss_dice: 0.3091  decode.d7.loss_cls: 0.3002  decode.d7.loss_mask: 0.2273  decode.d7.loss_dice: 0.2925  decode.d8.loss_cls: 0.2416  decode.d8.loss_mask: 0.2307  decode.d8.loss_dice: 0.3027
08/06 04:45:39 - mmengine - INFO - Iter(train) [ 18200/320000]  base_lr: 9.4867e-05 lr: 9.4867e-06  eta: 1 day, 17:08:25  time: 0.4919  data_time: 0.0104  memory: 5907  grad_norm: 109.7909  loss: 6.7683  decode.loss_cls: 0.1172  decode.loss_mask: 0.2222  decode.loss_dice: 0.2612  decode.d0.loss_cls: 0.9470  decode.d0.loss_mask: 0.2248  decode.d0.loss_dice: 0.2732  decode.d1.loss_cls: 0.1246  decode.d1.loss_mask: 0.2194  decode.d1.loss_dice: 0.2694  decode.d2.loss_cls: 0.1347  decode.d2.loss_mask: 0.2204  decode.d2.loss_dice: 0.2599  decode.d3.loss_cls: 0.0984  decode.d3.loss_mask: 0.2209  decode.d3.loss_dice: 0.2669  decode.d4.loss_cls: 0.0974  decode.d4.loss_mask: 0.2217  decode.d4.loss_dice: 0.2675  decode.d5.loss_cls: 0.1096  decode.d5.loss_mask: 0.2201  decode.d5.loss_dice: 0.2651  decode.d6.loss_cls: 0.0974  decode.d6.loss_mask: 0.2203  decode.d6.loss_dice: 0.2593  decode.d7.loss_cls: 0.0968  decode.d7.loss_mask: 0.2211  decode.d7.loss_dice: 0.2572  decode.d8.loss_cls: 0.0881  decode.d8.loss_mask: 0.2208  decode.d8.loss_dice: 0.2657
08/06 04:46:04 - mmengine - INFO - Iter(train) [ 18250/320000]  base_lr: 9.4853e-05 lr: 9.4853e-06  eta: 1 day, 17:08:02  time: 0.4912  data_time: 0.0105  memory: 5890  grad_norm: 116.9118  loss: 10.2744  decode.loss_cls: 0.4242  decode.loss_mask: 0.2798  decode.loss_dice: 0.2662  decode.d0.loss_cls: 1.0139  decode.d0.loss_mask: 0.3011  decode.d0.loss_dice: 0.2872  decode.d1.loss_cls: 0.4050  decode.d1.loss_mask: 0.2799  decode.d1.loss_dice: 0.2785  decode.d2.loss_cls: 0.3754  decode.d2.loss_mask: 0.2869  decode.d2.loss_dice: 0.2770  decode.d3.loss_cls: 0.4076  decode.d3.loss_mask: 0.2965  decode.d3.loss_dice: 0.2885  decode.d4.loss_cls: 0.4295  decode.d4.loss_mask: 0.2975  decode.d4.loss_dice: 0.2617  decode.d5.loss_cls: 0.3779  decode.d5.loss_mask: 0.2959  decode.d5.loss_dice: 0.2558  decode.d6.loss_cls: 0.3421  decode.d6.loss_mask: 0.3009  decode.d6.loss_dice: 0.2650  decode.d7.loss_cls: 0.4827  decode.d7.loss_mask: 0.2876  decode.d7.loss_dice: 0.2719  decode.d8.loss_cls: 0.3996  decode.d8.loss_mask: 0.2812  decode.d8.loss_dice: 0.2575
08/06 04:46:28 - mmengine - INFO - Iter(train) [ 18300/320000]  base_lr: 9.4838e-05 lr: 9.4838e-06  eta: 1 day, 17:07:39  time: 0.4925  data_time: 0.0104  memory: 5890  grad_norm: 250.5058  loss: 8.6413  decode.loss_cls: 0.3469  decode.loss_mask: 0.2534  decode.loss_dice: 0.2927  decode.d0.loss_cls: 1.0791  decode.d0.loss_mask: 0.2506  decode.d0.loss_dice: 0.2777  decode.d1.loss_cls: 0.2539  decode.d1.loss_mask: 0.2557  decode.d1.loss_dice: 0.2891  decode.d2.loss_cls: 0.2446  decode.d2.loss_mask: 0.2519  decode.d2.loss_dice: 0.3114  decode.d3.loss_cls: 0.2370  decode.d3.loss_mask: 0.2549  decode.d3.loss_dice: 0.3174  decode.d4.loss_cls: 0.1803  decode.d4.loss_mask: 0.2456  decode.d4.loss_dice: 0.3011  decode.d5.loss_cls: 0.1954  decode.d5.loss_mask: 0.2443  decode.d5.loss_dice: 0.2853  decode.d6.loss_cls: 0.1824  decode.d6.loss_mask: 0.2510  decode.d6.loss_dice: 0.3328  decode.d7.loss_cls: 0.2101  decode.d7.loss_mask: 0.2500  decode.d7.loss_dice: 0.3068  decode.d8.loss_cls: 0.2128  decode.d8.loss_mask: 0.2475  decode.d8.loss_dice: 0.2800
08/06 04:46:53 - mmengine - INFO - Iter(train) [ 18350/320000]  base_lr: 9.4824e-05 lr: 9.4824e-06  eta: 1 day, 17:07:15  time: 0.4924  data_time: 0.0104  memory: 5891  grad_norm: 211.0747  loss: 9.0933  decode.loss_cls: 0.2084  decode.loss_mask: 0.2650  decode.loss_dice: 0.3245  decode.d0.loss_cls: 1.0367  decode.d0.loss_mask: 0.2888  decode.d0.loss_dice: 0.3648  decode.d1.loss_cls: 0.3575  decode.d1.loss_mask: 0.2843  decode.d1.loss_dice: 0.3543  decode.d2.loss_cls: 0.2166  decode.d2.loss_mask: 0.2735  decode.d2.loss_dice: 0.3575  decode.d3.loss_cls: 0.2281  decode.d3.loss_mask: 0.2732  decode.d3.loss_dice: 0.3464  decode.d4.loss_cls: 0.2062  decode.d4.loss_mask: 0.2631  decode.d4.loss_dice: 0.3292  decode.d5.loss_cls: 0.1819  decode.d5.loss_mask: 0.2600  decode.d5.loss_dice: 0.3316  decode.d6.loss_cls: 0.2247  decode.d6.loss_mask: 0.2634  decode.d6.loss_dice: 0.3188  decode.d7.loss_cls: 0.1838  decode.d7.loss_mask: 0.2650  decode.d7.loss_dice: 0.3287  decode.d8.loss_cls: 0.1620  decode.d8.loss_mask: 0.2679  decode.d8.loss_dice: 0.3272
08/06 04:47:18 - mmengine - INFO - Iter(train) [ 18400/320000]  base_lr: 9.4810e-05 lr: 9.4810e-06  eta: 1 day, 17:06:51  time: 0.4915  data_time: 0.0104  memory: 5875  grad_norm: 145.9103  loss: 8.4050  decode.loss_cls: 0.2420  decode.loss_mask: 0.2464  decode.loss_dice: 0.2562  decode.d0.loss_cls: 1.0160  decode.d0.loss_mask: 0.2553  decode.d0.loss_dice: 0.2670  decode.d1.loss_cls: 0.3211  decode.d1.loss_mask: 0.2551  decode.d1.loss_dice: 0.2876  decode.d2.loss_cls: 0.2370  decode.d2.loss_mask: 0.2605  decode.d2.loss_dice: 0.2897  decode.d3.loss_cls: 0.2379  decode.d3.loss_mask: 0.2544  decode.d3.loss_dice: 0.2564  decode.d4.loss_cls: 0.2189  decode.d4.loss_mask: 0.2515  decode.d4.loss_dice: 0.2711  decode.d5.loss_cls: 0.2341  decode.d5.loss_mask: 0.2477  decode.d5.loss_dice: 0.2627  decode.d6.loss_cls: 0.2103  decode.d6.loss_mask: 0.2497  decode.d6.loss_dice: 0.2746  decode.d7.loss_cls: 0.2188  decode.d7.loss_mask: 0.2503  decode.d7.loss_dice: 0.2565  decode.d8.loss_cls: 0.2682  decode.d8.loss_mask: 0.2459  decode.d8.loss_dice: 0.2621
08/06 04:47:42 - mmengine - INFO - Iter(train) [ 18450/320000]  base_lr: 9.4796e-05 lr: 9.4796e-06  eta: 1 day, 17:06:28  time: 0.4929  data_time: 0.0103  memory: 5927  grad_norm: 150.8031  loss: 7.9310  decode.loss_cls: 0.1802  decode.loss_mask: 0.1974  decode.loss_dice: 0.3281  decode.d0.loss_cls: 1.1533  decode.d0.loss_mask: 0.2151  decode.d0.loss_dice: 0.3330  decode.d1.loss_cls: 0.2971  decode.d1.loss_mask: 0.1919  decode.d1.loss_dice: 0.2990  decode.d2.loss_cls: 0.1391  decode.d2.loss_mask: 0.2000  decode.d2.loss_dice: 0.2931  decode.d3.loss_cls: 0.1836  decode.d3.loss_mask: 0.1990  decode.d3.loss_dice: 0.3024  decode.d4.loss_cls: 0.1780  decode.d4.loss_mask: 0.1943  decode.d4.loss_dice: 0.3039  decode.d5.loss_cls: 0.1476  decode.d5.loss_mask: 0.1960  decode.d5.loss_dice: 0.3116  decode.d6.loss_cls: 0.1665  decode.d6.loss_mask: 0.1917  decode.d6.loss_dice: 0.3133  decode.d7.loss_cls: 0.1944  decode.d7.loss_mask: 0.1952  decode.d7.loss_dice: 0.3198  decode.d8.loss_cls: 0.1840  decode.d8.loss_mask: 0.1947  decode.d8.loss_dice: 0.3276
08/06 04:48:07 - mmengine - INFO - Iter(train) [ 18500/320000]  base_lr: 9.4782e-05 lr: 9.4782e-06  eta: 1 day, 17:06:04  time: 0.4914  data_time: 0.0105  memory: 5890  grad_norm: 72.0554  loss: 7.4080  decode.loss_cls: 0.0886  decode.loss_mask: 0.2497  decode.loss_dice: 0.2808  decode.d0.loss_cls: 0.8578  decode.d0.loss_mask: 0.2522  decode.d0.loss_dice: 0.2963  decode.d1.loss_cls: 0.2221  decode.d1.loss_mask: 0.2511  decode.d1.loss_dice: 0.2818  decode.d2.loss_cls: 0.1729  decode.d2.loss_mask: 0.2500  decode.d2.loss_dice: 0.2805  decode.d3.loss_cls: 0.1392  decode.d3.loss_mask: 0.2502  decode.d3.loss_dice: 0.2777  decode.d4.loss_cls: 0.1411  decode.d4.loss_mask: 0.2479  decode.d4.loss_dice: 0.2861  decode.d5.loss_cls: 0.1050  decode.d5.loss_mask: 0.2504  decode.d5.loss_dice: 0.2771  decode.d6.loss_cls: 0.1482  decode.d6.loss_mask: 0.2511  decode.d6.loss_dice: 0.2815  decode.d7.loss_cls: 0.1196  decode.d7.loss_mask: 0.2499  decode.d7.loss_dice: 0.2788  decode.d8.loss_cls: 0.0885  decode.d8.loss_mask: 0.2515  decode.d8.loss_dice: 0.2805
08/06 04:48:31 - mmengine - INFO - Iter(train) [ 18550/320000]  base_lr: 9.4768e-05 lr: 9.4768e-06  eta: 1 day, 17:05:41  time: 0.4926  data_time: 0.0105  memory: 5892  grad_norm: 242.1646  loss: 10.8431  decode.loss_cls: 0.2913  decode.loss_mask: 0.2656  decode.loss_dice: 0.4126  decode.d0.loss_cls: 1.0611  decode.d0.loss_mask: 0.2536  decode.d0.loss_dice: 0.4637  decode.d1.loss_cls: 0.3800  decode.d1.loss_mask: 0.2463  decode.d1.loss_dice: 0.4329  decode.d2.loss_cls: 0.3248  decode.d2.loss_mask: 0.2682  decode.d2.loss_dice: 0.4313  decode.d3.loss_cls: 0.4284  decode.d3.loss_mask: 0.2529  decode.d3.loss_dice: 0.4170  decode.d4.loss_cls: 0.4503  decode.d4.loss_mask: 0.2521  decode.d4.loss_dice: 0.4043  decode.d5.loss_cls: 0.3634  decode.d5.loss_mask: 0.2574  decode.d5.loss_dice: 0.4069  decode.d6.loss_cls: 0.2685  decode.d6.loss_mask: 0.2572  decode.d6.loss_dice: 0.4117  decode.d7.loss_cls: 0.2336  decode.d7.loss_mask: 0.2598  decode.d7.loss_dice: 0.4453  decode.d8.loss_cls: 0.2553  decode.d8.loss_mask: 0.2607  decode.d8.loss_dice: 0.3866
08/06 04:48:56 - mmengine - INFO - Iter(train) [ 18600/320000]  base_lr: 9.4753e-05 lr: 9.4753e-06  eta: 1 day, 17:05:18  time: 0.4920  data_time: 0.0104  memory: 5908  grad_norm: 143.6478  loss: 8.0966  decode.loss_cls: 0.2495  decode.loss_mask: 0.2439  decode.loss_dice: 0.2826  decode.d0.loss_cls: 0.9748  decode.d0.loss_mask: 0.2459  decode.d0.loss_dice: 0.3037  decode.d1.loss_cls: 0.2599  decode.d1.loss_mask: 0.2387  decode.d1.loss_dice: 0.2781  decode.d2.loss_cls: 0.1988  decode.d2.loss_mask: 0.2355  decode.d2.loss_dice: 0.2869  decode.d3.loss_cls: 0.1126  decode.d3.loss_mask: 0.2514  decode.d3.loss_dice: 0.2801  decode.d4.loss_cls: 0.1683  decode.d4.loss_mask: 0.2355  decode.d4.loss_dice: 0.2682  decode.d5.loss_cls: 0.2260  decode.d5.loss_mask: 0.2435  decode.d5.loss_dice: 0.3008  decode.d6.loss_cls: 0.1692  decode.d6.loss_mask: 0.2405  decode.d6.loss_dice: 0.2670  decode.d7.loss_cls: 0.2374  decode.d7.loss_mask: 0.2465  decode.d7.loss_dice: 0.2793  decode.d8.loss_cls: 0.2188  decode.d8.loss_mask: 0.2528  decode.d8.loss_dice: 0.3003
08/06 04:49:21 - mmengine - INFO - Iter(train) [ 18650/320000]  base_lr: 9.4739e-05 lr: 9.4739e-06  eta: 1 day, 17:04:54  time: 0.4930  data_time: 0.0104  memory: 5890  grad_norm: 161.7654  loss: 8.9910  decode.loss_cls: 0.2501  decode.loss_mask: 0.2286  decode.loss_dice: 0.2800  decode.d0.loss_cls: 1.2019  decode.d0.loss_mask: 0.2408  decode.d0.loss_dice: 0.3099  decode.d1.loss_cls: 0.3445  decode.d1.loss_mask: 0.2358  decode.d1.loss_dice: 0.2908  decode.d2.loss_cls: 0.3068  decode.d2.loss_mask: 0.2350  decode.d2.loss_dice: 0.2907  decode.d3.loss_cls: 0.2097  decode.d3.loss_mask: 0.2357  decode.d3.loss_dice: 0.2894  decode.d4.loss_cls: 0.2644  decode.d4.loss_mask: 0.2403  decode.d4.loss_dice: 0.2845  decode.d5.loss_cls: 0.2711  decode.d5.loss_mask: 0.2375  decode.d5.loss_dice: 0.2959  decode.d6.loss_cls: 0.3334  decode.d6.loss_mask: 0.2397  decode.d6.loss_dice: 0.3048  decode.d7.loss_cls: 0.2371  decode.d7.loss_mask: 0.2358  decode.d7.loss_dice: 0.2902  decode.d8.loss_cls: 0.2880  decode.d8.loss_mask: 0.2347  decode.d8.loss_dice: 0.2839
08/06 04:49:45 - mmengine - INFO - Iter(train) [ 18700/320000]  base_lr: 9.4725e-05 lr: 9.4725e-06  eta: 1 day, 17:04:33  time: 0.4934  data_time: 0.0106  memory: 5927  grad_norm: 154.3106  loss: 8.5644  decode.loss_cls: 0.2211  decode.loss_mask: 0.2288  decode.loss_dice: 0.3091  decode.d0.loss_cls: 1.0644  decode.d0.loss_mask: 0.2434  decode.d0.loss_dice: 0.3441  decode.d1.loss_cls: 0.2365  decode.d1.loss_mask: 0.2253  decode.d1.loss_dice: 0.3036  decode.d2.loss_cls: 0.1784  decode.d2.loss_mask: 0.2409  decode.d2.loss_dice: 0.3258  decode.d3.loss_cls: 0.2031  decode.d3.loss_mask: 0.2230  decode.d3.loss_dice: 0.3165  decode.d4.loss_cls: 0.2151  decode.d4.loss_mask: 0.2207  decode.d4.loss_dice: 0.3199  decode.d5.loss_cls: 0.2038  decode.d5.loss_mask: 0.2319  decode.d5.loss_dice: 0.3261  decode.d6.loss_cls: 0.2639  decode.d6.loss_mask: 0.2123  decode.d6.loss_dice: 0.3097  decode.d7.loss_cls: 0.2334  decode.d7.loss_mask: 0.2333  decode.d7.loss_dice: 0.3433  decode.d8.loss_cls: 0.2298  decode.d8.loss_mask: 0.2354  decode.d8.loss_dice: 0.3218
08/06 04:50:10 - mmengine - INFO - Iter(train) [ 18750/320000]  base_lr: 9.4711e-05 lr: 9.4711e-06  eta: 1 day, 17:04:09  time: 0.4918  data_time: 0.0106  memory: 5892  grad_norm: 215.2680  loss: 9.4126  decode.loss_cls: 0.1759  decode.loss_mask: 0.3429  decode.loss_dice: 0.3276  decode.d0.loss_cls: 1.0690  decode.d0.loss_mask: 0.3730  decode.d0.loss_dice: 0.3624  decode.d1.loss_cls: 0.2658  decode.d1.loss_mask: 0.3385  decode.d1.loss_dice: 0.3266  decode.d2.loss_cls: 0.1836  decode.d2.loss_mask: 0.3320  decode.d2.loss_dice: 0.3259  decode.d3.loss_cls: 0.1882  decode.d3.loss_mask: 0.3288  decode.d3.loss_dice: 0.3402  decode.d4.loss_cls: 0.1170  decode.d4.loss_mask: 0.3464  decode.d4.loss_dice: 0.3168  decode.d5.loss_cls: 0.1126  decode.d5.loss_mask: 0.3512  decode.d5.loss_dice: 0.3224  decode.d6.loss_cls: 0.1817  decode.d6.loss_mask: 0.3306  decode.d6.loss_dice: 0.3103  decode.d7.loss_cls: 0.1872  decode.d7.loss_mask: 0.3520  decode.d7.loss_dice: 0.3354  decode.d8.loss_cls: 0.2004  decode.d8.loss_mask: 0.3293  decode.d8.loss_dice: 0.3392
08/06 04:50:35 - mmengine - INFO - Iter(train) [ 18800/320000]  base_lr: 9.4697e-05 lr: 9.4697e-06  eta: 1 day, 17:03:45  time: 0.4924  data_time: 0.0106  memory: 5907  grad_norm: 190.3800  loss: 8.9985  decode.loss_cls: 0.2305  decode.loss_mask: 0.2550  decode.loss_dice: 0.3324  decode.d0.loss_cls: 0.9557  decode.d0.loss_mask: 0.2698  decode.d0.loss_dice: 0.3578  decode.d1.loss_cls: 0.3567  decode.d1.loss_mask: 0.2514  decode.d1.loss_dice: 0.3128  decode.d2.loss_cls: 0.2207  decode.d2.loss_mask: 0.2494  decode.d2.loss_dice: 0.3098  decode.d3.loss_cls: 0.2013  decode.d3.loss_mask: 0.2521  decode.d3.loss_dice: 0.3150  decode.d4.loss_cls: 0.2301  decode.d4.loss_mask: 0.2469  decode.d4.loss_dice: 0.3179  decode.d5.loss_cls: 0.2032  decode.d5.loss_mask: 0.2567  decode.d5.loss_dice: 0.3295  decode.d6.loss_cls: 0.2064  decode.d6.loss_mask: 0.2571  decode.d6.loss_dice: 0.3350  decode.d7.loss_cls: 0.2443  decode.d7.loss_mask: 0.2571  decode.d7.loss_dice: 0.3346  decode.d8.loss_cls: 0.3087  decode.d8.loss_mask: 0.2705  decode.d8.loss_dice: 0.3299
08/06 04:50:59 - mmengine - INFO - Iter(train) [ 18850/320000]  base_lr: 9.4683e-05 lr: 9.4683e-06  eta: 1 day, 17:03:22  time: 0.4929  data_time: 0.0105  memory: 5890  grad_norm: 155.2269  loss: 7.7727  decode.loss_cls: 0.2093  decode.loss_mask: 0.2158  decode.loss_dice: 0.2823  decode.d0.loss_cls: 1.1163  decode.d0.loss_mask: 0.2275  decode.d0.loss_dice: 0.2788  decode.d1.loss_cls: 0.2380  decode.d1.loss_mask: 0.2292  decode.d1.loss_dice: 0.2853  decode.d2.loss_cls: 0.2014  decode.d2.loss_mask: 0.2147  decode.d2.loss_dice: 0.2740  decode.d3.loss_cls: 0.1577  decode.d3.loss_mask: 0.2314  decode.d3.loss_dice: 0.2735  decode.d4.loss_cls: 0.1724  decode.d4.loss_mask: 0.2153  decode.d4.loss_dice: 0.2726  decode.d5.loss_cls: 0.1774  decode.d5.loss_mask: 0.2093  decode.d5.loss_dice: 0.2687  decode.d6.loss_cls: 0.1482  decode.d6.loss_mask: 0.2197  decode.d6.loss_dice: 0.2963  decode.d7.loss_cls: 0.1656  decode.d7.loss_mask: 0.2135  decode.d7.loss_dice: 0.2938  decode.d8.loss_cls: 0.1633  decode.d8.loss_mask: 0.2275  decode.d8.loss_dice: 0.2939
08/06 04:51:24 - mmengine - INFO - Iter(train) [ 18900/320000]  base_lr: 9.4669e-05 lr: 9.4669e-06  eta: 1 day, 17:02:58  time: 0.4922  data_time: 0.0105  memory: 5966  grad_norm: 162.4197  loss: 10.2515  decode.loss_cls: 0.3688  decode.loss_mask: 0.2172  decode.loss_dice: 0.3452  decode.d0.loss_cls: 0.9858  decode.d0.loss_mask: 0.2281  decode.d0.loss_dice: 0.3785  decode.d1.loss_cls: 0.5167  decode.d1.loss_mask: 0.2258  decode.d1.loss_dice: 0.3193  decode.d2.loss_cls: 0.4071  decode.d2.loss_mask: 0.2195  decode.d2.loss_dice: 0.3506  decode.d3.loss_cls: 0.3314  decode.d3.loss_mask: 0.2179  decode.d3.loss_dice: 0.3328  decode.d4.loss_cls: 0.4066  decode.d4.loss_mask: 0.2205  decode.d4.loss_dice: 0.3504  decode.d5.loss_cls: 0.3725  decode.d5.loss_mask: 0.2184  decode.d5.loss_dice: 0.3331  decode.d6.loss_cls: 0.4086  decode.d6.loss_mask: 0.2165  decode.d6.loss_dice: 0.3488  decode.d7.loss_cls: 0.3729  decode.d7.loss_mask: 0.2201  decode.d7.loss_dice: 0.3538  decode.d8.loss_cls: 0.4023  decode.d8.loss_mask: 0.2237  decode.d8.loss_dice: 0.3588
08/06 04:51:48 - mmengine - INFO - Iter(train) [ 18950/320000]  base_lr: 9.4654e-05 lr: 9.4654e-06  eta: 1 day, 17:02:35  time: 0.4919  data_time: 0.0105  memory: 5907  grad_norm: 233.6244  loss: 9.4856  decode.loss_cls: 0.2844  decode.loss_mask: 0.2742  decode.loss_dice: 0.3109  decode.d0.loss_cls: 0.9626  decode.d0.loss_mask: 0.2710  decode.d0.loss_dice: 0.3062  decode.d1.loss_cls: 0.3090  decode.d1.loss_mask: 0.2894  decode.d1.loss_dice: 0.3477  decode.d2.loss_cls: 0.2781  decode.d2.loss_mask: 0.2656  decode.d2.loss_dice: 0.3161  decode.d3.loss_cls: 0.2872  decode.d3.loss_mask: 0.2605  decode.d3.loss_dice: 0.2849  decode.d4.loss_cls: 0.3415  decode.d4.loss_mask: 0.2607  decode.d4.loss_dice: 0.3062  decode.d5.loss_cls: 0.3109  decode.d5.loss_mask: 0.2730  decode.d5.loss_dice: 0.3087  decode.d6.loss_cls: 0.2961  decode.d6.loss_mask: 0.2720  decode.d6.loss_dice: 0.3136  decode.d7.loss_cls: 0.3149  decode.d7.loss_mask: 0.2682  decode.d7.loss_dice: 0.3256  decode.d8.loss_cls: 0.2262  decode.d8.loss_mask: 0.2788  decode.d8.loss_dice: 0.3413
08/06 04:52:13 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 04:52:13 - mmengine - INFO - Iter(train) [ 19000/320000]  base_lr: 9.4640e-05 lr: 9.4640e-06  eta: 1 day, 17:02:13  time: 0.4912  data_time: 0.0105  memory: 5908  grad_norm: 101.7415  loss: 6.1163  decode.loss_cls: 0.0503  decode.loss_mask: 0.2257  decode.loss_dice: 0.2335  decode.d0.loss_cls: 0.9265  decode.d0.loss_mask: 0.2331  decode.d0.loss_dice: 0.2442  decode.d1.loss_cls: 0.0763  decode.d1.loss_mask: 0.2283  decode.d1.loss_dice: 0.2424  decode.d2.loss_cls: 0.0688  decode.d2.loss_mask: 0.2280  decode.d2.loss_dice: 0.2413  decode.d3.loss_cls: 0.0483  decode.d3.loss_mask: 0.2305  decode.d3.loss_dice: 0.2403  decode.d4.loss_cls: 0.0777  decode.d4.loss_mask: 0.2259  decode.d4.loss_dice: 0.2298  decode.d5.loss_cls: 0.0366  decode.d5.loss_mask: 0.2283  decode.d5.loss_dice: 0.2356  decode.d6.loss_cls: 0.0618  decode.d6.loss_mask: 0.2266  decode.d6.loss_dice: 0.2371  decode.d7.loss_cls: 0.0535  decode.d7.loss_mask: 0.2269  decode.d7.loss_dice: 0.2349  decode.d8.loss_cls: 0.0616  decode.d8.loss_mask: 0.2251  decode.d8.loss_dice: 0.2373
08/06 04:52:38 - mmengine - INFO - Iter(train) [ 19050/320000]  base_lr: 9.4626e-05 lr: 9.4626e-06  eta: 1 day, 17:01:50  time: 0.4917  data_time: 0.0105  memory: 5907  grad_norm: 139.4745  loss: 7.2956  decode.loss_cls: 0.1679  decode.loss_mask: 0.2591  decode.loss_dice: 0.2312  decode.d0.loss_cls: 1.0026  decode.d0.loss_mask: 0.2400  decode.d0.loss_dice: 0.2407  decode.d1.loss_cls: 0.1164  decode.d1.loss_mask: 0.2693  decode.d1.loss_dice: 0.2357  decode.d2.loss_cls: 0.1519  decode.d2.loss_mask: 0.2612  decode.d2.loss_dice: 0.2274  decode.d3.loss_cls: 0.1278  decode.d3.loss_mask: 0.2592  decode.d3.loss_dice: 0.2335  decode.d4.loss_cls: 0.1723  decode.d4.loss_mask: 0.2400  decode.d4.loss_dice: 0.2257  decode.d5.loss_cls: 0.1371  decode.d5.loss_mask: 0.2660  decode.d5.loss_dice: 0.2309  decode.d6.loss_cls: 0.1416  decode.d6.loss_mask: 0.2892  decode.d6.loss_dice: 0.2363  decode.d7.loss_cls: 0.1516  decode.d7.loss_mask: 0.2820  decode.d7.loss_dice: 0.2280  decode.d8.loss_cls: 0.1663  decode.d8.loss_mask: 0.2750  decode.d8.loss_dice: 0.2296
08/06 04:53:02 - mmengine - INFO - Iter(train) [ 19100/320000]  base_lr: 9.4612e-05 lr: 9.4612e-06  eta: 1 day, 17:01:26  time: 0.4933  data_time: 0.0106  memory: 5907  grad_norm: 141.2976  loss: 9.5224  decode.loss_cls: 0.2744  decode.loss_mask: 0.3009  decode.loss_dice: 0.3669  decode.d0.loss_cls: 0.9890  decode.d0.loss_mask: 0.3032  decode.d0.loss_dice: 0.3554  decode.d1.loss_cls: 0.2815  decode.d1.loss_mask: 0.2976  decode.d1.loss_dice: 0.3610  decode.d2.loss_cls: 0.1697  decode.d2.loss_mask: 0.2880  decode.d2.loss_dice: 0.3504  decode.d3.loss_cls: 0.2426  decode.d3.loss_mask: 0.2908  decode.d3.loss_dice: 0.3512  decode.d4.loss_cls: 0.2425  decode.d4.loss_mask: 0.2937  decode.d4.loss_dice: 0.3579  decode.d5.loss_cls: 0.2458  decode.d5.loss_mask: 0.2928  decode.d5.loss_dice: 0.3756  decode.d6.loss_cls: 0.1856  decode.d6.loss_mask: 0.2941  decode.d6.loss_dice: 0.3667  decode.d7.loss_cls: 0.1556  decode.d7.loss_mask: 0.2996  decode.d7.loss_dice: 0.3572  decode.d8.loss_cls: 0.1603  decode.d8.loss_mask: 0.3142  decode.d8.loss_dice: 0.3581
08/06 04:53:27 - mmengine - INFO - Iter(train) [ 19150/320000]  base_lr: 9.4598e-05 lr: 9.4598e-06  eta: 1 day, 17:01:03  time: 0.4911  data_time: 0.0104  memory: 5893  grad_norm: 196.8128  loss: 9.0598  decode.loss_cls: 0.1433  decode.loss_mask: 0.3477  decode.loss_dice: 0.3357  decode.d0.loss_cls: 0.9822  decode.d0.loss_mask: 0.3408  decode.d0.loss_dice: 0.3395  decode.d1.loss_cls: 0.2261  decode.d1.loss_mask: 0.3451  decode.d1.loss_dice: 0.3254  decode.d2.loss_cls: 0.1895  decode.d2.loss_mask: 0.3249  decode.d2.loss_dice: 0.3102  decode.d3.loss_cls: 0.2618  decode.d3.loss_mask: 0.2976  decode.d3.loss_dice: 0.2901  decode.d4.loss_cls: 0.2047  decode.d4.loss_mask: 0.2975  decode.d4.loss_dice: 0.2967  decode.d5.loss_cls: 0.2451  decode.d5.loss_mask: 0.2986  decode.d5.loss_dice: 0.2973  decode.d6.loss_cls: 0.1624  decode.d6.loss_mask: 0.3108  decode.d6.loss_dice: 0.3033  decode.d7.loss_cls: 0.1657  decode.d7.loss_mask: 0.3083  decode.d7.loss_dice: 0.2990  decode.d8.loss_cls: 0.1439  decode.d8.loss_mask: 0.3462  decode.d8.loss_dice: 0.3205
08/06 04:53:51 - mmengine - INFO - Iter(train) [ 19200/320000]  base_lr: 9.4584e-05 lr: 9.4584e-06  eta: 1 day, 17:00:39  time: 0.4919  data_time: 0.0104  memory: 5891  grad_norm: 285.7799  loss: 10.0847  decode.loss_cls: 0.2283  decode.loss_mask: 0.2734  decode.loss_dice: 0.3937  decode.d0.loss_cls: 1.1857  decode.d0.loss_mask: 0.2811  decode.d0.loss_dice: 0.4348  decode.d1.loss_cls: 0.2721  decode.d1.loss_mask: 0.2839  decode.d1.loss_dice: 0.3755  decode.d2.loss_cls: 0.2285  decode.d2.loss_mask: 0.2852  decode.d2.loss_dice: 0.3717  decode.d3.loss_cls: 0.2975  decode.d3.loss_mask: 0.2784  decode.d3.loss_dice: 0.3762  decode.d4.loss_cls: 0.2764  decode.d4.loss_mask: 0.2774  decode.d4.loss_dice: 0.3761  decode.d5.loss_cls: 0.2329  decode.d5.loss_mask: 0.2746  decode.d5.loss_dice: 0.3732  decode.d6.loss_cls: 0.2993  decode.d6.loss_mask: 0.2700  decode.d6.loss_dice: 0.3776  decode.d7.loss_cls: 0.2207  decode.d7.loss_mask: 0.2706  decode.d7.loss_dice: 0.4060  decode.d8.loss_cls: 0.2049  decode.d8.loss_mask: 0.2714  decode.d8.loss_dice: 0.3877
08/06 04:54:16 - mmengine - INFO - Iter(train) [ 19250/320000]  base_lr: 9.4570e-05 lr: 9.4570e-06  eta: 1 day, 17:00:15  time: 0.4909  data_time: 0.0103  memory: 5889  grad_norm: 154.0673  loss: 6.9899  decode.loss_cls: 0.1060  decode.loss_mask: 0.2535  decode.loss_dice: 0.2720  decode.d0.loss_cls: 0.8750  decode.d0.loss_mask: 0.2598  decode.d0.loss_dice: 0.2912  decode.d1.loss_cls: 0.0978  decode.d1.loss_mask: 0.2529  decode.d1.loss_dice: 0.2783  decode.d2.loss_cls: 0.0964  decode.d2.loss_mask: 0.2439  decode.d2.loss_dice: 0.2680  decode.d3.loss_cls: 0.0841  decode.d3.loss_mask: 0.2429  decode.d3.loss_dice: 0.2658  decode.d4.loss_cls: 0.0893  decode.d4.loss_mask: 0.2440  decode.d4.loss_dice: 0.2749  decode.d5.loss_cls: 0.1051  decode.d5.loss_mask: 0.2471  decode.d5.loss_dice: 0.2705  decode.d6.loss_cls: 0.1041  decode.d6.loss_mask: 0.2499  decode.d6.loss_dice: 0.2700  decode.d7.loss_cls: 0.0965  decode.d7.loss_mask: 0.2521  decode.d7.loss_dice: 0.2683  decode.d8.loss_cls: 0.1082  decode.d8.loss_mask: 0.2527  decode.d8.loss_dice: 0.2694
08/06 04:54:41 - mmengine - INFO - Iter(train) [ 19300/320000]  base_lr: 9.4555e-05 lr: 9.4555e-06  eta: 1 day, 16:59:52  time: 0.4915  data_time: 0.0102  memory: 5926  grad_norm: 96.4350  loss: 6.7757  decode.loss_cls: 0.0599  decode.loss_mask: 0.2936  decode.loss_dice: 0.2394  decode.d0.loss_cls: 0.8601  decode.d0.loss_mask: 0.3037  decode.d0.loss_dice: 0.2441  decode.d1.loss_cls: 0.0826  decode.d1.loss_mask: 0.3067  decode.d1.loss_dice: 0.2452  decode.d2.loss_cls: 0.0462  decode.d2.loss_mask: 0.3004  decode.d2.loss_dice: 0.2354  decode.d3.loss_cls: 0.0712  decode.d3.loss_mask: 0.2985  decode.d3.loss_dice: 0.2357  decode.d4.loss_cls: 0.0567  decode.d4.loss_mask: 0.2957  decode.d4.loss_dice: 0.2416  decode.d5.loss_cls: 0.0565  decode.d5.loss_mask: 0.2932  decode.d5.loss_dice: 0.2379  decode.d6.loss_cls: 0.0459  decode.d6.loss_mask: 0.2961  decode.d6.loss_dice: 0.2417  decode.d7.loss_cls: 0.0645  decode.d7.loss_mask: 0.2942  decode.d7.loss_dice: 0.2348  decode.d8.loss_cls: 0.0567  decode.d8.loss_mask: 0.2990  decode.d8.loss_dice: 0.2384
08/06 04:55:05 - mmengine - INFO - Iter(train) [ 19350/320000]  base_lr: 9.4541e-05 lr: 9.4541e-06  eta: 1 day, 16:59:28  time: 0.4930  data_time: 0.0106  memory: 5892  grad_norm: 206.7435  loss: 10.4233  decode.loss_cls: 0.2553  decode.loss_mask: 0.3123  decode.loss_dice: 0.3450  decode.d0.loss_cls: 1.1182  decode.d0.loss_mask: 0.3092  decode.d0.loss_dice: 0.3336  decode.d1.loss_cls: 0.3135  decode.d1.loss_mask: 0.3245  decode.d1.loss_dice: 0.3213  decode.d2.loss_cls: 0.2917  decode.d2.loss_mask: 0.3191  decode.d2.loss_dice: 0.3494  decode.d3.loss_cls: 0.2605  decode.d3.loss_mask: 0.3114  decode.d3.loss_dice: 0.3404  decode.d4.loss_cls: 0.3246  decode.d4.loss_mask: 0.3110  decode.d4.loss_dice: 0.3615  decode.d5.loss_cls: 0.3099  decode.d5.loss_mask: 0.3160  decode.d5.loss_dice: 0.3380  decode.d6.loss_cls: 0.3537  decode.d6.loss_mask: 0.3069  decode.d6.loss_dice: 0.3358  decode.d7.loss_cls: 0.3323  decode.d7.loss_mask: 0.3084  decode.d7.loss_dice: 0.3377  decode.d8.loss_cls: 0.3334  decode.d8.loss_mask: 0.3126  decode.d8.loss_dice: 0.3359
08/06 04:55:30 - mmengine - INFO - Iter(train) [ 19400/320000]  base_lr: 9.4527e-05 lr: 9.4527e-06  eta: 1 day, 16:59:04  time: 0.4921  data_time: 0.0106  memory: 5964  grad_norm: 111.8025  loss: 7.8333  decode.loss_cls: 0.1362  decode.loss_mask: 0.2271  decode.loss_dice: 0.2797  decode.d0.loss_cls: 0.9774  decode.d0.loss_mask: 0.2363  decode.d0.loss_dice: 0.2831  decode.d1.loss_cls: 0.3287  decode.d1.loss_mask: 0.2334  decode.d1.loss_dice: 0.2767  decode.d2.loss_cls: 0.2513  decode.d2.loss_mask: 0.2273  decode.d2.loss_dice: 0.2650  decode.d3.loss_cls: 0.2317  decode.d3.loss_mask: 0.2320  decode.d3.loss_dice: 0.2615  decode.d4.loss_cls: 0.1976  decode.d4.loss_mask: 0.2281  decode.d4.loss_dice: 0.2679  decode.d5.loss_cls: 0.1315  decode.d5.loss_mask: 0.2312  decode.d5.loss_dice: 0.2967  decode.d6.loss_cls: 0.1334  decode.d6.loss_mask: 0.2307  decode.d6.loss_dice: 0.2755  decode.d7.loss_cls: 0.2033  decode.d7.loss_mask: 0.2284  decode.d7.loss_dice: 0.2612  decode.d8.loss_cls: 0.1969  decode.d8.loss_mask: 0.2288  decode.d8.loss_dice: 0.2746
08/06 04:55:55 - mmengine - INFO - Iter(train) [ 19450/320000]  base_lr: 9.4513e-05 lr: 9.4513e-06  eta: 1 day, 16:58:41  time: 0.4934  data_time: 0.0107  memory: 5907  grad_norm: 211.7574  loss: 8.6630  decode.loss_cls: 0.2173  decode.loss_mask: 0.2505  decode.loss_dice: 0.3169  decode.d0.loss_cls: 0.8653  decode.d0.loss_mask: 0.2518  decode.d0.loss_dice: 0.3254  decode.d1.loss_cls: 0.3112  decode.d1.loss_mask: 0.2440  decode.d1.loss_dice: 0.3056  decode.d2.loss_cls: 0.2770  decode.d2.loss_mask: 0.2522  decode.d2.loss_dice: 0.2935  decode.d3.loss_cls: 0.2489  decode.d3.loss_mask: 0.2488  decode.d3.loss_dice: 0.3001  decode.d4.loss_cls: 0.2701  decode.d4.loss_mask: 0.2429  decode.d4.loss_dice: 0.2956  decode.d5.loss_cls: 0.2732  decode.d5.loss_mask: 0.2489  decode.d5.loss_dice: 0.2952  decode.d6.loss_cls: 0.2490  decode.d6.loss_mask: 0.2478  decode.d6.loss_dice: 0.2903  decode.d7.loss_cls: 0.2502  decode.d7.loss_mask: 0.2497  decode.d7.loss_dice: 0.2920  decode.d8.loss_cls: 0.2161  decode.d8.loss_mask: 0.2479  decode.d8.loss_dice: 0.2856
08/06 04:56:19 - mmengine - INFO - Iter(train) [ 19500/320000]  base_lr: 9.4499e-05 lr: 9.4499e-06  eta: 1 day, 16:58:18  time: 0.4923  data_time: 0.0103  memory: 5876  grad_norm: 89.4491  loss: 7.8351  decode.loss_cls: 0.1546  decode.loss_mask: 0.2437  decode.loss_dice: 0.3109  decode.d0.loss_cls: 0.8729  decode.d0.loss_mask: 0.2528  decode.d0.loss_dice: 0.3213  decode.d1.loss_cls: 0.2052  decode.d1.loss_mask: 0.2399  decode.d1.loss_dice: 0.2925  decode.d2.loss_cls: 0.1830  decode.d2.loss_mask: 0.2411  decode.d2.loss_dice: 0.2883  decode.d3.loss_cls: 0.1564  decode.d3.loss_mask: 0.2531  decode.d3.loss_dice: 0.2851  decode.d4.loss_cls: 0.1687  decode.d4.loss_mask: 0.2472  decode.d4.loss_dice: 0.2857  decode.d5.loss_cls: 0.1518  decode.d5.loss_mask: 0.2421  decode.d5.loss_dice: 0.2851  decode.d6.loss_cls: 0.1635  decode.d6.loss_mask: 0.2434  decode.d6.loss_dice: 0.2911  decode.d7.loss_cls: 0.2033  decode.d7.loss_mask: 0.2432  decode.d7.loss_dice: 0.2913  decode.d8.loss_cls: 0.1725  decode.d8.loss_mask: 0.2468  decode.d8.loss_dice: 0.2985
08/06 04:56:44 - mmengine - INFO - Iter(train) [ 19550/320000]  base_lr: 9.4485e-05 lr: 9.4485e-06  eta: 1 day, 16:57:54  time: 0.4920  data_time: 0.0104  memory: 5892  grad_norm: 188.5575  loss: 8.1058  decode.loss_cls: 0.1976  decode.loss_mask: 0.2511  decode.loss_dice: 0.2945  decode.d0.loss_cls: 0.8979  decode.d0.loss_mask: 0.2625  decode.d0.loss_dice: 0.3105  decode.d1.loss_cls: 0.2157  decode.d1.loss_mask: 0.2482  decode.d1.loss_dice: 0.2891  decode.d2.loss_cls: 0.1902  decode.d2.loss_mask: 0.2497  decode.d2.loss_dice: 0.3096  decode.d3.loss_cls: 0.1936  decode.d3.loss_mask: 0.2535  decode.d3.loss_dice: 0.3091  decode.d4.loss_cls: 0.1584  decode.d4.loss_mask: 0.2446  decode.d4.loss_dice: 0.2876  decode.d5.loss_cls: 0.1838  decode.d5.loss_mask: 0.2446  decode.d5.loss_dice: 0.3047  decode.d6.loss_cls: 0.1906  decode.d6.loss_mask: 0.2471  decode.d6.loss_dice: 0.2891  decode.d7.loss_cls: 0.1943  decode.d7.loss_mask: 0.2505  decode.d7.loss_dice: 0.3046  decode.d8.loss_cls: 0.1899  decode.d8.loss_mask: 0.2500  decode.d8.loss_dice: 0.2932
08/06 04:57:08 - mmengine - INFO - Iter(train) [ 19600/320000]  base_lr: 9.4470e-05 lr: 9.4470e-06  eta: 1 day, 16:57:32  time: 0.4921  data_time: 0.0106  memory: 5891  grad_norm: 134.8176  loss: 7.3278  decode.loss_cls: 0.1033  decode.loss_mask: 0.2699  decode.loss_dice: 0.2485  decode.d0.loss_cls: 0.8280  decode.d0.loss_mask: 0.2695  decode.d0.loss_dice: 0.2822  decode.d1.loss_cls: 0.1385  decode.d1.loss_mask: 0.2849  decode.d1.loss_dice: 0.3104  decode.d2.loss_cls: 0.1193  decode.d2.loss_mask: 0.2718  decode.d2.loss_dice: 0.2990  decode.d3.loss_cls: 0.0928  decode.d3.loss_mask: 0.2713  decode.d3.loss_dice: 0.2728  decode.d4.loss_cls: 0.1005  decode.d4.loss_mask: 0.2697  decode.d4.loss_dice: 0.2514  decode.d5.loss_cls: 0.1045  decode.d5.loss_mask: 0.2681  decode.d5.loss_dice: 0.2848  decode.d6.loss_cls: 0.1156  decode.d6.loss_mask: 0.2689  decode.d6.loss_dice: 0.2829  decode.d7.loss_cls: 0.0895  decode.d7.loss_mask: 0.2724  decode.d7.loss_dice: 0.2834  decode.d8.loss_cls: 0.1236  decode.d8.loss_mask: 0.2707  decode.d8.loss_dice: 0.2793
08/06 04:57:33 - mmengine - INFO - Iter(train) [ 19650/320000]  base_lr: 9.4456e-05 lr: 9.4456e-06  eta: 1 day, 16:57:09  time: 0.4933  data_time: 0.0105  memory: 5892  grad_norm: 82.1160  loss: 9.0625  decode.loss_cls: 0.1469  decode.loss_mask: 0.2686  decode.loss_dice: 0.3510  decode.d0.loss_cls: 1.0383  decode.d0.loss_mask: 0.2777  decode.d0.loss_dice: 0.3735  decode.d1.loss_cls: 0.3299  decode.d1.loss_mask: 0.2717  decode.d1.loss_dice: 0.3585  decode.d2.loss_cls: 0.1573  decode.d2.loss_mask: 0.2713  decode.d2.loss_dice: 0.3656  decode.d3.loss_cls: 0.2380  decode.d3.loss_mask: 0.2666  decode.d3.loss_dice: 0.3476  decode.d4.loss_cls: 0.2104  decode.d4.loss_mask: 0.2661  decode.d4.loss_dice: 0.3489  decode.d5.loss_cls: 0.1878  decode.d5.loss_mask: 0.2674  decode.d5.loss_dice: 0.3585  decode.d6.loss_cls: 0.1881  decode.d6.loss_mask: 0.2644  decode.d6.loss_dice: 0.3394  decode.d7.loss_cls: 0.1946  decode.d7.loss_mask: 0.2628  decode.d7.loss_dice: 0.3325  decode.d8.loss_cls: 0.1548  decode.d8.loss_mask: 0.2659  decode.d8.loss_dice: 0.3584
08/06 04:57:58 - mmengine - INFO - Iter(train) [ 19700/320000]  base_lr: 9.4442e-05 lr: 9.4442e-06  eta: 1 day, 16:56:46  time: 0.4925  data_time: 0.0107  memory: 5893  grad_norm: 287.9245  loss: 9.4301  decode.loss_cls: 0.2064  decode.loss_mask: 0.3210  decode.loss_dice: 0.3099  decode.d0.loss_cls: 0.8811  decode.d0.loss_mask: 0.3427  decode.d0.loss_dice: 0.3405  decode.d1.loss_cls: 0.2753  decode.d1.loss_mask: 0.3347  decode.d1.loss_dice: 0.3439  decode.d2.loss_cls: 0.1979  decode.d2.loss_mask: 0.3225  decode.d2.loss_dice: 0.3459  decode.d3.loss_cls: 0.1812  decode.d3.loss_mask: 0.3235  decode.d3.loss_dice: 0.3121  decode.d4.loss_cls: 0.1883  decode.d4.loss_mask: 0.3206  decode.d4.loss_dice: 0.3119  decode.d5.loss_cls: 0.1798  decode.d5.loss_mask: 0.3267  decode.d5.loss_dice: 0.3362  decode.d6.loss_cls: 0.1946  decode.d6.loss_mask: 0.3548  decode.d6.loss_dice: 0.3477  decode.d7.loss_cls: 0.1413  decode.d7.loss_mask: 0.4285  decode.d7.loss_dice: 0.3439  decode.d8.loss_cls: 0.2059  decode.d8.loss_mask: 0.3848  decode.d8.loss_dice: 0.3264
08/06 04:58:22 - mmengine - INFO - Iter(train) [ 19750/320000]  base_lr: 9.4428e-05 lr: 9.4428e-06  eta: 1 day, 16:56:23  time: 0.4925  data_time: 0.0105  memory: 5908  grad_norm: 158.9790  loss: 9.1209  decode.loss_cls: 0.3218  decode.loss_mask: 0.2003  decode.loss_dice: 0.3094  decode.d0.loss_cls: 1.0362  decode.d0.loss_mask: 0.2042  decode.d0.loss_dice: 0.2992  decode.d1.loss_cls: 0.4195  decode.d1.loss_mask: 0.1981  decode.d1.loss_dice: 0.2981  decode.d2.loss_cls: 0.2927  decode.d2.loss_mask: 0.1978  decode.d2.loss_dice: 0.3236  decode.d3.loss_cls: 0.2981  decode.d3.loss_mask: 0.2020  decode.d3.loss_dice: 0.2796  decode.d4.loss_cls: 0.3178  decode.d4.loss_mask: 0.1968  decode.d4.loss_dice: 0.2927  decode.d5.loss_cls: 0.3130  decode.d5.loss_mask: 0.2038  decode.d5.loss_dice: 0.3205  decode.d6.loss_cls: 0.3715  decode.d6.loss_mask: 0.1998  decode.d6.loss_dice: 0.3096  decode.d7.loss_cls: 0.3811  decode.d7.loss_mask: 0.1983  decode.d7.loss_dice: 0.2955  decode.d8.loss_cls: 0.3524  decode.d8.loss_mask: 0.2001  decode.d8.loss_dice: 0.2872
08/06 04:58:47 - mmengine - INFO - Iter(train) [ 19800/320000]  base_lr: 9.4414e-05 lr: 9.4414e-06  eta: 1 day, 16:55:59  time: 0.4923  data_time: 0.0105  memory: 5908  grad_norm: 160.9241  loss: 10.8780  decode.loss_cls: 0.1902  decode.loss_mask: 0.4456  decode.loss_dice: 0.3689  decode.d0.loss_cls: 1.0063  decode.d0.loss_mask: 0.4498  decode.d0.loss_dice: 0.3874  decode.d1.loss_cls: 0.2053  decode.d1.loss_mask: 0.4576  decode.d1.loss_dice: 0.3693  decode.d2.loss_cls: 0.1977  decode.d2.loss_mask: 0.4510  decode.d2.loss_dice: 0.3656  decode.d3.loss_cls: 0.1542  decode.d3.loss_mask: 0.4484  decode.d3.loss_dice: 0.3584  decode.d4.loss_cls: 0.2154  decode.d4.loss_mask: 0.4501  decode.d4.loss_dice: 0.3742  decode.d5.loss_cls: 0.1415  decode.d5.loss_mask: 0.4706  decode.d5.loss_dice: 0.4005  decode.d6.loss_cls: 0.2133  decode.d6.loss_mask: 0.4510  decode.d6.loss_dice: 0.3548  decode.d7.loss_cls: 0.1749  decode.d7.loss_mask: 0.4561  decode.d7.loss_dice: 0.3600  decode.d8.loss_cls: 0.1395  decode.d8.loss_mask: 0.4417  decode.d8.loss_dice: 0.3789
08/06 04:59:12 - mmengine - INFO - Iter(train) [ 19850/320000]  base_lr: 9.4400e-05 lr: 9.4400e-06  eta: 1 day, 16:55:36  time: 0.4925  data_time: 0.0108  memory: 5907  grad_norm: 96.0303  loss: 8.4905  decode.loss_cls: 0.1577  decode.loss_mask: 0.3094  decode.loss_dice: 0.2814  decode.d0.loss_cls: 0.9889  decode.d0.loss_mask: 0.3124  decode.d0.loss_dice: 0.3087  decode.d1.loss_cls: 0.1491  decode.d1.loss_mask: 0.3104  decode.d1.loss_dice: 0.3095  decode.d2.loss_cls: 0.1367  decode.d2.loss_mask: 0.3084  decode.d2.loss_dice: 0.3048  decode.d3.loss_cls: 0.1850  decode.d3.loss_mask: 0.3077  decode.d3.loss_dice: 0.2904  decode.d4.loss_cls: 0.1698  decode.d4.loss_mask: 0.3041  decode.d4.loss_dice: 0.2869  decode.d5.loss_cls: 0.1533  decode.d5.loss_mask: 0.3037  decode.d5.loss_dice: 0.2888  decode.d6.loss_cls: 0.1761  decode.d6.loss_mask: 0.3067  decode.d6.loss_dice: 0.2914  decode.d7.loss_cls: 0.1726  decode.d7.loss_mask: 0.3122  decode.d7.loss_dice: 0.2981  decode.d8.loss_cls: 0.1635  decode.d8.loss_mask: 0.3110  decode.d8.loss_dice: 0.2918
08/06 04:59:36 - mmengine - INFO - Iter(train) [ 19900/320000]  base_lr: 9.4386e-05 lr: 9.4386e-06  eta: 1 day, 16:55:13  time: 0.4928  data_time: 0.0106  memory: 5875  grad_norm: 112.0176  loss: 6.2712  decode.loss_cls: 0.1228  decode.loss_mask: 0.1925  decode.loss_dice: 0.2270  decode.d0.loss_cls: 0.9369  decode.d0.loss_mask: 0.1979  decode.d0.loss_dice: 0.2532  decode.d1.loss_cls: 0.1005  decode.d1.loss_mask: 0.1949  decode.d1.loss_dice: 0.2372  decode.d2.loss_cls: 0.1154  decode.d2.loss_mask: 0.1914  decode.d2.loss_dice: 0.2434  decode.d3.loss_cls: 0.1095  decode.d3.loss_mask: 0.1915  decode.d3.loss_dice: 0.2308  decode.d4.loss_cls: 0.1321  decode.d4.loss_mask: 0.1907  decode.d4.loss_dice: 0.2345  decode.d5.loss_cls: 0.1149  decode.d5.loss_mask: 0.1917  decode.d5.loss_dice: 0.2308  decode.d6.loss_cls: 0.1157  decode.d6.loss_mask: 0.1911  decode.d6.loss_dice: 0.2271  decode.d7.loss_cls: 0.1304  decode.d7.loss_mask: 0.1908  decode.d7.loss_dice: 0.2301  decode.d8.loss_cls: 0.1180  decode.d8.loss_mask: 0.1920  decode.d8.loss_dice: 0.2363
08/06 05:00:01 - mmengine - INFO - Iter(train) [ 19950/320000]  base_lr: 9.4371e-05 lr: 9.4371e-06  eta: 1 day, 16:54:49  time: 0.4926  data_time: 0.0104  memory: 5891  grad_norm: 213.4878  loss: 8.0889  decode.loss_cls: 0.1021  decode.loss_mask: 0.3050  decode.loss_dice: 0.3252  decode.d0.loss_cls: 0.8560  decode.d0.loss_mask: 0.3237  decode.d0.loss_dice: 0.3440  decode.d1.loss_cls: 0.2166  decode.d1.loss_mask: 0.3093  decode.d1.loss_dice: 0.3338  decode.d2.loss_cls: 0.0887  decode.d2.loss_mask: 0.3041  decode.d2.loss_dice: 0.3384  decode.d3.loss_cls: 0.0529  decode.d3.loss_mask: 0.3125  decode.d3.loss_dice: 0.3342  decode.d4.loss_cls: 0.0730  decode.d4.loss_mask: 0.3022  decode.d4.loss_dice: 0.3306  decode.d5.loss_cls: 0.0740  decode.d5.loss_mask: 0.2964  decode.d5.loss_dice: 0.3188  decode.d6.loss_cls: 0.0647  decode.d6.loss_mask: 0.2988  decode.d6.loss_dice: 0.3289  decode.d7.loss_cls: 0.1174  decode.d7.loss_mask: 0.3036  decode.d7.loss_dice: 0.3267  decode.d8.loss_cls: 0.0837  decode.d8.loss_mask: 0.2999  decode.d8.loss_dice: 0.3240
08/06 05:00:26 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 05:00:26 - mmengine - INFO - Iter(train) [ 20000/320000]  base_lr: 9.4357e-05 lr: 9.4357e-06  eta: 1 day, 16:54:26  time: 0.4923  data_time: 0.0107  memory: 5927  grad_norm: 143.4362  loss: 6.4767  decode.loss_cls: 0.1411  decode.loss_mask: 0.2026  decode.loss_dice: 0.2403  decode.d0.loss_cls: 0.9453  decode.d0.loss_mask: 0.2029  decode.d0.loss_dice: 0.2293  decode.d1.loss_cls: 0.2751  decode.d1.loss_mask: 0.2026  decode.d1.loss_dice: 0.2390  decode.d2.loss_cls: 0.1302  decode.d2.loss_mask: 0.2021  decode.d2.loss_dice: 0.2345  decode.d3.loss_cls: 0.0954  decode.d3.loss_mask: 0.2036  decode.d3.loss_dice: 0.2471  decode.d4.loss_cls: 0.0874  decode.d4.loss_mask: 0.2050  decode.d4.loss_dice: 0.2402  decode.d5.loss_cls: 0.0776  decode.d5.loss_mask: 0.2056  decode.d5.loss_dice: 0.2400  decode.d6.loss_cls: 0.0696  decode.d6.loss_mask: 0.2040  decode.d6.loss_dice: 0.2504  decode.d7.loss_cls: 0.0805  decode.d7.loss_mask: 0.2054  decode.d7.loss_dice: 0.2480  decode.d8.loss_cls: 0.1308  decode.d8.loss_mask: 0.2010  decode.d8.loss_dice: 0.2400
08/06 05:00:50 - mmengine - INFO - Iter(train) [ 20050/320000]  base_lr: 9.4343e-05 lr: 9.4343e-06  eta: 1 day, 16:54:02  time: 0.4927  data_time: 0.0105  memory: 5891  grad_norm: 164.9769  loss: 8.1963  decode.loss_cls: 0.0588  decode.loss_mask: 0.3075  decode.loss_dice: 0.3427  decode.d0.loss_cls: 0.9483  decode.d0.loss_mask: 0.3257  decode.d0.loss_dice: 0.3938  decode.d1.loss_cls: 0.1161  decode.d1.loss_mask: 0.3252  decode.d1.loss_dice: 0.3562  decode.d2.loss_cls: 0.0659  decode.d2.loss_mask: 0.3160  decode.d2.loss_dice: 0.3299  decode.d3.loss_cls: 0.1171  decode.d3.loss_mask: 0.3122  decode.d3.loss_dice: 0.3289  decode.d4.loss_cls: 0.0844  decode.d4.loss_mask: 0.3122  decode.d4.loss_dice: 0.3367  decode.d5.loss_cls: 0.0734  decode.d5.loss_mask: 0.3108  decode.d5.loss_dice: 0.3546  decode.d6.loss_cls: 0.0414  decode.d6.loss_mask: 0.3068  decode.d6.loss_dice: 0.3259  decode.d7.loss_cls: 0.0588  decode.d7.loss_mask: 0.3144  decode.d7.loss_dice: 0.3409  decode.d8.loss_cls: 0.0505  decode.d8.loss_mask: 0.3076  decode.d8.loss_dice: 0.3337
08/06 05:01:15 - mmengine - INFO - Iter(train) [ 20100/320000]  base_lr: 9.4329e-05 lr: 9.4329e-06  eta: 1 day, 16:53:40  time: 0.4928  data_time: 0.0105  memory: 5893  grad_norm: 99.9220  loss: 6.8601  decode.loss_cls: 0.1693  decode.loss_mask: 0.2028  decode.loss_dice: 0.2567  decode.d0.loss_cls: 0.9681  decode.d0.loss_mask: 0.2075  decode.d0.loss_dice: 0.2472  decode.d1.loss_cls: 0.2485  decode.d1.loss_mask: 0.2048  decode.d1.loss_dice: 0.2344  decode.d2.loss_cls: 0.1845  decode.d2.loss_mask: 0.2024  decode.d2.loss_dice: 0.2455  decode.d3.loss_cls: 0.1468  decode.d3.loss_mask: 0.1996  decode.d3.loss_dice: 0.2255  decode.d4.loss_cls: 0.1377  decode.d4.loss_mask: 0.2015  decode.d4.loss_dice: 0.2434  decode.d5.loss_cls: 0.1427  decode.d5.loss_mask: 0.2007  decode.d5.loss_dice: 0.2252  decode.d6.loss_cls: 0.1314  decode.d6.loss_mask: 0.2024  decode.d6.loss_dice: 0.2296  decode.d7.loss_cls: 0.1414  decode.d7.loss_mask: 0.2031  decode.d7.loss_dice: 0.2485  decode.d8.loss_cls: 0.1638  decode.d8.loss_mask: 0.2058  decode.d8.loss_dice: 0.2395
08/06 05:01:39 - mmengine - INFO - Iter(train) [ 20150/320000]  base_lr: 9.4315e-05 lr: 9.4315e-06  eta: 1 day, 16:53:17  time: 0.4916  data_time: 0.0104  memory: 5908  grad_norm: 114.6615  loss: 6.2984  decode.loss_cls: 0.0331  decode.loss_mask: 0.2292  decode.loss_dice: 0.2654  decode.d0.loss_cls: 0.8823  decode.d0.loss_mask: 0.2405  decode.d0.loss_dice: 0.2922  decode.d1.loss_cls: 0.1142  decode.d1.loss_mask: 0.2227  decode.d1.loss_dice: 0.2595  decode.d2.loss_cls: 0.0693  decode.d2.loss_mask: 0.2282  decode.d2.loss_dice: 0.2630  decode.d3.loss_cls: 0.0422  decode.d3.loss_mask: 0.2326  decode.d3.loss_dice: 0.2654  decode.d4.loss_cls: 0.0381  decode.d4.loss_mask: 0.2332  decode.d4.loss_dice: 0.2611  decode.d5.loss_cls: 0.0357  decode.d5.loss_mask: 0.2290  decode.d5.loss_dice: 0.2583  decode.d6.loss_cls: 0.0433  decode.d6.loss_mask: 0.2347  decode.d6.loss_dice: 0.2616  decode.d7.loss_cls: 0.0472  decode.d7.loss_mask: 0.2283  decode.d7.loss_dice: 0.2622  decode.d8.loss_cls: 0.0414  decode.d8.loss_mask: 0.2284  decode.d8.loss_dice: 0.2562
08/06 05:02:04 - mmengine - INFO - Iter(train) [ 20200/320000]  base_lr: 9.4301e-05 lr: 9.4301e-06  eta: 1 day, 16:52:54  time: 0.4934  data_time: 0.0106  memory: 5909  grad_norm: 78.5380  loss: 7.0114  decode.loss_cls: 0.1473  decode.loss_mask: 0.2176  decode.loss_dice: 0.2255  decode.d0.loss_cls: 1.1430  decode.d0.loss_mask: 0.2305  decode.d0.loss_dice: 0.2547  decode.d1.loss_cls: 0.2015  decode.d1.loss_mask: 0.2223  decode.d1.loss_dice: 0.2487  decode.d2.loss_cls: 0.1582  decode.d2.loss_mask: 0.2217  decode.d2.loss_dice: 0.2288  decode.d3.loss_cls: 0.1256  decode.d3.loss_mask: 0.2178  decode.d3.loss_dice: 0.2362  decode.d4.loss_cls: 0.1694  decode.d4.loss_mask: 0.2182  decode.d4.loss_dice: 0.2374  decode.d5.loss_cls: 0.1362  decode.d5.loss_mask: 0.2191  decode.d5.loss_dice: 0.2302  decode.d6.loss_cls: 0.1276  decode.d6.loss_mask: 0.2171  decode.d6.loss_dice: 0.2268  decode.d7.loss_cls: 0.1096  decode.d7.loss_mask: 0.2241  decode.d7.loss_dice: 0.2400  decode.d8.loss_cls: 0.1147  decode.d8.loss_mask: 0.2234  decode.d8.loss_dice: 0.2381
08/06 05:02:29 - mmengine - INFO - Iter(train) [ 20250/320000]  base_lr: 9.4286e-05 lr: 9.4286e-06  eta: 1 day, 16:52:30  time: 0.4924  data_time: 0.0106  memory: 5874  grad_norm: 152.7836  loss: 9.7183  decode.loss_cls: 0.2301  decode.loss_mask: 0.3232  decode.loss_dice: 0.3200  decode.d0.loss_cls: 0.9078  decode.d0.loss_mask: 0.3285  decode.d0.loss_dice: 0.3674  decode.d1.loss_cls: 0.2553  decode.d1.loss_mask: 0.3268  decode.d1.loss_dice: 0.3550  decode.d2.loss_cls: 0.2585  decode.d2.loss_mask: 0.3240  decode.d2.loss_dice: 0.3335  decode.d3.loss_cls: 0.2375  decode.d3.loss_mask: 0.3200  decode.d3.loss_dice: 0.3111  decode.d4.loss_cls: 0.2156  decode.d4.loss_mask: 0.3204  decode.d4.loss_dice: 0.3226  decode.d5.loss_cls: 0.2478  decode.d5.loss_mask: 0.3193  decode.d5.loss_dice: 0.3307  decode.d6.loss_cls: 0.2737  decode.d6.loss_mask: 0.3179  decode.d6.loss_dice: 0.3264  decode.d7.loss_cls: 0.2798  decode.d7.loss_mask: 0.3180  decode.d7.loss_dice: 0.3232  decode.d8.loss_cls: 0.2490  decode.d8.loss_mask: 0.3199  decode.d8.loss_dice: 0.3552
08/06 05:02:53 - mmengine - INFO - Iter(train) [ 20300/320000]  base_lr: 9.4272e-05 lr: 9.4272e-06  eta: 1 day, 16:52:06  time: 0.4923  data_time: 0.0104  memory: 5889  grad_norm: 312.8134  loss: 8.4266  decode.loss_cls: 0.2496  decode.loss_mask: 0.2060  decode.loss_dice: 0.2735  decode.d0.loss_cls: 0.9365  decode.d0.loss_mask: 0.2007  decode.d0.loss_dice: 0.3176  decode.d1.loss_cls: 0.2420  decode.d1.loss_mask: 0.2200  decode.d1.loss_dice: 0.3041  decode.d2.loss_cls: 0.2857  decode.d2.loss_mask: 0.2258  decode.d2.loss_dice: 0.3035  decode.d3.loss_cls: 0.2250  decode.d3.loss_mask: 0.2362  decode.d3.loss_dice: 0.2948  decode.d4.loss_cls: 0.2533  decode.d4.loss_mask: 0.2161  decode.d4.loss_dice: 0.2940  decode.d5.loss_cls: 0.3217  decode.d5.loss_mask: 0.2163  decode.d5.loss_dice: 0.2934  decode.d6.loss_cls: 0.2088  decode.d6.loss_mask: 0.2522  decode.d6.loss_dice: 0.2988  decode.d7.loss_cls: 0.2178  decode.d7.loss_mask: 0.2544  decode.d7.loss_dice: 0.3056  decode.d8.loss_cls: 0.2577  decode.d8.loss_mask: 0.2269  decode.d8.loss_dice: 0.2888
08/06 05:03:18 - mmengine - INFO - Iter(train) [ 20350/320000]  base_lr: 9.4258e-05 lr: 9.4258e-06  eta: 1 day, 16:51:43  time: 0.4922  data_time: 0.0103  memory: 5907  grad_norm: 140.8113  loss: 10.6523  decode.loss_cls: 0.2790  decode.loss_mask: 0.2797  decode.loss_dice: 0.3766  decode.d0.loss_cls: 0.9187  decode.d0.loss_mask: 0.2897  decode.d0.loss_dice: 0.3620  decode.d1.loss_cls: 0.4290  decode.d1.loss_mask: 0.2823  decode.d1.loss_dice: 0.3370  decode.d2.loss_cls: 0.4159  decode.d2.loss_mask: 0.2788  decode.d2.loss_dice: 0.3422  decode.d3.loss_cls: 0.3831  decode.d3.loss_mask: 0.2752  decode.d3.loss_dice: 0.3415  decode.d4.loss_cls: 0.3294  decode.d4.loss_mask: 0.2788  decode.d4.loss_dice: 0.3870  decode.d5.loss_cls: 0.3433  decode.d5.loss_mask: 0.2741  decode.d5.loss_dice: 0.3956  decode.d6.loss_cls: 0.3866  decode.d6.loss_mask: 0.2767  decode.d6.loss_dice: 0.3755  decode.d7.loss_cls: 0.3683  decode.d7.loss_mask: 0.2792  decode.d7.loss_dice: 0.3770  decode.d8.loss_cls: 0.3320  decode.d8.loss_mask: 0.2796  decode.d8.loss_dice: 0.3785
08/06 05:03:43 - mmengine - INFO - Iter(train) [ 20400/320000]  base_lr: 9.4244e-05 lr: 9.4244e-06  eta: 1 day, 16:51:21  time: 0.4921  data_time: 0.0107  memory: 5907  grad_norm: 153.9931  loss: 7.3363  decode.loss_cls: 0.1011  decode.loss_mask: 0.2854  decode.loss_dice: 0.2669  decode.d0.loss_cls: 0.8265  decode.d0.loss_mask: 0.2876  decode.d0.loss_dice: 0.2819  decode.d1.loss_cls: 0.1564  decode.d1.loss_mask: 0.2947  decode.d1.loss_dice: 0.2676  decode.d2.loss_cls: 0.0985  decode.d2.loss_mask: 0.2850  decode.d2.loss_dice: 0.2933  decode.d3.loss_cls: 0.0773  decode.d3.loss_mask: 0.2838  decode.d3.loss_dice: 0.2919  decode.d4.loss_cls: 0.0624  decode.d4.loss_mask: 0.2910  decode.d4.loss_dice: 0.2617  decode.d5.loss_cls: 0.0905  decode.d5.loss_mask: 0.2904  decode.d5.loss_dice: 0.2496  decode.d6.loss_cls: 0.0842  decode.d6.loss_mask: 0.2929  decode.d6.loss_dice: 0.2632  decode.d7.loss_cls: 0.1383  decode.d7.loss_mask: 0.2881  decode.d7.loss_dice: 0.2769  decode.d8.loss_cls: 0.0706  decode.d8.loss_mask: 0.2861  decode.d8.loss_dice: 0.2925
08/06 05:04:07 - mmengine - INFO - Iter(train) [ 20450/320000]  base_lr: 9.4230e-05 lr: 9.4230e-06  eta: 1 day, 16:50:58  time: 0.4914  data_time: 0.0102  memory: 5895  grad_norm: 188.9989  loss: 9.0916  decode.loss_cls: 0.3266  decode.loss_mask: 0.2169  decode.loss_dice: 0.3079  decode.d0.loss_cls: 1.0761  decode.d0.loss_mask: 0.2196  decode.d0.loss_dice: 0.3155  decode.d1.loss_cls: 0.3262  decode.d1.loss_mask: 0.2151  decode.d1.loss_dice: 0.3165  decode.d2.loss_cls: 0.2551  decode.d2.loss_mask: 0.2404  decode.d2.loss_dice: 0.3342  decode.d3.loss_cls: 0.2832  decode.d3.loss_mask: 0.2180  decode.d3.loss_dice: 0.2929  decode.d4.loss_cls: 0.2891  decode.d4.loss_mask: 0.2200  decode.d4.loss_dice: 0.2937  decode.d5.loss_cls: 0.3570  decode.d5.loss_mask: 0.2259  decode.d5.loss_dice: 0.3002  decode.d6.loss_cls: 0.2913  decode.d6.loss_mask: 0.2247  decode.d6.loss_dice: 0.2983  decode.d7.loss_cls: 0.2716  decode.d7.loss_mask: 0.2254  decode.d7.loss_dice: 0.3101  decode.d8.loss_cls: 0.3300  decode.d8.loss_mask: 0.2167  decode.d8.loss_dice: 0.2934
08/06 05:04:32 - mmengine - INFO - Iter(train) [ 20500/320000]  base_lr: 9.4216e-05 lr: 9.4216e-06  eta: 1 day, 16:50:34  time: 0.4917  data_time: 0.0104  memory: 5907  grad_norm: 107.3004  loss: 8.5768  decode.loss_cls: 0.1722  decode.loss_mask: 0.2758  decode.loss_dice: 0.3322  decode.d0.loss_cls: 0.9287  decode.d0.loss_mask: 0.2982  decode.d0.loss_dice: 0.3402  decode.d1.loss_cls: 0.2404  decode.d1.loss_mask: 0.2817  decode.d1.loss_dice: 0.3211  decode.d2.loss_cls: 0.1890  decode.d2.loss_mask: 0.2744  decode.d2.loss_dice: 0.3153  decode.d3.loss_cls: 0.1218  decode.d3.loss_mask: 0.2736  decode.d3.loss_dice: 0.3179  decode.d4.loss_cls: 0.1577  decode.d4.loss_mask: 0.2705  decode.d4.loss_dice: 0.3347  decode.d5.loss_cls: 0.1593  decode.d5.loss_mask: 0.2761  decode.d5.loss_dice: 0.3448  decode.d6.loss_cls: 0.2044  decode.d6.loss_mask: 0.2739  decode.d6.loss_dice: 0.3336  decode.d7.loss_cls: 0.1852  decode.d7.loss_mask: 0.2743  decode.d7.loss_dice: 0.3016  decode.d8.loss_cls: 0.1569  decode.d8.loss_mask: 0.2765  decode.d8.loss_dice: 0.3447
08/06 05:04:57 - mmengine - INFO - Iter(train) [ 20550/320000]  base_lr: 9.4202e-05 lr: 9.4202e-06  eta: 1 day, 16:50:11  time: 0.4927  data_time: 0.0105  memory: 5907  grad_norm: 115.1334  loss: 8.9867  decode.loss_cls: 0.1479  decode.loss_mask: 0.3412  decode.loss_dice: 0.3436  decode.d0.loss_cls: 0.9677  decode.d0.loss_mask: 0.3109  decode.d0.loss_dice: 0.3389  decode.d1.loss_cls: 0.2391  decode.d1.loss_mask: 0.2966  decode.d1.loss_dice: 0.3196  decode.d2.loss_cls: 0.1971  decode.d2.loss_mask: 0.3338  decode.d2.loss_dice: 0.3365  decode.d3.loss_cls: 0.2089  decode.d3.loss_mask: 0.2884  decode.d3.loss_dice: 0.3019  decode.d4.loss_cls: 0.1808  decode.d4.loss_mask: 0.3002  decode.d4.loss_dice: 0.3320  decode.d5.loss_cls: 0.1898  decode.d5.loss_mask: 0.3065  decode.d5.loss_dice: 0.3390  decode.d6.loss_cls: 0.1299  decode.d6.loss_mask: 0.3315  decode.d6.loss_dice: 0.3380  decode.d7.loss_cls: 0.1114  decode.d7.loss_mask: 0.3324  decode.d7.loss_dice: 0.3369  decode.d8.loss_cls: 0.1328  decode.d8.loss_mask: 0.3051  decode.d8.loss_dice: 0.3484
08/06 05:05:21 - mmengine - INFO - Iter(train) [ 20600/320000]  base_lr: 9.4187e-05 lr: 9.4187e-06  eta: 1 day, 16:49:47  time: 0.4920  data_time: 0.0104  memory: 5875  grad_norm: 103.1562  loss: 5.8112  decode.loss_cls: 0.0227  decode.loss_mask: 0.2231  decode.loss_dice: 0.2291  decode.d0.loss_cls: 0.8851  decode.d0.loss_mask: 0.2367  decode.d0.loss_dice: 0.2264  decode.d1.loss_cls: 0.1823  decode.d1.loss_mask: 0.2256  decode.d1.loss_dice: 0.2296  decode.d2.loss_cls: 0.0334  decode.d2.loss_mask: 0.2226  decode.d2.loss_dice: 0.2344  decode.d3.loss_cls: 0.0247  decode.d3.loss_mask: 0.2283  decode.d3.loss_dice: 0.2396  decode.d4.loss_cls: 0.0309  decode.d4.loss_mask: 0.2228  decode.d4.loss_dice: 0.2271  decode.d5.loss_cls: 0.0363  decode.d5.loss_mask: 0.2229  decode.d5.loss_dice: 0.2274  decode.d6.loss_cls: 0.0222  decode.d6.loss_mask: 0.2215  decode.d6.loss_dice: 0.2247  decode.d7.loss_cls: 0.0182  decode.d7.loss_mask: 0.2215  decode.d7.loss_dice: 0.2243  decode.d8.loss_cls: 0.0178  decode.d8.loss_mask: 0.2230  decode.d8.loss_dice: 0.2270
08/06 05:05:46 - mmengine - INFO - Iter(train) [ 20650/320000]  base_lr: 9.4173e-05 lr: 9.4173e-06  eta: 1 day, 16:49:24  time: 0.4941  data_time: 0.0106  memory: 5889  grad_norm: 315.9438  loss: 8.9476  decode.loss_cls: 0.2644  decode.loss_mask: 0.2108  decode.loss_dice: 0.3286  decode.d0.loss_cls: 1.0200  decode.d0.loss_mask: 0.2282  decode.d0.loss_dice: 0.3444  decode.d1.loss_cls: 0.3751  decode.d1.loss_mask: 0.2097  decode.d1.loss_dice: 0.3494  decode.d2.loss_cls: 0.3185  decode.d2.loss_mask: 0.2189  decode.d2.loss_dice: 0.3214  decode.d3.loss_cls: 0.3038  decode.d3.loss_mask: 0.2068  decode.d3.loss_dice: 0.3162  decode.d4.loss_cls: 0.2936  decode.d4.loss_mask: 0.2084  decode.d4.loss_dice: 0.3200  decode.d5.loss_cls: 0.2866  decode.d5.loss_mask: 0.2131  decode.d5.loss_dice: 0.3178  decode.d6.loss_cls: 0.2458  decode.d6.loss_mask: 0.2028  decode.d6.loss_dice: 0.3090  decode.d7.loss_cls: 0.2418  decode.d7.loss_mask: 0.2091  decode.d7.loss_dice: 0.3134  decode.d8.loss_cls: 0.2395  decode.d8.loss_mask: 0.2099  decode.d8.loss_dice: 0.3206
08/06 05:06:10 - mmengine - INFO - Iter(train) [ 20700/320000]  base_lr: 9.4159e-05 lr: 9.4159e-06  eta: 1 day, 16:49:00  time: 0.4922  data_time: 0.0104  memory: 5908  grad_norm: 76.9180  loss: 8.4653  decode.loss_cls: 0.1929  decode.loss_mask: 0.2157  decode.loss_dice: 0.3587  decode.d0.loss_cls: 1.0862  decode.d0.loss_mask: 0.2139  decode.d0.loss_dice: 0.3450  decode.d1.loss_cls: 0.1363  decode.d1.loss_mask: 0.2123  decode.d1.loss_dice: 0.3634  decode.d2.loss_cls: 0.1582  decode.d2.loss_mask: 0.2137  decode.d2.loss_dice: 0.3448  decode.d3.loss_cls: 0.2268  decode.d3.loss_mask: 0.2131  decode.d3.loss_dice: 0.3330  decode.d4.loss_cls: 0.2147  decode.d4.loss_mask: 0.2179  decode.d4.loss_dice: 0.3398  decode.d5.loss_cls: 0.2360  decode.d5.loss_mask: 0.2149  decode.d5.loss_dice: 0.3484  decode.d6.loss_cls: 0.1550  decode.d6.loss_mask: 0.2139  decode.d6.loss_dice: 0.3540  decode.d7.loss_cls: 0.2521  decode.d7.loss_mask: 0.2157  decode.d7.loss_dice: 0.3441  decode.d8.loss_cls: 0.1983  decode.d8.loss_mask: 0.2139  decode.d8.loss_dice: 0.3325
08/06 05:06:35 - mmengine - INFO - Iter(train) [ 20750/320000]  base_lr: 9.4145e-05 lr: 9.4145e-06  eta: 1 day, 16:48:37  time: 0.4922  data_time: 0.0106  memory: 5875  grad_norm: 473.6853  loss: 11.1260  decode.loss_cls: 0.3093  decode.loss_mask: 0.3407  decode.loss_dice: 0.3957  decode.d0.loss_cls: 1.1149  decode.d0.loss_mask: 0.3403  decode.d0.loss_dice: 0.3650  decode.d1.loss_cls: 0.3284  decode.d1.loss_mask: 0.3512  decode.d1.loss_dice: 0.3716  decode.d2.loss_cls: 0.2996  decode.d2.loss_mask: 0.3445  decode.d2.loss_dice: 0.3798  decode.d3.loss_cls: 0.2422  decode.d3.loss_mask: 0.3401  decode.d3.loss_dice: 0.3598  decode.d4.loss_cls: 0.2659  decode.d4.loss_mask: 0.3391  decode.d4.loss_dice: 0.3818  decode.d5.loss_cls: 0.3691  decode.d5.loss_mask: 0.3483  decode.d5.loss_dice: 0.3450  decode.d6.loss_cls: 0.3650  decode.d6.loss_mask: 0.3415  decode.d6.loss_dice: 0.3643  decode.d7.loss_cls: 0.3556  decode.d7.loss_mask: 0.3410  decode.d7.loss_dice: 0.3686  decode.d8.loss_cls: 0.3470  decode.d8.loss_mask: 0.3441  decode.d8.loss_dice: 0.3665
08/06 05:07:00 - mmengine - INFO - Iter(train) [ 20800/320000]  base_lr: 9.4131e-05 lr: 9.4131e-06  eta: 1 day, 16:48:13  time: 0.4928  data_time: 0.0107  memory: 5892  grad_norm: 148.7139  loss: 7.7385  decode.loss_cls: 0.2313  decode.loss_mask: 0.2384  decode.loss_dice: 0.2630  decode.d0.loss_cls: 0.8868  decode.d0.loss_mask: 0.2338  decode.d0.loss_dice: 0.2604  decode.d1.loss_cls: 0.1906  decode.d1.loss_mask: 0.2345  decode.d1.loss_dice: 0.2405  decode.d2.loss_cls: 0.1632  decode.d2.loss_mask: 0.2407  decode.d2.loss_dice: 0.2539  decode.d3.loss_cls: 0.1808  decode.d3.loss_mask: 0.2361  decode.d3.loss_dice: 0.2552  decode.d4.loss_cls: 0.1881  decode.d4.loss_mask: 0.2329  decode.d4.loss_dice: 0.2655  decode.d5.loss_cls: 0.2168  decode.d5.loss_mask: 0.2331  decode.d5.loss_dice: 0.2700  decode.d6.loss_cls: 0.2466  decode.d6.loss_mask: 0.2370  decode.d6.loss_dice: 0.2700  decode.d7.loss_cls: 0.2055  decode.d7.loss_mask: 0.2453  decode.d7.loss_dice: 0.2708  decode.d8.loss_cls: 0.2385  decode.d8.loss_mask: 0.2411  decode.d8.loss_dice: 0.2679
08/06 05:07:24 - mmengine - INFO - Iter(train) [ 20850/320000]  base_lr: 9.4117e-05 lr: 9.4117e-06  eta: 1 day, 16:47:50  time: 0.4922  data_time: 0.0105  memory: 5908  grad_norm: 206.5952  loss: 7.5188  decode.loss_cls: 0.0798  decode.loss_mask: 0.2743  decode.loss_dice: 0.2829  decode.d0.loss_cls: 0.9986  decode.d0.loss_mask: 0.2851  decode.d0.loss_dice: 0.3037  decode.d1.loss_cls: 0.1706  decode.d1.loss_mask: 0.2737  decode.d1.loss_dice: 0.2990  decode.d2.loss_cls: 0.0862  decode.d2.loss_mask: 0.2739  decode.d2.loss_dice: 0.2925  decode.d3.loss_cls: 0.0858  decode.d3.loss_mask: 0.2730  decode.d3.loss_dice: 0.2785  decode.d4.loss_cls: 0.0830  decode.d4.loss_mask: 0.2763  decode.d4.loss_dice: 0.3083  decode.d5.loss_cls: 0.0777  decode.d5.loss_mask: 0.2721  decode.d5.loss_dice: 0.2847  decode.d6.loss_cls: 0.1094  decode.d6.loss_mask: 0.2736  decode.d6.loss_dice: 0.2880  decode.d7.loss_cls: 0.0768  decode.d7.loss_mask: 0.2752  decode.d7.loss_dice: 0.2891  decode.d8.loss_cls: 0.0767  decode.d8.loss_mask: 0.2768  decode.d8.loss_dice: 0.2935
08/06 05:07:49 - mmengine - INFO - Iter(train) [ 20900/320000]  base_lr: 9.4102e-05 lr: 9.4102e-06  eta: 1 day, 16:47:26  time: 0.4922  data_time: 0.0105  memory: 5908  grad_norm: 217.2548  loss: 9.3390  decode.loss_cls: 0.2167  decode.loss_mask: 0.3191  decode.loss_dice: 0.3178  decode.d0.loss_cls: 1.0725  decode.d0.loss_mask: 0.3165  decode.d0.loss_dice: 0.3141  decode.d1.loss_cls: 0.2847  decode.d1.loss_mask: 0.3166  decode.d1.loss_dice: 0.3136  decode.d2.loss_cls: 0.2648  decode.d2.loss_mask: 0.3226  decode.d2.loss_dice: 0.3203  decode.d3.loss_cls: 0.1538  decode.d3.loss_mask: 0.3140  decode.d3.loss_dice: 0.2980  decode.d4.loss_cls: 0.2447  decode.d4.loss_mask: 0.3177  decode.d4.loss_dice: 0.3120  decode.d5.loss_cls: 0.1546  decode.d5.loss_mask: 0.3230  decode.d5.loss_dice: 0.3119  decode.d6.loss_cls: 0.1795  decode.d6.loss_mask: 0.3181  decode.d6.loss_dice: 0.3099  decode.d7.loss_cls: 0.2592  decode.d7.loss_mask: 0.3163  decode.d7.loss_dice: 0.3192  decode.d8.loss_cls: 0.1854  decode.d8.loss_mask: 0.3217  decode.d8.loss_dice: 0.3206
08/06 05:08:14 - mmengine - INFO - Iter(train) [ 20950/320000]  base_lr: 9.4088e-05 lr: 9.4088e-06  eta: 1 day, 16:47:03  time: 0.4927  data_time: 0.0104  memory: 5890  grad_norm: 80.9996  loss: 7.5019  decode.loss_cls: 0.1857  decode.loss_mask: 0.2534  decode.loss_dice: 0.2986  decode.d0.loss_cls: 0.7323  decode.d0.loss_mask: 0.2636  decode.d0.loss_dice: 0.2733  decode.d1.loss_cls: 0.1272  decode.d1.loss_mask: 0.2564  decode.d1.loss_dice: 0.2893  decode.d2.loss_cls: 0.1941  decode.d2.loss_mask: 0.2477  decode.d2.loss_dice: 0.2840  decode.d3.loss_cls: 0.1404  decode.d3.loss_mask: 0.2576  decode.d3.loss_dice: 0.2622  decode.d4.loss_cls: 0.1581  decode.d4.loss_mask: 0.2529  decode.d4.loss_dice: 0.2847  decode.d5.loss_cls: 0.1443  decode.d5.loss_mask: 0.2493  decode.d5.loss_dice: 0.2823  decode.d6.loss_cls: 0.1435  decode.d6.loss_mask: 0.2526  decode.d6.loss_dice: 0.2893  decode.d7.loss_cls: 0.1437  decode.d7.loss_mask: 0.2527  decode.d7.loss_dice: 0.2949  decode.d8.loss_cls: 0.1534  decode.d8.loss_mask: 0.2550  decode.d8.loss_dice: 0.2794
08/06 05:08:38 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 05:08:38 - mmengine - INFO - Iter(train) [ 21000/320000]  base_lr: 9.4074e-05 lr: 9.4074e-06  eta: 1 day, 16:46:41  time: 0.4926  data_time: 0.0104  memory: 5890  grad_norm: 180.7529  loss: 6.7121  decode.loss_cls: 0.1166  decode.loss_mask: 0.2313  decode.loss_dice: 0.2481  decode.d0.loss_cls: 1.0025  decode.d0.loss_mask: 0.2158  decode.d0.loss_dice: 0.2650  decode.d1.loss_cls: 0.1260  decode.d1.loss_mask: 0.2250  decode.d1.loss_dice: 0.2646  decode.d2.loss_cls: 0.0962  decode.d2.loss_mask: 0.2244  decode.d2.loss_dice: 0.2610  decode.d3.loss_cls: 0.0855  decode.d3.loss_mask: 0.2201  decode.d3.loss_dice: 0.2586  decode.d4.loss_cls: 0.0999  decode.d4.loss_mask: 0.2231  decode.d4.loss_dice: 0.2483  decode.d5.loss_cls: 0.1004  decode.d5.loss_mask: 0.2259  decode.d5.loss_dice: 0.2587  decode.d6.loss_cls: 0.0737  decode.d6.loss_mask: 0.2250  decode.d6.loss_dice: 0.2480  decode.d7.loss_cls: 0.0998  decode.d7.loss_mask: 0.2265  decode.d7.loss_dice: 0.2496  decode.d8.loss_cls: 0.1135  decode.d8.loss_mask: 0.2285  decode.d8.loss_dice: 0.2505
08/06 05:09:03 - mmengine - INFO - Iter(train) [ 21050/320000]  base_lr: 9.4060e-05 lr: 9.4060e-06  eta: 1 day, 16:46:18  time: 0.4926  data_time: 0.0106  memory: 5907  grad_norm: 136.5006  loss: 6.7471  decode.loss_cls: 0.1149  decode.loss_mask: 0.2207  decode.loss_dice: 0.2659  decode.d0.loss_cls: 0.9616  decode.d0.loss_mask: 0.2133  decode.d0.loss_dice: 0.2816  decode.d1.loss_cls: 0.1032  decode.d1.loss_mask: 0.2113  decode.d1.loss_dice: 0.2655  decode.d2.loss_cls: 0.0982  decode.d2.loss_mask: 0.2125  decode.d2.loss_dice: 0.2608  decode.d3.loss_cls: 0.0687  decode.d3.loss_mask: 0.2150  decode.d3.loss_dice: 0.2633  decode.d4.loss_cls: 0.1246  decode.d4.loss_mask: 0.2178  decode.d4.loss_dice: 0.2764  decode.d5.loss_cls: 0.1069  decode.d5.loss_mask: 0.2131  decode.d5.loss_dice: 0.2596  decode.d6.loss_cls: 0.1088  decode.d6.loss_mask: 0.2103  decode.d6.loss_dice: 0.2620  decode.d7.loss_cls: 0.1468  decode.d7.loss_mask: 0.2114  decode.d7.loss_dice: 0.2639  decode.d8.loss_cls: 0.1083  decode.d8.loss_mask: 0.2171  decode.d8.loss_dice: 0.2635
08/06 05:09:28 - mmengine - INFO - Iter(train) [ 21100/320000]  base_lr: 9.4046e-05 lr: 9.4046e-06  eta: 1 day, 16:45:54  time: 0.4912  data_time: 0.0102  memory: 5909  grad_norm: 170.1458  loss: 7.2404  decode.loss_cls: 0.1501  decode.loss_mask: 0.2477  decode.loss_dice: 0.2435  decode.d0.loss_cls: 0.8349  decode.d0.loss_mask: 0.2644  decode.d0.loss_dice: 0.2653  decode.d1.loss_cls: 0.1279  decode.d1.loss_mask: 0.2482  decode.d1.loss_dice: 0.2562  decode.d2.loss_cls: 0.1244  decode.d2.loss_mask: 0.2556  decode.d2.loss_dice: 0.2657  decode.d3.loss_cls: 0.1749  decode.d3.loss_mask: 0.2432  decode.d3.loss_dice: 0.2553  decode.d4.loss_cls: 0.1350  decode.d4.loss_mask: 0.2671  decode.d4.loss_dice: 0.2655  decode.d5.loss_cls: 0.1514  decode.d5.loss_mask: 0.2502  decode.d5.loss_dice: 0.2603  decode.d6.loss_cls: 0.1670  decode.d6.loss_mask: 0.2536  decode.d6.loss_dice: 0.2499  decode.d7.loss_cls: 0.1277  decode.d7.loss_mask: 0.2475  decode.d7.loss_dice: 0.2603  decode.d8.loss_cls: 0.1624  decode.d8.loss_mask: 0.2426  decode.d8.loss_dice: 0.2426
08/06 05:09:52 - mmengine - INFO - Iter(train) [ 21150/320000]  base_lr: 9.4032e-05 lr: 9.4032e-06  eta: 1 day, 16:45:30  time: 0.4890  data_time: 0.0103  memory: 5889  grad_norm: 94.8639  loss: 7.7013  decode.loss_cls: 0.1456  decode.loss_mask: 0.2934  decode.loss_dice: 0.2592  decode.d0.loss_cls: 0.8132  decode.d0.loss_mask: 0.3058  decode.d0.loss_dice: 0.2672  decode.d1.loss_cls: 0.1474  decode.d1.loss_mask: 0.3060  decode.d1.loss_dice: 0.2774  decode.d2.loss_cls: 0.1254  decode.d2.loss_mask: 0.2986  decode.d2.loss_dice: 0.2694  decode.d3.loss_cls: 0.1217  decode.d3.loss_mask: 0.2936  decode.d3.loss_dice: 0.2614  decode.d4.loss_cls: 0.1487  decode.d4.loss_mask: 0.2951  decode.d4.loss_dice: 0.2769  decode.d5.loss_cls: 0.1433  decode.d5.loss_mask: 0.2950  decode.d5.loss_dice: 0.2613  decode.d6.loss_cls: 0.1380  decode.d6.loss_mask: 0.2983  decode.d6.loss_dice: 0.2718  decode.d7.loss_cls: 0.1471  decode.d7.loss_mask: 0.2930  decode.d7.loss_dice: 0.2607  decode.d8.loss_cls: 0.1385  decode.d8.loss_mask: 0.2892  decode.d8.loss_dice: 0.2593
08/06 05:10:17 - mmengine - INFO - Iter(train) [ 21200/320000]  base_lr: 9.4018e-05 lr: 9.4018e-06  eta: 1 day, 16:45:04  time: 0.4899  data_time: 0.0104  memory: 5889  grad_norm: 348.3854  loss: 11.8273  decode.loss_cls: 0.3930  decode.loss_mask: 0.4276  decode.loss_dice: 0.3810  decode.d0.loss_cls: 1.1512  decode.d0.loss_mask: 0.3080  decode.d0.loss_dice: 0.3764  decode.d1.loss_cls: 0.4199  decode.d1.loss_mask: 0.3361  decode.d1.loss_dice: 0.3708  decode.d2.loss_cls: 0.2611  decode.d2.loss_mask: 0.4042  decode.d2.loss_dice: 0.3755  decode.d3.loss_cls: 0.2863  decode.d3.loss_mask: 0.3946  decode.d3.loss_dice: 0.3718  decode.d4.loss_cls: 0.3976  decode.d4.loss_mask: 0.3478  decode.d4.loss_dice: 0.3647  decode.d5.loss_cls: 0.2523  decode.d5.loss_mask: 0.4346  decode.d5.loss_dice: 0.3774  decode.d6.loss_cls: 0.3327  decode.d6.loss_mask: 0.4206  decode.d6.loss_dice: 0.3713  decode.d7.loss_cls: 0.3461  decode.d7.loss_mask: 0.4231  decode.d7.loss_dice: 0.3741  decode.d8.loss_cls: 0.3334  decode.d8.loss_mask: 0.4160  decode.d8.loss_dice: 0.3778
08/06 05:10:41 - mmengine - INFO - Iter(train) [ 21250/320000]  base_lr: 9.4003e-05 lr: 9.4003e-06  eta: 1 day, 16:44:40  time: 0.4897  data_time: 0.0105  memory: 5927  grad_norm: 262.9678  loss: 9.1122  decode.loss_cls: 0.1363  decode.loss_mask: 0.4302  decode.loss_dice: 0.2652  decode.d0.loss_cls: 0.8881  decode.d0.loss_mask: 0.4680  decode.d0.loss_dice: 0.2596  decode.d1.loss_cls: 0.1580  decode.d1.loss_mask: 0.4427  decode.d1.loss_dice: 0.2911  decode.d2.loss_cls: 0.1014  decode.d2.loss_mask: 0.4343  decode.d2.loss_dice: 0.2777  decode.d3.loss_cls: 0.1075  decode.d3.loss_mask: 0.4465  decode.d3.loss_dice: 0.2801  decode.d4.loss_cls: 0.0929  decode.d4.loss_mask: 0.4399  decode.d4.loss_dice: 0.2750  decode.d5.loss_cls: 0.1074  decode.d5.loss_mask: 0.4381  decode.d5.loss_dice: 0.2609  decode.d6.loss_cls: 0.1240  decode.d6.loss_mask: 0.4398  decode.d6.loss_dice: 0.2611  decode.d7.loss_cls: 0.1241  decode.d7.loss_mask: 0.4427  decode.d7.loss_dice: 0.2754  decode.d8.loss_cls: 0.1310  decode.d8.loss_mask: 0.4389  decode.d8.loss_dice: 0.2744
08/06 05:11:06 - mmengine - INFO - Iter(train) [ 21300/320000]  base_lr: 9.3989e-05 lr: 9.3989e-06  eta: 1 day, 16:44:15  time: 0.4921  data_time: 0.0107  memory: 5929  grad_norm: 190.2598  loss: 10.3631  decode.loss_cls: 0.1891  decode.loss_mask: 0.3535  decode.loss_dice: 0.3664  decode.d0.loss_cls: 0.9647  decode.d0.loss_mask: 0.3618  decode.d0.loss_dice: 0.3886  decode.d1.loss_cls: 0.2747  decode.d1.loss_mask: 0.3539  decode.d1.loss_dice: 0.3676  decode.d2.loss_cls: 0.2578  decode.d2.loss_mask: 0.3531  decode.d2.loss_dice: 0.3580  decode.d3.loss_cls: 0.2002  decode.d3.loss_mask: 0.3416  decode.d3.loss_dice: 0.3612  decode.d4.loss_cls: 0.2296  decode.d4.loss_mask: 0.3458  decode.d4.loss_dice: 0.3674  decode.d5.loss_cls: 0.2556  decode.d5.loss_mask: 0.3461  decode.d5.loss_dice: 0.3580  decode.d6.loss_cls: 0.2757  decode.d6.loss_mask: 0.3414  decode.d6.loss_dice: 0.3714  decode.d7.loss_cls: 0.2696  decode.d7.loss_mask: 0.3538  decode.d7.loss_dice: 0.3815  decode.d8.loss_cls: 0.2328  decode.d8.loss_mask: 0.3634  decode.d8.loss_dice: 0.3787
08/06 05:11:30 - mmengine - INFO - Iter(train) [ 21350/320000]  base_lr: 9.3975e-05 lr: 9.3975e-06  eta: 1 day, 16:43:51  time: 0.4906  data_time: 0.0106  memory: 5908  grad_norm: 112.6179  loss: 8.0495  decode.loss_cls: 0.0579  decode.loss_mask: 0.3135  decode.loss_dice: 0.3156  decode.d0.loss_cls: 0.9092  decode.d0.loss_mask: 0.3106  decode.d0.loss_dice: 0.3540  decode.d1.loss_cls: 0.1131  decode.d1.loss_mask: 0.3132  decode.d1.loss_dice: 0.3346  decode.d2.loss_cls: 0.0842  decode.d2.loss_mask: 0.3117  decode.d2.loss_dice: 0.3189  decode.d3.loss_cls: 0.1145  decode.d3.loss_mask: 0.3093  decode.d3.loss_dice: 0.3181  decode.d4.loss_cls: 0.1067  decode.d4.loss_mask: 0.3076  decode.d4.loss_dice: 0.3350  decode.d5.loss_cls: 0.1272  decode.d5.loss_mask: 0.3084  decode.d5.loss_dice: 0.3059  decode.d6.loss_cls: 0.0472  decode.d6.loss_mask: 0.3126  decode.d6.loss_dice: 0.3113  decode.d7.loss_cls: 0.0500  decode.d7.loss_mask: 0.3141  decode.d7.loss_dice: 0.3170  decode.d8.loss_cls: 0.0766  decode.d8.loss_mask: 0.3129  decode.d8.loss_dice: 0.3386
08/06 05:11:55 - mmengine - INFO - Iter(train) [ 21400/320000]  base_lr: 9.3961e-05 lr: 9.3961e-06  eta: 1 day, 16:43:26  time: 0.4899  data_time: 0.0105  memory: 5908  grad_norm: 61.4675  loss: 6.0357  decode.loss_cls: 0.1550  decode.loss_mask: 0.1961  decode.loss_dice: 0.2024  decode.d0.loss_cls: 0.8258  decode.d0.loss_mask: 0.1985  decode.d0.loss_dice: 0.2150  decode.d1.loss_cls: 0.0975  decode.d1.loss_mask: 0.1956  decode.d1.loss_dice: 0.2098  decode.d2.loss_cls: 0.0745  decode.d2.loss_mask: 0.1972  decode.d2.loss_dice: 0.2102  decode.d3.loss_cls: 0.1108  decode.d3.loss_mask: 0.2005  decode.d3.loss_dice: 0.2063  decode.d4.loss_cls: 0.1328  decode.d4.loss_mask: 0.1996  decode.d4.loss_dice: 0.2065  decode.d5.loss_cls: 0.1601  decode.d5.loss_mask: 0.1983  decode.d5.loss_dice: 0.2083  decode.d6.loss_cls: 0.1338  decode.d6.loss_mask: 0.1985  decode.d6.loss_dice: 0.2095  decode.d7.loss_cls: 0.1424  decode.d7.loss_mask: 0.1985  decode.d7.loss_dice: 0.2051  decode.d8.loss_cls: 0.1466  decode.d8.loss_mask: 0.1982  decode.d8.loss_dice: 0.2025
08/06 05:12:19 - mmengine - INFO - Iter(train) [ 21450/320000]  base_lr: 9.3947e-05 lr: 9.3947e-06  eta: 1 day, 16:43:01  time: 0.4906  data_time: 0.0105  memory: 5876  grad_norm: 88.0274  loss: 8.2919  decode.loss_cls: 0.1137  decode.loss_mask: 0.3177  decode.loss_dice: 0.3115  decode.d0.loss_cls: 0.7673  decode.d0.loss_mask: 0.3252  decode.d0.loss_dice: 0.3188  decode.d1.loss_cls: 0.2247  decode.d1.loss_mask: 0.3215  decode.d1.loss_dice: 0.3151  decode.d2.loss_cls: 0.1239  decode.d2.loss_mask: 0.3161  decode.d2.loss_dice: 0.2961  decode.d3.loss_cls: 0.1173  decode.d3.loss_mask: 0.3158  decode.d3.loss_dice: 0.3264  decode.d4.loss_cls: 0.1630  decode.d4.loss_mask: 0.3217  decode.d4.loss_dice: 0.2804  decode.d5.loss_cls: 0.0912  decode.d5.loss_mask: 0.3198  decode.d5.loss_dice: 0.3101  decode.d6.loss_cls: 0.1230  decode.d6.loss_mask: 0.3184  decode.d6.loss_dice: 0.3084  decode.d7.loss_cls: 0.1314  decode.d7.loss_mask: 0.3146  decode.d7.loss_dice: 0.3346  decode.d8.loss_cls: 0.1072  decode.d8.loss_mask: 0.3212  decode.d8.loss_dice: 0.3360
08/06 05:12:44 - mmengine - INFO - Iter(train) [ 21500/320000]  base_lr: 9.3933e-05 lr: 9.3933e-06  eta: 1 day, 16:42:37  time: 0.4906  data_time: 0.0106  memory: 5907  grad_norm: 135.6630  loss: 8.6870  decode.loss_cls: 0.1897  decode.loss_mask: 0.2482  decode.loss_dice: 0.2922  decode.d0.loss_cls: 1.0532  decode.d0.loss_mask: 0.2385  decode.d0.loss_dice: 0.2916  decode.d1.loss_cls: 0.2907  decode.d1.loss_mask: 0.2416  decode.d1.loss_dice: 0.3090  decode.d2.loss_cls: 0.1906  decode.d2.loss_mask: 0.2404  decode.d2.loss_dice: 0.3058  decode.d3.loss_cls: 0.3298  decode.d3.loss_mask: 0.2351  decode.d3.loss_dice: 0.2899  decode.d4.loss_cls: 0.2816  decode.d4.loss_mask: 0.2327  decode.d4.loss_dice: 0.2907  decode.d5.loss_cls: 0.2546  decode.d5.loss_mask: 0.2353  decode.d5.loss_dice: 0.3055  decode.d6.loss_cls: 0.2405  decode.d6.loss_mask: 0.2463  decode.d6.loss_dice: 0.3026  decode.d7.loss_cls: 0.2778  decode.d7.loss_mask: 0.2459  decode.d7.loss_dice: 0.2902  decode.d8.loss_cls: 0.1703  decode.d8.loss_mask: 0.2480  decode.d8.loss_dice: 0.3186
08/06 05:13:09 - mmengine - INFO - Iter(train) [ 21550/320000]  base_lr: 9.3918e-05 lr: 9.3918e-06  eta: 1 day, 16:42:14  time: 0.4910  data_time: 0.0108  memory: 5876  grad_norm: 242.6359  loss: 9.9936  decode.loss_cls: 0.2210  decode.loss_mask: 0.4120  decode.loss_dice: 0.3629  decode.d0.loss_cls: 0.9611  decode.d0.loss_mask: 0.3009  decode.d0.loss_dice: 0.3430  decode.d1.loss_cls: 0.2950  decode.d1.loss_mask: 0.3262  decode.d1.loss_dice: 0.3197  decode.d2.loss_cls: 0.2370  decode.d2.loss_mask: 0.3224  decode.d2.loss_dice: 0.3439  decode.d3.loss_cls: 0.2607  decode.d3.loss_mask: 0.3135  decode.d3.loss_dice: 0.3326  decode.d4.loss_cls: 0.2405  decode.d4.loss_mask: 0.3313  decode.d4.loss_dice: 0.3384  decode.d5.loss_cls: 0.2546  decode.d5.loss_mask: 0.3213  decode.d5.loss_dice: 0.3610  decode.d6.loss_cls: 0.2778  decode.d6.loss_mask: 0.3182  decode.d6.loss_dice: 0.3471  decode.d7.loss_cls: 0.2101  decode.d7.loss_mask: 0.3537  decode.d7.loss_dice: 0.3546  decode.d8.loss_cls: 0.1667  decode.d8.loss_mask: 0.3942  decode.d8.loss_dice: 0.3724
08/06 05:13:33 - mmengine - INFO - Iter(train) [ 21600/320000]  base_lr: 9.3904e-05 lr: 9.3904e-06  eta: 1 day, 16:41:49  time: 0.4899  data_time: 0.0106  memory: 5908  grad_norm: 190.1742  loss: 9.8018  decode.loss_cls: 0.1739  decode.loss_mask: 0.3700  decode.loss_dice: 0.3597  decode.d0.loss_cls: 0.7471  decode.d0.loss_mask: 0.3682  decode.d0.loss_dice: 0.3695  decode.d1.loss_cls: 0.2721  decode.d1.loss_mask: 0.3581  decode.d1.loss_dice: 0.3517  decode.d2.loss_cls: 0.2298  decode.d2.loss_mask: 0.3501  decode.d2.loss_dice: 0.3552  decode.d3.loss_cls: 0.1935  decode.d3.loss_mask: 0.3576  decode.d3.loss_dice: 0.3605  decode.d4.loss_cls: 0.1646  decode.d4.loss_mask: 0.3626  decode.d4.loss_dice: 0.3614  decode.d5.loss_cls: 0.1715  decode.d5.loss_mask: 0.3571  decode.d5.loss_dice: 0.3588  decode.d6.loss_cls: 0.1808  decode.d6.loss_mask: 0.3609  decode.d6.loss_dice: 0.3509  decode.d7.loss_cls: 0.2434  decode.d7.loss_mask: 0.3587  decode.d7.loss_dice: 0.3532  decode.d8.loss_cls: 0.2348  decode.d8.loss_mask: 0.3670  decode.d8.loss_dice: 0.3590
08/06 05:13:58 - mmengine - INFO - Iter(train) [ 21650/320000]  base_lr: 9.3890e-05 lr: 9.3890e-06  eta: 1 day, 16:41:24  time: 0.4916  data_time: 0.0108  memory: 5890  grad_norm: 86.1594  loss: 8.6906  decode.loss_cls: 0.2129  decode.loss_mask: 0.2630  decode.loss_dice: 0.2989  decode.d0.loss_cls: 0.9769  decode.d0.loss_mask: 0.2718  decode.d0.loss_dice: 0.3081  decode.d1.loss_cls: 0.2858  decode.d1.loss_mask: 0.2806  decode.d1.loss_dice: 0.3087  decode.d2.loss_cls: 0.2234  decode.d2.loss_mask: 0.2713  decode.d2.loss_dice: 0.3085  decode.d3.loss_cls: 0.2305  decode.d3.loss_mask: 0.2582  decode.d3.loss_dice: 0.2991  decode.d4.loss_cls: 0.2411  decode.d4.loss_mask: 0.2613  decode.d4.loss_dice: 0.3001  decode.d5.loss_cls: 0.2174  decode.d5.loss_mask: 0.2613  decode.d5.loss_dice: 0.3004  decode.d6.loss_cls: 0.2093  decode.d6.loss_mask: 0.2649  decode.d6.loss_dice: 0.2974  decode.d7.loss_cls: 0.1962  decode.d7.loss_mask: 0.2630  decode.d7.loss_dice: 0.3095  decode.d8.loss_cls: 0.2029  decode.d8.loss_mask: 0.2649  decode.d8.loss_dice: 0.3031
08/06 05:14:22 - mmengine - INFO - Iter(train) [ 21700/320000]  base_lr: 9.3876e-05 lr: 9.3876e-06  eta: 1 day, 16:40:59  time: 0.4921  data_time: 0.0106  memory: 5891  grad_norm: 125.1219  loss: 8.8968  decode.loss_cls: 0.2608  decode.loss_mask: 0.2626  decode.loss_dice: 0.2833  decode.d0.loss_cls: 1.1010  decode.d0.loss_mask: 0.2695  decode.d0.loss_dice: 0.3080  decode.d1.loss_cls: 0.3360  decode.d1.loss_mask: 0.2597  decode.d1.loss_dice: 0.2890  decode.d2.loss_cls: 0.2785  decode.d2.loss_mask: 0.2547  decode.d2.loss_dice: 0.2839  decode.d3.loss_cls: 0.2316  decode.d3.loss_mask: 0.2543  decode.d3.loss_dice: 0.2827  decode.d4.loss_cls: 0.2334  decode.d4.loss_mask: 0.2590  decode.d4.loss_dice: 0.2912  decode.d5.loss_cls: 0.2077  decode.d5.loss_mask: 0.2645  decode.d5.loss_dice: 0.2912  decode.d6.loss_cls: 0.2860  decode.d6.loss_mask: 0.2665  decode.d6.loss_dice: 0.2962  decode.d7.loss_cls: 0.2284  decode.d7.loss_mask: 0.2679  decode.d7.loss_dice: 0.2936  decode.d8.loss_cls: 0.2263  decode.d8.loss_mask: 0.2575  decode.d8.loss_dice: 0.2717
08/06 05:14:47 - mmengine - INFO - Iter(train) [ 21750/320000]  base_lr: 9.3862e-05 lr: 9.3862e-06  eta: 1 day, 16:40:34  time: 0.4915  data_time: 0.0107  memory: 5908  grad_norm: 195.8835  loss: 8.7890  decode.loss_cls: 0.2978  decode.loss_mask: 0.2525  decode.loss_dice: 0.2745  decode.d0.loss_cls: 1.0692  decode.d0.loss_mask: 0.2419  decode.d0.loss_dice: 0.2764  decode.d1.loss_cls: 0.2364  decode.d1.loss_mask: 0.2864  decode.d1.loss_dice: 0.2864  decode.d2.loss_cls: 0.2507  decode.d2.loss_mask: 0.2698  decode.d2.loss_dice: 0.2542  decode.d3.loss_cls: 0.2872  decode.d3.loss_mask: 0.2494  decode.d3.loss_dice: 0.2460  decode.d4.loss_cls: 0.3637  decode.d4.loss_mask: 0.2424  decode.d4.loss_dice: 0.2438  decode.d5.loss_cls: 0.2646  decode.d5.loss_mask: 0.2804  decode.d5.loss_dice: 0.2627  decode.d6.loss_cls: 0.2782  decode.d6.loss_mask: 0.2530  decode.d6.loss_dice: 0.2638  decode.d7.loss_cls: 0.2619  decode.d7.loss_mask: 0.2705  decode.d7.loss_dice: 0.2569  decode.d8.loss_cls: 0.2249  decode.d8.loss_mask: 0.2638  decode.d8.loss_dice: 0.2795
08/06 05:15:11 - mmengine - INFO - Iter(train) [ 21800/320000]  base_lr: 9.3848e-05 lr: 9.3848e-06  eta: 1 day, 16:40:10  time: 0.4912  data_time: 0.0107  memory: 5907  grad_norm: 195.0831  loss: 8.5131  decode.loss_cls: 0.1360  decode.loss_mask: 0.2484  decode.loss_dice: 0.2934  decode.d0.loss_cls: 0.9625  decode.d0.loss_mask: 0.2619  decode.d0.loss_dice: 0.2846  decode.d1.loss_cls: 0.2104  decode.d1.loss_mask: 0.2615  decode.d1.loss_dice: 0.2769  decode.d2.loss_cls: 0.2143  decode.d2.loss_mask: 0.2734  decode.d2.loss_dice: 0.3105  decode.d3.loss_cls: 0.3180  decode.d3.loss_mask: 0.2550  decode.d3.loss_dice: 0.2752  decode.d4.loss_cls: 0.3094  decode.d4.loss_mask: 0.2526  decode.d4.loss_dice: 0.2824  decode.d5.loss_cls: 0.2878  decode.d5.loss_mask: 0.2516  decode.d5.loss_dice: 0.2685  decode.d6.loss_cls: 0.2621  decode.d6.loss_mask: 0.2493  decode.d6.loss_dice: 0.2698  decode.d7.loss_cls: 0.2427  decode.d7.loss_mask: 0.2573  decode.d7.loss_dice: 0.2851  decode.d8.loss_cls: 0.1599  decode.d8.loss_mask: 0.2525  decode.d8.loss_dice: 0.2999
08/06 05:15:36 - mmengine - INFO - Iter(train) [ 21850/320000]  base_lr: 9.3833e-05 lr: 9.3833e-06  eta: 1 day, 16:39:48  time: 0.4907  data_time: 0.0107  memory: 5908  grad_norm: 113.9489  loss: 7.4878  decode.loss_cls: 0.0732  decode.loss_mask: 0.2837  decode.loss_dice: 0.2637  decode.d0.loss_cls: 0.9595  decode.d0.loss_mask: 0.2996  decode.d0.loss_dice: 0.2735  decode.d1.loss_cls: 0.0779  decode.d1.loss_mask: 0.2852  decode.d1.loss_dice: 0.2750  decode.d2.loss_cls: 0.1225  decode.d2.loss_mask: 0.2874  decode.d2.loss_dice: 0.2700  decode.d3.loss_cls: 0.1054  decode.d3.loss_mask: 0.2845  decode.d3.loss_dice: 0.2726  decode.d4.loss_cls: 0.1259  decode.d4.loss_mask: 0.2882  decode.d4.loss_dice: 0.2703  decode.d5.loss_cls: 0.0924  decode.d5.loss_mask: 0.2852  decode.d5.loss_dice: 0.2726  decode.d6.loss_cls: 0.1220  decode.d6.loss_mask: 0.2865  decode.d6.loss_dice: 0.2686  decode.d7.loss_cls: 0.0857  decode.d7.loss_mask: 0.2868  decode.d7.loss_dice: 0.2665  decode.d8.loss_cls: 0.1504  decode.d8.loss_mask: 0.2847  decode.d8.loss_dice: 0.2682
08/06 05:16:01 - mmengine - INFO - Iter(train) [ 21900/320000]  base_lr: 9.3819e-05 lr: 9.3819e-06  eta: 1 day, 16:39:23  time: 0.4907  data_time: 0.0107  memory: 5891  grad_norm: 102.1607  loss: 9.6444  decode.loss_cls: 0.2433  decode.loss_mask: 0.2812  decode.loss_dice: 0.3449  decode.d0.loss_cls: 1.1237  decode.d0.loss_mask: 0.2911  decode.d0.loss_dice: 0.3492  decode.d1.loss_cls: 0.2686  decode.d1.loss_mask: 0.2847  decode.d1.loss_dice: 0.3542  decode.d2.loss_cls: 0.3102  decode.d2.loss_mask: 0.2842  decode.d2.loss_dice: 0.3427  decode.d3.loss_cls: 0.2560  decode.d3.loss_mask: 0.2949  decode.d3.loss_dice: 0.3472  decode.d4.loss_cls: 0.2355  decode.d4.loss_mask: 0.2875  decode.d4.loss_dice: 0.3385  decode.d5.loss_cls: 0.2348  decode.d5.loss_mask: 0.2787  decode.d5.loss_dice: 0.3232  decode.d6.loss_cls: 0.2316  decode.d6.loss_mask: 0.2942  decode.d6.loss_dice: 0.3432  decode.d7.loss_cls: 0.2127  decode.d7.loss_mask: 0.2933  decode.d7.loss_dice: 0.3449  decode.d8.loss_cls: 0.2195  decode.d8.loss_mask: 0.2882  decode.d8.loss_dice: 0.3425
08/06 05:16:25 - mmengine - INFO - Iter(train) [ 21950/320000]  base_lr: 9.3805e-05 lr: 9.3805e-06  eta: 1 day, 16:38:59  time: 0.4901  data_time: 0.0106  memory: 5890  grad_norm: 212.9685  loss: 9.8734  decode.loss_cls: 0.1985  decode.loss_mask: 0.3210  decode.loss_dice: 0.3466  decode.d0.loss_cls: 1.0480  decode.d0.loss_mask: 0.3162  decode.d0.loss_dice: 0.3554  decode.d1.loss_cls: 0.2860  decode.d1.loss_mask: 0.3155  decode.d1.loss_dice: 0.3357  decode.d2.loss_cls: 0.2493  decode.d2.loss_mask: 0.3173  decode.d2.loss_dice: 0.3394  decode.d3.loss_cls: 0.2189  decode.d3.loss_mask: 0.3131  decode.d3.loss_dice: 0.3537  decode.d4.loss_cls: 0.2271  decode.d4.loss_mask: 0.3162  decode.d4.loss_dice: 0.3656  decode.d5.loss_cls: 0.2440  decode.d5.loss_mask: 0.3208  decode.d5.loss_dice: 0.3762  decode.d6.loss_cls: 0.2594  decode.d6.loss_mask: 0.3161  decode.d6.loss_dice: 0.3560  decode.d7.loss_cls: 0.1956  decode.d7.loss_mask: 0.3157  decode.d7.loss_dice: 0.3624  decode.d8.loss_cls: 0.2517  decode.d8.loss_mask: 0.3097  decode.d8.loss_dice: 0.3422
08/06 05:16:50 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 05:16:50 - mmengine - INFO - Iter(train) [ 22000/320000]  base_lr: 9.3791e-05 lr: 9.3791e-06  eta: 1 day, 16:38:35  time: 0.4926  data_time: 0.0109  memory: 5908  grad_norm: 181.7640  loss: 10.4993  decode.loss_cls: 0.2357  decode.loss_mask: 0.3155  decode.loss_dice: 0.4118  decode.d0.loss_cls: 1.0118  decode.d0.loss_mask: 0.3167  decode.d0.loss_dice: 0.4309  decode.d1.loss_cls: 0.3380  decode.d1.loss_mask: 0.3120  decode.d1.loss_dice: 0.4046  decode.d2.loss_cls: 0.2516  decode.d2.loss_mask: 0.3040  decode.d2.loss_dice: 0.3968  decode.d3.loss_cls: 0.1989  decode.d3.loss_mask: 0.3050  decode.d3.loss_dice: 0.3914  decode.d4.loss_cls: 0.2469  decode.d4.loss_mask: 0.3100  decode.d4.loss_dice: 0.3987  decode.d5.loss_cls: 0.2162  decode.d5.loss_mask: 0.3146  decode.d5.loss_dice: 0.4325  decode.d6.loss_cls: 0.2779  decode.d6.loss_mask: 0.3096  decode.d6.loss_dice: 0.4036  decode.d7.loss_cls: 0.2902  decode.d7.loss_mask: 0.3148  decode.d7.loss_dice: 0.4140  decode.d8.loss_cls: 0.2165  decode.d8.loss_mask: 0.3152  decode.d8.loss_dice: 0.4141
08/06 05:17:14 - mmengine - INFO - Iter(train) [ 22050/320000]  base_lr: 9.3777e-05 lr: 9.3777e-06  eta: 1 day, 16:38:11  time: 0.4944  data_time: 0.0110  memory: 5892  grad_norm: 219.4158  loss: 8.7813  decode.loss_cls: 0.1639  decode.loss_mask: 0.3692  decode.loss_dice: 0.3676  decode.d0.loss_cls: 1.1161  decode.d0.loss_mask: 0.2469  decode.d0.loss_dice: 0.3682  decode.d1.loss_cls: 0.2686  decode.d1.loss_mask: 0.2476  decode.d1.loss_dice: 0.3187  decode.d2.loss_cls: 0.2404  decode.d2.loss_mask: 0.2341  decode.d2.loss_dice: 0.3399  decode.d3.loss_cls: 0.1988  decode.d3.loss_mask: 0.2363  decode.d3.loss_dice: 0.3196  decode.d4.loss_cls: 0.1822  decode.d4.loss_mask: 0.2346  decode.d4.loss_dice: 0.3055  decode.d5.loss_cls: 0.1857  decode.d5.loss_mask: 0.2558  decode.d5.loss_dice: 0.3314  decode.d6.loss_cls: 0.2300  decode.d6.loss_mask: 0.2434  decode.d6.loss_dice: 0.3336  decode.d7.loss_cls: 0.1705  decode.d7.loss_mask: 0.2572  decode.d7.loss_dice: 0.3177  decode.d8.loss_cls: 0.1650  decode.d8.loss_mask: 0.2560  decode.d8.loss_dice: 0.2768
08/06 05:17:39 - mmengine - INFO - Iter(train) [ 22100/320000]  base_lr: 9.3763e-05 lr: 9.3763e-06  eta: 1 day, 16:37:48  time: 0.4925  data_time: 0.0107  memory: 5907  grad_norm: 153.2034  loss: 7.6532  decode.loss_cls: 0.1586  decode.loss_mask: 0.2553  decode.loss_dice: 0.2617  decode.d0.loss_cls: 0.9204  decode.d0.loss_mask: 0.2563  decode.d0.loss_dice: 0.2572  decode.d1.loss_cls: 0.2119  decode.d1.loss_mask: 0.2552  decode.d1.loss_dice: 0.2790  decode.d2.loss_cls: 0.1833  decode.d2.loss_mask: 0.2631  decode.d2.loss_dice: 0.2651  decode.d3.loss_cls: 0.1530  decode.d3.loss_mask: 0.2560  decode.d3.loss_dice: 0.2604  decode.d4.loss_cls: 0.1795  decode.d4.loss_mask: 0.2534  decode.d4.loss_dice: 0.2604  decode.d5.loss_cls: 0.1583  decode.d5.loss_mask: 0.2555  decode.d5.loss_dice: 0.2449  decode.d6.loss_cls: 0.1643  decode.d6.loss_mask: 0.2572  decode.d6.loss_dice: 0.2707  decode.d7.loss_cls: 0.1482  decode.d7.loss_mask: 0.2590  decode.d7.loss_dice: 0.2655  decode.d8.loss_cls: 0.1722  decode.d8.loss_mask: 0.2547  decode.d8.loss_dice: 0.2726
08/06 05:18:04 - mmengine - INFO - Iter(train) [ 22150/320000]  base_lr: 9.3748e-05 lr: 9.3748e-06  eta: 1 day, 16:37:24  time: 0.4925  data_time: 0.0105  memory: 5908  grad_norm: 111.4296  loss: 8.2750  decode.loss_cls: 0.2383  decode.loss_mask: 0.2185  decode.loss_dice: 0.3231  decode.d0.loss_cls: 1.2530  decode.d0.loss_mask: 0.2162  decode.d0.loss_dice: 0.3159  decode.d1.loss_cls: 0.2375  decode.d1.loss_mask: 0.2206  decode.d1.loss_dice: 0.2990  decode.d2.loss_cls: 0.1830  decode.d2.loss_mask: 0.2171  decode.d2.loss_dice: 0.3029  decode.d3.loss_cls: 0.1636  decode.d3.loss_mask: 0.2212  decode.d3.loss_dice: 0.3150  decode.d4.loss_cls: 0.1333  decode.d4.loss_mask: 0.2200  decode.d4.loss_dice: 0.3120  decode.d5.loss_cls: 0.1348  decode.d5.loss_mask: 0.2193  decode.d5.loss_dice: 0.3058  decode.d6.loss_cls: 0.1592  decode.d6.loss_mask: 0.2180  decode.d6.loss_dice: 0.3159  decode.d7.loss_cls: 0.2351  decode.d7.loss_mask: 0.2210  decode.d7.loss_dice: 0.3207  decode.d8.loss_cls: 0.2082  decode.d8.loss_mask: 0.2218  decode.d8.loss_dice: 0.3252
08/06 05:18:28 - mmengine - INFO - Iter(train) [ 22200/320000]  base_lr: 9.3734e-05 lr: 9.3734e-06  eta: 1 day, 16:37:01  time: 0.4921  data_time: 0.0104  memory: 5926  grad_norm: 205.3624  loss: 7.0748  decode.loss_cls: 0.0953  decode.loss_mask: 0.2498  decode.loss_dice: 0.2659  decode.d0.loss_cls: 0.9642  decode.d0.loss_mask: 0.2616  decode.d0.loss_dice: 0.2665  decode.d1.loss_cls: 0.1137  decode.d1.loss_mask: 0.2523  decode.d1.loss_dice: 0.2633  decode.d2.loss_cls: 0.1290  decode.d2.loss_mask: 0.2517  decode.d2.loss_dice: 0.2737  decode.d3.loss_cls: 0.0954  decode.d3.loss_mask: 0.2558  decode.d3.loss_dice: 0.2731  decode.d4.loss_cls: 0.0986  decode.d4.loss_mask: 0.2528  decode.d4.loss_dice: 0.2829  decode.d5.loss_cls: 0.0830  decode.d5.loss_mask: 0.2501  decode.d5.loss_dice: 0.2674  decode.d6.loss_cls: 0.0737  decode.d6.loss_mask: 0.2518  decode.d6.loss_dice: 0.2773  decode.d7.loss_cls: 0.0818  decode.d7.loss_mask: 0.2513  decode.d7.loss_dice: 0.2774  decode.d8.loss_cls: 0.0888  decode.d8.loss_mask: 0.2521  decode.d8.loss_dice: 0.2743
08/06 05:18:53 - mmengine - INFO - Iter(train) [ 22250/320000]  base_lr: 9.3720e-05 lr: 9.3720e-06  eta: 1 day, 16:36:37  time: 0.4928  data_time: 0.0106  memory: 5890  grad_norm: 167.2897  loss: 9.7581  decode.loss_cls: 0.1664  decode.loss_mask: 0.3407  decode.loss_dice: 0.3738  decode.d0.loss_cls: 1.0119  decode.d0.loss_mask: 0.3630  decode.d0.loss_dice: 0.3746  decode.d1.loss_cls: 0.1389  decode.d1.loss_mask: 0.3436  decode.d1.loss_dice: 0.3864  decode.d2.loss_cls: 0.2070  decode.d2.loss_mask: 0.3448  decode.d2.loss_dice: 0.3868  decode.d3.loss_cls: 0.1524  decode.d3.loss_mask: 0.3468  decode.d3.loss_dice: 0.3855  decode.d4.loss_cls: 0.1518  decode.d4.loss_mask: 0.3462  decode.d4.loss_dice: 0.3769  decode.d5.loss_cls: 0.1767  decode.d5.loss_mask: 0.3421  decode.d5.loss_dice: 0.3869  decode.d6.loss_cls: 0.1485  decode.d6.loss_mask: 0.3416  decode.d6.loss_dice: 0.3740  decode.d7.loss_cls: 0.1603  decode.d7.loss_mask: 0.3404  decode.d7.loss_dice: 0.3857  decode.d8.loss_cls: 0.1712  decode.d8.loss_mask: 0.3463  decode.d8.loss_dice: 0.3871
08/06 05:19:17 - mmengine - INFO - Iter(train) [ 22300/320000]  base_lr: 9.3706e-05 lr: 9.3706e-06  eta: 1 day, 16:36:14  time: 0.4927  data_time: 0.0107  memory: 5892  grad_norm: 183.4065  loss: 8.8149  decode.loss_cls: 0.1982  decode.loss_mask: 0.2706  decode.loss_dice: 0.2994  decode.d0.loss_cls: 0.9830  decode.d0.loss_mask: 0.2897  decode.d0.loss_dice: 0.3233  decode.d1.loss_cls: 0.3042  decode.d1.loss_mask: 0.2797  decode.d1.loss_dice: 0.3386  decode.d2.loss_cls: 0.2443  decode.d2.loss_mask: 0.2747  decode.d2.loss_dice: 0.3172  decode.d3.loss_cls: 0.1855  decode.d3.loss_mask: 0.2752  decode.d3.loss_dice: 0.2960  decode.d4.loss_cls: 0.2280  decode.d4.loss_mask: 0.2811  decode.d4.loss_dice: 0.3013  decode.d5.loss_cls: 0.2265  decode.d5.loss_mask: 0.2729  decode.d5.loss_dice: 0.3075  decode.d6.loss_cls: 0.2330  decode.d6.loss_mask: 0.2686  decode.d6.loss_dice: 0.2938  decode.d7.loss_cls: 0.1914  decode.d7.loss_mask: 0.2713  decode.d7.loss_dice: 0.2903  decode.d8.loss_cls: 0.2027  decode.d8.loss_mask: 0.2700  decode.d8.loss_dice: 0.2968
08/06 05:19:42 - mmengine - INFO - Iter(train) [ 22350/320000]  base_lr: 9.3692e-05 lr: 9.3692e-06  eta: 1 day, 16:35:50  time: 0.4927  data_time: 0.0106  memory: 5907  grad_norm: 117.3245  loss: 8.7855  decode.loss_cls: 0.2047  decode.loss_mask: 0.2893  decode.loss_dice: 0.3278  decode.d0.loss_cls: 0.7427  decode.d0.loss_mask: 0.3079  decode.d0.loss_dice: 0.3836  decode.d1.loss_cls: 0.1824  decode.d1.loss_mask: 0.2988  decode.d1.loss_dice: 0.3343  decode.d2.loss_cls: 0.1446  decode.d2.loss_mask: 0.2932  decode.d2.loss_dice: 0.3909  decode.d3.loss_cls: 0.1642  decode.d3.loss_mask: 0.2943  decode.d3.loss_dice: 0.3579  decode.d4.loss_cls: 0.1878  decode.d4.loss_mask: 0.2899  decode.d4.loss_dice: 0.3237  decode.d5.loss_cls: 0.1664  decode.d5.loss_mask: 0.2903  decode.d5.loss_dice: 0.3255  decode.d6.loss_cls: 0.1890  decode.d6.loss_mask: 0.2958  decode.d6.loss_dice: 0.3491  decode.d7.loss_cls: 0.1911  decode.d7.loss_mask: 0.2914  decode.d7.loss_dice: 0.3297  decode.d8.loss_cls: 0.2053  decode.d8.loss_mask: 0.2951  decode.d8.loss_dice: 0.3387
08/06 05:20:07 - mmengine - INFO - Iter(train) [ 22400/320000]  base_lr: 9.3678e-05 lr: 9.3678e-06  eta: 1 day, 16:35:26  time: 0.4925  data_time: 0.0104  memory: 5891  grad_norm: 108.6468  loss: 7.3791  decode.loss_cls: 0.2026  decode.loss_mask: 0.1827  decode.loss_dice: 0.2922  decode.d0.loss_cls: 0.9624  decode.d0.loss_mask: 0.1803  decode.d0.loss_dice: 0.2960  decode.d1.loss_cls: 0.2907  decode.d1.loss_mask: 0.1815  decode.d1.loss_dice: 0.2848  decode.d2.loss_cls: 0.2151  decode.d2.loss_mask: 0.1806  decode.d2.loss_dice: 0.2834  decode.d3.loss_cls: 0.2024  decode.d3.loss_mask: 0.1790  decode.d3.loss_dice: 0.2837  decode.d4.loss_cls: 0.1359  decode.d4.loss_mask: 0.1800  decode.d4.loss_dice: 0.2965  decode.d5.loss_cls: 0.1434  decode.d5.loss_mask: 0.1796  decode.d5.loss_dice: 0.3078  decode.d6.loss_cls: 0.1303  decode.d6.loss_mask: 0.1797  decode.d6.loss_dice: 0.2966  decode.d7.loss_cls: 0.1839  decode.d7.loss_mask: 0.1816  decode.d7.loss_dice: 0.2931  decode.d8.loss_cls: 0.1814  decode.d8.loss_mask: 0.1818  decode.d8.loss_dice: 0.2901
08/06 05:20:31 - mmengine - INFO - Iter(train) [ 22450/320000]  base_lr: 9.3663e-05 lr: 9.3663e-06  eta: 1 day, 16:35:04  time: 0.4924  data_time: 0.0107  memory: 5891  grad_norm: 129.4985  loss: 7.8031  decode.loss_cls: 0.1842  decode.loss_mask: 0.2398  decode.loss_dice: 0.2627  decode.d0.loss_cls: 0.8001  decode.d0.loss_mask: 0.2442  decode.d0.loss_dice: 0.2839  decode.d1.loss_cls: 0.1788  decode.d1.loss_mask: 0.2424  decode.d1.loss_dice: 0.2655  decode.d2.loss_cls: 0.2892  decode.d2.loss_mask: 0.2416  decode.d2.loss_dice: 0.2577  decode.d3.loss_cls: 0.2306  decode.d3.loss_mask: 0.2374  decode.d3.loss_dice: 0.2565  decode.d4.loss_cls: 0.1802  decode.d4.loss_mask: 0.2429  decode.d4.loss_dice: 0.2616  decode.d5.loss_cls: 0.2287  decode.d5.loss_mask: 0.2393  decode.d5.loss_dice: 0.2552  decode.d6.loss_cls: 0.1983  decode.d6.loss_mask: 0.2374  decode.d6.loss_dice: 0.2581  decode.d7.loss_cls: 0.2200  decode.d7.loss_mask: 0.2415  decode.d7.loss_dice: 0.2647  decode.d8.loss_cls: 0.2653  decode.d8.loss_mask: 0.2377  decode.d8.loss_dice: 0.2576
08/06 05:20:56 - mmengine - INFO - Iter(train) [ 22500/320000]  base_lr: 9.3649e-05 lr: 9.3649e-06  eta: 1 day, 16:34:40  time: 0.4913  data_time: 0.0108  memory: 5908  grad_norm: 134.2782  loss: 7.9623  decode.loss_cls: 0.1216  decode.loss_mask: 0.2869  decode.loss_dice: 0.2609  decode.d0.loss_cls: 0.8717  decode.d0.loss_mask: 0.2797  decode.d0.loss_dice: 0.2663  decode.d1.loss_cls: 0.2821  decode.d1.loss_mask: 0.2755  decode.d1.loss_dice: 0.2524  decode.d2.loss_cls: 0.2469  decode.d2.loss_mask: 0.2721  decode.d2.loss_dice: 0.2720  decode.d3.loss_cls: 0.2144  decode.d3.loss_mask: 0.2781  decode.d3.loss_dice: 0.2721  decode.d4.loss_cls: 0.2000  decode.d4.loss_mask: 0.2753  decode.d4.loss_dice: 0.2655  decode.d5.loss_cls: 0.1827  decode.d5.loss_mask: 0.2996  decode.d5.loss_dice: 0.2784  decode.d6.loss_cls: 0.1918  decode.d6.loss_mask: 0.2815  decode.d6.loss_dice: 0.2524  decode.d7.loss_cls: 0.0946  decode.d7.loss_mask: 0.2831  decode.d7.loss_dice: 0.2459  decode.d8.loss_cls: 0.1394  decode.d8.loss_mask: 0.2819  decode.d8.loss_dice: 0.2374
08/06 05:21:21 - mmengine - INFO - Iter(train) [ 22550/320000]  base_lr: 9.3635e-05 lr: 9.3635e-06  eta: 1 day, 16:34:16  time: 0.4923  data_time: 0.0106  memory: 5892  grad_norm: 200.2337  loss: 9.4011  decode.loss_cls: 0.3093  decode.loss_mask: 0.2455  decode.loss_dice: 0.3011  decode.d0.loss_cls: 1.0802  decode.d0.loss_mask: 0.2596  decode.d0.loss_dice: 0.3336  decode.d1.loss_cls: 0.3757  decode.d1.loss_mask: 0.2472  decode.d1.loss_dice: 0.3004  decode.d2.loss_cls: 0.3119  decode.d2.loss_mask: 0.2471  decode.d2.loss_dice: 0.3026  decode.d3.loss_cls: 0.3581  decode.d3.loss_mask: 0.2381  decode.d3.loss_dice: 0.2924  decode.d4.loss_cls: 0.3099  decode.d4.loss_mask: 0.2458  decode.d4.loss_dice: 0.2988  decode.d5.loss_cls: 0.3093  decode.d5.loss_mask: 0.2458  decode.d5.loss_dice: 0.2945  decode.d6.loss_cls: 0.3143  decode.d6.loss_mask: 0.2449  decode.d6.loss_dice: 0.2956  decode.d7.loss_cls: 0.2875  decode.d7.loss_mask: 0.2416  decode.d7.loss_dice: 0.2934  decode.d8.loss_cls: 0.2786  decode.d8.loss_mask: 0.2422  decode.d8.loss_dice: 0.2964
08/06 05:21:45 - mmengine - INFO - Iter(train) [ 22600/320000]  base_lr: 9.3621e-05 lr: 9.3621e-06  eta: 1 day, 16:33:52  time: 0.4921  data_time: 0.0109  memory: 5908  grad_norm: 95.8160  loss: 7.9030  decode.loss_cls: 0.2101  decode.loss_mask: 0.2560  decode.loss_dice: 0.2377  decode.d0.loss_cls: 0.9492  decode.d0.loss_mask: 0.2531  decode.d0.loss_dice: 0.2396  decode.d1.loss_cls: 0.2417  decode.d1.loss_mask: 0.2580  decode.d1.loss_dice: 0.2468  decode.d2.loss_cls: 0.2104  decode.d2.loss_mask: 0.2548  decode.d2.loss_dice: 0.2433  decode.d3.loss_cls: 0.2016  decode.d3.loss_mask: 0.2511  decode.d3.loss_dice: 0.2411  decode.d4.loss_cls: 0.2146  decode.d4.loss_mask: 0.2538  decode.d4.loss_dice: 0.2429  decode.d5.loss_cls: 0.2282  decode.d5.loss_mask: 0.2522  decode.d5.loss_dice: 0.2470  decode.d6.loss_cls: 0.2442  decode.d6.loss_mask: 0.2511  decode.d6.loss_dice: 0.2407  decode.d7.loss_cls: 0.2228  decode.d7.loss_mask: 0.2481  decode.d7.loss_dice: 0.2481  decode.d8.loss_cls: 0.2191  decode.d8.loss_mask: 0.2496  decode.d8.loss_dice: 0.2463
08/06 05:22:10 - mmengine - INFO - Iter(train) [ 22650/320000]  base_lr: 9.3607e-05 lr: 9.3607e-06  eta: 1 day, 16:33:28  time: 0.4915  data_time: 0.0107  memory: 5980  grad_norm: 227.1324  loss: 8.0593  decode.loss_cls: 0.0773  decode.loss_mask: 0.2688  decode.loss_dice: 0.3603  decode.d0.loss_cls: 1.0067  decode.d0.loss_mask: 0.2676  decode.d0.loss_dice: 0.3291  decode.d1.loss_cls: 0.2537  decode.d1.loss_mask: 0.2590  decode.d1.loss_dice: 0.3151  decode.d2.loss_cls: 0.1460  decode.d2.loss_mask: 0.2578  decode.d2.loss_dice: 0.3110  decode.d3.loss_cls: 0.0917  decode.d3.loss_mask: 0.2603  decode.d3.loss_dice: 0.3342  decode.d4.loss_cls: 0.1272  decode.d4.loss_mask: 0.2599  decode.d4.loss_dice: 0.3338  decode.d5.loss_cls: 0.1029  decode.d5.loss_mask: 0.2619  decode.d5.loss_dice: 0.3413  decode.d6.loss_cls: 0.1232  decode.d6.loss_mask: 0.2609  decode.d6.loss_dice: 0.3316  decode.d7.loss_cls: 0.0925  decode.d7.loss_mask: 0.2588  decode.d7.loss_dice: 0.3420  decode.d8.loss_cls: 0.1062  decode.d8.loss_mask: 0.2600  decode.d8.loss_dice: 0.3186
08/06 05:22:34 - mmengine - INFO - Iter(train) [ 22700/320000]  base_lr: 9.3593e-05 lr: 9.3593e-06  eta: 1 day, 16:33:04  time: 0.4920  data_time: 0.0106  memory: 5890  grad_norm: 129.7326  loss: 8.1933  decode.loss_cls: 0.1553  decode.loss_mask: 0.2628  decode.loss_dice: 0.3196  decode.d0.loss_cls: 0.7865  decode.d0.loss_mask: 0.2740  decode.d0.loss_dice: 0.3484  decode.d1.loss_cls: 0.2035  decode.d1.loss_mask: 0.2659  decode.d1.loss_dice: 0.3164  decode.d2.loss_cls: 0.1980  decode.d2.loss_mask: 0.2663  decode.d2.loss_dice: 0.3060  decode.d3.loss_cls: 0.2032  decode.d3.loss_mask: 0.2665  decode.d3.loss_dice: 0.2946  decode.d4.loss_cls: 0.2067  decode.d4.loss_mask: 0.2648  decode.d4.loss_dice: 0.3133  decode.d5.loss_cls: 0.1598  decode.d5.loss_mask: 0.2599  decode.d5.loss_dice: 0.3130  decode.d6.loss_cls: 0.1804  decode.d6.loss_mask: 0.2663  decode.d6.loss_dice: 0.3123  decode.d7.loss_cls: 0.1624  decode.d7.loss_mask: 0.2644  decode.d7.loss_dice: 0.3233  decode.d8.loss_cls: 0.1227  decode.d8.loss_mask: 0.2630  decode.d8.loss_dice: 0.3141
08/06 05:22:59 - mmengine - INFO - Iter(train) [ 22750/320000]  base_lr: 9.3578e-05 lr: 9.3578e-06  eta: 1 day, 16:32:40  time: 0.4915  data_time: 0.0110  memory: 5891  grad_norm: 264.9238  loss: 9.2893  decode.loss_cls: 0.1773  decode.loss_mask: 0.3030  decode.loss_dice: 0.3067  decode.d0.loss_cls: 1.0047  decode.d0.loss_mask: 0.3208  decode.d0.loss_dice: 0.3804  decode.d1.loss_cls: 0.1801  decode.d1.loss_mask: 0.3453  decode.d1.loss_dice: 0.3421  decode.d2.loss_cls: 0.2268  decode.d2.loss_mask: 0.3224  decode.d2.loss_dice: 0.3183  decode.d3.loss_cls: 0.1868  decode.d3.loss_mask: 0.3287  decode.d3.loss_dice: 0.3354  decode.d4.loss_cls: 0.1919  decode.d4.loss_mask: 0.3475  decode.d4.loss_dice: 0.3294  decode.d5.loss_cls: 0.2286  decode.d5.loss_mask: 0.3020  decode.d5.loss_dice: 0.3381  decode.d6.loss_cls: 0.1845  decode.d6.loss_mask: 0.3069  decode.d6.loss_dice: 0.3451  decode.d7.loss_cls: 0.1639  decode.d7.loss_mask: 0.3034  decode.d7.loss_dice: 0.3422  decode.d8.loss_cls: 0.1907  decode.d8.loss_mask: 0.2980  decode.d8.loss_dice: 0.3384
08/06 05:23:24 - mmengine - INFO - Iter(train) [ 22800/320000]  base_lr: 9.3564e-05 lr: 9.3564e-06  eta: 1 day, 16:32:16  time: 0.4920  data_time: 0.0109  memory: 5892  grad_norm: 81.0237  loss: 7.7314  decode.loss_cls: 0.1438  decode.loss_mask: 0.2287  decode.loss_dice: 0.3046  decode.d0.loss_cls: 0.8979  decode.d0.loss_mask: 0.2375  decode.d0.loss_dice: 0.3261  decode.d1.loss_cls: 0.2490  decode.d1.loss_mask: 0.2317  decode.d1.loss_dice: 0.2880  decode.d2.loss_cls: 0.1844  decode.d2.loss_mask: 0.2371  decode.d2.loss_dice: 0.2982  decode.d3.loss_cls: 0.1581  decode.d3.loss_mask: 0.2524  decode.d3.loss_dice: 0.3102  decode.d4.loss_cls: 0.1358  decode.d4.loss_mask: 0.2313  decode.d4.loss_dice: 0.3034  decode.d5.loss_cls: 0.1639  decode.d5.loss_mask: 0.2332  decode.d5.loss_dice: 0.2877  decode.d6.loss_cls: 0.1689  decode.d6.loss_mask: 0.2313  decode.d6.loss_dice: 0.2898  decode.d7.loss_cls: 0.1361  decode.d7.loss_mask: 0.2326  decode.d7.loss_dice: 0.3032  decode.d8.loss_cls: 0.1345  decode.d8.loss_mask: 0.2303  decode.d8.loss_dice: 0.3019
08/06 05:23:48 - mmengine - INFO - Iter(train) [ 22850/320000]  base_lr: 9.3550e-05 lr: 9.3550e-06  eta: 1 day, 16:31:52  time: 0.4914  data_time: 0.0108  memory: 5892  grad_norm: 74.8045  loss: 6.5714  decode.loss_cls: 0.1081  decode.loss_mask: 0.2252  decode.loss_dice: 0.2490  decode.d0.loss_cls: 0.9153  decode.d0.loss_mask: 0.2310  decode.d0.loss_dice: 0.2773  decode.d1.loss_cls: 0.1058  decode.d1.loss_mask: 0.2288  decode.d1.loss_dice: 0.2600  decode.d2.loss_cls: 0.1337  decode.d2.loss_mask: 0.2205  decode.d2.loss_dice: 0.2441  decode.d3.loss_cls: 0.1045  decode.d3.loss_mask: 0.2183  decode.d3.loss_dice: 0.2495  decode.d4.loss_cls: 0.1082  decode.d4.loss_mask: 0.2290  decode.d4.loss_dice: 0.2478  decode.d5.loss_cls: 0.1074  decode.d5.loss_mask: 0.2206  decode.d5.loss_dice: 0.2425  decode.d6.loss_cls: 0.0795  decode.d6.loss_mask: 0.2231  decode.d6.loss_dice: 0.2411  decode.d7.loss_cls: 0.0740  decode.d7.loss_mask: 0.2230  decode.d7.loss_dice: 0.2435  decode.d8.loss_cls: 0.0948  decode.d8.loss_mask: 0.2217  decode.d8.loss_dice: 0.2439
08/06 05:24:13 - mmengine - INFO - Iter(train) [ 22900/320000]  base_lr: 9.3536e-05 lr: 9.3536e-06  eta: 1 day, 16:31:28  time: 0.4910  data_time: 0.0106  memory: 5927  grad_norm: 252.6072  loss: 9.5077  decode.loss_cls: 0.2938  decode.loss_mask: 0.2723  decode.loss_dice: 0.3512  decode.d0.loss_cls: 0.9188  decode.d0.loss_mask: 0.2774  decode.d0.loss_dice: 0.3710  decode.d1.loss_cls: 0.2953  decode.d1.loss_mask: 0.2752  decode.d1.loss_dice: 0.3396  decode.d2.loss_cls: 0.2442  decode.d2.loss_mask: 0.2722  decode.d2.loss_dice: 0.3401  decode.d3.loss_cls: 0.2547  decode.d3.loss_mask: 0.2678  decode.d3.loss_dice: 0.2980  decode.d4.loss_cls: 0.2534  decode.d4.loss_mask: 0.2693  decode.d4.loss_dice: 0.3305  decode.d5.loss_cls: 0.2531  decode.d5.loss_mask: 0.2750  decode.d5.loss_dice: 0.3454  decode.d6.loss_cls: 0.2733  decode.d6.loss_mask: 0.2698  decode.d6.loss_dice: 0.3288  decode.d7.loss_cls: 0.3000  decode.d7.loss_mask: 0.2899  decode.d7.loss_dice: 0.3389  decode.d8.loss_cls: 0.2751  decode.d8.loss_mask: 0.2914  decode.d8.loss_dice: 0.3419
08/06 05:24:38 - mmengine - INFO - Iter(train) [ 22950/320000]  base_lr: 9.3522e-05 lr: 9.3522e-06  eta: 1 day, 16:31:06  time: 0.4928  data_time: 0.0107  memory: 5926  grad_norm: 82.4553  loss: 8.5325  decode.loss_cls: 0.2466  decode.loss_mask: 0.2325  decode.loss_dice: 0.2849  decode.d0.loss_cls: 1.0983  decode.d0.loss_mask: 0.2371  decode.d0.loss_dice: 0.2713  decode.d1.loss_cls: 0.3091  decode.d1.loss_mask: 0.2263  decode.d1.loss_dice: 0.2821  decode.d2.loss_cls: 0.2385  decode.d2.loss_mask: 0.2281  decode.d2.loss_dice: 0.2738  decode.d3.loss_cls: 0.2735  decode.d3.loss_mask: 0.2344  decode.d3.loss_dice: 0.2689  decode.d4.loss_cls: 0.2437  decode.d4.loss_mask: 0.2356  decode.d4.loss_dice: 0.2873  decode.d5.loss_cls: 0.2617  decode.d5.loss_mask: 0.2393  decode.d5.loss_dice: 0.3073  decode.d6.loss_cls: 0.2622  decode.d6.loss_mask: 0.2299  decode.d6.loss_dice: 0.2919  decode.d7.loss_cls: 0.2105  decode.d7.loss_mask: 0.2349  decode.d7.loss_dice: 0.2803  decode.d8.loss_cls: 0.2154  decode.d8.loss_mask: 0.2277  decode.d8.loss_dice: 0.2995
08/06 05:25:02 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 05:25:02 - mmengine - INFO - Iter(train) [ 23000/320000]  base_lr: 9.3508e-05 lr: 9.3508e-06  eta: 1 day, 16:30:42  time: 0.4929  data_time: 0.0107  memory: 5909  grad_norm: 85.8337  loss: 8.3371  decode.loss_cls: 0.1319  decode.loss_mask: 0.3002  decode.loss_dice: 0.2964  decode.d0.loss_cls: 0.9453  decode.d0.loss_mask: 0.3239  decode.d0.loss_dice: 0.3036  decode.d1.loss_cls: 0.1796  decode.d1.loss_mask: 0.3039  decode.d1.loss_dice: 0.2798  decode.d2.loss_cls: 0.1456  decode.d2.loss_mask: 0.3019  decode.d2.loss_dice: 0.2832  decode.d3.loss_cls: 0.2136  decode.d3.loss_mask: 0.2883  decode.d3.loss_dice: 0.2769  decode.d4.loss_cls: 0.1514  decode.d4.loss_mask: 0.3159  decode.d4.loss_dice: 0.2877  decode.d5.loss_cls: 0.1420  decode.d5.loss_mask: 0.3048  decode.d5.loss_dice: 0.2941  decode.d6.loss_cls: 0.1460  decode.d6.loss_mask: 0.3256  decode.d6.loss_dice: 0.2818  decode.d7.loss_cls: 0.1456  decode.d7.loss_mask: 0.3273  decode.d7.loss_dice: 0.2897  decode.d8.loss_cls: 0.1542  decode.d8.loss_mask: 0.3018  decode.d8.loss_dice: 0.2950
08/06 05:25:27 - mmengine - INFO - Iter(train) [ 23050/320000]  base_lr: 9.3493e-05 lr: 9.3493e-06  eta: 1 day, 16:30:18  time: 0.4926  data_time: 0.0109  memory: 5907  grad_norm: 110.6685  loss: 6.8648  decode.loss_cls: 0.0905  decode.loss_mask: 0.2336  decode.loss_dice: 0.2394  decode.d0.loss_cls: 0.8474  decode.d0.loss_mask: 0.2441  decode.d0.loss_dice: 0.2706  decode.d1.loss_cls: 0.2509  decode.d1.loss_mask: 0.2357  decode.d1.loss_dice: 0.2415  decode.d2.loss_cls: 0.1724  decode.d2.loss_mask: 0.2312  decode.d2.loss_dice: 0.2401  decode.d3.loss_cls: 0.1270  decode.d3.loss_mask: 0.2315  decode.d3.loss_dice: 0.2475  decode.d4.loss_cls: 0.1155  decode.d4.loss_mask: 0.2355  decode.d4.loss_dice: 0.2413  decode.d5.loss_cls: 0.1453  decode.d5.loss_mask: 0.2322  decode.d5.loss_dice: 0.2420  decode.d6.loss_cls: 0.1430  decode.d6.loss_mask: 0.2323  decode.d6.loss_dice: 0.2412  decode.d7.loss_cls: 0.0930  decode.d7.loss_mask: 0.2311  decode.d7.loss_dice: 0.2386  decode.d8.loss_cls: 0.0930  decode.d8.loss_mask: 0.2341  decode.d8.loss_dice: 0.2436
08/06 05:25:51 - mmengine - INFO - Iter(train) [ 23100/320000]  base_lr: 9.3479e-05 lr: 9.3479e-06  eta: 1 day, 16:29:54  time: 0.4909  data_time: 0.0106  memory: 5891  grad_norm: 116.6865  loss: 7.5120  decode.loss_cls: 0.1222  decode.loss_mask: 0.2212  decode.loss_dice: 0.2929  decode.d0.loss_cls: 1.0093  decode.d0.loss_mask: 0.2298  decode.d0.loss_dice: 0.3176  decode.d1.loss_cls: 0.1770  decode.d1.loss_mask: 0.2302  decode.d1.loss_dice: 0.3144  decode.d2.loss_cls: 0.1385  decode.d2.loss_mask: 0.2275  decode.d2.loss_dice: 0.3041  decode.d3.loss_cls: 0.1502  decode.d3.loss_mask: 0.2197  decode.d3.loss_dice: 0.2860  decode.d4.loss_cls: 0.1637  decode.d4.loss_mask: 0.2197  decode.d4.loss_dice: 0.2877  decode.d5.loss_cls: 0.1413  decode.d5.loss_mask: 0.2213  decode.d5.loss_dice: 0.2944  decode.d6.loss_cls: 0.1501  decode.d6.loss_mask: 0.2198  decode.d6.loss_dice: 0.2796  decode.d7.loss_cls: 0.1567  decode.d7.loss_mask: 0.2184  decode.d7.loss_dice: 0.2888  decode.d8.loss_cls: 0.1011  decode.d8.loss_mask: 0.2257  decode.d8.loss_dice: 0.3029
08/06 05:26:16 - mmengine - INFO - Iter(train) [ 23150/320000]  base_lr: 9.3465e-05 lr: 9.3465e-06  eta: 1 day, 16:29:31  time: 0.4918  data_time: 0.0107  memory: 5892  grad_norm: 67.5712  loss: 7.3104  decode.loss_cls: 0.1322  decode.loss_mask: 0.2284  decode.loss_dice: 0.2849  decode.d0.loss_cls: 0.8497  decode.d0.loss_mask: 0.2209  decode.d0.loss_dice: 0.2885  decode.d1.loss_cls: 0.1592  decode.d1.loss_mask: 0.2188  decode.d1.loss_dice: 0.2914  decode.d2.loss_cls: 0.2056  decode.d2.loss_mask: 0.2199  decode.d2.loss_dice: 0.2877  decode.d3.loss_cls: 0.1767  decode.d3.loss_mask: 0.2272  decode.d3.loss_dice: 0.2837  decode.d4.loss_cls: 0.1347  decode.d4.loss_mask: 0.2239  decode.d4.loss_dice: 0.2996  decode.d5.loss_cls: 0.1239  decode.d5.loss_mask: 0.2272  decode.d5.loss_dice: 0.2897  decode.d6.loss_cls: 0.0973  decode.d6.loss_mask: 0.2229  decode.d6.loss_dice: 0.2864  decode.d7.loss_cls: 0.1644  decode.d7.loss_mask: 0.2201  decode.d7.loss_dice: 0.2851  decode.d8.loss_cls: 0.1477  decode.d8.loss_mask: 0.2297  decode.d8.loss_dice: 0.2832
08/06 05:26:41 - mmengine - INFO - Iter(train) [ 23200/320000]  base_lr: 9.3451e-05 lr: 9.3451e-06  eta: 1 day, 16:29:07  time: 0.4923  data_time: 0.0108  memory: 5890  grad_norm: 107.1518  loss: 7.9807  decode.loss_cls: 0.1710  decode.loss_mask: 0.2324  decode.loss_dice: 0.2966  decode.d0.loss_cls: 1.0136  decode.d0.loss_mask: 0.2495  decode.d0.loss_dice: 0.2965  decode.d1.loss_cls: 0.1931  decode.d1.loss_mask: 0.2327  decode.d1.loss_dice: 0.2934  decode.d2.loss_cls: 0.1778  decode.d2.loss_mask: 0.2326  decode.d2.loss_dice: 0.2801  decode.d3.loss_cls: 0.1602  decode.d3.loss_mask: 0.2337  decode.d3.loss_dice: 0.3001  decode.d4.loss_cls: 0.1938  decode.d4.loss_mask: 0.2323  decode.d4.loss_dice: 0.2910  decode.d5.loss_cls: 0.2246  decode.d5.loss_mask: 0.2335  decode.d5.loss_dice: 0.3016  decode.d6.loss_cls: 0.1858  decode.d6.loss_mask: 0.2303  decode.d6.loss_dice: 0.2944  decode.d7.loss_cls: 0.1984  decode.d7.loss_mask: 0.2315  decode.d7.loss_dice: 0.2971  decode.d8.loss_cls: 0.1970  decode.d8.loss_mask: 0.2290  decode.d8.loss_dice: 0.2772
08/06 05:27:05 - mmengine - INFO - Iter(train) [ 23250/320000]  base_lr: 9.3437e-05 lr: 9.3437e-06  eta: 1 day, 16:28:45  time: 0.4921  data_time: 0.0105  memory: 5888  grad_norm: 113.2350  loss: 8.6988  decode.loss_cls: 0.2240  decode.loss_mask: 0.2752  decode.loss_dice: 0.3088  decode.d0.loss_cls: 1.0057  decode.d0.loss_mask: 0.2749  decode.d0.loss_dice: 0.2879  decode.d1.loss_cls: 0.2344  decode.d1.loss_mask: 0.2772  decode.d1.loss_dice: 0.2911  decode.d2.loss_cls: 0.2286  decode.d2.loss_mask: 0.2779  decode.d2.loss_dice: 0.3069  decode.d3.loss_cls: 0.2131  decode.d3.loss_mask: 0.2781  decode.d3.loss_dice: 0.3132  decode.d4.loss_cls: 0.2284  decode.d4.loss_mask: 0.2790  decode.d4.loss_dice: 0.2886  decode.d5.loss_cls: 0.2333  decode.d5.loss_mask: 0.2834  decode.d5.loss_dice: 0.3138  decode.d6.loss_cls: 0.1842  decode.d6.loss_mask: 0.2774  decode.d6.loss_dice: 0.2790  decode.d7.loss_cls: 0.1734  decode.d7.loss_mask: 0.2777  decode.d7.loss_dice: 0.3034  decode.d8.loss_cls: 0.1861  decode.d8.loss_mask: 0.2773  decode.d8.loss_dice: 0.3169
08/06 05:27:30 - mmengine - INFO - Iter(train) [ 23300/320000]  base_lr: 9.3423e-05 lr: 9.3423e-06  eta: 1 day, 16:28:21  time: 0.4928  data_time: 0.0107  memory: 5891  grad_norm: 134.5297  loss: 9.2644  decode.loss_cls: 0.2172  decode.loss_mask: 0.2625  decode.loss_dice: 0.3283  decode.d0.loss_cls: 1.1584  decode.d0.loss_mask: 0.2720  decode.d0.loss_dice: 0.3673  decode.d1.loss_cls: 0.3704  decode.d1.loss_mask: 0.2601  decode.d1.loss_dice: 0.3001  decode.d2.loss_cls: 0.3259  decode.d2.loss_mask: 0.2571  decode.d2.loss_dice: 0.3250  decode.d3.loss_cls: 0.1991  decode.d3.loss_mask: 0.2548  decode.d3.loss_dice: 0.3059  decode.d4.loss_cls: 0.2510  decode.d4.loss_mask: 0.2543  decode.d4.loss_dice: 0.3052  decode.d5.loss_cls: 0.2318  decode.d5.loss_mask: 0.2589  decode.d5.loss_dice: 0.3162  decode.d6.loss_cls: 0.2460  decode.d6.loss_mask: 0.2556  decode.d6.loss_dice: 0.3105  decode.d7.loss_cls: 0.2245  decode.d7.loss_mask: 0.2617  decode.d7.loss_dice: 0.3164  decode.d8.loss_cls: 0.2425  decode.d8.loss_mask: 0.2619  decode.d8.loss_dice: 0.3241
08/06 05:27:55 - mmengine - INFO - Iter(train) [ 23350/320000]  base_lr: 9.3408e-05 lr: 9.3408e-06  eta: 1 day, 16:27:57  time: 0.4924  data_time: 0.0109  memory: 5908  grad_norm: 80.5883  loss: 8.2276  decode.loss_cls: 0.2194  decode.loss_mask: 0.2600  decode.loss_dice: 0.2623  decode.d0.loss_cls: 0.9239  decode.d0.loss_mask: 0.2611  decode.d0.loss_dice: 0.2927  decode.d1.loss_cls: 0.2618  decode.d1.loss_mask: 0.2582  decode.d1.loss_dice: 0.2835  decode.d2.loss_cls: 0.1771  decode.d2.loss_mask: 0.2609  decode.d2.loss_dice: 0.2702  decode.d3.loss_cls: 0.1827  decode.d3.loss_mask: 0.2633  decode.d3.loss_dice: 0.2729  decode.d4.loss_cls: 0.1977  decode.d4.loss_mask: 0.2609  decode.d4.loss_dice: 0.2743  decode.d5.loss_cls: 0.1940  decode.d5.loss_mask: 0.2601  decode.d5.loss_dice: 0.2711  decode.d6.loss_cls: 0.2431  decode.d6.loss_mask: 0.2584  decode.d6.loss_dice: 0.2718  decode.d7.loss_cls: 0.2379  decode.d7.loss_mask: 0.2618  decode.d7.loss_dice: 0.2712  decode.d8.loss_cls: 0.2356  decode.d8.loss_mask: 0.2671  decode.d8.loss_dice: 0.2730
08/06 05:28:19 - mmengine - INFO - Iter(train) [ 23400/320000]  base_lr: 9.3394e-05 lr: 9.3394e-06  eta: 1 day, 16:27:33  time: 0.4923  data_time: 0.0107  memory: 5889  grad_norm: 155.3979  loss: 8.2164  decode.loss_cls: 0.2134  decode.loss_mask: 0.2056  decode.loss_dice: 0.2633  decode.d0.loss_cls: 1.0785  decode.d0.loss_mask: 0.2287  decode.d0.loss_dice: 0.2991  decode.d1.loss_cls: 0.2864  decode.d1.loss_mask: 0.2286  decode.d1.loss_dice: 0.2595  decode.d2.loss_cls: 0.3247  decode.d2.loss_mask: 0.2046  decode.d2.loss_dice: 0.2639  decode.d3.loss_cls: 0.2348  decode.d3.loss_mask: 0.2227  decode.d3.loss_dice: 0.2653  decode.d4.loss_cls: 0.3418  decode.d4.loss_mask: 0.2105  decode.d4.loss_dice: 0.2663  decode.d5.loss_cls: 0.1782  decode.d5.loss_mask: 0.2259  decode.d5.loss_dice: 0.2597  decode.d6.loss_cls: 0.1924  decode.d6.loss_mask: 0.2256  decode.d6.loss_dice: 0.2656  decode.d7.loss_cls: 0.2680  decode.d7.loss_mask: 0.2057  decode.d7.loss_dice: 0.2605  decode.d8.loss_cls: 0.2964  decode.d8.loss_mask: 0.2028  decode.d8.loss_dice: 0.2380
08/06 05:28:44 - mmengine - INFO - Iter(train) [ 23450/320000]  base_lr: 9.3380e-05 lr: 9.3380e-06  eta: 1 day, 16:27:09  time: 0.4926  data_time: 0.0106  memory: 5927  grad_norm: 211.6652  loss: 9.0319  decode.loss_cls: 0.2374  decode.loss_mask: 0.2650  decode.loss_dice: 0.3443  decode.d0.loss_cls: 0.9602  decode.d0.loss_mask: 0.2887  decode.d0.loss_dice: 0.3900  decode.d1.loss_cls: 0.2639  decode.d1.loss_mask: 0.2718  decode.d1.loss_dice: 0.3507  decode.d2.loss_cls: 0.1980  decode.d2.loss_mask: 0.2717  decode.d2.loss_dice: 0.3741  decode.d3.loss_cls: 0.1749  decode.d3.loss_mask: 0.2743  decode.d3.loss_dice: 0.3419  decode.d4.loss_cls: 0.2005  decode.d4.loss_mask: 0.2675  decode.d4.loss_dice: 0.3416  decode.d5.loss_cls: 0.1533  decode.d5.loss_mask: 0.2696  decode.d5.loss_dice: 0.3551  decode.d6.loss_cls: 0.1745  decode.d6.loss_mask: 0.2700  decode.d6.loss_dice: 0.3588  decode.d7.loss_cls: 0.2069  decode.d7.loss_mask: 0.2672  decode.d7.loss_dice: 0.3581  decode.d8.loss_cls: 0.1818  decode.d8.loss_mask: 0.2685  decode.d8.loss_dice: 0.3519
08/06 05:29:08 - mmengine - INFO - Iter(train) [ 23500/320000]  base_lr: 9.3366e-05 lr: 9.3366e-06  eta: 1 day, 16:26:46  time: 0.4912  data_time: 0.0105  memory: 5908  grad_norm: 126.2051  loss: 9.2287  decode.loss_cls: 0.3096  decode.loss_mask: 0.2582  decode.loss_dice: 0.2664  decode.d0.loss_cls: 0.9132  decode.d0.loss_mask: 0.2681  decode.d0.loss_dice: 0.2733  decode.d1.loss_cls: 0.3348  decode.d1.loss_mask: 0.2595  decode.d1.loss_dice: 0.2838  decode.d2.loss_cls: 0.3194  decode.d2.loss_mask: 0.2613  decode.d2.loss_dice: 0.2892  decode.d3.loss_cls: 0.3277  decode.d3.loss_mask: 0.2630  decode.d3.loss_dice: 0.2817  decode.d4.loss_cls: 0.2948  decode.d4.loss_mask: 0.2600  decode.d4.loss_dice: 0.2548  decode.d5.loss_cls: 0.3166  decode.d5.loss_mask: 0.2566  decode.d5.loss_dice: 0.2946  decode.d6.loss_cls: 0.2952  decode.d6.loss_mask: 0.2575  decode.d6.loss_dice: 0.2475  decode.d7.loss_cls: 0.3755  decode.d7.loss_mask: 0.2569  decode.d7.loss_dice: 0.2838  decode.d8.loss_cls: 0.3653  decode.d8.loss_mask: 0.2614  decode.d8.loss_dice: 0.2989
08/06 05:29:33 - mmengine - INFO - Iter(train) [ 23550/320000]  base_lr: 9.3352e-05 lr: 9.3352e-06  eta: 1 day, 16:26:22  time: 0.4930  data_time: 0.0107  memory: 5892  grad_norm: 121.6422  loss: 9.3983  decode.loss_cls: 0.2987  decode.loss_mask: 0.2883  decode.loss_dice: 0.3234  decode.d0.loss_cls: 0.9549  decode.d0.loss_mask: 0.2897  decode.d0.loss_dice: 0.3356  decode.d1.loss_cls: 0.3310  decode.d1.loss_mask: 0.2761  decode.d1.loss_dice: 0.3136  decode.d2.loss_cls: 0.2977  decode.d2.loss_mask: 0.2741  decode.d2.loss_dice: 0.3134  decode.d3.loss_cls: 0.2487  decode.d3.loss_mask: 0.2760  decode.d3.loss_dice: 0.3116  decode.d4.loss_cls: 0.2618  decode.d4.loss_mask: 0.2742  decode.d4.loss_dice: 0.3060  decode.d5.loss_cls: 0.2525  decode.d5.loss_mask: 0.2738  decode.d5.loss_dice: 0.3236  decode.d6.loss_cls: 0.2112  decode.d6.loss_mask: 0.2829  decode.d6.loss_dice: 0.3394  decode.d7.loss_cls: 0.2540  decode.d7.loss_mask: 0.2810  decode.d7.loss_dice: 0.3291  decode.d8.loss_cls: 0.2734  decode.d8.loss_mask: 0.2878  decode.d8.loss_dice: 0.3147
08/06 05:29:58 - mmengine - INFO - Iter(train) [ 23600/320000]  base_lr: 9.3338e-05 lr: 9.3338e-06  eta: 1 day, 16:25:58  time: 0.4921  data_time: 0.0109  memory: 5858  grad_norm: 161.9536  loss: 8.7066  decode.loss_cls: 0.1353  decode.loss_mask: 0.3509  decode.loss_dice: 0.3080  decode.d0.loss_cls: 0.9304  decode.d0.loss_mask: 0.3582  decode.d0.loss_dice: 0.3357  decode.d1.loss_cls: 0.1142  decode.d1.loss_mask: 0.3487  decode.d1.loss_dice: 0.3142  decode.d2.loss_cls: 0.1362  decode.d2.loss_mask: 0.3487  decode.d2.loss_dice: 0.3052  decode.d3.loss_cls: 0.1378  decode.d3.loss_mask: 0.3479  decode.d3.loss_dice: 0.3105  decode.d4.loss_cls: 0.0894  decode.d4.loss_mask: 0.3600  decode.d4.loss_dice: 0.3101  decode.d5.loss_cls: 0.1105  decode.d5.loss_mask: 0.3448  decode.d5.loss_dice: 0.3046  decode.d6.loss_cls: 0.1944  decode.d6.loss_mask: 0.3385  decode.d6.loss_dice: 0.2915  decode.d7.loss_cls: 0.1273  decode.d7.loss_mask: 0.3517  decode.d7.loss_dice: 0.3055  decode.d8.loss_cls: 0.1579  decode.d8.loss_mask: 0.3408  decode.d8.loss_dice: 0.2975
08/06 05:30:22 - mmengine - INFO - Iter(train) [ 23650/320000]  base_lr: 9.3323e-05 lr: 9.3323e-06  eta: 1 day, 16:25:34  time: 0.4934  data_time: 0.0107  memory: 5892  grad_norm: 343.0111  loss: 8.1257  decode.loss_cls: 0.0741  decode.loss_mask: 0.2246  decode.loss_dice: 0.3882  decode.d0.loss_cls: 0.9724  decode.d0.loss_mask: 0.2434  decode.d0.loss_dice: 0.3695  decode.d1.loss_cls: 0.2148  decode.d1.loss_mask: 0.2315  decode.d1.loss_dice: 0.3623  decode.d2.loss_cls: 0.1006  decode.d2.loss_mask: 0.2236  decode.d2.loss_dice: 0.3849  decode.d3.loss_cls: 0.2048  decode.d3.loss_mask: 0.2112  decode.d3.loss_dice: 0.3549  decode.d4.loss_cls: 0.1115  decode.d4.loss_mask: 0.2350  decode.d4.loss_dice: 0.3757  decode.d5.loss_cls: 0.0867  decode.d5.loss_mask: 0.2302  decode.d5.loss_dice: 0.3752  decode.d6.loss_cls: 0.0858  decode.d6.loss_mask: 0.2423  decode.d6.loss_dice: 0.3813  decode.d7.loss_cls: 0.1391  decode.d7.loss_mask: 0.2185  decode.d7.loss_dice: 0.3790  decode.d8.loss_cls: 0.1097  decode.d8.loss_mask: 0.2171  decode.d8.loss_dice: 0.3779
08/06 05:30:47 - mmengine - INFO - Iter(train) [ 23700/320000]  base_lr: 9.3309e-05 lr: 9.3309e-06  eta: 1 day, 16:25:11  time: 0.4911  data_time: 0.0106  memory: 5909  grad_norm: 250.0181  loss: 8.0041  decode.loss_cls: 0.1575  decode.loss_mask: 0.2502  decode.loss_dice: 0.2919  decode.d0.loss_cls: 0.8682  decode.d0.loss_mask: 0.2547  decode.d0.loss_dice: 0.2929  decode.d1.loss_cls: 0.2681  decode.d1.loss_mask: 0.2437  decode.d1.loss_dice: 0.2948  decode.d2.loss_cls: 0.2966  decode.d2.loss_mask: 0.2400  decode.d2.loss_dice: 0.2770  decode.d3.loss_cls: 0.2248  decode.d3.loss_mask: 0.2342  decode.d3.loss_dice: 0.2724  decode.d4.loss_cls: 0.1831  decode.d4.loss_mask: 0.2294  decode.d4.loss_dice: 0.2767  decode.d5.loss_cls: 0.1978  decode.d5.loss_mask: 0.2336  decode.d5.loss_dice: 0.2664  decode.d6.loss_cls: 0.1838  decode.d6.loss_mask: 0.2440  decode.d6.loss_dice: 0.2799  decode.d7.loss_cls: 0.1996  decode.d7.loss_mask: 0.2357  decode.d7.loss_dice: 0.2785  decode.d8.loss_cls: 0.1785  decode.d8.loss_mask: 0.2518  decode.d8.loss_dice: 0.2984
08/06 05:31:12 - mmengine - INFO - Iter(train) [ 23750/320000]  base_lr: 9.3295e-05 lr: 9.3295e-06  eta: 1 day, 16:24:46  time: 0.4923  data_time: 0.0108  memory: 5892  grad_norm: 51.5773  loss: 7.2673  decode.loss_cls: 0.2239  decode.loss_mask: 0.1895  decode.loss_dice: 0.2288  decode.d0.loss_cls: 1.0257  decode.d0.loss_mask: 0.1970  decode.d0.loss_dice: 0.2519  decode.d1.loss_cls: 0.2824  decode.d1.loss_mask: 0.1896  decode.d1.loss_dice: 0.2257  decode.d2.loss_cls: 0.2250  decode.d2.loss_mask: 0.1925  decode.d2.loss_dice: 0.2343  decode.d3.loss_cls: 0.2007  decode.d3.loss_mask: 0.1906  decode.d3.loss_dice: 0.2350  decode.d4.loss_cls: 0.2211  decode.d4.loss_mask: 0.1911  decode.d4.loss_dice: 0.2287  decode.d5.loss_cls: 0.2206  decode.d5.loss_mask: 0.1893  decode.d5.loss_dice: 0.2211  decode.d6.loss_cls: 0.2181  decode.d6.loss_mask: 0.1913  decode.d6.loss_dice: 0.2237  decode.d7.loss_cls: 0.1686  decode.d7.loss_mask: 0.1994  decode.d7.loss_dice: 0.2571  decode.d8.loss_cls: 0.2294  decode.d8.loss_mask: 0.1886  decode.d8.loss_dice: 0.2266
08/06 05:31:36 - mmengine - INFO - Iter(train) [ 23800/320000]  base_lr: 9.3281e-05 lr: 9.3281e-06  eta: 1 day, 16:24:23  time: 0.4922  data_time: 0.0108  memory: 5908  grad_norm: 225.5523  loss: 9.1005  decode.loss_cls: 0.3170  decode.loss_mask: 0.2231  decode.loss_dice: 0.2889  decode.d0.loss_cls: 1.0120  decode.d0.loss_mask: 0.2302  decode.d0.loss_dice: 0.3269  decode.d1.loss_cls: 0.3367  decode.d1.loss_mask: 0.2292  decode.d1.loss_dice: 0.2842  decode.d2.loss_cls: 0.2707  decode.d2.loss_mask: 0.2229  decode.d2.loss_dice: 0.2955  decode.d3.loss_cls: 0.3390  decode.d3.loss_mask: 0.2211  decode.d3.loss_dice: 0.3116  decode.d4.loss_cls: 0.2966  decode.d4.loss_mask: 0.2261  decode.d4.loss_dice: 0.2834  decode.d5.loss_cls: 0.3186  decode.d5.loss_mask: 0.2226  decode.d5.loss_dice: 0.3082  decode.d6.loss_cls: 0.3197  decode.d6.loss_mask: 0.2221  decode.d6.loss_dice: 0.3087  decode.d7.loss_cls: 0.3077  decode.d7.loss_mask: 0.2231  decode.d7.loss_dice: 0.2976  decode.d8.loss_cls: 0.3338  decode.d8.loss_mask: 0.2229  decode.d8.loss_dice: 0.3007
08/06 05:32:01 - mmengine - INFO - Iter(train) [ 23850/320000]  base_lr: 9.3267e-05 lr: 9.3267e-06  eta: 1 day, 16:24:00  time: 0.4916  data_time: 0.0106  memory: 5892  grad_norm: 105.9339  loss: 8.5910  decode.loss_cls: 0.2787  decode.loss_mask: 0.2347  decode.loss_dice: 0.3108  decode.d0.loss_cls: 1.0588  decode.d0.loss_mask: 0.2422  decode.d0.loss_dice: 0.3046  decode.d1.loss_cls: 0.3163  decode.d1.loss_mask: 0.2342  decode.d1.loss_dice: 0.2998  decode.d2.loss_cls: 0.2181  decode.d2.loss_mask: 0.2374  decode.d2.loss_dice: 0.3204  decode.d3.loss_cls: 0.2459  decode.d3.loss_mask: 0.2350  decode.d3.loss_dice: 0.2996  decode.d4.loss_cls: 0.2044  decode.d4.loss_mask: 0.2341  decode.d4.loss_dice: 0.2957  decode.d5.loss_cls: 0.1695  decode.d5.loss_mask: 0.2319  decode.d5.loss_dice: 0.3135  decode.d6.loss_cls: 0.1761  decode.d6.loss_mask: 0.2360  decode.d6.loss_dice: 0.3104  decode.d7.loss_cls: 0.2276  decode.d7.loss_mask: 0.2416  decode.d7.loss_dice: 0.3147  decode.d8.loss_cls: 0.2210  decode.d8.loss_mask: 0.2408  decode.d8.loss_dice: 0.3376
08/06 05:32:26 - mmengine - INFO - Iter(train) [ 23900/320000]  base_lr: 9.3253e-05 lr: 9.3253e-06  eta: 1 day, 16:23:37  time: 0.4922  data_time: 0.0110  memory: 5874  grad_norm: 65.3715  loss: 5.6583  decode.loss_cls: 0.0460  decode.loss_mask: 0.2283  decode.loss_dice: 0.2126  decode.d0.loss_cls: 0.8471  decode.d0.loss_mask: 0.2275  decode.d0.loss_dice: 0.2189  decode.d1.loss_cls: 0.0683  decode.d1.loss_mask: 0.2270  decode.d1.loss_dice: 0.2141  decode.d2.loss_cls: 0.0425  decode.d2.loss_mask: 0.2242  decode.d2.loss_dice: 0.2132  decode.d3.loss_cls: 0.0601  decode.d3.loss_mask: 0.2248  decode.d3.loss_dice: 0.2093  decode.d4.loss_cls: 0.0487  decode.d4.loss_mask: 0.2233  decode.d4.loss_dice: 0.2148  decode.d5.loss_cls: 0.0497  decode.d5.loss_mask: 0.2235  decode.d5.loss_dice: 0.2136  decode.d6.loss_cls: 0.0341  decode.d6.loss_mask: 0.2260  decode.d6.loss_dice: 0.2100  decode.d7.loss_cls: 0.0375  decode.d7.loss_mask: 0.2252  decode.d7.loss_dice: 0.2096  decode.d8.loss_cls: 0.0393  decode.d8.loss_mask: 0.2258  decode.d8.loss_dice: 0.2134
08/06 05:32:50 - mmengine - INFO - Iter(train) [ 23950/320000]  base_lr: 9.3238e-05 lr: 9.3238e-06  eta: 1 day, 16:23:13  time: 0.4914  data_time: 0.0108  memory: 5928  grad_norm: 240.7419  loss: 8.4848  decode.loss_cls: 0.0788  decode.loss_mask: 0.2850  decode.loss_dice: 0.3662  decode.d0.loss_cls: 0.8052  decode.d0.loss_mask: 0.2929  decode.d0.loss_dice: 0.3544  decode.d1.loss_cls: 0.2330  decode.d1.loss_mask: 0.2955  decode.d1.loss_dice: 0.3511  decode.d2.loss_cls: 0.1859  decode.d2.loss_mask: 0.2840  decode.d2.loss_dice: 0.3622  decode.d3.loss_cls: 0.1227  decode.d3.loss_mask: 0.2831  decode.d3.loss_dice: 0.3610  decode.d4.loss_cls: 0.0810  decode.d4.loss_mask: 0.2820  decode.d4.loss_dice: 0.3623  decode.d5.loss_cls: 0.0792  decode.d5.loss_mask: 0.2829  decode.d5.loss_dice: 0.3567  decode.d6.loss_cls: 0.2039  decode.d6.loss_mask: 0.2821  decode.d6.loss_dice: 0.3386  decode.d7.loss_cls: 0.1403  decode.d7.loss_mask: 0.2890  decode.d7.loss_dice: 0.3497  decode.d8.loss_cls: 0.1227  decode.d8.loss_mask: 0.2905  decode.d8.loss_dice: 0.3629
08/06 05:33:15 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 05:33:15 - mmengine - INFO - Iter(train) [ 24000/320000]  base_lr: 9.3224e-05 lr: 9.3224e-06  eta: 1 day, 16:22:48  time: 0.4907  data_time: 0.0107  memory: 5877  grad_norm: 80.8708  loss: 7.2451  decode.loss_cls: 0.1470  decode.loss_mask: 0.2321  decode.loss_dice: 0.2704  decode.d0.loss_cls: 0.8244  decode.d0.loss_mask: 0.2489  decode.d0.loss_dice: 0.2796  decode.d1.loss_cls: 0.1910  decode.d1.loss_mask: 0.2366  decode.d1.loss_dice: 0.2561  decode.d2.loss_cls: 0.1364  decode.d2.loss_mask: 0.2475  decode.d2.loss_dice: 0.2871  decode.d3.loss_cls: 0.1379  decode.d3.loss_mask: 0.2346  decode.d3.loss_dice: 0.2717  decode.d4.loss_cls: 0.1180  decode.d4.loss_mask: 0.2378  decode.d4.loss_dice: 0.2683  decode.d5.loss_cls: 0.1220  decode.d5.loss_mask: 0.2392  decode.d5.loss_dice: 0.2815  decode.d6.loss_cls: 0.1456  decode.d6.loss_mask: 0.2364  decode.d6.loss_dice: 0.2831  decode.d7.loss_cls: 0.1523  decode.d7.loss_mask: 0.2352  decode.d7.loss_dice: 0.2814  decode.d8.loss_cls: 0.1302  decode.d8.loss_mask: 0.2339  decode.d8.loss_dice: 0.2788
08/06 05:33:39 - mmengine - INFO - Iter(train) [ 24050/320000]  base_lr: 9.3210e-05 lr: 9.3210e-06  eta: 1 day, 16:22:25  time: 0.4915  data_time: 0.0106  memory: 5926  grad_norm: 153.0722  loss: 7.6190  decode.loss_cls: 0.2059  decode.loss_mask: 0.2269  decode.loss_dice: 0.2804  decode.d0.loss_cls: 0.9969  decode.d0.loss_mask: 0.2279  decode.d0.loss_dice: 0.2869  decode.d1.loss_cls: 0.2315  decode.d1.loss_mask: 0.2272  decode.d1.loss_dice: 0.2788  decode.d2.loss_cls: 0.1695  decode.d2.loss_mask: 0.2278  decode.d2.loss_dice: 0.2762  decode.d3.loss_cls: 0.1288  decode.d3.loss_mask: 0.2291  decode.d3.loss_dice: 0.2942  decode.d4.loss_cls: 0.1655  decode.d4.loss_mask: 0.2252  decode.d4.loss_dice: 0.2912  decode.d5.loss_cls: 0.1203  decode.d5.loss_mask: 0.2291  decode.d5.loss_dice: 0.2896  decode.d6.loss_cls: 0.1604  decode.d6.loss_mask: 0.2316  decode.d6.loss_dice: 0.2815  decode.d7.loss_cls: 0.1755  decode.d7.loss_mask: 0.2298  decode.d7.loss_dice: 0.2863  decode.d8.loss_cls: 0.1395  decode.d8.loss_mask: 0.2254  decode.d8.loss_dice: 0.2802
08/06 05:34:04 - mmengine - INFO - Iter(train) [ 24100/320000]  base_lr: 9.3196e-05 lr: 9.3196e-06  eta: 1 day, 16:22:01  time: 0.4917  data_time: 0.0106  memory: 5927  grad_norm: 169.4065  loss: 7.2100  decode.loss_cls: 0.1118  decode.loss_mask: 0.2322  decode.loss_dice: 0.3037  decode.d0.loss_cls: 0.8166  decode.d0.loss_mask: 0.2385  decode.d0.loss_dice: 0.3021  decode.d1.loss_cls: 0.1133  decode.d1.loss_mask: 0.2317  decode.d1.loss_dice: 0.2944  decode.d2.loss_cls: 0.1017  decode.d2.loss_mask: 0.2334  decode.d2.loss_dice: 0.2963  decode.d3.loss_cls: 0.1409  decode.d3.loss_mask: 0.2318  decode.d3.loss_dice: 0.2939  decode.d4.loss_cls: 0.1236  decode.d4.loss_mask: 0.2332  decode.d4.loss_dice: 0.2940  decode.d5.loss_cls: 0.2103  decode.d5.loss_mask: 0.2367  decode.d5.loss_dice: 0.2839  decode.d6.loss_cls: 0.1246  decode.d6.loss_mask: 0.2333  decode.d6.loss_dice: 0.2853  decode.d7.loss_cls: 0.0989  decode.d7.loss_mask: 0.2334  decode.d7.loss_dice: 0.2911  decode.d8.loss_cls: 0.1168  decode.d8.loss_mask: 0.2368  decode.d8.loss_dice: 0.2656
08/06 05:34:29 - mmengine - INFO - Iter(train) [ 24150/320000]  base_lr: 9.3182e-05 lr: 9.3182e-06  eta: 1 day, 16:21:37  time: 0.4930  data_time: 0.0109  memory: 5908  grad_norm: 93.5239  loss: 8.0175  decode.loss_cls: 0.2120  decode.loss_mask: 0.2467  decode.loss_dice: 0.2346  decode.d0.loss_cls: 1.0175  decode.d0.loss_mask: 0.2481  decode.d0.loss_dice: 0.2539  decode.d1.loss_cls: 0.2523  decode.d1.loss_mask: 0.2625  decode.d1.loss_dice: 0.2601  decode.d2.loss_cls: 0.2693  decode.d2.loss_mask: 0.2494  decode.d2.loss_dice: 0.2530  decode.d3.loss_cls: 0.2412  decode.d3.loss_mask: 0.2375  decode.d3.loss_dice: 0.2384  decode.d4.loss_cls: 0.2036  decode.d4.loss_mask: 0.2392  decode.d4.loss_dice: 0.2455  decode.d5.loss_cls: 0.1981  decode.d5.loss_mask: 0.2514  decode.d5.loss_dice: 0.2550  decode.d6.loss_cls: 0.1826  decode.d6.loss_mask: 0.2581  decode.d6.loss_dice: 0.2442  decode.d7.loss_cls: 0.2168  decode.d7.loss_mask: 0.2940  decode.d7.loss_dice: 0.2608  decode.d8.loss_cls: 0.1978  decode.d8.loss_mask: 0.2494  decode.d8.loss_dice: 0.2446
08/06 05:34:53 - mmengine - INFO - Iter(train) [ 24200/320000]  base_lr: 9.3168e-05 lr: 9.3168e-06  eta: 1 day, 16:21:13  time: 0.4924  data_time: 0.0108  memory: 5891  grad_norm: 154.5152  loss: 9.0971  decode.loss_cls: 0.2341  decode.loss_mask: 0.2621  decode.loss_dice: 0.3317  decode.d0.loss_cls: 0.9348  decode.d0.loss_mask: 0.2721  decode.d0.loss_dice: 0.3773  decode.d1.loss_cls: 0.2314  decode.d1.loss_mask: 0.2797  decode.d1.loss_dice: 0.3516  decode.d2.loss_cls: 0.1648  decode.d2.loss_mask: 0.2761  decode.d2.loss_dice: 0.3388  decode.d3.loss_cls: 0.2920  decode.d3.loss_mask: 0.2618  decode.d3.loss_dice: 0.3109  decode.d4.loss_cls: 0.2800  decode.d4.loss_mask: 0.2601  decode.d4.loss_dice: 0.3250  decode.d5.loss_cls: 0.2412  decode.d5.loss_mask: 0.2669  decode.d5.loss_dice: 0.3369  decode.d6.loss_cls: 0.2267  decode.d6.loss_mask: 0.2653  decode.d6.loss_dice: 0.3208  decode.d7.loss_cls: 0.2413  decode.d7.loss_mask: 0.2634  decode.d7.loss_dice: 0.3329  decode.d8.loss_cls: 0.2246  decode.d8.loss_mask: 0.2674  decode.d8.loss_dice: 0.3256
08/06 05:35:18 - mmengine - INFO - Iter(train) [ 24250/320000]  base_lr: 9.3153e-05 lr: 9.3153e-06  eta: 1 day, 16:20:49  time: 0.4918  data_time: 0.0110  memory: 5890  grad_norm: 247.3045  loss: 10.6680  decode.loss_cls: 0.1762  decode.loss_mask: 0.3594  decode.loss_dice: 0.3580  decode.d0.loss_cls: 1.2054  decode.d0.loss_mask: 0.3404  decode.d0.loss_dice: 0.3917  decode.d1.loss_cls: 0.4199  decode.d1.loss_mask: 0.3499  decode.d1.loss_dice: 0.3683  decode.d2.loss_cls: 0.2956  decode.d2.loss_mask: 0.3481  decode.d2.loss_dice: 0.3465  decode.d3.loss_cls: 0.3177  decode.d3.loss_mask: 0.3584  decode.d3.loss_dice: 0.3425  decode.d4.loss_cls: 0.2880  decode.d4.loss_mask: 0.3446  decode.d4.loss_dice: 0.3372  decode.d5.loss_cls: 0.2560  decode.d5.loss_mask: 0.3465  decode.d5.loss_dice: 0.3499  decode.d6.loss_cls: 0.2012  decode.d6.loss_mask: 0.3448  decode.d6.loss_dice: 0.3502  decode.d7.loss_cls: 0.2445  decode.d7.loss_mask: 0.3451  decode.d7.loss_dice: 0.3551  decode.d8.loss_cls: 0.1931  decode.d8.loss_mask: 0.3606  decode.d8.loss_dice: 0.3731
08/06 05:35:42 - mmengine - INFO - Iter(train) [ 24300/320000]  base_lr: 9.3139e-05 lr: 9.3139e-06  eta: 1 day, 16:20:25  time: 0.4926  data_time: 0.0107  memory: 5891  grad_norm: 132.5153  loss: 8.7804  decode.loss_cls: 0.2458  decode.loss_mask: 0.2201  decode.loss_dice: 0.3307  decode.d0.loss_cls: 0.9377  decode.d0.loss_mask: 0.2315  decode.d0.loss_dice: 0.3699  decode.d1.loss_cls: 0.2694  decode.d1.loss_mask: 0.2248  decode.d1.loss_dice: 0.3249  decode.d2.loss_cls: 0.2168  decode.d2.loss_mask: 0.2235  decode.d2.loss_dice: 0.3456  decode.d3.loss_cls: 0.2414  decode.d3.loss_mask: 0.2249  decode.d3.loss_dice: 0.3360  decode.d4.loss_cls: 0.2292  decode.d4.loss_mask: 0.2259  decode.d4.loss_dice: 0.3453  decode.d5.loss_cls: 0.2141  decode.d5.loss_mask: 0.2231  decode.d5.loss_dice: 0.3656  decode.d6.loss_cls: 0.2335  decode.d6.loss_mask: 0.2240  decode.d6.loss_dice: 0.3467  decode.d7.loss_cls: 0.2183  decode.d7.loss_mask: 0.2255  decode.d7.loss_dice: 0.3492  decode.d8.loss_cls: 0.2824  decode.d8.loss_mask: 0.2219  decode.d8.loss_dice: 0.3324
08/06 05:36:07 - mmengine - INFO - Iter(train) [ 24350/320000]  base_lr: 9.3125e-05 lr: 9.3125e-06  eta: 1 day, 16:20:01  time: 0.4921  data_time: 0.0106  memory: 5893  grad_norm: 146.2083  loss: 8.0137  decode.loss_cls: 0.2155  decode.loss_mask: 0.2111  decode.loss_dice: 0.2876  decode.d0.loss_cls: 0.9241  decode.d0.loss_mask: 0.2180  decode.d0.loss_dice: 0.3104  decode.d1.loss_cls: 0.2054  decode.d1.loss_mask: 0.2177  decode.d1.loss_dice: 0.2940  decode.d2.loss_cls: 0.1998  decode.d2.loss_mask: 0.2175  decode.d2.loss_dice: 0.2951  decode.d3.loss_cls: 0.2025  decode.d3.loss_mask: 0.2137  decode.d3.loss_dice: 0.3011  decode.d4.loss_cls: 0.2161  decode.d4.loss_mask: 0.2181  decode.d4.loss_dice: 0.3204  decode.d5.loss_cls: 0.1739  decode.d5.loss_mask: 0.2213  decode.d5.loss_dice: 0.3144  decode.d6.loss_cls: 0.2497  decode.d6.loss_mask: 0.2121  decode.d6.loss_dice: 0.3101  decode.d7.loss_cls: 0.2291  decode.d7.loss_mask: 0.2117  decode.d7.loss_dice: 0.2957  decode.d8.loss_cls: 0.2121  decode.d8.loss_mask: 0.2124  decode.d8.loss_dice: 0.3029
08/06 05:36:32 - mmengine - INFO - Iter(train) [ 24400/320000]  base_lr: 9.3111e-05 lr: 9.3111e-06  eta: 1 day, 16:19:39  time: 0.4927  data_time: 0.0110  memory: 5926  grad_norm: 90.6559  loss: 8.9398  decode.loss_cls: 0.2623  decode.loss_mask: 0.3008  decode.loss_dice: 0.3064  decode.d0.loss_cls: 0.9272  decode.d0.loss_mask: 0.3113  decode.d0.loss_dice: 0.3210  decode.d1.loss_cls: 0.2772  decode.d1.loss_mask: 0.3068  decode.d1.loss_dice: 0.3015  decode.d2.loss_cls: 0.2228  decode.d2.loss_mask: 0.3009  decode.d2.loss_dice: 0.2777  decode.d3.loss_cls: 0.1951  decode.d3.loss_mask: 0.3046  decode.d3.loss_dice: 0.3174  decode.d4.loss_cls: 0.2286  decode.d4.loss_mask: 0.3068  decode.d4.loss_dice: 0.2963  decode.d5.loss_cls: 0.1880  decode.d5.loss_mask: 0.3053  decode.d5.loss_dice: 0.2976  decode.d6.loss_cls: 0.1817  decode.d6.loss_mask: 0.3037  decode.d6.loss_dice: 0.3003  decode.d7.loss_cls: 0.2048  decode.d7.loss_mask: 0.3020  decode.d7.loss_dice: 0.2907  decode.d8.loss_cls: 0.1940  decode.d8.loss_mask: 0.3051  decode.d8.loss_dice: 0.3019
08/06 05:36:56 - mmengine - INFO - Iter(train) [ 24450/320000]  base_lr: 9.3097e-05 lr: 9.3097e-06  eta: 1 day, 16:19:16  time: 0.4926  data_time: 0.0108  memory: 5908  grad_norm: 249.2756  loss: 8.6167  decode.loss_cls: 0.2098  decode.loss_mask: 0.2523  decode.loss_dice: 0.3207  decode.d0.loss_cls: 1.1408  decode.d0.loss_mask: 0.2450  decode.d0.loss_dice: 0.3247  decode.d1.loss_cls: 0.3943  decode.d1.loss_mask: 0.2386  decode.d1.loss_dice: 0.3170  decode.d2.loss_cls: 0.2226  decode.d2.loss_mask: 0.2327  decode.d2.loss_dice: 0.3213  decode.d3.loss_cls: 0.1277  decode.d3.loss_mask: 0.2543  decode.d3.loss_dice: 0.3301  decode.d4.loss_cls: 0.1921  decode.d4.loss_mask: 0.2356  decode.d4.loss_dice: 0.3053  decode.d5.loss_cls: 0.1609  decode.d5.loss_mask: 0.2405  decode.d5.loss_dice: 0.3346  decode.d6.loss_cls: 0.1479  decode.d6.loss_mask: 0.2347  decode.d6.loss_dice: 0.3292  decode.d7.loss_cls: 0.1602  decode.d7.loss_mask: 0.2441  decode.d7.loss_dice: 0.3143  decode.d8.loss_cls: 0.2026  decode.d8.loss_mask: 0.2463  decode.d8.loss_dice: 0.3365
08/06 05:37:21 - mmengine - INFO - Iter(train) [ 24500/320000]  base_lr: 9.3082e-05 lr: 9.3082e-06  eta: 1 day, 16:18:52  time: 0.4920  data_time: 0.0112  memory: 5892  grad_norm: 178.5934  loss: 6.9659  decode.loss_cls: 0.0941  decode.loss_mask: 0.2521  decode.loss_dice: 0.2427  decode.d0.loss_cls: 0.8881  decode.d0.loss_mask: 0.2519  decode.d0.loss_dice: 0.2587  decode.d1.loss_cls: 0.1717  decode.d1.loss_mask: 0.2661  decode.d1.loss_dice: 0.2723  decode.d2.loss_cls: 0.0916  decode.d2.loss_mask: 0.2503  decode.d2.loss_dice: 0.2528  decode.d3.loss_cls: 0.1354  decode.d3.loss_mask: 0.2523  decode.d3.loss_dice: 0.2387  decode.d4.loss_cls: 0.1613  decode.d4.loss_mask: 0.2541  decode.d4.loss_dice: 0.2421  decode.d5.loss_cls: 0.0855  decode.d5.loss_mask: 0.2552  decode.d5.loss_dice: 0.2451  decode.d6.loss_cls: 0.1291  decode.d6.loss_mask: 0.2495  decode.d6.loss_dice: 0.2461  decode.d7.loss_cls: 0.0611  decode.d7.loss_mask: 0.2523  decode.d7.loss_dice: 0.2611  decode.d8.loss_cls: 0.0929  decode.d8.loss_mask: 0.2516  decode.d8.loss_dice: 0.2602
08/06 05:37:46 - mmengine - INFO - Iter(train) [ 24550/320000]  base_lr: 9.3068e-05 lr: 9.3068e-06  eta: 1 day, 16:18:28  time: 0.4924  data_time: 0.0111  memory: 5907  grad_norm: 123.8658  loss: 8.6782  decode.loss_cls: 0.2134  decode.loss_mask: 0.2836  decode.loss_dice: 0.2879  decode.d0.loss_cls: 0.9516  decode.d0.loss_mask: 0.2917  decode.d0.loss_dice: 0.3300  decode.d1.loss_cls: 0.1825  decode.d1.loss_mask: 0.2805  decode.d1.loss_dice: 0.2962  decode.d2.loss_cls: 0.2361  decode.d2.loss_mask: 0.3012  decode.d2.loss_dice: 0.3063  decode.d3.loss_cls: 0.2175  decode.d3.loss_mask: 0.2861  decode.d3.loss_dice: 0.3081  decode.d4.loss_cls: 0.1938  decode.d4.loss_mask: 0.3019  decode.d4.loss_dice: 0.3235  decode.d5.loss_cls: 0.2160  decode.d5.loss_mask: 0.2857  decode.d5.loss_dice: 0.2883  decode.d6.loss_cls: 0.1876  decode.d6.loss_mask: 0.2913  decode.d6.loss_dice: 0.2951  decode.d7.loss_cls: 0.1862  decode.d7.loss_mask: 0.2805  decode.d7.loss_dice: 0.3104  decode.d8.loss_cls: 0.1944  decode.d8.loss_mask: 0.2796  decode.d8.loss_dice: 0.2707
08/06 05:38:10 - mmengine - INFO - Iter(train) [ 24600/320000]  base_lr: 9.3054e-05 lr: 9.3054e-06  eta: 1 day, 16:18:04  time: 0.4917  data_time: 0.0107  memory: 5891  grad_norm: 296.9405  loss: 8.8815  decode.loss_cls: 0.2312  decode.loss_mask: 0.2470  decode.loss_dice: 0.2953  decode.d0.loss_cls: 0.8641  decode.d0.loss_mask: 0.2366  decode.d0.loss_dice: 0.3316  decode.d1.loss_cls: 0.3723  decode.d1.loss_mask: 0.2275  decode.d1.loss_dice: 0.3026  decode.d2.loss_cls: 0.2799  decode.d2.loss_mask: 0.2307  decode.d2.loss_dice: 0.2967  decode.d3.loss_cls: 0.3285  decode.d3.loss_mask: 0.2298  decode.d3.loss_dice: 0.2962  decode.d4.loss_cls: 0.2341  decode.d4.loss_mask: 0.2415  decode.d4.loss_dice: 0.3104  decode.d5.loss_cls: 0.3437  decode.d5.loss_mask: 0.2313  decode.d5.loss_dice: 0.3075  decode.d6.loss_cls: 0.3003  decode.d6.loss_mask: 0.2255  decode.d6.loss_dice: 0.3006  decode.d7.loss_cls: 0.3086  decode.d7.loss_mask: 0.2278  decode.d7.loss_dice: 0.3021  decode.d8.loss_cls: 0.2322  decode.d8.loss_mask: 0.2450  decode.d8.loss_dice: 0.3009
08/06 05:38:35 - mmengine - INFO - Iter(train) [ 24650/320000]  base_lr: 9.3040e-05 lr: 9.3040e-06  eta: 1 day, 16:17:40  time: 0.4915  data_time: 0.0106  memory: 5908  grad_norm: 144.5777  loss: 6.9154  decode.loss_cls: 0.1818  decode.loss_mask: 0.2271  decode.loss_dice: 0.2474  decode.d0.loss_cls: 0.8436  decode.d0.loss_mask: 0.2337  decode.d0.loss_dice: 0.2842  decode.d1.loss_cls: 0.1056  decode.d1.loss_mask: 0.2264  decode.d1.loss_dice: 0.2560  decode.d2.loss_cls: 0.1013  decode.d2.loss_mask: 0.2285  decode.d2.loss_dice: 0.2543  decode.d3.loss_cls: 0.1074  decode.d3.loss_mask: 0.2263  decode.d3.loss_dice: 0.2513  decode.d4.loss_cls: 0.1193  decode.d4.loss_mask: 0.2229  decode.d4.loss_dice: 0.2508  decode.d5.loss_cls: 0.1287  decode.d5.loss_mask: 0.2262  decode.d5.loss_dice: 0.2495  decode.d6.loss_cls: 0.1459  decode.d6.loss_mask: 0.2260  decode.d6.loss_dice: 0.2515  decode.d7.loss_cls: 0.1549  decode.d7.loss_mask: 0.2290  decode.d7.loss_dice: 0.2503  decode.d8.loss_cls: 0.1869  decode.d8.loss_mask: 0.2316  decode.d8.loss_dice: 0.2671
08/06 05:39:00 - mmengine - INFO - Iter(train) [ 24700/320000]  base_lr: 9.3026e-05 lr: 9.3026e-06  eta: 1 day, 16:17:18  time: 0.4927  data_time: 0.0107  memory: 5908  grad_norm: 164.1126  loss: 6.4702  decode.loss_cls: 0.1192  decode.loss_mask: 0.1875  decode.loss_dice: 0.2810  decode.d0.loss_cls: 0.9547  decode.d0.loss_mask: 0.1952  decode.d0.loss_dice: 0.2661  decode.d1.loss_cls: 0.1076  decode.d1.loss_mask: 0.1874  decode.d1.loss_dice: 0.2486  decode.d2.loss_cls: 0.1209  decode.d2.loss_mask: 0.1837  decode.d2.loss_dice: 0.2809  decode.d3.loss_cls: 0.1164  decode.d3.loss_mask: 0.1824  decode.d3.loss_dice: 0.2657  decode.d4.loss_cls: 0.0922  decode.d4.loss_mask: 0.1845  decode.d4.loss_dice: 0.2742  decode.d5.loss_cls: 0.0975  decode.d5.loss_mask: 0.1897  decode.d5.loss_dice: 0.2755  decode.d6.loss_cls: 0.1163  decode.d6.loss_mask: 0.1878  decode.d6.loss_dice: 0.2683  decode.d7.loss_cls: 0.1067  decode.d7.loss_mask: 0.1884  decode.d7.loss_dice: 0.2455  decode.d8.loss_cls: 0.1142  decode.d8.loss_mask: 0.1847  decode.d8.loss_dice: 0.2474
08/06 05:39:24 - mmengine - INFO - Iter(train) [ 24750/320000]  base_lr: 9.3012e-05 lr: 9.3012e-06  eta: 1 day, 16:16:54  time: 0.4919  data_time: 0.0108  memory: 5891  grad_norm: 67.3469  loss: 6.8883  decode.loss_cls: 0.0383  decode.loss_mask: 0.2328  decode.loss_dice: 0.2993  decode.d0.loss_cls: 0.8156  decode.d0.loss_mask: 0.2395  decode.d0.loss_dice: 0.3261  decode.d1.loss_cls: 0.1174  decode.d1.loss_mask: 0.2405  decode.d1.loss_dice: 0.2974  decode.d2.loss_cls: 0.1505  decode.d2.loss_mask: 0.2297  decode.d2.loss_dice: 0.2957  decode.d3.loss_cls: 0.1319  decode.d3.loss_mask: 0.2328  decode.d3.loss_dice: 0.2803  decode.d4.loss_cls: 0.0522  decode.d4.loss_mask: 0.2330  decode.d4.loss_dice: 0.2901  decode.d5.loss_cls: 0.0374  decode.d5.loss_mask: 0.2410  decode.d5.loss_dice: 0.2981  decode.d6.loss_cls: 0.0696  decode.d6.loss_mask: 0.2372  decode.d6.loss_dice: 0.3035  decode.d7.loss_cls: 0.0417  decode.d7.loss_mask: 0.2356  decode.d7.loss_dice: 0.3022  decode.d8.loss_cls: 0.0941  decode.d8.loss_mask: 0.2342  decode.d8.loss_dice: 0.2907
08/06 05:39:49 - mmengine - INFO - Iter(train) [ 24800/320000]  base_lr: 9.2997e-05 lr: 9.2997e-06  eta: 1 day, 16:16:30  time: 0.4914  data_time: 0.0108  memory: 5892  grad_norm: 98.2020  loss: 7.4382  decode.loss_cls: 0.0550  decode.loss_mask: 0.3170  decode.loss_dice: 0.2608  decode.d0.loss_cls: 0.8384  decode.d0.loss_mask: 0.3168  decode.d0.loss_dice: 0.2749  decode.d1.loss_cls: 0.1296  decode.d1.loss_mask: 0.3240  decode.d1.loss_dice: 0.2711  decode.d2.loss_cls: 0.0908  decode.d2.loss_mask: 0.3217  decode.d2.loss_dice: 0.2700  decode.d3.loss_cls: 0.1070  decode.d3.loss_mask: 0.3130  decode.d3.loss_dice: 0.2659  decode.d4.loss_cls: 0.0897  decode.d4.loss_mask: 0.3233  decode.d4.loss_dice: 0.2715  decode.d5.loss_cls: 0.0596  decode.d5.loss_mask: 0.3236  decode.d5.loss_dice: 0.2685  decode.d6.loss_cls: 0.0575  decode.d6.loss_mask: 0.3186  decode.d6.loss_dice: 0.2627  decode.d7.loss_cls: 0.0869  decode.d7.loss_mask: 0.3152  decode.d7.loss_dice: 0.2632  decode.d8.loss_cls: 0.0681  decode.d8.loss_mask: 0.3188  decode.d8.loss_dice: 0.2549
08/06 05:40:13 - mmengine - INFO - Iter(train) [ 24850/320000]  base_lr: 9.2983e-05 lr: 9.2983e-06  eta: 1 day, 16:16:06  time: 0.4921  data_time: 0.0107  memory: 5907  grad_norm: 89.5188  loss: 6.6870  decode.loss_cls: 0.0974  decode.loss_mask: 0.2128  decode.loss_dice: 0.3032  decode.d0.loss_cls: 0.8434  decode.d0.loss_mask: 0.2136  decode.d0.loss_dice: 0.3159  decode.d1.loss_cls: 0.1405  decode.d1.loss_mask: 0.2118  decode.d1.loss_dice: 0.3092  decode.d2.loss_cls: 0.0703  decode.d2.loss_mask: 0.2112  decode.d2.loss_dice: 0.2897  decode.d3.loss_cls: 0.0552  decode.d3.loss_mask: 0.2100  decode.d3.loss_dice: 0.2888  decode.d4.loss_cls: 0.1028  decode.d4.loss_mask: 0.2108  decode.d4.loss_dice: 0.2844  decode.d5.loss_cls: 0.0914  decode.d5.loss_mask: 0.2095  decode.d5.loss_dice: 0.2895  decode.d6.loss_cls: 0.1219  decode.d6.loss_mask: 0.2102  decode.d6.loss_dice: 0.2882  decode.d7.loss_cls: 0.0410  decode.d7.loss_mask: 0.2127  decode.d7.loss_dice: 0.3101  decode.d8.loss_cls: 0.0315  decode.d8.loss_mask: 0.2105  decode.d8.loss_dice: 0.2993
08/06 05:40:38 - mmengine - INFO - Iter(train) [ 24900/320000]  base_lr: 9.2969e-05 lr: 9.2969e-06  eta: 1 day, 16:15:42  time: 0.4921  data_time: 0.0109  memory: 5895  grad_norm: 114.7652  loss: 8.6596  decode.loss_cls: 0.2106  decode.loss_mask: 0.2623  decode.loss_dice: 0.2786  decode.d0.loss_cls: 1.0185  decode.d0.loss_mask: 0.2724  decode.d0.loss_dice: 0.2962  decode.d1.loss_cls: 0.2702  decode.d1.loss_mask: 0.2624  decode.d1.loss_dice: 0.2714  decode.d2.loss_cls: 0.2031  decode.d2.loss_mask: 0.2611  decode.d2.loss_dice: 0.2807  decode.d3.loss_cls: 0.2302  decode.d3.loss_mask: 0.2604  decode.d3.loss_dice: 0.2604  decode.d4.loss_cls: 0.1982  decode.d4.loss_mask: 0.2674  decode.d4.loss_dice: 0.2843  decode.d5.loss_cls: 0.2445  decode.d5.loss_mask: 0.2623  decode.d5.loss_dice: 0.2815  decode.d6.loss_cls: 0.2632  decode.d6.loss_mask: 0.2606  decode.d6.loss_dice: 0.2726  decode.d7.loss_cls: 0.3298  decode.d7.loss_mask: 0.2608  decode.d7.loss_dice: 0.2780  decode.d8.loss_cls: 0.2678  decode.d8.loss_mask: 0.2647  decode.d8.loss_dice: 0.2854
08/06 05:41:03 - mmengine - INFO - Iter(train) [ 24950/320000]  base_lr: 9.2955e-05 lr: 9.2955e-06  eta: 1 day, 16:15:18  time: 0.4922  data_time: 0.0109  memory: 5890  grad_norm: 331.2890  loss: 7.9265  decode.loss_cls: 0.1407  decode.loss_mask: 0.2912  decode.loss_dice: 0.2716  decode.d0.loss_cls: 0.8547  decode.d0.loss_mask: 0.3084  decode.d0.loss_dice: 0.2995  decode.d1.loss_cls: 0.1603  decode.d1.loss_mask: 0.2992  decode.d1.loss_dice: 0.2811  decode.d2.loss_cls: 0.1696  decode.d2.loss_mask: 0.2916  decode.d2.loss_dice: 0.2724  decode.d3.loss_cls: 0.1848  decode.d3.loss_mask: 0.2967  decode.d3.loss_dice: 0.2960  decode.d4.loss_cls: 0.1472  decode.d4.loss_mask: 0.2904  decode.d4.loss_dice: 0.2783  decode.d5.loss_cls: 0.1585  decode.d5.loss_mask: 0.2950  decode.d5.loss_dice: 0.2758  decode.d6.loss_cls: 0.1163  decode.d6.loss_mask: 0.2918  decode.d6.loss_dice: 0.2766  decode.d7.loss_cls: 0.1221  decode.d7.loss_mask: 0.2908  decode.d7.loss_dice: 0.2721  decode.d8.loss_cls: 0.1263  decode.d8.loss_mask: 0.2917  decode.d8.loss_dice: 0.2761
08/06 05:41:27 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 05:41:27 - mmengine - INFO - Iter(train) [ 25000/320000]  base_lr: 9.2941e-05 lr: 9.2941e-06  eta: 1 day, 16:14:54  time: 0.4918  data_time: 0.0107  memory: 5908  grad_norm: 53.9137  loss: 6.2333  decode.loss_cls: 0.1107  decode.loss_mask: 0.2124  decode.loss_dice: 0.2314  decode.d0.loss_cls: 0.7732  decode.d0.loss_mask: 0.2123  decode.d0.loss_dice: 0.2397  decode.d1.loss_cls: 0.1273  decode.d1.loss_mask: 0.2126  decode.d1.loss_dice: 0.2342  decode.d2.loss_cls: 0.0933  decode.d2.loss_mask: 0.2107  decode.d2.loss_dice: 0.2268  decode.d3.loss_cls: 0.0897  decode.d3.loss_mask: 0.2087  decode.d3.loss_dice: 0.2362  decode.d4.loss_cls: 0.0918  decode.d4.loss_mask: 0.2090  decode.d4.loss_dice: 0.2333  decode.d5.loss_cls: 0.0899  decode.d5.loss_mask: 0.2103  decode.d5.loss_dice: 0.2362  decode.d6.loss_cls: 0.1557  decode.d6.loss_mask: 0.2077  decode.d6.loss_dice: 0.2637  decode.d7.loss_cls: 0.1041  decode.d7.loss_mask: 0.2117  decode.d7.loss_dice: 0.2304  decode.d8.loss_cls: 0.1259  decode.d8.loss_mask: 0.2107  decode.d8.loss_dice: 0.2337
08/06 05:41:52 - mmengine - INFO - Iter(train) [ 25050/320000]  base_lr: 9.2927e-05 lr: 9.2927e-06  eta: 1 day, 16:14:30  time: 0.4924  data_time: 0.0109  memory: 5928  grad_norm: 104.9102  loss: 7.9061  decode.loss_cls: 0.1352  decode.loss_mask: 0.2386  decode.loss_dice: 0.3418  decode.d0.loss_cls: 0.9448  decode.d0.loss_mask: 0.2406  decode.d0.loss_dice: 0.3418  decode.d1.loss_cls: 0.2077  decode.d1.loss_mask: 0.2401  decode.d1.loss_dice: 0.3348  decode.d2.loss_cls: 0.1148  decode.d2.loss_mask: 0.2357  decode.d2.loss_dice: 0.3389  decode.d3.loss_cls: 0.1117  decode.d3.loss_mask: 0.2325  decode.d3.loss_dice: 0.3301  decode.d4.loss_cls: 0.1287  decode.d4.loss_mask: 0.2345  decode.d4.loss_dice: 0.3265  decode.d5.loss_cls: 0.1471  decode.d5.loss_mask: 0.2364  decode.d5.loss_dice: 0.3104  decode.d6.loss_cls: 0.1572  decode.d6.loss_mask: 0.2390  decode.d6.loss_dice: 0.3280  decode.d7.loss_cls: 0.1222  decode.d7.loss_mask: 0.2390  decode.d7.loss_dice: 0.3416  decode.d8.loss_cls: 0.1295  decode.d8.loss_mask: 0.2370  decode.d8.loss_dice: 0.3398
08/06 05:42:17 - mmengine - INFO - Iter(train) [ 25100/320000]  base_lr: 9.2912e-05 lr: 9.2912e-06  eta: 1 day, 16:14:06  time: 0.4933  data_time: 0.0108  memory: 5890  grad_norm: 86.3990  loss: 9.0350  decode.loss_cls: 0.1992  decode.loss_mask: 0.2338  decode.loss_dice: 0.4107  decode.d0.loss_cls: 0.8462  decode.d0.loss_mask: 0.2463  decode.d0.loss_dice: 0.4157  decode.d1.loss_cls: 0.2781  decode.d1.loss_mask: 0.2360  decode.d1.loss_dice: 0.4024  decode.d2.loss_cls: 0.1189  decode.d2.loss_mask: 0.2388  decode.d2.loss_dice: 0.4387  decode.d3.loss_cls: 0.1502  decode.d3.loss_mask: 0.2380  decode.d3.loss_dice: 0.4576  decode.d4.loss_cls: 0.1854  decode.d4.loss_mask: 0.2356  decode.d4.loss_dice: 0.4337  decode.d5.loss_cls: 0.1252  decode.d5.loss_mask: 0.2370  decode.d5.loss_dice: 0.4288  decode.d6.loss_cls: 0.1284  decode.d6.loss_mask: 0.2360  decode.d6.loss_dice: 0.4260  decode.d7.loss_cls: 0.1787  decode.d7.loss_mask: 0.2369  decode.d7.loss_dice: 0.4339  decode.d8.loss_cls: 0.1494  decode.d8.loss_mask: 0.2401  decode.d8.loss_dice: 0.4492
08/06 05:42:41 - mmengine - INFO - Iter(train) [ 25150/320000]  base_lr: 9.2898e-05 lr: 9.2898e-06  eta: 1 day, 16:13:42  time: 0.4930  data_time: 0.0108  memory: 5893  grad_norm: 66.8646  loss: 6.3660  decode.loss_cls: 0.0804  decode.loss_mask: 0.2287  decode.loss_dice: 0.2411  decode.d0.loss_cls: 0.7800  decode.d0.loss_mask: 0.2392  decode.d0.loss_dice: 0.2741  decode.d1.loss_cls: 0.0963  decode.d1.loss_mask: 0.2319  decode.d1.loss_dice: 0.2607  decode.d2.loss_cls: 0.1005  decode.d2.loss_mask: 0.2332  decode.d2.loss_dice: 0.2497  decode.d3.loss_cls: 0.0691  decode.d3.loss_mask: 0.2311  decode.d3.loss_dice: 0.2343  decode.d4.loss_cls: 0.0707  decode.d4.loss_mask: 0.2268  decode.d4.loss_dice: 0.2355  decode.d5.loss_cls: 0.0986  decode.d5.loss_mask: 0.2336  decode.d5.loss_dice: 0.2431  decode.d6.loss_cls: 0.0837  decode.d6.loss_mask: 0.2297  decode.d6.loss_dice: 0.2344  decode.d7.loss_cls: 0.1125  decode.d7.loss_mask: 0.2365  decode.d7.loss_dice: 0.2361  decode.d8.loss_cls: 0.0949  decode.d8.loss_mask: 0.2324  decode.d8.loss_dice: 0.2472
08/06 05:43:06 - mmengine - INFO - Iter(train) [ 25200/320000]  base_lr: 9.2884e-05 lr: 9.2884e-06  eta: 1 day, 16:13:18  time: 0.4926  data_time: 0.0109  memory: 5926  grad_norm: 249.2790  loss: 8.2584  decode.loss_cls: 0.1664  decode.loss_mask: 0.2282  decode.loss_dice: 0.2975  decode.d0.loss_cls: 1.0260  decode.d0.loss_mask: 0.2432  decode.d0.loss_dice: 0.3058  decode.d1.loss_cls: 0.2694  decode.d1.loss_mask: 0.2398  decode.d1.loss_dice: 0.3257  decode.d2.loss_cls: 0.2256  decode.d2.loss_mask: 0.2383  decode.d2.loss_dice: 0.2984  decode.d3.loss_cls: 0.2177  decode.d3.loss_mask: 0.2356  decode.d3.loss_dice: 0.2965  decode.d4.loss_cls: 0.1572  decode.d4.loss_mask: 0.2416  decode.d4.loss_dice: 0.3135  decode.d5.loss_cls: 0.2280  decode.d5.loss_mask: 0.2322  decode.d5.loss_dice: 0.2953  decode.d6.loss_cls: 0.2452  decode.d6.loss_mask: 0.2274  decode.d6.loss_dice: 0.2824  decode.d7.loss_cls: 0.1853  decode.d7.loss_mask: 0.2304  decode.d7.loss_dice: 0.2805  decode.d8.loss_cls: 0.1863  decode.d8.loss_mask: 0.2350  decode.d8.loss_dice: 0.3041
08/06 05:43:30 - mmengine - INFO - Iter(train) [ 25250/320000]  base_lr: 9.2870e-05 lr: 9.2870e-06  eta: 1 day, 16:12:54  time: 0.4918  data_time: 0.0109  memory: 5889  grad_norm: 227.2144  loss: 10.2715  decode.loss_cls: 0.3064  decode.loss_mask: 0.3169  decode.loss_dice: 0.3825  decode.d0.loss_cls: 0.9974  decode.d0.loss_mask: 0.3076  decode.d0.loss_dice: 0.3629  decode.d1.loss_cls: 0.3295  decode.d1.loss_mask: 0.2985  decode.d1.loss_dice: 0.3445  decode.d2.loss_cls: 0.2606  decode.d2.loss_mask: 0.3084  decode.d2.loss_dice: 0.3608  decode.d3.loss_cls: 0.2499  decode.d3.loss_mask: 0.3105  decode.d3.loss_dice: 0.3751  decode.d4.loss_cls: 0.2166  decode.d4.loss_mask: 0.3143  decode.d4.loss_dice: 0.3789  decode.d5.loss_cls: 0.2025  decode.d5.loss_mask: 0.3231  decode.d5.loss_dice: 0.3704  decode.d6.loss_cls: 0.2507  decode.d6.loss_mask: 0.3205  decode.d6.loss_dice: 0.3851  decode.d7.loss_cls: 0.2671  decode.d7.loss_mask: 0.3339  decode.d7.loss_dice: 0.3800  decode.d8.loss_cls: 0.3359  decode.d8.loss_mask: 0.3206  decode.d8.loss_dice: 0.3605
08/06 05:43:55 - mmengine - INFO - Iter(train) [ 25300/320000]  base_lr: 9.2856e-05 lr: 9.2856e-06  eta: 1 day, 16:12:31  time: 0.4913  data_time: 0.0109  memory: 5908  grad_norm: 158.8702  loss: 9.8445  decode.loss_cls: 0.2147  decode.loss_mask: 0.3769  decode.loss_dice: 0.3473  decode.d0.loss_cls: 0.9035  decode.d0.loss_mask: 0.3641  decode.d0.loss_dice: 0.4104  decode.d1.loss_cls: 0.2832  decode.d1.loss_mask: 0.3819  decode.d1.loss_dice: 0.3644  decode.d2.loss_cls: 0.1665  decode.d2.loss_mask: 0.3724  decode.d2.loss_dice: 0.3669  decode.d3.loss_cls: 0.1347  decode.d3.loss_mask: 0.3707  decode.d3.loss_dice: 0.3521  decode.d4.loss_cls: 0.1683  decode.d4.loss_mask: 0.3703  decode.d4.loss_dice: 0.3464  decode.d5.loss_cls: 0.1629  decode.d5.loss_mask: 0.3713  decode.d5.loss_dice: 0.3353  decode.d6.loss_cls: 0.1175  decode.d6.loss_mask: 0.3614  decode.d6.loss_dice: 0.3605  decode.d7.loss_cls: 0.1726  decode.d7.loss_mask: 0.3835  decode.d7.loss_dice: 0.3534  decode.d8.loss_cls: 0.2010  decode.d8.loss_mask: 0.3811  decode.d8.loss_dice: 0.3491
08/06 05:44:20 - mmengine - INFO - Iter(train) [ 25350/320000]  base_lr: 9.2841e-05 lr: 9.2841e-06  eta: 1 day, 16:12:08  time: 0.4919  data_time: 0.0106  memory: 5907  grad_norm: 144.9491  loss: 5.9701  decode.loss_cls: 0.0468  decode.loss_mask: 0.2115  decode.loss_dice: 0.2509  decode.d0.loss_cls: 0.9369  decode.d0.loss_mask: 0.2082  decode.d0.loss_dice: 0.2722  decode.d1.loss_cls: 0.0830  decode.d1.loss_mask: 0.2043  decode.d1.loss_dice: 0.2537  decode.d2.loss_cls: 0.0233  decode.d2.loss_mask: 0.2149  decode.d2.loss_dice: 0.2590  decode.d3.loss_cls: 0.0349  decode.d3.loss_mask: 0.2073  decode.d3.loss_dice: 0.2477  decode.d4.loss_cls: 0.0417  decode.d4.loss_mask: 0.2024  decode.d4.loss_dice: 0.2476  decode.d5.loss_cls: 0.0492  decode.d5.loss_mask: 0.2049  decode.d5.loss_dice: 0.2486  decode.d6.loss_cls: 0.0620  decode.d6.loss_mask: 0.2048  decode.d6.loss_dice: 0.2511  decode.d7.loss_cls: 0.0622  decode.d7.loss_mask: 0.2029  decode.d7.loss_dice: 0.2430  decode.d8.loss_cls: 0.0374  decode.d8.loss_mask: 0.2061  decode.d8.loss_dice: 0.2516
08/06 05:44:44 - mmengine - INFO - Iter(train) [ 25400/320000]  base_lr: 9.2827e-05 lr: 9.2827e-06  eta: 1 day, 16:11:44  time: 0.4924  data_time: 0.0110  memory: 5926  grad_norm: 149.6049  loss: 8.4658  decode.loss_cls: 0.1433  decode.loss_mask: 0.2757  decode.loss_dice: 0.3091  decode.d0.loss_cls: 1.0458  decode.d0.loss_mask: 0.2641  decode.d0.loss_dice: 0.3075  decode.d1.loss_cls: 0.3013  decode.d1.loss_mask: 0.2749  decode.d1.loss_dice: 0.3029  decode.d2.loss_cls: 0.2151  decode.d2.loss_mask: 0.2549  decode.d2.loss_dice: 0.2962  decode.d3.loss_cls: 0.1360  decode.d3.loss_mask: 0.2731  decode.d3.loss_dice: 0.3029  decode.d4.loss_cls: 0.2052  decode.d4.loss_mask: 0.2674  decode.d4.loss_dice: 0.2946  decode.d5.loss_cls: 0.1621  decode.d5.loss_mask: 0.2820  decode.d5.loss_dice: 0.3021  decode.d6.loss_cls: 0.1571  decode.d6.loss_mask: 0.2725  decode.d6.loss_dice: 0.3005  decode.d7.loss_cls: 0.1482  decode.d7.loss_mask: 0.2710  decode.d7.loss_dice: 0.3115  decode.d8.loss_cls: 0.2420  decode.d8.loss_mask: 0.2515  decode.d8.loss_dice: 0.2951
08/06 05:45:09 - mmengine - INFO - Iter(train) [ 25450/320000]  base_lr: 9.2813e-05 lr: 9.2813e-06  eta: 1 day, 16:11:20  time: 0.4918  data_time: 0.0106  memory: 5908  grad_norm: 139.4304  loss: 10.9604  decode.loss_cls: 0.3525  decode.loss_mask: 0.2914  decode.loss_dice: 0.3658  decode.d0.loss_cls: 1.0050  decode.d0.loss_mask: 0.3045  decode.d0.loss_dice: 0.3813  decode.d1.loss_cls: 0.2745  decode.d1.loss_mask: 0.3028  decode.d1.loss_dice: 0.4269  decode.d2.loss_cls: 0.2878  decode.d2.loss_mask: 0.2959  decode.d2.loss_dice: 0.3906  decode.d3.loss_cls: 0.5032  decode.d3.loss_mask: 0.2759  decode.d3.loss_dice: 0.3808  decode.d4.loss_cls: 0.3798  decode.d4.loss_mask: 0.2778  decode.d4.loss_dice: 0.3768  decode.d5.loss_cls: 0.3956  decode.d5.loss_mask: 0.2852  decode.d5.loss_dice: 0.3865  decode.d6.loss_cls: 0.3283  decode.d6.loss_mask: 0.2901  decode.d6.loss_dice: 0.4019  decode.d7.loss_cls: 0.3016  decode.d7.loss_mask: 0.2870  decode.d7.loss_dice: 0.3987  decode.d8.loss_cls: 0.3175  decode.d8.loss_mask: 0.2953  decode.d8.loss_dice: 0.3992
08/06 05:45:34 - mmengine - INFO - Iter(train) [ 25500/320000]  base_lr: 9.2799e-05 lr: 9.2799e-06  eta: 1 day, 16:10:56  time: 0.4916  data_time: 0.0107  memory: 5890  grad_norm: 144.6033  loss: 8.0133  decode.loss_cls: 0.1101  decode.loss_mask: 0.2547  decode.loss_dice: 0.3385  decode.d0.loss_cls: 0.9407  decode.d0.loss_mask: 0.2601  decode.d0.loss_dice: 0.3089  decode.d1.loss_cls: 0.1634  decode.d1.loss_mask: 0.2614  decode.d1.loss_dice: 0.3330  decode.d2.loss_cls: 0.1309  decode.d2.loss_mask: 0.2554  decode.d2.loss_dice: 0.3123  decode.d3.loss_cls: 0.1016  decode.d3.loss_mask: 0.2573  decode.d3.loss_dice: 0.3426  decode.d4.loss_cls: 0.1674  decode.d4.loss_mask: 0.2570  decode.d4.loss_dice: 0.3192  decode.d5.loss_cls: 0.1277  decode.d5.loss_mask: 0.2568  decode.d5.loss_dice: 0.3223  decode.d6.loss_cls: 0.1339  decode.d6.loss_mask: 0.2605  decode.d6.loss_dice: 0.3145  decode.d7.loss_cls: 0.1103  decode.d7.loss_mask: 0.2570  decode.d7.loss_dice: 0.3324  decode.d8.loss_cls: 0.1948  decode.d8.loss_mask: 0.2575  decode.d8.loss_dice: 0.3314
08/06 05:45:58 - mmengine - INFO - Iter(train) [ 25550/320000]  base_lr: 9.2785e-05 lr: 9.2785e-06  eta: 1 day, 16:10:32  time: 0.4924  data_time: 0.0110  memory: 5927  grad_norm: 99.8515  loss: 9.8105  decode.loss_cls: 0.3990  decode.loss_mask: 0.2301  decode.loss_dice: 0.2684  decode.d0.loss_cls: 1.0153  decode.d0.loss_mask: 0.2384  decode.d0.loss_dice: 0.3141  decode.d1.loss_cls: 0.4577  decode.d1.loss_mask: 0.2367  decode.d1.loss_dice: 0.2944  decode.d2.loss_cls: 0.4461  decode.d2.loss_mask: 0.2300  decode.d2.loss_dice: 0.3012  decode.d3.loss_cls: 0.3513  decode.d3.loss_mask: 0.2313  decode.d3.loss_dice: 0.2704  decode.d4.loss_cls: 0.3632  decode.d4.loss_mask: 0.2333  decode.d4.loss_dice: 0.3029  decode.d5.loss_cls: 0.4073  decode.d5.loss_mask: 0.2294  decode.d5.loss_dice: 0.2581  decode.d6.loss_cls: 0.3711  decode.d6.loss_mask: 0.2308  decode.d6.loss_dice: 0.3083  decode.d7.loss_cls: 0.3876  decode.d7.loss_mask: 0.2314  decode.d7.loss_dice: 0.2972  decode.d8.loss_cls: 0.3884  decode.d8.loss_mask: 0.2313  decode.d8.loss_dice: 0.2859
08/06 05:46:23 - mmengine - INFO - Iter(train) [ 25600/320000]  base_lr: 9.2771e-05 lr: 9.2771e-06  eta: 1 day, 16:10:08  time: 0.4932  data_time: 0.0110  memory: 5874  grad_norm: 197.0073  loss: 8.9391  decode.loss_cls: 0.3256  decode.loss_mask: 0.2168  decode.loss_dice: 0.2979  decode.d0.loss_cls: 1.0184  decode.d0.loss_mask: 0.2145  decode.d0.loss_dice: 0.2937  decode.d1.loss_cls: 0.3605  decode.d1.loss_mask: 0.2110  decode.d1.loss_dice: 0.2941  decode.d2.loss_cls: 0.2971  decode.d2.loss_mask: 0.2229  decode.d2.loss_dice: 0.2994  decode.d3.loss_cls: 0.2672  decode.d3.loss_mask: 0.2212  decode.d3.loss_dice: 0.2947  decode.d4.loss_cls: 0.3192  decode.d4.loss_mask: 0.2176  decode.d4.loss_dice: 0.3251  decode.d5.loss_cls: 0.2302  decode.d5.loss_mask: 0.2160  decode.d5.loss_dice: 0.2884  decode.d6.loss_cls: 0.3008  decode.d6.loss_mask: 0.2171  decode.d6.loss_dice: 0.3052  decode.d7.loss_cls: 0.2842  decode.d7.loss_mask: 0.2170  decode.d7.loss_dice: 0.3117  decode.d8.loss_cls: 0.3492  decode.d8.loss_mask: 0.2132  decode.d8.loss_dice: 0.3092
08/06 05:46:47 - mmengine - INFO - Iter(train) [ 25650/320000]  base_lr: 9.2756e-05 lr: 9.2756e-06  eta: 1 day, 16:09:44  time: 0.4924  data_time: 0.0109  memory: 5890  grad_norm: 152.1460  loss: 9.9544  decode.loss_cls: 0.2321  decode.loss_mask: 0.3337  decode.loss_dice: 0.3144  decode.d0.loss_cls: 1.0057  decode.d0.loss_mask: 0.3445  decode.d0.loss_dice: 0.3427  decode.d1.loss_cls: 0.3270  decode.d1.loss_mask: 0.3462  decode.d1.loss_dice: 0.3318  decode.d2.loss_cls: 0.2945  decode.d2.loss_mask: 0.3389  decode.d2.loss_dice: 0.2998  decode.d3.loss_cls: 0.3095  decode.d3.loss_mask: 0.3380  decode.d3.loss_dice: 0.3052  decode.d4.loss_cls: 0.2897  decode.d4.loss_mask: 0.3318  decode.d4.loss_dice: 0.3147  decode.d5.loss_cls: 0.2302  decode.d5.loss_mask: 0.3288  decode.d5.loss_dice: 0.3098  decode.d6.loss_cls: 0.2824  decode.d6.loss_mask: 0.3289  decode.d6.loss_dice: 0.2951  decode.d7.loss_cls: 0.2673  decode.d7.loss_mask: 0.3362  decode.d7.loss_dice: 0.2972  decode.d8.loss_cls: 0.2395  decode.d8.loss_mask: 0.3253  decode.d8.loss_dice: 0.3134
08/06 05:47:12 - mmengine - INFO - Iter(train) [ 25700/320000]  base_lr: 9.2742e-05 lr: 9.2742e-06  eta: 1 day, 16:09:20  time: 0.4917  data_time: 0.0106  memory: 5907  grad_norm: 98.8077  loss: 8.5002  decode.loss_cls: 0.1671  decode.loss_mask: 0.2751  decode.loss_dice: 0.3040  decode.d0.loss_cls: 0.9730  decode.d0.loss_mask: 0.2821  decode.d0.loss_dice: 0.3241  decode.d1.loss_cls: 0.1768  decode.d1.loss_mask: 0.2828  decode.d1.loss_dice: 0.3391  decode.d2.loss_cls: 0.1574  decode.d2.loss_mask: 0.2721  decode.d2.loss_dice: 0.3043  decode.d3.loss_cls: 0.2287  decode.d3.loss_mask: 0.2743  decode.d3.loss_dice: 0.3165  decode.d4.loss_cls: 0.1630  decode.d4.loss_mask: 0.2731  decode.d4.loss_dice: 0.3484  decode.d5.loss_cls: 0.1969  decode.d5.loss_mask: 0.2729  decode.d5.loss_dice: 0.3272  decode.d6.loss_cls: 0.1934  decode.d6.loss_mask: 0.2736  decode.d6.loss_dice: 0.2998  decode.d7.loss_cls: 0.1432  decode.d7.loss_mask: 0.2744  decode.d7.loss_dice: 0.3198  decode.d8.loss_cls: 0.1434  decode.d8.loss_mask: 0.2725  decode.d8.loss_dice: 0.3210
08/06 05:47:37 - mmengine - INFO - Iter(train) [ 25750/320000]  base_lr: 9.2728e-05 lr: 9.2728e-06  eta: 1 day, 16:08:57  time: 0.4920  data_time: 0.0108  memory: 5892  grad_norm: 133.0934  loss: 6.7804  decode.loss_cls: 0.2033  decode.loss_mask: 0.1847  decode.loss_dice: 0.2467  decode.d0.loss_cls: 0.8919  decode.d0.loss_mask: 0.1930  decode.d0.loss_dice: 0.2685  decode.d1.loss_cls: 0.1515  decode.d1.loss_mask: 0.1898  decode.d1.loss_dice: 0.2532  decode.d2.loss_cls: 0.1896  decode.d2.loss_mask: 0.1867  decode.d2.loss_dice: 0.2307  decode.d3.loss_cls: 0.1608  decode.d3.loss_mask: 0.1859  decode.d3.loss_dice: 0.2283  decode.d4.loss_cls: 0.1483  decode.d4.loss_mask: 0.1861  decode.d4.loss_dice: 0.2481  decode.d5.loss_cls: 0.1485  decode.d5.loss_mask: 0.1876  decode.d5.loss_dice: 0.2436  decode.d6.loss_cls: 0.1892  decode.d6.loss_mask: 0.1885  decode.d6.loss_dice: 0.2401  decode.d7.loss_cls: 0.2090  decode.d7.loss_mask: 0.1874  decode.d7.loss_dice: 0.2313  decode.d8.loss_cls: 0.1823  decode.d8.loss_mask: 0.1882  decode.d8.loss_dice: 0.2378
08/06 05:48:01 - mmengine - INFO - Iter(train) [ 25800/320000]  base_lr: 9.2714e-05 lr: 9.2714e-06  eta: 1 day, 16:08:34  time: 0.4920  data_time: 0.0106  memory: 5910  grad_norm: 243.2679  loss: 6.9129  decode.loss_cls: 0.1113  decode.loss_mask: 0.2248  decode.loss_dice: 0.2567  decode.d0.loss_cls: 1.0244  decode.d0.loss_mask: 0.2345  decode.d0.loss_dice: 0.2630  decode.d1.loss_cls: 0.1985  decode.d1.loss_mask: 0.2258  decode.d1.loss_dice: 0.2788  decode.d2.loss_cls: 0.0482  decode.d2.loss_mask: 0.2294  decode.d2.loss_dice: 0.2675  decode.d3.loss_cls: 0.1199  decode.d3.loss_mask: 0.2241  decode.d3.loss_dice: 0.2740  decode.d4.loss_cls: 0.0462  decode.d4.loss_mask: 0.2333  decode.d4.loss_dice: 0.2651  decode.d5.loss_cls: 0.0510  decode.d5.loss_mask: 0.2324  decode.d5.loss_dice: 0.2604  decode.d6.loss_cls: 0.0748  decode.d6.loss_mask: 0.2326  decode.d6.loss_dice: 0.2676  decode.d7.loss_cls: 0.1433  decode.d7.loss_mask: 0.2392  decode.d7.loss_dice: 0.2974  decode.d8.loss_cls: 0.0945  decode.d8.loss_mask: 0.2302  decode.d8.loss_dice: 0.2642
08/06 05:48:26 - mmengine - INFO - Iter(train) [ 25850/320000]  base_lr: 9.2700e-05 lr: 9.2700e-06  eta: 1 day, 16:08:10  time: 0.4925  data_time: 0.0108  memory: 5907  grad_norm: 115.9552  loss: 5.9557  decode.loss_cls: 0.0741  decode.loss_mask: 0.1802  decode.loss_dice: 0.2422  decode.d0.loss_cls: 0.8999  decode.d0.loss_mask: 0.1892  decode.d0.loss_dice: 0.2592  decode.d1.loss_cls: 0.0806  decode.d1.loss_mask: 0.1831  decode.d1.loss_dice: 0.2473  decode.d2.loss_cls: 0.0794  decode.d2.loss_mask: 0.1811  decode.d2.loss_dice: 0.2482  decode.d3.loss_cls: 0.0841  decode.d3.loss_mask: 0.1907  decode.d3.loss_dice: 0.2460  decode.d4.loss_cls: 0.0801  decode.d4.loss_mask: 0.1897  decode.d4.loss_dice: 0.2565  decode.d5.loss_cls: 0.0873  decode.d5.loss_mask: 0.1857  decode.d5.loss_dice: 0.2460  decode.d6.loss_cls: 0.0779  decode.d6.loss_mask: 0.1846  decode.d6.loss_dice: 0.2447  decode.d7.loss_cls: 0.0806  decode.d7.loss_mask: 0.1818  decode.d7.loss_dice: 0.2433  decode.d8.loss_cls: 0.0798  decode.d8.loss_mask: 0.1840  decode.d8.loss_dice: 0.2483
08/06 05:48:51 - mmengine - INFO - Iter(train) [ 25900/320000]  base_lr: 9.2685e-05 lr: 9.2685e-06  eta: 1 day, 16:07:46  time: 0.4926  data_time: 0.0106  memory: 5874  grad_norm: 91.0548  loss: 8.8181  decode.loss_cls: 0.1847  decode.loss_mask: 0.2695  decode.loss_dice: 0.3453  decode.d0.loss_cls: 0.7715  decode.d0.loss_mask: 0.2604  decode.d0.loss_dice: 0.3740  decode.d1.loss_cls: 0.1509  decode.d1.loss_mask: 0.2499  decode.d1.loss_dice: 0.3590  decode.d2.loss_cls: 0.1824  decode.d2.loss_mask: 0.2834  decode.d2.loss_dice: 0.3683  decode.d3.loss_cls: 0.2322  decode.d3.loss_mask: 0.2693  decode.d3.loss_dice: 0.3442  decode.d4.loss_cls: 0.2229  decode.d4.loss_mask: 0.2765  decode.d4.loss_dice: 0.3715  decode.d5.loss_cls: 0.1896  decode.d5.loss_mask: 0.2652  decode.d5.loss_dice: 0.3426  decode.d6.loss_cls: 0.2260  decode.d6.loss_mask: 0.2732  decode.d6.loss_dice: 0.3427  decode.d7.loss_cls: 0.1804  decode.d7.loss_mask: 0.2699  decode.d7.loss_dice: 0.3462  decode.d8.loss_cls: 0.2568  decode.d8.loss_mask: 0.2660  decode.d8.loss_dice: 0.3438
08/06 05:49:15 - mmengine - INFO - Iter(train) [ 25950/320000]  base_lr: 9.2671e-05 lr: 9.2671e-06  eta: 1 day, 16:07:22  time: 0.4932  data_time: 0.0107  memory: 5907  grad_norm: 147.4855  loss: 7.5470  decode.loss_cls: 0.1637  decode.loss_mask: 0.2592  decode.loss_dice: 0.2262  decode.d0.loss_cls: 0.9515  decode.d0.loss_mask: 0.2700  decode.d0.loss_dice: 0.2612  decode.d1.loss_cls: 0.2682  decode.d1.loss_mask: 0.2546  decode.d1.loss_dice: 0.2265  decode.d2.loss_cls: 0.1656  decode.d2.loss_mask: 0.2527  decode.d2.loss_dice: 0.2605  decode.d3.loss_cls: 0.1697  decode.d3.loss_mask: 0.2598  decode.d3.loss_dice: 0.2236  decode.d4.loss_cls: 0.2099  decode.d4.loss_mask: 0.2434  decode.d4.loss_dice: 0.2218  decode.d5.loss_cls: 0.1835  decode.d5.loss_mask: 0.2507  decode.d5.loss_dice: 0.2433  decode.d6.loss_cls: 0.1961  decode.d6.loss_mask: 0.2549  decode.d6.loss_dice: 0.2318  decode.d7.loss_cls: 0.1401  decode.d7.loss_mask: 0.2494  decode.d7.loss_dice: 0.2478  decode.d8.loss_cls: 0.1561  decode.d8.loss_mask: 0.2537  decode.d8.loss_dice: 0.2517
08/06 05:49:40 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 05:49:40 - mmengine - INFO - Iter(train) [ 26000/320000]  base_lr: 9.2657e-05 lr: 9.2657e-06  eta: 1 day, 16:06:58  time: 0.4932  data_time: 0.0109  memory: 5908  grad_norm: 65.8311  loss: 7.3150  decode.loss_cls: 0.1376  decode.loss_mask: 0.2398  decode.loss_dice: 0.3140  decode.d0.loss_cls: 0.9567  decode.d0.loss_mask: 0.2445  decode.d0.loss_dice: 0.2874  decode.d1.loss_cls: 0.1246  decode.d1.loss_mask: 0.2384  decode.d1.loss_dice: 0.2634  decode.d2.loss_cls: 0.1236  decode.d2.loss_mask: 0.2335  decode.d2.loss_dice: 0.2868  decode.d3.loss_cls: 0.1074  decode.d3.loss_mask: 0.2379  decode.d3.loss_dice: 0.3043  decode.d4.loss_cls: 0.1072  decode.d4.loss_mask: 0.2372  decode.d4.loss_dice: 0.2677  decode.d5.loss_cls: 0.1025  decode.d5.loss_mask: 0.2365  decode.d5.loss_dice: 0.2795  decode.d6.loss_cls: 0.1423  decode.d6.loss_mask: 0.2374  decode.d6.loss_dice: 0.2632  decode.d7.loss_cls: 0.1402  decode.d7.loss_mask: 0.2338  decode.d7.loss_dice: 0.2740  decode.d8.loss_cls: 0.1355  decode.d8.loss_mask: 0.2454  decode.d8.loss_dice: 0.3127
08/06 05:50:05 - mmengine - INFO - Iter(train) [ 26050/320000]  base_lr: 9.2643e-05 lr: 9.2643e-06  eta: 1 day, 16:06:34  time: 0.4928  data_time: 0.0110  memory: 5874  grad_norm: 150.8545  loss: 6.9713  decode.loss_cls: 0.1371  decode.loss_mask: 0.2225  decode.loss_dice: 0.2260  decode.d0.loss_cls: 0.9173  decode.d0.loss_mask: 0.2311  decode.d0.loss_dice: 0.2551  decode.d1.loss_cls: 0.1592  decode.d1.loss_mask: 0.2083  decode.d1.loss_dice: 0.2336  decode.d2.loss_cls: 0.1438  decode.d2.loss_mask: 0.2135  decode.d2.loss_dice: 0.2346  decode.d3.loss_cls: 0.1551  decode.d3.loss_mask: 0.2153  decode.d3.loss_dice: 0.2280  decode.d4.loss_cls: 0.2143  decode.d4.loss_mask: 0.2220  decode.d4.loss_dice: 0.2329  decode.d5.loss_cls: 0.1848  decode.d5.loss_mask: 0.2388  decode.d5.loss_dice: 0.2580  decode.d6.loss_cls: 0.1558  decode.d6.loss_mask: 0.2261  decode.d6.loss_dice: 0.2437  decode.d7.loss_cls: 0.1550  decode.d7.loss_mask: 0.2238  decode.d7.loss_dice: 0.2419  decode.d8.loss_cls: 0.1360  decode.d8.loss_mask: 0.2236  decode.d8.loss_dice: 0.2342
08/06 05:50:29 - mmengine - INFO - Iter(train) [ 26100/320000]  base_lr: 9.2629e-05 lr: 9.2629e-06  eta: 1 day, 16:06:13  time: 0.4920  data_time: 0.0108  memory: 5908  grad_norm: 175.5476  loss: 9.0180  decode.loss_cls: 0.0714  decode.loss_mask: 0.4050  decode.loss_dice: 0.3343  decode.d0.loss_cls: 0.9049  decode.d0.loss_mask: 0.4172  decode.d0.loss_dice: 0.3193  decode.d1.loss_cls: 0.1601  decode.d1.loss_mask: 0.4199  decode.d1.loss_dice: 0.3381  decode.d2.loss_cls: 0.1143  decode.d2.loss_mask: 0.4177  decode.d2.loss_dice: 0.3100  decode.d3.loss_cls: 0.0352  decode.d3.loss_mask: 0.4167  decode.d3.loss_dice: 0.3348  decode.d4.loss_cls: 0.0360  decode.d4.loss_mask: 0.4154  decode.d4.loss_dice: 0.3230  decode.d5.loss_cls: 0.0439  decode.d5.loss_mask: 0.4142  decode.d5.loss_dice: 0.3290  decode.d6.loss_cls: 0.0360  decode.d6.loss_mask: 0.4221  decode.d6.loss_dice: 0.3338  decode.d7.loss_cls: 0.0910  decode.d7.loss_mask: 0.4062  decode.d7.loss_dice: 0.3348  decode.d8.loss_cls: 0.0760  decode.d8.loss_mask: 0.4165  decode.d8.loss_dice: 0.3415
08/06 05:50:54 - mmengine - INFO - Iter(train) [ 26150/320000]  base_lr: 9.2615e-05 lr: 9.2615e-06  eta: 1 day, 16:05:49  time: 0.4925  data_time: 0.0109  memory: 5892  grad_norm: 226.2875  loss: 9.0416  decode.loss_cls: 0.2553  decode.loss_mask: 0.2660  decode.loss_dice: 0.3164  decode.d0.loss_cls: 0.8868  decode.d0.loss_mask: 0.2824  decode.d0.loss_dice: 0.3415  decode.d1.loss_cls: 0.2491  decode.d1.loss_mask: 0.2702  decode.d1.loss_dice: 0.3068  decode.d2.loss_cls: 0.2255  decode.d2.loss_mask: 0.2693  decode.d2.loss_dice: 0.3100  decode.d3.loss_cls: 0.3020  decode.d3.loss_mask: 0.2626  decode.d3.loss_dice: 0.3049  decode.d4.loss_cls: 0.2793  decode.d4.loss_mask: 0.2706  decode.d4.loss_dice: 0.3145  decode.d5.loss_cls: 0.2603  decode.d5.loss_mask: 0.2807  decode.d5.loss_dice: 0.3164  decode.d6.loss_cls: 0.2081  decode.d6.loss_mask: 0.2762  decode.d6.loss_dice: 0.3288  decode.d7.loss_cls: 0.2228  decode.d7.loss_mask: 0.2768  decode.d7.loss_dice: 0.3417  decode.d8.loss_cls: 0.2053  decode.d8.loss_mask: 0.2868  decode.d8.loss_dice: 0.3246
08/06 05:51:19 - mmengine - INFO - Iter(train) [ 26200/320000]  base_lr: 9.2600e-05 lr: 9.2600e-06  eta: 1 day, 16:05:25  time: 0.4928  data_time: 0.0110  memory: 5890  grad_norm: 206.0520  loss: 8.7850  decode.loss_cls: 0.2087  decode.loss_mask: 0.2864  decode.loss_dice: 0.3037  decode.d0.loss_cls: 0.9179  decode.d0.loss_mask: 0.3278  decode.d0.loss_dice: 0.3065  decode.d1.loss_cls: 0.2165  decode.d1.loss_mask: 0.2911  decode.d1.loss_dice: 0.3013  decode.d2.loss_cls: 0.2467  decode.d2.loss_mask: 0.2797  decode.d2.loss_dice: 0.2781  decode.d3.loss_cls: 0.1683  decode.d3.loss_mask: 0.2864  decode.d3.loss_dice: 0.2958  decode.d4.loss_cls: 0.2924  decode.d4.loss_mask: 0.2852  decode.d4.loss_dice: 0.2913  decode.d5.loss_cls: 0.2417  decode.d5.loss_mask: 0.2924  decode.d5.loss_dice: 0.2961  decode.d6.loss_cls: 0.2003  decode.d6.loss_mask: 0.2830  decode.d6.loss_dice: 0.2945  decode.d7.loss_cls: 0.2287  decode.d7.loss_mask: 0.2831  decode.d7.loss_dice: 0.2914  decode.d8.loss_cls: 0.1954  decode.d8.loss_mask: 0.2956  decode.d8.loss_dice: 0.2988
08/06 05:51:43 - mmengine - INFO - Iter(train) [ 26250/320000]  base_lr: 9.2586e-05 lr: 9.2586e-06  eta: 1 day, 16:05:01  time: 0.4925  data_time: 0.0109  memory: 5892  grad_norm: 310.3050  loss: 9.1712  decode.loss_cls: 0.2257  decode.loss_mask: 0.2551  decode.loss_dice: 0.3357  decode.d0.loss_cls: 1.0108  decode.d0.loss_mask: 0.2740  decode.d0.loss_dice: 0.4148  decode.d1.loss_cls: 0.2715  decode.d1.loss_mask: 0.2699  decode.d1.loss_dice: 0.3748  decode.d2.loss_cls: 0.2324  decode.d2.loss_mask: 0.2563  decode.d2.loss_dice: 0.3383  decode.d3.loss_cls: 0.2283  decode.d3.loss_mask: 0.2548  decode.d3.loss_dice: 0.3374  decode.d4.loss_cls: 0.2125  decode.d4.loss_mask: 0.2555  decode.d4.loss_dice: 0.3542  decode.d5.loss_cls: 0.2190  decode.d5.loss_mask: 0.2550  decode.d5.loss_dice: 0.3583  decode.d6.loss_cls: 0.2486  decode.d6.loss_mask: 0.2540  decode.d6.loss_dice: 0.3379  decode.d7.loss_cls: 0.1971  decode.d7.loss_mask: 0.2556  decode.d7.loss_dice: 0.3392  decode.d8.loss_cls: 0.2339  decode.d8.loss_mask: 0.2522  decode.d8.loss_dice: 0.3184
08/06 05:52:08 - mmengine - INFO - Iter(train) [ 26300/320000]  base_lr: 9.2572e-05 lr: 9.2572e-06  eta: 1 day, 16:04:37  time: 0.4932  data_time: 0.0109  memory: 5877  grad_norm: 114.3951  loss: 11.2892  decode.loss_cls: 0.3238  decode.loss_mask: 0.3074  decode.loss_dice: 0.4415  decode.d0.loss_cls: 1.0714  decode.d0.loss_mask: 0.3045  decode.d0.loss_dice: 0.4038  decode.d1.loss_cls: 0.4033  decode.d1.loss_mask: 0.2985  decode.d1.loss_dice: 0.4084  decode.d2.loss_cls: 0.3198  decode.d2.loss_mask: 0.2977  decode.d2.loss_dice: 0.4164  decode.d3.loss_cls: 0.3700  decode.d3.loss_mask: 0.2921  decode.d3.loss_dice: 0.3880  decode.d4.loss_cls: 0.4088  decode.d4.loss_mask: 0.2981  decode.d4.loss_dice: 0.4273  decode.d5.loss_cls: 0.3163  decode.d5.loss_mask: 0.2993  decode.d5.loss_dice: 0.4357  decode.d6.loss_cls: 0.3038  decode.d6.loss_mask: 0.3028  decode.d6.loss_dice: 0.4153  decode.d7.loss_cls: 0.3111  decode.d7.loss_mask: 0.2990  decode.d7.loss_dice: 0.3731  decode.d8.loss_cls: 0.3530  decode.d8.loss_mask: 0.2964  decode.d8.loss_dice: 0.4026
08/06 05:52:33 - mmengine - INFO - Iter(train) [ 26350/320000]  base_lr: 9.2558e-05 lr: 9.2558e-06  eta: 1 day, 16:04:14  time: 0.4932  data_time: 0.0109  memory: 5907  grad_norm: 303.5513  loss: 9.2105  decode.loss_cls: 0.1452  decode.loss_mask: 0.3342  decode.loss_dice: 0.3454  decode.d0.loss_cls: 0.9414  decode.d0.loss_mask: 0.3254  decode.d0.loss_dice: 0.3555  decode.d1.loss_cls: 0.3101  decode.d1.loss_mask: 0.3252  decode.d1.loss_dice: 0.3515  decode.d2.loss_cls: 0.1955  decode.d2.loss_mask: 0.3188  decode.d2.loss_dice: 0.3410  decode.d3.loss_cls: 0.1536  decode.d3.loss_mask: 0.3198  decode.d3.loss_dice: 0.3366  decode.d4.loss_cls: 0.1194  decode.d4.loss_mask: 0.3271  decode.d4.loss_dice: 0.3447  decode.d5.loss_cls: 0.1437  decode.d5.loss_mask: 0.3171  decode.d5.loss_dice: 0.3346  decode.d6.loss_cls: 0.1655  decode.d6.loss_mask: 0.3255  decode.d6.loss_dice: 0.3405  decode.d7.loss_cls: 0.1274  decode.d7.loss_mask: 0.3235  decode.d7.loss_dice: 0.3359  decode.d8.loss_cls: 0.2351  decode.d8.loss_mask: 0.3158  decode.d8.loss_dice: 0.3553
08/06 05:52:57 - mmengine - INFO - Iter(train) [ 26400/320000]  base_lr: 9.2544e-05 lr: 9.2544e-06  eta: 1 day, 16:03:50  time: 0.4930  data_time: 0.0111  memory: 5892  grad_norm: 137.3571  loss: 11.4533  decode.loss_cls: 0.4658  decode.loss_mask: 0.3416  decode.loss_dice: 0.3715  decode.d0.loss_cls: 1.0294  decode.d0.loss_mask: 0.3395  decode.d0.loss_dice: 0.3738  decode.d1.loss_cls: 0.3591  decode.d1.loss_mask: 0.3482  decode.d1.loss_dice: 0.3093  decode.d2.loss_cls: 0.2887  decode.d2.loss_mask: 0.3413  decode.d2.loss_dice: 0.3413  decode.d3.loss_cls: 0.3306  decode.d3.loss_mask: 0.3477  decode.d3.loss_dice: 0.3614  decode.d4.loss_cls: 0.3698  decode.d4.loss_mask: 0.3410  decode.d4.loss_dice: 0.3729  decode.d5.loss_cls: 0.3215  decode.d5.loss_mask: 0.3561  decode.d5.loss_dice: 0.3935  decode.d6.loss_cls: 0.3561  decode.d6.loss_mask: 0.3375  decode.d6.loss_dice: 0.3953  decode.d7.loss_cls: 0.3969  decode.d7.loss_mask: 0.3324  decode.d7.loss_dice: 0.3700  decode.d8.loss_cls: 0.4223  decode.d8.loss_mask: 0.3476  decode.d8.loss_dice: 0.3914
08/06 05:53:22 - mmengine - INFO - Iter(train) [ 26450/320000]  base_lr: 9.2529e-05 lr: 9.2529e-06  eta: 1 day, 16:03:26  time: 0.4934  data_time: 0.0109  memory: 5927  grad_norm: 101.7107  loss: 8.5557  decode.loss_cls: 0.1674  decode.loss_mask: 0.2593  decode.loss_dice: 0.2901  decode.d0.loss_cls: 0.9266  decode.d0.loss_mask: 0.2662  decode.d0.loss_dice: 0.3393  decode.d1.loss_cls: 0.2160  decode.d1.loss_mask: 0.2643  decode.d1.loss_dice: 0.2872  decode.d2.loss_cls: 0.2520  decode.d2.loss_mask: 0.2625  decode.d2.loss_dice: 0.2971  decode.d3.loss_cls: 0.2473  decode.d3.loss_mask: 0.2594  decode.d3.loss_dice: 0.2847  decode.d4.loss_cls: 0.2911  decode.d4.loss_mask: 0.2559  decode.d4.loss_dice: 0.2954  decode.d5.loss_cls: 0.2380  decode.d5.loss_mask: 0.2624  decode.d5.loss_dice: 0.2891  decode.d6.loss_cls: 0.2041  decode.d6.loss_mask: 0.2609  decode.d6.loss_dice: 0.3181  decode.d7.loss_cls: 0.2056  decode.d7.loss_mask: 0.2632  decode.d7.loss_dice: 0.2926  decode.d8.loss_cls: 0.2069  decode.d8.loss_mask: 0.2589  decode.d8.loss_dice: 0.2941
08/06 05:53:46 - mmengine - INFO - Iter(train) [ 26500/320000]  base_lr: 9.2515e-05 lr: 9.2515e-06  eta: 1 day, 16:03:02  time: 0.4923  data_time: 0.0108  memory: 5910  grad_norm: 161.6218  loss: 8.3420  decode.loss_cls: 0.2201  decode.loss_mask: 0.2705  decode.loss_dice: 0.2777  decode.d0.loss_cls: 0.8849  decode.d0.loss_mask: 0.2841  decode.d0.loss_dice: 0.3092  decode.d1.loss_cls: 0.2592  decode.d1.loss_mask: 0.2554  decode.d1.loss_dice: 0.2946  decode.d2.loss_cls: 0.2761  decode.d2.loss_mask: 0.2578  decode.d2.loss_dice: 0.2974  decode.d3.loss_cls: 0.2009  decode.d3.loss_mask: 0.2505  decode.d3.loss_dice: 0.2648  decode.d4.loss_cls: 0.1760  decode.d4.loss_mask: 0.2508  decode.d4.loss_dice: 0.2705  decode.d5.loss_cls: 0.1632  decode.d5.loss_mask: 0.2930  decode.d5.loss_dice: 0.3230  decode.d6.loss_cls: 0.1505  decode.d6.loss_mask: 0.3005  decode.d6.loss_dice: 0.3160  decode.d7.loss_cls: 0.1616  decode.d7.loss_mask: 0.2845  decode.d7.loss_dice: 0.3011  decode.d8.loss_cls: 0.1924  decode.d8.loss_mask: 0.2710  decode.d8.loss_dice: 0.2847
08/06 05:54:11 - mmengine - INFO - Iter(train) [ 26550/320000]  base_lr: 9.2501e-05 lr: 9.2501e-06  eta: 1 day, 16:02:38  time: 0.4933  data_time: 0.0108  memory: 5927  grad_norm: 85.2285  loss: 6.9961  decode.loss_cls: 0.1339  decode.loss_mask: 0.1860  decode.loss_dice: 0.2393  decode.d0.loss_cls: 1.0976  decode.d0.loss_mask: 0.2105  decode.d0.loss_dice: 0.3224  decode.d1.loss_cls: 0.1896  decode.d1.loss_mask: 0.1915  decode.d1.loss_dice: 0.2673  decode.d2.loss_cls: 0.1100  decode.d2.loss_mask: 0.1870  decode.d2.loss_dice: 0.2601  decode.d3.loss_cls: 0.1537  decode.d3.loss_mask: 0.1832  decode.d3.loss_dice: 0.2538  decode.d4.loss_cls: 0.1549  decode.d4.loss_mask: 0.1837  decode.d4.loss_dice: 0.2736  decode.d5.loss_cls: 0.1614  decode.d5.loss_mask: 0.1849  decode.d5.loss_dice: 0.2761  decode.d6.loss_cls: 0.1475  decode.d6.loss_mask: 0.1859  decode.d6.loss_dice: 0.2558  decode.d7.loss_cls: 0.1426  decode.d7.loss_mask: 0.1867  decode.d7.loss_dice: 0.2666  decode.d8.loss_cls: 0.1574  decode.d8.loss_mask: 0.1843  decode.d8.loss_dice: 0.2488
08/06 05:54:36 - mmengine - INFO - Iter(train) [ 26600/320000]  base_lr: 9.2487e-05 lr: 9.2487e-06  eta: 1 day, 16:02:14  time: 0.4919  data_time: 0.0107  memory: 5926  grad_norm: 129.6233  loss: 7.4240  decode.loss_cls: 0.1259  decode.loss_mask: 0.2906  decode.loss_dice: 0.2919  decode.d0.loss_cls: 0.8454  decode.d0.loss_mask: 0.2742  decode.d0.loss_dice: 0.2891  decode.d1.loss_cls: 0.1556  decode.d1.loss_mask: 0.2647  decode.d1.loss_dice: 0.2620  decode.d2.loss_cls: 0.0608  decode.d2.loss_mask: 0.2718  decode.d2.loss_dice: 0.2936  decode.d3.loss_cls: 0.0886  decode.d3.loss_mask: 0.2615  decode.d3.loss_dice: 0.2634  decode.d4.loss_cls: 0.0871  decode.d4.loss_mask: 0.2728  decode.d4.loss_dice: 0.2731  decode.d5.loss_cls: 0.1185  decode.d5.loss_mask: 0.2629  decode.d5.loss_dice: 0.2547  decode.d6.loss_cls: 0.1520  decode.d6.loss_mask: 0.2651  decode.d6.loss_dice: 0.2903  decode.d7.loss_cls: 0.1548  decode.d7.loss_mask: 0.2569  decode.d7.loss_dice: 0.2617  decode.d8.loss_cls: 0.1985  decode.d8.loss_mask: 0.2687  decode.d8.loss_dice: 0.2679
08/06 05:55:00 - mmengine - INFO - Iter(train) [ 26650/320000]  base_lr: 9.2473e-05 lr: 9.2473e-06  eta: 1 day, 16:01:50  time: 0.4928  data_time: 0.0108  memory: 5892  grad_norm: 123.6672  loss: 7.4160  decode.loss_cls: 0.1531  decode.loss_mask: 0.2207  decode.loss_dice: 0.2724  decode.d0.loss_cls: 0.9456  decode.d0.loss_mask: 0.2306  decode.d0.loss_dice: 0.2996  decode.d1.loss_cls: 0.2699  decode.d1.loss_mask: 0.2244  decode.d1.loss_dice: 0.2786  decode.d2.loss_cls: 0.1563  decode.d2.loss_mask: 0.2271  decode.d2.loss_dice: 0.2739  decode.d3.loss_cls: 0.1199  decode.d3.loss_mask: 0.2204  decode.d3.loss_dice: 0.2797  decode.d4.loss_cls: 0.1705  decode.d4.loss_mask: 0.2183  decode.d4.loss_dice: 0.2640  decode.d5.loss_cls: 0.1521  decode.d5.loss_mask: 0.2254  decode.d5.loss_dice: 0.2796  decode.d6.loss_cls: 0.1196  decode.d6.loss_mask: 0.2234  decode.d6.loss_dice: 0.2755  decode.d7.loss_cls: 0.1462  decode.d7.loss_mask: 0.2241  decode.d7.loss_dice: 0.2721  decode.d8.loss_cls: 0.1637  decode.d8.loss_mask: 0.2226  decode.d8.loss_dice: 0.2869
08/06 05:55:25 - mmengine - INFO - Iter(train) [ 26700/320000]  base_lr: 9.2459e-05 lr: 9.2459e-06  eta: 1 day, 16:01:27  time: 0.4925  data_time: 0.0109  memory: 5891  grad_norm: 365.1188  loss: 8.9378  decode.loss_cls: 0.1642  decode.loss_mask: 0.2857  decode.loss_dice: 0.3537  decode.d0.loss_cls: 0.9236  decode.d0.loss_mask: 0.3086  decode.d0.loss_dice: 0.4020  decode.d1.loss_cls: 0.2364  decode.d1.loss_mask: 0.2950  decode.d1.loss_dice: 0.3564  decode.d2.loss_cls: 0.1900  decode.d2.loss_mask: 0.2830  decode.d2.loss_dice: 0.3401  decode.d3.loss_cls: 0.1090  decode.d3.loss_mask: 0.2887  decode.d3.loss_dice: 0.3855  decode.d4.loss_cls: 0.1644  decode.d4.loss_mask: 0.2918  decode.d4.loss_dice: 0.3578  decode.d5.loss_cls: 0.1428  decode.d5.loss_mask: 0.2894  decode.d5.loss_dice: 0.3335  decode.d6.loss_cls: 0.1864  decode.d6.loss_mask: 0.2940  decode.d6.loss_dice: 0.3311  decode.d7.loss_cls: 0.1666  decode.d7.loss_mask: 0.2906  decode.d7.loss_dice: 0.3452  decode.d8.loss_cls: 0.1846  decode.d8.loss_mask: 0.2874  decode.d8.loss_dice: 0.3505
08/06 05:55:50 - mmengine - INFO - Iter(train) [ 26750/320000]  base_lr: 9.2444e-05 lr: 9.2444e-06  eta: 1 day, 16:01:03  time: 0.4935  data_time: 0.0107  memory: 5891  grad_norm: 88.3340  loss: 7.7332  decode.loss_cls: 0.1912  decode.loss_mask: 0.2376  decode.loss_dice: 0.2568  decode.d0.loss_cls: 1.0528  decode.d0.loss_mask: 0.2289  decode.d0.loss_dice: 0.2709  decode.d1.loss_cls: 0.2744  decode.d1.loss_mask: 0.2227  decode.d1.loss_dice: 0.2580  decode.d2.loss_cls: 0.1859  decode.d2.loss_mask: 0.2272  decode.d2.loss_dice: 0.2507  decode.d3.loss_cls: 0.1991  decode.d3.loss_mask: 0.2172  decode.d3.loss_dice: 0.2392  decode.d4.loss_cls: 0.2364  decode.d4.loss_mask: 0.2177  decode.d4.loss_dice: 0.2447  decode.d5.loss_cls: 0.2196  decode.d5.loss_mask: 0.2168  decode.d5.loss_dice: 0.2455  decode.d6.loss_cls: 0.2153  decode.d6.loss_mask: 0.2177  decode.d6.loss_dice: 0.2470  decode.d7.loss_cls: 0.2413  decode.d7.loss_mask: 0.2157  decode.d7.loss_dice: 0.2480  decode.d8.loss_cls: 0.1899  decode.d8.loss_mask: 0.2182  decode.d8.loss_dice: 0.2469
08/06 05:56:14 - mmengine - INFO - Iter(train) [ 26800/320000]  base_lr: 9.2430e-05 lr: 9.2430e-06  eta: 1 day, 16:00:40  time: 0.4931  data_time: 0.0110  memory: 5907  grad_norm: 117.5318  loss: 6.2873  decode.loss_cls: 0.1049  decode.loss_mask: 0.2079  decode.loss_dice: 0.2238  decode.d0.loss_cls: 0.8985  decode.d0.loss_mask: 0.2147  decode.d0.loss_dice: 0.2286  decode.d1.loss_cls: 0.1574  decode.d1.loss_mask: 0.2091  decode.d1.loss_dice: 0.2213  decode.d2.loss_cls: 0.0884  decode.d2.loss_mask: 0.2070  decode.d2.loss_dice: 0.2300  decode.d3.loss_cls: 0.1259  decode.d3.loss_mask: 0.2090  decode.d3.loss_dice: 0.2287  decode.d4.loss_cls: 0.1094  decode.d4.loss_mask: 0.2073  decode.d4.loss_dice: 0.2324  decode.d5.loss_cls: 0.0908  decode.d5.loss_mask: 0.2109  decode.d5.loss_dice: 0.2292  decode.d6.loss_cls: 0.1038  decode.d6.loss_mask: 0.2095  decode.d6.loss_dice: 0.2316  decode.d7.loss_cls: 0.1110  decode.d7.loss_mask: 0.2083  decode.d7.loss_dice: 0.2264  decode.d8.loss_cls: 0.1274  decode.d8.loss_mask: 0.2064  decode.d8.loss_dice: 0.2277
08/06 05:56:39 - mmengine - INFO - Iter(train) [ 26850/320000]  base_lr: 9.2416e-05 lr: 9.2416e-06  eta: 1 day, 16:00:16  time: 0.4927  data_time: 0.0109  memory: 5888  grad_norm: 237.7662  loss: 9.4987  decode.loss_cls: 0.2516  decode.loss_mask: 0.3212  decode.loss_dice: 0.2794  decode.d0.loss_cls: 1.0146  decode.d0.loss_mask: 0.3100  decode.d0.loss_dice: 0.2960  decode.d1.loss_cls: 0.2530  decode.d1.loss_mask: 0.3117  decode.d1.loss_dice: 0.2724  decode.d2.loss_cls: 0.2536  decode.d2.loss_mask: 0.3158  decode.d2.loss_dice: 0.2670  decode.d3.loss_cls: 0.2566  decode.d3.loss_mask: 0.3181  decode.d3.loss_dice: 0.2752  decode.d4.loss_cls: 0.3015  decode.d4.loss_mask: 0.3209  decode.d4.loss_dice: 0.2849  decode.d5.loss_cls: 0.3603  decode.d5.loss_mask: 0.3003  decode.d5.loss_dice: 0.2646  decode.d6.loss_cls: 0.2862  decode.d6.loss_mask: 0.3255  decode.d6.loss_dice: 0.2850  decode.d7.loss_cls: 0.3053  decode.d7.loss_mask: 0.3171  decode.d7.loss_dice: 0.2896  decode.d8.loss_cls: 0.2596  decode.d8.loss_mask: 0.3233  decode.d8.loss_dice: 0.2783
08/06 05:57:04 - mmengine - INFO - Iter(train) [ 26900/320000]  base_lr: 9.2402e-05 lr: 9.2402e-06  eta: 1 day, 15:59:52  time: 0.4928  data_time: 0.0110  memory: 5875  grad_norm: 106.0070  loss: 8.3722  decode.loss_cls: 0.2598  decode.loss_mask: 0.1999  decode.loss_dice: 0.3026  decode.d0.loss_cls: 0.9172  decode.d0.loss_mask: 0.2062  decode.d0.loss_dice: 0.3393  decode.d1.loss_cls: 0.2958  decode.d1.loss_mask: 0.2013  decode.d1.loss_dice: 0.3021  decode.d2.loss_cls: 0.2661  decode.d2.loss_mask: 0.1980  decode.d2.loss_dice: 0.3011  decode.d3.loss_cls: 0.2465  decode.d3.loss_mask: 0.2003  decode.d3.loss_dice: 0.3063  decode.d4.loss_cls: 0.2459  decode.d4.loss_mask: 0.2016  decode.d4.loss_dice: 0.3027  decode.d5.loss_cls: 0.2698  decode.d5.loss_mask: 0.2021  decode.d5.loss_dice: 0.3050  decode.d6.loss_cls: 0.2491  decode.d6.loss_mask: 0.2010  decode.d6.loss_dice: 0.2916  decode.d7.loss_cls: 0.2646  decode.d7.loss_mask: 0.2004  decode.d7.loss_dice: 0.3092  decode.d8.loss_cls: 0.2761  decode.d8.loss_mask: 0.2008  decode.d8.loss_dice: 0.3098
08/06 05:57:28 - mmengine - INFO - Iter(train) [ 26950/320000]  base_lr: 9.2388e-05 lr: 9.2388e-06  eta: 1 day, 15:59:28  time: 0.4928  data_time: 0.0108  memory: 5892  grad_norm: 193.4966  loss: 7.6539  decode.loss_cls: 0.1323  decode.loss_mask: 0.2573  decode.loss_dice: 0.2946  decode.d0.loss_cls: 0.9533  decode.d0.loss_mask: 0.2668  decode.d0.loss_dice: 0.3036  decode.d1.loss_cls: 0.1871  decode.d1.loss_mask: 0.2556  decode.d1.loss_dice: 0.2965  decode.d2.loss_cls: 0.1387  decode.d2.loss_mask: 0.2564  decode.d2.loss_dice: 0.2969  decode.d3.loss_cls: 0.1338  decode.d3.loss_mask: 0.2561  decode.d3.loss_dice: 0.2929  decode.d4.loss_cls: 0.1024  decode.d4.loss_mask: 0.2607  decode.d4.loss_dice: 0.3028  decode.d5.loss_cls: 0.1007  decode.d5.loss_mask: 0.2588  decode.d5.loss_dice: 0.3076  decode.d6.loss_cls: 0.0935  decode.d6.loss_mask: 0.2560  decode.d6.loss_dice: 0.2943  decode.d7.loss_cls: 0.0947  decode.d7.loss_mask: 0.2583  decode.d7.loss_dice: 0.2930  decode.d8.loss_cls: 0.1518  decode.d8.loss_mask: 0.2606  decode.d8.loss_dice: 0.2969
08/06 05:57:53 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 05:57:53 - mmengine - INFO - Iter(train) [ 27000/320000]  base_lr: 9.2373e-05 lr: 9.2373e-06  eta: 1 day, 15:59:04  time: 0.4925  data_time: 0.0108  memory: 5892  grad_norm: 172.0212  loss: 9.6910  decode.loss_cls: 0.3226  decode.loss_mask: 0.2409  decode.loss_dice: 0.2963  decode.d0.loss_cls: 1.0637  decode.d0.loss_mask: 0.2601  decode.d0.loss_dice: 0.3582  decode.d1.loss_cls: 0.3689  decode.d1.loss_mask: 0.2509  decode.d1.loss_dice: 0.3125  decode.d2.loss_cls: 0.3331  decode.d2.loss_mask: 0.2496  decode.d2.loss_dice: 0.3429  decode.d3.loss_cls: 0.3491  decode.d3.loss_mask: 0.2477  decode.d3.loss_dice: 0.3137  decode.d4.loss_cls: 0.3222  decode.d4.loss_mask: 0.2458  decode.d4.loss_dice: 0.3573  decode.d5.loss_cls: 0.3149  decode.d5.loss_mask: 0.2433  decode.d5.loss_dice: 0.3336  decode.d6.loss_cls: 0.3072  decode.d6.loss_mask: 0.2432  decode.d6.loss_dice: 0.2938  decode.d7.loss_cls: 0.3166  decode.d7.loss_mask: 0.2427  decode.d7.loss_dice: 0.2886  decode.d8.loss_cls: 0.3167  decode.d8.loss_mask: 0.2441  decode.d8.loss_dice: 0.3106
08/06 05:58:17 - mmengine - INFO - Iter(train) [ 27050/320000]  base_lr: 9.2359e-05 lr: 9.2359e-06  eta: 1 day, 15:58:40  time: 0.4925  data_time: 0.0106  memory: 5876  grad_norm: 141.8044  loss: 8.8717  decode.loss_cls: 0.2191  decode.loss_mask: 0.2530  decode.loss_dice: 0.3175  decode.d0.loss_cls: 0.9816  decode.d0.loss_mask: 0.2433  decode.d0.loss_dice: 0.2818  decode.d1.loss_cls: 0.3347  decode.d1.loss_mask: 0.2470  decode.d1.loss_dice: 0.3391  decode.d2.loss_cls: 0.2181  decode.d2.loss_mask: 0.2461  decode.d2.loss_dice: 0.3165  decode.d3.loss_cls: 0.2703  decode.d3.loss_mask: 0.2468  decode.d3.loss_dice: 0.3361  decode.d4.loss_cls: 0.2179  decode.d4.loss_mask: 0.2440  decode.d4.loss_dice: 0.3259  decode.d5.loss_cls: 0.2376  decode.d5.loss_mask: 0.2479  decode.d5.loss_dice: 0.3122  decode.d6.loss_cls: 0.2730  decode.d6.loss_mask: 0.2440  decode.d6.loss_dice: 0.3341  decode.d7.loss_cls: 0.2258  decode.d7.loss_mask: 0.2474  decode.d7.loss_dice: 0.3109  decode.d8.loss_cls: 0.2389  decode.d8.loss_mask: 0.2530  decode.d8.loss_dice: 0.3084
08/06 05:58:42 - mmengine - INFO - Iter(train) [ 27100/320000]  base_lr: 9.2345e-05 lr: 9.2345e-06  eta: 1 day, 15:58:16  time: 0.4928  data_time: 0.0109  memory: 5891  grad_norm: 132.2482  loss: 9.8524  decode.loss_cls: 0.2799  decode.loss_mask: 0.2623  decode.loss_dice: 0.3266  decode.d0.loss_cls: 1.1342  decode.d0.loss_mask: 0.2754  decode.d0.loss_dice: 0.3630  decode.d1.loss_cls: 0.4545  decode.d1.loss_mask: 0.2672  decode.d1.loss_dice: 0.3518  decode.d2.loss_cls: 0.2778  decode.d2.loss_mask: 0.2655  decode.d2.loss_dice: 0.3397  decode.d3.loss_cls: 0.2867  decode.d3.loss_mask: 0.2677  decode.d3.loss_dice: 0.3250  decode.d4.loss_cls: 0.3098  decode.d4.loss_mask: 0.2744  decode.d4.loss_dice: 0.3202  decode.d5.loss_cls: 0.2805  decode.d5.loss_mask: 0.2695  decode.d5.loss_dice: 0.3348  decode.d6.loss_cls: 0.2369  decode.d6.loss_mask: 0.2704  decode.d6.loss_dice: 0.3283  decode.d7.loss_cls: 0.2651  decode.d7.loss_mask: 0.2677  decode.d7.loss_dice: 0.3281  decode.d8.loss_cls: 0.3008  decode.d8.loss_mask: 0.2617  decode.d8.loss_dice: 0.3270
08/06 05:59:07 - mmengine - INFO - Iter(train) [ 27150/320000]  base_lr: 9.2331e-05 lr: 9.2331e-06  eta: 1 day, 15:57:52  time: 0.4918  data_time: 0.0108  memory: 5926  grad_norm: 201.7942  loss: 7.3948  decode.loss_cls: 0.0978  decode.loss_mask: 0.2651  decode.loss_dice: 0.3019  decode.d0.loss_cls: 0.7296  decode.d0.loss_mask: 0.2744  decode.d0.loss_dice: 0.3062  decode.d1.loss_cls: 0.0821  decode.d1.loss_mask: 0.2657  decode.d1.loss_dice: 0.3021  decode.d2.loss_cls: 0.0791  decode.d2.loss_mask: 0.2653  decode.d2.loss_dice: 0.3112  decode.d3.loss_cls: 0.1306  decode.d3.loss_mask: 0.2672  decode.d3.loss_dice: 0.3157  decode.d4.loss_cls: 0.0946  decode.d4.loss_mask: 0.2637  decode.d4.loss_dice: 0.3024  decode.d5.loss_cls: 0.1008  decode.d5.loss_mask: 0.2600  decode.d5.loss_dice: 0.2942  decode.d6.loss_cls: 0.1251  decode.d6.loss_mask: 0.2603  decode.d6.loss_dice: 0.2940  decode.d7.loss_cls: 0.1043  decode.d7.loss_mask: 0.2647  decode.d7.loss_dice: 0.2925  decode.d8.loss_cls: 0.1731  decode.d8.loss_mask: 0.2649  decode.d8.loss_dice: 0.3064
08/06 05:59:31 - mmengine - INFO - Iter(train) [ 27200/320000]  base_lr: 9.2317e-05 lr: 9.2317e-06  eta: 1 day, 15:57:29  time: 0.4923  data_time: 0.0109  memory: 5908  grad_norm: 127.2309  loss: 6.7375  decode.loss_cls: 0.0826  decode.loss_mask: 0.2691  decode.loss_dice: 0.2506  decode.d0.loss_cls: 0.7813  decode.d0.loss_mask: 0.2825  decode.d0.loss_dice: 0.2488  decode.d1.loss_cls: 0.1124  decode.d1.loss_mask: 0.2674  decode.d1.loss_dice: 0.2458  decode.d2.loss_cls: 0.0891  decode.d2.loss_mask: 0.2632  decode.d2.loss_dice: 0.2359  decode.d3.loss_cls: 0.0676  decode.d3.loss_mask: 0.2613  decode.d3.loss_dice: 0.2361  decode.d4.loss_cls: 0.0829  decode.d4.loss_mask: 0.2618  decode.d4.loss_dice: 0.2338  decode.d5.loss_cls: 0.1015  decode.d5.loss_mask: 0.2637  decode.d5.loss_dice: 0.2486  decode.d6.loss_cls: 0.0964  decode.d6.loss_mask: 0.2650  decode.d6.loss_dice: 0.2515  decode.d7.loss_cls: 0.1023  decode.d7.loss_mask: 0.2635  decode.d7.loss_dice: 0.2631  decode.d8.loss_cls: 0.1111  decode.d8.loss_mask: 0.2655  decode.d8.loss_dice: 0.2332
08/06 05:59:56 - mmengine - INFO - Iter(train) [ 27250/320000]  base_lr: 9.2302e-05 lr: 9.2302e-06  eta: 1 day, 15:57:06  time: 0.4928  data_time: 0.0108  memory: 5909  grad_norm: 101.9387  loss: 6.4708  decode.loss_cls: 0.0573  decode.loss_mask: 0.2345  decode.loss_dice: 0.2544  decode.d0.loss_cls: 0.8428  decode.d0.loss_mask: 0.2409  decode.d0.loss_dice: 0.2398  decode.d1.loss_cls: 0.1527  decode.d1.loss_mask: 0.2320  decode.d1.loss_dice: 0.2329  decode.d2.loss_cls: 0.0979  decode.d2.loss_mask: 0.2380  decode.d2.loss_dice: 0.2497  decode.d3.loss_cls: 0.0759  decode.d3.loss_mask: 0.2338  decode.d3.loss_dice: 0.2444  decode.d4.loss_cls: 0.1034  decode.d4.loss_mask: 0.2377  decode.d4.loss_dice: 0.2438  decode.d5.loss_cls: 0.1092  decode.d5.loss_mask: 0.2380  decode.d5.loss_dice: 0.2667  decode.d6.loss_cls: 0.0816  decode.d6.loss_mask: 0.2318  decode.d6.loss_dice: 0.2339  decode.d7.loss_cls: 0.0696  decode.d7.loss_mask: 0.2313  decode.d7.loss_dice: 0.2275  decode.d8.loss_cls: 0.0879  decode.d8.loss_mask: 0.2349  decode.d8.loss_dice: 0.2469
08/06 06:00:21 - mmengine - INFO - Iter(train) [ 27300/320000]  base_lr: 9.2288e-05 lr: 9.2288e-06  eta: 1 day, 15:56:42  time: 0.4921  data_time: 0.0109  memory: 5890  grad_norm: 338.9163  loss: 8.5641  decode.loss_cls: 0.2350  decode.loss_mask: 0.2867  decode.loss_dice: 0.2916  decode.d0.loss_cls: 0.9030  decode.d0.loss_mask: 0.2952  decode.d0.loss_dice: 0.3028  decode.d1.loss_cls: 0.2124  decode.d1.loss_mask: 0.2931  decode.d1.loss_dice: 0.2998  decode.d2.loss_cls: 0.2328  decode.d2.loss_mask: 0.2883  decode.d2.loss_dice: 0.2945  decode.d3.loss_cls: 0.1957  decode.d3.loss_mask: 0.2916  decode.d3.loss_dice: 0.2829  decode.d4.loss_cls: 0.2386  decode.d4.loss_mask: 0.2909  decode.d4.loss_dice: 0.2729  decode.d5.loss_cls: 0.1961  decode.d5.loss_mask: 0.2876  decode.d5.loss_dice: 0.2836  decode.d6.loss_cls: 0.1740  decode.d6.loss_mask: 0.2872  decode.d6.loss_dice: 0.2796  decode.d7.loss_cls: 0.1714  decode.d7.loss_mask: 0.2870  decode.d7.loss_dice: 0.2834  decode.d8.loss_cls: 0.2301  decode.d8.loss_mask: 0.2916  decode.d8.loss_dice: 0.2846
08/06 06:00:45 - mmengine - INFO - Iter(train) [ 27350/320000]  base_lr: 9.2274e-05 lr: 9.2274e-06  eta: 1 day, 15:56:18  time: 0.4928  data_time: 0.0108  memory: 5908  grad_norm: 223.6174  loss: 8.6540  decode.loss_cls: 0.2414  decode.loss_mask: 0.2643  decode.loss_dice: 0.3026  decode.d0.loss_cls: 0.9758  decode.d0.loss_mask: 0.2722  decode.d0.loss_dice: 0.3175  decode.d1.loss_cls: 0.2197  decode.d1.loss_mask: 0.2684  decode.d1.loss_dice: 0.2916  decode.d2.loss_cls: 0.1272  decode.d2.loss_mask: 0.2683  decode.d2.loss_dice: 0.3067  decode.d3.loss_cls: 0.2071  decode.d3.loss_mask: 0.2657  decode.d3.loss_dice: 0.3069  decode.d4.loss_cls: 0.2199  decode.d4.loss_mask: 0.2683  decode.d4.loss_dice: 0.3166  decode.d5.loss_cls: 0.2213  decode.d5.loss_mask: 0.2664  decode.d5.loss_dice: 0.2869  decode.d6.loss_cls: 0.2809  decode.d6.loss_mask: 0.2681  decode.d6.loss_dice: 0.2713  decode.d7.loss_cls: 0.2849  decode.d7.loss_mask: 0.2643  decode.d7.loss_dice: 0.2664  decode.d8.loss_cls: 0.2723  decode.d8.loss_mask: 0.2700  decode.d8.loss_dice: 0.2609
08/06 06:01:10 - mmengine - INFO - Iter(train) [ 27400/320000]  base_lr: 9.2260e-05 lr: 9.2260e-06  eta: 1 day, 15:55:55  time: 0.4925  data_time: 0.0108  memory: 5892  grad_norm: 100.1333  loss: 9.6052  decode.loss_cls: 0.2905  decode.loss_mask: 0.1729  decode.loss_dice: 0.3808  decode.d0.loss_cls: 0.9869  decode.d0.loss_mask: 0.1739  decode.d0.loss_dice: 0.3921  decode.d1.loss_cls: 0.4198  decode.d1.loss_mask: 0.1717  decode.d1.loss_dice: 0.3533  decode.d2.loss_cls: 0.3673  decode.d2.loss_mask: 0.1718  decode.d2.loss_dice: 0.3589  decode.d3.loss_cls: 0.3381  decode.d3.loss_mask: 0.1726  decode.d3.loss_dice: 0.3469  decode.d4.loss_cls: 0.3295  decode.d4.loss_mask: 0.1718  decode.d4.loss_dice: 0.3350  decode.d5.loss_cls: 0.3567  decode.d5.loss_mask: 0.1732  decode.d5.loss_dice: 0.3502  decode.d6.loss_cls: 0.3711  decode.d6.loss_mask: 0.1702  decode.d6.loss_dice: 0.3585  decode.d7.loss_cls: 0.3737  decode.d7.loss_mask: 0.1720  decode.d7.loss_dice: 0.3885  decode.d8.loss_cls: 0.3898  decode.d8.loss_mask: 0.1708  decode.d8.loss_dice: 0.3966
08/06 06:01:35 - mmengine - INFO - Iter(train) [ 27450/320000]  base_lr: 9.2246e-05 lr: 9.2246e-06  eta: 1 day, 15:55:31  time: 0.4926  data_time: 0.0109  memory: 5907  grad_norm: 79.5441  loss: 7.4889  decode.loss_cls: 0.0638  decode.loss_mask: 0.3014  decode.loss_dice: 0.2882  decode.d0.loss_cls: 0.9474  decode.d0.loss_mask: 0.2739  decode.d0.loss_dice: 0.2756  decode.d1.loss_cls: 0.1052  decode.d1.loss_mask: 0.2795  decode.d1.loss_dice: 0.2970  decode.d2.loss_cls: 0.1103  decode.d2.loss_mask: 0.2701  decode.d2.loss_dice: 0.2891  decode.d3.loss_cls: 0.0929  decode.d3.loss_mask: 0.2857  decode.d3.loss_dice: 0.2839  decode.d4.loss_cls: 0.0572  decode.d4.loss_mask: 0.2881  decode.d4.loss_dice: 0.2848  decode.d5.loss_cls: 0.0695  decode.d5.loss_mask: 0.3012  decode.d5.loss_dice: 0.2934  decode.d6.loss_cls: 0.0806  decode.d6.loss_mask: 0.3121  decode.d6.loss_dice: 0.2967  decode.d7.loss_cls: 0.1253  decode.d7.loss_mask: 0.2748  decode.d7.loss_dice: 0.2884  decode.d8.loss_cls: 0.0616  decode.d8.loss_mask: 0.3028  decode.d8.loss_dice: 0.2882
08/06 06:01:59 - mmengine - INFO - Iter(train) [ 27500/320000]  base_lr: 9.2232e-05 lr: 9.2232e-06  eta: 1 day, 15:55:07  time: 0.4927  data_time: 0.0110  memory: 5910  grad_norm: 147.1696  loss: 8.1900  decode.loss_cls: 0.1845  decode.loss_mask: 0.2648  decode.loss_dice: 0.3045  decode.d0.loss_cls: 0.7492  decode.d0.loss_mask: 0.2652  decode.d0.loss_dice: 0.3143  decode.d1.loss_cls: 0.2101  decode.d1.loss_mask: 0.2654  decode.d1.loss_dice: 0.3092  decode.d2.loss_cls: 0.1738  decode.d2.loss_mask: 0.2726  decode.d2.loss_dice: 0.3066  decode.d3.loss_cls: 0.1872  decode.d3.loss_mask: 0.2674  decode.d3.loss_dice: 0.3077  decode.d4.loss_cls: 0.2092  decode.d4.loss_mask: 0.2633  decode.d4.loss_dice: 0.3020  decode.d5.loss_cls: 0.2295  decode.d5.loss_mask: 0.2633  decode.d5.loss_dice: 0.3020  decode.d6.loss_cls: 0.1673  decode.d6.loss_mask: 0.2703  decode.d6.loss_dice: 0.3085  decode.d7.loss_cls: 0.1752  decode.d7.loss_mask: 0.2651  decode.d7.loss_dice: 0.3052  decode.d8.loss_cls: 0.1773  decode.d8.loss_mask: 0.2636  decode.d8.loss_dice: 0.3057
08/06 06:02:24 - mmengine - INFO - Iter(train) [ 27550/320000]  base_lr: 9.2217e-05 lr: 9.2217e-06  eta: 1 day, 15:54:45  time: 0.4928  data_time: 0.0108  memory: 5907  grad_norm: 100.3731  loss: 7.0819  decode.loss_cls: 0.0925  decode.loss_mask: 0.2520  decode.loss_dice: 0.2626  decode.d0.loss_cls: 0.9201  decode.d0.loss_mask: 0.2626  decode.d0.loss_dice: 0.2674  decode.d1.loss_cls: 0.1682  decode.d1.loss_mask: 0.2529  decode.d1.loss_dice: 0.2572  decode.d2.loss_cls: 0.1453  decode.d2.loss_mask: 0.2540  decode.d2.loss_dice: 0.2631  decode.d3.loss_cls: 0.1213  decode.d3.loss_mask: 0.2522  decode.d3.loss_dice: 0.2595  decode.d4.loss_cls: 0.1040  decode.d4.loss_mask: 0.2546  decode.d4.loss_dice: 0.2577  decode.d5.loss_cls: 0.1049  decode.d5.loss_mask: 0.2551  decode.d5.loss_dice: 0.2599  decode.d6.loss_cls: 0.1042  decode.d6.loss_mask: 0.2557  decode.d6.loss_dice: 0.2570  decode.d7.loss_cls: 0.0974  decode.d7.loss_mask: 0.2539  decode.d7.loss_dice: 0.2639  decode.d8.loss_cls: 0.0777  decode.d8.loss_mask: 0.2391  decode.d8.loss_dice: 0.2660
08/06 06:02:49 - mmengine - INFO - Iter(train) [ 27600/320000]  base_lr: 9.2203e-05 lr: 9.2203e-06  eta: 1 day, 15:54:21  time: 0.4915  data_time: 0.0105  memory: 5892  grad_norm: 360.0610  loss: 8.7488  decode.loss_cls: 0.1774  decode.loss_mask: 0.2514  decode.loss_dice: 0.3367  decode.d0.loss_cls: 1.0616  decode.d0.loss_mask: 0.1857  decode.d0.loss_dice: 0.3110  decode.d1.loss_cls: 0.2587  decode.d1.loss_mask: 0.2180  decode.d1.loss_dice: 0.3373  decode.d2.loss_cls: 0.3265  decode.d2.loss_mask: 0.1816  decode.d2.loss_dice: 0.2958  decode.d3.loss_cls: 0.3460  decode.d3.loss_mask: 0.1815  decode.d3.loss_dice: 0.3036  decode.d4.loss_cls: 0.3083  decode.d4.loss_mask: 0.1765  decode.d4.loss_dice: 0.3105  decode.d5.loss_cls: 0.2841  decode.d5.loss_mask: 0.1856  decode.d5.loss_dice: 0.3187  decode.d6.loss_cls: 0.2748  decode.d6.loss_mask: 0.2150  decode.d6.loss_dice: 0.3025  decode.d7.loss_cls: 0.2296  decode.d7.loss_mask: 0.2675  decode.d7.loss_dice: 0.3205  decode.d8.loss_cls: 0.2230  decode.d8.loss_mask: 0.2312  decode.d8.loss_dice: 0.3283
08/06 06:03:13 - mmengine - INFO - Iter(train) [ 27650/320000]  base_lr: 9.2189e-05 lr: 9.2189e-06  eta: 1 day, 15:53:57  time: 0.4918  data_time: 0.0108  memory: 5964  grad_norm: 67.3227  loss: 7.7924  decode.loss_cls: 0.1120  decode.loss_mask: 0.2929  decode.loss_dice: 0.2815  decode.d0.loss_cls: 0.8645  decode.d0.loss_mask: 0.3011  decode.d0.loss_dice: 0.2635  decode.d1.loss_cls: 0.1686  decode.d1.loss_mask: 0.2882  decode.d1.loss_dice: 0.2604  decode.d2.loss_cls: 0.1341  decode.d2.loss_mask: 0.2885  decode.d2.loss_dice: 0.2852  decode.d3.loss_cls: 0.1404  decode.d3.loss_mask: 0.2889  decode.d3.loss_dice: 0.2768  decode.d4.loss_cls: 0.1367  decode.d4.loss_mask: 0.2887  decode.d4.loss_dice: 0.2877  decode.d5.loss_cls: 0.1297  decode.d5.loss_mask: 0.2895  decode.d5.loss_dice: 0.2746  decode.d6.loss_cls: 0.1327  decode.d6.loss_mask: 0.2869  decode.d6.loss_dice: 0.2884  decode.d7.loss_cls: 0.1317  decode.d7.loss_mask: 0.2905  decode.d7.loss_dice: 0.2789  decode.d8.loss_cls: 0.1674  decode.d8.loss_mask: 0.2909  decode.d8.loss_dice: 0.2713
08/06 06:03:38 - mmengine - INFO - Iter(train) [ 27700/320000]  base_lr: 9.2175e-05 lr: 9.2175e-06  eta: 1 day, 15:53:33  time: 0.4920  data_time: 0.0106  memory: 5892  grad_norm: 253.6825  loss: 8.3747  decode.loss_cls: 0.1619  decode.loss_mask: 0.3045  decode.loss_dice: 0.3021  decode.d0.loss_cls: 0.9143  decode.d0.loss_mask: 0.3271  decode.d0.loss_dice: 0.3091  decode.d1.loss_cls: 0.2454  decode.d1.loss_mask: 0.3084  decode.d1.loss_dice: 0.2883  decode.d2.loss_cls: 0.0985  decode.d2.loss_mask: 0.3065  decode.d2.loss_dice: 0.3078  decode.d3.loss_cls: 0.1092  decode.d3.loss_mask: 0.2978  decode.d3.loss_dice: 0.2889  decode.d4.loss_cls: 0.1292  decode.d4.loss_mask: 0.3024  decode.d4.loss_dice: 0.2833  decode.d5.loss_cls: 0.1471  decode.d5.loss_mask: 0.3063  decode.d5.loss_dice: 0.3005  decode.d6.loss_cls: 0.1522  decode.d6.loss_mask: 0.3041  decode.d6.loss_dice: 0.2864  decode.d7.loss_cls: 0.2115  decode.d7.loss_mask: 0.2985  decode.d7.loss_dice: 0.2939  decode.d8.loss_cls: 0.2166  decode.d8.loss_mask: 0.3008  decode.d8.loss_dice: 0.2723
08/06 06:04:03 - mmengine - INFO - Iter(train) [ 27750/320000]  base_lr: 9.2161e-05 lr: 9.2161e-06  eta: 1 day, 15:53:09  time: 0.4923  data_time: 0.0108  memory: 5891  grad_norm: 82.4373  loss: 9.0835  decode.loss_cls: 0.1666  decode.loss_mask: 0.3281  decode.loss_dice: 0.3236  decode.d0.loss_cls: 0.9311  decode.d0.loss_mask: 0.3344  decode.d0.loss_dice: 0.3252  decode.d1.loss_cls: 0.2849  decode.d1.loss_mask: 0.3271  decode.d1.loss_dice: 0.3322  decode.d2.loss_cls: 0.1673  decode.d2.loss_mask: 0.3514  decode.d2.loss_dice: 0.3386  decode.d3.loss_cls: 0.1593  decode.d3.loss_mask: 0.3510  decode.d3.loss_dice: 0.3106  decode.d4.loss_cls: 0.1527  decode.d4.loss_mask: 0.3427  decode.d4.loss_dice: 0.3169  decode.d5.loss_cls: 0.1481  decode.d5.loss_mask: 0.3351  decode.d5.loss_dice: 0.3281  decode.d6.loss_cls: 0.1513  decode.d6.loss_mask: 0.3428  decode.d6.loss_dice: 0.3119  decode.d7.loss_cls: 0.2301  decode.d7.loss_mask: 0.3239  decode.d7.loss_dice: 0.2833  decode.d8.loss_cls: 0.1502  decode.d8.loss_mask: 0.3348  decode.d8.loss_dice: 0.3002
08/06 06:04:27 - mmengine - INFO - Iter(train) [ 27800/320000]  base_lr: 9.2146e-05 lr: 9.2146e-06  eta: 1 day, 15:52:45  time: 0.4923  data_time: 0.0107  memory: 5892  grad_norm: 136.3482  loss: 7.3969  decode.loss_cls: 0.1682  decode.loss_mask: 0.1791  decode.loss_dice: 0.2650  decode.d0.loss_cls: 0.9505  decode.d0.loss_mask: 0.1634  decode.d0.loss_dice: 0.2609  decode.d1.loss_cls: 0.2729  decode.d1.loss_mask: 0.1673  decode.d1.loss_dice: 0.2725  decode.d2.loss_cls: 0.3183  decode.d2.loss_mask: 0.1638  decode.d2.loss_dice: 0.2640  decode.d3.loss_cls: 0.2441  decode.d3.loss_mask: 0.1665  decode.d3.loss_dice: 0.2589  decode.d4.loss_cls: 0.2654  decode.d4.loss_mask: 0.1663  decode.d4.loss_dice: 0.2663  decode.d5.loss_cls: 0.2336  decode.d5.loss_mask: 0.1677  decode.d5.loss_dice: 0.2662  decode.d6.loss_cls: 0.2541  decode.d6.loss_mask: 0.1678  decode.d6.loss_dice: 0.2713  decode.d7.loss_cls: 0.1901  decode.d7.loss_mask: 0.1668  decode.d7.loss_dice: 0.2624  decode.d8.loss_cls: 0.1752  decode.d8.loss_mask: 0.1678  decode.d8.loss_dice: 0.2608
08/06 06:04:52 - mmengine - INFO - Iter(train) [ 27850/320000]  base_lr: 9.2132e-05 lr: 9.2132e-06  eta: 1 day, 15:52:21  time: 0.4930  data_time: 0.0110  memory: 5874  grad_norm: 102.6537  loss: 6.5502  decode.loss_cls: 0.0484  decode.loss_mask: 0.2476  decode.loss_dice: 0.2359  decode.d0.loss_cls: 1.0006  decode.d0.loss_mask: 0.2583  decode.d0.loss_dice: 0.2586  decode.d1.loss_cls: 0.0903  decode.d1.loss_mask: 0.2465  decode.d1.loss_dice: 0.2433  decode.d2.loss_cls: 0.0600  decode.d2.loss_mask: 0.2449  decode.d2.loss_dice: 0.2426  decode.d3.loss_cls: 0.0773  decode.d3.loss_mask: 0.2489  decode.d3.loss_dice: 0.2359  decode.d4.loss_cls: 0.0694  decode.d4.loss_mask: 0.2500  decode.d4.loss_dice: 0.2485  decode.d5.loss_cls: 0.0986  decode.d5.loss_mask: 0.2490  decode.d5.loss_dice: 0.2531  decode.d6.loss_cls: 0.0595  decode.d6.loss_mask: 0.2501  decode.d6.loss_dice: 0.2394  decode.d7.loss_cls: 0.0609  decode.d7.loss_mask: 0.2498  decode.d7.loss_dice: 0.2449  decode.d8.loss_cls: 0.0537  decode.d8.loss_mask: 0.2491  decode.d8.loss_dice: 0.2353
08/06 06:05:16 - mmengine - INFO - Iter(train) [ 27900/320000]  base_lr: 9.2118e-05 lr: 9.2118e-06  eta: 1 day, 15:51:57  time: 0.4927  data_time: 0.0107  memory: 5907  grad_norm: 126.3056  loss: 8.8482  decode.loss_cls: 0.1200  decode.loss_mask: 0.2826  decode.loss_dice: 0.3464  decode.d0.loss_cls: 1.0079  decode.d0.loss_mask: 0.2829  decode.d0.loss_dice: 0.4042  decode.d1.loss_cls: 0.2301  decode.d1.loss_mask: 0.2843  decode.d1.loss_dice: 0.3472  decode.d2.loss_cls: 0.2479  decode.d2.loss_mask: 0.2813  decode.d2.loss_dice: 0.3228  decode.d3.loss_cls: 0.1843  decode.d3.loss_mask: 0.2831  decode.d3.loss_dice: 0.3349  decode.d4.loss_cls: 0.1344  decode.d4.loss_mask: 0.2816  decode.d4.loss_dice: 0.3522  decode.d5.loss_cls: 0.1652  decode.d5.loss_mask: 0.2800  decode.d5.loss_dice: 0.3543  decode.d6.loss_cls: 0.1838  decode.d6.loss_mask: 0.2848  decode.d6.loss_dice: 0.3252  decode.d7.loss_cls: 0.1526  decode.d7.loss_mask: 0.2888  decode.d7.loss_dice: 0.3334  decode.d8.loss_cls: 0.1335  decode.d8.loss_mask: 0.2852  decode.d8.loss_dice: 0.3335
08/06 06:05:41 - mmengine - INFO - Iter(train) [ 27950/320000]  base_lr: 9.2104e-05 lr: 9.2104e-06  eta: 1 day, 15:51:33  time: 0.4915  data_time: 0.0105  memory: 5926  grad_norm: 165.1810  loss: 8.7158  decode.loss_cls: 0.2768  decode.loss_mask: 0.2340  decode.loss_dice: 0.3478  decode.d0.loss_cls: 0.9277  decode.d0.loss_mask: 0.2605  decode.d0.loss_dice: 0.3306  decode.d1.loss_cls: 0.3145  decode.d1.loss_mask: 0.2342  decode.d1.loss_dice: 0.2870  decode.d2.loss_cls: 0.2281  decode.d2.loss_mask: 0.2347  decode.d2.loss_dice: 0.3108  decode.d3.loss_cls: 0.2023  decode.d3.loss_mask: 0.2390  decode.d3.loss_dice: 0.3180  decode.d4.loss_cls: 0.1532  decode.d4.loss_mask: 0.2386  decode.d4.loss_dice: 0.3054  decode.d5.loss_cls: 0.2308  decode.d5.loss_mask: 0.2357  decode.d5.loss_dice: 0.3295  decode.d6.loss_cls: 0.2504  decode.d6.loss_mask: 0.2372  decode.d6.loss_dice: 0.3162  decode.d7.loss_cls: 0.2475  decode.d7.loss_mask: 0.2374  decode.d7.loss_dice: 0.3274  decode.d8.loss_cls: 0.2964  decode.d8.loss_mask: 0.2380  decode.d8.loss_dice: 0.3260
08/06 06:06:06 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 06:06:06 - mmengine - INFO - Iter(train) [ 28000/320000]  base_lr: 9.2090e-05 lr: 9.2090e-06  eta: 1 day, 15:51:08  time: 0.4908  data_time: 0.0105  memory: 5907  grad_norm: 120.7201  loss: 6.1077  decode.loss_cls: 0.1003  decode.loss_mask: 0.2028  decode.loss_dice: 0.2505  decode.d0.loss_cls: 0.9193  decode.d0.loss_mask: 0.2081  decode.d0.loss_dice: 0.2516  decode.d1.loss_cls: 0.0610  decode.d1.loss_mask: 0.2051  decode.d1.loss_dice: 0.2550  decode.d2.loss_cls: 0.0793  decode.d2.loss_mask: 0.2025  decode.d2.loss_dice: 0.2459  decode.d3.loss_cls: 0.0589  decode.d3.loss_mask: 0.2028  decode.d3.loss_dice: 0.2498  decode.d4.loss_cls: 0.0720  decode.d4.loss_mask: 0.2001  decode.d4.loss_dice: 0.2446  decode.d5.loss_cls: 0.0794  decode.d5.loss_mask: 0.2014  decode.d5.loss_dice: 0.2572  decode.d6.loss_cls: 0.0662  decode.d6.loss_mask: 0.2008  decode.d6.loss_dice: 0.2470  decode.d7.loss_cls: 0.0731  decode.d7.loss_mask: 0.2041  decode.d7.loss_dice: 0.2471  decode.d8.loss_cls: 0.0737  decode.d8.loss_mask: 0.2003  decode.d8.loss_dice: 0.2480
08/06 06:06:30 - mmengine - INFO - Iter(train) [ 28050/320000]  base_lr: 9.2075e-05 lr: 9.2075e-06  eta: 1 day, 15:50:44  time: 0.4910  data_time: 0.0106  memory: 5890  grad_norm: 250.4893  loss: 7.0811  decode.loss_cls: 0.0499  decode.loss_mask: 0.2899  decode.loss_dice: 0.2783  decode.d0.loss_cls: 0.8764  decode.d0.loss_mask: 0.3046  decode.d0.loss_dice: 0.2770  decode.d1.loss_cls: 0.0865  decode.d1.loss_mask: 0.3024  decode.d1.loss_dice: 0.2987  decode.d2.loss_cls: 0.0316  decode.d2.loss_mask: 0.2967  decode.d2.loss_dice: 0.2855  decode.d3.loss_cls: 0.0358  decode.d3.loss_mask: 0.2881  decode.d3.loss_dice: 0.2779  decode.d4.loss_cls: 0.0310  decode.d4.loss_mask: 0.2877  decode.d4.loss_dice: 0.2794  decode.d5.loss_cls: 0.0308  decode.d5.loss_mask: 0.2907  decode.d5.loss_dice: 0.2850  decode.d6.loss_cls: 0.0531  decode.d6.loss_mask: 0.2906  decode.d6.loss_dice: 0.2804  decode.d7.loss_cls: 0.0736  decode.d7.loss_mask: 0.2916  decode.d7.loss_dice: 0.2773  decode.d8.loss_cls: 0.0604  decode.d8.loss_mask: 0.2913  decode.d8.loss_dice: 0.2788
08/06 06:06:55 - mmengine - INFO - Iter(train) [ 28100/320000]  base_lr: 9.2061e-05 lr: 9.2061e-06  eta: 1 day, 15:50:20  time: 0.4921  data_time: 0.0109  memory: 5875  grad_norm: 56.8241  loss: 7.9952  decode.loss_cls: 0.1274  decode.loss_mask: 0.2536  decode.loss_dice: 0.3213  decode.d0.loss_cls: 0.8103  decode.d0.loss_mask: 0.2566  decode.d0.loss_dice: 0.3101  decode.d1.loss_cls: 0.2509  decode.d1.loss_mask: 0.2567  decode.d1.loss_dice: 0.3184  decode.d2.loss_cls: 0.2069  decode.d2.loss_mask: 0.2545  decode.d2.loss_dice: 0.2954  decode.d3.loss_cls: 0.2244  decode.d3.loss_mask: 0.2536  decode.d3.loss_dice: 0.3035  decode.d4.loss_cls: 0.1692  decode.d4.loss_mask: 0.2580  decode.d4.loss_dice: 0.3051  decode.d5.loss_cls: 0.0849  decode.d5.loss_mask: 0.2570  decode.d5.loss_dice: 0.3194  decode.d6.loss_cls: 0.1699  decode.d6.loss_mask: 0.2554  decode.d6.loss_dice: 0.2979  decode.d7.loss_cls: 0.1659  decode.d7.loss_mask: 0.2576  decode.d7.loss_dice: 0.3119  decode.d8.loss_cls: 0.1273  decode.d8.loss_mask: 0.2593  decode.d8.loss_dice: 0.3128
08/06 06:07:20 - mmengine - INFO - Iter(train) [ 28150/320000]  base_lr: 9.2047e-05 lr: 9.2047e-06  eta: 1 day, 15:49:57  time: 0.4920  data_time: 0.0107  memory: 5928  grad_norm: 254.5904  loss: 7.6978  decode.loss_cls: 0.0173  decode.loss_mask: 0.3430  decode.loss_dice: 0.3162  decode.d0.loss_cls: 0.8118  decode.d0.loss_mask: 0.3567  decode.d0.loss_dice: 0.3288  decode.d1.loss_cls: 0.0848  decode.d1.loss_mask: 0.3511  decode.d1.loss_dice: 0.3083  decode.d2.loss_cls: 0.0472  decode.d2.loss_mask: 0.3488  decode.d2.loss_dice: 0.3052  decode.d3.loss_cls: 0.0368  decode.d3.loss_mask: 0.3530  decode.d3.loss_dice: 0.3019  decode.d4.loss_cls: 0.0179  decode.d4.loss_mask: 0.3486  decode.d4.loss_dice: 0.3092  decode.d5.loss_cls: 0.0246  decode.d5.loss_mask: 0.3382  decode.d5.loss_dice: 0.3213  decode.d6.loss_cls: 0.0213  decode.d6.loss_mask: 0.3477  decode.d6.loss_dice: 0.3051  decode.d7.loss_cls: 0.0321  decode.d7.loss_mask: 0.3450  decode.d7.loss_dice: 0.3029  decode.d8.loss_cls: 0.0354  decode.d8.loss_mask: 0.3408  decode.d8.loss_dice: 0.2968
08/06 06:07:44 - mmengine - INFO - Iter(train) [ 28200/320000]  base_lr: 9.2033e-05 lr: 9.2033e-06  eta: 1 day, 15:49:33  time: 0.4925  data_time: 0.0107  memory: 5893  grad_norm: 203.3498  loss: 9.1714  decode.loss_cls: 0.1972  decode.loss_mask: 0.2738  decode.loss_dice: 0.3806  decode.d0.loss_cls: 0.9511  decode.d0.loss_mask: 0.2761  decode.d0.loss_dice: 0.4006  decode.d1.loss_cls: 0.2215  decode.d1.loss_mask: 0.2635  decode.d1.loss_dice: 0.3432  decode.d2.loss_cls: 0.1789  decode.d2.loss_mask: 0.2667  decode.d2.loss_dice: 0.3611  decode.d3.loss_cls: 0.1832  decode.d3.loss_mask: 0.2693  decode.d3.loss_dice: 0.3471  decode.d4.loss_cls: 0.2080  decode.d4.loss_mask: 0.2696  decode.d4.loss_dice: 0.3528  decode.d5.loss_cls: 0.1720  decode.d5.loss_mask: 0.2708  decode.d5.loss_dice: 0.3646  decode.d6.loss_cls: 0.2362  decode.d6.loss_mask: 0.2716  decode.d6.loss_dice: 0.3671  decode.d7.loss_cls: 0.1896  decode.d7.loss_mask: 0.2858  decode.d7.loss_dice: 0.4002  decode.d8.loss_cls: 0.2036  decode.d8.loss_mask: 0.2803  decode.d8.loss_dice: 0.3853
08/06 06:08:09 - mmengine - INFO - Iter(train) [ 28250/320000]  base_lr: 9.2019e-05 lr: 9.2019e-06  eta: 1 day, 15:49:09  time: 0.4927  data_time: 0.0106  memory: 5910  grad_norm: 334.6255  loss: 7.2585  decode.loss_cls: 0.1220  decode.loss_mask: 0.2607  decode.loss_dice: 0.2817  decode.d0.loss_cls: 0.7738  decode.d0.loss_mask: 0.2987  decode.d0.loss_dice: 0.3435  decode.d1.loss_cls: 0.1056  decode.d1.loss_mask: 0.2691  decode.d1.loss_dice: 0.2939  decode.d2.loss_cls: 0.1289  decode.d2.loss_mask: 0.2683  decode.d2.loss_dice: 0.2980  decode.d3.loss_cls: 0.1015  decode.d3.loss_mask: 0.2632  decode.d3.loss_dice: 0.2697  decode.d4.loss_cls: 0.1055  decode.d4.loss_mask: 0.2608  decode.d4.loss_dice: 0.2851  decode.d5.loss_cls: 0.0852  decode.d5.loss_mask: 0.2615  decode.d5.loss_dice: 0.2654  decode.d6.loss_cls: 0.0950  decode.d6.loss_mask: 0.2610  decode.d6.loss_dice: 0.2609  decode.d7.loss_cls: 0.1151  decode.d7.loss_mask: 0.2658  decode.d7.loss_dice: 0.2883  decode.d8.loss_cls: 0.0927  decode.d8.loss_mask: 0.2647  decode.d8.loss_dice: 0.2728
08/06 06:08:33 - mmengine - INFO - Iter(train) [ 28300/320000]  base_lr: 9.2004e-05 lr: 9.2004e-06  eta: 1 day, 15:48:45  time: 0.4912  data_time: 0.0105  memory: 5892  grad_norm: 162.7483  loss: 8.1660  decode.loss_cls: 0.1473  decode.loss_mask: 0.2494  decode.loss_dice: 0.3247  decode.d0.loss_cls: 1.0280  decode.d0.loss_mask: 0.2400  decode.d0.loss_dice: 0.3162  decode.d1.loss_cls: 0.2387  decode.d1.loss_mask: 0.2418  decode.d1.loss_dice: 0.3130  decode.d2.loss_cls: 0.1487  decode.d2.loss_mask: 0.2719  decode.d2.loss_dice: 0.3149  decode.d3.loss_cls: 0.1396  decode.d3.loss_mask: 0.2809  decode.d3.loss_dice: 0.3055  decode.d4.loss_cls: 0.1186  decode.d4.loss_mask: 0.2663  decode.d4.loss_dice: 0.3124  decode.d5.loss_cls: 0.0801  decode.d5.loss_mask: 0.2904  decode.d5.loss_dice: 0.3354  decode.d6.loss_cls: 0.1244  decode.d6.loss_mask: 0.2859  decode.d6.loss_dice: 0.3271  decode.d7.loss_cls: 0.1172  decode.d7.loss_mask: 0.3029  decode.d7.loss_dice: 0.3369  decode.d8.loss_cls: 0.1085  decode.d8.loss_mask: 0.2732  decode.d8.loss_dice: 0.3258
08/06 06:08:58 - mmengine - INFO - Iter(train) [ 28350/320000]  base_lr: 9.1990e-05 lr: 9.1990e-06  eta: 1 day, 15:48:21  time: 0.4928  data_time: 0.0109  memory: 5875  grad_norm: 116.2083  loss: 6.4538  decode.loss_cls: 0.0808  decode.loss_mask: 0.2532  decode.loss_dice: 0.2282  decode.d0.loss_cls: 1.0368  decode.d0.loss_mask: 0.2148  decode.d0.loss_dice: 0.2312  decode.d1.loss_cls: 0.1548  decode.d1.loss_mask: 0.2131  decode.d1.loss_dice: 0.2268  decode.d2.loss_cls: 0.1375  decode.d2.loss_mask: 0.2100  decode.d2.loss_dice: 0.2159  decode.d3.loss_cls: 0.1002  decode.d3.loss_mask: 0.2095  decode.d3.loss_dice: 0.2222  decode.d4.loss_cls: 0.1080  decode.d4.loss_mask: 0.2104  decode.d4.loss_dice: 0.2209  decode.d5.loss_cls: 0.1137  decode.d5.loss_mask: 0.2121  decode.d5.loss_dice: 0.2228  decode.d6.loss_cls: 0.0895  decode.d6.loss_mask: 0.2125  decode.d6.loss_dice: 0.2227  decode.d7.loss_cls: 0.1179  decode.d7.loss_mask: 0.2101  decode.d7.loss_dice: 0.2168  decode.d8.loss_cls: 0.1276  decode.d8.loss_mask: 0.2109  decode.d8.loss_dice: 0.2228
08/06 06:09:23 - mmengine - INFO - Iter(train) [ 28400/320000]  base_lr: 9.1976e-05 lr: 9.1976e-06  eta: 1 day, 15:47:57  time: 0.4920  data_time: 0.0108  memory: 5908  grad_norm: 119.1682  loss: 6.7546  decode.loss_cls: 0.0628  decode.loss_mask: 0.2378  decode.loss_dice: 0.2669  decode.d0.loss_cls: 0.9838  decode.d0.loss_mask: 0.2499  decode.d0.loss_dice: 0.2758  decode.d1.loss_cls: 0.1713  decode.d1.loss_mask: 0.2439  decode.d1.loss_dice: 0.2594  decode.d2.loss_cls: 0.0787  decode.d2.loss_mask: 0.2355  decode.d2.loss_dice: 0.2569  decode.d3.loss_cls: 0.0935  decode.d3.loss_mask: 0.2336  decode.d3.loss_dice: 0.2625  decode.d4.loss_cls: 0.0689  decode.d4.loss_mask: 0.2353  decode.d4.loss_dice: 0.2636  decode.d5.loss_cls: 0.0614  decode.d5.loss_mask: 0.2359  decode.d5.loss_dice: 0.2588  decode.d6.loss_cls: 0.0760  decode.d6.loss_mask: 0.2376  decode.d6.loss_dice: 0.2654  decode.d7.loss_cls: 0.0739  decode.d7.loss_mask: 0.2344  decode.d7.loss_dice: 0.2556  decode.d8.loss_cls: 0.0934  decode.d8.loss_mask: 0.2355  decode.d8.loss_dice: 0.2469
08/06 06:09:47 - mmengine - INFO - Iter(train) [ 28450/320000]  base_lr: 9.1962e-05 lr: 9.1962e-06  eta: 1 day, 15:47:33  time: 0.4935  data_time: 0.0107  memory: 5908  grad_norm: 183.5364  loss: 7.9117  decode.loss_cls: 0.2301  decode.loss_mask: 0.2335  decode.loss_dice: 0.2648  decode.d0.loss_cls: 0.9545  decode.d0.loss_mask: 0.2391  decode.d0.loss_dice: 0.2735  decode.d1.loss_cls: 0.2372  decode.d1.loss_mask: 0.2381  decode.d1.loss_dice: 0.2530  decode.d2.loss_cls: 0.1832  decode.d2.loss_mask: 0.2351  decode.d2.loss_dice: 0.2765  decode.d3.loss_cls: 0.2331  decode.d3.loss_mask: 0.2341  decode.d3.loss_dice: 0.2687  decode.d4.loss_cls: 0.2156  decode.d4.loss_mask: 0.2342  decode.d4.loss_dice: 0.2621  decode.d5.loss_cls: 0.2275  decode.d5.loss_mask: 0.2373  decode.d5.loss_dice: 0.2667  decode.d6.loss_cls: 0.2055  decode.d6.loss_mask: 0.2353  decode.d6.loss_dice: 0.2599  decode.d7.loss_cls: 0.2129  decode.d7.loss_mask: 0.2327  decode.d7.loss_dice: 0.2658  decode.d8.loss_cls: 0.2004  decode.d8.loss_mask: 0.2374  decode.d8.loss_dice: 0.2639
08/06 06:10:12 - mmengine - INFO - Iter(train) [ 28500/320000]  base_lr: 9.1948e-05 lr: 9.1948e-06  eta: 1 day, 15:47:09  time: 0.4925  data_time: 0.0107  memory: 5876  grad_norm: 249.0818  loss: 8.4605  decode.loss_cls: 0.1600  decode.loss_mask: 0.3049  decode.loss_dice: 0.2807  decode.d0.loss_cls: 0.8798  decode.d0.loss_mask: 0.3187  decode.d0.loss_dice: 0.3195  decode.d1.loss_cls: 0.2692  decode.d1.loss_mask: 0.3005  decode.d1.loss_dice: 0.2836  decode.d2.loss_cls: 0.1988  decode.d2.loss_mask: 0.2939  decode.d2.loss_dice: 0.2897  decode.d3.loss_cls: 0.2259  decode.d3.loss_mask: 0.2911  decode.d3.loss_dice: 0.2714  decode.d4.loss_cls: 0.1587  decode.d4.loss_mask: 0.2957  decode.d4.loss_dice: 0.3156  decode.d5.loss_cls: 0.1628  decode.d5.loss_mask: 0.2947  decode.d5.loss_dice: 0.2813  decode.d6.loss_cls: 0.1548  decode.d6.loss_mask: 0.2975  decode.d6.loss_dice: 0.2869  decode.d7.loss_cls: 0.1573  decode.d7.loss_mask: 0.2983  decode.d7.loss_dice: 0.2741  decode.d8.loss_cls: 0.1560  decode.d8.loss_mask: 0.3365  decode.d8.loss_dice: 0.3023
08/06 06:10:37 - mmengine - INFO - Iter(train) [ 28550/320000]  base_lr: 9.1934e-05 lr: 9.1934e-06  eta: 1 day, 15:46:45  time: 0.4926  data_time: 0.0107  memory: 5892  grad_norm: 168.2491  loss: 6.9352  decode.loss_cls: 0.0665  decode.loss_mask: 0.2515  decode.loss_dice: 0.2978  decode.d0.loss_cls: 0.8879  decode.d0.loss_mask: 0.2201  decode.d0.loss_dice: 0.3040  decode.d1.loss_cls: 0.1422  decode.d1.loss_mask: 0.2337  decode.d1.loss_dice: 0.2856  decode.d2.loss_cls: 0.0798  decode.d2.loss_mask: 0.2280  decode.d2.loss_dice: 0.2786  decode.d3.loss_cls: 0.0787  decode.d3.loss_mask: 0.2288  decode.d3.loss_dice: 0.2929  decode.d4.loss_cls: 0.0849  decode.d4.loss_mask: 0.2319  decode.d4.loss_dice: 0.2959  decode.d5.loss_cls: 0.0876  decode.d5.loss_mask: 0.2315  decode.d5.loss_dice: 0.2901  decode.d6.loss_cls: 0.0779  decode.d6.loss_mask: 0.2363  decode.d6.loss_dice: 0.2991  decode.d7.loss_cls: 0.0861  decode.d7.loss_mask: 0.2274  decode.d7.loss_dice: 0.2803  decode.d8.loss_cls: 0.0954  decode.d8.loss_mask: 0.2331  decode.d8.loss_dice: 0.3014
08/06 06:11:01 - mmengine - INFO - Iter(train) [ 28600/320000]  base_lr: 9.1919e-05 lr: 9.1919e-06  eta: 1 day, 15:46:20  time: 0.4922  data_time: 0.0107  memory: 5875  grad_norm: 125.5853  loss: 9.7264  decode.loss_cls: 0.1220  decode.loss_mask: 0.3818  decode.loss_dice: 0.3544  decode.d0.loss_cls: 0.9483  decode.d0.loss_mask: 0.4044  decode.d0.loss_dice: 0.3885  decode.d1.loss_cls: 0.1784  decode.d1.loss_mask: 0.3771  decode.d1.loss_dice: 0.3868  decode.d2.loss_cls: 0.1321  decode.d2.loss_mask: 0.3728  decode.d2.loss_dice: 0.3574  decode.d3.loss_cls: 0.1660  decode.d3.loss_mask: 0.3947  decode.d3.loss_dice: 0.3673  decode.d4.loss_cls: 0.1219  decode.d4.loss_mask: 0.3828  decode.d4.loss_dice: 0.3767  decode.d5.loss_cls: 0.1604  decode.d5.loss_mask: 0.3872  decode.d5.loss_dice: 0.3593  decode.d6.loss_cls: 0.1331  decode.d6.loss_mask: 0.3840  decode.d6.loss_dice: 0.3457  decode.d7.loss_cls: 0.1663  decode.d7.loss_mask: 0.3828  decode.d7.loss_dice: 0.3234  decode.d8.loss_cls: 0.1318  decode.d8.loss_mask: 0.3855  decode.d8.loss_dice: 0.3539
08/06 06:11:26 - mmengine - INFO - Iter(train) [ 28650/320000]  base_lr: 9.1905e-05 lr: 9.1905e-06  eta: 1 day, 15:45:58  time: 0.4932  data_time: 0.0106  memory: 5875  grad_norm: 78.5338  loss: 7.7589  decode.loss_cls: 0.1709  decode.loss_mask: 0.2678  decode.loss_dice: 0.2655  decode.d0.loss_cls: 0.9459  decode.d0.loss_mask: 0.2688  decode.d0.loss_dice: 0.2684  decode.d1.loss_cls: 0.1875  decode.d1.loss_mask: 0.2667  decode.d1.loss_dice: 0.2617  decode.d2.loss_cls: 0.1085  decode.d2.loss_mask: 0.2707  decode.d2.loss_dice: 0.2719  decode.d3.loss_cls: 0.1456  decode.d3.loss_mask: 0.2722  decode.d3.loss_dice: 0.2689  decode.d4.loss_cls: 0.1362  decode.d4.loss_mask: 0.2687  decode.d4.loss_dice: 0.2738  decode.d5.loss_cls: 0.1670  decode.d5.loss_mask: 0.2720  decode.d5.loss_dice: 0.2696  decode.d6.loss_cls: 0.1639  decode.d6.loss_mask: 0.2681  decode.d6.loss_dice: 0.2568  decode.d7.loss_cls: 0.1804  decode.d7.loss_mask: 0.2696  decode.d7.loss_dice: 0.2502  decode.d8.loss_cls: 0.2082  decode.d8.loss_mask: 0.2721  decode.d8.loss_dice: 0.2613
08/06 06:11:51 - mmengine - INFO - Iter(train) [ 28700/320000]  base_lr: 9.1891e-05 lr: 9.1891e-06  eta: 1 day, 15:45:34  time: 0.4929  data_time: 0.0106  memory: 5908  grad_norm: 164.5034  loss: 8.5784  decode.loss_cls: 0.2382  decode.loss_mask: 0.2221  decode.loss_dice: 0.3311  decode.d0.loss_cls: 1.1172  decode.d0.loss_mask: 0.2305  decode.d0.loss_dice: 0.3797  decode.d1.loss_cls: 0.2654  decode.d1.loss_mask: 0.2284  decode.d1.loss_dice: 0.3171  decode.d2.loss_cls: 0.1708  decode.d2.loss_mask: 0.2241  decode.d2.loss_dice: 0.3192  decode.d3.loss_cls: 0.2298  decode.d3.loss_mask: 0.2232  decode.d3.loss_dice: 0.3126  decode.d4.loss_cls: 0.1907  decode.d4.loss_mask: 0.2257  decode.d4.loss_dice: 0.3246  decode.d5.loss_cls: 0.2169  decode.d5.loss_mask: 0.2270  decode.d5.loss_dice: 0.3150  decode.d6.loss_cls: 0.2051  decode.d6.loss_mask: 0.2283  decode.d6.loss_dice: 0.3282  decode.d7.loss_cls: 0.1895  decode.d7.loss_mask: 0.2171  decode.d7.loss_dice: 0.3377  decode.d8.loss_cls: 0.2056  decode.d8.loss_mask: 0.2289  decode.d8.loss_dice: 0.3288
08/06 06:12:15 - mmengine - INFO - Iter(train) [ 28750/320000]  base_lr: 9.1877e-05 lr: 9.1877e-06  eta: 1 day, 15:45:10  time: 0.4921  data_time: 0.0105  memory: 5980  grad_norm: 122.4563  loss: 7.2734  decode.loss_cls: 0.1576  decode.loss_mask: 0.2104  decode.loss_dice: 0.3009  decode.d0.loss_cls: 0.9641  decode.d0.loss_mask: 0.1977  decode.d0.loss_dice: 0.2951  decode.d1.loss_cls: 0.1653  decode.d1.loss_mask: 0.1988  decode.d1.loss_dice: 0.2736  decode.d2.loss_cls: 0.1718  decode.d2.loss_mask: 0.1948  decode.d2.loss_dice: 0.2756  decode.d3.loss_cls: 0.2077  decode.d3.loss_mask: 0.1981  decode.d3.loss_dice: 0.2843  decode.d4.loss_cls: 0.1407  decode.d4.loss_mask: 0.1994  decode.d4.loss_dice: 0.2896  decode.d5.loss_cls: 0.1638  decode.d5.loss_mask: 0.1975  decode.d5.loss_dice: 0.2826  decode.d6.loss_cls: 0.1180  decode.d6.loss_mask: 0.1987  decode.d6.loss_dice: 0.3030  decode.d7.loss_cls: 0.1428  decode.d7.loss_mask: 0.2010  decode.d7.loss_dice: 0.2973  decode.d8.loss_cls: 0.1326  decode.d8.loss_mask: 0.2121  decode.d8.loss_dice: 0.2984
08/06 06:12:40 - mmengine - INFO - Iter(train) [ 28800/320000]  base_lr: 9.1863e-05 lr: 9.1863e-06  eta: 1 day, 15:44:46  time: 0.4929  data_time: 0.0110  memory: 5909  grad_norm: 129.0006  loss: 6.5110  decode.loss_cls: 0.0781  decode.loss_mask: 0.2579  decode.loss_dice: 0.2310  decode.d0.loss_cls: 0.8665  decode.d0.loss_mask: 0.2665  decode.d0.loss_dice: 0.2509  decode.d1.loss_cls: 0.0749  decode.d1.loss_mask: 0.2592  decode.d1.loss_dice: 0.2464  decode.d2.loss_cls: 0.0555  decode.d2.loss_mask: 0.2627  decode.d2.loss_dice: 0.2553  decode.d3.loss_cls: 0.0621  decode.d3.loss_mask: 0.2581  decode.d3.loss_dice: 0.2444  decode.d4.loss_cls: 0.0816  decode.d4.loss_mask: 0.2652  decode.d4.loss_dice: 0.2457  decode.d5.loss_cls: 0.0612  decode.d5.loss_mask: 0.2675  decode.d5.loss_dice: 0.2400  decode.d6.loss_cls: 0.0648  decode.d6.loss_mask: 0.2599  decode.d6.loss_dice: 0.2322  decode.d7.loss_cls: 0.0683  decode.d7.loss_mask: 0.2601  decode.d7.loss_dice: 0.2376  decode.d8.loss_cls: 0.0597  decode.d8.loss_mask: 0.2620  decode.d8.loss_dice: 0.2355
08/06 06:13:04 - mmengine - INFO - Iter(train) [ 28850/320000]  base_lr: 9.1848e-05 lr: 9.1848e-06  eta: 1 day, 15:44:22  time: 0.4927  data_time: 0.0109  memory: 5889  grad_norm: 138.2165  loss: 7.5141  decode.loss_cls: 0.1041  decode.loss_mask: 0.3068  decode.loss_dice: 0.2315  decode.d0.loss_cls: 0.9855  decode.d0.loss_mask: 0.3181  decode.d0.loss_dice: 0.2390  decode.d1.loss_cls: 0.1470  decode.d1.loss_mask: 0.3179  decode.d1.loss_dice: 0.2418  decode.d2.loss_cls: 0.1040  decode.d2.loss_mask: 0.3181  decode.d2.loss_dice: 0.2360  decode.d3.loss_cls: 0.1114  decode.d3.loss_mask: 0.3163  decode.d3.loss_dice: 0.2340  decode.d4.loss_cls: 0.1175  decode.d4.loss_mask: 0.3092  decode.d4.loss_dice: 0.2345  decode.d5.loss_cls: 0.1088  decode.d5.loss_mask: 0.3118  decode.d5.loss_dice: 0.2371  decode.d6.loss_cls: 0.1115  decode.d6.loss_mask: 0.3156  decode.d6.loss_dice: 0.2342  decode.d7.loss_cls: 0.1221  decode.d7.loss_mask: 0.3089  decode.d7.loss_dice: 0.2354  decode.d8.loss_cls: 0.1177  decode.d8.loss_mask: 0.3044  decode.d8.loss_dice: 0.2337
08/06 06:13:29 - mmengine - INFO - Iter(train) [ 28900/320000]  base_lr: 9.1834e-05 lr: 9.1834e-06  eta: 1 day, 15:43:58  time: 0.4925  data_time: 0.0108  memory: 5895  grad_norm: 124.4351  loss: 8.9563  decode.loss_cls: 0.2076  decode.loss_mask: 0.2668  decode.loss_dice: 0.3306  decode.d0.loss_cls: 0.9217  decode.d0.loss_mask: 0.2783  decode.d0.loss_dice: 0.3334  decode.d1.loss_cls: 0.2028  decode.d1.loss_mask: 0.2759  decode.d1.loss_dice: 0.3427  decode.d2.loss_cls: 0.2770  decode.d2.loss_mask: 0.2731  decode.d2.loss_dice: 0.3470  decode.d3.loss_cls: 0.2013  decode.d3.loss_mask: 0.2604  decode.d3.loss_dice: 0.3381  decode.d4.loss_cls: 0.2031  decode.d4.loss_mask: 0.2633  decode.d4.loss_dice: 0.3049  decode.d5.loss_cls: 0.2055  decode.d5.loss_mask: 0.2637  decode.d5.loss_dice: 0.3427  decode.d6.loss_cls: 0.2542  decode.d6.loss_mask: 0.2647  decode.d6.loss_dice: 0.3146  decode.d7.loss_cls: 0.2311  decode.d7.loss_mask: 0.2650  decode.d7.loss_dice: 0.3264  decode.d8.loss_cls: 0.2508  decode.d8.loss_mask: 0.2661  decode.d8.loss_dice: 0.3435
08/06 06:13:54 - mmengine - INFO - Iter(train) [ 28950/320000]  base_lr: 9.1820e-05 lr: 9.1820e-06  eta: 1 day, 15:43:36  time: 0.4931  data_time: 0.0110  memory: 5927  grad_norm: 96.5383  loss: 5.9397  decode.loss_cls: 0.0255  decode.loss_mask: 0.2193  decode.loss_dice: 0.2540  decode.d0.loss_cls: 0.8501  decode.d0.loss_mask: 0.2228  decode.d0.loss_dice: 0.2679  decode.d1.loss_cls: 0.0383  decode.d1.loss_mask: 0.2276  decode.d1.loss_dice: 0.2673  decode.d2.loss_cls: 0.0302  decode.d2.loss_mask: 0.2198  decode.d2.loss_dice: 0.2544  decode.d3.loss_cls: 0.0281  decode.d3.loss_mask: 0.2195  decode.d3.loss_dice: 0.2520  decode.d4.loss_cls: 0.0632  decode.d4.loss_mask: 0.2180  decode.d4.loss_dice: 0.2492  decode.d5.loss_cls: 0.0372  decode.d5.loss_mask: 0.2165  decode.d5.loss_dice: 0.2482  decode.d6.loss_cls: 0.0698  decode.d6.loss_mask: 0.2202  decode.d6.loss_dice: 0.2488  decode.d7.loss_cls: 0.0276  decode.d7.loss_mask: 0.2189  decode.d7.loss_dice: 0.2506  decode.d8.loss_cls: 0.0255  decode.d8.loss_mask: 0.2180  decode.d8.loss_dice: 0.2512
08/06 06:14:19 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 06:14:19 - mmengine - INFO - Iter(train) [ 29000/320000]  base_lr: 9.1806e-05 lr: 9.1806e-06  eta: 1 day, 15:43:12  time: 0.4934  data_time: 0.0109  memory: 5927  grad_norm: 141.5565  loss: 6.9570  decode.loss_cls: 0.1094  decode.loss_mask: 0.1905  decode.loss_dice: 0.2689  decode.d0.loss_cls: 0.9187  decode.d0.loss_mask: 0.1950  decode.d0.loss_dice: 0.2852  decode.d1.loss_cls: 0.1952  decode.d1.loss_mask: 0.1896  decode.d1.loss_dice: 0.2717  decode.d2.loss_cls: 0.1141  decode.d2.loss_mask: 0.1907  decode.d2.loss_dice: 0.2682  decode.d3.loss_cls: 0.1356  decode.d3.loss_mask: 0.1909  decode.d3.loss_dice: 0.2625  decode.d4.loss_cls: 0.1982  decode.d4.loss_mask: 0.1902  decode.d4.loss_dice: 0.2517  decode.d5.loss_cls: 0.1881  decode.d5.loss_mask: 0.1897  decode.d5.loss_dice: 0.2578  decode.d6.loss_cls: 0.2021  decode.d6.loss_mask: 0.1909  decode.d6.loss_dice: 0.2621  decode.d7.loss_cls: 0.1783  decode.d7.loss_mask: 0.1934  decode.d7.loss_dice: 0.2523  decode.d8.loss_cls: 0.1725  decode.d8.loss_mask: 0.1922  decode.d8.loss_dice: 0.2513
08/06 06:14:43 - mmengine - INFO - Iter(train) [ 29050/320000]  base_lr: 9.1792e-05 lr: 9.1792e-06  eta: 1 day, 15:42:48  time: 0.4935  data_time: 0.0110  memory: 5907  grad_norm: 80.1702  loss: 6.9569  decode.loss_cls: 0.0791  decode.loss_mask: 0.2667  decode.loss_dice: 0.2489  decode.d0.loss_cls: 0.9239  decode.d0.loss_mask: 0.2732  decode.d0.loss_dice: 0.2390  decode.d1.loss_cls: 0.1550  decode.d1.loss_mask: 0.2690  decode.d1.loss_dice: 0.2509  decode.d2.loss_cls: 0.0987  decode.d2.loss_mask: 0.2704  decode.d2.loss_dice: 0.2374  decode.d3.loss_cls: 0.1053  decode.d3.loss_mask: 0.2698  decode.d3.loss_dice: 0.2365  decode.d4.loss_cls: 0.0909  decode.d4.loss_mask: 0.2711  decode.d4.loss_dice: 0.2413  decode.d5.loss_cls: 0.1027  decode.d5.loss_mask: 0.2667  decode.d5.loss_dice: 0.2402  decode.d6.loss_cls: 0.0970  decode.d6.loss_mask: 0.2671  decode.d6.loss_dice: 0.2437  decode.d7.loss_cls: 0.1044  decode.d7.loss_mask: 0.2660  decode.d7.loss_dice: 0.2359  decode.d8.loss_cls: 0.0938  decode.d8.loss_mask: 0.2679  decode.d8.loss_dice: 0.2443
08/06 06:15:08 - mmengine - INFO - Iter(train) [ 29100/320000]  base_lr: 9.1777e-05 lr: 9.1777e-06  eta: 1 day, 15:42:24  time: 0.4931  data_time: 0.0111  memory: 5889  grad_norm: 180.2742  loss: 9.0233  decode.loss_cls: 0.2244  decode.loss_mask: 0.2594  decode.loss_dice: 0.3627  decode.d0.loss_cls: 0.8265  decode.d0.loss_mask: 0.2592  decode.d0.loss_dice: 0.3746  decode.d1.loss_cls: 0.2549  decode.d1.loss_mask: 0.2541  decode.d1.loss_dice: 0.3687  decode.d2.loss_cls: 0.1742  decode.d2.loss_mask: 0.2535  decode.d2.loss_dice: 0.3639  decode.d3.loss_cls: 0.2094  decode.d3.loss_mask: 0.2515  decode.d3.loss_dice: 0.3603  decode.d4.loss_cls: 0.1933  decode.d4.loss_mask: 0.2569  decode.d4.loss_dice: 0.3510  decode.d5.loss_cls: 0.2533  decode.d5.loss_mask: 0.2550  decode.d5.loss_dice: 0.3594  decode.d6.loss_cls: 0.2079  decode.d6.loss_mask: 0.2599  decode.d6.loss_dice: 0.3690  decode.d7.loss_cls: 0.2089  decode.d7.loss_mask: 0.2575  decode.d7.loss_dice: 0.3612  decode.d8.loss_cls: 0.2616  decode.d8.loss_mask: 0.2657  decode.d8.loss_dice: 0.3656
08/06 06:15:32 - mmengine - INFO - Iter(train) [ 29150/320000]  base_lr: 9.1763e-05 lr: 9.1763e-06  eta: 1 day, 15:42:00  time: 0.4927  data_time: 0.0109  memory: 5893  grad_norm: 99.1300  loss: 7.4511  decode.loss_cls: 0.1111  decode.loss_mask: 0.2752  decode.loss_dice: 0.2962  decode.d0.loss_cls: 0.8322  decode.d0.loss_mask: 0.2778  decode.d0.loss_dice: 0.3028  decode.d1.loss_cls: 0.0629  decode.d1.loss_mask: 0.2824  decode.d1.loss_dice: 0.2883  decode.d2.loss_cls: 0.0877  decode.d2.loss_mask: 0.2803  decode.d2.loss_dice: 0.3002  decode.d3.loss_cls: 0.0816  decode.d3.loss_mask: 0.2746  decode.d3.loss_dice: 0.2995  decode.d4.loss_cls: 0.0988  decode.d4.loss_mask: 0.2790  decode.d4.loss_dice: 0.2930  decode.d5.loss_cls: 0.1061  decode.d5.loss_mask: 0.2748  decode.d5.loss_dice: 0.2853  decode.d6.loss_cls: 0.1162  decode.d6.loss_mask: 0.2787  decode.d6.loss_dice: 0.2849  decode.d7.loss_cls: 0.1481  decode.d7.loss_mask: 0.2731  decode.d7.loss_dice: 0.2875  decode.d8.loss_cls: 0.1162  decode.d8.loss_mask: 0.2692  decode.d8.loss_dice: 0.2874
08/06 06:15:57 - mmengine - INFO - Iter(train) [ 29200/320000]  base_lr: 9.1749e-05 lr: 9.1749e-06  eta: 1 day, 15:41:37  time: 0.4939  data_time: 0.0109  memory: 5908  grad_norm: 274.4578  loss: 8.2615  decode.loss_cls: 0.1887  decode.loss_mask: 0.2687  decode.loss_dice: 0.2813  decode.d0.loss_cls: 0.9684  decode.d0.loss_mask: 0.2662  decode.d0.loss_dice: 0.3239  decode.d1.loss_cls: 0.1739  decode.d1.loss_mask: 0.2575  decode.d1.loss_dice: 0.2982  decode.d2.loss_cls: 0.1712  decode.d2.loss_mask: 0.2626  decode.d2.loss_dice: 0.2910  decode.d3.loss_cls: 0.1572  decode.d3.loss_mask: 0.2647  decode.d3.loss_dice: 0.3344  decode.d4.loss_cls: 0.1749  decode.d4.loss_mask: 0.2656  decode.d4.loss_dice: 0.3035  decode.d5.loss_cls: 0.1933  decode.d5.loss_mask: 0.2796  decode.d5.loss_dice: 0.3023  decode.d6.loss_cls: 0.1458  decode.d6.loss_mask: 0.2750  decode.d6.loss_dice: 0.3021  decode.d7.loss_cls: 0.1849  decode.d7.loss_mask: 0.2739  decode.d7.loss_dice: 0.3110  decode.d8.loss_cls: 0.1688  decode.d8.loss_mask: 0.2696  decode.d8.loss_dice: 0.3032
08/06 06:16:22 - mmengine - INFO - Iter(train) [ 29250/320000]  base_lr: 9.1735e-05 lr: 9.1735e-06  eta: 1 day, 15:41:13  time: 0.4934  data_time: 0.0109  memory: 5909  grad_norm: 134.9786  loss: 8.5455  decode.loss_cls: 0.3372  decode.loss_mask: 0.2072  decode.loss_dice: 0.2983  decode.d0.loss_cls: 0.8890  decode.d0.loss_mask: 0.2185  decode.d0.loss_dice: 0.3784  decode.d1.loss_cls: 0.2033  decode.d1.loss_mask: 0.2117  decode.d1.loss_dice: 0.3950  decode.d2.loss_cls: 0.1625  decode.d2.loss_mask: 0.2105  decode.d2.loss_dice: 0.3437  decode.d3.loss_cls: 0.2074  decode.d3.loss_mask: 0.2066  decode.d3.loss_dice: 0.3348  decode.d4.loss_cls: 0.2620  decode.d4.loss_mask: 0.2108  decode.d4.loss_dice: 0.2901  decode.d5.loss_cls: 0.2045  decode.d5.loss_mask: 0.2076  decode.d5.loss_dice: 0.3647  decode.d6.loss_cls: 0.2418  decode.d6.loss_mask: 0.2089  decode.d6.loss_dice: 0.3324  decode.d7.loss_cls: 0.2314  decode.d7.loss_mask: 0.2067  decode.d7.loss_dice: 0.3633  decode.d8.loss_cls: 0.2708  decode.d8.loss_mask: 0.2039  decode.d8.loss_dice: 0.3426
08/06 06:16:46 - mmengine - INFO - Iter(train) [ 29300/320000]  base_lr: 9.1721e-05 lr: 9.1721e-06  eta: 1 day, 15:40:49  time: 0.4932  data_time: 0.0109  memory: 5892  grad_norm: 139.8541  loss: 9.8780  decode.loss_cls: 0.2310  decode.loss_mask: 0.3306  decode.loss_dice: 0.3685  decode.d0.loss_cls: 0.9019  decode.d0.loss_mask: 0.3390  decode.d0.loss_dice: 0.4010  decode.d1.loss_cls: 0.2610  decode.d1.loss_mask: 0.3402  decode.d1.loss_dice: 0.3859  decode.d2.loss_cls: 0.1663  decode.d2.loss_mask: 0.3382  decode.d2.loss_dice: 0.3721  decode.d3.loss_cls: 0.2103  decode.d3.loss_mask: 0.3297  decode.d3.loss_dice: 0.3676  decode.d4.loss_cls: 0.2163  decode.d4.loss_mask: 0.3306  decode.d4.loss_dice: 0.3741  decode.d5.loss_cls: 0.1723  decode.d5.loss_mask: 0.3315  decode.d5.loss_dice: 0.3799  decode.d6.loss_cls: 0.1779  decode.d6.loss_mask: 0.3343  decode.d6.loss_dice: 0.3748  decode.d7.loss_cls: 0.2382  decode.d7.loss_mask: 0.3303  decode.d7.loss_dice: 0.3776  decode.d8.loss_cls: 0.1959  decode.d8.loss_mask: 0.3321  decode.d8.loss_dice: 0.3687
08/06 06:17:11 - mmengine - INFO - Iter(train) [ 29350/320000]  base_lr: 9.1706e-05 lr: 9.1706e-06  eta: 1 day, 15:40:25  time: 0.4938  data_time: 0.0108  memory: 5908  grad_norm: 118.1943  loss: 7.7873  decode.loss_cls: 0.1932  decode.loss_mask: 0.2543  decode.loss_dice: 0.2877  decode.d0.loss_cls: 0.7906  decode.d0.loss_mask: 0.2613  decode.d0.loss_dice: 0.2968  decode.d1.loss_cls: 0.1200  decode.d1.loss_mask: 0.2563  decode.d1.loss_dice: 0.2893  decode.d2.loss_cls: 0.1236  decode.d2.loss_mask: 0.2608  decode.d2.loss_dice: 0.2961  decode.d3.loss_cls: 0.1994  decode.d3.loss_mask: 0.2582  decode.d3.loss_dice: 0.2819  decode.d4.loss_cls: 0.1504  decode.d4.loss_mask: 0.2557  decode.d4.loss_dice: 0.2902  decode.d5.loss_cls: 0.2075  decode.d5.loss_mask: 0.2581  decode.d5.loss_dice: 0.2808  decode.d6.loss_cls: 0.2234  decode.d6.loss_mask: 0.2615  decode.d6.loss_dice: 0.2658  decode.d7.loss_cls: 0.1756  decode.d7.loss_mask: 0.2620  decode.d7.loss_dice: 0.2777  decode.d8.loss_cls: 0.1808  decode.d8.loss_mask: 0.2608  decode.d8.loss_dice: 0.2673
08/06 06:17:36 - mmengine - INFO - Iter(train) [ 29400/320000]  base_lr: 9.1692e-05 lr: 9.1692e-06  eta: 1 day, 15:40:02  time: 0.4934  data_time: 0.0109  memory: 5908  grad_norm: 176.4400  loss: 6.9801  decode.loss_cls: 0.0907  decode.loss_mask: 0.2470  decode.loss_dice: 0.2700  decode.d0.loss_cls: 0.7739  decode.d0.loss_mask: 0.2469  decode.d0.loss_dice: 0.3007  decode.d1.loss_cls: 0.0724  decode.d1.loss_mask: 0.2410  decode.d1.loss_dice: 0.2724  decode.d2.loss_cls: 0.1199  decode.d2.loss_mask: 0.2445  decode.d2.loss_dice: 0.2812  decode.d3.loss_cls: 0.1814  decode.d3.loss_mask: 0.2450  decode.d3.loss_dice: 0.2675  decode.d4.loss_cls: 0.1284  decode.d4.loss_mask: 0.2424  decode.d4.loss_dice: 0.2576  decode.d5.loss_cls: 0.0463  decode.d5.loss_mask: 0.2603  decode.d5.loss_dice: 0.2993  decode.d6.loss_cls: 0.1602  decode.d6.loss_mask: 0.2489  decode.d6.loss_dice: 0.2757  decode.d7.loss_cls: 0.0304  decode.d7.loss_mask: 0.2775  decode.d7.loss_dice: 0.2919  decode.d8.loss_cls: 0.0910  decode.d8.loss_mask: 0.2459  decode.d8.loss_dice: 0.2698
08/06 06:18:00 - mmengine - INFO - Iter(train) [ 29450/320000]  base_lr: 9.1678e-05 lr: 9.1678e-06  eta: 1 day, 15:39:38  time: 0.4923  data_time: 0.0107  memory: 5908  grad_norm: 79.4461  loss: 6.9333  decode.loss_cls: 0.0798  decode.loss_mask: 0.2046  decode.loss_dice: 0.2958  decode.d0.loss_cls: 1.0127  decode.d0.loss_mask: 0.2070  decode.d0.loss_dice: 0.2992  decode.d1.loss_cls: 0.1161  decode.d1.loss_mask: 0.2047  decode.d1.loss_dice: 0.2789  decode.d2.loss_cls: 0.1448  decode.d2.loss_mask: 0.2054  decode.d2.loss_dice: 0.3069  decode.d3.loss_cls: 0.1365  decode.d3.loss_mask: 0.2042  decode.d3.loss_dice: 0.2991  decode.d4.loss_cls: 0.1284  decode.d4.loss_mask: 0.1987  decode.d4.loss_dice: 0.2698  decode.d5.loss_cls: 0.0801  decode.d5.loss_mask: 0.2004  decode.d5.loss_dice: 0.2942  decode.d6.loss_cls: 0.0848  decode.d6.loss_mask: 0.2009  decode.d6.loss_dice: 0.2826  decode.d7.loss_cls: 0.1148  decode.d7.loss_mask: 0.2024  decode.d7.loss_dice: 0.3043  decode.d8.loss_cls: 0.0936  decode.d8.loss_mask: 0.2049  decode.d8.loss_dice: 0.2776
08/06 06:18:25 - mmengine - INFO - Iter(train) [ 29500/320000]  base_lr: 9.1664e-05 lr: 9.1664e-06  eta: 1 day, 15:39:14  time: 0.4923  data_time: 0.0108  memory: 5907  grad_norm: 159.8196  loss: 8.7687  decode.loss_cls: 0.1744  decode.loss_mask: 0.2694  decode.loss_dice: 0.3582  decode.d0.loss_cls: 0.8512  decode.d0.loss_mask: 0.2706  decode.d0.loss_dice: 0.3492  decode.d1.loss_cls: 0.2720  decode.d1.loss_mask: 0.2637  decode.d1.loss_dice: 0.3182  decode.d2.loss_cls: 0.1993  decode.d2.loss_mask: 0.2775  decode.d2.loss_dice: 0.3366  decode.d3.loss_cls: 0.2167  decode.d3.loss_mask: 0.2649  decode.d3.loss_dice: 0.2989  decode.d4.loss_cls: 0.2118  decode.d4.loss_mask: 0.2667  decode.d4.loss_dice: 0.3093  decode.d5.loss_cls: 0.2329  decode.d5.loss_mask: 0.2678  decode.d5.loss_dice: 0.3318  decode.d6.loss_cls: 0.2060  decode.d6.loss_mask: 0.2680  decode.d6.loss_dice: 0.3281  decode.d7.loss_cls: 0.1675  decode.d7.loss_mask: 0.2716  decode.d7.loss_dice: 0.3589  decode.d8.loss_cls: 0.1925  decode.d8.loss_mask: 0.2748  decode.d8.loss_dice: 0.3601
08/06 06:18:50 - mmengine - INFO - Iter(train) [ 29550/320000]  base_lr: 9.1650e-05 lr: 9.1650e-06  eta: 1 day, 15:38:50  time: 0.4918  data_time: 0.0107  memory: 5875  grad_norm: 51.6162  loss: 5.2664  decode.loss_cls: 0.0095  decode.loss_mask: 0.2116  decode.loss_dice: 0.2238  decode.d0.loss_cls: 0.7916  decode.d0.loss_mask: 0.2132  decode.d0.loss_dice: 0.2392  decode.d1.loss_cls: 0.0329  decode.d1.loss_mask: 0.2124  decode.d1.loss_dice: 0.2250  decode.d2.loss_cls: 0.0138  decode.d2.loss_mask: 0.2108  decode.d2.loss_dice: 0.2312  decode.d3.loss_cls: 0.0113  decode.d3.loss_mask: 0.2120  decode.d3.loss_dice: 0.2182  decode.d4.loss_cls: 0.0093  decode.d4.loss_mask: 0.2107  decode.d4.loss_dice: 0.2203  decode.d5.loss_cls: 0.0079  decode.d5.loss_mask: 0.2143  decode.d5.loss_dice: 0.2227  decode.d6.loss_cls: 0.0089  decode.d6.loss_mask: 0.2090  decode.d6.loss_dice: 0.2182  decode.d7.loss_cls: 0.0079  decode.d7.loss_mask: 0.2121  decode.d7.loss_dice: 0.2200  decode.d8.loss_cls: 0.0121  decode.d8.loss_mask: 0.2099  decode.d8.loss_dice: 0.2266
08/06 06:19:14 - mmengine - INFO - Iter(train) [ 29600/320000]  base_lr: 9.1635e-05 lr: 9.1635e-06  eta: 1 day, 15:38:25  time: 0.4912  data_time: 0.0105  memory: 5891  grad_norm: 182.4620  loss: 8.3268  decode.loss_cls: 0.2082  decode.loss_mask: 0.2515  decode.loss_dice: 0.2623  decode.d0.loss_cls: 1.1010  decode.d0.loss_mask: 0.2620  decode.d0.loss_dice: 0.2643  decode.d1.loss_cls: 0.2214  decode.d1.loss_mask: 0.2524  decode.d1.loss_dice: 0.2809  decode.d2.loss_cls: 0.2268  decode.d2.loss_mask: 0.2519  decode.d2.loss_dice: 0.2843  decode.d3.loss_cls: 0.2262  decode.d3.loss_mask: 0.2484  decode.d3.loss_dice: 0.2543  decode.d4.loss_cls: 0.2385  decode.d4.loss_mask: 0.2529  decode.d4.loss_dice: 0.2644  decode.d5.loss_cls: 0.2317  decode.d5.loss_mask: 0.2487  decode.d5.loss_dice: 0.2639  decode.d6.loss_cls: 0.2337  decode.d6.loss_mask: 0.2536  decode.d6.loss_dice: 0.2670  decode.d7.loss_cls: 0.2243  decode.d7.loss_mask: 0.2509  decode.d7.loss_dice: 0.2609  decode.d8.loss_cls: 0.2168  decode.d8.loss_mask: 0.2519  decode.d8.loss_dice: 0.2717
08/06 06:19:39 - mmengine - INFO - Iter(train) [ 29650/320000]  base_lr: 9.1621e-05 lr: 9.1621e-06  eta: 1 day, 15:38:01  time: 0.4926  data_time: 0.0111  memory: 5964  grad_norm: 118.4345  loss: 6.7006  decode.loss_cls: 0.0442  decode.loss_mask: 0.2741  decode.loss_dice: 0.2495  decode.d0.loss_cls: 0.9809  decode.d0.loss_mask: 0.2795  decode.d0.loss_dice: 0.2664  decode.d1.loss_cls: 0.1055  decode.d1.loss_mask: 0.2826  decode.d1.loss_dice: 0.2510  decode.d2.loss_cls: 0.0448  decode.d2.loss_mask: 0.2767  decode.d2.loss_dice: 0.2539  decode.d3.loss_cls: 0.0465  decode.d3.loss_mask: 0.2752  decode.d3.loss_dice: 0.2521  decode.d4.loss_cls: 0.0365  decode.d4.loss_mask: 0.2755  decode.d4.loss_dice: 0.2527  decode.d5.loss_cls: 0.0377  decode.d5.loss_mask: 0.2760  decode.d5.loss_dice: 0.2461  decode.d6.loss_cls: 0.0301  decode.d6.loss_mask: 0.2743  decode.d6.loss_dice: 0.2452  decode.d7.loss_cls: 0.0403  decode.d7.loss_mask: 0.2725  decode.d7.loss_dice: 0.2542  decode.d8.loss_cls: 0.0499  decode.d8.loss_mask: 0.2819  decode.d8.loss_dice: 0.2448
08/06 06:20:04 - mmengine - INFO - Iter(train) [ 29700/320000]  base_lr: 9.1607e-05 lr: 9.1607e-06  eta: 1 day, 15:37:37  time: 0.4920  data_time: 0.0108  memory: 5874  grad_norm: 103.2381  loss: 7.9063  decode.loss_cls: 0.0908  decode.loss_mask: 0.2657  decode.loss_dice: 0.3193  decode.d0.loss_cls: 0.8053  decode.d0.loss_mask: 0.2720  decode.d0.loss_dice: 0.3193  decode.d1.loss_cls: 0.2093  decode.d1.loss_mask: 0.2645  decode.d1.loss_dice: 0.3239  decode.d2.loss_cls: 0.1817  decode.d2.loss_mask: 0.2642  decode.d2.loss_dice: 0.3036  decode.d3.loss_cls: 0.1442  decode.d3.loss_mask: 0.2627  decode.d3.loss_dice: 0.3127  decode.d4.loss_cls: 0.1424  decode.d4.loss_mask: 0.2636  decode.d4.loss_dice: 0.3116  decode.d5.loss_cls: 0.1144  decode.d5.loss_mask: 0.2670  decode.d5.loss_dice: 0.3097  decode.d6.loss_cls: 0.1817  decode.d6.loss_mask: 0.2645  decode.d6.loss_dice: 0.3168  decode.d7.loss_cls: 0.1241  decode.d7.loss_mask: 0.2660  decode.d7.loss_dice: 0.3206  decode.d8.loss_cls: 0.1025  decode.d8.loss_mask: 0.2657  decode.d8.loss_dice: 0.3167
08/06 06:20:28 - mmengine - INFO - Iter(train) [ 29750/320000]  base_lr: 9.1593e-05 lr: 9.1593e-06  eta: 1 day, 15:37:13  time: 0.4917  data_time: 0.0108  memory: 5892  grad_norm: 76.3265  loss: 6.3770  decode.loss_cls: 0.0855  decode.loss_mask: 0.2178  decode.loss_dice: 0.2338  decode.d0.loss_cls: 0.9321  decode.d0.loss_mask: 0.2187  decode.d0.loss_dice: 0.2343  decode.d1.loss_cls: 0.0996  decode.d1.loss_mask: 0.2211  decode.d1.loss_dice: 0.2472  decode.d2.loss_cls: 0.1033  decode.d2.loss_mask: 0.2195  decode.d2.loss_dice: 0.2298  decode.d3.loss_cls: 0.0777  decode.d3.loss_mask: 0.2167  decode.d3.loss_dice: 0.2343  decode.d4.loss_cls: 0.1091  decode.d4.loss_mask: 0.2148  decode.d4.loss_dice: 0.2337  decode.d5.loss_cls: 0.0875  decode.d5.loss_mask: 0.2146  decode.d5.loss_dice: 0.2285  decode.d6.loss_cls: 0.1003  decode.d6.loss_mask: 0.2183  decode.d6.loss_dice: 0.2317  decode.d7.loss_cls: 0.1658  decode.d7.loss_mask: 0.2167  decode.d7.loss_dice: 0.2369  decode.d8.loss_cls: 0.0899  decode.d8.loss_mask: 0.2163  decode.d8.loss_dice: 0.2415
08/06 06:20:53 - mmengine - INFO - Iter(train) [ 29800/320000]  base_lr: 9.1579e-05 lr: 9.1579e-06  eta: 1 day, 15:36:49  time: 0.4912  data_time: 0.0108  memory: 5926  grad_norm: 158.5709  loss: 8.1998  decode.loss_cls: 0.0968  decode.loss_mask: 0.3589  decode.loss_dice: 0.2727  decode.d0.loss_cls: 0.9409  decode.d0.loss_mask: 0.3627  decode.d0.loss_dice: 0.3083  decode.d1.loss_cls: 0.0923  decode.d1.loss_mask: 0.3643  decode.d1.loss_dice: 0.2727  decode.d2.loss_cls: 0.0893  decode.d2.loss_mask: 0.3583  decode.d2.loss_dice: 0.2743  decode.d3.loss_cls: 0.0966  decode.d3.loss_mask: 0.3628  decode.d3.loss_dice: 0.2698  decode.d4.loss_cls: 0.0959  decode.d4.loss_mask: 0.3570  decode.d4.loss_dice: 0.2692  decode.d5.loss_cls: 0.0922  decode.d5.loss_mask: 0.3596  decode.d5.loss_dice: 0.2670  decode.d6.loss_cls: 0.1032  decode.d6.loss_mask: 0.3704  decode.d6.loss_dice: 0.2687  decode.d7.loss_cls: 0.1259  decode.d7.loss_mask: 0.3597  decode.d7.loss_dice: 0.2749  decode.d8.loss_cls: 0.1075  decode.d8.loss_mask: 0.3561  decode.d8.loss_dice: 0.2720
08/06 06:21:17 - mmengine - INFO - Iter(train) [ 29850/320000]  base_lr: 9.1564e-05 lr: 9.1564e-06  eta: 1 day, 15:36:25  time: 0.4922  data_time: 0.0108  memory: 5907  grad_norm: 211.2386  loss: 7.2502  decode.loss_cls: 0.0808  decode.loss_mask: 0.2544  decode.loss_dice: 0.2755  decode.d0.loss_cls: 0.9694  decode.d0.loss_mask: 0.2604  decode.d0.loss_dice: 0.3181  decode.d1.loss_cls: 0.2016  decode.d1.loss_mask: 0.2587  decode.d1.loss_dice: 0.2929  decode.d2.loss_cls: 0.0348  decode.d2.loss_mask: 0.2620  decode.d2.loss_dice: 0.3009  decode.d3.loss_cls: 0.0625  decode.d3.loss_mask: 0.2561  decode.d3.loss_dice: 0.2761  decode.d4.loss_cls: 0.0593  decode.d4.loss_mask: 0.2578  decode.d4.loss_dice: 0.2741  decode.d5.loss_cls: 0.0801  decode.d5.loss_mask: 0.2585  decode.d5.loss_dice: 0.2706  decode.d6.loss_cls: 0.1361  decode.d6.loss_mask: 0.2552  decode.d6.loss_dice: 0.3066  decode.d7.loss_cls: 0.0426  decode.d7.loss_mask: 0.2600  decode.d7.loss_dice: 0.3076  decode.d8.loss_cls: 0.0791  decode.d8.loss_mask: 0.2561  decode.d8.loss_dice: 0.3022
08/06 06:21:42 - mmengine - INFO - Iter(train) [ 29900/320000]  base_lr: 9.1550e-05 lr: 9.1550e-06  eta: 1 day, 15:36:01  time: 0.4921  data_time: 0.0109  memory: 5889  grad_norm: 130.0313  loss: 6.0250  decode.loss_cls: 0.0321  decode.loss_mask: 0.2358  decode.loss_dice: 0.2455  decode.d0.loss_cls: 0.7760  decode.d0.loss_mask: 0.2352  decode.d0.loss_dice: 0.2546  decode.d1.loss_cls: 0.0435  decode.d1.loss_mask: 0.2413  decode.d1.loss_dice: 0.2491  decode.d2.loss_cls: 0.0363  decode.d2.loss_mask: 0.2373  decode.d2.loss_dice: 0.2409  decode.d3.loss_cls: 0.0229  decode.d3.loss_mask: 0.2374  decode.d3.loss_dice: 0.2458  decode.d4.loss_cls: 0.0246  decode.d4.loss_mask: 0.2370  decode.d4.loss_dice: 0.2598  decode.d5.loss_cls: 0.0443  decode.d5.loss_mask: 0.2356  decode.d5.loss_dice: 0.2455  decode.d6.loss_cls: 0.0749  decode.d6.loss_mask: 0.2324  decode.d6.loss_dice: 0.2435  decode.d7.loss_cls: 0.1054  decode.d7.loss_mask: 0.2351  decode.d7.loss_dice: 0.2390  decode.d8.loss_cls: 0.0322  decode.d8.loss_mask: 0.2349  decode.d8.loss_dice: 0.2473
08/06 06:22:07 - mmengine - INFO - Iter(train) [ 29950/320000]  base_lr: 9.1536e-05 lr: 9.1536e-06  eta: 1 day, 15:35:37  time: 0.4920  data_time: 0.0109  memory: 5908  grad_norm: 75.6604  loss: 8.3256  decode.loss_cls: 0.1660  decode.loss_mask: 0.2638  decode.loss_dice: 0.2871  decode.d0.loss_cls: 1.0874  decode.d0.loss_mask: 0.2662  decode.d0.loss_dice: 0.2974  decode.d1.loss_cls: 0.1760  decode.d1.loss_mask: 0.2612  decode.d1.loss_dice: 0.2768  decode.d2.loss_cls: 0.2442  decode.d2.loss_mask: 0.2599  decode.d2.loss_dice: 0.2583  decode.d3.loss_cls: 0.1842  decode.d3.loss_mask: 0.2626  decode.d3.loss_dice: 0.2685  decode.d4.loss_cls: 0.1705  decode.d4.loss_mask: 0.2586  decode.d4.loss_dice: 0.3041  decode.d5.loss_cls: 0.1926  decode.d5.loss_mask: 0.2621  decode.d5.loss_dice: 0.2899  decode.d6.loss_cls: 0.3015  decode.d6.loss_mask: 0.2624  decode.d6.loss_dice: 0.2893  decode.d7.loss_cls: 0.1577  decode.d7.loss_mask: 0.2604  decode.d7.loss_dice: 0.2665  decode.d8.loss_cls: 0.1816  decode.d8.loss_mask: 0.2624  decode.d8.loss_dice: 0.3063
08/06 06:22:31 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 06:22:31 - mmengine - INFO - Iter(train) [ 30000/320000]  base_lr: 9.1522e-05 lr: 9.1522e-06  eta: 1 day, 15:35:13  time: 0.4924  data_time: 0.0109  memory: 5926  grad_norm: 101.1920  loss: 6.5949  decode.loss_cls: 0.0720  decode.loss_mask: 0.2186  decode.loss_dice: 0.2761  decode.d0.loss_cls: 0.8345  decode.d0.loss_mask: 0.2187  decode.d0.loss_dice: 0.3004  decode.d1.loss_cls: 0.1585  decode.d1.loss_mask: 0.2170  decode.d1.loss_dice: 0.2915  decode.d2.loss_cls: 0.0735  decode.d2.loss_mask: 0.2145  decode.d2.loss_dice: 0.2731  decode.d3.loss_cls: 0.0691  decode.d3.loss_mask: 0.2180  decode.d3.loss_dice: 0.2751  decode.d4.loss_cls: 0.0710  decode.d4.loss_mask: 0.2175  decode.d4.loss_dice: 0.2900  decode.d5.loss_cls: 0.0858  decode.d5.loss_mask: 0.2147  decode.d5.loss_dice: 0.2783  decode.d6.loss_cls: 0.0748  decode.d6.loss_mask: 0.2211  decode.d6.loss_dice: 0.2920  decode.d7.loss_cls: 0.0640  decode.d7.loss_mask: 0.2198  decode.d7.loss_dice: 0.2797  decode.d8.loss_cls: 0.0864  decode.d8.loss_mask: 0.2182  decode.d8.loss_dice: 0.2708
08/06 06:22:56 - mmengine - INFO - Iter(train) [ 30050/320000]  base_lr: 9.1508e-05 lr: 9.1508e-06  eta: 1 day, 15:34:49  time: 0.4928  data_time: 0.0108  memory: 5907  grad_norm: 121.2647  loss: 8.7260  decode.loss_cls: 0.2832  decode.loss_mask: 0.2419  decode.loss_dice: 0.3112  decode.d0.loss_cls: 1.0251  decode.d0.loss_mask: 0.2456  decode.d0.loss_dice: 0.3713  decode.d1.loss_cls: 0.3176  decode.d1.loss_mask: 0.2366  decode.d1.loss_dice: 0.3013  decode.d2.loss_cls: 0.2037  decode.d2.loss_mask: 0.2404  decode.d2.loss_dice: 0.3344  decode.d3.loss_cls: 0.2617  decode.d3.loss_mask: 0.2349  decode.d3.loss_dice: 0.3056  decode.d4.loss_cls: 0.2187  decode.d4.loss_mask: 0.2335  decode.d4.loss_dice: 0.2982  decode.d5.loss_cls: 0.1977  decode.d5.loss_mask: 0.2372  decode.d5.loss_dice: 0.3216  decode.d6.loss_cls: 0.1976  decode.d6.loss_mask: 0.2391  decode.d6.loss_dice: 0.3141  decode.d7.loss_cls: 0.1836  decode.d7.loss_mask: 0.2397  decode.d7.loss_dice: 0.3078  decode.d8.loss_cls: 0.2660  decode.d8.loss_mask: 0.2433  decode.d8.loss_dice: 0.3132
08/06 06:23:21 - mmengine - INFO - Iter(train) [ 30100/320000]  base_lr: 9.1493e-05 lr: 9.1493e-06  eta: 1 day, 15:34:26  time: 0.4929  data_time: 0.0110  memory: 5875  grad_norm: 175.2523  loss: 9.4773  decode.loss_cls: 0.2027  decode.loss_mask: 0.3114  decode.loss_dice: 0.2922  decode.d0.loss_cls: 1.0456  decode.d0.loss_mask: 0.3331  decode.d0.loss_dice: 0.2915  decode.d1.loss_cls: 0.3272  decode.d1.loss_mask: 0.3256  decode.d1.loss_dice: 0.2964  decode.d2.loss_cls: 0.3025  decode.d2.loss_mask: 0.3138  decode.d2.loss_dice: 0.2892  decode.d3.loss_cls: 0.2453  decode.d3.loss_mask: 0.3176  decode.d3.loss_dice: 0.3264  decode.d4.loss_cls: 0.2762  decode.d4.loss_mask: 0.3178  decode.d4.loss_dice: 0.2857  decode.d5.loss_cls: 0.2387  decode.d5.loss_mask: 0.3262  decode.d5.loss_dice: 0.2867  decode.d6.loss_cls: 0.2366  decode.d6.loss_mask: 0.3273  decode.d6.loss_dice: 0.3003  decode.d7.loss_cls: 0.2244  decode.d7.loss_mask: 0.3191  decode.d7.loss_dice: 0.3031  decode.d8.loss_cls: 0.2256  decode.d8.loss_mask: 0.3135  decode.d8.loss_dice: 0.2755
08/06 06:23:45 - mmengine - INFO - Iter(train) [ 30150/320000]  base_lr: 9.1479e-05 lr: 9.1479e-06  eta: 1 day, 15:34:02  time: 0.4929  data_time: 0.0110  memory: 5908  grad_norm: 160.8621  loss: 9.8937  decode.loss_cls: 0.2589  decode.loss_mask: 0.2673  decode.loss_dice: 0.3209  decode.d0.loss_cls: 1.0753  decode.d0.loss_mask: 0.2684  decode.d0.loss_dice: 0.3388  decode.d1.loss_cls: 0.3300  decode.d1.loss_mask: 0.2589  decode.d1.loss_dice: 0.3358  decode.d2.loss_cls: 0.3019  decode.d2.loss_mask: 0.2570  decode.d2.loss_dice: 0.3201  decode.d3.loss_cls: 0.2826  decode.d3.loss_mask: 0.2722  decode.d3.loss_dice: 0.3431  decode.d4.loss_cls: 0.2903  decode.d4.loss_mask: 0.2686  decode.d4.loss_dice: 0.3372  decode.d5.loss_cls: 0.3131  decode.d5.loss_mask: 0.2722  decode.d5.loss_dice: 0.3367  decode.d6.loss_cls: 0.3595  decode.d6.loss_mask: 0.2856  decode.d6.loss_dice: 0.3584  decode.d7.loss_cls: 0.3468  decode.d7.loss_mask: 0.2963  decode.d7.loss_dice: 0.3622  decode.d8.loss_cls: 0.2577  decode.d8.loss_mask: 0.2681  decode.d8.loss_dice: 0.3097
08/06 06:24:10 - mmengine - INFO - Iter(train) [ 30200/320000]  base_lr: 9.1465e-05 lr: 9.1465e-06  eta: 1 day, 15:33:38  time: 0.4930  data_time: 0.0108  memory: 5908  grad_norm: 112.4872  loss: 7.5068  decode.loss_cls: 0.1279  decode.loss_mask: 0.2732  decode.loss_dice: 0.2763  decode.d0.loss_cls: 0.9374  decode.d0.loss_mask: 0.2803  decode.d0.loss_dice: 0.2725  decode.d1.loss_cls: 0.1640  decode.d1.loss_mask: 0.2714  decode.d1.loss_dice: 0.2715  decode.d2.loss_cls: 0.1034  decode.d2.loss_mask: 0.2721  decode.d2.loss_dice: 0.2772  decode.d3.loss_cls: 0.1251  decode.d3.loss_mask: 0.2693  decode.d3.loss_dice: 0.2976  decode.d4.loss_cls: 0.0950  decode.d4.loss_mask: 0.2689  decode.d4.loss_dice: 0.2830  decode.d5.loss_cls: 0.1111  decode.d5.loss_mask: 0.2690  decode.d5.loss_dice: 0.2844  decode.d6.loss_cls: 0.0973  decode.d6.loss_mask: 0.2658  decode.d6.loss_dice: 0.2880  decode.d7.loss_cls: 0.1013  decode.d7.loss_mask: 0.2729  decode.d7.loss_dice: 0.2787  decode.d8.loss_cls: 0.1288  decode.d8.loss_mask: 0.2717  decode.d8.loss_dice: 0.2720
08/06 06:24:35 - mmengine - INFO - Iter(train) [ 30250/320000]  base_lr: 9.1451e-05 lr: 9.1451e-06  eta: 1 day, 15:33:14  time: 0.4918  data_time: 0.0108  memory: 5889  grad_norm: 161.3770  loss: 9.8198  decode.loss_cls: 0.2048  decode.loss_mask: 0.4050  decode.loss_dice: 0.3844  decode.d0.loss_cls: 0.8823  decode.d0.loss_mask: 0.3126  decode.d0.loss_dice: 0.3586  decode.d1.loss_cls: 0.2099  decode.d1.loss_mask: 0.3057  decode.d1.loss_dice: 0.3596  decode.d2.loss_cls: 0.1972  decode.d2.loss_mask: 0.3044  decode.d2.loss_dice: 0.3511  decode.d3.loss_cls: 0.2124  decode.d3.loss_mask: 0.3047  decode.d3.loss_dice: 0.3698  decode.d4.loss_cls: 0.2076  decode.d4.loss_mask: 0.3135  decode.d4.loss_dice: 0.3619  decode.d5.loss_cls: 0.2129  decode.d5.loss_mask: 0.3143  decode.d5.loss_dice: 0.3922  decode.d6.loss_cls: 0.2007  decode.d6.loss_mask: 0.3086  decode.d6.loss_dice: 0.3630  decode.d7.loss_cls: 0.2141  decode.d7.loss_mask: 0.3349  decode.d7.loss_dice: 0.3977  decode.d8.loss_cls: 0.2810  decode.d8.loss_mask: 0.3613  decode.d8.loss_dice: 0.3935
08/06 06:24:59 - mmengine - INFO - Iter(train) [ 30300/320000]  base_lr: 9.1437e-05 lr: 9.1437e-06  eta: 1 day, 15:32:50  time: 0.4907  data_time: 0.0108  memory: 5893  grad_norm: 170.9107  loss: 7.9008  decode.loss_cls: 0.1959  decode.loss_mask: 0.2737  decode.loss_dice: 0.2687  decode.d0.loss_cls: 0.8798  decode.d0.loss_mask: 0.2822  decode.d0.loss_dice: 0.2863  decode.d1.loss_cls: 0.2332  decode.d1.loss_mask: 0.2720  decode.d1.loss_dice: 0.2710  decode.d2.loss_cls: 0.1821  decode.d2.loss_mask: 0.2744  decode.d2.loss_dice: 0.2718  decode.d3.loss_cls: 0.1356  decode.d3.loss_mask: 0.2629  decode.d3.loss_dice: 0.2577  decode.d4.loss_cls: 0.1287  decode.d4.loss_mask: 0.2660  decode.d4.loss_dice: 0.2584  decode.d5.loss_cls: 0.1593  decode.d5.loss_mask: 0.2665  decode.d5.loss_dice: 0.2659  decode.d6.loss_cls: 0.2032  decode.d6.loss_mask: 0.2679  decode.d6.loss_dice: 0.2675  decode.d7.loss_cls: 0.1811  decode.d7.loss_mask: 0.2718  decode.d7.loss_dice: 0.2687  decode.d8.loss_cls: 0.2054  decode.d8.loss_mask: 0.2748  decode.d8.loss_dice: 0.2683
08/06 06:25:24 - mmengine - INFO - Iter(train) [ 30350/320000]  base_lr: 9.1422e-05 lr: 9.1422e-06  eta: 1 day, 15:32:25  time: 0.4932  data_time: 0.0108  memory: 5876  grad_norm: 293.1551  loss: 10.2326  decode.loss_cls: 0.2153  decode.loss_mask: 0.3025  decode.loss_dice: 0.3843  decode.d0.loss_cls: 1.0660  decode.d0.loss_mask: 0.3093  decode.d0.loss_dice: 0.3607  decode.d1.loss_cls: 0.2862  decode.d1.loss_mask: 0.3055  decode.d1.loss_dice: 0.3934  decode.d2.loss_cls: 0.2654  decode.d2.loss_mask: 0.3009  decode.d2.loss_dice: 0.3867  decode.d3.loss_cls: 0.2677  decode.d3.loss_mask: 0.2971  decode.d3.loss_dice: 0.3933  decode.d4.loss_cls: 0.2616  decode.d4.loss_mask: 0.3029  decode.d4.loss_dice: 0.3927  decode.d5.loss_cls: 0.2491  decode.d5.loss_mask: 0.2991  decode.d5.loss_dice: 0.3675  decode.d6.loss_cls: 0.2465  decode.d6.loss_mask: 0.3013  decode.d6.loss_dice: 0.3877  decode.d7.loss_cls: 0.2236  decode.d7.loss_mask: 0.3025  decode.d7.loss_dice: 0.4045  decode.d8.loss_cls: 0.2644  decode.d8.loss_mask: 0.3050  decode.d8.loss_dice: 0.3895
08/06 06:25:49 - mmengine - INFO - Iter(train) [ 30400/320000]  base_lr: 9.1408e-05 lr: 9.1408e-06  eta: 1 day, 15:32:03  time: 0.4927  data_time: 0.0110  memory: 5892  grad_norm: 287.3158  loss: 8.5227  decode.loss_cls: 0.2151  decode.loss_mask: 0.2692  decode.loss_dice: 0.2664  decode.d0.loss_cls: 1.0551  decode.d0.loss_mask: 0.2778  decode.d0.loss_dice: 0.2658  decode.d1.loss_cls: 0.3011  decode.d1.loss_mask: 0.2756  decode.d1.loss_dice: 0.2545  decode.d2.loss_cls: 0.2821  decode.d2.loss_mask: 0.2716  decode.d2.loss_dice: 0.2691  decode.d3.loss_cls: 0.2133  decode.d3.loss_mask: 0.2713  decode.d3.loss_dice: 0.2590  decode.d4.loss_cls: 0.2045  decode.d4.loss_mask: 0.2686  decode.d4.loss_dice: 0.2602  decode.d5.loss_cls: 0.2096  decode.d5.loss_mask: 0.2721  decode.d5.loss_dice: 0.2512  decode.d6.loss_cls: 0.1973  decode.d6.loss_mask: 0.2719  decode.d6.loss_dice: 0.2638  decode.d7.loss_cls: 0.2696  decode.d7.loss_mask: 0.2668  decode.d7.loss_dice: 0.2614  decode.d8.loss_cls: 0.2489  decode.d8.loss_mask: 0.2694  decode.d8.loss_dice: 0.2602
08/06 06:26:13 - mmengine - INFO - Iter(train) [ 30450/320000]  base_lr: 9.1394e-05 lr: 9.1394e-06  eta: 1 day, 15:31:39  time: 0.4928  data_time: 0.0110  memory: 5910  grad_norm: 125.3015  loss: 8.7821  decode.loss_cls: 0.2525  decode.loss_mask: 0.2899  decode.loss_dice: 0.2816  decode.d0.loss_cls: 0.8227  decode.d0.loss_mask: 0.3068  decode.d0.loss_dice: 0.2908  decode.d1.loss_cls: 0.2565  decode.d1.loss_mask: 0.2954  decode.d1.loss_dice: 0.2893  decode.d2.loss_cls: 0.2575  decode.d2.loss_mask: 0.2929  decode.d2.loss_dice: 0.2908  decode.d3.loss_cls: 0.2515  decode.d3.loss_mask: 0.2918  decode.d3.loss_dice: 0.3083  decode.d4.loss_cls: 0.2595  decode.d4.loss_mask: 0.2904  decode.d4.loss_dice: 0.2963  decode.d5.loss_cls: 0.2046  decode.d5.loss_mask: 0.2942  decode.d5.loss_dice: 0.2861  decode.d6.loss_cls: 0.1851  decode.d6.loss_mask: 0.2938  decode.d6.loss_dice: 0.2935  decode.d7.loss_cls: 0.2054  decode.d7.loss_mask: 0.2947  decode.d7.loss_dice: 0.2865  decode.d8.loss_cls: 0.2310  decode.d8.loss_mask: 0.2928  decode.d8.loss_dice: 0.2900
08/06 06:26:38 - mmengine - INFO - Iter(train) [ 30500/320000]  base_lr: 9.1380e-05 lr: 9.1380e-06  eta: 1 day, 15:31:15  time: 0.4932  data_time: 0.0110  memory: 5907  grad_norm: 130.0190  loss: 7.0388  decode.loss_cls: 0.0347  decode.loss_mask: 0.2921  decode.loss_dice: 0.2716  decode.d0.loss_cls: 0.8193  decode.d0.loss_mask: 0.2960  decode.d0.loss_dice: 0.2853  decode.d1.loss_cls: 0.1092  decode.d1.loss_mask: 0.2952  decode.d1.loss_dice: 0.2731  decode.d2.loss_cls: 0.0758  decode.d2.loss_mask: 0.2942  decode.d2.loss_dice: 0.2763  decode.d3.loss_cls: 0.0552  decode.d3.loss_mask: 0.3029  decode.d3.loss_dice: 0.2690  decode.d4.loss_cls: 0.0435  decode.d4.loss_mask: 0.2978  decode.d4.loss_dice: 0.2728  decode.d5.loss_cls: 0.0505  decode.d5.loss_mask: 0.2936  decode.d5.loss_dice: 0.2718  decode.d6.loss_cls: 0.0369  decode.d6.loss_mask: 0.2949  decode.d6.loss_dice: 0.2736  decode.d7.loss_cls: 0.0697  decode.d7.loss_mask: 0.2925  decode.d7.loss_dice: 0.2720  decode.d8.loss_cls: 0.0635  decode.d8.loss_mask: 0.2852  decode.d8.loss_dice: 0.2705
08/06 06:27:02 - mmengine - INFO - Iter(train) [ 30550/320000]  base_lr: 9.1366e-05 lr: 9.1366e-06  eta: 1 day, 15:30:51  time: 0.4936  data_time: 0.0109  memory: 5890  grad_norm: 128.9396  loss: 8.8938  decode.loss_cls: 0.2850  decode.loss_mask: 0.2336  decode.loss_dice: 0.3222  decode.d0.loss_cls: 1.0549  decode.d0.loss_mask: 0.2373  decode.d0.loss_dice: 0.3205  decode.d1.loss_cls: 0.2503  decode.d1.loss_mask: 0.2482  decode.d1.loss_dice: 0.3226  decode.d2.loss_cls: 0.2957  decode.d2.loss_mask: 0.2543  decode.d2.loss_dice: 0.3466  decode.d3.loss_cls: 0.3187  decode.d3.loss_mask: 0.2308  decode.d3.loss_dice: 0.3111  decode.d4.loss_cls: 0.1672  decode.d4.loss_mask: 0.2557  decode.d4.loss_dice: 0.3233  decode.d5.loss_cls: 0.2073  decode.d5.loss_mask: 0.2490  decode.d5.loss_dice: 0.3180  decode.d6.loss_cls: 0.2028  decode.d6.loss_mask: 0.2499  decode.d6.loss_dice: 0.3238  decode.d7.loss_cls: 0.1940  decode.d7.loss_mask: 0.2590  decode.d7.loss_dice: 0.3221  decode.d8.loss_cls: 0.2370  decode.d8.loss_mask: 0.2363  decode.d8.loss_dice: 0.3163
08/06 06:27:27 - mmengine - INFO - Iter(train) [ 30600/320000]  base_lr: 9.1351e-05 lr: 9.1351e-06  eta: 1 day, 15:30:27  time: 0.4930  data_time: 0.0112  memory: 5908  grad_norm: 341.7792  loss: 11.4035  decode.loss_cls: 0.4125  decode.loss_mask: 0.3249  decode.loss_dice: 0.3038  decode.d0.loss_cls: 1.2436  decode.d0.loss_mask: 0.3366  decode.d0.loss_dice: 0.3138  decode.d1.loss_cls: 0.3162  decode.d1.loss_mask: 0.3536  decode.d1.loss_dice: 0.3149  decode.d2.loss_cls: 0.2448  decode.d2.loss_mask: 0.3149  decode.d2.loss_dice: 0.3010  decode.d3.loss_cls: 0.3071  decode.d3.loss_mask: 0.3590  decode.d3.loss_dice: 0.3627  decode.d4.loss_cls: 0.4133  decode.d4.loss_mask: 0.3445  decode.d4.loss_dice: 0.3139  decode.d5.loss_cls: 0.3987  decode.d5.loss_mask: 0.3473  decode.d5.loss_dice: 0.3443  decode.d6.loss_cls: 0.4535  decode.d6.loss_mask: 0.3459  decode.d6.loss_dice: 0.3552  decode.d7.loss_cls: 0.4567  decode.d7.loss_mask: 0.3752  decode.d7.loss_dice: 0.3967  decode.d8.loss_cls: 0.4304  decode.d8.loss_mask: 0.3195  decode.d8.loss_dice: 0.2990
08/06 06:27:52 - mmengine - INFO - Iter(train) [ 30650/320000]  base_lr: 9.1337e-05 lr: 9.1337e-06  eta: 1 day, 15:30:03  time: 0.4923  data_time: 0.0110  memory: 5875  grad_norm: 210.0325  loss: 8.8486  decode.loss_cls: 0.1773  decode.loss_mask: 0.2920  decode.loss_dice: 0.2846  decode.d0.loss_cls: 1.0934  decode.d0.loss_mask: 0.3140  decode.d0.loss_dice: 0.3118  decode.d1.loss_cls: 0.1913  decode.d1.loss_mask: 0.3034  decode.d1.loss_dice: 0.3158  decode.d2.loss_cls: 0.1834  decode.d2.loss_mask: 0.3005  decode.d2.loss_dice: 0.3002  decode.d3.loss_cls: 0.2392  decode.d3.loss_mask: 0.2938  decode.d3.loss_dice: 0.2841  decode.d4.loss_cls: 0.1968  decode.d4.loss_mask: 0.2946  decode.d4.loss_dice: 0.2836  decode.d5.loss_cls: 0.1876  decode.d5.loss_mask: 0.3030  decode.d5.loss_dice: 0.2981  decode.d6.loss_cls: 0.1917  decode.d6.loss_mask: 0.2933  decode.d6.loss_dice: 0.3055  decode.d7.loss_cls: 0.2200  decode.d7.loss_mask: 0.2949  decode.d7.loss_dice: 0.2910  decode.d8.loss_cls: 0.2077  decode.d8.loss_mask: 0.3031  decode.d8.loss_dice: 0.2930
08/06 06:28:16 - mmengine - INFO - Iter(train) [ 30700/320000]  base_lr: 9.1323e-05 lr: 9.1323e-06  eta: 1 day, 15:29:40  time: 0.4931  data_time: 0.0113  memory: 5909  grad_norm: 261.5067  loss: 8.3470  decode.loss_cls: 0.1336  decode.loss_mask: 0.2930  decode.loss_dice: 0.3271  decode.d0.loss_cls: 0.8120  decode.d0.loss_mask: 0.3069  decode.d0.loss_dice: 0.3495  decode.d1.loss_cls: 0.2134  decode.d1.loss_mask: 0.2905  decode.d1.loss_dice: 0.3385  decode.d2.loss_cls: 0.1455  decode.d2.loss_mask: 0.2936  decode.d2.loss_dice: 0.2946  decode.d3.loss_cls: 0.1378  decode.d3.loss_mask: 0.2945  decode.d3.loss_dice: 0.3179  decode.d4.loss_cls: 0.1405  decode.d4.loss_mask: 0.2928  decode.d4.loss_dice: 0.3269  decode.d5.loss_cls: 0.1289  decode.d5.loss_mask: 0.2920  decode.d5.loss_dice: 0.3226  decode.d6.loss_cls: 0.1432  decode.d6.loss_mask: 0.2935  decode.d6.loss_dice: 0.3191  decode.d7.loss_cls: 0.1660  decode.d7.loss_mask: 0.2942  decode.d7.loss_dice: 0.3001  decode.d8.loss_cls: 0.1453  decode.d8.loss_mask: 0.2956  decode.d8.loss_dice: 0.3380
08/06 06:28:41 - mmengine - INFO - Iter(train) [ 30750/320000]  base_lr: 9.1309e-05 lr: 9.1309e-06  eta: 1 day, 15:29:15  time: 0.4930  data_time: 0.0110  memory: 5908  grad_norm: 115.7994  loss: 8.7498  decode.loss_cls: 0.2782  decode.loss_mask: 0.2643  decode.loss_dice: 0.2932  decode.d0.loss_cls: 0.8883  decode.d0.loss_mask: 0.2734  decode.d0.loss_dice: 0.2857  decode.d1.loss_cls: 0.2778  decode.d1.loss_mask: 0.2727  decode.d1.loss_dice: 0.2779  decode.d2.loss_cls: 0.2366  decode.d2.loss_mask: 0.2669  decode.d2.loss_dice: 0.2817  decode.d3.loss_cls: 0.2504  decode.d3.loss_mask: 0.2669  decode.d3.loss_dice: 0.2993  decode.d4.loss_cls: 0.2491  decode.d4.loss_mask: 0.2674  decode.d4.loss_dice: 0.3088  decode.d5.loss_cls: 0.2292  decode.d5.loss_mask: 0.2659  decode.d5.loss_dice: 0.3083  decode.d6.loss_cls: 0.2223  decode.d6.loss_mask: 0.2651  decode.d6.loss_dice: 0.3140  decode.d7.loss_cls: 0.2367  decode.d7.loss_mask: 0.2676  decode.d7.loss_dice: 0.2974  decode.d8.loss_cls: 0.2607  decode.d8.loss_mask: 0.2670  decode.d8.loss_dice: 0.2769
08/06 06:29:06 - mmengine - INFO - Iter(train) [ 30800/320000]  base_lr: 9.1295e-05 lr: 9.1295e-06  eta: 1 day, 15:28:52  time: 0.4927  data_time: 0.0109  memory: 5891  grad_norm: 193.8027  loss: 9.1778  decode.loss_cls: 0.2002  decode.loss_mask: 0.2775  decode.loss_dice: 0.3233  decode.d0.loss_cls: 1.1050  decode.d0.loss_mask: 0.2798  decode.d0.loss_dice: 0.3322  decode.d1.loss_cls: 0.2875  decode.d1.loss_mask: 0.2773  decode.d1.loss_dice: 0.3375  decode.d2.loss_cls: 0.2175  decode.d2.loss_mask: 0.2827  decode.d2.loss_dice: 0.3572  decode.d3.loss_cls: 0.2031  decode.d3.loss_mask: 0.2704  decode.d3.loss_dice: 0.3260  decode.d4.loss_cls: 0.1803  decode.d4.loss_mask: 0.2781  decode.d4.loss_dice: 0.3409  decode.d5.loss_cls: 0.2236  decode.d5.loss_mask: 0.2764  decode.d5.loss_dice: 0.3472  decode.d6.loss_cls: 0.1750  decode.d6.loss_mask: 0.2804  decode.d6.loss_dice: 0.3468  decode.d7.loss_cls: 0.2104  decode.d7.loss_mask: 0.2785  decode.d7.loss_dice: 0.3231  decode.d8.loss_cls: 0.2348  decode.d8.loss_mask: 0.2784  decode.d8.loss_dice: 0.3266
08/06 06:29:30 - mmengine - INFO - Iter(train) [ 30850/320000]  base_lr: 9.1280e-05 lr: 9.1280e-06  eta: 1 day, 15:28:28  time: 0.4917  data_time: 0.0110  memory: 5926  grad_norm: 117.5875  loss: 8.2843  decode.loss_cls: 0.1723  decode.loss_mask: 0.3229  decode.loss_dice: 0.2686  decode.d0.loss_cls: 0.9477  decode.d0.loss_mask: 0.3431  decode.d0.loss_dice: 0.2779  decode.d1.loss_cls: 0.1598  decode.d1.loss_mask: 0.3305  decode.d1.loss_dice: 0.2551  decode.d2.loss_cls: 0.0974  decode.d2.loss_mask: 0.3283  decode.d2.loss_dice: 0.2534  decode.d3.loss_cls: 0.1376  decode.d3.loss_mask: 0.3279  decode.d3.loss_dice: 0.2501  decode.d4.loss_cls: 0.1145  decode.d4.loss_mask: 0.3322  decode.d4.loss_dice: 0.2612  decode.d5.loss_cls: 0.2042  decode.d5.loss_mask: 0.3280  decode.d5.loss_dice: 0.2554  decode.d6.loss_cls: 0.1853  decode.d6.loss_mask: 0.3263  decode.d6.loss_dice: 0.2527  decode.d7.loss_cls: 0.1760  decode.d7.loss_mask: 0.3227  decode.d7.loss_dice: 0.2649  decode.d8.loss_cls: 0.1904  decode.d8.loss_mask: 0.3227  decode.d8.loss_dice: 0.2751
08/06 06:29:55 - mmengine - INFO - Iter(train) [ 30900/320000]  base_lr: 9.1266e-05 lr: 9.1266e-06  eta: 1 day, 15:28:04  time: 0.4923  data_time: 0.0109  memory: 5875  grad_norm: 186.2723  loss: 6.6785  decode.loss_cls: 0.1321  decode.loss_mask: 0.2219  decode.loss_dice: 0.2229  decode.d0.loss_cls: 0.9320  decode.d0.loss_mask: 0.2288  decode.d0.loss_dice: 0.2229  decode.d1.loss_cls: 0.1249  decode.d1.loss_mask: 0.2257  decode.d1.loss_dice: 0.2281  decode.d2.loss_cls: 0.1119  decode.d2.loss_mask: 0.2243  decode.d2.loss_dice: 0.2309  decode.d3.loss_cls: 0.1309  decode.d3.loss_mask: 0.2246  decode.d3.loss_dice: 0.2246  decode.d4.loss_cls: 0.1360  decode.d4.loss_mask: 0.2253  decode.d4.loss_dice: 0.2223  decode.d5.loss_cls: 0.1581  decode.d5.loss_mask: 0.2236  decode.d5.loss_dice: 0.2235  decode.d6.loss_cls: 0.1308  decode.d6.loss_mask: 0.2263  decode.d6.loss_dice: 0.2203  decode.d7.loss_cls: 0.1628  decode.d7.loss_mask: 0.2223  decode.d7.loss_dice: 0.2343  decode.d8.loss_cls: 0.1452  decode.d8.loss_mask: 0.2228  decode.d8.loss_dice: 0.2384
08/06 06:30:20 - mmengine - INFO - Iter(train) [ 30950/320000]  base_lr: 9.1252e-05 lr: 9.1252e-06  eta: 1 day, 15:27:39  time: 0.4924  data_time: 0.0108  memory: 5875  grad_norm: 131.8974  loss: 9.3386  decode.loss_cls: 0.1697  decode.loss_mask: 0.3637  decode.loss_dice: 0.3223  decode.d0.loss_cls: 0.9162  decode.d0.loss_mask: 0.2913  decode.d0.loss_dice: 0.3436  decode.d1.loss_cls: 0.2417  decode.d1.loss_mask: 0.3014  decode.d1.loss_dice: 0.3428  decode.d2.loss_cls: 0.2143  decode.d2.loss_mask: 0.3579  decode.d2.loss_dice: 0.3259  decode.d3.loss_cls: 0.2152  decode.d3.loss_mask: 0.2790  decode.d3.loss_dice: 0.3195  decode.d4.loss_cls: 0.2476  decode.d4.loss_mask: 0.2652  decode.d4.loss_dice: 0.3124  decode.d5.loss_cls: 0.2908  decode.d5.loss_mask: 0.2666  decode.d5.loss_dice: 0.3124  decode.d6.loss_cls: 0.1880  decode.d6.loss_mask: 0.3654  decode.d6.loss_dice: 0.3253  decode.d7.loss_cls: 0.1670  decode.d7.loss_mask: 0.3737  decode.d7.loss_dice: 0.3248  decode.d8.loss_cls: 0.1932  decode.d8.loss_mask: 0.3724  decode.d8.loss_dice: 0.3294
08/06 06:30:44 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 06:30:44 - mmengine - INFO - Iter(train) [ 31000/320000]  base_lr: 9.1238e-05 lr: 9.1238e-06  eta: 1 day, 15:27:16  time: 0.4925  data_time: 0.0109  memory: 5893  grad_norm: 79.8661  loss: 8.4265  decode.loss_cls: 0.2515  decode.loss_mask: 0.2168  decode.loss_dice: 0.3045  decode.d0.loss_cls: 1.0094  decode.d0.loss_mask: 0.2211  decode.d0.loss_dice: 0.3143  decode.d1.loss_cls: 0.2617  decode.d1.loss_mask: 0.2197  decode.d1.loss_dice: 0.3057  decode.d2.loss_cls: 0.2485  decode.d2.loss_mask: 0.2230  decode.d2.loss_dice: 0.3044  decode.d3.loss_cls: 0.2187  decode.d3.loss_mask: 0.2264  decode.d3.loss_dice: 0.3031  decode.d4.loss_cls: 0.2335  decode.d4.loss_mask: 0.2215  decode.d4.loss_dice: 0.3053  decode.d5.loss_cls: 0.2194  decode.d5.loss_mask: 0.2198  decode.d5.loss_dice: 0.3066  decode.d6.loss_cls: 0.2598  decode.d6.loss_mask: 0.2135  decode.d6.loss_dice: 0.2907  decode.d7.loss_cls: 0.2638  decode.d7.loss_mask: 0.2156  decode.d7.loss_dice: 0.2945  decode.d8.loss_cls: 0.2393  decode.d8.loss_mask: 0.2180  decode.d8.loss_dice: 0.2962
08/06 06:31:09 - mmengine - INFO - Iter(train) [ 31050/320000]  base_lr: 9.1223e-05 lr: 9.1223e-06  eta: 1 day, 15:26:52  time: 0.4922  data_time: 0.0110  memory: 5891  grad_norm: 158.0838  loss: 7.7220  decode.loss_cls: 0.1796  decode.loss_mask: 0.2507  decode.loss_dice: 0.2731  decode.d0.loss_cls: 0.9239  decode.d0.loss_mask: 0.2615  decode.d0.loss_dice: 0.2611  decode.d1.loss_cls: 0.2490  decode.d1.loss_mask: 0.2615  decode.d1.loss_dice: 0.2609  decode.d2.loss_cls: 0.1929  decode.d2.loss_mask: 0.2574  decode.d2.loss_dice: 0.2790  decode.d3.loss_cls: 0.1524  decode.d3.loss_mask: 0.2499  decode.d3.loss_dice: 0.2705  decode.d4.loss_cls: 0.1490  decode.d4.loss_mask: 0.2524  decode.d4.loss_dice: 0.2769  decode.d5.loss_cls: 0.1288  decode.d5.loss_mask: 0.2492  decode.d5.loss_dice: 0.2777  decode.d6.loss_cls: 0.1782  decode.d6.loss_mask: 0.2583  decode.d6.loss_dice: 0.2644  decode.d7.loss_cls: 0.1513  decode.d7.loss_mask: 0.2508  decode.d7.loss_dice: 0.2708  decode.d8.loss_cls: 0.1671  decode.d8.loss_mask: 0.2530  decode.d8.loss_dice: 0.2708
08/06 06:31:34 - mmengine - INFO - Iter(train) [ 31100/320000]  base_lr: 9.1209e-05 lr: 9.1209e-06  eta: 1 day, 15:26:28  time: 0.4924  data_time: 0.0112  memory: 5909  grad_norm: 115.0555  loss: 7.6846  decode.loss_cls: 0.0456  decode.loss_mask: 0.3215  decode.loss_dice: 0.3141  decode.d0.loss_cls: 0.8794  decode.d0.loss_mask: 0.3278  decode.d0.loss_dice: 0.3278  decode.d1.loss_cls: 0.0600  decode.d1.loss_mask: 0.3242  decode.d1.loss_dice: 0.2953  decode.d2.loss_cls: 0.0475  decode.d2.loss_mask: 0.3232  decode.d2.loss_dice: 0.2939  decode.d3.loss_cls: 0.0401  decode.d3.loss_mask: 0.3192  decode.d3.loss_dice: 0.2954  decode.d4.loss_cls: 0.1432  decode.d4.loss_mask: 0.3206  decode.d4.loss_dice: 0.2852  decode.d5.loss_cls: 0.0910  decode.d5.loss_mask: 0.3205  decode.d5.loss_dice: 0.2955  decode.d6.loss_cls: 0.0893  decode.d6.loss_mask: 0.3123  decode.d6.loss_dice: 0.2907  decode.d7.loss_cls: 0.0363  decode.d7.loss_mask: 0.3184  decode.d7.loss_dice: 0.3035  decode.d8.loss_cls: 0.0387  decode.d8.loss_mask: 0.3207  decode.d8.loss_dice: 0.3036
08/06 06:31:58 - mmengine - INFO - Iter(train) [ 31150/320000]  base_lr: 9.1195e-05 lr: 9.1195e-06  eta: 1 day, 15:26:04  time: 0.4924  data_time: 0.0112  memory: 5891  grad_norm: 185.8889  loss: 8.6356  decode.loss_cls: 0.2522  decode.loss_mask: 0.2565  decode.loss_dice: 0.3003  decode.d0.loss_cls: 0.8819  decode.d0.loss_mask: 0.2651  decode.d0.loss_dice: 0.3391  decode.d1.loss_cls: 0.2390  decode.d1.loss_mask: 0.2606  decode.d1.loss_dice: 0.2829  decode.d2.loss_cls: 0.2716  decode.d2.loss_mask: 0.2537  decode.d2.loss_dice: 0.2728  decode.d3.loss_cls: 0.1916  decode.d3.loss_mask: 0.2530  decode.d3.loss_dice: 0.3059  decode.d4.loss_cls: 0.2611  decode.d4.loss_mask: 0.2546  decode.d4.loss_dice: 0.2902  decode.d5.loss_cls: 0.2297  decode.d5.loss_mask: 0.2536  decode.d5.loss_dice: 0.2942  decode.d6.loss_cls: 0.2463  decode.d6.loss_mask: 0.2696  decode.d6.loss_dice: 0.2982  decode.d7.loss_cls: 0.2660  decode.d7.loss_mask: 0.2608  decode.d7.loss_dice: 0.3094  decode.d8.loss_cls: 0.2046  decode.d8.loss_mask: 0.2522  decode.d8.loss_dice: 0.3192
08/06 06:32:23 - mmengine - INFO - Iter(train) [ 31200/320000]  base_lr: 9.1181e-05 lr: 9.1181e-06  eta: 1 day, 15:25:40  time: 0.4921  data_time: 0.0109  memory: 5875  grad_norm: 125.1388  loss: 8.5305  decode.loss_cls: 0.2244  decode.loss_mask: 0.2566  decode.loss_dice: 0.3344  decode.d0.loss_cls: 0.8585  decode.d0.loss_mask: 0.2640  decode.d0.loss_dice: 0.3883  decode.d1.loss_cls: 0.1045  decode.d1.loss_mask: 0.2572  decode.d1.loss_dice: 0.3742  decode.d2.loss_cls: 0.1483  decode.d2.loss_mask: 0.2598  decode.d2.loss_dice: 0.3665  decode.d3.loss_cls: 0.1156  decode.d3.loss_mask: 0.2602  decode.d3.loss_dice: 0.3402  decode.d4.loss_cls: 0.1238  decode.d4.loss_mask: 0.2584  decode.d4.loss_dice: 0.3511  decode.d5.loss_cls: 0.1729  decode.d5.loss_mask: 0.2839  decode.d5.loss_dice: 0.3814  decode.d6.loss_cls: 0.1925  decode.d6.loss_mask: 0.2726  decode.d6.loss_dice: 0.3755  decode.d7.loss_cls: 0.2125  decode.d7.loss_mask: 0.2588  decode.d7.loss_dice: 0.3194  decode.d8.loss_cls: 0.1677  decode.d8.loss_mask: 0.2614  decode.d8.loss_dice: 0.3458
08/06 06:32:48 - mmengine - INFO - Iter(train) [ 31250/320000]  base_lr: 9.1167e-05 lr: 9.1167e-06  eta: 1 day, 15:25:16  time: 0.4931  data_time: 0.0114  memory: 5927  grad_norm: 52.8850  loss: 7.1696  decode.loss_cls: 0.1338  decode.loss_mask: 0.2697  decode.loss_dice: 0.2904  decode.d0.loss_cls: 0.7899  decode.d0.loss_mask: 0.2724  decode.d0.loss_dice: 0.2889  decode.d1.loss_cls: 0.0851  decode.d1.loss_mask: 0.2658  decode.d1.loss_dice: 0.2920  decode.d2.loss_cls: 0.0603  decode.d2.loss_mask: 0.2687  decode.d2.loss_dice: 0.3134  decode.d3.loss_cls: 0.0872  decode.d3.loss_mask: 0.2689  decode.d3.loss_dice: 0.2867  decode.d4.loss_cls: 0.0782  decode.d4.loss_mask: 0.2690  decode.d4.loss_dice: 0.3143  decode.d5.loss_cls: 0.0776  decode.d5.loss_mask: 0.2686  decode.d5.loss_dice: 0.2849  decode.d6.loss_cls: 0.0887  decode.d6.loss_mask: 0.2689  decode.d6.loss_dice: 0.2784  decode.d7.loss_cls: 0.0895  decode.d7.loss_mask: 0.2688  decode.d7.loss_dice: 0.2827  decode.d8.loss_cls: 0.0774  decode.d8.loss_mask: 0.2667  decode.d8.loss_dice: 0.2826
08/06 06:33:12 - mmengine - INFO - Iter(train) [ 31300/320000]  base_lr: 9.1152e-05 lr: 9.1152e-06  eta: 1 day, 15:24:52  time: 0.4922  data_time: 0.0110  memory: 5892  grad_norm: 89.1567  loss: 7.1863  decode.loss_cls: 0.1162  decode.loss_mask: 0.2570  decode.loss_dice: 0.2700  decode.d0.loss_cls: 0.8127  decode.d0.loss_mask: 0.2608  decode.d0.loss_dice: 0.2993  decode.d1.loss_cls: 0.1052  decode.d1.loss_mask: 0.2549  decode.d1.loss_dice: 0.2740  decode.d2.loss_cls: 0.1435  decode.d2.loss_mask: 0.2575  decode.d2.loss_dice: 0.2695  decode.d3.loss_cls: 0.1232  decode.d3.loss_mask: 0.2513  decode.d3.loss_dice: 0.2702  decode.d4.loss_cls: 0.1101  decode.d4.loss_mask: 0.2527  decode.d4.loss_dice: 0.2618  decode.d5.loss_cls: 0.1154  decode.d5.loss_mask: 0.2571  decode.d5.loss_dice: 0.2712  decode.d6.loss_cls: 0.1246  decode.d6.loss_mask: 0.2601  decode.d6.loss_dice: 0.2657  decode.d7.loss_cls: 0.1296  decode.d7.loss_mask: 0.2562  decode.d7.loss_dice: 0.2690  decode.d8.loss_cls: 0.1202  decode.d8.loss_mask: 0.2563  decode.d8.loss_dice: 0.2711
08/06 06:33:37 - mmengine - INFO - Iter(train) [ 31350/320000]  base_lr: 9.1138e-05 lr: 9.1138e-06  eta: 1 day, 15:24:28  time: 0.4918  data_time: 0.0109  memory: 5891  grad_norm: 140.2756  loss: 7.3535  decode.loss_cls: 0.1875  decode.loss_mask: 0.2276  decode.loss_dice: 0.2277  decode.d0.loss_cls: 0.7887  decode.d0.loss_mask: 0.2314  decode.d0.loss_dice: 0.2734  decode.d1.loss_cls: 0.1728  decode.d1.loss_mask: 0.2340  decode.d1.loss_dice: 0.2592  decode.d2.loss_cls: 0.2163  decode.d2.loss_mask: 0.2286  decode.d2.loss_dice: 0.2505  decode.d3.loss_cls: 0.1780  decode.d3.loss_mask: 0.2292  decode.d3.loss_dice: 0.2467  decode.d4.loss_cls: 0.2249  decode.d4.loss_mask: 0.2242  decode.d4.loss_dice: 0.2679  decode.d5.loss_cls: 0.2015  decode.d5.loss_mask: 0.2239  decode.d5.loss_dice: 0.2377  decode.d6.loss_cls: 0.1999  decode.d6.loss_mask: 0.2240  decode.d6.loss_dice: 0.2610  decode.d7.loss_cls: 0.2187  decode.d7.loss_mask: 0.2293  decode.d7.loss_dice: 0.2621  decode.d8.loss_cls: 0.1525  decode.d8.loss_mask: 0.2310  decode.d8.loss_dice: 0.2435
08/06 06:34:01 - mmengine - INFO - Iter(train) [ 31400/320000]  base_lr: 9.1124e-05 lr: 9.1124e-06  eta: 1 day, 15:24:03  time: 0.4918  data_time: 0.0109  memory: 5875  grad_norm: 109.8283  loss: 7.2310  decode.loss_cls: 0.1182  decode.loss_mask: 0.2269  decode.loss_dice: 0.2940  decode.d0.loss_cls: 0.9309  decode.d0.loss_mask: 0.2274  decode.d0.loss_dice: 0.2924  decode.d1.loss_cls: 0.2085  decode.d1.loss_mask: 0.2299  decode.d1.loss_dice: 0.2771  decode.d2.loss_cls: 0.1788  decode.d2.loss_mask: 0.2251  decode.d2.loss_dice: 0.2669  decode.d3.loss_cls: 0.1512  decode.d3.loss_mask: 0.2250  decode.d3.loss_dice: 0.2816  decode.d4.loss_cls: 0.1412  decode.d4.loss_mask: 0.2271  decode.d4.loss_dice: 0.2670  decode.d5.loss_cls: 0.1313  decode.d5.loss_mask: 0.2270  decode.d5.loss_dice: 0.2722  decode.d6.loss_cls: 0.0937  decode.d6.loss_mask: 0.2271  decode.d6.loss_dice: 0.2637  decode.d7.loss_cls: 0.1248  decode.d7.loss_mask: 0.2265  decode.d7.loss_dice: 0.2562  decode.d8.loss_cls: 0.1323  decode.d8.loss_mask: 0.2281  decode.d8.loss_dice: 0.2788
08/06 06:34:26 - mmengine - INFO - Iter(train) [ 31450/320000]  base_lr: 9.1110e-05 lr: 9.1110e-06  eta: 1 day, 15:23:39  time: 0.4923  data_time: 0.0112  memory: 5893  grad_norm: 99.0443  loss: 6.7827  decode.loss_cls: 0.1080  decode.loss_mask: 0.2426  decode.loss_dice: 0.2585  decode.d0.loss_cls: 0.8366  decode.d0.loss_mask: 0.2533  decode.d0.loss_dice: 0.2686  decode.d1.loss_cls: 0.1123  decode.d1.loss_mask: 0.2418  decode.d1.loss_dice: 0.2631  decode.d2.loss_cls: 0.1017  decode.d2.loss_mask: 0.2399  decode.d2.loss_dice: 0.2551  decode.d3.loss_cls: 0.1169  decode.d3.loss_mask: 0.2390  decode.d3.loss_dice: 0.2539  decode.d4.loss_cls: 0.1111  decode.d4.loss_mask: 0.2414  decode.d4.loss_dice: 0.2564  decode.d5.loss_cls: 0.1057  decode.d5.loss_mask: 0.2403  decode.d5.loss_dice: 0.2560  decode.d6.loss_cls: 0.0880  decode.d6.loss_mask: 0.2412  decode.d6.loss_dice: 0.2545  decode.d7.loss_cls: 0.1023  decode.d7.loss_mask: 0.2422  decode.d7.loss_dice: 0.2571  decode.d8.loss_cls: 0.1014  decode.d8.loss_mask: 0.2393  decode.d8.loss_dice: 0.2548
08/06 06:34:51 - mmengine - INFO - Iter(train) [ 31500/320000]  base_lr: 9.1096e-05 lr: 9.1096e-06  eta: 1 day, 15:23:16  time: 0.4936  data_time: 0.0111  memory: 5926  grad_norm: 115.8136  loss: 7.9747  decode.loss_cls: 0.1511  decode.loss_mask: 0.2424  decode.loss_dice: 0.2980  decode.d0.loss_cls: 1.0236  decode.d0.loss_mask: 0.2440  decode.d0.loss_dice: 0.2710  decode.d1.loss_cls: 0.2674  decode.d1.loss_mask: 0.2501  decode.d1.loss_dice: 0.2938  decode.d2.loss_cls: 0.1558  decode.d2.loss_mask: 0.2459  decode.d2.loss_dice: 0.2744  decode.d3.loss_cls: 0.1453  decode.d3.loss_mask: 0.2467  decode.d3.loss_dice: 0.2619  decode.d4.loss_cls: 0.1769  decode.d4.loss_mask: 0.2455  decode.d4.loss_dice: 0.2812  decode.d5.loss_cls: 0.2089  decode.d5.loss_mask: 0.2471  decode.d5.loss_dice: 0.2972  decode.d6.loss_cls: 0.2039  decode.d6.loss_mask: 0.2430  decode.d6.loss_dice: 0.2703  decode.d7.loss_cls: 0.1756  decode.d7.loss_mask: 0.2451  decode.d7.loss_dice: 0.3048  decode.d8.loss_cls: 0.1755  decode.d8.loss_mask: 0.2456  decode.d8.loss_dice: 0.2825
08/06 06:35:15 - mmengine - INFO - Iter(train) [ 31550/320000]  base_lr: 9.1081e-05 lr: 9.1081e-06  eta: 1 day, 15:22:52  time: 0.4928  data_time: 0.0111  memory: 5893  grad_norm: 100.4312  loss: 9.1790  decode.loss_cls: 0.1899  decode.loss_mask: 0.3098  decode.loss_dice: 0.3215  decode.d0.loss_cls: 1.0279  decode.d0.loss_mask: 0.3238  decode.d0.loss_dice: 0.3498  decode.d1.loss_cls: 0.2526  decode.d1.loss_mask: 0.3144  decode.d1.loss_dice: 0.3142  decode.d2.loss_cls: 0.2061  decode.d2.loss_mask: 0.3058  decode.d2.loss_dice: 0.3152  decode.d3.loss_cls: 0.2143  decode.d3.loss_mask: 0.3128  decode.d3.loss_dice: 0.3248  decode.d4.loss_cls: 0.1837  decode.d4.loss_mask: 0.3167  decode.d4.loss_dice: 0.3180  decode.d5.loss_cls: 0.1546  decode.d5.loss_mask: 0.3118  decode.d5.loss_dice: 0.3124  decode.d6.loss_cls: 0.2002  decode.d6.loss_mask: 0.3162  decode.d6.loss_dice: 0.3064  decode.d7.loss_cls: 0.1722  decode.d7.loss_mask: 0.3145  decode.d7.loss_dice: 0.3413  decode.d8.loss_cls: 0.1964  decode.d8.loss_mask: 0.3150  decode.d8.loss_dice: 0.3367
08/06 06:35:40 - mmengine - INFO - Iter(train) [ 31600/320000]  base_lr: 9.1067e-05 lr: 9.1067e-06  eta: 1 day, 15:22:28  time: 0.4928  data_time: 0.0111  memory: 5892  grad_norm: 130.8462  loss: 8.2387  decode.loss_cls: 0.2344  decode.loss_mask: 0.2395  decode.loss_dice: 0.2643  decode.d0.loss_cls: 1.0751  decode.d0.loss_mask: 0.2566  decode.d0.loss_dice: 0.2842  decode.d1.loss_cls: 0.2874  decode.d1.loss_mask: 0.2392  decode.d1.loss_dice: 0.2526  decode.d2.loss_cls: 0.2436  decode.d2.loss_mask: 0.2386  decode.d2.loss_dice: 0.2585  decode.d3.loss_cls: 0.1729  decode.d3.loss_mask: 0.2380  decode.d3.loss_dice: 0.2644  decode.d4.loss_cls: 0.3013  decode.d4.loss_mask: 0.2370  decode.d4.loss_dice: 0.2435  decode.d5.loss_cls: 0.2584  decode.d5.loss_mask: 0.2419  decode.d5.loss_dice: 0.2488  decode.d6.loss_cls: 0.2127  decode.d6.loss_mask: 0.2391  decode.d6.loss_dice: 0.2308  decode.d7.loss_cls: 0.2363  decode.d7.loss_mask: 0.2414  decode.d7.loss_dice: 0.2689  decode.d8.loss_cls: 0.2333  decode.d8.loss_mask: 0.2392  decode.d8.loss_dice: 0.2568
08/06 06:36:05 - mmengine - INFO - Iter(train) [ 31650/320000]  base_lr: 9.1053e-05 lr: 9.1053e-06  eta: 1 day, 15:22:04  time: 0.4937  data_time: 0.0109  memory: 5907  grad_norm: 103.0766  loss: 6.3062  decode.loss_cls: 0.0873  decode.loss_mask: 0.1876  decode.loss_dice: 0.2588  decode.d0.loss_cls: 0.9469  decode.d0.loss_mask: 0.1893  decode.d0.loss_dice: 0.2791  decode.d1.loss_cls: 0.1888  decode.d1.loss_mask: 0.1912  decode.d1.loss_dice: 0.2691  decode.d2.loss_cls: 0.1262  decode.d2.loss_mask: 0.1873  decode.d2.loss_dice: 0.2502  decode.d3.loss_cls: 0.0928  decode.d3.loss_mask: 0.1892  decode.d3.loss_dice: 0.2478  decode.d4.loss_cls: 0.0497  decode.d4.loss_mask: 0.2060  decode.d4.loss_dice: 0.2658  decode.d5.loss_cls: 0.0816  decode.d5.loss_mask: 0.1867  decode.d5.loss_dice: 0.2469  decode.d6.loss_cls: 0.0920  decode.d6.loss_mask: 0.1880  decode.d6.loss_dice: 0.2506  decode.d7.loss_cls: 0.0833  decode.d7.loss_mask: 0.1883  decode.d7.loss_dice: 0.2569  decode.d8.loss_cls: 0.0842  decode.d8.loss_mask: 0.1836  decode.d8.loss_dice: 0.2512
08/06 06:36:29 - mmengine - INFO - Iter(train) [ 31700/320000]  base_lr: 9.1039e-05 lr: 9.1039e-06  eta: 1 day, 15:21:40  time: 0.4920  data_time: 0.0108  memory: 5874  grad_norm: 75.4016  loss: 6.0768  decode.loss_cls: 0.0935  decode.loss_mask: 0.1838  decode.loss_dice: 0.2259  decode.d0.loss_cls: 0.8136  decode.d0.loss_mask: 0.1886  decode.d0.loss_dice: 0.2472  decode.d1.loss_cls: 0.1542  decode.d1.loss_mask: 0.1879  decode.d1.loss_dice: 0.2207  decode.d2.loss_cls: 0.1562  decode.d2.loss_mask: 0.1833  decode.d2.loss_dice: 0.2237  decode.d3.loss_cls: 0.1416  decode.d3.loss_mask: 0.1850  decode.d3.loss_dice: 0.2210  decode.d4.loss_cls: 0.1510  decode.d4.loss_mask: 0.1856  decode.d4.loss_dice: 0.2261  decode.d5.loss_cls: 0.1403  decode.d5.loss_mask: 0.1856  decode.d5.loss_dice: 0.2307  decode.d6.loss_cls: 0.1121  decode.d6.loss_mask: 0.1823  decode.d6.loss_dice: 0.2337  decode.d7.loss_cls: 0.1041  decode.d7.loss_mask: 0.1847  decode.d7.loss_dice: 0.2270  decode.d8.loss_cls: 0.0645  decode.d8.loss_mask: 0.1837  decode.d8.loss_dice: 0.2392
08/06 06:36:54 - mmengine - INFO - Iter(train) [ 31750/320000]  base_lr: 9.1025e-05 lr: 9.1025e-06  eta: 1 day, 15:21:17  time: 0.4925  data_time: 0.0108  memory: 5893  grad_norm: 86.2182  loss: 6.2523  decode.loss_cls: 0.0149  decode.loss_mask: 0.2343  decode.loss_dice: 0.2869  decode.d0.loss_cls: 0.8362  decode.d0.loss_mask: 0.2369  decode.d0.loss_dice: 0.2885  decode.d1.loss_cls: 0.0479  decode.d1.loss_mask: 0.2431  decode.d1.loss_dice: 0.2838  decode.d2.loss_cls: 0.0370  decode.d2.loss_mask: 0.2377  decode.d2.loss_dice: 0.2855  decode.d3.loss_cls: 0.0264  decode.d3.loss_mask: 0.2344  decode.d3.loss_dice: 0.2845  decode.d4.loss_cls: 0.0214  decode.d4.loss_mask: 0.2339  decode.d4.loss_dice: 0.2860  decode.d5.loss_cls: 0.0194  decode.d5.loss_mask: 0.2312  decode.d5.loss_dice: 0.2809  decode.d6.loss_cls: 0.0162  decode.d6.loss_mask: 0.2325  decode.d6.loss_dice: 0.2879  decode.d7.loss_cls: 0.0178  decode.d7.loss_mask: 0.2305  decode.d7.loss_dice: 0.2846  decode.d8.loss_cls: 0.0150  decode.d8.loss_mask: 0.2315  decode.d8.loss_dice: 0.2853
08/06 06:37:19 - mmengine - INFO - Iter(train) [ 31800/320000]  base_lr: 9.1010e-05 lr: 9.1010e-06  eta: 1 day, 15:20:54  time: 0.4934  data_time: 0.0106  memory: 5907  grad_norm: 160.8811  loss: 6.0319  decode.loss_cls: 0.1677  decode.loss_mask: 0.1727  decode.loss_dice: 0.2341  decode.d0.loss_cls: 0.8396  decode.d0.loss_mask: 0.1891  decode.d0.loss_dice: 0.2859  decode.d1.loss_cls: 0.1514  decode.d1.loss_mask: 0.1766  decode.d1.loss_dice: 0.2436  decode.d2.loss_cls: 0.1021  decode.d2.loss_mask: 0.1743  decode.d2.loss_dice: 0.2321  decode.d3.loss_cls: 0.1079  decode.d3.loss_mask: 0.1810  decode.d3.loss_dice: 0.2420  decode.d4.loss_cls: 0.0873  decode.d4.loss_mask: 0.1755  decode.d4.loss_dice: 0.2253  decode.d5.loss_cls: 0.0890  decode.d5.loss_mask: 0.1759  decode.d5.loss_dice: 0.2179  decode.d6.loss_cls: 0.0768  decode.d6.loss_mask: 0.1736  decode.d6.loss_dice: 0.2368  decode.d7.loss_cls: 0.1132  decode.d7.loss_mask: 0.1745  decode.d7.loss_dice: 0.2248  decode.d8.loss_cls: 0.1593  decode.d8.loss_mask: 0.1760  decode.d8.loss_dice: 0.2262
08/06 06:37:44 - mmengine - INFO - Iter(train) [ 31850/320000]  base_lr: 9.0996e-05 lr: 9.0996e-06  eta: 1 day, 15:20:30  time: 0.4931  data_time: 0.0109  memory: 5875  grad_norm: 253.4486  loss: 6.3985  decode.loss_cls: 0.1550  decode.loss_mask: 0.2274  decode.loss_dice: 0.2373  decode.d0.loss_cls: 0.8360  decode.d0.loss_mask: 0.2022  decode.d0.loss_dice: 0.2424  decode.d1.loss_cls: 0.2196  decode.d1.loss_mask: 0.2046  decode.d1.loss_dice: 0.2455  decode.d2.loss_cls: 0.0953  decode.d2.loss_mask: 0.2156  decode.d2.loss_dice: 0.2366  decode.d3.loss_cls: 0.0899  decode.d3.loss_mask: 0.2033  decode.d3.loss_dice: 0.2307  decode.d4.loss_cls: 0.1385  decode.d4.loss_mask: 0.2050  decode.d4.loss_dice: 0.2350  decode.d5.loss_cls: 0.0860  decode.d5.loss_mask: 0.2186  decode.d5.loss_dice: 0.2606  decode.d6.loss_cls: 0.1167  decode.d6.loss_mask: 0.2009  decode.d6.loss_dice: 0.2400  decode.d7.loss_cls: 0.0809  decode.d7.loss_mask: 0.2096  decode.d7.loss_dice: 0.2278  decode.d8.loss_cls: 0.1011  decode.d8.loss_mask: 0.2064  decode.d8.loss_dice: 0.2302
08/06 06:38:08 - mmengine - INFO - Iter(train) [ 31900/320000]  base_lr: 9.0982e-05 lr: 9.0982e-06  eta: 1 day, 15:20:06  time: 0.4934  data_time: 0.0109  memory: 5895  grad_norm: 82.9721  loss: 7.2024  decode.loss_cls: 0.1644  decode.loss_mask: 0.2673  decode.loss_dice: 0.2473  decode.d0.loss_cls: 0.8253  decode.d0.loss_mask: 0.2714  decode.d0.loss_dice: 0.2716  decode.d1.loss_cls: 0.1385  decode.d1.loss_mask: 0.2662  decode.d1.loss_dice: 0.2671  decode.d2.loss_cls: 0.1290  decode.d2.loss_mask: 0.2626  decode.d2.loss_dice: 0.2396  decode.d3.loss_cls: 0.1920  decode.d3.loss_mask: 0.2621  decode.d3.loss_dice: 0.2694  decode.d4.loss_cls: 0.1034  decode.d4.loss_mask: 0.2581  decode.d4.loss_dice: 0.2426  decode.d5.loss_cls: 0.1278  decode.d5.loss_mask: 0.2594  decode.d5.loss_dice: 0.2655  decode.d6.loss_cls: 0.1025  decode.d6.loss_mask: 0.2614  decode.d6.loss_dice: 0.2504  decode.d7.loss_cls: 0.0952  decode.d7.loss_mask: 0.2655  decode.d7.loss_dice: 0.2616  decode.d8.loss_cls: 0.1075  decode.d8.loss_mask: 0.2646  decode.d8.loss_dice: 0.2633
08/06 06:38:33 - mmengine - INFO - Iter(train) [ 31950/320000]  base_lr: 9.0968e-05 lr: 9.0968e-06  eta: 1 day, 15:19:42  time: 0.4926  data_time: 0.0110  memory: 5926  grad_norm: 161.2213  loss: 8.6732  decode.loss_cls: 0.1925  decode.loss_mask: 0.2632  decode.loss_dice: 0.3107  decode.d0.loss_cls: 0.9081  decode.d0.loss_mask: 0.2680  decode.d0.loss_dice: 0.3006  decode.d1.loss_cls: 0.2122  decode.d1.loss_mask: 0.2681  decode.d1.loss_dice: 0.3099  decode.d2.loss_cls: 0.2203  decode.d2.loss_mask: 0.2658  decode.d2.loss_dice: 0.2968  decode.d3.loss_cls: 0.2068  decode.d3.loss_mask: 0.2611  decode.d3.loss_dice: 0.2985  decode.d4.loss_cls: 0.2284  decode.d4.loss_mask: 0.2625  decode.d4.loss_dice: 0.3104  decode.d5.loss_cls: 0.2480  decode.d5.loss_mask: 0.2685  decode.d5.loss_dice: 0.3253  decode.d6.loss_cls: 0.2525  decode.d6.loss_mask: 0.2664  decode.d6.loss_dice: 0.3100  decode.d7.loss_cls: 0.2423  decode.d7.loss_mask: 0.2688  decode.d7.loss_dice: 0.3081  decode.d8.loss_cls: 0.2173  decode.d8.loss_mask: 0.2693  decode.d8.loss_dice: 0.3125
08/06 06:38:57 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 06:38:57 - mmengine - INFO - Iter(train) [ 32000/320000]  base_lr: 9.0954e-05 lr: 9.0954e-06  eta: 1 day, 15:19:18  time: 0.4934  data_time: 0.0111  memory: 5890  grad_norm: 137.7545  loss: 9.1184  decode.loss_cls: 0.2205  decode.loss_mask: 0.2759  decode.loss_dice: 0.2892  decode.d0.loss_cls: 0.8553  decode.d0.loss_mask: 0.2927  decode.d0.loss_dice: 0.3312  decode.d1.loss_cls: 0.2878  decode.d1.loss_mask: 0.2751  decode.d1.loss_dice: 0.2917  decode.d2.loss_cls: 0.2864  decode.d2.loss_mask: 0.2837  decode.d2.loss_dice: 0.2890  decode.d3.loss_cls: 0.2369  decode.d3.loss_mask: 0.2880  decode.d3.loss_dice: 0.2955  decode.d4.loss_cls: 0.3068  decode.d4.loss_mask: 0.2762  decode.d4.loss_dice: 0.2948  decode.d5.loss_cls: 0.2769  decode.d5.loss_mask: 0.2761  decode.d5.loss_dice: 0.3013  decode.d6.loss_cls: 0.2818  decode.d6.loss_mask: 0.2869  decode.d6.loss_dice: 0.2896  decode.d7.loss_cls: 0.2711  decode.d7.loss_mask: 0.2803  decode.d7.loss_dice: 0.3001  decode.d8.loss_cls: 0.2932  decode.d8.loss_mask: 0.2822  decode.d8.loss_dice: 0.3020
08/06 06:39:22 - mmengine - INFO - Iter(train) [ 32050/320000]  base_lr: 9.0939e-05 lr: 9.0939e-06  eta: 1 day, 15:18:54  time: 0.4936  data_time: 0.0112  memory: 5907  grad_norm: 104.2010  loss: 6.8196  decode.loss_cls: 0.0630  decode.loss_mask: 0.2720  decode.loss_dice: 0.2700  decode.d0.loss_cls: 0.8164  decode.d0.loss_mask: 0.2741  decode.d0.loss_dice: 0.2755  decode.d1.loss_cls: 0.0854  decode.d1.loss_mask: 0.2679  decode.d1.loss_dice: 0.2741  decode.d2.loss_cls: 0.0984  decode.d2.loss_mask: 0.2692  decode.d2.loss_dice: 0.2448  decode.d3.loss_cls: 0.0754  decode.d3.loss_mask: 0.2652  decode.d3.loss_dice: 0.2452  decode.d4.loss_cls: 0.0772  decode.d4.loss_mask: 0.2701  decode.d4.loss_dice: 0.2550  decode.d5.loss_cls: 0.0518  decode.d5.loss_mask: 0.2653  decode.d5.loss_dice: 0.2678  decode.d6.loss_cls: 0.0800  decode.d6.loss_mask: 0.2643  decode.d6.loss_dice: 0.2637  decode.d7.loss_cls: 0.0883  decode.d7.loss_mask: 0.2659  decode.d7.loss_dice: 0.2716  decode.d8.loss_cls: 0.0554  decode.d8.loss_mask: 0.2696  decode.d8.loss_dice: 0.2771
08/06 06:39:47 - mmengine - INFO - Iter(train) [ 32100/320000]  base_lr: 9.0925e-05 lr: 9.0925e-06  eta: 1 day, 15:18:30  time: 0.4927  data_time: 0.0111  memory: 5875  grad_norm: 179.1532  loss: 8.6151  decode.loss_cls: 0.2331  decode.loss_mask: 0.2419  decode.loss_dice: 0.3069  decode.d0.loss_cls: 1.1074  decode.d0.loss_mask: 0.2502  decode.d0.loss_dice: 0.3327  decode.d1.loss_cls: 0.2343  decode.d1.loss_mask: 0.2415  decode.d1.loss_dice: 0.3001  decode.d2.loss_cls: 0.2218  decode.d2.loss_mask: 0.2438  decode.d2.loss_dice: 0.3165  decode.d3.loss_cls: 0.2043  decode.d3.loss_mask: 0.2393  decode.d3.loss_dice: 0.3021  decode.d4.loss_cls: 0.2072  decode.d4.loss_mask: 0.2443  decode.d4.loss_dice: 0.3080  decode.d5.loss_cls: 0.2035  decode.d5.loss_mask: 0.2422  decode.d5.loss_dice: 0.3053  decode.d6.loss_cls: 0.2300  decode.d6.loss_mask: 0.2434  decode.d6.loss_dice: 0.3162  decode.d7.loss_cls: 0.2183  decode.d7.loss_mask: 0.2393  decode.d7.loss_dice: 0.3043  decode.d8.loss_cls: 0.2265  decode.d8.loss_mask: 0.2441  decode.d8.loss_dice: 0.3067
08/06 06:40:11 - mmengine - INFO - Iter(train) [ 32150/320000]  base_lr: 9.0911e-05 lr: 9.0911e-06  eta: 1 day, 15:18:06  time: 0.4923  data_time: 0.0111  memory: 5907  grad_norm: 71.7576  loss: 9.8143  decode.loss_cls: 0.3506  decode.loss_mask: 0.2325  decode.loss_dice: 0.3522  decode.d0.loss_cls: 0.9187  decode.d0.loss_mask: 0.2395  decode.d0.loss_dice: 0.4114  decode.d1.loss_cls: 0.4524  decode.d1.loss_mask: 0.2348  decode.d1.loss_dice: 0.3582  decode.d2.loss_cls: 0.3219  decode.d2.loss_mask: 0.2373  decode.d2.loss_dice: 0.3167  decode.d3.loss_cls: 0.3330  decode.d3.loss_mask: 0.2338  decode.d3.loss_dice: 0.3458  decode.d4.loss_cls: 0.3163  decode.d4.loss_mask: 0.2325  decode.d4.loss_dice: 0.3609  decode.d5.loss_cls: 0.3089  decode.d5.loss_mask: 0.2382  decode.d5.loss_dice: 0.3451  decode.d6.loss_cls: 0.2758  decode.d6.loss_mask: 0.2377  decode.d6.loss_dice: 0.3270  decode.d7.loss_cls: 0.2999  decode.d7.loss_mask: 0.2363  decode.d7.loss_dice: 0.3473  decode.d8.loss_cls: 0.3687  decode.d8.loss_mask: 0.2361  decode.d8.loss_dice: 0.3447
08/06 06:40:36 - mmengine - INFO - Iter(train) [ 32200/320000]  base_lr: 9.0897e-05 lr: 9.0897e-06  eta: 1 day, 15:17:42  time: 0.4930  data_time: 0.0111  memory: 5891  grad_norm: 215.7621  loss: 10.3002  decode.loss_cls: 0.2657  decode.loss_mask: 0.3231  decode.loss_dice: 0.3282  decode.d0.loss_cls: 1.0406  decode.d0.loss_mask: 0.3504  decode.d0.loss_dice: 0.3399  decode.d1.loss_cls: 0.3537  decode.d1.loss_mask: 0.3409  decode.d1.loss_dice: 0.3178  decode.d2.loss_cls: 0.2882  decode.d2.loss_mask: 0.3250  decode.d2.loss_dice: 0.3095  decode.d3.loss_cls: 0.3104  decode.d3.loss_mask: 0.3257  decode.d3.loss_dice: 0.3303  decode.d4.loss_cls: 0.3051  decode.d4.loss_mask: 0.3270  decode.d4.loss_dice: 0.3047  decode.d5.loss_cls: 0.3151  decode.d5.loss_mask: 0.3218  decode.d5.loss_dice: 0.3339  decode.d6.loss_cls: 0.3194  decode.d6.loss_mask: 0.3158  decode.d6.loss_dice: 0.3294  decode.d7.loss_cls: 0.3031  decode.d7.loss_mask: 0.3258  decode.d7.loss_dice: 0.3443  decode.d8.loss_cls: 0.2691  decode.d8.loss_mask: 0.3166  decode.d8.loss_dice: 0.3197
08/06 06:41:01 - mmengine - INFO - Iter(train) [ 32250/320000]  base_lr: 9.0882e-05 lr: 9.0882e-06  eta: 1 day, 15:17:17  time: 0.4927  data_time: 0.0111  memory: 5859  grad_norm: 139.5757  loss: 9.0891  decode.loss_cls: 0.1925  decode.loss_mask: 0.2735  decode.loss_dice: 0.3923  decode.d0.loss_cls: 1.0163  decode.d0.loss_mask: 0.2630  decode.d0.loss_dice: 0.3312  decode.d1.loss_cls: 0.2638  decode.d1.loss_mask: 0.2590  decode.d1.loss_dice: 0.3414  decode.d2.loss_cls: 0.2090  decode.d2.loss_mask: 0.2574  decode.d2.loss_dice: 0.3176  decode.d3.loss_cls: 0.1817  decode.d3.loss_mask: 0.2571  decode.d3.loss_dice: 0.3358  decode.d4.loss_cls: 0.2569  decode.d4.loss_mask: 0.2647  decode.d4.loss_dice: 0.3306  decode.d5.loss_cls: 0.2068  decode.d5.loss_mask: 0.2691  decode.d5.loss_dice: 0.3709  decode.d6.loss_cls: 0.1862  decode.d6.loss_mask: 0.2689  decode.d6.loss_dice: 0.3793  decode.d7.loss_cls: 0.1831  decode.d7.loss_mask: 0.2653  decode.d7.loss_dice: 0.3695  decode.d8.loss_cls: 0.1900  decode.d8.loss_mask: 0.2645  decode.d8.loss_dice: 0.3916
08/06 06:41:25 - mmengine - INFO - Iter(train) [ 32300/320000]  base_lr: 9.0868e-05 lr: 9.0868e-06  eta: 1 day, 15:16:53  time: 0.4930  data_time: 0.0112  memory: 5926  grad_norm: 83.0905  loss: 8.8044  decode.loss_cls: 0.2276  decode.loss_mask: 0.2784  decode.loss_dice: 0.2749  decode.d0.loss_cls: 1.0593  decode.d0.loss_mask: 0.2795  decode.d0.loss_dice: 0.2766  decode.d1.loss_cls: 0.3435  decode.d1.loss_mask: 0.2739  decode.d1.loss_dice: 0.2709  decode.d2.loss_cls: 0.2977  decode.d2.loss_mask: 0.2656  decode.d2.loss_dice: 0.2625  decode.d3.loss_cls: 0.2692  decode.d3.loss_mask: 0.2691  decode.d3.loss_dice: 0.2727  decode.d4.loss_cls: 0.2770  decode.d4.loss_mask: 0.2760  decode.d4.loss_dice: 0.2884  decode.d5.loss_cls: 0.2372  decode.d5.loss_mask: 0.2701  decode.d5.loss_dice: 0.2668  decode.d6.loss_cls: 0.2312  decode.d6.loss_mask: 0.2692  decode.d6.loss_dice: 0.2665  decode.d7.loss_cls: 0.2080  decode.d7.loss_mask: 0.2694  decode.d7.loss_dice: 0.2710  decode.d8.loss_cls: 0.2052  decode.d8.loss_mask: 0.2734  decode.d8.loss_dice: 0.2735
08/06 06:41:50 - mmengine - INFO - Iter(train) [ 32350/320000]  base_lr: 9.0854e-05 lr: 9.0854e-06  eta: 1 day, 15:16:29  time: 0.4920  data_time: 0.0110  memory: 5891  grad_norm: 92.3720  loss: 8.0527  decode.loss_cls: 0.2094  decode.loss_mask: 0.2550  decode.loss_dice: 0.3226  decode.d0.loss_cls: 0.9089  decode.d0.loss_mask: 0.2413  decode.d0.loss_dice: 0.3363  decode.d1.loss_cls: 0.2292  decode.d1.loss_mask: 0.2368  decode.d1.loss_dice: 0.3224  decode.d2.loss_cls: 0.1577  decode.d2.loss_mask: 0.2365  decode.d2.loss_dice: 0.3195  decode.d3.loss_cls: 0.1165  decode.d3.loss_mask: 0.2364  decode.d3.loss_dice: 0.3211  decode.d4.loss_cls: 0.1683  decode.d4.loss_mask: 0.2367  decode.d4.loss_dice: 0.3204  decode.d5.loss_cls: 0.1647  decode.d5.loss_mask: 0.2340  decode.d5.loss_dice: 0.3070  decode.d6.loss_cls: 0.1697  decode.d6.loss_mask: 0.2439  decode.d6.loss_dice: 0.3281  decode.d7.loss_cls: 0.1770  decode.d7.loss_mask: 0.2537  decode.d7.loss_dice: 0.3073  decode.d8.loss_cls: 0.1250  decode.d8.loss_mask: 0.2527  decode.d8.loss_dice: 0.3148
08/06 06:42:15 - mmengine - INFO - Iter(train) [ 32400/320000]  base_lr: 9.0840e-05 lr: 9.0840e-06  eta: 1 day, 15:16:06  time: 0.4920  data_time: 0.0111  memory: 5907  grad_norm: 77.2443  loss: 7.2573  decode.loss_cls: 0.1881  decode.loss_mask: 0.2286  decode.loss_dice: 0.2485  decode.d0.loss_cls: 0.8444  decode.d0.loss_mask: 0.2330  decode.d0.loss_dice: 0.2704  decode.d1.loss_cls: 0.1903  decode.d1.loss_mask: 0.2306  decode.d1.loss_dice: 0.2389  decode.d2.loss_cls: 0.1722  decode.d2.loss_mask: 0.2301  decode.d2.loss_dice: 0.2557  decode.d3.loss_cls: 0.1794  decode.d3.loss_mask: 0.2266  decode.d3.loss_dice: 0.2321  decode.d4.loss_cls: 0.2064  decode.d4.loss_mask: 0.2313  decode.d4.loss_dice: 0.2887  decode.d5.loss_cls: 0.1636  decode.d5.loss_mask: 0.2302  decode.d5.loss_dice: 0.2591  decode.d6.loss_cls: 0.1604  decode.d6.loss_mask: 0.2267  decode.d6.loss_dice: 0.2576  decode.d7.loss_cls: 0.1620  decode.d7.loss_mask: 0.2279  decode.d7.loss_dice: 0.2468  decode.d8.loss_cls: 0.1589  decode.d8.loss_mask: 0.2314  decode.d8.loss_dice: 0.2374
08/06 06:42:39 - mmengine - INFO - Iter(train) [ 32450/320000]  base_lr: 9.0826e-05 lr: 9.0826e-06  eta: 1 day, 15:15:42  time: 0.4930  data_time: 0.0109  memory: 5907  grad_norm: 133.4049  loss: 7.1764  decode.loss_cls: 0.0619  decode.loss_mask: 0.2655  decode.loss_dice: 0.3046  decode.d0.loss_cls: 0.9661  decode.d0.loss_mask: 0.2478  decode.d0.loss_dice: 0.2873  decode.d1.loss_cls: 0.1430  decode.d1.loss_mask: 0.2425  decode.d1.loss_dice: 0.2730  decode.d2.loss_cls: 0.1024  decode.d2.loss_mask: 0.2384  decode.d2.loss_dice: 0.2722  decode.d3.loss_cls: 0.0978  decode.d3.loss_mask: 0.2434  decode.d3.loss_dice: 0.2794  decode.d4.loss_cls: 0.1080  decode.d4.loss_mask: 0.2449  decode.d4.loss_dice: 0.2796  decode.d5.loss_cls: 0.1274  decode.d5.loss_mask: 0.2496  decode.d5.loss_dice: 0.2864  decode.d6.loss_cls: 0.0578  decode.d6.loss_mask: 0.2671  decode.d6.loss_dice: 0.2923  decode.d7.loss_cls: 0.0607  decode.d7.loss_mask: 0.2667  decode.d7.loss_dice: 0.2875  decode.d8.loss_cls: 0.0548  decode.d8.loss_mask: 0.2712  decode.d8.loss_dice: 0.2970
08/06 06:43:04 - mmengine - INFO - Iter(train) [ 32500/320000]  base_lr: 9.0811e-05 lr: 9.0811e-06  eta: 1 day, 15:15:18  time: 0.4928  data_time: 0.0110  memory: 5891  grad_norm: 165.5187  loss: 6.2966  decode.loss_cls: 0.0996  decode.loss_mask: 0.2207  decode.loss_dice: 0.2569  decode.d0.loss_cls: 0.8304  decode.d0.loss_mask: 0.2298  decode.d0.loss_dice: 0.2946  decode.d1.loss_cls: 0.1240  decode.d1.loss_mask: 0.2246  decode.d1.loss_dice: 0.2636  decode.d2.loss_cls: 0.0508  decode.d2.loss_mask: 0.2207  decode.d2.loss_dice: 0.2529  decode.d3.loss_cls: 0.0476  decode.d3.loss_mask: 0.2233  decode.d3.loss_dice: 0.2474  decode.d4.loss_cls: 0.0624  decode.d4.loss_mask: 0.2228  decode.d4.loss_dice: 0.2383  decode.d5.loss_cls: 0.0627  decode.d5.loss_mask: 0.2203  decode.d5.loss_dice: 0.2353  decode.d6.loss_cls: 0.0683  decode.d6.loss_mask: 0.2218  decode.d6.loss_dice: 0.2401  decode.d7.loss_cls: 0.0815  decode.d7.loss_mask: 0.2229  decode.d7.loss_dice: 0.2617  decode.d8.loss_cls: 0.1017  decode.d8.loss_mask: 0.2193  decode.d8.loss_dice: 0.2506
08/06 06:43:29 - mmengine - INFO - Iter(train) [ 32550/320000]  base_lr: 9.0797e-05 lr: 9.0797e-06  eta: 1 day, 15:14:54  time: 0.4929  data_time: 0.0112  memory: 5927  grad_norm: 62.2576  loss: 6.4343  decode.loss_cls: 0.0825  decode.loss_mask: 0.2386  decode.loss_dice: 0.2513  decode.d0.loss_cls: 0.7315  decode.d0.loss_mask: 0.2405  decode.d0.loss_dice: 0.2398  decode.d1.loss_cls: 0.0417  decode.d1.loss_mask: 0.2349  decode.d1.loss_dice: 0.2498  decode.d2.loss_cls: 0.1119  decode.d2.loss_mask: 0.2366  decode.d2.loss_dice: 0.2631  decode.d3.loss_cls: 0.0868  decode.d3.loss_mask: 0.2366  decode.d3.loss_dice: 0.2484  decode.d4.loss_cls: 0.0805  decode.d4.loss_mask: 0.2358  decode.d4.loss_dice: 0.2456  decode.d5.loss_cls: 0.0988  decode.d5.loss_mask: 0.2353  decode.d5.loss_dice: 0.2557  decode.d6.loss_cls: 0.1276  decode.d6.loss_mask: 0.2359  decode.d6.loss_dice: 0.2466  decode.d7.loss_cls: 0.1259  decode.d7.loss_mask: 0.2369  decode.d7.loss_dice: 0.2581  decode.d8.loss_cls: 0.0807  decode.d8.loss_mask: 0.2355  decode.d8.loss_dice: 0.2413
08/06 06:43:53 - mmengine - INFO - Iter(train) [ 32600/320000]  base_lr: 9.0783e-05 lr: 9.0783e-06  eta: 1 day, 15:14:30  time: 0.4935  data_time: 0.0111  memory: 5909  grad_norm: 189.9898  loss: 6.8118  decode.loss_cls: 0.1192  decode.loss_mask: 0.2499  decode.loss_dice: 0.2548  decode.d0.loss_cls: 1.0939  decode.d0.loss_mask: 0.2155  decode.d0.loss_dice: 0.2502  decode.d1.loss_cls: 0.1835  decode.d1.loss_mask: 0.2444  decode.d1.loss_dice: 0.2475  decode.d2.loss_cls: 0.0733  decode.d2.loss_mask: 0.2491  decode.d2.loss_dice: 0.2527  decode.d3.loss_cls: 0.0543  decode.d3.loss_mask: 0.2355  decode.d3.loss_dice: 0.2465  decode.d4.loss_cls: 0.0562  decode.d4.loss_mask: 0.2299  decode.d4.loss_dice: 0.2514  decode.d5.loss_cls: 0.0928  decode.d5.loss_mask: 0.2296  decode.d5.loss_dice: 0.2490  decode.d6.loss_cls: 0.0846  decode.d6.loss_mask: 0.2433  decode.d6.loss_dice: 0.2507  decode.d7.loss_cls: 0.0733  decode.d7.loss_mask: 0.2459  decode.d7.loss_dice: 0.2600  decode.d8.loss_cls: 0.0709  decode.d8.loss_mask: 0.2440  decode.d8.loss_dice: 0.2600
08/06 06:44:18 - mmengine - INFO - Iter(train) [ 32650/320000]  base_lr: 9.0769e-05 lr: 9.0769e-06  eta: 1 day, 15:14:06  time: 0.4921  data_time: 0.0110  memory: 5890  grad_norm: 127.4015  loss: 6.1070  decode.loss_cls: 0.1025  decode.loss_mask: 0.2297  decode.loss_dice: 0.2220  decode.d0.loss_cls: 0.7475  decode.d0.loss_mask: 0.2443  decode.d0.loss_dice: 0.2302  decode.d1.loss_cls: 0.0715  decode.d1.loss_mask: 0.2358  decode.d1.loss_dice: 0.2316  decode.d2.loss_cls: 0.0452  decode.d2.loss_mask: 0.2344  decode.d2.loss_dice: 0.2244  decode.d3.loss_cls: 0.0881  decode.d3.loss_mask: 0.2310  decode.d3.loss_dice: 0.2197  decode.d4.loss_cls: 0.0861  decode.d4.loss_mask: 0.2298  decode.d4.loss_dice: 0.2261  decode.d5.loss_cls: 0.0912  decode.d5.loss_mask: 0.2316  decode.d5.loss_dice: 0.2252  decode.d6.loss_cls: 0.0780  decode.d6.loss_mask: 0.2336  decode.d6.loss_dice: 0.2385  decode.d7.loss_cls: 0.0798  decode.d7.loss_mask: 0.2312  decode.d7.loss_dice: 0.2326  decode.d8.loss_cls: 0.1031  decode.d8.loss_mask: 0.2322  decode.d8.loss_dice: 0.2304
08/06 06:44:43 - mmengine - INFO - Iter(train) [ 32700/320000]  base_lr: 9.0755e-05 lr: 9.0755e-06  eta: 1 day, 15:13:42  time: 0.4921  data_time: 0.0110  memory: 5891  grad_norm: 323.9288  loss: 8.0835  decode.loss_cls: 0.1120  decode.loss_mask: 0.3288  decode.loss_dice: 0.2617  decode.d0.loss_cls: 0.9087  decode.d0.loss_mask: 0.3571  decode.d0.loss_dice: 0.2833  decode.d1.loss_cls: 0.1568  decode.d1.loss_mask: 0.3337  decode.d1.loss_dice: 0.2804  decode.d2.loss_cls: 0.1191  decode.d2.loss_mask: 0.3275  decode.d2.loss_dice: 0.2674  decode.d3.loss_cls: 0.1256  decode.d3.loss_mask: 0.3272  decode.d3.loss_dice: 0.2649  decode.d4.loss_cls: 0.1273  decode.d4.loss_mask: 0.3316  decode.d4.loss_dice: 0.2701  decode.d5.loss_cls: 0.1252  decode.d5.loss_mask: 0.3404  decode.d5.loss_dice: 0.2696  decode.d6.loss_cls: 0.1434  decode.d6.loss_mask: 0.3277  decode.d6.loss_dice: 0.2609  decode.d7.loss_cls: 0.1365  decode.d7.loss_mask: 0.3295  decode.d7.loss_dice: 0.2644  decode.d8.loss_cls: 0.1182  decode.d8.loss_mask: 0.3249  decode.d8.loss_dice: 0.2596
08/06 06:45:07 - mmengine - INFO - Iter(train) [ 32750/320000]  base_lr: 9.0740e-05 lr: 9.0740e-06  eta: 1 day, 15:13:18  time: 0.4929  data_time: 0.0107  memory: 5908  grad_norm: 99.5178  loss: 5.4087  decode.loss_cls: 0.0152  decode.loss_mask: 0.1803  decode.loss_dice: 0.2360  decode.d0.loss_cls: 0.8942  decode.d0.loss_mask: 0.1754  decode.d0.loss_dice: 0.2382  decode.d1.loss_cls: 0.0575  decode.d1.loss_mask: 0.1806  decode.d1.loss_dice: 0.2480  decode.d2.loss_cls: 0.0440  decode.d2.loss_mask: 0.1698  decode.d2.loss_dice: 0.2335  decode.d3.loss_cls: 0.0425  decode.d3.loss_mask: 0.1794  decode.d3.loss_dice: 0.2474  decode.d4.loss_cls: 0.0687  decode.d4.loss_mask: 0.1650  decode.d4.loss_dice: 0.2257  decode.d5.loss_cls: 0.0872  decode.d5.loss_mask: 0.1684  decode.d5.loss_dice: 0.2227  decode.d6.loss_cls: 0.0192  decode.d6.loss_mask: 0.1791  decode.d6.loss_dice: 0.2444  decode.d7.loss_cls: 0.0247  decode.d7.loss_mask: 0.1750  decode.d7.loss_dice: 0.2368  decode.d8.loss_cls: 0.0277  decode.d8.loss_mask: 0.1816  decode.d8.loss_dice: 0.2403
08/06 06:45:32 - mmengine - INFO - Iter(train) [ 32800/320000]  base_lr: 9.0726e-05 lr: 9.0726e-06  eta: 1 day, 15:12:54  time: 0.4929  data_time: 0.0110  memory: 5982  grad_norm: 205.9422  loss: 7.2139  decode.loss_cls: 0.0833  decode.loss_mask: 0.2372  decode.loss_dice: 0.2902  decode.d0.loss_cls: 0.8805  decode.d0.loss_mask: 0.2437  decode.d0.loss_dice: 0.2885  decode.d1.loss_cls: 0.1079  decode.d1.loss_mask: 0.2426  decode.d1.loss_dice: 0.2967  decode.d2.loss_cls: 0.1282  decode.d2.loss_mask: 0.2398  decode.d2.loss_dice: 0.2750  decode.d3.loss_cls: 0.1573  decode.d3.loss_mask: 0.2384  decode.d3.loss_dice: 0.2845  decode.d4.loss_cls: 0.1426  decode.d4.loss_mask: 0.2423  decode.d4.loss_dice: 0.2795  decode.d5.loss_cls: 0.1619  decode.d5.loss_mask: 0.2369  decode.d5.loss_dice: 0.2719  decode.d6.loss_cls: 0.1267  decode.d6.loss_mask: 0.2389  decode.d6.loss_dice: 0.2768  decode.d7.loss_cls: 0.1006  decode.d7.loss_mask: 0.2361  decode.d7.loss_dice: 0.2770  decode.d8.loss_cls: 0.1031  decode.d8.loss_mask: 0.2380  decode.d8.loss_dice: 0.2881
08/06 06:45:56 - mmengine - INFO - Iter(train) [ 32850/320000]  base_lr: 9.0712e-05 lr: 9.0712e-06  eta: 1 day, 15:12:30  time: 0.4916  data_time: 0.0109  memory: 5927  grad_norm: 183.3509  loss: 7.3364  decode.loss_cls: 0.1489  decode.loss_mask: 0.2404  decode.loss_dice: 0.2911  decode.d0.loss_cls: 0.8195  decode.d0.loss_mask: 0.2529  decode.d0.loss_dice: 0.3109  decode.d1.loss_cls: 0.0918  decode.d1.loss_mask: 0.2435  decode.d1.loss_dice: 0.2867  decode.d2.loss_cls: 0.1060  decode.d2.loss_mask: 0.2432  decode.d2.loss_dice: 0.2920  decode.d3.loss_cls: 0.1233  decode.d3.loss_mask: 0.2469  decode.d3.loss_dice: 0.2828  decode.d4.loss_cls: 0.1202  decode.d4.loss_mask: 0.2380  decode.d4.loss_dice: 0.2865  decode.d5.loss_cls: 0.1639  decode.d5.loss_mask: 0.2427  decode.d5.loss_dice: 0.3109  decode.d6.loss_cls: 0.1486  decode.d6.loss_mask: 0.2463  decode.d6.loss_dice: 0.2962  decode.d7.loss_cls: 0.1025  decode.d7.loss_mask: 0.2497  decode.d7.loss_dice: 0.2943  decode.d8.loss_cls: 0.1228  decode.d8.loss_mask: 0.2437  decode.d8.loss_dice: 0.2903
08/06 06:46:21 - mmengine - INFO - Iter(train) [ 32900/320000]  base_lr: 9.0698e-05 lr: 9.0698e-06  eta: 1 day, 15:12:06  time: 0.4925  data_time: 0.0109  memory: 5907  grad_norm: 350.5315  loss: 8.1692  decode.loss_cls: 0.0426  decode.loss_mask: 0.3334  decode.loss_dice: 0.3115  decode.d0.loss_cls: 0.9202  decode.d0.loss_mask: 0.3312  decode.d0.loss_dice: 0.3039  decode.d1.loss_cls: 0.2162  decode.d1.loss_mask: 0.3141  decode.d1.loss_dice: 0.2930  decode.d2.loss_cls: 0.1146  decode.d2.loss_mask: 0.3505  decode.d2.loss_dice: 0.3030  decode.d3.loss_cls: 0.0797  decode.d3.loss_mask: 0.3599  decode.d3.loss_dice: 0.2776  decode.d4.loss_cls: 0.1281  decode.d4.loss_mask: 0.3640  decode.d4.loss_dice: 0.2967  decode.d5.loss_cls: 0.0779  decode.d5.loss_mask: 0.3504  decode.d5.loss_dice: 0.2930  decode.d6.loss_cls: 0.0968  decode.d6.loss_mask: 0.3502  decode.d6.loss_dice: 0.2911  decode.d7.loss_cls: 0.0536  decode.d7.loss_mask: 0.3347  decode.d7.loss_dice: 0.2961  decode.d8.loss_cls: 0.0639  decode.d8.loss_mask: 0.3263  decode.d8.loss_dice: 0.2948
08/06 06:46:46 - mmengine - INFO - Iter(train) [ 32950/320000]  base_lr: 9.0683e-05 lr: 9.0683e-06  eta: 1 day, 15:11:43  time: 0.4938  data_time: 0.0110  memory: 5892  grad_norm: 180.5112  loss: 8.1180  decode.loss_cls: 0.2327  decode.loss_mask: 0.2449  decode.loss_dice: 0.2750  decode.d0.loss_cls: 0.8634  decode.d0.loss_mask: 0.2605  decode.d0.loss_dice: 0.2903  decode.d1.loss_cls: 0.2213  decode.d1.loss_mask: 0.2953  decode.d1.loss_dice: 0.2836  decode.d2.loss_cls: 0.2054  decode.d2.loss_mask: 0.2437  decode.d2.loss_dice: 0.2545  decode.d3.loss_cls: 0.2135  decode.d3.loss_mask: 0.2703  decode.d3.loss_dice: 0.2857  decode.d4.loss_cls: 0.1992  decode.d4.loss_mask: 0.2467  decode.d4.loss_dice: 0.2725  decode.d5.loss_cls: 0.2511  decode.d5.loss_mask: 0.2415  decode.d5.loss_dice: 0.2535  decode.d6.loss_cls: 0.2436  decode.d6.loss_mask: 0.2423  decode.d6.loss_dice: 0.2586  decode.d7.loss_cls: 0.2224  decode.d7.loss_mask: 0.2394  decode.d7.loss_dice: 0.2532  decode.d8.loss_cls: 0.2351  decode.d8.loss_mask: 0.2434  decode.d8.loss_dice: 0.2753
08/06 06:47:10 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 06:47:10 - mmengine - INFO - Iter(train) [ 33000/320000]  base_lr: 9.0669e-05 lr: 9.0669e-06  eta: 1 day, 15:11:19  time: 0.4930  data_time: 0.0109  memory: 5964  grad_norm: 196.2721  loss: 6.2304  decode.loss_cls: 0.0706  decode.loss_mask: 0.2309  decode.loss_dice: 0.2272  decode.d0.loss_cls: 0.8512  decode.d0.loss_mask: 0.2330  decode.d0.loss_dice: 0.2555  decode.d1.loss_cls: 0.1066  decode.d1.loss_mask: 0.2278  decode.d1.loss_dice: 0.2447  decode.d2.loss_cls: 0.0982  decode.d2.loss_mask: 0.2307  decode.d2.loss_dice: 0.2383  decode.d3.loss_cls: 0.0600  decode.d3.loss_mask: 0.2348  decode.d3.loss_dice: 0.2374  decode.d4.loss_cls: 0.0673  decode.d4.loss_mask: 0.2241  decode.d4.loss_dice: 0.2322  decode.d5.loss_cls: 0.0864  decode.d5.loss_mask: 0.2305  decode.d5.loss_dice: 0.2358  decode.d6.loss_cls: 0.0755  decode.d6.loss_mask: 0.2248  decode.d6.loss_dice: 0.2326  decode.d7.loss_cls: 0.0650  decode.d7.loss_mask: 0.2211  decode.d7.loss_dice: 0.2323  decode.d8.loss_cls: 0.0880  decode.d8.loss_mask: 0.2406  decode.d8.loss_dice: 0.2273
08/06 06:47:35 - mmengine - INFO - Iter(train) [ 33050/320000]  base_lr: 9.0655e-05 lr: 9.0655e-06  eta: 1 day, 15:10:55  time: 0.4930  data_time: 0.0112  memory: 5927  grad_norm: 57.3886  loss: 6.7114  decode.loss_cls: 0.1140  decode.loss_mask: 0.2253  decode.loss_dice: 0.2284  decode.d0.loss_cls: 0.9215  decode.d0.loss_mask: 0.2286  decode.d0.loss_dice: 0.2353  decode.d1.loss_cls: 0.1227  decode.d1.loss_mask: 0.2246  decode.d1.loss_dice: 0.2148  decode.d2.loss_cls: 0.1423  decode.d2.loss_mask: 0.2233  decode.d2.loss_dice: 0.2540  decode.d3.loss_cls: 0.1441  decode.d3.loss_mask: 0.2255  decode.d3.loss_dice: 0.2272  decode.d4.loss_cls: 0.1446  decode.d4.loss_mask: 0.2244  decode.d4.loss_dice: 0.2480  decode.d5.loss_cls: 0.1304  decode.d5.loss_mask: 0.2278  decode.d5.loss_dice: 0.2294  decode.d6.loss_cls: 0.1377  decode.d6.loss_mask: 0.2248  decode.d6.loss_dice: 0.2254  decode.d7.loss_cls: 0.1386  decode.d7.loss_mask: 0.2231  decode.d7.loss_dice: 0.2334  decode.d8.loss_cls: 0.1082  decode.d8.loss_mask: 0.2240  decode.d8.loss_dice: 0.2600
08/06 06:48:00 - mmengine - INFO - Iter(train) [ 33100/320000]  base_lr: 9.0641e-05 lr: 9.0641e-06  eta: 1 day, 15:10:31  time: 0.4924  data_time: 0.0112  memory: 5893  grad_norm: 311.7905  loss: 8.2840  decode.loss_cls: 0.1338  decode.loss_mask: 0.3513  decode.loss_dice: 0.2860  decode.d0.loss_cls: 0.9345  decode.d0.loss_mask: 0.3234  decode.d0.loss_dice: 0.2900  decode.d1.loss_cls: 0.1981  decode.d1.loss_mask: 0.3089  decode.d1.loss_dice: 0.2623  decode.d2.loss_cls: 0.1547  decode.d2.loss_mask: 0.3003  decode.d2.loss_dice: 0.2734  decode.d3.loss_cls: 0.1468  decode.d3.loss_mask: 0.3098  decode.d3.loss_dice: 0.2724  decode.d4.loss_cls: 0.1529  decode.d4.loss_mask: 0.3185  decode.d4.loss_dice: 0.2762  decode.d5.loss_cls: 0.1625  decode.d5.loss_mask: 0.3169  decode.d5.loss_dice: 0.2809  decode.d6.loss_cls: 0.1384  decode.d6.loss_mask: 0.3308  decode.d6.loss_dice: 0.2761  decode.d7.loss_cls: 0.1181  decode.d7.loss_mask: 0.3230  decode.d7.loss_dice: 0.2817  decode.d8.loss_cls: 0.1484  decode.d8.loss_mask: 0.3285  decode.d8.loss_dice: 0.2854
08/06 06:48:24 - mmengine - INFO - Iter(train) [ 33150/320000]  base_lr: 9.0627e-05 lr: 9.0627e-06  eta: 1 day, 15:10:07  time: 0.4929  data_time: 0.0109  memory: 5908  grad_norm: 85.2702  loss: 7.2229  decode.loss_cls: 0.1613  decode.loss_mask: 0.2304  decode.loss_dice: 0.2419  decode.d0.loss_cls: 0.9317  decode.d0.loss_mask: 0.2402  decode.d0.loss_dice: 0.2675  decode.d1.loss_cls: 0.1319  decode.d1.loss_mask: 0.2355  decode.d1.loss_dice: 0.2596  decode.d2.loss_cls: 0.2005  decode.d2.loss_mask: 0.2252  decode.d2.loss_dice: 0.2526  decode.d3.loss_cls: 0.1982  decode.d3.loss_mask: 0.2272  decode.d3.loss_dice: 0.2427  decode.d4.loss_cls: 0.1823  decode.d4.loss_mask: 0.2295  decode.d4.loss_dice: 0.2624  decode.d5.loss_cls: 0.1788  decode.d5.loss_mask: 0.2244  decode.d5.loss_dice: 0.2432  decode.d6.loss_cls: 0.1192  decode.d6.loss_mask: 0.2276  decode.d6.loss_dice: 0.2446  decode.d7.loss_cls: 0.1656  decode.d7.loss_mask: 0.2253  decode.d7.loss_dice: 0.2394  decode.d8.loss_cls: 0.1574  decode.d8.loss_mask: 0.2321  decode.d8.loss_dice: 0.2446
08/06 06:48:49 - mmengine - INFO - Iter(train) [ 33200/320000]  base_lr: 9.0612e-05 lr: 9.0612e-06  eta: 1 day, 15:09:43  time: 0.4923  data_time: 0.0110  memory: 5889  grad_norm: 111.3785  loss: 8.6684  decode.loss_cls: 0.3072  decode.loss_mask: 0.2680  decode.loss_dice: 0.2889  decode.d0.loss_cls: 0.8867  decode.d0.loss_mask: 0.2621  decode.d0.loss_dice: 0.2854  decode.d1.loss_cls: 0.2230  decode.d1.loss_mask: 0.2857  decode.d1.loss_dice: 0.2847  decode.d2.loss_cls: 0.1883  decode.d2.loss_mask: 0.2833  decode.d2.loss_dice: 0.2870  decode.d3.loss_cls: 0.2430  decode.d3.loss_mask: 0.2873  decode.d3.loss_dice: 0.2868  decode.d4.loss_cls: 0.1980  decode.d4.loss_mask: 0.2846  decode.d4.loss_dice: 0.2816  decode.d5.loss_cls: 0.2209  decode.d5.loss_mask: 0.2883  decode.d5.loss_dice: 0.2935  decode.d6.loss_cls: 0.2088  decode.d6.loss_mask: 0.2827  decode.d6.loss_dice: 0.2989  decode.d7.loss_cls: 0.2292  decode.d7.loss_mask: 0.2857  decode.d7.loss_dice: 0.3257  decode.d8.loss_cls: 0.2234  decode.d8.loss_mask: 0.2910  decode.d8.loss_dice: 0.2886
08/06 06:49:14 - mmengine - INFO - Iter(train) [ 33250/320000]  base_lr: 9.0598e-05 lr: 9.0598e-06  eta: 1 day, 15:09:21  time: 0.4931  data_time: 0.0109  memory: 5927  grad_norm: 61.6304  loss: 7.1389  decode.loss_cls: 0.0963  decode.loss_mask: 0.2429  decode.loss_dice: 0.2894  decode.d0.loss_cls: 0.8750  decode.d0.loss_mask: 0.2423  decode.d0.loss_dice: 0.2790  decode.d1.loss_cls: 0.1577  decode.d1.loss_mask: 0.2429  decode.d1.loss_dice: 0.2649  decode.d2.loss_cls: 0.1229  decode.d2.loss_mask: 0.2393  decode.d2.loss_dice: 0.2840  decode.d3.loss_cls: 0.1485  decode.d3.loss_mask: 0.2445  decode.d3.loss_dice: 0.2708  decode.d4.loss_cls: 0.1179  decode.d4.loss_mask: 0.2380  decode.d4.loss_dice: 0.2752  decode.d5.loss_cls: 0.1287  decode.d5.loss_mask: 0.2365  decode.d5.loss_dice: 0.2663  decode.d6.loss_cls: 0.1306  decode.d6.loss_mask: 0.2422  decode.d6.loss_dice: 0.2693  decode.d7.loss_cls: 0.0925  decode.d7.loss_mask: 0.2436  decode.d7.loss_dice: 0.2764  decode.d8.loss_cls: 0.0994  decode.d8.loss_mask: 0.2430  decode.d8.loss_dice: 0.2787
08/06 06:49:39 - mmengine - INFO - Iter(train) [ 33300/320000]  base_lr: 9.0584e-05 lr: 9.0584e-06  eta: 1 day, 15:08:57  time: 0.4926  data_time: 0.0109  memory: 5907  grad_norm: 135.3089  loss: 8.9071  decode.loss_cls: 0.2561  decode.loss_mask: 0.2488  decode.loss_dice: 0.3145  decode.d0.loss_cls: 1.0289  decode.d0.loss_mask: 0.2680  decode.d0.loss_dice: 0.3706  decode.d1.loss_cls: 0.2595  decode.d1.loss_mask: 0.2523  decode.d1.loss_dice: 0.3363  decode.d2.loss_cls: 0.2925  decode.d2.loss_mask: 0.2426  decode.d2.loss_dice: 0.3435  decode.d3.loss_cls: 0.2022  decode.d3.loss_mask: 0.2464  decode.d3.loss_dice: 0.3381  decode.d4.loss_cls: 0.1939  decode.d4.loss_mask: 0.2522  decode.d4.loss_dice: 0.3352  decode.d5.loss_cls: 0.2229  decode.d5.loss_mask: 0.2474  decode.d5.loss_dice: 0.3179  decode.d6.loss_cls: 0.1939  decode.d6.loss_mask: 0.2545  decode.d6.loss_dice: 0.3494  decode.d7.loss_cls: 0.1671  decode.d7.loss_mask: 0.2514  decode.d7.loss_dice: 0.3057  decode.d8.loss_cls: 0.2501  decode.d8.loss_mask: 0.2543  decode.d8.loss_dice: 0.3110
08/06 06:50:03 - mmengine - INFO - Iter(train) [ 33350/320000]  base_lr: 9.0570e-05 lr: 9.0570e-06  eta: 1 day, 15:08:32  time: 0.4932  data_time: 0.0111  memory: 5893  grad_norm: 107.8931  loss: 8.6733  decode.loss_cls: 0.1589  decode.loss_mask: 0.3182  decode.loss_dice: 0.2995  decode.d0.loss_cls: 1.0232  decode.d0.loss_mask: 0.3214  decode.d0.loss_dice: 0.3197  decode.d1.loss_cls: 0.2087  decode.d1.loss_mask: 0.3160  decode.d1.loss_dice: 0.2907  decode.d2.loss_cls: 0.2222  decode.d2.loss_mask: 0.3126  decode.d2.loss_dice: 0.2807  decode.d3.loss_cls: 0.1566  decode.d3.loss_mask: 0.3081  decode.d3.loss_dice: 0.2903  decode.d4.loss_cls: 0.1641  decode.d4.loss_mask: 0.3122  decode.d4.loss_dice: 0.2986  decode.d5.loss_cls: 0.1566  decode.d5.loss_mask: 0.3117  decode.d5.loss_dice: 0.2957  decode.d6.loss_cls: 0.1800  decode.d6.loss_mask: 0.3114  decode.d6.loss_dice: 0.2919  decode.d7.loss_cls: 0.1445  decode.d7.loss_mask: 0.3096  decode.d7.loss_dice: 0.2945  decode.d8.loss_cls: 0.1506  decode.d8.loss_mask: 0.3195  decode.d8.loss_dice: 0.3055
08/06 06:50:28 - mmengine - INFO - Iter(train) [ 33400/320000]  base_lr: 9.0555e-05 lr: 9.0555e-06  eta: 1 day, 15:08:09  time: 0.4921  data_time: 0.0111  memory: 5892  grad_norm: 163.2029  loss: 7.8755  decode.loss_cls: 0.1673  decode.loss_mask: 0.2615  decode.loss_dice: 0.2858  decode.d0.loss_cls: 0.9180  decode.d0.loss_mask: 0.2700  decode.d0.loss_dice: 0.2836  decode.d1.loss_cls: 0.2333  decode.d1.loss_mask: 0.2629  decode.d1.loss_dice: 0.2633  decode.d2.loss_cls: 0.1500  decode.d2.loss_mask: 0.2617  decode.d2.loss_dice: 0.2721  decode.d3.loss_cls: 0.1912  decode.d3.loss_mask: 0.2592  decode.d3.loss_dice: 0.2700  decode.d4.loss_cls: 0.1720  decode.d4.loss_mask: 0.2600  decode.d4.loss_dice: 0.2638  decode.d5.loss_cls: 0.2040  decode.d5.loss_mask: 0.2604  decode.d5.loss_dice: 0.2684  decode.d6.loss_cls: 0.1681  decode.d6.loss_mask: 0.2606  decode.d6.loss_dice: 0.2600  decode.d7.loss_cls: 0.1841  decode.d7.loss_mask: 0.2620  decode.d7.loss_dice: 0.2682  decode.d8.loss_cls: 0.1726  decode.d8.loss_mask: 0.2605  decode.d8.loss_dice: 0.2610
08/06 06:50:53 - mmengine - INFO - Iter(train) [ 33450/320000]  base_lr: 9.0541e-05 lr: 9.0541e-06  eta: 1 day, 15:07:44  time: 0.4927  data_time: 0.0109  memory: 5874  grad_norm: 364.0909  loss: 9.7479  decode.loss_cls: 0.2166  decode.loss_mask: 0.3551  decode.loss_dice: 0.3294  decode.d0.loss_cls: 0.7651  decode.d0.loss_mask: 0.3848  decode.d0.loss_dice: 0.3482  decode.d1.loss_cls: 0.2516  decode.d1.loss_mask: 0.3634  decode.d1.loss_dice: 0.3200  decode.d2.loss_cls: 0.1702  decode.d2.loss_mask: 0.3651  decode.d2.loss_dice: 0.3211  decode.d3.loss_cls: 0.2030  decode.d3.loss_mask: 0.3691  decode.d3.loss_dice: 0.3141  decode.d4.loss_cls: 0.1793  decode.d4.loss_mask: 0.3693  decode.d4.loss_dice: 0.3334  decode.d5.loss_cls: 0.2310  decode.d5.loss_mask: 0.3623  decode.d5.loss_dice: 0.3491  decode.d6.loss_cls: 0.2907  decode.d6.loss_mask: 0.3610  decode.d6.loss_dice: 0.3465  decode.d7.loss_cls: 0.2537  decode.d7.loss_mask: 0.3637  decode.d7.loss_dice: 0.3088  decode.d8.loss_cls: 0.1940  decode.d8.loss_mask: 0.3655  decode.d8.loss_dice: 0.3629
08/06 06:51:17 - mmengine - INFO - Iter(train) [ 33500/320000]  base_lr: 9.0527e-05 lr: 9.0527e-06  eta: 1 day, 15:07:20  time: 0.4927  data_time: 0.0108  memory: 5964  grad_norm: 114.4028  loss: 8.7165  decode.loss_cls: 0.0890  decode.loss_mask: 0.3486  decode.loss_dice: 0.3179  decode.d0.loss_cls: 0.9870  decode.d0.loss_mask: 0.3490  decode.d0.loss_dice: 0.3264  decode.d1.loss_cls: 0.1905  decode.d1.loss_mask: 0.3406  decode.d1.loss_dice: 0.3221  decode.d2.loss_cls: 0.1182  decode.d2.loss_mask: 0.3495  decode.d2.loss_dice: 0.3272  decode.d3.loss_cls: 0.1069  decode.d3.loss_mask: 0.3499  decode.d3.loss_dice: 0.3167  decode.d4.loss_cls: 0.2008  decode.d4.loss_mask: 0.3421  decode.d4.loss_dice: 0.3107  decode.d5.loss_cls: 0.0991  decode.d5.loss_mask: 0.3492  decode.d5.loss_dice: 0.3246  decode.d6.loss_cls: 0.0901  decode.d6.loss_mask: 0.3504  decode.d6.loss_dice: 0.3219  decode.d7.loss_cls: 0.0683  decode.d7.loss_mask: 0.3454  decode.d7.loss_dice: 0.3202  decode.d8.loss_cls: 0.0776  decode.d8.loss_mask: 0.3512  decode.d8.loss_dice: 0.3255
08/06 06:51:42 - mmengine - INFO - Iter(train) [ 33550/320000]  base_lr: 9.0513e-05 lr: 9.0513e-06  eta: 1 day, 15:06:56  time: 0.4931  data_time: 0.0111  memory: 5893  grad_norm: 192.6517  loss: 7.2668  decode.loss_cls: 0.1750  decode.loss_mask: 0.2272  decode.loss_dice: 0.2522  decode.d0.loss_cls: 1.0221  decode.d0.loss_mask: 0.2413  decode.d0.loss_dice: 0.2714  decode.d1.loss_cls: 0.1543  decode.d1.loss_mask: 0.2314  decode.d1.loss_dice: 0.2583  decode.d2.loss_cls: 0.1270  decode.d2.loss_mask: 0.2337  decode.d2.loss_dice: 0.2555  decode.d3.loss_cls: 0.1289  decode.d3.loss_mask: 0.2470  decode.d3.loss_dice: 0.2695  decode.d4.loss_cls: 0.1794  decode.d4.loss_mask: 0.2266  decode.d4.loss_dice: 0.2481  decode.d5.loss_cls: 0.1641  decode.d5.loss_mask: 0.2263  decode.d5.loss_dice: 0.2500  decode.d6.loss_cls: 0.1500  decode.d6.loss_mask: 0.2274  decode.d6.loss_dice: 0.2512  decode.d7.loss_cls: 0.1408  decode.d7.loss_mask: 0.2287  decode.d7.loss_dice: 0.2439  decode.d8.loss_cls: 0.1481  decode.d8.loss_mask: 0.2303  decode.d8.loss_dice: 0.2571
08/06 06:52:06 - mmengine - INFO - Iter(train) [ 33600/320000]  base_lr: 9.0499e-05 lr: 9.0499e-06  eta: 1 day, 15:06:32  time: 0.4917  data_time: 0.0110  memory: 5891  grad_norm: 109.2567  loss: 6.7165  decode.loss_cls: 0.0730  decode.loss_mask: 0.2637  decode.loss_dice: 0.2388  decode.d0.loss_cls: 0.9604  decode.d0.loss_mask: 0.2806  decode.d0.loss_dice: 0.2667  decode.d1.loss_cls: 0.0632  decode.d1.loss_mask: 0.2830  decode.d1.loss_dice: 0.2485  decode.d2.loss_cls: 0.0493  decode.d2.loss_mask: 0.2979  decode.d2.loss_dice: 0.2776  decode.d3.loss_cls: 0.0325  decode.d3.loss_mask: 0.2886  decode.d3.loss_dice: 0.2583  decode.d4.loss_cls: 0.0490  decode.d4.loss_mask: 0.2774  decode.d4.loss_dice: 0.2362  decode.d5.loss_cls: 0.0391  decode.d5.loss_mask: 0.2764  decode.d5.loss_dice: 0.2423  decode.d6.loss_cls: 0.0529  decode.d6.loss_mask: 0.2720  decode.d6.loss_dice: 0.2661  decode.d7.loss_cls: 0.0450  decode.d7.loss_mask: 0.2637  decode.d7.loss_dice: 0.2455  decode.d8.loss_cls: 0.0462  decode.d8.loss_mask: 0.2672  decode.d8.loss_dice: 0.2551
08/06 06:52:31 - mmengine - INFO - Iter(train) [ 33650/320000]  base_lr: 9.0484e-05 lr: 9.0484e-06  eta: 1 day, 15:06:08  time: 0.4921  data_time: 0.0112  memory: 5910  grad_norm: 150.4821  loss: 7.5181  decode.loss_cls: 0.0774  decode.loss_mask: 0.2950  decode.loss_dice: 0.3118  decode.d0.loss_cls: 0.7728  decode.d0.loss_mask: 0.2970  decode.d0.loss_dice: 0.3130  decode.d1.loss_cls: 0.0892  decode.d1.loss_mask: 0.2919  decode.d1.loss_dice: 0.3389  decode.d2.loss_cls: 0.0706  decode.d2.loss_mask: 0.2966  decode.d2.loss_dice: 0.3113  decode.d3.loss_cls: 0.0317  decode.d3.loss_mask: 0.2901  decode.d3.loss_dice: 0.3205  decode.d4.loss_cls: 0.0376  decode.d4.loss_mask: 0.2927  decode.d4.loss_dice: 0.3176  decode.d5.loss_cls: 0.0824  decode.d5.loss_mask: 0.2937  decode.d5.loss_dice: 0.3146  decode.d6.loss_cls: 0.0796  decode.d6.loss_mask: 0.2927  decode.d6.loss_dice: 0.3135  decode.d7.loss_cls: 0.0877  decode.d7.loss_mask: 0.2939  decode.d7.loss_dice: 0.3138  decode.d8.loss_cls: 0.0614  decode.d8.loss_mask: 0.2954  decode.d8.loss_dice: 0.3338
08/06 06:52:56 - mmengine - INFO - Iter(train) [ 33700/320000]  base_lr: 9.0470e-05 lr: 9.0470e-06  eta: 1 day, 15:05:44  time: 0.4949  data_time: 0.0114  memory: 5891  grad_norm: 221.7668  loss: 7.1015  decode.loss_cls: 0.0817  decode.loss_mask: 0.2701  decode.loss_dice: 0.2641  decode.d0.loss_cls: 0.8436  decode.d0.loss_mask: 0.2859  decode.d0.loss_dice: 0.2793  decode.d1.loss_cls: 0.0950  decode.d1.loss_mask: 0.2709  decode.d1.loss_dice: 0.2880  decode.d2.loss_cls: 0.1066  decode.d2.loss_mask: 0.2657  decode.d2.loss_dice: 0.2639  decode.d3.loss_cls: 0.1000  decode.d3.loss_mask: 0.2776  decode.d3.loss_dice: 0.2817  decode.d4.loss_cls: 0.0907  decode.d4.loss_mask: 0.2771  decode.d4.loss_dice: 0.2640  decode.d5.loss_cls: 0.0917  decode.d5.loss_mask: 0.2710  decode.d5.loss_dice: 0.2706  decode.d6.loss_cls: 0.0853  decode.d6.loss_mask: 0.2700  decode.d6.loss_dice: 0.2721  decode.d7.loss_cls: 0.0928  decode.d7.loss_mask: 0.2660  decode.d7.loss_dice: 0.2664  decode.d8.loss_cls: 0.0841  decode.d8.loss_mask: 0.2671  decode.d8.loss_dice: 0.2586
08/06 06:53:20 - mmengine - INFO - Iter(train) [ 33750/320000]  base_lr: 9.0456e-05 lr: 9.0456e-06  eta: 1 day, 15:05:20  time: 0.4931  data_time: 0.0111  memory: 5889  grad_norm: 127.2969  loss: 10.2826  decode.loss_cls: 0.1956  decode.loss_mask: 0.3466  decode.loss_dice: 0.3363  decode.d0.loss_cls: 1.0025  decode.d0.loss_mask: 0.3661  decode.d0.loss_dice: 0.4102  decode.d1.loss_cls: 0.2307  decode.d1.loss_mask: 0.3386  decode.d1.loss_dice: 0.3623  decode.d2.loss_cls: 0.2333  decode.d2.loss_mask: 0.3492  decode.d2.loss_dice: 0.3642  decode.d3.loss_cls: 0.2897  decode.d3.loss_mask: 0.3558  decode.d3.loss_dice: 0.3474  decode.d4.loss_cls: 0.2287  decode.d4.loss_mask: 0.3629  decode.d4.loss_dice: 0.3572  decode.d5.loss_cls: 0.2823  decode.d5.loss_mask: 0.3551  decode.d5.loss_dice: 0.3428  decode.d6.loss_cls: 0.2823  decode.d6.loss_mask: 0.3508  decode.d6.loss_dice: 0.3323  decode.d7.loss_cls: 0.2510  decode.d7.loss_mask: 0.3528  decode.d7.loss_dice: 0.3568  decode.d8.loss_cls: 0.1903  decode.d8.loss_mask: 0.3668  decode.d8.loss_dice: 0.3420
08/06 06:53:45 - mmengine - INFO - Iter(train) [ 33800/320000]  base_lr: 9.0442e-05 lr: 9.0442e-06  eta: 1 day, 15:04:56  time: 0.4930  data_time: 0.0109  memory: 5891  grad_norm: 114.1971  loss: 6.6290  decode.loss_cls: 0.0723  decode.loss_mask: 0.2359  decode.loss_dice: 0.2536  decode.d0.loss_cls: 0.9192  decode.d0.loss_mask: 0.2468  decode.d0.loss_dice: 0.2538  decode.d1.loss_cls: 0.0670  decode.d1.loss_mask: 0.2381  decode.d1.loss_dice: 0.2579  decode.d2.loss_cls: 0.0983  decode.d2.loss_mask: 0.2359  decode.d2.loss_dice: 0.2595  decode.d3.loss_cls: 0.1038  decode.d3.loss_mask: 0.2349  decode.d3.loss_dice: 0.2487  decode.d4.loss_cls: 0.1250  decode.d4.loss_mask: 0.2379  decode.d4.loss_dice: 0.2561  decode.d5.loss_cls: 0.0981  decode.d5.loss_mask: 0.2341  decode.d5.loss_dice: 0.2768  decode.d6.loss_cls: 0.0709  decode.d6.loss_mask: 0.2318  decode.d6.loss_dice: 0.2511  decode.d7.loss_cls: 0.0661  decode.d7.loss_mask: 0.2322  decode.d7.loss_dice: 0.2589  decode.d8.loss_cls: 0.0753  decode.d8.loss_mask: 0.2352  decode.d8.loss_dice: 0.2538
08/06 06:54:10 - mmengine - INFO - Iter(train) [ 33850/320000]  base_lr: 9.0428e-05 lr: 9.0428e-06  eta: 1 day, 15:04:33  time: 0.4924  data_time: 0.0112  memory: 5889  grad_norm: 182.5585  loss: 10.0766  decode.loss_cls: 0.1651  decode.loss_mask: 0.3536  decode.loss_dice: 0.3196  decode.d0.loss_cls: 1.0995  decode.d0.loss_mask: 0.3650  decode.d0.loss_dice: 0.3519  decode.d1.loss_cls: 0.2900  decode.d1.loss_mask: 0.3566  decode.d1.loss_dice: 0.3397  decode.d2.loss_cls: 0.2848  decode.d2.loss_mask: 0.3534  decode.d2.loss_dice: 0.3598  decode.d3.loss_cls: 0.2652  decode.d3.loss_mask: 0.3553  decode.d3.loss_dice: 0.3041  decode.d4.loss_cls: 0.2044  decode.d4.loss_mask: 0.3563  decode.d4.loss_dice: 0.3351  decode.d5.loss_cls: 0.2641  decode.d5.loss_mask: 0.3503  decode.d5.loss_dice: 0.2975  decode.d6.loss_cls: 0.2086  decode.d6.loss_mask: 0.3561  decode.d6.loss_dice: 0.3235  decode.d7.loss_cls: 0.2312  decode.d7.loss_mask: 0.3596  decode.d7.loss_dice: 0.3420  decode.d8.loss_cls: 0.2065  decode.d8.loss_mask: 0.3642  decode.d8.loss_dice: 0.3138
08/06 06:54:34 - mmengine - INFO - Iter(train) [ 33900/320000]  base_lr: 9.0413e-05 lr: 9.0413e-06  eta: 1 day, 15:04:09  time: 0.4932  data_time: 0.0110  memory: 5908  grad_norm: 55.1426  loss: 5.7590  decode.loss_cls: 0.0659  decode.loss_mask: 0.2045  decode.loss_dice: 0.2156  decode.d0.loss_cls: 0.8384  decode.d0.loss_mask: 0.2062  decode.d0.loss_dice: 0.2274  decode.d1.loss_cls: 0.0562  decode.d1.loss_mask: 0.2055  decode.d1.loss_dice: 0.2300  decode.d2.loss_cls: 0.1009  decode.d2.loss_mask: 0.2018  decode.d2.loss_dice: 0.2180  decode.d3.loss_cls: 0.0871  decode.d3.loss_mask: 0.2068  decode.d3.loss_dice: 0.2257  decode.d4.loss_cls: 0.0750  decode.d4.loss_mask: 0.2028  decode.d4.loss_dice: 0.2255  decode.d5.loss_cls: 0.0760  decode.d5.loss_mask: 0.2043  decode.d5.loss_dice: 0.2189  decode.d6.loss_cls: 0.0666  decode.d6.loss_mask: 0.2048  decode.d6.loss_dice: 0.2217  decode.d7.loss_cls: 0.0638  decode.d7.loss_mask: 0.2036  decode.d7.loss_dice: 0.2212  decode.d8.loss_cls: 0.0628  decode.d8.loss_mask: 0.2038  decode.d8.loss_dice: 0.2179
08/06 06:54:59 - mmengine - INFO - Iter(train) [ 33950/320000]  base_lr: 9.0399e-05 lr: 9.0399e-06  eta: 1 day, 15:03:45  time: 0.4934  data_time: 0.0111  memory: 5908  grad_norm: 128.6094  loss: 6.7794  decode.loss_cls: 0.1558  decode.loss_mask: 0.2338  decode.loss_dice: 0.2170  decode.d0.loss_cls: 0.8540  decode.d0.loss_mask: 0.2412  decode.d0.loss_dice: 0.2214  decode.d1.loss_cls: 0.1508  decode.d1.loss_mask: 0.2386  decode.d1.loss_dice: 0.2197  decode.d2.loss_cls: 0.1469  decode.d2.loss_mask: 0.2394  decode.d2.loss_dice: 0.2242  decode.d3.loss_cls: 0.1243  decode.d3.loss_mask: 0.2343  decode.d3.loss_dice: 0.2229  decode.d4.loss_cls: 0.1588  decode.d4.loss_mask: 0.2335  decode.d4.loss_dice: 0.2207  decode.d5.loss_cls: 0.1682  decode.d5.loss_mask: 0.2339  decode.d5.loss_dice: 0.2188  decode.d6.loss_cls: 0.1690  decode.d6.loss_mask: 0.2356  decode.d6.loss_dice: 0.2187  decode.d7.loss_cls: 0.1458  decode.d7.loss_mask: 0.2349  decode.d7.loss_dice: 0.2192  decode.d8.loss_cls: 0.1492  decode.d8.loss_mask: 0.2329  decode.d8.loss_dice: 0.2156
08/06 06:55:24 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 06:55:24 - mmengine - INFO - Iter(train) [ 34000/320000]  base_lr: 9.0385e-05 lr: 9.0385e-06  eta: 1 day, 15:03:21  time: 0.4926  data_time: 0.0109  memory: 5891  grad_norm: 52.6799  loss: 4.5823  decode.loss_cls: 0.0142  decode.loss_mask: 0.1720  decode.loss_dice: 0.1984  decode.d0.loss_cls: 0.7758  decode.d0.loss_mask: 0.1752  decode.d0.loss_dice: 0.2070  decode.d1.loss_cls: 0.0188  decode.d1.loss_mask: 0.1709  decode.d1.loss_dice: 0.1926  decode.d2.loss_cls: 0.0170  decode.d2.loss_mask: 0.1701  decode.d2.loss_dice: 0.1926  decode.d3.loss_cls: 0.0170  decode.d3.loss_mask: 0.1693  decode.d3.loss_dice: 0.1946  decode.d4.loss_cls: 0.0213  decode.d4.loss_mask: 0.1700  decode.d4.loss_dice: 0.1956  decode.d5.loss_cls: 0.0136  decode.d5.loss_mask: 0.1693  decode.d5.loss_dice: 0.1950  decode.d6.loss_cls: 0.0099  decode.d6.loss_mask: 0.1700  decode.d6.loss_dice: 0.1944  decode.d7.loss_cls: 0.0106  decode.d7.loss_mask: 0.1704  decode.d7.loss_dice: 0.1947  decode.d8.loss_cls: 0.0136  decode.d8.loss_mask: 0.1699  decode.d8.loss_dice: 0.1985
08/06 06:55:48 - mmengine - INFO - Iter(train) [ 34050/320000]  base_lr: 9.0371e-05 lr: 9.0371e-06  eta: 1 day, 15:02:57  time: 0.4913  data_time: 0.0109  memory: 5907  grad_norm: 128.2894  loss: 6.6765  decode.loss_cls: 0.1780  decode.loss_mask: 0.2335  decode.loss_dice: 0.2401  decode.d0.loss_cls: 0.7961  decode.d0.loss_mask: 0.2456  decode.d0.loss_dice: 0.2702  decode.d1.loss_cls: 0.2527  decode.d1.loss_mask: 0.2353  decode.d1.loss_dice: 0.2373  decode.d2.loss_cls: 0.0650  decode.d2.loss_mask: 0.2347  decode.d2.loss_dice: 0.2523  decode.d3.loss_cls: 0.0375  decode.d3.loss_mask: 0.2320  decode.d3.loss_dice: 0.2520  decode.d4.loss_cls: 0.1033  decode.d4.loss_mask: 0.2349  decode.d4.loss_dice: 0.2538  decode.d5.loss_cls: 0.0820  decode.d5.loss_mask: 0.2333  decode.d5.loss_dice: 0.2608  decode.d6.loss_cls: 0.1074  decode.d6.loss_mask: 0.2335  decode.d6.loss_dice: 0.2462  decode.d7.loss_cls: 0.0736  decode.d7.loss_mask: 0.2331  decode.d7.loss_dice: 0.2506  decode.d8.loss_cls: 0.1280  decode.d8.loss_mask: 0.2322  decode.d8.loss_dice: 0.2414
08/06 06:56:13 - mmengine - INFO - Iter(train) [ 34100/320000]  base_lr: 9.0356e-05 lr: 9.0356e-06  eta: 1 day, 15:02:33  time: 0.4924  data_time: 0.0108  memory: 5890  grad_norm: 123.6693  loss: 6.1991  decode.loss_cls: 0.0808  decode.loss_mask: 0.1773  decode.loss_dice: 0.3156  decode.d0.loss_cls: 0.8555  decode.d0.loss_mask: 0.1774  decode.d0.loss_dice: 0.3446  decode.d1.loss_cls: 0.0424  decode.d1.loss_mask: 0.1769  decode.d1.loss_dice: 0.2895  decode.d2.loss_cls: 0.0630  decode.d2.loss_mask: 0.1761  decode.d2.loss_dice: 0.2850  decode.d3.loss_cls: 0.0983  decode.d3.loss_mask: 0.1754  decode.d3.loss_dice: 0.2957  decode.d4.loss_cls: 0.0283  decode.d4.loss_mask: 0.1758  decode.d4.loss_dice: 0.2922  decode.d5.loss_cls: 0.0278  decode.d5.loss_mask: 0.1720  decode.d5.loss_dice: 0.2696  decode.d6.loss_cls: 0.0598  decode.d6.loss_mask: 0.1755  decode.d6.loss_dice: 0.2848  decode.d7.loss_cls: 0.0809  decode.d7.loss_mask: 0.1765  decode.d7.loss_dice: 0.3308  decode.d8.loss_cls: 0.0745  decode.d8.loss_mask: 0.1766  decode.d8.loss_dice: 0.3205
08/06 06:56:38 - mmengine - INFO - Iter(train) [ 34150/320000]  base_lr: 9.0342e-05 lr: 9.0342e-06  eta: 1 day, 15:02:08  time: 0.4919  data_time: 0.0109  memory: 5907  grad_norm: 82.4027  loss: 6.5287  decode.loss_cls: 0.1197  decode.loss_mask: 0.1916  decode.loss_dice: 0.2481  decode.d0.loss_cls: 0.9131  decode.d0.loss_mask: 0.2007  decode.d0.loss_dice: 0.2627  decode.d1.loss_cls: 0.2101  decode.d1.loss_mask: 0.1966  decode.d1.loss_dice: 0.2603  decode.d2.loss_cls: 0.1116  decode.d2.loss_mask: 0.1962  decode.d2.loss_dice: 0.2301  decode.d3.loss_cls: 0.1119  decode.d3.loss_mask: 0.1888  decode.d3.loss_dice: 0.2419  decode.d4.loss_cls: 0.1069  decode.d4.loss_mask: 0.1928  decode.d4.loss_dice: 0.2646  decode.d5.loss_cls: 0.0740  decode.d5.loss_mask: 0.1936  decode.d5.loss_dice: 0.2793  decode.d6.loss_cls: 0.1085  decode.d6.loss_mask: 0.1905  decode.d6.loss_dice: 0.2627  decode.d7.loss_cls: 0.1250  decode.d7.loss_mask: 0.1944  decode.d7.loss_dice: 0.2596  decode.d8.loss_cls: 0.1442  decode.d8.loss_mask: 0.1919  decode.d8.loss_dice: 0.2573
08/06 06:57:02 - mmengine - INFO - Iter(train) [ 34200/320000]  base_lr: 9.0328e-05 lr: 9.0328e-06  eta: 1 day, 15:01:44  time: 0.4923  data_time: 0.0112  memory: 5890  grad_norm: 101.3503  loss: 9.2776  decode.loss_cls: 0.2073  decode.loss_mask: 0.2824  decode.loss_dice: 0.3240  decode.d0.loss_cls: 0.7974  decode.d0.loss_mask: 0.2875  decode.d0.loss_dice: 0.3467  decode.d1.loss_cls: 0.3363  decode.d1.loss_mask: 0.2842  decode.d1.loss_dice: 0.3713  decode.d2.loss_cls: 0.2865  decode.d2.loss_mask: 0.2775  decode.d2.loss_dice: 0.3179  decode.d3.loss_cls: 0.2874  decode.d3.loss_mask: 0.2796  decode.d3.loss_dice: 0.3185  decode.d4.loss_cls: 0.2397  decode.d4.loss_mask: 0.2836  decode.d4.loss_dice: 0.3242  decode.d5.loss_cls: 0.2445  decode.d5.loss_mask: 0.2844  decode.d5.loss_dice: 0.3341  decode.d6.loss_cls: 0.2535  decode.d6.loss_mask: 0.2816  decode.d6.loss_dice: 0.3445  decode.d7.loss_cls: 0.2759  decode.d7.loss_mask: 0.2766  decode.d7.loss_dice: 0.3158  decode.d8.loss_cls: 0.2083  decode.d8.loss_mask: 0.2772  decode.d8.loss_dice: 0.3288
08/06 06:57:27 - mmengine - INFO - Iter(train) [ 34250/320000]  base_lr: 9.0314e-05 lr: 9.0314e-06  eta: 1 day, 15:01:20  time: 0.4928  data_time: 0.0113  memory: 5907  grad_norm: 94.5917  loss: 9.8518  decode.loss_cls: 0.1903  decode.loss_mask: 0.3013  decode.loss_dice: 0.3556  decode.d0.loss_cls: 1.1238  decode.d0.loss_mask: 0.3091  decode.d0.loss_dice: 0.3519  decode.d1.loss_cls: 0.3362  decode.d1.loss_mask: 0.3013  decode.d1.loss_dice: 0.3855  decode.d2.loss_cls: 0.2702  decode.d2.loss_mask: 0.2981  decode.d2.loss_dice: 0.3196  decode.d3.loss_cls: 0.1977  decode.d3.loss_mask: 0.3055  decode.d3.loss_dice: 0.3688  decode.d4.loss_cls: 0.2256  decode.d4.loss_mask: 0.2996  decode.d4.loss_dice: 0.3326  decode.d5.loss_cls: 0.2242  decode.d5.loss_mask: 0.3010  decode.d5.loss_dice: 0.3323  decode.d6.loss_cls: 0.2657  decode.d6.loss_mask: 0.2996  decode.d6.loss_dice: 0.3527  decode.d7.loss_cls: 0.2516  decode.d7.loss_mask: 0.3049  decode.d7.loss_dice: 0.3490  decode.d8.loss_cls: 0.2102  decode.d8.loss_mask: 0.3049  decode.d8.loss_dice: 0.3831
08/06 06:57:52 - mmengine - INFO - Iter(train) [ 34300/320000]  base_lr: 9.0300e-05 lr: 9.0300e-06  eta: 1 day, 15:00:56  time: 0.4929  data_time: 0.0111  memory: 5888  grad_norm: 76.8212  loss: 8.2673  decode.loss_cls: 0.1765  decode.loss_mask: 0.2243  decode.loss_dice: 0.3619  decode.d0.loss_cls: 0.9469  decode.d0.loss_mask: 0.2293  decode.d0.loss_dice: 0.3418  decode.d1.loss_cls: 0.1802  decode.d1.loss_mask: 0.2236  decode.d1.loss_dice: 0.3355  decode.d2.loss_cls: 0.1872  decode.d2.loss_mask: 0.2281  decode.d2.loss_dice: 0.3504  decode.d3.loss_cls: 0.1264  decode.d3.loss_mask: 0.2248  decode.d3.loss_dice: 0.3680  decode.d4.loss_cls: 0.1607  decode.d4.loss_mask: 0.2266  decode.d4.loss_dice: 0.3520  decode.d5.loss_cls: 0.1649  decode.d5.loss_mask: 0.2256  decode.d5.loss_dice: 0.3631  decode.d6.loss_cls: 0.1669  decode.d6.loss_mask: 0.2277  decode.d6.loss_dice: 0.3285  decode.d7.loss_cls: 0.2066  decode.d7.loss_mask: 0.2266  decode.d7.loss_dice: 0.3395  decode.d8.loss_cls: 0.1882  decode.d8.loss_mask: 0.2254  decode.d8.loss_dice: 0.3603
08/06 06:58:16 - mmengine - INFO - Iter(train) [ 34350/320000]  base_lr: 9.0285e-05 lr: 9.0285e-06  eta: 1 day, 15:00:33  time: 0.4935  data_time: 0.0111  memory: 5907  grad_norm: 84.2223  loss: 6.4843  decode.loss_cls: 0.0387  decode.loss_mask: 0.2259  decode.loss_dice: 0.2838  decode.d0.loss_cls: 0.8587  decode.d0.loss_mask: 0.2275  decode.d0.loss_dice: 0.3035  decode.d1.loss_cls: 0.1556  decode.d1.loss_mask: 0.2249  decode.d1.loss_dice: 0.2859  decode.d2.loss_cls: 0.0993  decode.d2.loss_mask: 0.2267  decode.d2.loss_dice: 0.3242  decode.d3.loss_cls: 0.0341  decode.d3.loss_mask: 0.2255  decode.d3.loss_dice: 0.2790  decode.d4.loss_cls: 0.0294  decode.d4.loss_mask: 0.2264  decode.d4.loss_dice: 0.2753  decode.d5.loss_cls: 0.0252  decode.d5.loss_mask: 0.2272  decode.d5.loss_dice: 0.2928  decode.d6.loss_cls: 0.0296  decode.d6.loss_mask: 0.2257  decode.d6.loss_dice: 0.2852  decode.d7.loss_cls: 0.0186  decode.d7.loss_mask: 0.2321  decode.d7.loss_dice: 0.2943  decode.d8.loss_cls: 0.0226  decode.d8.loss_mask: 0.2238  decode.d8.loss_dice: 0.2829
08/06 06:58:41 - mmengine - INFO - Iter(train) [ 34400/320000]  base_lr: 9.0271e-05 lr: 9.0271e-06  eta: 1 day, 15:00:09  time: 0.4933  data_time: 0.0111  memory: 5910  grad_norm: 91.8343  loss: 8.0377  decode.loss_cls: 0.1728  decode.loss_mask: 0.2472  decode.loss_dice: 0.2987  decode.d0.loss_cls: 0.9411  decode.d0.loss_mask: 0.2573  decode.d0.loss_dice: 0.3508  decode.d1.loss_cls: 0.2779  decode.d1.loss_mask: 0.2435  decode.d1.loss_dice: 0.2878  decode.d2.loss_cls: 0.1853  decode.d2.loss_mask: 0.2468  decode.d2.loss_dice: 0.2959  decode.d3.loss_cls: 0.1547  decode.d3.loss_mask: 0.2461  decode.d3.loss_dice: 0.2707  decode.d4.loss_cls: 0.1613  decode.d4.loss_mask: 0.2458  decode.d4.loss_dice: 0.2922  decode.d5.loss_cls: 0.1626  decode.d5.loss_mask: 0.2468  decode.d5.loss_dice: 0.3044  decode.d6.loss_cls: 0.1247  decode.d6.loss_mask: 0.2481  decode.d6.loss_dice: 0.3163  decode.d7.loss_cls: 0.1622  decode.d7.loss_mask: 0.2429  decode.d7.loss_dice: 0.3131  decode.d8.loss_cls: 0.1950  decode.d8.loss_mask: 0.2456  decode.d8.loss_dice: 0.3002
08/06 06:59:06 - mmengine - INFO - Iter(train) [ 34450/320000]  base_lr: 9.0257e-05 lr: 9.0257e-06  eta: 1 day, 14:59:45  time: 0.4930  data_time: 0.0111  memory: 5908  grad_norm: 117.5414  loss: 6.8638  decode.loss_cls: 0.1537  decode.loss_mask: 0.1999  decode.loss_dice: 0.2481  decode.d0.loss_cls: 0.9324  decode.d0.loss_mask: 0.2088  decode.d0.loss_dice: 0.2994  decode.d1.loss_cls: 0.1993  decode.d1.loss_mask: 0.2014  decode.d1.loss_dice: 0.2385  decode.d2.loss_cls: 0.1504  decode.d2.loss_mask: 0.1996  decode.d2.loss_dice: 0.2445  decode.d3.loss_cls: 0.1018  decode.d3.loss_mask: 0.1993  decode.d3.loss_dice: 0.2690  decode.d4.loss_cls: 0.1283  decode.d4.loss_mask: 0.2012  decode.d4.loss_dice: 0.2637  decode.d5.loss_cls: 0.1210  decode.d5.loss_mask: 0.1996  decode.d5.loss_dice: 0.2889  decode.d6.loss_cls: 0.1288  decode.d6.loss_mask: 0.1975  decode.d6.loss_dice: 0.2434  decode.d7.loss_cls: 0.1434  decode.d7.loss_mask: 0.2020  decode.d7.loss_dice: 0.2637  decode.d8.loss_cls: 0.1448  decode.d8.loss_mask: 0.2013  decode.d8.loss_dice: 0.2901
08/06 06:59:30 - mmengine - INFO - Iter(train) [ 34500/320000]  base_lr: 9.0243e-05 lr: 9.0243e-06  eta: 1 day, 14:59:20  time: 0.4928  data_time: 0.0110  memory: 5893  grad_norm: 171.9689  loss: 9.4238  decode.loss_cls: 0.2718  decode.loss_mask: 0.2928  decode.loss_dice: 0.3359  decode.d0.loss_cls: 1.0936  decode.d0.loss_mask: 0.3247  decode.d0.loss_dice: 0.3744  decode.d1.loss_cls: 0.2602  decode.d1.loss_mask: 0.2932  decode.d1.loss_dice: 0.3518  decode.d2.loss_cls: 0.2835  decode.d2.loss_mask: 0.2847  decode.d2.loss_dice: 0.3117  decode.d3.loss_cls: 0.2167  decode.d3.loss_mask: 0.2922  decode.d3.loss_dice: 0.3447  decode.d4.loss_cls: 0.1792  decode.d4.loss_mask: 0.2958  decode.d4.loss_dice: 0.3481  decode.d5.loss_cls: 0.2378  decode.d5.loss_mask: 0.2879  decode.d5.loss_dice: 0.2938  decode.d6.loss_cls: 0.1872  decode.d6.loss_mask: 0.3006  decode.d6.loss_dice: 0.3437  decode.d7.loss_cls: 0.2091  decode.d7.loss_mask: 0.2859  decode.d7.loss_dice: 0.3052  decode.d8.loss_cls: 0.2112  decode.d8.loss_mask: 0.2838  decode.d8.loss_dice: 0.3225
08/06 06:59:55 - mmengine - INFO - Iter(train) [ 34550/320000]  base_lr: 9.0228e-05 lr: 9.0228e-06  eta: 1 day, 14:58:56  time: 0.4924  data_time: 0.0108  memory: 5874  grad_norm: 179.6735  loss: 10.2989  decode.loss_cls: 0.2525  decode.loss_mask: 0.2780  decode.loss_dice: 0.3907  decode.d0.loss_cls: 1.0062  decode.d0.loss_mask: 0.2988  decode.d0.loss_dice: 0.3939  decode.d1.loss_cls: 0.3674  decode.d1.loss_mask: 0.2839  decode.d1.loss_dice: 0.3637  decode.d2.loss_cls: 0.3079  decode.d2.loss_mask: 0.2832  decode.d2.loss_dice: 0.3619  decode.d3.loss_cls: 0.2598  decode.d3.loss_mask: 0.2817  decode.d3.loss_dice: 0.3734  decode.d4.loss_cls: 0.3387  decode.d4.loss_mask: 0.2805  decode.d4.loss_dice: 0.3597  decode.d5.loss_cls: 0.3087  decode.d5.loss_mask: 0.2779  decode.d5.loss_dice: 0.3733  decode.d6.loss_cls: 0.3053  decode.d6.loss_mask: 0.2828  decode.d6.loss_dice: 0.3536  decode.d7.loss_cls: 0.3125  decode.d7.loss_mask: 0.2821  decode.d7.loss_dice: 0.3730  decode.d8.loss_cls: 0.3281  decode.d8.loss_mask: 0.2751  decode.d8.loss_dice: 0.3443
08/06 07:00:20 - mmengine - INFO - Iter(train) [ 34600/320000]  base_lr: 9.0214e-05 lr: 9.0214e-06  eta: 1 day, 14:58:32  time: 0.4929  data_time: 0.0111  memory: 5890  grad_norm: 147.4329  loss: 9.6758  decode.loss_cls: 0.1771  decode.loss_mask: 0.3655  decode.loss_dice: 0.3259  decode.d0.loss_cls: 0.8431  decode.d0.loss_mask: 0.3769  decode.d0.loss_dice: 0.3538  decode.d1.loss_cls: 0.2276  decode.d1.loss_mask: 0.3719  decode.d1.loss_dice: 0.3262  decode.d2.loss_cls: 0.2437  decode.d2.loss_mask: 0.3641  decode.d2.loss_dice: 0.3208  decode.d3.loss_cls: 0.2003  decode.d3.loss_mask: 0.3673  decode.d3.loss_dice: 0.3191  decode.d4.loss_cls: 0.2249  decode.d4.loss_mask: 0.3666  decode.d4.loss_dice: 0.3108  decode.d5.loss_cls: 0.2424  decode.d5.loss_mask: 0.3669  decode.d5.loss_dice: 0.3444  decode.d6.loss_cls: 0.1678  decode.d6.loss_mask: 0.3685  decode.d6.loss_dice: 0.3285  decode.d7.loss_cls: 0.2104  decode.d7.loss_mask: 0.3673  decode.d7.loss_dice: 0.3132  decode.d8.loss_cls: 0.1963  decode.d8.loss_mask: 0.3683  decode.d8.loss_dice: 0.3162
08/06 07:00:44 - mmengine - INFO - Iter(train) [ 34650/320000]  base_lr: 9.0200e-05 lr: 9.0200e-06  eta: 1 day, 14:58:10  time: 0.4936  data_time: 0.0110  memory: 5892  grad_norm: 90.5976  loss: 7.2317  decode.loss_cls: 0.0478  decode.loss_mask: 0.2840  decode.loss_dice: 0.2694  decode.d0.loss_cls: 0.9041  decode.d0.loss_mask: 0.2837  decode.d0.loss_dice: 0.2705  decode.d1.loss_cls: 0.1195  decode.d1.loss_mask: 0.2838  decode.d1.loss_dice: 0.2778  decode.d2.loss_cls: 0.1154  decode.d2.loss_mask: 0.2829  decode.d2.loss_dice: 0.2700  decode.d3.loss_cls: 0.0754  decode.d3.loss_mask: 0.2843  decode.d3.loss_dice: 0.2709  decode.d4.loss_cls: 0.0730  decode.d4.loss_mask: 0.2874  decode.d4.loss_dice: 0.2727  decode.d5.loss_cls: 0.0698  decode.d5.loss_mask: 0.2831  decode.d5.loss_dice: 0.2670  decode.d6.loss_cls: 0.1081  decode.d6.loss_mask: 0.2856  decode.d6.loss_dice: 0.2727  decode.d7.loss_cls: 0.1110  decode.d7.loss_mask: 0.2813  decode.d7.loss_dice: 0.2659  decode.d8.loss_cls: 0.0641  decode.d8.loss_mask: 0.2834  decode.d8.loss_dice: 0.2672
08/06 07:01:09 - mmengine - INFO - Iter(train) [ 34700/320000]  base_lr: 9.0186e-05 lr: 9.0186e-06  eta: 1 day, 14:57:46  time: 0.4929  data_time: 0.0111  memory: 5892  grad_norm: 99.4755  loss: 6.9619  decode.loss_cls: 0.0514  decode.loss_mask: 0.2502  decode.loss_dice: 0.2649  decode.d0.loss_cls: 0.8399  decode.d0.loss_mask: 0.2469  decode.d0.loss_dice: 0.2713  decode.d1.loss_cls: 0.1822  decode.d1.loss_mask: 0.2453  decode.d1.loss_dice: 0.2444  decode.d2.loss_cls: 0.1407  decode.d2.loss_mask: 0.2456  decode.d2.loss_dice: 0.2538  decode.d3.loss_cls: 0.1167  decode.d3.loss_mask: 0.2405  decode.d3.loss_dice: 0.2648  decode.d4.loss_cls: 0.1210  decode.d4.loss_mask: 0.2401  decode.d4.loss_dice: 0.2512  decode.d5.loss_cls: 0.1164  decode.d5.loss_mask: 0.2442  decode.d5.loss_dice: 0.2767  decode.d6.loss_cls: 0.0969  decode.d6.loss_mask: 0.2461  decode.d6.loss_dice: 0.2474  decode.d7.loss_cls: 0.1784  decode.d7.loss_mask: 0.2432  decode.d7.loss_dice: 0.2557  decode.d8.loss_cls: 0.0723  decode.d8.loss_mask: 0.2443  decode.d8.loss_dice: 0.2695
08/06 07:01:34 - mmengine - INFO - Iter(train) [ 34750/320000]  base_lr: 9.0172e-05 lr: 9.0172e-06  eta: 1 day, 14:57:22  time: 0.4926  data_time: 0.0111  memory: 5875  grad_norm: 102.9681  loss: 7.9472  decode.loss_cls: 0.2257  decode.loss_mask: 0.2226  decode.loss_dice: 0.2667  decode.d0.loss_cls: 0.8765  decode.d0.loss_mask: 0.2249  decode.d0.loss_dice: 0.2601  decode.d1.loss_cls: 0.2940  decode.d1.loss_mask: 0.2215  decode.d1.loss_dice: 0.2594  decode.d2.loss_cls: 0.2896  decode.d2.loss_mask: 0.2196  decode.d2.loss_dice: 0.2455  decode.d3.loss_cls: 0.2419  decode.d3.loss_mask: 0.2204  decode.d3.loss_dice: 0.2754  decode.d4.loss_cls: 0.2425  decode.d4.loss_mask: 0.2212  decode.d4.loss_dice: 0.2613  decode.d5.loss_cls: 0.2343  decode.d5.loss_mask: 0.2212  decode.d5.loss_dice: 0.2716  decode.d6.loss_cls: 0.2587  decode.d6.loss_mask: 0.2224  decode.d6.loss_dice: 0.2395  decode.d7.loss_cls: 0.2110  decode.d7.loss_mask: 0.2217  decode.d7.loss_dice: 0.2497  decode.d8.loss_cls: 0.2560  decode.d8.loss_mask: 0.2200  decode.d8.loss_dice: 0.2720
08/06 07:01:58 - mmengine - INFO - Iter(train) [ 34800/320000]  base_lr: 9.0157e-05 lr: 9.0157e-06  eta: 1 day, 14:56:58  time: 0.4931  data_time: 0.0111  memory: 5888  grad_norm: 182.4801  loss: 7.7680  decode.loss_cls: 0.0951  decode.loss_mask: 0.2902  decode.loss_dice: 0.3037  decode.d0.loss_cls: 0.7752  decode.d0.loss_mask: 0.3067  decode.d0.loss_dice: 0.3089  decode.d1.loss_cls: 0.1732  decode.d1.loss_mask: 0.2983  decode.d1.loss_dice: 0.3100  decode.d2.loss_cls: 0.1574  decode.d2.loss_mask: 0.2906  decode.d2.loss_dice: 0.3200  decode.d3.loss_cls: 0.0929  decode.d3.loss_mask: 0.2869  decode.d3.loss_dice: 0.3167  decode.d4.loss_cls: 0.1320  decode.d4.loss_mask: 0.2839  decode.d4.loss_dice: 0.3128  decode.d5.loss_cls: 0.1024  decode.d5.loss_mask: 0.2871  decode.d5.loss_dice: 0.3113  decode.d6.loss_cls: 0.0454  decode.d6.loss_mask: 0.2892  decode.d6.loss_dice: 0.3065  decode.d7.loss_cls: 0.0790  decode.d7.loss_mask: 0.2857  decode.d7.loss_dice: 0.3183  decode.d8.loss_cls: 0.0871  decode.d8.loss_mask: 0.2903  decode.d8.loss_dice: 0.3110
08/06 07:02:23 - mmengine - INFO - Iter(train) [ 34850/320000]  base_lr: 9.0143e-05 lr: 9.0143e-06  eta: 1 day, 14:56:34  time: 0.4941  data_time: 0.0110  memory: 5907  grad_norm: 178.9595  loss: 7.2396  decode.loss_cls: 0.2888  decode.loss_mask: 0.1922  decode.loss_dice: 0.2694  decode.d0.loss_cls: 0.8894  decode.d0.loss_mask: 0.1944  decode.d0.loss_dice: 0.2786  decode.d1.loss_cls: 0.2015  decode.d1.loss_mask: 0.1886  decode.d1.loss_dice: 0.2568  decode.d2.loss_cls: 0.1423  decode.d2.loss_mask: 0.1884  decode.d2.loss_dice: 0.2574  decode.d3.loss_cls: 0.0898  decode.d3.loss_mask: 0.1893  decode.d3.loss_dice: 0.2556  decode.d4.loss_cls: 0.1373  decode.d4.loss_mask: 0.2007  decode.d4.loss_dice: 0.2650  decode.d5.loss_cls: 0.2171  decode.d5.loss_mask: 0.1935  decode.d5.loss_dice: 0.2666  decode.d6.loss_cls: 0.1692  decode.d6.loss_mask: 0.1919  decode.d6.loss_dice: 0.2649  decode.d7.loss_cls: 0.3020  decode.d7.loss_mask: 0.1920  decode.d7.loss_dice: 0.2628  decode.d8.loss_cls: 0.2418  decode.d8.loss_mask: 0.1934  decode.d8.loss_dice: 0.2590
08/06 07:02:48 - mmengine - INFO - Iter(train) [ 34900/320000]  base_lr: 9.0129e-05 lr: 9.0129e-06  eta: 1 day, 14:56:10  time: 0.4935  data_time: 0.0111  memory: 5909  grad_norm: 147.5557  loss: 8.6925  decode.loss_cls: 0.1735  decode.loss_mask: 0.2720  decode.loss_dice: 0.3153  decode.d0.loss_cls: 1.1000  decode.d0.loss_mask: 0.2741  decode.d0.loss_dice: 0.3337  decode.d1.loss_cls: 0.3095  decode.d1.loss_mask: 0.2724  decode.d1.loss_dice: 0.3110  decode.d2.loss_cls: 0.2419  decode.d2.loss_mask: 0.2594  decode.d2.loss_dice: 0.2960  decode.d3.loss_cls: 0.2031  decode.d3.loss_mask: 0.2307  decode.d3.loss_dice: 0.3000  decode.d4.loss_cls: 0.2179  decode.d4.loss_mask: 0.2368  decode.d4.loss_dice: 0.3162  decode.d5.loss_cls: 0.1898  decode.d5.loss_mask: 0.2712  decode.d5.loss_dice: 0.2952  decode.d6.loss_cls: 0.1727  decode.d6.loss_mask: 0.2677  decode.d6.loss_dice: 0.2903  decode.d7.loss_cls: 0.1793  decode.d7.loss_mask: 0.2711  decode.d7.loss_dice: 0.2945  decode.d8.loss_cls: 0.1992  decode.d8.loss_mask: 0.2759  decode.d8.loss_dice: 0.3222
08/06 07:03:12 - mmengine - INFO - Iter(train) [ 34950/320000]  base_lr: 9.0115e-05 lr: 9.0115e-06  eta: 1 day, 14:55:46  time: 0.4935  data_time: 0.0110  memory: 5890  grad_norm: 49.4975  loss: 5.8281  decode.loss_cls: 0.0140  decode.loss_mask: 0.2637  decode.loss_dice: 0.2235  decode.d0.loss_cls: 0.7885  decode.d0.loss_mask: 0.2631  decode.d0.loss_dice: 0.2393  decode.d1.loss_cls: 0.0385  decode.d1.loss_mask: 0.2606  decode.d1.loss_dice: 0.2253  decode.d2.loss_cls: 0.0218  decode.d2.loss_mask: 0.2591  decode.d2.loss_dice: 0.2211  decode.d3.loss_cls: 0.0161  decode.d3.loss_mask: 0.2634  decode.d3.loss_dice: 0.2223  decode.d4.loss_cls: 0.0169  decode.d4.loss_mask: 0.2649  decode.d4.loss_dice: 0.2226  decode.d5.loss_cls: 0.0114  decode.d5.loss_mask: 0.2596  decode.d5.loss_dice: 0.2252  decode.d6.loss_cls: 0.0140  decode.d6.loss_mask: 0.2608  decode.d6.loss_dice: 0.2301  decode.d7.loss_cls: 0.0137  decode.d7.loss_mask: 0.2601  decode.d7.loss_dice: 0.2268  decode.d8.loss_cls: 0.0126  decode.d8.loss_mask: 0.2622  decode.d8.loss_dice: 0.2271
08/06 07:03:37 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 07:03:37 - mmengine - INFO - Iter(train) [ 35000/320000]  base_lr: 9.0100e-05 lr: 9.0100e-06  eta: 1 day, 14:55:22  time: 0.4931  data_time: 0.0111  memory: 5874  grad_norm: 156.0027  loss: 9.0039  decode.loss_cls: 0.1948  decode.loss_mask: 0.2925  decode.loss_dice: 0.3340  decode.d0.loss_cls: 0.9552  decode.d0.loss_mask: 0.2922  decode.d0.loss_dice: 0.3400  decode.d1.loss_cls: 0.2825  decode.d1.loss_mask: 0.3037  decode.d1.loss_dice: 0.3440  decode.d2.loss_cls: 0.1587  decode.d2.loss_mask: 0.2929  decode.d2.loss_dice: 0.3187  decode.d3.loss_cls: 0.1823  decode.d3.loss_mask: 0.2995  decode.d3.loss_dice: 0.3198  decode.d4.loss_cls: 0.1613  decode.d4.loss_mask: 0.3015  decode.d4.loss_dice: 0.3260  decode.d5.loss_cls: 0.1878  decode.d5.loss_mask: 0.2993  decode.d5.loss_dice: 0.3420  decode.d6.loss_cls: 0.1991  decode.d6.loss_mask: 0.2988  decode.d6.loss_dice: 0.3090  decode.d7.loss_cls: 0.2134  decode.d7.loss_mask: 0.2959  decode.d7.loss_dice: 0.3171  decode.d8.loss_cls: 0.2129  decode.d8.loss_mask: 0.2968  decode.d8.loss_dice: 0.3324
08/06 07:04:02 - mmengine - INFO - Iter(train) [ 35050/320000]  base_lr: 9.0086e-05 lr: 9.0086e-06  eta: 1 day, 14:54:58  time: 0.4930  data_time: 0.0111  memory: 5966  grad_norm: 60.8956  loss: 7.6327  decode.loss_cls: 0.1607  decode.loss_mask: 0.2254  decode.loss_dice: 0.2750  decode.d0.loss_cls: 0.8611  decode.d0.loss_mask: 0.2262  decode.d0.loss_dice: 0.3160  decode.d1.loss_cls: 0.1807  decode.d1.loss_mask: 0.2265  decode.d1.loss_dice: 0.2851  decode.d2.loss_cls: 0.1983  decode.d2.loss_mask: 0.2277  decode.d2.loss_dice: 0.2888  decode.d3.loss_cls: 0.1392  decode.d3.loss_mask: 0.2320  decode.d3.loss_dice: 0.2954  decode.d4.loss_cls: 0.1601  decode.d4.loss_mask: 0.2258  decode.d4.loss_dice: 0.2893  decode.d5.loss_cls: 0.2145  decode.d5.loss_mask: 0.2284  decode.d5.loss_dice: 0.2837  decode.d6.loss_cls: 0.1763  decode.d6.loss_mask: 0.2295  decode.d6.loss_dice: 0.2809  decode.d7.loss_cls: 0.1741  decode.d7.loss_mask: 0.2290  decode.d7.loss_dice: 0.3029  decode.d8.loss_cls: 0.1862  decode.d8.loss_mask: 0.2273  decode.d8.loss_dice: 0.2865
08/06 07:04:26 - mmengine - INFO - Iter(train) [ 35100/320000]  base_lr: 9.0072e-05 lr: 9.0072e-06  eta: 1 day, 14:54:34  time: 0.4926  data_time: 0.0110  memory: 5892  grad_norm: 234.4701  loss: 9.1706  decode.loss_cls: 0.1948  decode.loss_mask: 0.2920  decode.loss_dice: 0.3067  decode.d0.loss_cls: 0.9436  decode.d0.loss_mask: 0.3238  decode.d0.loss_dice: 0.3294  decode.d1.loss_cls: 0.2715  decode.d1.loss_mask: 0.3036  decode.d1.loss_dice: 0.3225  decode.d2.loss_cls: 0.2667  decode.d2.loss_mask: 0.2933  decode.d2.loss_dice: 0.2961  decode.d3.loss_cls: 0.2230  decode.d3.loss_mask: 0.2924  decode.d3.loss_dice: 0.3152  decode.d4.loss_cls: 0.1989  decode.d4.loss_mask: 0.2910  decode.d4.loss_dice: 0.3144  decode.d5.loss_cls: 0.2076  decode.d5.loss_mask: 0.2889  decode.d5.loss_dice: 0.3110  decode.d6.loss_cls: 0.2075  decode.d6.loss_mask: 0.2928  decode.d6.loss_dice: 0.3119  decode.d7.loss_cls: 0.2807  decode.d7.loss_mask: 0.2944  decode.d7.loss_dice: 0.3173  decode.d8.loss_cls: 0.2781  decode.d8.loss_mask: 0.2886  decode.d8.loss_dice: 0.3127
08/06 07:04:51 - mmengine - INFO - Iter(train) [ 35150/320000]  base_lr: 9.0058e-05 lr: 9.0058e-06  eta: 1 day, 14:54:11  time: 0.4933  data_time: 0.0110  memory: 5877  grad_norm: 100.7094  loss: 7.3652  decode.loss_cls: 0.1300  decode.loss_mask: 0.2756  decode.loss_dice: 0.2653  decode.d0.loss_cls: 0.9487  decode.d0.loss_mask: 0.2623  decode.d0.loss_dice: 0.2502  decode.d1.loss_cls: 0.2431  decode.d1.loss_mask: 0.2460  decode.d1.loss_dice: 0.2691  decode.d2.loss_cls: 0.1375  decode.d2.loss_mask: 0.2466  decode.d2.loss_dice: 0.2803  decode.d3.loss_cls: 0.1159  decode.d3.loss_mask: 0.2460  decode.d3.loss_dice: 0.2645  decode.d4.loss_cls: 0.1260  decode.d4.loss_mask: 0.2434  decode.d4.loss_dice: 0.2532  decode.d5.loss_cls: 0.1019  decode.d5.loss_mask: 0.2452  decode.d5.loss_dice: 0.2606  decode.d6.loss_cls: 0.1362  decode.d6.loss_mask: 0.2524  decode.d6.loss_dice: 0.2516  decode.d7.loss_cls: 0.1414  decode.d7.loss_mask: 0.2559  decode.d7.loss_dice: 0.2559  decode.d8.loss_cls: 0.1422  decode.d8.loss_mask: 0.2576  decode.d8.loss_dice: 0.2608
08/06 07:05:16 - mmengine - INFO - Iter(train) [ 35200/320000]  base_lr: 9.0043e-05 lr: 9.0043e-06  eta: 1 day, 14:53:47  time: 0.4939  data_time: 0.0112  memory: 5966  grad_norm: 109.6947  loss: 7.1153  decode.loss_cls: 0.1369  decode.loss_mask: 0.2163  decode.loss_dice: 0.2653  decode.d0.loss_cls: 1.0020  decode.d0.loss_mask: 0.2123  decode.d0.loss_dice: 0.2843  decode.d1.loss_cls: 0.0825  decode.d1.loss_mask: 0.2157  decode.d1.loss_dice: 0.2826  decode.d2.loss_cls: 0.1425  decode.d2.loss_mask: 0.2129  decode.d2.loss_dice: 0.2689  decode.d3.loss_cls: 0.1560  decode.d3.loss_mask: 0.2147  decode.d3.loss_dice: 0.2802  decode.d4.loss_cls: 0.1333  decode.d4.loss_mask: 0.2166  decode.d4.loss_dice: 0.2687  decode.d5.loss_cls: 0.1205  decode.d5.loss_mask: 0.2133  decode.d5.loss_dice: 0.2671  decode.d6.loss_cls: 0.1671  decode.d6.loss_mask: 0.2124  decode.d6.loss_dice: 0.2688  decode.d7.loss_cls: 0.1552  decode.d7.loss_mask: 0.2110  decode.d7.loss_dice: 0.2651  decode.d8.loss_cls: 0.1610  decode.d8.loss_mask: 0.2118  decode.d8.loss_dice: 0.2704
08/06 07:05:41 - mmengine - INFO - Iter(train) [ 35250/320000]  base_lr: 9.0029e-05 lr: 9.0029e-06  eta: 1 day, 14:53:24  time: 0.4930  data_time: 0.0111  memory: 5890  grad_norm: 136.0080  loss: 7.3282  decode.loss_cls: 0.1046  decode.loss_mask: 0.2588  decode.loss_dice: 0.2965  decode.d0.loss_cls: 0.8397  decode.d0.loss_mask: 0.2575  decode.d0.loss_dice: 0.2909  decode.d1.loss_cls: 0.0902  decode.d1.loss_mask: 0.2579  decode.d1.loss_dice: 0.3197  decode.d2.loss_cls: 0.1026  decode.d2.loss_mask: 0.2532  decode.d2.loss_dice: 0.3188  decode.d3.loss_cls: 0.1114  decode.d3.loss_mask: 0.2562  decode.d3.loss_dice: 0.2809  decode.d4.loss_cls: 0.0930  decode.d4.loss_mask: 0.2565  decode.d4.loss_dice: 0.3052  decode.d5.loss_cls: 0.1153  decode.d5.loss_mask: 0.2541  decode.d5.loss_dice: 0.3059  decode.d6.loss_cls: 0.1095  decode.d6.loss_mask: 0.2558  decode.d6.loss_dice: 0.3025  decode.d7.loss_cls: 0.0843  decode.d7.loss_mask: 0.2552  decode.d7.loss_dice: 0.2964  decode.d8.loss_cls: 0.0891  decode.d8.loss_mask: 0.2553  decode.d8.loss_dice: 0.3115
08/06 07:06:05 - mmengine - INFO - Iter(train) [ 35300/320000]  base_lr: 9.0015e-05 lr: 9.0015e-06  eta: 1 day, 14:53:00  time: 0.4931  data_time: 0.0111  memory: 5908  grad_norm: 118.0091  loss: 7.5876  decode.loss_cls: 0.1802  decode.loss_mask: 0.2074  decode.loss_dice: 0.2705  decode.d0.loss_cls: 0.8422  decode.d0.loss_mask: 0.2240  decode.d0.loss_dice: 0.2983  decode.d1.loss_cls: 0.2368  decode.d1.loss_mask: 0.2226  decode.d1.loss_dice: 0.2986  decode.d2.loss_cls: 0.1830  decode.d2.loss_mask: 0.2150  decode.d2.loss_dice: 0.2797  decode.d3.loss_cls: 0.1448  decode.d3.loss_mask: 0.2115  decode.d3.loss_dice: 0.2847  decode.d4.loss_cls: 0.2033  decode.d4.loss_mask: 0.2069  decode.d4.loss_dice: 0.2565  decode.d5.loss_cls: 0.2080  decode.d5.loss_mask: 0.2151  decode.d5.loss_dice: 0.2802  decode.d6.loss_cls: 0.2155  decode.d6.loss_mask: 0.2144  decode.d6.loss_dice: 0.2882  decode.d7.loss_cls: 0.1995  decode.d7.loss_mask: 0.2108  decode.d7.loss_dice: 0.2822  decode.d8.loss_cls: 0.2079  decode.d8.loss_mask: 0.2136  decode.d8.loss_dice: 0.2861
08/06 07:06:30 - mmengine - INFO - Iter(train) [ 35350/320000]  base_lr: 9.0001e-05 lr: 9.0001e-06  eta: 1 day, 14:52:36  time: 0.4934  data_time: 0.0109  memory: 5907  grad_norm: 74.6495  loss: 5.4131  decode.loss_cls: 0.0306  decode.loss_mask: 0.1973  decode.loss_dice: 0.2178  decode.d0.loss_cls: 0.9553  decode.d0.loss_mask: 0.2073  decode.d0.loss_dice: 0.2222  decode.d1.loss_cls: 0.0254  decode.d1.loss_mask: 0.2022  decode.d1.loss_dice: 0.2206  decode.d2.loss_cls: 0.0131  decode.d2.loss_mask: 0.1997  decode.d2.loss_dice: 0.2209  decode.d3.loss_cls: 0.0193  decode.d3.loss_mask: 0.1999  decode.d3.loss_dice: 0.2164  decode.d4.loss_cls: 0.0796  decode.d4.loss_mask: 0.1978  decode.d4.loss_dice: 0.2176  decode.d5.loss_cls: 0.0219  decode.d5.loss_mask: 0.1989  decode.d5.loss_dice: 0.2287  decode.d6.loss_cls: 0.0224  decode.d6.loss_mask: 0.1981  decode.d6.loss_dice: 0.2249  decode.d7.loss_cls: 0.0186  decode.d7.loss_mask: 0.2007  decode.d7.loss_dice: 0.2165  decode.d8.loss_cls: 0.0238  decode.d8.loss_mask: 0.1973  decode.d8.loss_dice: 0.2182
08/06 07:06:55 - mmengine - INFO - Iter(train) [ 35400/320000]  base_lr: 8.9987e-05 lr: 8.9987e-06  eta: 1 day, 14:52:12  time: 0.4926  data_time: 0.0109  memory: 5875  grad_norm: 107.8872  loss: 6.8526  decode.loss_cls: 0.1323  decode.loss_mask: 0.2079  decode.loss_dice: 0.2466  decode.d0.loss_cls: 0.9998  decode.d0.loss_mask: 0.1959  decode.d0.loss_dice: 0.2630  decode.d1.loss_cls: 0.1790  decode.d1.loss_mask: 0.2079  decode.d1.loss_dice: 0.2741  decode.d2.loss_cls: 0.1394  decode.d2.loss_mask: 0.1999  decode.d2.loss_dice: 0.2588  decode.d3.loss_cls: 0.1089  decode.d3.loss_mask: 0.2011  decode.d3.loss_dice: 0.2738  decode.d4.loss_cls: 0.1153  decode.d4.loss_mask: 0.2071  decode.d4.loss_dice: 0.2453  decode.d5.loss_cls: 0.1649  decode.d5.loss_mask: 0.2069  decode.d5.loss_dice: 0.2544  decode.d6.loss_cls: 0.1318  decode.d6.loss_mask: 0.2059  decode.d6.loss_dice: 0.2500  decode.d7.loss_cls: 0.1032  decode.d7.loss_mask: 0.2048  decode.d7.loss_dice: 0.2398  decode.d8.loss_cls: 0.1775  decode.d8.loss_mask: 0.2051  decode.d8.loss_dice: 0.2523
08/06 07:07:19 - mmengine - INFO - Iter(train) [ 35450/320000]  base_lr: 8.9972e-05 lr: 8.9972e-06  eta: 1 day, 14:51:48  time: 0.4932  data_time: 0.0110  memory: 5908  grad_norm: 286.3799  loss: 8.2366  decode.loss_cls: 0.1764  decode.loss_mask: 0.2856  decode.loss_dice: 0.3015  decode.d0.loss_cls: 0.8187  decode.d0.loss_mask: 0.3010  decode.d0.loss_dice: 0.3126  decode.d1.loss_cls: 0.1691  decode.d1.loss_mask: 0.2786  decode.d1.loss_dice: 0.2897  decode.d2.loss_cls: 0.0969  decode.d2.loss_mask: 0.2813  decode.d2.loss_dice: 0.2937  decode.d3.loss_cls: 0.1554  decode.d3.loss_mask: 0.2911  decode.d3.loss_dice: 0.3009  decode.d4.loss_cls: 0.1473  decode.d4.loss_mask: 0.2836  decode.d4.loss_dice: 0.2827  decode.d5.loss_cls: 0.1730  decode.d5.loss_mask: 0.2979  decode.d5.loss_dice: 0.3039  decode.d6.loss_cls: 0.1997  decode.d6.loss_mask: 0.3142  decode.d6.loss_dice: 0.3082  decode.d7.loss_cls: 0.2286  decode.d7.loss_mask: 0.2858  decode.d7.loss_dice: 0.2856  decode.d8.loss_cls: 0.1898  decode.d8.loss_mask: 0.2881  decode.d8.loss_dice: 0.2960
08/06 07:07:44 - mmengine - INFO - Iter(train) [ 35500/320000]  base_lr: 8.9958e-05 lr: 8.9958e-06  eta: 1 day, 14:51:24  time: 0.4929  data_time: 0.0110  memory: 5889  grad_norm: 132.7273  loss: 7.1662  decode.loss_cls: 0.0867  decode.loss_mask: 0.2251  decode.loss_dice: 0.2683  decode.d0.loss_cls: 0.9103  decode.d0.loss_mask: 0.2307  decode.d0.loss_dice: 0.2918  decode.d1.loss_cls: 0.2642  decode.d1.loss_mask: 0.2331  decode.d1.loss_dice: 0.2819  decode.d2.loss_cls: 0.1562  decode.d2.loss_mask: 0.2319  decode.d2.loss_dice: 0.2845  decode.d3.loss_cls: 0.1035  decode.d3.loss_mask: 0.2282  decode.d3.loss_dice: 0.2872  decode.d4.loss_cls: 0.1672  decode.d4.loss_mask: 0.2361  decode.d4.loss_dice: 0.2872  decode.d5.loss_cls: 0.0960  decode.d5.loss_mask: 0.2246  decode.d5.loss_dice: 0.2806  decode.d6.loss_cls: 0.0867  decode.d6.loss_mask: 0.2270  decode.d6.loss_dice: 0.2815  decode.d7.loss_cls: 0.0886  decode.d7.loss_mask: 0.2286  decode.d7.loss_dice: 0.2807  decode.d8.loss_cls: 0.0865  decode.d8.loss_mask: 0.2294  decode.d8.loss_dice: 0.2820
08/06 07:08:09 - mmengine - INFO - Iter(train) [ 35550/320000]  base_lr: 8.9944e-05 lr: 8.9944e-06  eta: 1 day, 14:51:00  time: 0.4929  data_time: 0.0111  memory: 5891  grad_norm: 256.2311  loss: 8.6487  decode.loss_cls: 0.2353  decode.loss_mask: 0.2294  decode.loss_dice: 0.3141  decode.d0.loss_cls: 0.9759  decode.d0.loss_mask: 0.2406  decode.d0.loss_dice: 0.3298  decode.d1.loss_cls: 0.2541  decode.d1.loss_mask: 0.2512  decode.d1.loss_dice: 0.3349  decode.d2.loss_cls: 0.1686  decode.d2.loss_mask: 0.2339  decode.d2.loss_dice: 0.3299  decode.d3.loss_cls: 0.1641  decode.d3.loss_mask: 0.2419  decode.d3.loss_dice: 0.3142  decode.d4.loss_cls: 0.2309  decode.d4.loss_mask: 0.2490  decode.d4.loss_dice: 0.3596  decode.d5.loss_cls: 0.2255  decode.d5.loss_mask: 0.2425  decode.d5.loss_dice: 0.3357  decode.d6.loss_cls: 0.2256  decode.d6.loss_mask: 0.2453  decode.d6.loss_dice: 0.3475  decode.d7.loss_cls: 0.2018  decode.d7.loss_mask: 0.2308  decode.d7.loss_dice: 0.3197  decode.d8.loss_cls: 0.2530  decode.d8.loss_mask: 0.2357  decode.d8.loss_dice: 0.3283
08/06 07:08:33 - mmengine - INFO - Iter(train) [ 35600/320000]  base_lr: 8.9930e-05 lr: 8.9930e-06  eta: 1 day, 14:50:36  time: 0.4931  data_time: 0.0112  memory: 5964  grad_norm: 94.4947  loss: 8.8889  decode.loss_cls: 0.2016  decode.loss_mask: 0.2718  decode.loss_dice: 0.3323  decode.d0.loss_cls: 0.8399  decode.d0.loss_mask: 0.2861  decode.d0.loss_dice: 0.3331  decode.d1.loss_cls: 0.2892  decode.d1.loss_mask: 0.2690  decode.d1.loss_dice: 0.3153  decode.d2.loss_cls: 0.2040  decode.d2.loss_mask: 0.2692  decode.d2.loss_dice: 0.3303  decode.d3.loss_cls: 0.2310  decode.d3.loss_mask: 0.2680  decode.d3.loss_dice: 0.3288  decode.d4.loss_cls: 0.2270  decode.d4.loss_mask: 0.2728  decode.d4.loss_dice: 0.3145  decode.d5.loss_cls: 0.2257  decode.d5.loss_mask: 0.2712  decode.d5.loss_dice: 0.3240  decode.d6.loss_cls: 0.1988  decode.d6.loss_mask: 0.2764  decode.d6.loss_dice: 0.3339  decode.d7.loss_cls: 0.2752  decode.d7.loss_mask: 0.2705  decode.d7.loss_dice: 0.3106  decode.d8.loss_cls: 0.2339  decode.d8.loss_mask: 0.2695  decode.d8.loss_dice: 0.3153
08/06 07:08:58 - mmengine - INFO - Iter(train) [ 35650/320000]  base_lr: 8.9915e-05 lr: 8.9915e-06  eta: 1 day, 14:50:12  time: 0.4921  data_time: 0.0108  memory: 5909  grad_norm: 93.2088  loss: 8.5493  decode.loss_cls: 0.2380  decode.loss_mask: 0.2542  decode.loss_dice: 0.2638  decode.d0.loss_cls: 0.9504  decode.d0.loss_mask: 0.2691  decode.d0.loss_dice: 0.3352  decode.d1.loss_cls: 0.2227  decode.d1.loss_mask: 0.2631  decode.d1.loss_dice: 0.3008  decode.d2.loss_cls: 0.2375  decode.d2.loss_mask: 0.2651  decode.d2.loss_dice: 0.3121  decode.d3.loss_cls: 0.2074  decode.d3.loss_mask: 0.2608  decode.d3.loss_dice: 0.3034  decode.d4.loss_cls: 0.2008  decode.d4.loss_mask: 0.2608  decode.d4.loss_dice: 0.2948  decode.d5.loss_cls: 0.1974  decode.d5.loss_mask: 0.2620  decode.d5.loss_dice: 0.3138  decode.d6.loss_cls: 0.2257  decode.d6.loss_mask: 0.2590  decode.d6.loss_dice: 0.2690  decode.d7.loss_cls: 0.1923  decode.d7.loss_mask: 0.2592  decode.d7.loss_dice: 0.3216  decode.d8.loss_cls: 0.2618  decode.d8.loss_mask: 0.2582  decode.d8.loss_dice: 0.2893
08/06 07:09:23 - mmengine - INFO - Iter(train) [ 35700/320000]  base_lr: 8.9901e-05 lr: 8.9901e-06  eta: 1 day, 14:49:48  time: 0.4936  data_time: 0.0112  memory: 5927  grad_norm: 110.2115  loss: 8.1875  decode.loss_cls: 0.2131  decode.loss_mask: 0.2557  decode.loss_dice: 0.2586  decode.d0.loss_cls: 0.7112  decode.d0.loss_mask: 0.2628  decode.d0.loss_dice: 0.2704  decode.d1.loss_cls: 0.2003  decode.d1.loss_mask: 0.2610  decode.d1.loss_dice: 0.2817  decode.d2.loss_cls: 0.2295  decode.d2.loss_mask: 0.2520  decode.d2.loss_dice: 0.2806  decode.d3.loss_cls: 0.3290  decode.d3.loss_mask: 0.2523  decode.d3.loss_dice: 0.2677  decode.d4.loss_cls: 0.2587  decode.d4.loss_mask: 0.2538  decode.d4.loss_dice: 0.2692  decode.d5.loss_cls: 0.2784  decode.d5.loss_mask: 0.2542  decode.d5.loss_dice: 0.2708  decode.d6.loss_cls: 0.2839  decode.d6.loss_mask: 0.2525  decode.d6.loss_dice: 0.2679  decode.d7.loss_cls: 0.2722  decode.d7.loss_mask: 0.2521  decode.d7.loss_dice: 0.2371  decode.d8.loss_cls: 0.2067  decode.d8.loss_mask: 0.2569  decode.d8.loss_dice: 0.2473
08/06 07:09:47 - mmengine - INFO - Iter(train) [ 35750/320000]  base_lr: 8.9887e-05 lr: 8.9887e-06  eta: 1 day, 14:49:25  time: 0.4953  data_time: 0.0109  memory: 5893  grad_norm: 124.2752  loss: 7.8328  decode.loss_cls: 0.1906  decode.loss_mask: 0.2328  decode.loss_dice: 0.2931  decode.d0.loss_cls: 0.9427  decode.d0.loss_mask: 0.2319  decode.d0.loss_dice: 0.2827  decode.d1.loss_cls: 0.1438  decode.d1.loss_mask: 0.2317  decode.d1.loss_dice: 0.3130  decode.d2.loss_cls: 0.1382  decode.d2.loss_mask: 0.2354  decode.d2.loss_dice: 0.3140  decode.d3.loss_cls: 0.1555  decode.d3.loss_mask: 0.2345  decode.d3.loss_dice: 0.3028  decode.d4.loss_cls: 0.1828  decode.d4.loss_mask: 0.2335  decode.d4.loss_dice: 0.3166  decode.d5.loss_cls: 0.1949  decode.d5.loss_mask: 0.2351  decode.d5.loss_dice: 0.2885  decode.d6.loss_cls: 0.1795  decode.d6.loss_mask: 0.2351  decode.d6.loss_dice: 0.2923  decode.d7.loss_cls: 0.1793  decode.d7.loss_mask: 0.2326  decode.d7.loss_dice: 0.3003  decode.d8.loss_cls: 0.1795  decode.d8.loss_mask: 0.2352  decode.d8.loss_dice: 0.3048
08/06 07:10:12 - mmengine - INFO - Iter(train) [ 35800/320000]  base_lr: 8.9873e-05 lr: 8.9873e-06  eta: 1 day, 14:49:03  time: 0.4958  data_time: 0.0112  memory: 5890  grad_norm: 111.8203  loss: 6.0328  decode.loss_cls: 0.0602  decode.loss_mask: 0.2066  decode.loss_dice: 0.2425  decode.d0.loss_cls: 0.9120  decode.d0.loss_mask: 0.2120  decode.d0.loss_dice: 0.2582  decode.d1.loss_cls: 0.1288  decode.d1.loss_mask: 0.2071  decode.d1.loss_dice: 0.2400  decode.d2.loss_cls: 0.0583  decode.d2.loss_mask: 0.2051  decode.d2.loss_dice: 0.2377  decode.d3.loss_cls: 0.0619  decode.d3.loss_mask: 0.2042  decode.d3.loss_dice: 0.2440  decode.d4.loss_cls: 0.0774  decode.d4.loss_mask: 0.2038  decode.d4.loss_dice: 0.2403  decode.d5.loss_cls: 0.0517  decode.d5.loss_mask: 0.2039  decode.d5.loss_dice: 0.2483  decode.d6.loss_cls: 0.0547  decode.d6.loss_mask: 0.2051  decode.d6.loss_dice: 0.2501  decode.d7.loss_cls: 0.0567  decode.d7.loss_mask: 0.2081  decode.d7.loss_dice: 0.2444  decode.d8.loss_cls: 0.0592  decode.d8.loss_mask: 0.2063  decode.d8.loss_dice: 0.2444
08/06 07:10:37 - mmengine - INFO - Iter(train) [ 35850/320000]  base_lr: 8.9858e-05 lr: 8.9858e-06  eta: 1 day, 14:48:40  time: 0.4955  data_time: 0.0112  memory: 5893  grad_norm: 200.8579  loss: 9.9598  decode.loss_cls: 0.3050  decode.loss_mask: 0.2527  decode.loss_dice: 0.3584  decode.d0.loss_cls: 1.1424  decode.d0.loss_mask: 0.2701  decode.d0.loss_dice: 0.3681  decode.d1.loss_cls: 0.4105  decode.d1.loss_mask: 0.2597  decode.d1.loss_dice: 0.3398  decode.d2.loss_cls: 0.3728  decode.d2.loss_mask: 0.2630  decode.d2.loss_dice: 0.3426  decode.d3.loss_cls: 0.2834  decode.d3.loss_mask: 0.2603  decode.d3.loss_dice: 0.3412  decode.d4.loss_cls: 0.2904  decode.d4.loss_mask: 0.2601  decode.d4.loss_dice: 0.3458  decode.d5.loss_cls: 0.3005  decode.d5.loss_mask: 0.2600  decode.d5.loss_dice: 0.3443  decode.d6.loss_cls: 0.2750  decode.d6.loss_mask: 0.2597  decode.d6.loss_dice: 0.3039  decode.d7.loss_cls: 0.2644  decode.d7.loss_mask: 0.2582  decode.d7.loss_dice: 0.3483  decode.d8.loss_cls: 0.2999  decode.d8.loss_mask: 0.2544  decode.d8.loss_dice: 0.3251
08/06 07:11:02 - mmengine - INFO - Iter(train) [ 35900/320000]  base_lr: 8.9844e-05 lr: 8.9844e-06  eta: 1 day, 14:48:17  time: 0.4958  data_time: 0.0112  memory: 5929  grad_norm: 79.5363  loss: 7.8718  decode.loss_cls: 0.1365  decode.loss_mask: 0.2394  decode.loss_dice: 0.3475  decode.d0.loss_cls: 0.8937  decode.d0.loss_mask: 0.2445  decode.d0.loss_dice: 0.3640  decode.d1.loss_cls: 0.1703  decode.d1.loss_mask: 0.2501  decode.d1.loss_dice: 0.3623  decode.d2.loss_cls: 0.1000  decode.d2.loss_mask: 0.2445  decode.d2.loss_dice: 0.3498  decode.d3.loss_cls: 0.0756  decode.d3.loss_mask: 0.2388  decode.d3.loss_dice: 0.3446  decode.d4.loss_cls: 0.0886  decode.d4.loss_mask: 0.2411  decode.d4.loss_dice: 0.3616  decode.d5.loss_cls: 0.1199  decode.d5.loss_mask: 0.2326  decode.d5.loss_dice: 0.3532  decode.d6.loss_cls: 0.1199  decode.d6.loss_mask: 0.2334  decode.d6.loss_dice: 0.3460  decode.d7.loss_cls: 0.1434  decode.d7.loss_mask: 0.2383  decode.d7.loss_dice: 0.3533  decode.d8.loss_cls: 0.0817  decode.d8.loss_mask: 0.2463  decode.d8.loss_dice: 0.3512
08/06 07:11:27 - mmengine - INFO - Iter(train) [ 35950/320000]  base_lr: 8.9830e-05 lr: 8.9830e-06  eta: 1 day, 14:47:53  time: 0.4946  data_time: 0.0110  memory: 5908  grad_norm: 76.3317  loss: 7.3404  decode.loss_cls: 0.0668  decode.loss_mask: 0.2667  decode.loss_dice: 0.3021  decode.d0.loss_cls: 0.8365  decode.d0.loss_mask: 0.2623  decode.d0.loss_dice: 0.3100  decode.d1.loss_cls: 0.1231  decode.d1.loss_mask: 0.2639  decode.d1.loss_dice: 0.3051  decode.d2.loss_cls: 0.0886  decode.d2.loss_mask: 0.2627  decode.d2.loss_dice: 0.2986  decode.d3.loss_cls: 0.0818  decode.d3.loss_mask: 0.2648  decode.d3.loss_dice: 0.3087  decode.d4.loss_cls: 0.1234  decode.d4.loss_mask: 0.2675  decode.d4.loss_dice: 0.2991  decode.d5.loss_cls: 0.0824  decode.d5.loss_mask: 0.2678  decode.d5.loss_dice: 0.3079  decode.d6.loss_cls: 0.0746  decode.d6.loss_mask: 0.2648  decode.d6.loss_dice: 0.3040  decode.d7.loss_cls: 0.0801  decode.d7.loss_mask: 0.2635  decode.d7.loss_dice: 0.3062  decode.d8.loss_cls: 0.0918  decode.d8.loss_mask: 0.2663  decode.d8.loss_dice: 0.2992
08/06 07:11:51 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 07:11:51 - mmengine - INFO - Iter(train) [ 36000/320000]  base_lr: 8.9816e-05 lr: 8.9816e-06  eta: 1 day, 14:47:30  time: 0.4958  data_time: 0.0112  memory: 5893  grad_norm: 155.6863  loss: 8.0929  decode.loss_cls: 0.1242  decode.loss_mask: 0.2582  decode.loss_dice: 0.2984  decode.d0.loss_cls: 0.8835  decode.d0.loss_mask: 0.2733  decode.d0.loss_dice: 0.3726  decode.d1.loss_cls: 0.1915  decode.d1.loss_mask: 0.2581  decode.d1.loss_dice: 0.3238  decode.d2.loss_cls: 0.1951  decode.d2.loss_mask: 0.2613  decode.d2.loss_dice: 0.3127  decode.d3.loss_cls: 0.1994  decode.d3.loss_mask: 0.2605  decode.d3.loss_dice: 0.3231  decode.d4.loss_cls: 0.1934  decode.d4.loss_mask: 0.2601  decode.d4.loss_dice: 0.3198  decode.d5.loss_cls: 0.1385  decode.d5.loss_mask: 0.2583  decode.d5.loss_dice: 0.3150  decode.d6.loss_cls: 0.1274  decode.d6.loss_mask: 0.2589  decode.d6.loss_dice: 0.3122  decode.d7.loss_cls: 0.1195  decode.d7.loss_mask: 0.2576  decode.d7.loss_dice: 0.3037  decode.d8.loss_cls: 0.1261  decode.d8.loss_mask: 0.2574  decode.d8.loss_dice: 0.3092
08/06 07:12:16 - mmengine - INFO - Iter(train) [ 36050/320000]  base_lr: 8.9802e-05 lr: 8.9802e-06  eta: 1 day, 14:47:07  time: 0.4962  data_time: 0.0114  memory: 5908  grad_norm: 179.1010  loss: 10.1107  decode.loss_cls: 0.2660  decode.loss_mask: 0.3071  decode.loss_dice: 0.3253  decode.d0.loss_cls: 1.0237  decode.d0.loss_mask: 0.3213  decode.d0.loss_dice: 0.3937  decode.d1.loss_cls: 0.2734  decode.d1.loss_mask: 0.3158  decode.d1.loss_dice: 0.3684  decode.d2.loss_cls: 0.2477  decode.d2.loss_mask: 0.3080  decode.d2.loss_dice: 0.3580  decode.d3.loss_cls: 0.2998  decode.d3.loss_mask: 0.3126  decode.d3.loss_dice: 0.3360  decode.d4.loss_cls: 0.3104  decode.d4.loss_mask: 0.3075  decode.d4.loss_dice: 0.3248  decode.d5.loss_cls: 0.3217  decode.d5.loss_mask: 0.3054  decode.d5.loss_dice: 0.3224  decode.d6.loss_cls: 0.2709  decode.d6.loss_mask: 0.3097  decode.d6.loss_dice: 0.3355  decode.d7.loss_cls: 0.2737  decode.d7.loss_mask: 0.3069  decode.d7.loss_dice: 0.3362  decode.d8.loss_cls: 0.2834  decode.d8.loss_mask: 0.3077  decode.d8.loss_dice: 0.3376
08/06 07:12:41 - mmengine - INFO - Iter(train) [ 36100/320000]  base_lr: 8.9787e-05 lr: 8.9787e-06  eta: 1 day, 14:46:45  time: 0.4908  data_time: 0.0110  memory: 5890  grad_norm: 153.0067  loss: 9.7701  decode.loss_cls: 0.2429  decode.loss_mask: 0.2893  decode.loss_dice: 0.3736  decode.d0.loss_cls: 0.9207  decode.d0.loss_mask: 0.2789  decode.d0.loss_dice: 0.3663  decode.d1.loss_cls: 0.2490  decode.d1.loss_mask: 0.2784  decode.d1.loss_dice: 0.3824  decode.d2.loss_cls: 0.2240  decode.d2.loss_mask: 0.2757  decode.d2.loss_dice: 0.3584  decode.d3.loss_cls: 0.2510  decode.d3.loss_mask: 0.2899  decode.d3.loss_dice: 0.3671  decode.d4.loss_cls: 0.2398  decode.d4.loss_mask: 0.2913  decode.d4.loss_dice: 0.3810  decode.d5.loss_cls: 0.2864  decode.d5.loss_mask: 0.2731  decode.d5.loss_dice: 0.3558  decode.d6.loss_cls: 0.2510  decode.d6.loss_mask: 0.2843  decode.d6.loss_dice: 0.3840  decode.d7.loss_cls: 0.2699  decode.d7.loss_mask: 0.2992  decode.d7.loss_dice: 0.3849  decode.d8.loss_cls: 0.2671  decode.d8.loss_mask: 0.2815  decode.d8.loss_dice: 0.3733
08/06 07:13:06 - mmengine - INFO - Iter(train) [ 36150/320000]  base_lr: 8.9773e-05 lr: 8.9773e-06  eta: 1 day, 14:46:21  time: 0.4942  data_time: 0.0113  memory: 5907  grad_norm: 251.4618  loss: 9.3990  decode.loss_cls: 0.1855  decode.loss_mask: 0.3029  decode.loss_dice: 0.3482  decode.d0.loss_cls: 0.8241  decode.d0.loss_mask: 0.3063  decode.d0.loss_dice: 0.3919  decode.d1.loss_cls: 0.2199  decode.d1.loss_mask: 0.3030  decode.d1.loss_dice: 0.3889  decode.d2.loss_cls: 0.1732  decode.d2.loss_mask: 0.2982  decode.d2.loss_dice: 0.3751  decode.d3.loss_cls: 0.2286  decode.d3.loss_mask: 0.3034  decode.d3.loss_dice: 0.3690  decode.d4.loss_cls: 0.1737  decode.d4.loss_mask: 0.2966  decode.d4.loss_dice: 0.3730  decode.d5.loss_cls: 0.2102  decode.d5.loss_mask: 0.2972  decode.d5.loss_dice: 0.3467  decode.d6.loss_cls: 0.2010  decode.d6.loss_mask: 0.2968  decode.d6.loss_dice: 0.3875  decode.d7.loss_cls: 0.2039  decode.d7.loss_mask: 0.2992  decode.d7.loss_dice: 0.3910  decode.d8.loss_cls: 0.2093  decode.d8.loss_mask: 0.3033  decode.d8.loss_dice: 0.3915
08/06 07:13:30 - mmengine - INFO - Iter(train) [ 36200/320000]  base_lr: 8.9759e-05 lr: 8.9759e-06  eta: 1 day, 14:45:58  time: 0.4936  data_time: 0.0110  memory: 5892  grad_norm: 89.0007  loss: 7.7479  decode.loss_cls: 0.1944  decode.loss_mask: 0.2927  decode.loss_dice: 0.2427  decode.d0.loss_cls: 0.9371  decode.d0.loss_mask: 0.2790  decode.d0.loss_dice: 0.2568  decode.d1.loss_cls: 0.1868  decode.d1.loss_mask: 0.2444  decode.d1.loss_dice: 0.2346  decode.d2.loss_cls: 0.2085  decode.d2.loss_mask: 0.2566  decode.d2.loss_dice: 0.2521  decode.d3.loss_cls: 0.1947  decode.d3.loss_mask: 0.2856  decode.d3.loss_dice: 0.2692  decode.d4.loss_cls: 0.2171  decode.d4.loss_mask: 0.2552  decode.d4.loss_dice: 0.2236  decode.d5.loss_cls: 0.1905  decode.d5.loss_mask: 0.2554  decode.d5.loss_dice: 0.2202  decode.d6.loss_cls: 0.1951  decode.d6.loss_mask: 0.2487  decode.d6.loss_dice: 0.2183  decode.d7.loss_cls: 0.1955  decode.d7.loss_mask: 0.2633  decode.d7.loss_dice: 0.2428  decode.d8.loss_cls: 0.2029  decode.d8.loss_mask: 0.2516  decode.d8.loss_dice: 0.2323
08/06 07:13:55 - mmengine - INFO - Iter(train) [ 36250/320000]  base_lr: 8.9745e-05 lr: 8.9745e-06  eta: 1 day, 14:45:34  time: 0.4943  data_time: 0.0111  memory: 5891  grad_norm: 64.1890  loss: 9.3171  decode.loss_cls: 0.2988  decode.loss_mask: 0.2342  decode.loss_dice: 0.3057  decode.d0.loss_cls: 1.0724  decode.d0.loss_mask: 0.2417  decode.d0.loss_dice: 0.3186  decode.d1.loss_cls: 0.4584  decode.d1.loss_mask: 0.2330  decode.d1.loss_dice: 0.2730  decode.d2.loss_cls: 0.2863  decode.d2.loss_mask: 0.2338  decode.d2.loss_dice: 0.3091  decode.d3.loss_cls: 0.3550  decode.d3.loss_mask: 0.2338  decode.d3.loss_dice: 0.3041  decode.d4.loss_cls: 0.3270  decode.d4.loss_mask: 0.2330  decode.d4.loss_dice: 0.2901  decode.d5.loss_cls: 0.3048  decode.d5.loss_mask: 0.2319  decode.d5.loss_dice: 0.2960  decode.d6.loss_cls: 0.2768  decode.d6.loss_mask: 0.2326  decode.d6.loss_dice: 0.3072  decode.d7.loss_cls: 0.2889  decode.d7.loss_mask: 0.2347  decode.d7.loss_dice: 0.3084  decode.d8.loss_cls: 0.2724  decode.d8.loss_mask: 0.2349  decode.d8.loss_dice: 0.3205
08/06 07:14:20 - mmengine - INFO - Iter(train) [ 36300/320000]  base_lr: 8.9730e-05 lr: 8.9730e-06  eta: 1 day, 14:45:10  time: 0.4927  data_time: 0.0109  memory: 5876  grad_norm: 138.4315  loss: 6.0553  decode.loss_cls: 0.0555  decode.loss_mask: 0.2208  decode.loss_dice: 0.2324  decode.d0.loss_cls: 0.9053  decode.d0.loss_mask: 0.2174  decode.d0.loss_dice: 0.2183  decode.d1.loss_cls: 0.1418  decode.d1.loss_mask: 0.2223  decode.d1.loss_dice: 0.2424  decode.d2.loss_cls: 0.0612  decode.d2.loss_mask: 0.2256  decode.d2.loss_dice: 0.2398  decode.d3.loss_cls: 0.0851  decode.d3.loss_mask: 0.2194  decode.d3.loss_dice: 0.2288  decode.d4.loss_cls: 0.0558  decode.d4.loss_mask: 0.2188  decode.d4.loss_dice: 0.2295  decode.d5.loss_cls: 0.0432  decode.d5.loss_mask: 0.2198  decode.d5.loss_dice: 0.2341  decode.d6.loss_cls: 0.0677  decode.d6.loss_mask: 0.2180  decode.d6.loss_dice: 0.2224  decode.d7.loss_cls: 0.0622  decode.d7.loss_mask: 0.2201  decode.d7.loss_dice: 0.2341  decode.d8.loss_cls: 0.0536  decode.d8.loss_mask: 0.2187  decode.d8.loss_dice: 0.2412
08/06 07:14:45 - mmengine - INFO - Iter(train) [ 36350/320000]  base_lr: 8.9716e-05 lr: 8.9716e-06  eta: 1 day, 14:44:46  time: 0.4935  data_time: 0.0110  memory: 5874  grad_norm: 207.6065  loss: 7.1838  decode.loss_cls: 0.1868  decode.loss_mask: 0.2094  decode.loss_dice: 0.2200  decode.d0.loss_cls: 0.8779  decode.d0.loss_mask: 0.2184  decode.d0.loss_dice: 0.2274  decode.d1.loss_cls: 0.2436  decode.d1.loss_mask: 0.2151  decode.d1.loss_dice: 0.2370  decode.d2.loss_cls: 0.2073  decode.d2.loss_mask: 0.2167  decode.d2.loss_dice: 0.2335  decode.d3.loss_cls: 0.2490  decode.d3.loss_mask: 0.2143  decode.d3.loss_dice: 0.2271  decode.d4.loss_cls: 0.1710  decode.d4.loss_mask: 0.2139  decode.d4.loss_dice: 0.2302  decode.d5.loss_cls: 0.2297  decode.d5.loss_mask: 0.2124  decode.d5.loss_dice: 0.2310  decode.d6.loss_cls: 0.1793  decode.d6.loss_mask: 0.2155  decode.d6.loss_dice: 0.2309  decode.d7.loss_cls: 0.2083  decode.d7.loss_mask: 0.2120  decode.d7.loss_dice: 0.2272  decode.d8.loss_cls: 0.2058  decode.d8.loss_mask: 0.2109  decode.d8.loss_dice: 0.2222
08/06 07:15:09 - mmengine - INFO - Iter(train) [ 36400/320000]  base_lr: 8.9702e-05 lr: 8.9702e-06  eta: 1 day, 14:44:23  time: 0.4946  data_time: 0.0113  memory: 5889  grad_norm: 360.7168  loss: 6.9715  decode.loss_cls: 0.0666  decode.loss_mask: 0.2621  decode.loss_dice: 0.2409  decode.d0.loss_cls: 0.8506  decode.d0.loss_mask: 0.2730  decode.d0.loss_dice: 0.2490  decode.d1.loss_cls: 0.1589  decode.d1.loss_mask: 0.2651  decode.d1.loss_dice: 0.2590  decode.d2.loss_cls: 0.1123  decode.d2.loss_mask: 0.2658  decode.d2.loss_dice: 0.2568  decode.d3.loss_cls: 0.0804  decode.d3.loss_mask: 0.2652  decode.d3.loss_dice: 0.2419  decode.d4.loss_cls: 0.1435  decode.d4.loss_mask: 0.2669  decode.d4.loss_dice: 0.2479  decode.d5.loss_cls: 0.1433  decode.d5.loss_mask: 0.2640  decode.d5.loss_dice: 0.2482  decode.d6.loss_cls: 0.1354  decode.d6.loss_mask: 0.2655  decode.d6.loss_dice: 0.2458  decode.d7.loss_cls: 0.0781  decode.d7.loss_mask: 0.2593  decode.d7.loss_dice: 0.2487  decode.d8.loss_cls: 0.0634  decode.d8.loss_mask: 0.2640  decode.d8.loss_dice: 0.2499
08/06 07:15:34 - mmengine - INFO - Iter(train) [ 36450/320000]  base_lr: 8.9688e-05 lr: 8.9688e-06  eta: 1 day, 14:43:59  time: 0.4935  data_time: 0.0111  memory: 5927  grad_norm: 165.3936  loss: 8.4784  decode.loss_cls: 0.2232  decode.loss_mask: 0.2281  decode.loss_dice: 0.2955  decode.d0.loss_cls: 0.8942  decode.d0.loss_mask: 0.2298  decode.d0.loss_dice: 0.3128  decode.d1.loss_cls: 0.3049  decode.d1.loss_mask: 0.2306  decode.d1.loss_dice: 0.2949  decode.d2.loss_cls: 0.1968  decode.d2.loss_mask: 0.2281  decode.d2.loss_dice: 0.3001  decode.d3.loss_cls: 0.2350  decode.d3.loss_mask: 0.2379  decode.d3.loss_dice: 0.3188  decode.d4.loss_cls: 0.2628  decode.d4.loss_mask: 0.2333  decode.d4.loss_dice: 0.3096  decode.d5.loss_cls: 0.2574  decode.d5.loss_mask: 0.2304  decode.d5.loss_dice: 0.3124  decode.d6.loss_cls: 0.2428  decode.d6.loss_mask: 0.2278  decode.d6.loss_dice: 0.3020  decode.d7.loss_cls: 0.2718  decode.d7.loss_mask: 0.2284  decode.d7.loss_dice: 0.2910  decode.d8.loss_cls: 0.2395  decode.d8.loss_mask: 0.2301  decode.d8.loss_dice: 0.3084
08/06 07:15:59 - mmengine - INFO - Iter(train) [ 36500/320000]  base_lr: 8.9673e-05 lr: 8.9673e-06  eta: 1 day, 14:43:35  time: 0.4943  data_time: 0.0114  memory: 5889  grad_norm: 158.3024  loss: 7.1152  decode.loss_cls: 0.0942  decode.loss_mask: 0.2938  decode.loss_dice: 0.2752  decode.d0.loss_cls: 0.7184  decode.d0.loss_mask: 0.3082  decode.d0.loss_dice: 0.2645  decode.d1.loss_cls: 0.0751  decode.d1.loss_mask: 0.3014  decode.d1.loss_dice: 0.2517  decode.d2.loss_cls: 0.0779  decode.d2.loss_mask: 0.3024  decode.d2.loss_dice: 0.2629  decode.d3.loss_cls: 0.0731  decode.d3.loss_mask: 0.2983  decode.d3.loss_dice: 0.2532  decode.d4.loss_cls: 0.0814  decode.d4.loss_mask: 0.2981  decode.d4.loss_dice: 0.2613  decode.d5.loss_cls: 0.0986  decode.d5.loss_mask: 0.2941  decode.d5.loss_dice: 0.2692  decode.d6.loss_cls: 0.1006  decode.d6.loss_mask: 0.2941  decode.d6.loss_dice: 0.2544  decode.d7.loss_cls: 0.0909  decode.d7.loss_mask: 0.2963  decode.d7.loss_dice: 0.2805  decode.d8.loss_cls: 0.0778  decode.d8.loss_mask: 0.2948  decode.d8.loss_dice: 0.2727
08/06 07:16:23 - mmengine - INFO - Iter(train) [ 36550/320000]  base_lr: 8.9659e-05 lr: 8.9659e-06  eta: 1 day, 14:43:11  time: 0.4938  data_time: 0.0111  memory: 5926  grad_norm: 75.7328  loss: 7.0409  decode.loss_cls: 0.0482  decode.loss_mask: 0.2669  decode.loss_dice: 0.2895  decode.d0.loss_cls: 0.9255  decode.d0.loss_mask: 0.2783  decode.d0.loss_dice: 0.2850  decode.d1.loss_cls: 0.0884  decode.d1.loss_mask: 0.2770  decode.d1.loss_dice: 0.2935  decode.d2.loss_cls: 0.0654  decode.d2.loss_mask: 0.2758  decode.d2.loss_dice: 0.3053  decode.d3.loss_cls: 0.0425  decode.d3.loss_mask: 0.2752  decode.d3.loss_dice: 0.2934  decode.d4.loss_cls: 0.0430  decode.d4.loss_mask: 0.2682  decode.d4.loss_dice: 0.2965  decode.d5.loss_cls: 0.0430  decode.d5.loss_mask: 0.2720  decode.d5.loss_dice: 0.2874  decode.d6.loss_cls: 0.0406  decode.d6.loss_mask: 0.2688  decode.d6.loss_dice: 0.2871  decode.d7.loss_cls: 0.0585  decode.d7.loss_mask: 0.2740  decode.d7.loss_dice: 0.2954  decode.d8.loss_cls: 0.0424  decode.d8.loss_mask: 0.2664  decode.d8.loss_dice: 0.2879
08/06 07:16:48 - mmengine - INFO - Iter(train) [ 36600/320000]  base_lr: 8.9645e-05 lr: 8.9645e-06  eta: 1 day, 14:42:47  time: 0.4930  data_time: 0.0110  memory: 5907  grad_norm: 75.1011  loss: 6.3455  decode.loss_cls: 0.0681  decode.loss_mask: 0.2479  decode.loss_dice: 0.2571  decode.d0.loss_cls: 0.8806  decode.d0.loss_mask: 0.2459  decode.d0.loss_dice: 0.2455  decode.d1.loss_cls: 0.0424  decode.d1.loss_mask: 0.2445  decode.d1.loss_dice: 0.2583  decode.d2.loss_cls: 0.1073  decode.d2.loss_mask: 0.2416  decode.d2.loss_dice: 0.2358  decode.d3.loss_cls: 0.0581  decode.d3.loss_mask: 0.2452  decode.d3.loss_dice: 0.2533  decode.d4.loss_cls: 0.0339  decode.d4.loss_mask: 0.2411  decode.d4.loss_dice: 0.2539  decode.d5.loss_cls: 0.0292  decode.d5.loss_mask: 0.2439  decode.d5.loss_dice: 0.2534  decode.d6.loss_cls: 0.0360  decode.d6.loss_mask: 0.2441  decode.d6.loss_dice: 0.2649  decode.d7.loss_cls: 0.0439  decode.d7.loss_mask: 0.2423  decode.d7.loss_dice: 0.2584  decode.d8.loss_cls: 0.0746  decode.d8.loss_mask: 0.2410  decode.d8.loss_dice: 0.2531
08/06 07:17:13 - mmengine - INFO - Iter(train) [ 36650/320000]  base_lr: 8.9631e-05 lr: 8.9631e-06  eta: 1 day, 14:42:23  time: 0.4945  data_time: 0.0112  memory: 5907  grad_norm: 163.8960  loss: 7.4198  decode.loss_cls: 0.1767  decode.loss_mask: 0.2198  decode.loss_dice: 0.2753  decode.d0.loss_cls: 0.9796  decode.d0.loss_mask: 0.2215  decode.d0.loss_dice: 0.2728  decode.d1.loss_cls: 0.1710  decode.d1.loss_mask: 0.2194  decode.d1.loss_dice: 0.2785  decode.d2.loss_cls: 0.1493  decode.d2.loss_mask: 0.2232  decode.d2.loss_dice: 0.2796  decode.d3.loss_cls: 0.1371  decode.d3.loss_mask: 0.2259  decode.d3.loss_dice: 0.2771  decode.d4.loss_cls: 0.1783  decode.d4.loss_mask: 0.2195  decode.d4.loss_dice: 0.2715  decode.d5.loss_cls: 0.1733  decode.d5.loss_mask: 0.2225  decode.d5.loss_dice: 0.2837  decode.d6.loss_cls: 0.1622  decode.d6.loss_mask: 0.2259  decode.d6.loss_dice: 0.2821  decode.d7.loss_cls: 0.1422  decode.d7.loss_mask: 0.2239  decode.d7.loss_dice: 0.2779  decode.d8.loss_cls: 0.1660  decode.d8.loss_mask: 0.2189  decode.d8.loss_dice: 0.2650
08/06 07:17:37 - mmengine - INFO - Iter(train) [ 36700/320000]  base_lr: 8.9617e-05 lr: 8.9617e-06  eta: 1 day, 14:42:00  time: 0.4942  data_time: 0.0111  memory: 5875  grad_norm: 122.1581  loss: 8.2993  decode.loss_cls: 0.2926  decode.loss_mask: 0.2681  decode.loss_dice: 0.2689  decode.d0.loss_cls: 0.9047  decode.d0.loss_mask: 0.3042  decode.d0.loss_dice: 0.3141  decode.d1.loss_cls: 0.2188  decode.d1.loss_mask: 0.2753  decode.d1.loss_dice: 0.2846  decode.d2.loss_cls: 0.2075  decode.d2.loss_mask: 0.2707  decode.d2.loss_dice: 0.2770  decode.d3.loss_cls: 0.1446  decode.d3.loss_mask: 0.2713  decode.d3.loss_dice: 0.2647  decode.d4.loss_cls: 0.2235  decode.d4.loss_mask: 0.2698  decode.d4.loss_dice: 0.2697  decode.d5.loss_cls: 0.1817  decode.d5.loss_mask: 0.2741  decode.d5.loss_dice: 0.2760  decode.d6.loss_cls: 0.1838  decode.d6.loss_mask: 0.2726  decode.d6.loss_dice: 0.2693  decode.d7.loss_cls: 0.2406  decode.d7.loss_mask: 0.2652  decode.d7.loss_dice: 0.2630  decode.d8.loss_cls: 0.2130  decode.d8.loss_mask: 0.2684  decode.d8.loss_dice: 0.2617
08/06 07:18:02 - mmengine - INFO - Iter(train) [ 36750/320000]  base_lr: 8.9602e-05 lr: 8.9602e-06  eta: 1 day, 14:41:36  time: 0.4942  data_time: 0.0111  memory: 5877  grad_norm: 97.9538  loss: 6.0422  decode.loss_cls: 0.0467  decode.loss_mask: 0.2092  decode.loss_dice: 0.2402  decode.d0.loss_cls: 0.9985  decode.d0.loss_mask: 0.2150  decode.d0.loss_dice: 0.2333  decode.d1.loss_cls: 0.0877  decode.d1.loss_mask: 0.2147  decode.d1.loss_dice: 0.2412  decode.d2.loss_cls: 0.0541  decode.d2.loss_mask: 0.2098  decode.d2.loss_dice: 0.2430  decode.d3.loss_cls: 0.0452  decode.d3.loss_mask: 0.2099  decode.d3.loss_dice: 0.2541  decode.d4.loss_cls: 0.0663  decode.d4.loss_mask: 0.2079  decode.d4.loss_dice: 0.2424  decode.d5.loss_cls: 0.0504  decode.d5.loss_mask: 0.2090  decode.d5.loss_dice: 0.2412  decode.d6.loss_cls: 0.0499  decode.d6.loss_mask: 0.2106  decode.d6.loss_dice: 0.2437  decode.d7.loss_cls: 0.0637  decode.d7.loss_mask: 0.2109  decode.d7.loss_dice: 0.2413  decode.d8.loss_cls: 0.0304  decode.d8.loss_mask: 0.2119  decode.d8.loss_dice: 0.2600
08/06 07:18:27 - mmengine - INFO - Iter(train) [ 36800/320000]  base_lr: 8.9588e-05 lr: 8.9588e-06  eta: 1 day, 14:41:12  time: 0.4931  data_time: 0.0110  memory: 5893  grad_norm: 74.7901  loss: 7.2658  decode.loss_cls: 0.0455  decode.loss_mask: 0.3245  decode.loss_dice: 0.2788  decode.d0.loss_cls: 0.7415  decode.d0.loss_mask: 0.3220  decode.d0.loss_dice: 0.2993  decode.d1.loss_cls: 0.1562  decode.d1.loss_mask: 0.3168  decode.d1.loss_dice: 0.2815  decode.d2.loss_cls: 0.0322  decode.d2.loss_mask: 0.3247  decode.d2.loss_dice: 0.2868  decode.d3.loss_cls: 0.0270  decode.d3.loss_mask: 0.3210  decode.d3.loss_dice: 0.2808  decode.d4.loss_cls: 0.0263  decode.d4.loss_mask: 0.3262  decode.d4.loss_dice: 0.2802  decode.d5.loss_cls: 0.0521  decode.d5.loss_mask: 0.3230  decode.d5.loss_dice: 0.2766  decode.d6.loss_cls: 0.0307  decode.d6.loss_mask: 0.3251  decode.d6.loss_dice: 0.2817  decode.d7.loss_cls: 0.0341  decode.d7.loss_mask: 0.3226  decode.d7.loss_dice: 0.2840  decode.d8.loss_cls: 0.0556  decode.d8.loss_mask: 0.3283  decode.d8.loss_dice: 0.2808
08/06 07:18:52 - mmengine - INFO - Iter(train) [ 36850/320000]  base_lr: 8.9574e-05 lr: 8.9574e-06  eta: 1 day, 14:40:48  time: 0.4930  data_time: 0.0112  memory: 5927  grad_norm: 69.4039  loss: 6.3024  decode.loss_cls: 0.0512  decode.loss_mask: 0.2221  decode.loss_dice: 0.2469  decode.d0.loss_cls: 0.9101  decode.d0.loss_mask: 0.2287  decode.d0.loss_dice: 0.2505  decode.d1.loss_cls: 0.1046  decode.d1.loss_mask: 0.2226  decode.d1.loss_dice: 0.2429  decode.d2.loss_cls: 0.1399  decode.d2.loss_mask: 0.2251  decode.d2.loss_dice: 0.2506  decode.d3.loss_cls: 0.0442  decode.d3.loss_mask: 0.2248  decode.d3.loss_dice: 0.2488  decode.d4.loss_cls: 0.0706  decode.d4.loss_mask: 0.2254  decode.d4.loss_dice: 0.2484  decode.d5.loss_cls: 0.0823  decode.d5.loss_mask: 0.2235  decode.d5.loss_dice: 0.2464  decode.d6.loss_cls: 0.0487  decode.d6.loss_mask: 0.2202  decode.d6.loss_dice: 0.2493  decode.d7.loss_cls: 0.0702  decode.d7.loss_mask: 0.2254  decode.d7.loss_dice: 0.2464  decode.d8.loss_cls: 0.0566  decode.d8.loss_mask: 0.2258  decode.d8.loss_dice: 0.2501
08/06 07:19:16 - mmengine - INFO - Iter(train) [ 36900/320000]  base_lr: 8.9560e-05 lr: 8.9560e-06  eta: 1 day, 14:40:25  time: 0.4934  data_time: 0.0112  memory: 5910  grad_norm: 84.4623  loss: 6.7317  decode.loss_cls: 0.0754  decode.loss_mask: 0.2554  decode.loss_dice: 0.2604  decode.d0.loss_cls: 0.7655  decode.d0.loss_mask: 0.2695  decode.d0.loss_dice: 0.2725  decode.d1.loss_cls: 0.0953  decode.d1.loss_mask: 0.2600  decode.d1.loss_dice: 0.2668  decode.d2.loss_cls: 0.0947  decode.d2.loss_mask: 0.2572  decode.d2.loss_dice: 0.2627  decode.d3.loss_cls: 0.0808  decode.d3.loss_mask: 0.2565  decode.d3.loss_dice: 0.2594  decode.d4.loss_cls: 0.0749  decode.d4.loss_mask: 0.2570  decode.d4.loss_dice: 0.2719  decode.d5.loss_cls: 0.0937  decode.d5.loss_mask: 0.2561  decode.d5.loss_dice: 0.2641  decode.d6.loss_cls: 0.0807  decode.d6.loss_mask: 0.2561  decode.d6.loss_dice: 0.2669  decode.d7.loss_cls: 0.0718  decode.d7.loss_mask: 0.2578  decode.d7.loss_dice: 0.2657  decode.d8.loss_cls: 0.0660  decode.d8.loss_mask: 0.2556  decode.d8.loss_dice: 0.2615
08/06 07:19:41 - mmengine - INFO - Iter(train) [ 36950/320000]  base_lr: 8.9545e-05 lr: 8.9545e-06  eta: 1 day, 14:40:01  time: 0.4944  data_time: 0.0112  memory: 5908  grad_norm: 64.4346  loss: 7.5823  decode.loss_cls: 0.1595  decode.loss_mask: 0.2626  decode.loss_dice: 0.2784  decode.d0.loss_cls: 0.9642  decode.d0.loss_mask: 0.2680  decode.d0.loss_dice: 0.2584  decode.d1.loss_cls: 0.1594  decode.d1.loss_mask: 0.2660  decode.d1.loss_dice: 0.2582  decode.d2.loss_cls: 0.1053  decode.d2.loss_mask: 0.2609  decode.d2.loss_dice: 0.2623  decode.d3.loss_cls: 0.1131  decode.d3.loss_mask: 0.2577  decode.d3.loss_dice: 0.2692  decode.d4.loss_cls: 0.1373  decode.d4.loss_mask: 0.2633  decode.d4.loss_dice: 0.2557  decode.d5.loss_cls: 0.1829  decode.d5.loss_mask: 0.2610  decode.d5.loss_dice: 0.2717  decode.d6.loss_cls: 0.1548  decode.d6.loss_mask: 0.2600  decode.d6.loss_dice: 0.2635  decode.d7.loss_cls: 0.1474  decode.d7.loss_mask: 0.2618  decode.d7.loss_dice: 0.2576  decode.d8.loss_cls: 0.2065  decode.d8.loss_mask: 0.2575  decode.d8.loss_dice: 0.2581
08/06 07:20:06 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 07:20:06 - mmengine - INFO - Iter(train) [ 37000/320000]  base_lr: 8.9531e-05 lr: 8.9531e-06  eta: 1 day, 14:39:37  time: 0.4926  data_time: 0.0112  memory: 5891  grad_norm: 112.3463  loss: 8.2033  decode.loss_cls: 0.1642  decode.loss_mask: 0.2673  decode.loss_dice: 0.3055  decode.d0.loss_cls: 0.9416  decode.d0.loss_mask: 0.2684  decode.d0.loss_dice: 0.3117  decode.d1.loss_cls: 0.2121  decode.d1.loss_mask: 0.2733  decode.d1.loss_dice: 0.2931  decode.d2.loss_cls: 0.1592  decode.d2.loss_mask: 0.2686  decode.d2.loss_dice: 0.2915  decode.d3.loss_cls: 0.2018  decode.d3.loss_mask: 0.2654  decode.d3.loss_dice: 0.2845  decode.d4.loss_cls: 0.1945  decode.d4.loss_mask: 0.2673  decode.d4.loss_dice: 0.2893  decode.d5.loss_cls: 0.2238  decode.d5.loss_mask: 0.2695  decode.d5.loss_dice: 0.2860  decode.d6.loss_cls: 0.1768  decode.d6.loss_mask: 0.2704  decode.d6.loss_dice: 0.2904  decode.d7.loss_cls: 0.1549  decode.d7.loss_mask: 0.2689  decode.d7.loss_dice: 0.2861  decode.d8.loss_cls: 0.1625  decode.d8.loss_mask: 0.2677  decode.d8.loss_dice: 0.2870
08/06 07:20:30 - mmengine - INFO - Iter(train) [ 37050/320000]  base_lr: 8.9517e-05 lr: 8.9517e-06  eta: 1 day, 14:39:13  time: 0.4937  data_time: 0.0111  memory: 5907  grad_norm: 27.9410  loss: 4.4543  decode.loss_cls: 0.0112  decode.loss_mask: 0.1662  decode.loss_dice: 0.1880  decode.d0.loss_cls: 0.7877  decode.d0.loss_mask: 0.1685  decode.d0.loss_dice: 0.1914  decode.d1.loss_cls: 0.0146  decode.d1.loss_mask: 0.1696  decode.d1.loss_dice: 0.1933  decode.d2.loss_cls: 0.0150  decode.d2.loss_mask: 0.1690  decode.d2.loss_dice: 0.1892  decode.d3.loss_cls: 0.0097  decode.d3.loss_mask: 0.1692  decode.d3.loss_dice: 0.1821  decode.d4.loss_cls: 0.0089  decode.d4.loss_mask: 0.1683  decode.d4.loss_dice: 0.1878  decode.d5.loss_cls: 0.0116  decode.d5.loss_mask: 0.1686  decode.d5.loss_dice: 0.1844  decode.d6.loss_cls: 0.0130  decode.d6.loss_mask: 0.1672  decode.d6.loss_dice: 0.1874  decode.d7.loss_cls: 0.0094  decode.d7.loss_mask: 0.1680  decode.d7.loss_dice: 0.1850  decode.d8.loss_cls: 0.0121  decode.d8.loss_mask: 0.1691  decode.d8.loss_dice: 0.1889
08/06 07:20:55 - mmengine - INFO - Iter(train) [ 37100/320000]  base_lr: 8.9503e-05 lr: 8.9503e-06  eta: 1 day, 14:38:49  time: 0.4933  data_time: 0.0113  memory: 5889  grad_norm: 82.0297  loss: 6.8004  decode.loss_cls: 0.0857  decode.loss_mask: 0.2394  decode.loss_dice: 0.2685  decode.d0.loss_cls: 0.8015  decode.d0.loss_mask: 0.2390  decode.d0.loss_dice: 0.2548  decode.d1.loss_cls: 0.1275  decode.d1.loss_mask: 0.2400  decode.d1.loss_dice: 0.2515  decode.d2.loss_cls: 0.0993  decode.d2.loss_mask: 0.2386  decode.d2.loss_dice: 0.2543  decode.d3.loss_cls: 0.1166  decode.d3.loss_mask: 0.2426  decode.d3.loss_dice: 0.2423  decode.d4.loss_cls: 0.1333  decode.d4.loss_mask: 0.2412  decode.d4.loss_dice: 0.2468  decode.d5.loss_cls: 0.1448  decode.d5.loss_mask: 0.2431  decode.d5.loss_dice: 0.2664  decode.d6.loss_cls: 0.1395  decode.d6.loss_mask: 0.2413  decode.d6.loss_dice: 0.2645  decode.d7.loss_cls: 0.1108  decode.d7.loss_mask: 0.2407  decode.d7.loss_dice: 0.2376  decode.d8.loss_cls: 0.0934  decode.d8.loss_mask: 0.2412  decode.d8.loss_dice: 0.2542
08/06 07:21:20 - mmengine - INFO - Iter(train) [ 37150/320000]  base_lr: 8.9488e-05 lr: 8.9488e-06  eta: 1 day, 14:38:25  time: 0.4942  data_time: 0.0115  memory: 5908  grad_norm: 145.4523  loss: 6.8623  decode.loss_cls: 0.1653  decode.loss_mask: 0.2585  decode.loss_dice: 0.2270  decode.d0.loss_cls: 0.8417  decode.d0.loss_mask: 0.2434  decode.d0.loss_dice: 0.2419  decode.d1.loss_cls: 0.1829  decode.d1.loss_mask: 0.2394  decode.d1.loss_dice: 0.2473  decode.d2.loss_cls: 0.1620  decode.d2.loss_mask: 0.2383  decode.d2.loss_dice: 0.2273  decode.d3.loss_cls: 0.1303  decode.d3.loss_mask: 0.2339  decode.d3.loss_dice: 0.2212  decode.d4.loss_cls: 0.1267  decode.d4.loss_mask: 0.2403  decode.d4.loss_dice: 0.2221  decode.d5.loss_cls: 0.1490  decode.d5.loss_mask: 0.2354  decode.d5.loss_dice: 0.2225  decode.d6.loss_cls: 0.1143  decode.d6.loss_mask: 0.2551  decode.d6.loss_dice: 0.2318  decode.d7.loss_cls: 0.1191  decode.d7.loss_mask: 0.2506  decode.d7.loss_dice: 0.2263  decode.d8.loss_cls: 0.1328  decode.d8.loss_mask: 0.2532  decode.d8.loss_dice: 0.2228
08/06 07:21:44 - mmengine - INFO - Iter(train) [ 37200/320000]  base_lr: 8.9474e-05 lr: 8.9474e-06  eta: 1 day, 14:38:02  time: 0.4945  data_time: 0.0111  memory: 5889  grad_norm: 77.5633  loss: 6.6143  decode.loss_cls: 0.0543  decode.loss_mask: 0.2754  decode.loss_dice: 0.2437  decode.d0.loss_cls: 0.8122  decode.d0.loss_mask: 0.2793  decode.d0.loss_dice: 0.2745  decode.d1.loss_cls: 0.0351  decode.d1.loss_mask: 0.2759  decode.d1.loss_dice: 0.2674  decode.d2.loss_cls: 0.0786  decode.d2.loss_mask: 0.2747  decode.d2.loss_dice: 0.2645  decode.d3.loss_cls: 0.0526  decode.d3.loss_mask: 0.2739  decode.d3.loss_dice: 0.2632  decode.d4.loss_cls: 0.0491  decode.d4.loss_mask: 0.2744  decode.d4.loss_dice: 0.2538  decode.d5.loss_cls: 0.0339  decode.d5.loss_mask: 0.2780  decode.d5.loss_dice: 0.2600  decode.d6.loss_cls: 0.0347  decode.d6.loss_mask: 0.2741  decode.d6.loss_dice: 0.2511  decode.d7.loss_cls: 0.0534  decode.d7.loss_mask: 0.2751  decode.d7.loss_dice: 0.2513  decode.d8.loss_cls: 0.0736  decode.d8.loss_mask: 0.2761  decode.d8.loss_dice: 0.2504
08/06 07:22:09 - mmengine - INFO - Iter(train) [ 37250/320000]  base_lr: 8.9460e-05 lr: 8.9460e-06  eta: 1 day, 14:37:38  time: 0.4933  data_time: 0.0110  memory: 5928  grad_norm: 100.1191  loss: 8.5728  decode.loss_cls: 0.2680  decode.loss_mask: 0.2101  decode.loss_dice: 0.3235  decode.d0.loss_cls: 0.8378  decode.d0.loss_mask: 0.2178  decode.d0.loss_dice: 0.3559  decode.d1.loss_cls: 0.2521  decode.d1.loss_mask: 0.2082  decode.d1.loss_dice: 0.3454  decode.d2.loss_cls: 0.2578  decode.d2.loss_mask: 0.2076  decode.d2.loss_dice: 0.3543  decode.d3.loss_cls: 0.2887  decode.d3.loss_mask: 0.2087  decode.d3.loss_dice: 0.2949  decode.d4.loss_cls: 0.2887  decode.d4.loss_mask: 0.2087  decode.d4.loss_dice: 0.3229  decode.d5.loss_cls: 0.2479  decode.d5.loss_mask: 0.2088  decode.d5.loss_dice: 0.3124  decode.d6.loss_cls: 0.2539  decode.d6.loss_mask: 0.2085  decode.d6.loss_dice: 0.3309  decode.d7.loss_cls: 0.2619  decode.d7.loss_mask: 0.2059  decode.d7.loss_dice: 0.3064  decode.d8.loss_cls: 0.2398  decode.d8.loss_mask: 0.2077  decode.d8.loss_dice: 0.3376
08/06 07:22:34 - mmengine - INFO - Iter(train) [ 37300/320000]  base_lr: 8.9446e-05 lr: 8.9446e-06  eta: 1 day, 14:37:14  time: 0.4922  data_time: 0.0108  memory: 5891  grad_norm: 220.6798  loss: 7.3940  decode.loss_cls: 0.0826  decode.loss_mask: 0.2860  decode.loss_dice: 0.2779  decode.d0.loss_cls: 0.8574  decode.d0.loss_mask: 0.2945  decode.d0.loss_dice: 0.2642  decode.d1.loss_cls: 0.1336  decode.d1.loss_mask: 0.2876  decode.d1.loss_dice: 0.2727  decode.d2.loss_cls: 0.1112  decode.d2.loss_mask: 0.2833  decode.d2.loss_dice: 0.2568  decode.d3.loss_cls: 0.1261  decode.d3.loss_mask: 0.2919  decode.d3.loss_dice: 0.2561  decode.d4.loss_cls: 0.1320  decode.d4.loss_mask: 0.2868  decode.d4.loss_dice: 0.2619  decode.d5.loss_cls: 0.1018  decode.d5.loss_mask: 0.2813  decode.d5.loss_dice: 0.2721  decode.d6.loss_cls: 0.1014  decode.d6.loss_mask: 0.2845  decode.d6.loss_dice: 0.2664  decode.d7.loss_cls: 0.0851  decode.d7.loss_mask: 0.2901  decode.d7.loss_dice: 0.2801  decode.d8.loss_cls: 0.0991  decode.d8.loss_mask: 0.2877  decode.d8.loss_dice: 0.2820
08/06 07:22:58 - mmengine - INFO - Iter(train) [ 37350/320000]  base_lr: 8.9431e-05 lr: 8.9431e-06  eta: 1 day, 14:36:50  time: 0.4943  data_time: 0.0113  memory: 5926  grad_norm: 144.1608  loss: 7.3152  decode.loss_cls: 0.1088  decode.loss_mask: 0.2469  decode.loss_dice: 0.2588  decode.d0.loss_cls: 0.9958  decode.d0.loss_mask: 0.2539  decode.d0.loss_dice: 0.2907  decode.d1.loss_cls: 0.2487  decode.d1.loss_mask: 0.2473  decode.d1.loss_dice: 0.2613  decode.d2.loss_cls: 0.1766  decode.d2.loss_mask: 0.2490  decode.d2.loss_dice: 0.2613  decode.d3.loss_cls: 0.1467  decode.d3.loss_mask: 0.2460  decode.d3.loss_dice: 0.2523  decode.d4.loss_cls: 0.1119  decode.d4.loss_mask: 0.2462  decode.d4.loss_dice: 0.2544  decode.d5.loss_cls: 0.1474  decode.d5.loss_mask: 0.2460  decode.d5.loss_dice: 0.2612  decode.d6.loss_cls: 0.0993  decode.d6.loss_mask: 0.2446  decode.d6.loss_dice: 0.2501  decode.d7.loss_cls: 0.0982  decode.d7.loss_mask: 0.2493  decode.d7.loss_dice: 0.2608  decode.d8.loss_cls: 0.0982  decode.d8.loss_mask: 0.2441  decode.d8.loss_dice: 0.2595
08/06 07:23:23 - mmengine - INFO - Iter(train) [ 37400/320000]  base_lr: 8.9417e-05 lr: 8.9417e-06  eta: 1 day, 14:36:26  time: 0.4939  data_time: 0.0112  memory: 5907  grad_norm: 91.8530  loss: 7.8506  decode.loss_cls: 0.1188  decode.loss_mask: 0.2354  decode.loss_dice: 0.3073  decode.d0.loss_cls: 1.0028  decode.d0.loss_mask: 0.2348  decode.d0.loss_dice: 0.2957  decode.d1.loss_cls: 0.1946  decode.d1.loss_mask: 0.2336  decode.d1.loss_dice: 0.2847  decode.d2.loss_cls: 0.1901  decode.d2.loss_mask: 0.2299  decode.d2.loss_dice: 0.3070  decode.d3.loss_cls: 0.1529  decode.d3.loss_mask: 0.2336  decode.d3.loss_dice: 0.2886  decode.d4.loss_cls: 0.1384  decode.d4.loss_mask: 0.2365  decode.d4.loss_dice: 0.2975  decode.d5.loss_cls: 0.1991  decode.d5.loss_mask: 0.2312  decode.d5.loss_dice: 0.2853  decode.d6.loss_cls: 0.1630  decode.d6.loss_mask: 0.2320  decode.d6.loss_dice: 0.2945  decode.d7.loss_cls: 0.1968  decode.d7.loss_mask: 0.2308  decode.d7.loss_dice: 0.2983  decode.d8.loss_cls: 0.1973  decode.d8.loss_mask: 0.2289  decode.d8.loss_dice: 0.3111
08/06 07:23:48 - mmengine - INFO - Iter(train) [ 37450/320000]  base_lr: 8.9403e-05 lr: 8.9403e-06  eta: 1 day, 14:36:02  time: 0.4936  data_time: 0.0110  memory: 5875  grad_norm: 129.4339  loss: 7.4979  decode.loss_cls: 0.0910  decode.loss_mask: 0.3105  decode.loss_dice: 0.2538  decode.d0.loss_cls: 0.8214  decode.d0.loss_mask: 0.3351  decode.d0.loss_dice: 0.2861  decode.d1.loss_cls: 0.1161  decode.d1.loss_mask: 0.3068  decode.d1.loss_dice: 0.2529  decode.d2.loss_cls: 0.0468  decode.d2.loss_mask: 0.3128  decode.d2.loss_dice: 0.2923  decode.d3.loss_cls: 0.1081  decode.d3.loss_mask: 0.3055  decode.d3.loss_dice: 0.2895  decode.d4.loss_cls: 0.1059  decode.d4.loss_mask: 0.3062  decode.d4.loss_dice: 0.2749  decode.d5.loss_cls: 0.0752  decode.d5.loss_mask: 0.3041  decode.d5.loss_dice: 0.2562  decode.d6.loss_cls: 0.0927  decode.d6.loss_mask: 0.3070  decode.d6.loss_dice: 0.2782  decode.d7.loss_cls: 0.1239  decode.d7.loss_mask: 0.3041  decode.d7.loss_dice: 0.2722  decode.d8.loss_cls: 0.0950  decode.d8.loss_mask: 0.3093  decode.d8.loss_dice: 0.2644
08/06 07:24:13 - mmengine - INFO - Iter(train) [ 37500/320000]  base_lr: 8.9389e-05 lr: 8.9389e-06  eta: 1 day, 14:35:39  time: 0.4933  data_time: 0.0109  memory: 5910  grad_norm: 89.5132  loss: 8.3781  decode.loss_cls: 0.1573  decode.loss_mask: 0.2686  decode.loss_dice: 0.3106  decode.d0.loss_cls: 0.9958  decode.d0.loss_mask: 0.2686  decode.d0.loss_dice: 0.3279  decode.d1.loss_cls: 0.2469  decode.d1.loss_mask: 0.2657  decode.d1.loss_dice: 0.3321  decode.d2.loss_cls: 0.1861  decode.d2.loss_mask: 0.2678  decode.d2.loss_dice: 0.3188  decode.d3.loss_cls: 0.1354  decode.d3.loss_mask: 0.2738  decode.d3.loss_dice: 0.3159  decode.d4.loss_cls: 0.1316  decode.d4.loss_mask: 0.2692  decode.d4.loss_dice: 0.3109  decode.d5.loss_cls: 0.1563  decode.d5.loss_mask: 0.2650  decode.d5.loss_dice: 0.3295  decode.d6.loss_cls: 0.1540  decode.d6.loss_mask: 0.2690  decode.d6.loss_dice: 0.3230  decode.d7.loss_cls: 0.1554  decode.d7.loss_mask: 0.2647  decode.d7.loss_dice: 0.3216  decode.d8.loss_cls: 0.1561  decode.d8.loss_mask: 0.2676  decode.d8.loss_dice: 0.3331
08/06 07:24:37 - mmengine - INFO - Iter(train) [ 37550/320000]  base_lr: 8.9375e-05 lr: 8.9375e-06  eta: 1 day, 14:35:15  time: 0.4933  data_time: 0.0111  memory: 5874  grad_norm: 173.6937  loss: 7.9772  decode.loss_cls: 0.0339  decode.loss_mask: 0.3250  decode.loss_dice: 0.3282  decode.d0.loss_cls: 0.8462  decode.d0.loss_mask: 0.3282  decode.d0.loss_dice: 0.3307  decode.d1.loss_cls: 0.1280  decode.d1.loss_mask: 0.3213  decode.d1.loss_dice: 0.3114  decode.d2.loss_cls: 0.0834  decode.d2.loss_mask: 0.3664  decode.d2.loss_dice: 0.3250  decode.d3.loss_cls: 0.0514  decode.d3.loss_mask: 0.3504  decode.d3.loss_dice: 0.3190  decode.d4.loss_cls: 0.0599  decode.d4.loss_mask: 0.3564  decode.d4.loss_dice: 0.3202  decode.d5.loss_cls: 0.0418  decode.d5.loss_mask: 0.3364  decode.d5.loss_dice: 0.3167  decode.d6.loss_cls: 0.0448  decode.d6.loss_mask: 0.3330  decode.d6.loss_dice: 0.3120  decode.d7.loss_cls: 0.0289  decode.d7.loss_mask: 0.3340  decode.d7.loss_dice: 0.3271  decode.d8.loss_cls: 0.0669  decode.d8.loss_mask: 0.3234  decode.d8.loss_dice: 0.3271
08/06 07:25:02 - mmengine - INFO - Iter(train) [ 37600/320000]  base_lr: 8.9360e-05 lr: 8.9360e-06  eta: 1 day, 14:34:51  time: 0.4944  data_time: 0.0112  memory: 5892  grad_norm: 107.6825  loss: 7.8855  decode.loss_cls: 0.1290  decode.loss_mask: 0.2742  decode.loss_dice: 0.2850  decode.d0.loss_cls: 0.9693  decode.d0.loss_mask: 0.2797  decode.d0.loss_dice: 0.3066  decode.d1.loss_cls: 0.1407  decode.d1.loss_mask: 0.2888  decode.d1.loss_dice: 0.2891  decode.d2.loss_cls: 0.1184  decode.d2.loss_mask: 0.2848  decode.d2.loss_dice: 0.2737  decode.d3.loss_cls: 0.1613  decode.d3.loss_mask: 0.2879  decode.d3.loss_dice: 0.2829  decode.d4.loss_cls: 0.1178  decode.d4.loss_mask: 0.2857  decode.d4.loss_dice: 0.2930  decode.d5.loss_cls: 0.1316  decode.d5.loss_mask: 0.2780  decode.d5.loss_dice: 0.2887  decode.d6.loss_cls: 0.1293  decode.d6.loss_mask: 0.2768  decode.d6.loss_dice: 0.2744  decode.d7.loss_cls: 0.1484  decode.d7.loss_mask: 0.2813  decode.d7.loss_dice: 0.3053  decode.d8.loss_cls: 0.1300  decode.d8.loss_mask: 0.2779  decode.d8.loss_dice: 0.2960
08/06 07:25:27 - mmengine - INFO - Iter(train) [ 37650/320000]  base_lr: 8.9346e-05 lr: 8.9346e-06  eta: 1 day, 14:34:27  time: 0.4928  data_time: 0.0110  memory: 5890  grad_norm: 89.8085  loss: 7.8872  decode.loss_cls: 0.1881  decode.loss_mask: 0.2698  decode.loss_dice: 0.2547  decode.d0.loss_cls: 0.9111  decode.d0.loss_mask: 0.2687  decode.d0.loss_dice: 0.2461  decode.d1.loss_cls: 0.1990  decode.d1.loss_mask: 0.2672  decode.d1.loss_dice: 0.2647  decode.d2.loss_cls: 0.1485  decode.d2.loss_mask: 0.2877  decode.d2.loss_dice: 0.2698  decode.d3.loss_cls: 0.1915  decode.d3.loss_mask: 0.2683  decode.d3.loss_dice: 0.2578  decode.d4.loss_cls: 0.1838  decode.d4.loss_mask: 0.2667  decode.d4.loss_dice: 0.2505  decode.d5.loss_cls: 0.1827  decode.d5.loss_mask: 0.2764  decode.d5.loss_dice: 0.2720  decode.d6.loss_cls: 0.1330  decode.d6.loss_mask: 0.2887  decode.d6.loss_dice: 0.2810  decode.d7.loss_cls: 0.1757  decode.d7.loss_mask: 0.2860  decode.d7.loss_dice: 0.2959  decode.d8.loss_cls: 0.1814  decode.d8.loss_mask: 0.2668  decode.d8.loss_dice: 0.2536
08/06 07:25:51 - mmengine - INFO - Iter(train) [ 37700/320000]  base_lr: 8.9332e-05 lr: 8.9332e-06  eta: 1 day, 14:34:03  time: 0.4916  data_time: 0.0108  memory: 5908  grad_norm: 94.2893  loss: 9.1544  decode.loss_cls: 0.2241  decode.loss_mask: 0.2966  decode.loss_dice: 0.3108  decode.d0.loss_cls: 0.9625  decode.d0.loss_mask: 0.3067  decode.d0.loss_dice: 0.3227  decode.d1.loss_cls: 0.1751  decode.d1.loss_mask: 0.3005  decode.d1.loss_dice: 0.3044  decode.d2.loss_cls: 0.1868  decode.d2.loss_mask: 0.2972  decode.d2.loss_dice: 0.3035  decode.d3.loss_cls: 0.2619  decode.d3.loss_mask: 0.2930  decode.d3.loss_dice: 0.2915  decode.d4.loss_cls: 0.2175  decode.d4.loss_mask: 0.2964  decode.d4.loss_dice: 0.3091  decode.d5.loss_cls: 0.2965  decode.d5.loss_mask: 0.2943  decode.d5.loss_dice: 0.2992  decode.d6.loss_cls: 0.2658  decode.d6.loss_mask: 0.2944  decode.d6.loss_dice: 0.3007  decode.d7.loss_cls: 0.2734  decode.d7.loss_mask: 0.2937  decode.d7.loss_dice: 0.3025  decode.d8.loss_cls: 0.2840  decode.d8.loss_mask: 0.2945  decode.d8.loss_dice: 0.2949
08/06 07:26:16 - mmengine - INFO - Iter(train) [ 37750/320000]  base_lr: 8.9318e-05 lr: 8.9318e-06  eta: 1 day, 14:33:38  time: 0.4925  data_time: 0.0109  memory: 5893  grad_norm: 74.9428  loss: 5.7445  decode.loss_cls: 0.0466  decode.loss_mask: 0.2465  decode.loss_dice: 0.2101  decode.d0.loss_cls: 0.7370  decode.d0.loss_mask: 0.2474  decode.d0.loss_dice: 0.2139  decode.d1.loss_cls: 0.1173  decode.d1.loss_mask: 0.2465  decode.d1.loss_dice: 0.2064  decode.d2.loss_cls: 0.0537  decode.d2.loss_mask: 0.2407  decode.d2.loss_dice: 0.2078  decode.d3.loss_cls: 0.0408  decode.d3.loss_mask: 0.2465  decode.d3.loss_dice: 0.2132  decode.d4.loss_cls: 0.0399  decode.d4.loss_mask: 0.2496  decode.d4.loss_dice: 0.2128  decode.d5.loss_cls: 0.0449  decode.d5.loss_mask: 0.2445  decode.d5.loss_dice: 0.2056  decode.d6.loss_cls: 0.0426  decode.d6.loss_mask: 0.2447  decode.d6.loss_dice: 0.2060  decode.d7.loss_cls: 0.0288  decode.d7.loss_mask: 0.2451  decode.d7.loss_dice: 0.2062  decode.d8.loss_cls: 0.0439  decode.d8.loss_mask: 0.2446  decode.d8.loss_dice: 0.2109
08/06 07:26:40 - mmengine - INFO - Iter(train) [ 37800/320000]  base_lr: 8.9303e-05 lr: 8.9303e-06  eta: 1 day, 14:33:14  time: 0.4914  data_time: 0.0109  memory: 5875  grad_norm: 148.5718  loss: 7.8242  decode.loss_cls: 0.1354  decode.loss_mask: 0.2970  decode.loss_dice: 0.2489  decode.d0.loss_cls: 0.7602  decode.d0.loss_mask: 0.3125  decode.d0.loss_dice: 0.3254  decode.d1.loss_cls: 0.2042  decode.d1.loss_mask: 0.2993  decode.d1.loss_dice: 0.2945  decode.d2.loss_cls: 0.2005  decode.d2.loss_mask: 0.2980  decode.d2.loss_dice: 0.2508  decode.d3.loss_cls: 0.1535  decode.d3.loss_mask: 0.2981  decode.d3.loss_dice: 0.2734  decode.d4.loss_cls: 0.1613  decode.d4.loss_mask: 0.3000  decode.d4.loss_dice: 0.2529  decode.d5.loss_cls: 0.1549  decode.d5.loss_mask: 0.2939  decode.d5.loss_dice: 0.2535  decode.d6.loss_cls: 0.1697  decode.d6.loss_mask: 0.2908  decode.d6.loss_dice: 0.2421  decode.d7.loss_cls: 0.1557  decode.d7.loss_mask: 0.2929  decode.d7.loss_dice: 0.2409  decode.d8.loss_cls: 0.0986  decode.d8.loss_mask: 0.2944  decode.d8.loss_dice: 0.2709
08/06 07:27:05 - mmengine - INFO - Iter(train) [ 37850/320000]  base_lr: 8.9289e-05 lr: 8.9289e-06  eta: 1 day, 14:32:49  time: 0.4920  data_time: 0.0106  memory: 5891  grad_norm: 83.0854  loss: 6.7506  decode.loss_cls: 0.1075  decode.loss_mask: 0.2508  decode.loss_dice: 0.2374  decode.d0.loss_cls: 0.8617  decode.d0.loss_mask: 0.2546  decode.d0.loss_dice: 0.2533  decode.d1.loss_cls: 0.1283  decode.d1.loss_mask: 0.2483  decode.d1.loss_dice: 0.2401  decode.d2.loss_cls: 0.1445  decode.d2.loss_mask: 0.2528  decode.d2.loss_dice: 0.2490  decode.d3.loss_cls: 0.0868  decode.d3.loss_mask: 0.2508  decode.d3.loss_dice: 0.2461  decode.d4.loss_cls: 0.0952  decode.d4.loss_mask: 0.2520  decode.d4.loss_dice: 0.2366  decode.d5.loss_cls: 0.1159  decode.d5.loss_mask: 0.2504  decode.d5.loss_dice: 0.2402  decode.d6.loss_cls: 0.0935  decode.d6.loss_mask: 0.2514  decode.d6.loss_dice: 0.2397  decode.d7.loss_cls: 0.0859  decode.d7.loss_mask: 0.2502  decode.d7.loss_dice: 0.2386  decode.d8.loss_cls: 0.0744  decode.d8.loss_mask: 0.2531  decode.d8.loss_dice: 0.2616
08/06 07:27:30 - mmengine - INFO - Iter(train) [ 37900/320000]  base_lr: 8.9275e-05 lr: 8.9275e-06  eta: 1 day, 14:32:25  time: 0.4930  data_time: 0.0110  memory: 5907  grad_norm: 161.7457  loss: 8.5869  decode.loss_cls: 0.2594  decode.loss_mask: 0.2541  decode.loss_dice: 0.2721  decode.d0.loss_cls: 0.9994  decode.d0.loss_mask: 0.2450  decode.d0.loss_dice: 0.2619  decode.d1.loss_cls: 0.2830  decode.d1.loss_mask: 0.2401  decode.d1.loss_dice: 0.2710  decode.d2.loss_cls: 0.2732  decode.d2.loss_mask: 0.2740  decode.d2.loss_dice: 0.2646  decode.d3.loss_cls: 0.2453  decode.d3.loss_mask: 0.2748  decode.d3.loss_dice: 0.2558  decode.d4.loss_cls: 0.2405  decode.d4.loss_mask: 0.2786  decode.d4.loss_dice: 0.2592  decode.d5.loss_cls: 0.2184  decode.d5.loss_mask: 0.2728  decode.d5.loss_dice: 0.2723  decode.d6.loss_cls: 0.2435  decode.d6.loss_mask: 0.2762  decode.d6.loss_dice: 0.2749  decode.d7.loss_cls: 0.2769  decode.d7.loss_mask: 0.2658  decode.d7.loss_dice: 0.2640  decode.d8.loss_cls: 0.2443  decode.d8.loss_mask: 0.2588  decode.d8.loss_dice: 0.2672
08/06 07:27:54 - mmengine - INFO - Iter(train) [ 37950/320000]  base_lr: 8.9261e-05 lr: 8.9261e-06  eta: 1 day, 14:32:01  time: 0.4931  data_time: 0.0109  memory: 5889  grad_norm: 135.3643  loss: 7.3702  decode.loss_cls: 0.1486  decode.loss_mask: 0.2525  decode.loss_dice: 0.2675  decode.d0.loss_cls: 1.0012  decode.d0.loss_mask: 0.2570  decode.d0.loss_dice: 0.3009  decode.d1.loss_cls: 0.1586  decode.d1.loss_mask: 0.2480  decode.d1.loss_dice: 0.2627  decode.d2.loss_cls: 0.2255  decode.d2.loss_mask: 0.2483  decode.d2.loss_dice: 0.2540  decode.d3.loss_cls: 0.0945  decode.d3.loss_mask: 0.2522  decode.d3.loss_dice: 0.2758  decode.d4.loss_cls: 0.1206  decode.d4.loss_mask: 0.2447  decode.d4.loss_dice: 0.2764  decode.d5.loss_cls: 0.0923  decode.d5.loss_mask: 0.2508  decode.d5.loss_dice: 0.2715  decode.d6.loss_cls: 0.0877  decode.d6.loss_mask: 0.2534  decode.d6.loss_dice: 0.2631  decode.d7.loss_cls: 0.1072  decode.d7.loss_mask: 0.2535  decode.d7.loss_dice: 0.2843  decode.d8.loss_cls: 0.1017  decode.d8.loss_mask: 0.2461  decode.d8.loss_dice: 0.2697
08/06 07:28:19 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 07:28:19 - mmengine - INFO - Iter(train) [ 38000/320000]  base_lr: 8.9246e-05 lr: 8.9246e-06  eta: 1 day, 14:31:37  time: 0.4928  data_time: 0.0109  memory: 5893  grad_norm: 163.1122  loss: 6.6212  decode.loss_cls: 0.1133  decode.loss_mask: 0.1821  decode.loss_dice: 0.2453  decode.d0.loss_cls: 1.0148  decode.d0.loss_mask: 0.1907  decode.d0.loss_dice: 0.2567  decode.d1.loss_cls: 0.2250  decode.d1.loss_mask: 0.1916  decode.d1.loss_dice: 0.2730  decode.d2.loss_cls: 0.1098  decode.d2.loss_mask: 0.1864  decode.d2.loss_dice: 0.2722  decode.d3.loss_cls: 0.1317  decode.d3.loss_mask: 0.1844  decode.d3.loss_dice: 0.2588  decode.d4.loss_cls: 0.0940  decode.d4.loss_mask: 0.1830  decode.d4.loss_dice: 0.2611  decode.d5.loss_cls: 0.0828  decode.d5.loss_mask: 0.1871  decode.d5.loss_dice: 0.2730  decode.d6.loss_cls: 0.1195  decode.d6.loss_mask: 0.1820  decode.d6.loss_dice: 0.2602  decode.d7.loss_cls: 0.1526  decode.d7.loss_mask: 0.1838  decode.d7.loss_dice: 0.2544  decode.d8.loss_cls: 0.1130  decode.d8.loss_mask: 0.1825  decode.d8.loss_dice: 0.2565
08/06 07:28:44 - mmengine - INFO - Iter(train) [ 38050/320000]  base_lr: 8.9232e-05 lr: 8.9232e-06  eta: 1 day, 14:31:13  time: 0.4931  data_time: 0.0111  memory: 5891  grad_norm: 153.6760  loss: 7.3421  decode.loss_cls: 0.1720  decode.loss_mask: 0.2167  decode.loss_dice: 0.2795  decode.d0.loss_cls: 0.8049  decode.d0.loss_mask: 0.2175  decode.d0.loss_dice: 0.2789  decode.d1.loss_cls: 0.1462  decode.d1.loss_mask: 0.2162  decode.d1.loss_dice: 0.3035  decode.d2.loss_cls: 0.1477  decode.d2.loss_mask: 0.2147  decode.d2.loss_dice: 0.2879  decode.d3.loss_cls: 0.1523  decode.d3.loss_mask: 0.2171  decode.d3.loss_dice: 0.2832  decode.d4.loss_cls: 0.1695  decode.d4.loss_mask: 0.2137  decode.d4.loss_dice: 0.2682  decode.d5.loss_cls: 0.1839  decode.d5.loss_mask: 0.2142  decode.d5.loss_dice: 0.2921  decode.d6.loss_cls: 0.1880  decode.d6.loss_mask: 0.2147  decode.d6.loss_dice: 0.2905  decode.d7.loss_cls: 0.1891  decode.d7.loss_mask: 0.2129  decode.d7.loss_dice: 0.2804  decode.d8.loss_cls: 0.1811  decode.d8.loss_mask: 0.2169  decode.d8.loss_dice: 0.2886
08/06 07:29:09 - mmengine - INFO - Iter(train) [ 38100/320000]  base_lr: 8.9218e-05 lr: 8.9218e-06  eta: 1 day, 14:30:50  time: 0.4928  data_time: 0.0108  memory: 5891  grad_norm: 46.2258  loss: 6.2074  decode.loss_cls: 0.0461  decode.loss_mask: 0.2455  decode.loss_dice: 0.2232  decode.d0.loss_cls: 0.8390  decode.d0.loss_mask: 0.2506  decode.d0.loss_dice: 0.2405  decode.d1.loss_cls: 0.1188  decode.d1.loss_mask: 0.2455  decode.d1.loss_dice: 0.2337  decode.d2.loss_cls: 0.0505  decode.d2.loss_mask: 0.2443  decode.d2.loss_dice: 0.2258  decode.d3.loss_cls: 0.0627  decode.d3.loss_mask: 0.2483  decode.d3.loss_dice: 0.2234  decode.d4.loss_cls: 0.0922  decode.d4.loss_mask: 0.2450  decode.d4.loss_dice: 0.2192  decode.d5.loss_cls: 0.0768  decode.d5.loss_mask: 0.2462  decode.d5.loss_dice: 0.2413  decode.d6.loss_cls: 0.0750  decode.d6.loss_mask: 0.2435  decode.d6.loss_dice: 0.2253  decode.d7.loss_cls: 0.0573  decode.d7.loss_mask: 0.2429  decode.d7.loss_dice: 0.2256  decode.d8.loss_cls: 0.0464  decode.d8.loss_mask: 0.2416  decode.d8.loss_dice: 0.2314
08/06 07:29:33 - mmengine - INFO - Iter(train) [ 38150/320000]  base_lr: 8.9204e-05 lr: 8.9204e-06  eta: 1 day, 14:30:26  time: 0.4945  data_time: 0.0110  memory: 5926  grad_norm: 90.1394  loss: 6.1849  decode.loss_cls: 0.0315  decode.loss_mask: 0.2204  decode.loss_dice: 0.2585  decode.d0.loss_cls: 0.9540  decode.d0.loss_mask: 0.2278  decode.d0.loss_dice: 0.2651  decode.d1.loss_cls: 0.0821  decode.d1.loss_mask: 0.2204  decode.d1.loss_dice: 0.2485  decode.d2.loss_cls: 0.0245  decode.d2.loss_mask: 0.2170  decode.d2.loss_dice: 0.2463  decode.d3.loss_cls: 0.0393  decode.d3.loss_mask: 0.2254  decode.d3.loss_dice: 0.2559  decode.d4.loss_cls: 0.0395  decode.d4.loss_mask: 0.2200  decode.d4.loss_dice: 0.2637  decode.d5.loss_cls: 0.0488  decode.d5.loss_mask: 0.2181  decode.d5.loss_dice: 0.2565  decode.d6.loss_cls: 0.0940  decode.d6.loss_mask: 0.2174  decode.d6.loss_dice: 0.2601  decode.d7.loss_cls: 0.0572  decode.d7.loss_mask: 0.2151  decode.d7.loss_dice: 0.2576  decode.d8.loss_cls: 0.0366  decode.d8.loss_mask: 0.2236  decode.d8.loss_dice: 0.2600
08/06 07:29:58 - mmengine - INFO - Iter(train) [ 38200/320000]  base_lr: 8.9189e-05 lr: 8.9189e-06  eta: 1 day, 14:30:02  time: 0.4933  data_time: 0.0111  memory: 5875  grad_norm: 92.1049  loss: 8.3823  decode.loss_cls: 0.1419  decode.loss_mask: 0.3386  decode.loss_dice: 0.3240  decode.d0.loss_cls: 0.8070  decode.d0.loss_mask: 0.3525  decode.d0.loss_dice: 0.3279  decode.d1.loss_cls: 0.1286  decode.d1.loss_mask: 0.3391  decode.d1.loss_dice: 0.3076  decode.d2.loss_cls: 0.1183  decode.d2.loss_mask: 0.3400  decode.d2.loss_dice: 0.3030  decode.d3.loss_cls: 0.1264  decode.d3.loss_mask: 0.3427  decode.d3.loss_dice: 0.2933  decode.d4.loss_cls: 0.1380  decode.d4.loss_mask: 0.3410  decode.d4.loss_dice: 0.3043  decode.d5.loss_cls: 0.0809  decode.d5.loss_mask: 0.3439  decode.d5.loss_dice: 0.3109  decode.d6.loss_cls: 0.1009  decode.d6.loss_mask: 0.3367  decode.d6.loss_dice: 0.3037  decode.d7.loss_cls: 0.1279  decode.d7.loss_mask: 0.3368  decode.d7.loss_dice: 0.3136  decode.d8.loss_cls: 0.1062  decode.d8.loss_mask: 0.3398  decode.d8.loss_dice: 0.3068
08/06 07:30:23 - mmengine - INFO - Iter(train) [ 38250/320000]  base_lr: 8.9175e-05 lr: 8.9175e-06  eta: 1 day, 14:29:38  time: 0.4932  data_time: 0.0109  memory: 5889  grad_norm: 118.1955  loss: 8.1166  decode.loss_cls: 0.1640  decode.loss_mask: 0.3091  decode.loss_dice: 0.3013  decode.d0.loss_cls: 0.9441  decode.d0.loss_mask: 0.3144  decode.d0.loss_dice: 0.2882  decode.d1.loss_cls: 0.1369  decode.d1.loss_mask: 0.3059  decode.d1.loss_dice: 0.2733  decode.d2.loss_cls: 0.1287  decode.d2.loss_mask: 0.3001  decode.d2.loss_dice: 0.2687  decode.d3.loss_cls: 0.1172  decode.d3.loss_mask: 0.3083  decode.d3.loss_dice: 0.2904  decode.d4.loss_cls: 0.1086  decode.d4.loss_mask: 0.3062  decode.d4.loss_dice: 0.2804  decode.d5.loss_cls: 0.1109  decode.d5.loss_mask: 0.3129  decode.d5.loss_dice: 0.2964  decode.d6.loss_cls: 0.1195  decode.d6.loss_mask: 0.3109  decode.d6.loss_dice: 0.2981  decode.d7.loss_cls: 0.1440  decode.d7.loss_mask: 0.3042  decode.d7.loss_dice: 0.2947  decode.d8.loss_cls: 0.1712  decode.d8.loss_mask: 0.3178  decode.d8.loss_dice: 0.2903
08/06 07:30:47 - mmengine - INFO - Iter(train) [ 38300/320000]  base_lr: 8.9161e-05 lr: 8.9161e-06  eta: 1 day, 14:29:14  time: 0.4939  data_time: 0.0111  memory: 5908  grad_norm: 176.7051  loss: 6.4217  decode.loss_cls: 0.0551  decode.loss_mask: 0.2604  decode.loss_dice: 0.2190  decode.d0.loss_cls: 0.8965  decode.d0.loss_mask: 0.2614  decode.d0.loss_dice: 0.2254  decode.d1.loss_cls: 0.1197  decode.d1.loss_mask: 0.2567  decode.d1.loss_dice: 0.2156  decode.d2.loss_cls: 0.1106  decode.d2.loss_mask: 0.2594  decode.d2.loss_dice: 0.2214  decode.d3.loss_cls: 0.1134  decode.d3.loss_mask: 0.2475  decode.d3.loss_dice: 0.2126  decode.d4.loss_cls: 0.1023  decode.d4.loss_mask: 0.2495  decode.d4.loss_dice: 0.2266  decode.d5.loss_cls: 0.0591  decode.d5.loss_mask: 0.2644  decode.d5.loss_dice: 0.2213  decode.d6.loss_cls: 0.0519  decode.d6.loss_mask: 0.2649  decode.d6.loss_dice: 0.2298  decode.d7.loss_cls: 0.0117  decode.d7.loss_mask: 0.2677  decode.d7.loss_dice: 0.2399  decode.d8.loss_cls: 0.0683  decode.d8.loss_mask: 0.2654  decode.d8.loss_dice: 0.2241
08/06 07:31:12 - mmengine - INFO - Iter(train) [ 38350/320000]  base_lr: 8.9147e-05 lr: 8.9147e-06  eta: 1 day, 14:28:50  time: 0.4934  data_time: 0.0110  memory: 5892  grad_norm: 177.6684  loss: 9.3712  decode.loss_cls: 0.2257  decode.loss_mask: 0.3179  decode.loss_dice: 0.2980  decode.d0.loss_cls: 1.0491  decode.d0.loss_mask: 0.3168  decode.d0.loss_dice: 0.3150  decode.d1.loss_cls: 0.2699  decode.d1.loss_mask: 0.3153  decode.d1.loss_dice: 0.3273  decode.d2.loss_cls: 0.2573  decode.d2.loss_mask: 0.3112  decode.d2.loss_dice: 0.2969  decode.d3.loss_cls: 0.2321  decode.d3.loss_mask: 0.3184  decode.d3.loss_dice: 0.3099  decode.d4.loss_cls: 0.1903  decode.d4.loss_mask: 0.3145  decode.d4.loss_dice: 0.3080  decode.d5.loss_cls: 0.1936  decode.d5.loss_mask: 0.3112  decode.d5.loss_dice: 0.3022  decode.d6.loss_cls: 0.2232  decode.d6.loss_mask: 0.3125  decode.d6.loss_dice: 0.3126  decode.d7.loss_cls: 0.2710  decode.d7.loss_mask: 0.3119  decode.d7.loss_dice: 0.3122  decode.d8.loss_cls: 0.2223  decode.d8.loss_mask: 0.3160  decode.d8.loss_dice: 0.3090
08/06 07:31:37 - mmengine - INFO - Iter(train) [ 38400/320000]  base_lr: 8.9132e-05 lr: 8.9132e-06  eta: 1 day, 14:28:26  time: 0.4938  data_time: 0.0110  memory: 5891  grad_norm: 150.3866  loss: 6.8679  decode.loss_cls: 0.0713  decode.loss_mask: 0.2845  decode.loss_dice: 0.2788  decode.d0.loss_cls: 0.7823  decode.d0.loss_mask: 0.2906  decode.d0.loss_dice: 0.3033  decode.d1.loss_cls: 0.0415  decode.d1.loss_mask: 0.2854  decode.d1.loss_dice: 0.2764  decode.d2.loss_cls: 0.0402  decode.d2.loss_mask: 0.2837  decode.d2.loss_dice: 0.2713  decode.d3.loss_cls: 0.0473  decode.d3.loss_mask: 0.2878  decode.d3.loss_dice: 0.2728  decode.d4.loss_cls: 0.0682  decode.d4.loss_mask: 0.2834  decode.d4.loss_dice: 0.2769  decode.d5.loss_cls: 0.0230  decode.d5.loss_mask: 0.2861  decode.d5.loss_dice: 0.2800  decode.d6.loss_cls: 0.0293  decode.d6.loss_mask: 0.2814  decode.d6.loss_dice: 0.2778  decode.d7.loss_cls: 0.0565  decode.d7.loss_mask: 0.2886  decode.d7.loss_dice: 0.2715  decode.d8.loss_cls: 0.0591  decode.d8.loss_mask: 0.2838  decode.d8.loss_dice: 0.2851
08/06 07:32:01 - mmengine - INFO - Iter(train) [ 38450/320000]  base_lr: 8.9118e-05 lr: 8.9118e-06  eta: 1 day, 14:28:02  time: 0.4946  data_time: 0.0113  memory: 5908  grad_norm: 88.1853  loss: 6.5864  decode.loss_cls: 0.1034  decode.loss_mask: 0.2070  decode.loss_dice: 0.2441  decode.d0.loss_cls: 0.8769  decode.d0.loss_mask: 0.2153  decode.d0.loss_dice: 0.2588  decode.d1.loss_cls: 0.1517  decode.d1.loss_mask: 0.2088  decode.d1.loss_dice: 0.2338  decode.d2.loss_cls: 0.1635  decode.d2.loss_mask: 0.2038  decode.d2.loss_dice: 0.2315  decode.d3.loss_cls: 0.1649  decode.d3.loss_mask: 0.2057  decode.d3.loss_dice: 0.2320  decode.d4.loss_cls: 0.1117  decode.d4.loss_mask: 0.2098  decode.d4.loss_dice: 0.2470  decode.d5.loss_cls: 0.1366  decode.d5.loss_mask: 0.2098  decode.d5.loss_dice: 0.2303  decode.d6.loss_cls: 0.1186  decode.d6.loss_mask: 0.2084  decode.d6.loss_dice: 0.2419  decode.d7.loss_cls: 0.1611  decode.d7.loss_mask: 0.2077  decode.d7.loss_dice: 0.2326  decode.d8.loss_cls: 0.1334  decode.d8.loss_mask: 0.2069  decode.d8.loss_dice: 0.2295
08/06 07:32:26 - mmengine - INFO - Iter(train) [ 38500/320000]  base_lr: 8.9104e-05 lr: 8.9104e-06  eta: 1 day, 14:27:39  time: 0.4947  data_time: 0.0111  memory: 5891  grad_norm: 213.5389  loss: 7.3009  decode.loss_cls: 0.1402  decode.loss_mask: 0.2358  decode.loss_dice: 0.2916  decode.d0.loss_cls: 0.9448  decode.d0.loss_mask: 0.2392  decode.d0.loss_dice: 0.2830  decode.d1.loss_cls: 0.1513  decode.d1.loss_mask: 0.2352  decode.d1.loss_dice: 0.2919  decode.d2.loss_cls: 0.1348  decode.d2.loss_mask: 0.2284  decode.d2.loss_dice: 0.2672  decode.d3.loss_cls: 0.0790  decode.d3.loss_mask: 0.2379  decode.d3.loss_dice: 0.2962  decode.d4.loss_cls: 0.0949  decode.d4.loss_mask: 0.2373  decode.d4.loss_dice: 0.2952  decode.d5.loss_cls: 0.1012  decode.d5.loss_mask: 0.2364  decode.d5.loss_dice: 0.2990  decode.d6.loss_cls: 0.1555  decode.d6.loss_mask: 0.2362  decode.d6.loss_dice: 0.2917  decode.d7.loss_cls: 0.1275  decode.d7.loss_mask: 0.2362  decode.d7.loss_dice: 0.2894  decode.d8.loss_cls: 0.1192  decode.d8.loss_mask: 0.2362  decode.d8.loss_dice: 0.2885
08/06 07:32:51 - mmengine - INFO - Iter(train) [ 38550/320000]  base_lr: 8.9090e-05 lr: 8.9090e-06  eta: 1 day, 14:27:15  time: 0.4939  data_time: 0.0112  memory: 5892  grad_norm: 44.7941  loss: 5.4769  decode.loss_cls: 0.0073  decode.loss_mask: 0.2374  decode.loss_dice: 0.2313  decode.d0.loss_cls: 0.7093  decode.d0.loss_mask: 0.2376  decode.d0.loss_dice: 0.2293  decode.d1.loss_cls: 0.0107  decode.d1.loss_mask: 0.2418  decode.d1.loss_dice: 0.2397  decode.d2.loss_cls: 0.0092  decode.d2.loss_mask: 0.2351  decode.d2.loss_dice: 0.2319  decode.d3.loss_cls: 0.0119  decode.d3.loss_mask: 0.2378  decode.d3.loss_dice: 0.2280  decode.d4.loss_cls: 0.0138  decode.d4.loss_mask: 0.2363  decode.d4.loss_dice: 0.2233  decode.d5.loss_cls: 0.0091  decode.d5.loss_mask: 0.2309  decode.d5.loss_dice: 0.2299  decode.d6.loss_cls: 0.0099  decode.d6.loss_mask: 0.2359  decode.d6.loss_dice: 0.2331  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.2363  decode.d7.loss_dice: 0.2376  decode.d8.loss_cls: 0.0083  decode.d8.loss_mask: 0.2346  decode.d8.loss_dice: 0.2326
08/06 07:33:15 - mmengine - INFO - Iter(train) [ 38600/320000]  base_lr: 8.9075e-05 lr: 8.9075e-06  eta: 1 day, 14:26:51  time: 0.4935  data_time: 0.0111  memory: 5907  grad_norm: 112.4434  loss: 5.7307  decode.loss_cls: 0.0789  decode.loss_mask: 0.1958  decode.loss_dice: 0.2199  decode.d0.loss_cls: 0.8440  decode.d0.loss_mask: 0.2009  decode.d0.loss_dice: 0.2320  decode.d1.loss_cls: 0.1111  decode.d1.loss_mask: 0.1967  decode.d1.loss_dice: 0.2096  decode.d2.loss_cls: 0.1080  decode.d2.loss_mask: 0.1934  decode.d2.loss_dice: 0.2171  decode.d3.loss_cls: 0.0758  decode.d3.loss_mask: 0.1922  decode.d3.loss_dice: 0.2021  decode.d4.loss_cls: 0.0654  decode.d4.loss_mask: 0.1930  decode.d4.loss_dice: 0.2178  decode.d5.loss_cls: 0.0664  decode.d5.loss_mask: 0.1924  decode.d5.loss_dice: 0.2161  decode.d6.loss_cls: 0.0707  decode.d6.loss_mask: 0.1957  decode.d6.loss_dice: 0.2299  decode.d7.loss_cls: 0.1001  decode.d7.loss_mask: 0.1961  decode.d7.loss_dice: 0.2188  decode.d8.loss_cls: 0.0755  decode.d8.loss_mask: 0.1954  decode.d8.loss_dice: 0.2200
08/06 07:33:40 - mmengine - INFO - Iter(train) [ 38650/320000]  base_lr: 8.9061e-05 lr: 8.9061e-06  eta: 1 day, 14:26:28  time: 0.4931  data_time: 0.0110  memory: 5891  grad_norm: 117.6890  loss: 6.7856  decode.loss_cls: 0.0588  decode.loss_mask: 0.3005  decode.loss_dice: 0.2393  decode.d0.loss_cls: 0.7897  decode.d0.loss_mask: 0.3117  decode.d0.loss_dice: 0.2529  decode.d1.loss_cls: 0.0661  decode.d1.loss_mask: 0.3089  decode.d1.loss_dice: 0.2439  decode.d2.loss_cls: 0.0733  decode.d2.loss_mask: 0.2948  decode.d2.loss_dice: 0.2413  decode.d3.loss_cls: 0.0749  decode.d3.loss_mask: 0.2982  decode.d3.loss_dice: 0.2393  decode.d4.loss_cls: 0.0703  decode.d4.loss_mask: 0.2994  decode.d4.loss_dice: 0.2441  decode.d5.loss_cls: 0.0632  decode.d5.loss_mask: 0.2921  decode.d5.loss_dice: 0.2422  decode.d6.loss_cls: 0.0557  decode.d6.loss_mask: 0.2927  decode.d6.loss_dice: 0.2410  decode.d7.loss_cls: 0.0625  decode.d7.loss_mask: 0.2953  decode.d7.loss_dice: 0.2451  decode.d8.loss_cls: 0.0515  decode.d8.loss_mask: 0.2967  decode.d8.loss_dice: 0.2402
08/06 07:34:05 - mmengine - INFO - Iter(train) [ 38700/320000]  base_lr: 8.9047e-05 lr: 8.9047e-06  eta: 1 day, 14:26:04  time: 0.4933  data_time: 0.0109  memory: 5891  grad_norm: 345.2181  loss: 7.0105  decode.loss_cls: 0.0379  decode.loss_mask: 0.3192  decode.loss_dice: 0.2687  decode.d0.loss_cls: 0.7824  decode.d0.loss_mask: 0.3251  decode.d0.loss_dice: 0.2805  decode.d1.loss_cls: 0.0558  decode.d1.loss_mask: 0.3224  decode.d1.loss_dice: 0.2689  decode.d2.loss_cls: 0.0475  decode.d2.loss_mask: 0.3167  decode.d2.loss_dice: 0.2702  decode.d3.loss_cls: 0.0366  decode.d3.loss_mask: 0.3163  decode.d3.loss_dice: 0.2696  decode.d4.loss_cls: 0.0283  decode.d4.loss_mask: 0.3213  decode.d4.loss_dice: 0.2648  decode.d5.loss_cls: 0.0313  decode.d5.loss_mask: 0.3191  decode.d5.loss_dice: 0.2751  decode.d6.loss_cls: 0.0333  decode.d6.loss_mask: 0.3131  decode.d6.loss_dice: 0.2643  decode.d7.loss_cls: 0.0326  decode.d7.loss_mask: 0.3189  decode.d7.loss_dice: 0.2698  decode.d8.loss_cls: 0.0340  decode.d8.loss_mask: 0.3168  decode.d8.loss_dice: 0.2699
08/06 07:34:30 - mmengine - INFO - Iter(train) [ 38750/320000]  base_lr: 8.9033e-05 lr: 8.9033e-06  eta: 1 day, 14:25:40  time: 0.4932  data_time: 0.0110  memory: 5929  grad_norm: 175.6059  loss: 6.6073  decode.loss_cls: 0.1923  decode.loss_mask: 0.1785  decode.loss_dice: 0.2169  decode.d0.loss_cls: 0.8411  decode.d0.loss_mask: 0.1778  decode.d0.loss_dice: 0.2050  decode.d1.loss_cls: 0.1289  decode.d1.loss_mask: 0.1774  decode.d1.loss_dice: 0.2191  decode.d2.loss_cls: 0.1789  decode.d2.loss_mask: 0.1793  decode.d2.loss_dice: 0.2109  decode.d3.loss_cls: 0.2381  decode.d3.loss_mask: 0.1831  decode.d3.loss_dice: 0.2164  decode.d4.loss_cls: 0.2477  decode.d4.loss_mask: 0.1801  decode.d4.loss_dice: 0.2017  decode.d5.loss_cls: 0.2022  decode.d5.loss_mask: 0.1752  decode.d5.loss_dice: 0.2018  decode.d6.loss_cls: 0.2116  decode.d6.loss_mask: 0.1794  decode.d6.loss_dice: 0.2057  decode.d7.loss_cls: 0.2351  decode.d7.loss_mask: 0.1968  decode.d7.loss_dice: 0.2261  decode.d8.loss_cls: 0.1958  decode.d8.loss_mask: 0.1877  decode.d8.loss_dice: 0.2167
08/06 07:34:54 - mmengine - INFO - Iter(train) [ 38800/320000]  base_lr: 8.9018e-05 lr: 8.9018e-06  eta: 1 day, 14:25:16  time: 0.4936  data_time: 0.0109  memory: 5893  grad_norm: 82.2823  loss: 5.8295  decode.loss_cls: 0.0636  decode.loss_mask: 0.1980  decode.loss_dice: 0.2062  decode.d0.loss_cls: 0.8953  decode.d0.loss_mask: 0.1970  decode.d0.loss_dice: 0.2148  decode.d1.loss_cls: 0.1766  decode.d1.loss_mask: 0.2031  decode.d1.loss_dice: 0.2204  decode.d2.loss_cls: 0.1218  decode.d2.loss_mask: 0.1999  decode.d2.loss_dice: 0.2069  decode.d3.loss_cls: 0.0803  decode.d3.loss_mask: 0.2040  decode.d3.loss_dice: 0.2318  decode.d4.loss_cls: 0.0632  decode.d4.loss_mask: 0.2017  decode.d4.loss_dice: 0.2116  decode.d5.loss_cls: 0.0821  decode.d5.loss_mask: 0.1983  decode.d5.loss_dice: 0.2127  decode.d6.loss_cls: 0.0591  decode.d6.loss_mask: 0.2000  decode.d6.loss_dice: 0.2193  decode.d7.loss_cls: 0.0703  decode.d7.loss_mask: 0.2005  decode.d7.loss_dice: 0.2252  decode.d8.loss_cls: 0.0555  decode.d8.loss_mask: 0.1983  decode.d8.loss_dice: 0.2118
08/06 07:35:19 - mmengine - INFO - Iter(train) [ 38850/320000]  base_lr: 8.9004e-05 lr: 8.9004e-06  eta: 1 day, 14:24:52  time: 0.4936  data_time: 0.0111  memory: 5892  grad_norm: 72.8842  loss: 6.9338  decode.loss_cls: 0.0973  decode.loss_mask: 0.2434  decode.loss_dice: 0.2532  decode.d0.loss_cls: 0.9100  decode.d0.loss_mask: 0.2436  decode.d0.loss_dice: 0.2457  decode.d1.loss_cls: 0.0754  decode.d1.loss_mask: 0.2439  decode.d1.loss_dice: 0.2544  decode.d2.loss_cls: 0.0789  decode.d2.loss_mask: 0.2466  decode.d2.loss_dice: 0.2536  decode.d3.loss_cls: 0.1565  decode.d3.loss_mask: 0.2430  decode.d3.loss_dice: 0.2602  decode.d4.loss_cls: 0.1187  decode.d4.loss_mask: 0.2467  decode.d4.loss_dice: 0.2635  decode.d5.loss_cls: 0.1545  decode.d5.loss_mask: 0.2448  decode.d5.loss_dice: 0.2565  decode.d6.loss_cls: 0.1623  decode.d6.loss_mask: 0.2473  decode.d6.loss_dice: 0.2557  decode.d7.loss_cls: 0.0894  decode.d7.loss_mask: 0.2432  decode.d7.loss_dice: 0.2621  decode.d8.loss_cls: 0.0830  decode.d8.loss_mask: 0.2440  decode.d8.loss_dice: 0.2565
08/06 07:35:44 - mmengine - INFO - Iter(train) [ 38900/320000]  base_lr: 8.8990e-05 lr: 8.8990e-06  eta: 1 day, 14:24:28  time: 0.4936  data_time: 0.0112  memory: 5892  grad_norm: 46.6565  loss: 6.6488  decode.loss_cls: 0.1211  decode.loss_mask: 0.2368  decode.loss_dice: 0.2622  decode.d0.loss_cls: 0.7413  decode.d0.loss_mask: 0.2342  decode.d0.loss_dice: 0.2504  decode.d1.loss_cls: 0.1290  decode.d1.loss_mask: 0.2313  decode.d1.loss_dice: 0.2640  decode.d2.loss_cls: 0.1044  decode.d2.loss_mask: 0.2298  decode.d2.loss_dice: 0.2507  decode.d3.loss_cls: 0.1077  decode.d3.loss_mask: 0.2323  decode.d3.loss_dice: 0.2269  decode.d4.loss_cls: 0.1219  decode.d4.loss_mask: 0.2344  decode.d4.loss_dice: 0.2612  decode.d5.loss_cls: 0.1224  decode.d5.loss_mask: 0.2345  decode.d5.loss_dice: 0.2618  decode.d6.loss_cls: 0.1028  decode.d6.loss_mask: 0.2316  decode.d6.loss_dice: 0.2634  decode.d7.loss_cls: 0.1018  decode.d7.loss_mask: 0.2311  decode.d7.loss_dice: 0.2675  decode.d8.loss_cls: 0.1089  decode.d8.loss_mask: 0.2316  decode.d8.loss_dice: 0.2516
08/06 07:36:09 - mmengine - INFO - Iter(train) [ 38950/320000]  base_lr: 8.8976e-05 lr: 8.8976e-06  eta: 1 day, 14:24:06  time: 0.4944  data_time: 0.0112  memory: 5907  grad_norm: 201.1549  loss: 7.6949  decode.loss_cls: 0.1354  decode.loss_mask: 0.2720  decode.loss_dice: 0.3154  decode.d0.loss_cls: 0.9722  decode.d0.loss_mask: 0.2512  decode.d0.loss_dice: 0.3032  decode.d1.loss_cls: 0.1330  decode.d1.loss_mask: 0.2648  decode.d1.loss_dice: 0.2975  decode.d2.loss_cls: 0.0983  decode.d2.loss_mask: 0.2699  decode.d2.loss_dice: 0.2952  decode.d3.loss_cls: 0.1239  decode.d3.loss_mask: 0.2735  decode.d3.loss_dice: 0.2987  decode.d4.loss_cls: 0.1060  decode.d4.loss_mask: 0.2728  decode.d4.loss_dice: 0.3055  decode.d5.loss_cls: 0.0995  decode.d5.loss_mask: 0.2589  decode.d5.loss_dice: 0.3074  decode.d6.loss_cls: 0.0784  decode.d6.loss_mask: 0.2647  decode.d6.loss_dice: 0.3131  decode.d7.loss_cls: 0.1051  decode.d7.loss_mask: 0.2751  decode.d7.loss_dice: 0.3249  decode.d8.loss_cls: 0.0991  decode.d8.loss_mask: 0.2668  decode.d8.loss_dice: 0.3134
08/06 07:36:33 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 07:36:33 - mmengine - INFO - Iter(train) [ 39000/320000]  base_lr: 8.8961e-05 lr: 8.8961e-06  eta: 1 day, 14:23:42  time: 0.4939  data_time: 0.0111  memory: 5876  grad_norm: 312.4434  loss: 8.4461  decode.loss_cls: 0.2468  decode.loss_mask: 0.2472  decode.loss_dice: 0.3216  decode.d0.loss_cls: 0.9196  decode.d0.loss_mask: 0.2503  decode.d0.loss_dice: 0.3221  decode.d1.loss_cls: 0.2259  decode.d1.loss_mask: 0.2461  decode.d1.loss_dice: 0.3064  decode.d2.loss_cls: 0.1764  decode.d2.loss_mask: 0.2493  decode.d2.loss_dice: 0.2908  decode.d3.loss_cls: 0.2045  decode.d3.loss_mask: 0.2506  decode.d3.loss_dice: 0.2985  decode.d4.loss_cls: 0.2635  decode.d4.loss_mask: 0.2448  decode.d4.loss_dice: 0.2944  decode.d5.loss_cls: 0.2166  decode.d5.loss_mask: 0.2438  decode.d5.loss_dice: 0.3183  decode.d6.loss_cls: 0.1586  decode.d6.loss_mask: 0.2642  decode.d6.loss_dice: 0.2969  decode.d7.loss_cls: 0.2668  decode.d7.loss_mask: 0.2531  decode.d7.loss_dice: 0.3164  decode.d8.loss_cls: 0.1803  decode.d8.loss_mask: 0.2577  decode.d8.loss_dice: 0.3143
08/06 07:36:58 - mmengine - INFO - Iter(train) [ 39050/320000]  base_lr: 8.8947e-05 lr: 8.8947e-06  eta: 1 day, 14:23:18  time: 0.4936  data_time: 0.0112  memory: 5889  grad_norm: 129.8705  loss: 7.5308  decode.loss_cls: 0.1631  decode.loss_mask: 0.2721  decode.loss_dice: 0.2712  decode.d0.loss_cls: 0.8411  decode.d0.loss_mask: 0.2814  decode.d0.loss_dice: 0.2873  decode.d1.loss_cls: 0.1425  decode.d1.loss_mask: 0.2755  decode.d1.loss_dice: 0.2626  decode.d2.loss_cls: 0.1534  decode.d2.loss_mask: 0.2738  decode.d2.loss_dice: 0.2666  decode.d3.loss_cls: 0.1204  decode.d3.loss_mask: 0.2720  decode.d3.loss_dice: 0.2741  decode.d4.loss_cls: 0.1262  decode.d4.loss_mask: 0.2743  decode.d4.loss_dice: 0.2945  decode.d5.loss_cls: 0.1219  decode.d5.loss_mask: 0.2802  decode.d5.loss_dice: 0.2713  decode.d6.loss_cls: 0.1120  decode.d6.loss_mask: 0.2882  decode.d6.loss_dice: 0.2728  decode.d7.loss_cls: 0.1383  decode.d7.loss_mask: 0.2721  decode.d7.loss_dice: 0.2612  decode.d8.loss_cls: 0.1199  decode.d8.loss_mask: 0.2770  decode.d8.loss_dice: 0.2639
08/06 07:37:23 - mmengine - INFO - Iter(train) [ 39100/320000]  base_lr: 8.8933e-05 lr: 8.8933e-06  eta: 1 day, 14:22:54  time: 0.4947  data_time: 0.0112  memory: 5889  grad_norm: 113.9362  loss: 6.5296  decode.loss_cls: 0.0953  decode.loss_mask: 0.2079  decode.loss_dice: 0.2410  decode.d0.loss_cls: 0.9257  decode.d0.loss_mask: 0.2145  decode.d0.loss_dice: 0.2594  decode.d1.loss_cls: 0.1171  decode.d1.loss_mask: 0.2105  decode.d1.loss_dice: 0.2477  decode.d2.loss_cls: 0.1419  decode.d2.loss_mask: 0.2087  decode.d2.loss_dice: 0.2472  decode.d3.loss_cls: 0.1488  decode.d3.loss_mask: 0.2070  decode.d3.loss_dice: 0.2399  decode.d4.loss_cls: 0.1035  decode.d4.loss_mask: 0.2069  decode.d4.loss_dice: 0.2471  decode.d5.loss_cls: 0.1455  decode.d5.loss_mask: 0.2085  decode.d5.loss_dice: 0.2414  decode.d6.loss_cls: 0.1030  decode.d6.loss_mask: 0.2107  decode.d6.loss_dice: 0.2417  decode.d7.loss_cls: 0.0988  decode.d7.loss_mask: 0.2073  decode.d7.loss_dice: 0.2461  decode.d8.loss_cls: 0.1010  decode.d8.loss_mask: 0.2120  decode.d8.loss_dice: 0.2437
08/06 07:37:48 - mmengine - INFO - Iter(train) [ 39150/320000]  base_lr: 8.8919e-05 lr: 8.8919e-06  eta: 1 day, 14:22:31  time: 0.4941  data_time: 0.0111  memory: 5875  grad_norm: 124.9603  loss: 7.1659  decode.loss_cls: 0.1369  decode.loss_mask: 0.2450  decode.loss_dice: 0.2424  decode.d0.loss_cls: 0.8419  decode.d0.loss_mask: 0.2566  decode.d0.loss_dice: 0.2758  decode.d1.loss_cls: 0.1254  decode.d1.loss_mask: 0.2451  decode.d1.loss_dice: 0.2491  decode.d2.loss_cls: 0.1427  decode.d2.loss_mask: 0.2435  decode.d2.loss_dice: 0.2466  decode.d3.loss_cls: 0.1579  decode.d3.loss_mask: 0.2428  decode.d3.loss_dice: 0.2421  decode.d4.loss_cls: 0.1743  decode.d4.loss_mask: 0.2418  decode.d4.loss_dice: 0.2518  decode.d5.loss_cls: 0.1537  decode.d5.loss_mask: 0.2489  decode.d5.loss_dice: 0.2510  decode.d6.loss_cls: 0.1357  decode.d6.loss_mask: 0.2427  decode.d6.loss_dice: 0.2458  decode.d7.loss_cls: 0.1807  decode.d7.loss_mask: 0.2481  decode.d7.loss_dice: 0.2509  decode.d8.loss_cls: 0.1478  decode.d8.loss_mask: 0.2483  decode.d8.loss_dice: 0.2506
08/06 07:38:12 - mmengine - INFO - Iter(train) [ 39200/320000]  base_lr: 8.8904e-05 lr: 8.8904e-06  eta: 1 day, 14:22:07  time: 0.4932  data_time: 0.0112  memory: 5875  grad_norm: 116.5869  loss: 8.5054  decode.loss_cls: 0.3201  decode.loss_mask: 0.2134  decode.loss_dice: 0.2944  decode.d0.loss_cls: 1.0787  decode.d0.loss_mask: 0.2173  decode.d0.loss_dice: 0.2876  decode.d1.loss_cls: 0.2477  decode.d1.loss_mask: 0.2129  decode.d1.loss_dice: 0.2796  decode.d2.loss_cls: 0.2281  decode.d2.loss_mask: 0.2114  decode.d2.loss_dice: 0.2994  decode.d3.loss_cls: 0.1964  decode.d3.loss_mask: 0.2105  decode.d3.loss_dice: 0.2822  decode.d4.loss_cls: 0.2755  decode.d4.loss_mask: 0.2111  decode.d4.loss_dice: 0.2903  decode.d5.loss_cls: 0.2931  decode.d5.loss_mask: 0.2107  decode.d5.loss_dice: 0.2657  decode.d6.loss_cls: 0.3445  decode.d6.loss_mask: 0.2113  decode.d6.loss_dice: 0.2569  decode.d7.loss_cls: 0.3246  decode.d7.loss_mask: 0.2109  decode.d7.loss_dice: 0.2780  decode.d8.loss_cls: 0.2568  decode.d8.loss_mask: 0.2117  decode.d8.loss_dice: 0.2847
08/06 07:38:37 - mmengine - INFO - Iter(train) [ 39250/320000]  base_lr: 8.8890e-05 lr: 8.8890e-06  eta: 1 day, 14:21:43  time: 0.4939  data_time: 0.0111  memory: 5893  grad_norm: 69.4403  loss: 6.8714  decode.loss_cls: 0.0721  decode.loss_mask: 0.2394  decode.loss_dice: 0.2975  decode.d0.loss_cls: 0.9078  decode.d0.loss_mask: 0.2315  decode.d0.loss_dice: 0.3210  decode.d1.loss_cls: 0.1115  decode.d1.loss_mask: 0.2376  decode.d1.loss_dice: 0.3101  decode.d2.loss_cls: 0.0747  decode.d2.loss_mask: 0.2388  decode.d2.loss_dice: 0.2944  decode.d3.loss_cls: 0.0999  decode.d3.loss_mask: 0.2345  decode.d3.loss_dice: 0.2590  decode.d4.loss_cls: 0.0788  decode.d4.loss_mask: 0.2322  decode.d4.loss_dice: 0.2749  decode.d5.loss_cls: 0.0691  decode.d5.loss_mask: 0.2341  decode.d5.loss_dice: 0.2912  decode.d6.loss_cls: 0.0498  decode.d6.loss_mask: 0.2358  decode.d6.loss_dice: 0.2982  decode.d7.loss_cls: 0.0674  decode.d7.loss_mask: 0.2323  decode.d7.loss_dice: 0.2829  decode.d8.loss_cls: 0.0669  decode.d8.loss_mask: 0.2395  decode.d8.loss_dice: 0.2886
08/06 07:39:02 - mmengine - INFO - Iter(train) [ 39300/320000]  base_lr: 8.8876e-05 lr: 8.8876e-06  eta: 1 day, 14:21:19  time: 0.4952  data_time: 0.0112  memory: 5929  grad_norm: 130.2543  loss: 7.1438  decode.loss_cls: 0.1340  decode.loss_mask: 0.2299  decode.loss_dice: 0.2691  decode.d0.loss_cls: 0.9459  decode.d0.loss_mask: 0.2321  decode.d0.loss_dice: 0.2553  decode.d1.loss_cls: 0.1445  decode.d1.loss_mask: 0.2314  decode.d1.loss_dice: 0.2665  decode.d2.loss_cls: 0.1003  decode.d2.loss_mask: 0.2291  decode.d2.loss_dice: 0.2848  decode.d3.loss_cls: 0.1073  decode.d3.loss_mask: 0.2341  decode.d3.loss_dice: 0.2715  decode.d4.loss_cls: 0.1070  decode.d4.loss_mask: 0.2319  decode.d4.loss_dice: 0.2671  decode.d5.loss_cls: 0.1280  decode.d5.loss_mask: 0.2272  decode.d5.loss_dice: 0.2686  decode.d6.loss_cls: 0.1373  decode.d6.loss_mask: 0.2331  decode.d6.loss_dice: 0.2796  decode.d7.loss_cls: 0.1498  decode.d7.loss_mask: 0.2329  decode.d7.loss_dice: 0.2766  decode.d8.loss_cls: 0.1552  decode.d8.loss_mask: 0.2301  decode.d8.loss_dice: 0.2835
08/06 07:39:26 - mmengine - INFO - Iter(train) [ 39350/320000]  base_lr: 8.8862e-05 lr: 8.8862e-06  eta: 1 day, 14:20:55  time: 0.4938  data_time: 0.0113  memory: 5927  grad_norm: 122.8100  loss: 7.0043  decode.loss_cls: 0.0566  decode.loss_mask: 0.2394  decode.loss_dice: 0.2910  decode.d0.loss_cls: 0.8684  decode.d0.loss_mask: 0.2436  decode.d0.loss_dice: 0.2777  decode.d1.loss_cls: 0.1972  decode.d1.loss_mask: 0.2346  decode.d1.loss_dice: 0.2940  decode.d2.loss_cls: 0.1199  decode.d2.loss_mask: 0.2381  decode.d2.loss_dice: 0.2893  decode.d3.loss_cls: 0.1089  decode.d3.loss_mask: 0.2405  decode.d3.loss_dice: 0.2807  decode.d4.loss_cls: 0.0742  decode.d4.loss_mask: 0.2409  decode.d4.loss_dice: 0.2943  decode.d5.loss_cls: 0.0712  decode.d5.loss_mask: 0.2405  decode.d5.loss_dice: 0.2832  decode.d6.loss_cls: 0.0851  decode.d6.loss_mask: 0.2388  decode.d6.loss_dice: 0.2868  decode.d7.loss_cls: 0.0719  decode.d7.loss_mask: 0.2390  decode.d7.loss_dice: 0.2812  decode.d8.loss_cls: 0.0861  decode.d8.loss_mask: 0.2394  decode.d8.loss_dice: 0.2919
08/06 07:39:51 - mmengine - INFO - Iter(train) [ 39400/320000]  base_lr: 8.8847e-05 lr: 8.8847e-06  eta: 1 day, 14:20:32  time: 0.4942  data_time: 0.0111  memory: 5892  grad_norm: 104.3312  loss: 8.2342  decode.loss_cls: 0.2361  decode.loss_mask: 0.2300  decode.loss_dice: 0.2834  decode.d0.loss_cls: 1.0810  decode.d0.loss_mask: 0.2297  decode.d0.loss_dice: 0.2828  decode.d1.loss_cls: 0.2307  decode.d1.loss_mask: 0.2288  decode.d1.loss_dice: 0.2931  decode.d2.loss_cls: 0.1727  decode.d2.loss_mask: 0.2307  decode.d2.loss_dice: 0.2837  decode.d3.loss_cls: 0.1735  decode.d3.loss_mask: 0.2281  decode.d3.loss_dice: 0.3054  decode.d4.loss_cls: 0.2185  decode.d4.loss_mask: 0.2267  decode.d4.loss_dice: 0.3059  decode.d5.loss_cls: 0.2302  decode.d5.loss_mask: 0.2273  decode.d5.loss_dice: 0.2663  decode.d6.loss_cls: 0.1992  decode.d6.loss_mask: 0.2293  decode.d6.loss_dice: 0.2922  decode.d7.loss_cls: 0.2641  decode.d7.loss_mask: 0.2266  decode.d7.loss_dice: 0.2971  decode.d8.loss_cls: 0.2232  decode.d8.loss_mask: 0.2296  decode.d8.loss_dice: 0.3082
08/06 07:40:16 - mmengine - INFO - Iter(train) [ 39450/320000]  base_lr: 8.8833e-05 lr: 8.8833e-06  eta: 1 day, 14:20:08  time: 0.4961  data_time: 0.0114  memory: 5890  grad_norm: 169.1770  loss: 8.1955  decode.loss_cls: 0.1872  decode.loss_mask: 0.2601  decode.loss_dice: 0.3076  decode.d0.loss_cls: 0.9198  decode.d0.loss_mask: 0.2622  decode.d0.loss_dice: 0.3130  decode.d1.loss_cls: 0.1428  decode.d1.loss_mask: 0.2704  decode.d1.loss_dice: 0.2966  decode.d2.loss_cls: 0.2074  decode.d2.loss_mask: 0.2601  decode.d2.loss_dice: 0.3141  decode.d3.loss_cls: 0.1768  decode.d3.loss_mask: 0.2591  decode.d3.loss_dice: 0.2953  decode.d4.loss_cls: 0.1680  decode.d4.loss_mask: 0.2606  decode.d4.loss_dice: 0.3081  decode.d5.loss_cls: 0.1863  decode.d5.loss_mask: 0.2612  decode.d5.loss_dice: 0.3189  decode.d6.loss_cls: 0.1840  decode.d6.loss_mask: 0.2591  decode.d6.loss_dice: 0.3036  decode.d7.loss_cls: 0.1598  decode.d7.loss_mask: 0.2618  decode.d7.loss_dice: 0.3225  decode.d8.loss_cls: 0.1923  decode.d8.loss_mask: 0.2571  decode.d8.loss_dice: 0.2796
08/06 07:40:41 - mmengine - INFO - Iter(train) [ 39500/320000]  base_lr: 8.8819e-05 lr: 8.8819e-06  eta: 1 day, 14:19:45  time: 0.4937  data_time: 0.0110  memory: 5892  grad_norm: 96.7543  loss: 6.9017  decode.loss_cls: 0.1230  decode.loss_mask: 0.1927  decode.loss_dice: 0.2527  decode.d0.loss_cls: 0.9121  decode.d0.loss_mask: 0.1966  decode.d0.loss_dice: 0.2617  decode.d1.loss_cls: 0.2461  decode.d1.loss_mask: 0.1936  decode.d1.loss_dice: 0.2598  decode.d2.loss_cls: 0.1948  decode.d2.loss_mask: 0.1944  decode.d2.loss_dice: 0.2250  decode.d3.loss_cls: 0.1229  decode.d3.loss_mask: 0.1921  decode.d3.loss_dice: 0.2524  decode.d4.loss_cls: 0.1458  decode.d4.loss_mask: 0.1940  decode.d4.loss_dice: 0.2568  decode.d5.loss_cls: 0.2189  decode.d5.loss_mask: 0.1945  decode.d5.loss_dice: 0.2485  decode.d6.loss_cls: 0.1949  decode.d6.loss_mask: 0.1949  decode.d6.loss_dice: 0.2524  decode.d7.loss_cls: 0.1487  decode.d7.loss_mask: 0.1951  decode.d7.loss_dice: 0.2505  decode.d8.loss_cls: 0.1372  decode.d8.loss_mask: 0.1934  decode.d8.loss_dice: 0.2563
08/06 07:41:05 - mmengine - INFO - Iter(train) [ 39550/320000]  base_lr: 8.8805e-05 lr: 8.8805e-06  eta: 1 day, 14:19:22  time: 0.4945  data_time: 0.0112  memory: 5890  grad_norm: 687.1879  loss: 6.8759  decode.loss_cls: 0.0853  decode.loss_mask: 0.2712  decode.loss_dice: 0.3079  decode.d0.loss_cls: 0.8880  decode.d0.loss_mask: 0.2313  decode.d0.loss_dice: 0.2620  decode.d1.loss_cls: 0.1519  decode.d1.loss_mask: 0.2306  decode.d1.loss_dice: 0.2632  decode.d2.loss_cls: 0.0431  decode.d2.loss_mask: 0.2384  decode.d2.loss_dice: 0.3038  decode.d3.loss_cls: 0.0362  decode.d3.loss_mask: 0.2356  decode.d3.loss_dice: 0.2782  decode.d4.loss_cls: 0.0453  decode.d4.loss_mask: 0.2363  decode.d4.loss_dice: 0.2857  decode.d5.loss_cls: 0.0559  decode.d5.loss_mask: 0.2532  decode.d5.loss_dice: 0.2803  decode.d6.loss_cls: 0.0763  decode.d6.loss_mask: 0.2488  decode.d6.loss_dice: 0.2816  decode.d7.loss_cls: 0.0997  decode.d7.loss_mask: 0.2515  decode.d7.loss_dice: 0.2866  decode.d8.loss_cls: 0.0897  decode.d8.loss_mask: 0.2633  decode.d8.loss_dice: 0.2948
08/06 07:41:30 - mmengine - INFO - Iter(train) [ 39600/320000]  base_lr: 8.8790e-05 lr: 8.8790e-06  eta: 1 day, 14:18:58  time: 0.4942  data_time: 0.0112  memory: 5909  grad_norm: 196.2025  loss: 8.0196  decode.loss_cls: 0.1080  decode.loss_mask: 0.2914  decode.loss_dice: 0.3146  decode.d0.loss_cls: 1.0859  decode.d0.loss_mask: 0.2851  decode.d0.loss_dice: 0.2920  decode.d1.loss_cls: 0.1080  decode.d1.loss_mask: 0.2834  decode.d1.loss_dice: 0.3135  decode.d2.loss_cls: 0.1347  decode.d2.loss_mask: 0.2819  decode.d2.loss_dice: 0.3084  decode.d3.loss_cls: 0.1006  decode.d3.loss_mask: 0.2788  decode.d3.loss_dice: 0.2996  decode.d4.loss_cls: 0.0740  decode.d4.loss_mask: 0.2787  decode.d4.loss_dice: 0.3039  decode.d5.loss_cls: 0.1116  decode.d5.loss_mask: 0.2791  decode.d5.loss_dice: 0.3102  decode.d6.loss_cls: 0.1518  decode.d6.loss_mask: 0.2798  decode.d6.loss_dice: 0.3158  decode.d7.loss_cls: 0.1041  decode.d7.loss_mask: 0.2757  decode.d7.loss_dice: 0.3167  decode.d8.loss_cls: 0.1095  decode.d8.loss_mask: 0.2961  decode.d8.loss_dice: 0.3266
08/06 07:41:55 - mmengine - INFO - Iter(train) [ 39650/320000]  base_lr: 8.8776e-05 lr: 8.8776e-06  eta: 1 day, 14:18:34  time: 0.4938  data_time: 0.0112  memory: 5908  grad_norm: 145.6455  loss: 8.5005  decode.loss_cls: 0.0907  decode.loss_mask: 0.3552  decode.loss_dice: 0.3211  decode.d0.loss_cls: 0.8115  decode.d0.loss_mask: 0.3602  decode.d0.loss_dice: 0.3536  decode.d1.loss_cls: 0.1176  decode.d1.loss_mask: 0.3560  decode.d1.loss_dice: 0.2996  decode.d2.loss_cls: 0.1088  decode.d2.loss_mask: 0.3476  decode.d2.loss_dice: 0.3077  decode.d3.loss_cls: 0.1295  decode.d3.loss_mask: 0.3578  decode.d3.loss_dice: 0.3129  decode.d4.loss_cls: 0.1147  decode.d4.loss_mask: 0.3599  decode.d4.loss_dice: 0.3317  decode.d5.loss_cls: 0.0935  decode.d5.loss_mask: 0.3534  decode.d5.loss_dice: 0.3095  decode.d6.loss_cls: 0.1090  decode.d6.loss_mask: 0.3538  decode.d6.loss_dice: 0.3168  decode.d7.loss_cls: 0.1005  decode.d7.loss_mask: 0.3571  decode.d7.loss_dice: 0.2994  decode.d8.loss_cls: 0.0981  decode.d8.loss_mask: 0.3556  decode.d8.loss_dice: 0.3177
08/06 07:42:20 - mmengine - INFO - Iter(train) [ 39700/320000]  base_lr: 8.8762e-05 lr: 8.8762e-06  eta: 1 day, 14:18:10  time: 0.4959  data_time: 0.0112  memory: 5929  grad_norm: 76.7335  loss: 7.0981  decode.loss_cls: 0.0822  decode.loss_mask: 0.2887  decode.loss_dice: 0.2840  decode.d0.loss_cls: 0.8463  decode.d0.loss_mask: 0.2898  decode.d0.loss_dice: 0.2763  decode.d1.loss_cls: 0.0891  decode.d1.loss_mask: 0.2827  decode.d1.loss_dice: 0.2779  decode.d2.loss_cls: 0.0678  decode.d2.loss_mask: 0.2828  decode.d2.loss_dice: 0.2688  decode.d3.loss_cls: 0.0651  decode.d3.loss_mask: 0.2826  decode.d3.loss_dice: 0.2784  decode.d4.loss_cls: 0.0648  decode.d4.loss_mask: 0.2836  decode.d4.loss_dice: 0.2863  decode.d5.loss_cls: 0.0598  decode.d5.loss_mask: 0.2820  decode.d5.loss_dice: 0.2607  decode.d6.loss_cls: 0.0633  decode.d6.loss_mask: 0.2848  decode.d6.loss_dice: 0.2822  decode.d7.loss_cls: 0.0625  decode.d7.loss_mask: 0.2824  decode.d7.loss_dice: 0.2744  decode.d8.loss_cls: 0.1074  decode.d8.loss_mask: 0.2814  decode.d8.loss_dice: 0.2601
08/06 07:42:44 - mmengine - INFO - Iter(train) [ 39750/320000]  base_lr: 8.8748e-05 lr: 8.8748e-06  eta: 1 day, 14:17:47  time: 0.4934  data_time: 0.0110  memory: 5908  grad_norm: 94.2052  loss: 6.1135  decode.loss_cls: 0.0226  decode.loss_mask: 0.2362  decode.loss_dice: 0.2523  decode.d0.loss_cls: 0.9015  decode.d0.loss_mask: 0.2402  decode.d0.loss_dice: 0.2553  decode.d1.loss_cls: 0.0607  decode.d1.loss_mask: 0.2336  decode.d1.loss_dice: 0.2558  decode.d2.loss_cls: 0.0469  decode.d2.loss_mask: 0.2322  decode.d2.loss_dice: 0.2474  decode.d3.loss_cls: 0.0351  decode.d3.loss_mask: 0.2354  decode.d3.loss_dice: 0.2573  decode.d4.loss_cls: 0.0341  decode.d4.loss_mask: 0.2350  decode.d4.loss_dice: 0.2494  decode.d5.loss_cls: 0.0236  decode.d5.loss_mask: 0.2425  decode.d5.loss_dice: 0.2667  decode.d6.loss_cls: 0.0329  decode.d6.loss_mask: 0.2384  decode.d6.loss_dice: 0.2604  decode.d7.loss_cls: 0.0270  decode.d7.loss_mask: 0.2329  decode.d7.loss_dice: 0.2559  decode.d8.loss_cls: 0.0212  decode.d8.loss_mask: 0.2341  decode.d8.loss_dice: 0.2469
08/06 07:43:09 - mmengine - INFO - Iter(train) [ 39800/320000]  base_lr: 8.8733e-05 lr: 8.8733e-06  eta: 1 day, 14:17:22  time: 0.4917  data_time: 0.0107  memory: 5907  grad_norm: 163.3590  loss: 7.2914  decode.loss_cls: 0.0877  decode.loss_mask: 0.3178  decode.loss_dice: 0.2537  decode.d0.loss_cls: 0.8777  decode.d0.loss_mask: 0.2243  decode.d0.loss_dice: 0.2725  decode.d1.loss_cls: 0.2897  decode.d1.loss_mask: 0.2157  decode.d1.loss_dice: 0.2510  decode.d2.loss_cls: 0.2042  decode.d2.loss_mask: 0.2139  decode.d2.loss_dice: 0.2464  decode.d3.loss_cls: 0.1480  decode.d3.loss_mask: 0.2130  decode.d3.loss_dice: 0.2581  decode.d4.loss_cls: 0.1238  decode.d4.loss_mask: 0.2072  decode.d4.loss_dice: 0.2461  decode.d5.loss_cls: 0.1278  decode.d5.loss_mask: 0.2763  decode.d5.loss_dice: 0.2802  decode.d6.loss_cls: 0.0794  decode.d6.loss_mask: 0.3262  decode.d6.loss_dice: 0.2628  decode.d7.loss_cls: 0.1657  decode.d7.loss_mask: 0.2133  decode.d7.loss_dice: 0.2540  decode.d8.loss_cls: 0.0731  decode.d8.loss_mask: 0.3197  decode.d8.loss_dice: 0.2619
08/06 07:43:34 - mmengine - INFO - Iter(train) [ 39850/320000]  base_lr: 8.8719e-05 lr: 8.8719e-06  eta: 1 day, 14:16:58  time: 0.4936  data_time: 0.0111  memory: 5889  grad_norm: 106.0684  loss: 7.5161  decode.loss_cls: 0.1721  decode.loss_mask: 0.2434  decode.loss_dice: 0.2640  decode.d0.loss_cls: 1.0238  decode.d0.loss_mask: 0.2485  decode.d0.loss_dice: 0.2944  decode.d1.loss_cls: 0.1854  decode.d1.loss_mask: 0.2417  decode.d1.loss_dice: 0.2860  decode.d2.loss_cls: 0.1376  decode.d2.loss_mask: 0.2409  decode.d2.loss_dice: 0.2510  decode.d3.loss_cls: 0.1321  decode.d3.loss_mask: 0.2447  decode.d3.loss_dice: 0.2656  decode.d4.loss_cls: 0.1316  decode.d4.loss_mask: 0.2431  decode.d4.loss_dice: 0.2724  decode.d5.loss_cls: 0.1163  decode.d5.loss_mask: 0.2449  decode.d5.loss_dice: 0.2854  decode.d6.loss_cls: 0.1504  decode.d6.loss_mask: 0.2456  decode.d6.loss_dice: 0.2780  decode.d7.loss_cls: 0.1086  decode.d7.loss_mask: 0.2427  decode.d7.loss_dice: 0.2747  decode.d8.loss_cls: 0.1641  decode.d8.loss_mask: 0.2454  decode.d8.loss_dice: 0.2815
08/06 07:43:58 - mmengine - INFO - Iter(train) [ 39900/320000]  base_lr: 8.8705e-05 lr: 8.8705e-06  eta: 1 day, 14:16:33  time: 0.4909  data_time: 0.0108  memory: 5892  grad_norm: 89.4492  loss: 7.7528  decode.loss_cls: 0.1734  decode.loss_mask: 0.2323  decode.loss_dice: 0.2717  decode.d0.loss_cls: 0.7568  decode.d0.loss_mask: 0.2407  decode.d0.loss_dice: 0.2967  decode.d1.loss_cls: 0.2285  decode.d1.loss_mask: 0.2322  decode.d1.loss_dice: 0.2750  decode.d2.loss_cls: 0.1965  decode.d2.loss_mask: 0.2305  decode.d2.loss_dice: 0.2765  decode.d3.loss_cls: 0.2710  decode.d3.loss_mask: 0.2312  decode.d3.loss_dice: 0.2621  decode.d4.loss_cls: 0.2379  decode.d4.loss_mask: 0.2306  decode.d4.loss_dice: 0.2724  decode.d5.loss_cls: 0.2049  decode.d5.loss_mask: 0.2314  decode.d5.loss_dice: 0.2764  decode.d6.loss_cls: 0.2613  decode.d6.loss_mask: 0.2316  decode.d6.loss_dice: 0.2964  decode.d7.loss_cls: 0.1589  decode.d7.loss_mask: 0.2290  decode.d7.loss_dice: 0.2803  decode.d8.loss_cls: 0.1718  decode.d8.loss_mask: 0.2314  decode.d8.loss_dice: 0.2635
08/06 07:44:23 - mmengine - INFO - Iter(train) [ 39950/320000]  base_lr: 8.8691e-05 lr: 8.8691e-06  eta: 1 day, 14:16:09  time: 0.4928  data_time: 0.0110  memory: 5875  grad_norm: 141.9809  loss: 9.7677  decode.loss_cls: 0.2714  decode.loss_mask: 0.3082  decode.loss_dice: 0.3104  decode.d0.loss_cls: 1.0981  decode.d0.loss_mask: 0.2602  decode.d0.loss_dice: 0.3204  decode.d1.loss_cls: 0.2510  decode.d1.loss_mask: 0.2954  decode.d1.loss_dice: 0.3145  decode.d2.loss_cls: 0.2714  decode.d2.loss_mask: 0.2856  decode.d2.loss_dice: 0.3074  decode.d3.loss_cls: 0.2535  decode.d3.loss_mask: 0.2867  decode.d3.loss_dice: 0.3035  decode.d4.loss_cls: 0.2607  decode.d4.loss_mask: 0.3110  decode.d4.loss_dice: 0.3351  decode.d5.loss_cls: 0.2895  decode.d5.loss_mask: 0.3183  decode.d5.loss_dice: 0.2959  decode.d6.loss_cls: 0.3521  decode.d6.loss_mask: 0.3147  decode.d6.loss_dice: 0.3039  decode.d7.loss_cls: 0.2982  decode.d7.loss_mask: 0.3132  decode.d7.loss_dice: 0.3154  decode.d8.loss_cls: 0.3035  decode.d8.loss_mask: 0.3172  decode.d8.loss_dice: 0.3015
08/06 07:44:47 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 07:44:47 - mmengine - INFO - Iter(train) [ 40000/320000]  base_lr: 8.8676e-05 lr: 8.8676e-06  eta: 1 day, 14:15:45  time: 0.4933  data_time: 0.0111  memory: 5908  grad_norm: 68.6006  loss: 7.4511  decode.loss_cls: 0.1846  decode.loss_mask: 0.2350  decode.loss_dice: 0.2732  decode.d0.loss_cls: 0.8870  decode.d0.loss_mask: 0.2386  decode.d0.loss_dice: 0.2887  decode.d1.loss_cls: 0.1924  decode.d1.loss_mask: 0.2387  decode.d1.loss_dice: 0.2990  decode.d2.loss_cls: 0.1863  decode.d2.loss_mask: 0.2338  decode.d2.loss_dice: 0.2779  decode.d3.loss_cls: 0.1558  decode.d3.loss_mask: 0.2366  decode.d3.loss_dice: 0.2725  decode.d4.loss_cls: 0.1604  decode.d4.loss_mask: 0.2338  decode.d4.loss_dice: 0.2982  decode.d5.loss_cls: 0.1156  decode.d5.loss_mask: 0.2312  decode.d5.loss_dice: 0.2807  decode.d6.loss_cls: 0.0562  decode.d6.loss_mask: 0.2366  decode.d6.loss_dice: 0.3118  decode.d7.loss_cls: 0.0757  decode.d7.loss_mask: 0.2415  decode.d7.loss_dice: 0.3144  decode.d8.loss_cls: 0.1698  decode.d8.loss_mask: 0.2394  decode.d8.loss_dice: 0.2857
08/06 07:44:47 - mmengine - INFO - Saving checkpoint at 40000 iterations
08/06 07:44:59 - mmengine - INFO - Iter(val) [  50/1587]    eta: 0:04:42  time: 0.1927  data_time: 0.0044  memory: 7279  
08/06 07:45:07 - mmengine - INFO - Iter(val) [ 100/1587]    eta: 0:04:12  time: 0.1568  data_time: 0.0048  memory: 2343  
08/06 07:45:15 - mmengine - INFO - Iter(val) [ 150/1587]    eta: 0:03:58  time: 0.1571  data_time: 0.0048  memory: 2343  
08/06 07:45:22 - mmengine - INFO - Iter(val) [ 200/1587]    eta: 0:03:46  time: 0.1563  data_time: 0.0046  memory: 2343  
08/06 07:45:30 - mmengine - INFO - Iter(val) [ 250/1587]    eta: 0:03:36  time: 0.1566  data_time: 0.0044  memory: 2343  
08/06 07:45:38 - mmengine - INFO - Iter(val) [ 300/1587]    eta: 0:03:27  time: 0.1571  data_time: 0.0046  memory: 2343  
08/06 07:45:46 - mmengine - INFO - Iter(val) [ 350/1587]    eta: 0:03:18  time: 0.1571  data_time: 0.0046  memory: 2343  
08/06 07:45:54 - mmengine - INFO - Iter(val) [ 400/1587]    eta: 0:03:10  time: 0.1569  data_time: 0.0044  memory: 2343  
08/06 07:46:02 - mmengine - INFO - Iter(val) [ 450/1587]    eta: 0:03:01  time: 0.1569  data_time: 0.0044  memory: 2343  
08/06 07:46:10 - mmengine - INFO - Iter(val) [ 500/1587]    eta: 0:02:53  time: 0.1572  data_time: 0.0046  memory: 2343  
08/06 07:46:17 - mmengine - INFO - Iter(val) [ 550/1587]    eta: 0:02:45  time: 0.1567  data_time: 0.0043  memory: 2343  
08/06 07:46:25 - mmengine - INFO - Iter(val) [ 600/1587]    eta: 0:02:36  time: 0.1567  data_time: 0.0043  memory: 2343  
08/06 07:46:33 - mmengine - INFO - Iter(val) [ 650/1587]    eta: 0:02:28  time: 0.1567  data_time: 0.0042  memory: 2343  
08/06 07:46:41 - mmengine - INFO - Iter(val) [ 700/1587]    eta: 0:02:20  time: 0.1563  data_time: 0.0042  memory: 2343  
08/06 07:46:49 - mmengine - INFO - Iter(val) [ 750/1587]    eta: 0:02:12  time: 0.1567  data_time: 0.0042  memory: 2343  
08/06 07:46:57 - mmengine - INFO - Iter(val) [ 800/1587]    eta: 0:02:04  time: 0.1566  data_time: 0.0042  memory: 2343  
08/06 07:47:04 - mmengine - INFO - Iter(val) [ 850/1587]    eta: 0:01:56  time: 0.1570  data_time: 0.0043  memory: 2343  
08/06 07:47:12 - mmengine - INFO - Iter(val) [ 900/1587]    eta: 0:01:48  time: 0.1569  data_time: 0.0043  memory: 2343  
08/06 07:47:20 - mmengine - INFO - Iter(val) [ 950/1587]    eta: 0:01:40  time: 0.1568  data_time: 0.0044  memory: 2343  
08/06 07:47:28 - mmengine - INFO - Iter(val) [1000/1587]    eta: 0:01:32  time: 0.1567  data_time: 0.0042  memory: 2343  
08/06 07:47:36 - mmengine - INFO - Iter(val) [1050/1587]    eta: 0:01:24  time: 0.1568  data_time: 0.0042  memory: 2343  
08/06 07:47:43 - mmengine - INFO - Iter(val) [1100/1587]    eta: 0:01:16  time: 0.1197  data_time: 0.0037  memory: 6927  
08/06 07:47:49 - mmengine - INFO - Iter(val) [1150/1587]    eta: 0:01:07  time: 0.1199  data_time: 0.0037  memory: 1886  
08/06 07:47:55 - mmengine - INFO - Iter(val) [1200/1587]    eta: 0:00:59  time: 0.1196  data_time: 0.0036  memory: 1886  
08/06 07:48:01 - mmengine - INFO - Iter(val) [1250/1587]    eta: 0:00:51  time: 0.1196  data_time: 0.0036  memory: 1886  
08/06 07:48:07 - mmengine - INFO - Iter(val) [1300/1587]    eta: 0:00:43  time: 0.1196  data_time: 0.0036  memory: 1886  
08/06 07:48:13 - mmengine - INFO - Iter(val) [1350/1587]    eta: 0:00:35  time: 0.1197  data_time: 0.0036  memory: 1886  
08/06 07:48:19 - mmengine - INFO - Iter(val) [1400/1587]    eta: 0:00:27  time: 0.1197  data_time: 0.0037  memory: 1886  
08/06 07:48:25 - mmengine - INFO - Iter(val) [1450/1587]    eta: 0:00:20  time: 0.1197  data_time: 0.0037  memory: 1886  
08/06 07:48:30 - mmengine - INFO - Iter(val) [1500/1587]    eta: 0:00:12  time: 0.1196  data_time: 0.0036  memory: 1886  
08/06 07:48:36 - mmengine - INFO - Iter(val) [1550/1587]    eta: 0:00:05  time: 0.1197  data_time: 0.0037  memory: 1886  
08/06 07:48:41 - mmengine - INFO - per class results:
08/06 07:48:41 - mmengine - INFO - 
+------------------------------------+-------+-------+
|               Class                |  IoU  |  Acc  |
+------------------------------------+-------+-------+
|             background             | 98.99 |  99.5 |
|            Aloo Dry fry            |  93.2 |  96.0 |
|      Avakaya Muddha Papu Rice      | 94.63 | 96.39 |
|      Baby-Corn & Capsicum-Dry      | 92.89 | 96.56 |
|           Cabbage Pakodi           | 88.15 | 90.73 |
|            Cabbage fry             | 92.25 | 95.27 |
|       Capsicum Paneer Curry        | 92.07 | 96.39 |
|           Chakar-Pongal            | 78.69 | 80.92 |
|            Chole-Masala            | 93.07 | 97.19 |
|        Cluster Beans Curry         | 90.29 |  92.9 |
|          Cucumber-Raitha           | 70.69 | 71.97 |
|         Gobi Masala Curry          | 93.15 | 96.06 |
|        Gutti Vankaya Curry         | 93.31 | 96.48 |
|             Jeera Rice             | 94.53 | 96.83 |
|            Mixed Curry             | 93.68 | 98.26 |
|             Muskmelon              | 70.38 | 71.33 |
|               Rajma                | 90.93 | 97.36 |
|              Rasgulla              | 95.14 | 98.76 |
|               Sambar               | 93.11 | 97.13 |
|            Tomato Rasam            | 94.24 | 97.41 |
|         Vankaya-Ali-Karam          | 89.26 | 96.24 |
|            Veg-Biriyani            | 91.81 | 95.64 |
|             aloo-curry             | 93.71 | 96.46 |
|                curd                |  93.4 | 97.38 |
|                dal                 | 93.34 | 97.03 |
|           fresh-chutney            |  91.4 | 95.37 |
|            green-salad             | 93.22 | 96.58 |
|         Moong-Beans-Curry          | 94.55 | 97.45 |
|              khichdi               | 91.58 | 97.63 |
|             lemon-rice             | 94.51 | 96.71 |
|        live-roti-with-ghee         | 97.92 | 98.75 |
|    non-spicy-curry-bottle-gourd    |  93.1 |  98.0 |
|               papad                |  93.2 | 95.53 |
|             plain-rice             | 95.52 | 97.45 |
|             watermelon             |  94.8 | 98.02 |
|              Aloo-Fry              | 92.01 | 96.16 |
|               Banana               | 95.35 | 96.54 |
|             Mix-Fruit              | 95.65 | 97.89 |
| Non-Spicy-Baby-Corn & Capsicum-Dry | 87.86 | 94.21 |
|               Sweet                | 75.54 | 77.11 |
|            Tomato-Rice             | 94.42 |  97.6 |
|         fried-papad-rings          |  87.3 | 96.91 |
|               gravy                | 91.83 | 94.97 |
|           ivy-gourd-fry            | 94.94 | 98.11 |
|            mango-pickle            | 90.71 |  92.8 |
|             papad-chat             | 91.97 | 97.81 |
|            pepper-rasam            |  93.8 | 95.77 |
|             pineapple              | 57.95 | 98.16 |
|              corn-fry              | 89.79 | 94.14 |
|            paneer-curry            | 91.24 | 96.05 |
|               semiya               | 91.49 | 96.05 |
+------------------------------------+-------+-------+
08/06 07:48:41 - mmengine - INFO - Iter(val) [1587/1587]    aAcc: 99.0700  mIoU: 90.7200  mAcc: 94.8600  data_time: 0.0045  time: 0.1455
08/06 07:48:42 - mmengine - INFO - The best checkpoint with 90.7200 mIoU at 40000 iter is saved to best_mIoU_iter_40000.pth.
08/06 07:49:13 - mmengine - INFO - Iter(train) [ 40050/320000]  base_lr: 8.8662e-05 lr: 8.8662e-06  eta: 1 day, 14:16:11  time: 0.4938  data_time: 0.0112  memory: 5909  grad_norm: 120.5801  loss: 8.1379  decode.loss_cls: 0.1561  decode.loss_mask: 0.2378  decode.loss_dice: 0.3087  decode.d0.loss_cls: 0.9274  decode.d0.loss_mask: 0.2510  decode.d0.loss_dice: 0.3243  decode.d1.loss_cls: 0.1712  decode.d1.loss_mask: 0.2800  decode.d1.loss_dice: 0.3419  decode.d2.loss_cls: 0.1845  decode.d2.loss_mask: 0.2465  decode.d2.loss_dice: 0.3238  decode.d3.loss_cls: 0.1507  decode.d3.loss_mask: 0.2429  decode.d3.loss_dice: 0.3121  decode.d4.loss_cls: 0.1656  decode.d4.loss_mask: 0.2476  decode.d4.loss_dice: 0.3299  decode.d5.loss_cls: 0.1794  decode.d5.loss_mask: 0.2489  decode.d5.loss_dice: 0.3303  decode.d6.loss_cls: 0.1577  decode.d6.loss_mask: 0.2399  decode.d6.loss_dice: 0.3127  decode.d7.loss_cls: 0.1496  decode.d7.loss_mask: 0.2444  decode.d7.loss_dice: 0.3215  decode.d8.loss_cls: 0.1855  decode.d8.loss_mask: 0.2435  decode.d8.loss_dice: 0.3226
08/06 07:49:37 - mmengine - INFO - Iter(train) [ 40100/320000]  base_lr: 8.8648e-05 lr: 8.8648e-06  eta: 1 day, 14:15:47  time: 0.4933  data_time: 0.0109  memory: 5911  grad_norm: 126.8783  loss: 7.6616  decode.loss_cls: 0.1372  decode.loss_mask: 0.2744  decode.loss_dice: 0.2839  decode.d0.loss_cls: 0.8955  decode.d0.loss_mask: 0.2916  decode.d0.loss_dice: 0.2954  decode.d1.loss_cls: 0.1888  decode.d1.loss_mask: 0.2770  decode.d1.loss_dice: 0.2823  decode.d2.loss_cls: 0.1155  decode.d2.loss_mask: 0.2745  decode.d2.loss_dice: 0.2841  decode.d3.loss_cls: 0.1274  decode.d3.loss_mask: 0.2767  decode.d3.loss_dice: 0.2808  decode.d4.loss_cls: 0.1418  decode.d4.loss_mask: 0.2760  decode.d4.loss_dice: 0.2839  decode.d5.loss_cls: 0.1615  decode.d5.loss_mask: 0.2716  decode.d5.loss_dice: 0.2792  decode.d6.loss_cls: 0.1397  decode.d6.loss_mask: 0.2693  decode.d6.loss_dice: 0.2688  decode.d7.loss_cls: 0.0844  decode.d7.loss_mask: 0.2698  decode.d7.loss_dice: 0.2969  decode.d8.loss_cls: 0.0712  decode.d8.loss_mask: 0.2699  decode.d8.loss_dice: 0.2925
08/06 07:50:02 - mmengine - INFO - Iter(train) [ 40150/320000]  base_lr: 8.8634e-05 lr: 8.8634e-06  eta: 1 day, 14:15:23  time: 0.4944  data_time: 0.0109  memory: 5931  grad_norm: 250.1338  loss: 6.9260  decode.loss_cls: 0.0583  decode.loss_mask: 0.2485  decode.loss_dice: 0.3036  decode.d0.loss_cls: 0.8681  decode.d0.loss_mask: 0.2494  decode.d0.loss_dice: 0.3279  decode.d1.loss_cls: 0.0961  decode.d1.loss_mask: 0.2412  decode.d1.loss_dice: 0.3012  decode.d2.loss_cls: 0.0813  decode.d2.loss_mask: 0.2377  decode.d2.loss_dice: 0.2805  decode.d3.loss_cls: 0.0560  decode.d3.loss_mask: 0.2461  decode.d3.loss_dice: 0.2870  decode.d4.loss_cls: 0.0635  decode.d4.loss_mask: 0.2466  decode.d4.loss_dice: 0.2848  decode.d5.loss_cls: 0.0533  decode.d5.loss_mask: 0.2505  decode.d5.loss_dice: 0.2997  decode.d6.loss_cls: 0.0657  decode.d6.loss_mask: 0.2528  decode.d6.loss_dice: 0.3099  decode.d7.loss_cls: 0.0578  decode.d7.loss_mask: 0.2539  decode.d7.loss_dice: 0.3060  decode.d8.loss_cls: 0.0556  decode.d8.loss_mask: 0.2449  decode.d8.loss_dice: 0.2980
08/06 07:50:27 - mmengine - INFO - Iter(train) [ 40200/320000]  base_lr: 8.8619e-05 lr: 8.8619e-06  eta: 1 day, 14:14:59  time: 0.4941  data_time: 0.0110  memory: 5909  grad_norm: 125.4879  loss: 7.8228  decode.loss_cls: 0.1436  decode.loss_mask: 0.2327  decode.loss_dice: 0.3174  decode.d0.loss_cls: 0.9456  decode.d0.loss_mask: 0.2416  decode.d0.loss_dice: 0.3254  decode.d1.loss_cls: 0.1526  decode.d1.loss_mask: 0.2365  decode.d1.loss_dice: 0.3113  decode.d2.loss_cls: 0.1416  decode.d2.loss_mask: 0.2350  decode.d2.loss_dice: 0.3104  decode.d3.loss_cls: 0.1445  decode.d3.loss_mask: 0.2337  decode.d3.loss_dice: 0.3039  decode.d4.loss_cls: 0.1443  decode.d4.loss_mask: 0.2349  decode.d4.loss_dice: 0.3130  decode.d5.loss_cls: 0.1563  decode.d5.loss_mask: 0.2337  decode.d5.loss_dice: 0.3105  decode.d6.loss_cls: 0.1579  decode.d6.loss_mask: 0.2377  decode.d6.loss_dice: 0.3039  decode.d7.loss_cls: 0.1949  decode.d7.loss_mask: 0.2395  decode.d7.loss_dice: 0.2999  decode.d8.loss_cls: 0.1607  decode.d8.loss_mask: 0.2353  decode.d8.loss_dice: 0.3245
08/06 07:50:52 - mmengine - INFO - Iter(train) [ 40250/320000]  base_lr: 8.8605e-05 lr: 8.8605e-06  eta: 1 day, 14:14:36  time: 0.4941  data_time: 0.0109  memory: 5911  grad_norm: 119.3674  loss: 8.2184  decode.loss_cls: 0.2109  decode.loss_mask: 0.2244  decode.loss_dice: 0.3047  decode.d0.loss_cls: 0.9360  decode.d0.loss_mask: 0.2324  decode.d0.loss_dice: 0.3586  decode.d1.loss_cls: 0.2096  decode.d1.loss_mask: 0.2289  decode.d1.loss_dice: 0.3112  decode.d2.loss_cls: 0.2169  decode.d2.loss_mask: 0.2263  decode.d2.loss_dice: 0.3060  decode.d3.loss_cls: 0.2363  decode.d3.loss_mask: 0.2293  decode.d3.loss_dice: 0.2897  decode.d4.loss_cls: 0.2251  decode.d4.loss_mask: 0.2285  decode.d4.loss_dice: 0.3104  decode.d5.loss_cls: 0.2275  decode.d5.loss_mask: 0.2278  decode.d5.loss_dice: 0.2880  decode.d6.loss_cls: 0.2110  decode.d6.loss_mask: 0.2322  decode.d6.loss_dice: 0.3268  decode.d7.loss_cls: 0.2013  decode.d7.loss_mask: 0.2263  decode.d7.loss_dice: 0.2967  decode.d8.loss_cls: 0.1809  decode.d8.loss_mask: 0.2259  decode.d8.loss_dice: 0.2889
08/06 07:51:16 - mmengine - INFO - Iter(train) [ 40300/320000]  base_lr: 8.8591e-05 lr: 8.8591e-06  eta: 1 day, 14:14:12  time: 0.4937  data_time: 0.0110  memory: 5911  grad_norm: 228.4237  loss: 5.9499  decode.loss_cls: 0.0821  decode.loss_mask: 0.2368  decode.loss_dice: 0.2431  decode.d0.loss_cls: 0.7431  decode.d0.loss_mask: 0.2450  decode.d0.loss_dice: 0.2662  decode.d1.loss_cls: 0.0875  decode.d1.loss_mask: 0.2024  decode.d1.loss_dice: 0.2522  decode.d2.loss_cls: 0.0234  decode.d2.loss_mask: 0.2461  decode.d2.loss_dice: 0.2450  decode.d3.loss_cls: 0.0190  decode.d3.loss_mask: 0.2306  decode.d3.loss_dice: 0.2480  decode.d4.loss_cls: 0.0664  decode.d4.loss_mask: 0.1922  decode.d4.loss_dice: 0.2416  decode.d5.loss_cls: 0.0522  decode.d5.loss_mask: 0.1956  decode.d5.loss_dice: 0.2506  decode.d6.loss_cls: 0.0177  decode.d6.loss_mask: 0.2528  decode.d6.loss_dice: 0.2545  decode.d7.loss_cls: 0.0228  decode.d7.loss_mask: 0.2459  decode.d7.loss_dice: 0.2511  decode.d8.loss_cls: 0.0172  decode.d8.loss_mask: 0.2674  decode.d8.loss_dice: 0.2512
08/06 07:51:41 - mmengine - INFO - Iter(train) [ 40350/320000]  base_lr: 8.8577e-05 lr: 8.8577e-06  eta: 1 day, 14:13:48  time: 0.4929  data_time: 0.0111  memory: 5911  grad_norm: 80.1226  loss: 7.7308  decode.loss_cls: 0.1904  decode.loss_mask: 0.2341  decode.loss_dice: 0.2816  decode.d0.loss_cls: 0.8490  decode.d0.loss_mask: 0.2338  decode.d0.loss_dice: 0.2888  decode.d1.loss_cls: 0.1711  decode.d1.loss_mask: 0.2330  decode.d1.loss_dice: 0.2738  decode.d2.loss_cls: 0.1809  decode.d2.loss_mask: 0.2313  decode.d2.loss_dice: 0.2682  decode.d3.loss_cls: 0.1815  decode.d3.loss_mask: 0.2281  decode.d3.loss_dice: 0.2753  decode.d4.loss_cls: 0.1907  decode.d4.loss_mask: 0.2315  decode.d4.loss_dice: 0.2919  decode.d5.loss_cls: 0.2429  decode.d5.loss_mask: 0.2330  decode.d5.loss_dice: 0.2778  decode.d6.loss_cls: 0.2019  decode.d6.loss_mask: 0.2317  decode.d6.loss_dice: 0.2705  decode.d7.loss_cls: 0.1994  decode.d7.loss_mask: 0.2314  decode.d7.loss_dice: 0.2827  decode.d8.loss_cls: 0.2107  decode.d8.loss_mask: 0.2312  decode.d8.loss_dice: 0.2825
08/06 07:52:06 - mmengine - INFO - Iter(train) [ 40400/320000]  base_lr: 8.8562e-05 lr: 8.8562e-06  eta: 1 day, 14:13:24  time: 0.4937  data_time: 0.0110  memory: 5895  grad_norm: 42.7215  loss: 6.2116  decode.loss_cls: 0.0695  decode.loss_mask: 0.2560  decode.loss_dice: 0.2512  decode.d0.loss_cls: 0.8566  decode.d0.loss_mask: 0.2574  decode.d0.loss_dice: 0.2413  decode.d1.loss_cls: 0.0289  decode.d1.loss_mask: 0.2560  decode.d1.loss_dice: 0.2444  decode.d2.loss_cls: 0.0225  decode.d2.loss_mask: 0.2571  decode.d2.loss_dice: 0.2487  decode.d3.loss_cls: 0.0229  decode.d3.loss_mask: 0.2552  decode.d3.loss_dice: 0.2540  decode.d4.loss_cls: 0.0196  decode.d4.loss_mask: 0.2564  decode.d4.loss_dice: 0.2527  decode.d5.loss_cls: 0.0253  decode.d5.loss_mask: 0.2553  decode.d5.loss_dice: 0.2438  decode.d6.loss_cls: 0.0396  decode.d6.loss_mask: 0.2535  decode.d6.loss_dice: 0.2521  decode.d7.loss_cls: 0.0377  decode.d7.loss_mask: 0.2556  decode.d7.loss_dice: 0.2475  decode.d8.loss_cls: 0.0428  decode.d8.loss_mask: 0.2574  decode.d8.loss_dice: 0.2505
08/06 07:52:31 - mmengine - INFO - Iter(train) [ 40450/320000]  base_lr: 8.8548e-05 lr: 8.8548e-06  eta: 1 day, 14:13:00  time: 0.4934  data_time: 0.0109  memory: 5891  grad_norm: 156.1261  loss: 7.9028  decode.loss_cls: 0.2742  decode.loss_mask: 0.2119  decode.loss_dice: 0.2852  decode.d0.loss_cls: 0.8503  decode.d0.loss_mask: 0.2127  decode.d0.loss_dice: 0.2883  decode.d1.loss_cls: 0.2381  decode.d1.loss_mask: 0.2101  decode.d1.loss_dice: 0.2549  decode.d2.loss_cls: 0.2605  decode.d2.loss_mask: 0.2110  decode.d2.loss_dice: 0.2430  decode.d3.loss_cls: 0.2209  decode.d3.loss_mask: 0.2102  decode.d3.loss_dice: 0.2789  decode.d4.loss_cls: 0.1993  decode.d4.loss_mask: 0.2175  decode.d4.loss_dice: 0.2632  decode.d5.loss_cls: 0.1921  decode.d5.loss_mask: 0.2279  decode.d5.loss_dice: 0.2910  decode.d6.loss_cls: 0.2200  decode.d6.loss_mask: 0.2413  decode.d6.loss_dice: 0.2828  decode.d7.loss_cls: 0.2424  decode.d7.loss_mask: 0.2313  decode.d7.loss_dice: 0.2833  decode.d8.loss_cls: 0.2543  decode.d8.loss_mask: 0.2164  decode.d8.loss_dice: 0.2897
08/06 07:52:55 - mmengine - INFO - Iter(train) [ 40500/320000]  base_lr: 8.8534e-05 lr: 8.8534e-06  eta: 1 day, 14:12:36  time: 0.4939  data_time: 0.0113  memory: 5911  grad_norm: 120.4677  loss: 7.8822  decode.loss_cls: 0.1631  decode.loss_mask: 0.2943  decode.loss_dice: 0.2431  decode.d0.loss_cls: 0.9945  decode.d0.loss_mask: 0.3250  decode.d0.loss_dice: 0.2891  decode.d1.loss_cls: 0.1082  decode.d1.loss_mask: 0.2694  decode.d1.loss_dice: 0.2539  decode.d2.loss_cls: 0.0984  decode.d2.loss_mask: 0.2712  decode.d2.loss_dice: 0.2644  decode.d3.loss_cls: 0.1271  decode.d3.loss_mask: 0.2710  decode.d3.loss_dice: 0.2630  decode.d4.loss_cls: 0.1561  decode.d4.loss_mask: 0.3240  decode.d4.loss_dice: 0.2863  decode.d5.loss_cls: 0.1467  decode.d5.loss_mask: 0.3258  decode.d5.loss_dice: 0.2660  decode.d6.loss_cls: 0.1742  decode.d6.loss_mask: 0.3179  decode.d6.loss_dice: 0.2744  decode.d7.loss_cls: 0.1257  decode.d7.loss_mask: 0.2965  decode.d7.loss_dice: 0.2569  decode.d8.loss_cls: 0.1522  decode.d8.loss_mask: 0.2875  decode.d8.loss_dice: 0.2561
08/06 07:53:20 - mmengine - INFO - Iter(train) [ 40550/320000]  base_lr: 8.8520e-05 lr: 8.8520e-06  eta: 1 day, 14:12:12  time: 0.4938  data_time: 0.0111  memory: 5894  grad_norm: 227.9418  loss: 9.1465  decode.loss_cls: 0.3518  decode.loss_mask: 0.2323  decode.loss_dice: 0.2906  decode.d0.loss_cls: 1.0549  decode.d0.loss_mask: 0.2484  decode.d0.loss_dice: 0.3175  decode.d1.loss_cls: 0.2275  decode.d1.loss_mask: 0.2459  decode.d1.loss_dice: 0.3169  decode.d2.loss_cls: 0.3043  decode.d2.loss_mask: 0.2345  decode.d2.loss_dice: 0.3031  decode.d3.loss_cls: 0.3128  decode.d3.loss_mask: 0.2343  decode.d3.loss_dice: 0.2972  decode.d4.loss_cls: 0.3189  decode.d4.loss_mask: 0.2355  decode.d4.loss_dice: 0.3093  decode.d5.loss_cls: 0.3171  decode.d5.loss_mask: 0.2298  decode.d5.loss_dice: 0.2845  decode.d6.loss_cls: 0.2921  decode.d6.loss_mask: 0.2297  decode.d6.loss_dice: 0.2846  decode.d7.loss_cls: 0.3151  decode.d7.loss_mask: 0.2312  decode.d7.loss_dice: 0.2985  decode.d8.loss_cls: 0.3291  decode.d8.loss_mask: 0.2301  decode.d8.loss_dice: 0.2692
08/06 07:53:45 - mmengine - INFO - Iter(train) [ 40600/320000]  base_lr: 8.8505e-05 lr: 8.8505e-06  eta: 1 day, 14:11:48  time: 0.4931  data_time: 0.0110  memory: 5878  grad_norm: 404.6915  loss: 8.1915  decode.loss_cls: 0.1614  decode.loss_mask: 0.3359  decode.loss_dice: 0.3019  decode.d0.loss_cls: 0.8471  decode.d0.loss_mask: 0.3521  decode.d0.loss_dice: 0.2892  decode.d1.loss_cls: 0.1126  decode.d1.loss_mask: 0.3433  decode.d1.loss_dice: 0.2845  decode.d2.loss_cls: 0.1230  decode.d2.loss_mask: 0.3423  decode.d2.loss_dice: 0.2753  decode.d3.loss_cls: 0.1105  decode.d3.loss_mask: 0.3425  decode.d3.loss_dice: 0.2707  decode.d4.loss_cls: 0.1228  decode.d4.loss_mask: 0.3528  decode.d4.loss_dice: 0.2722  decode.d5.loss_cls: 0.0761  decode.d5.loss_mask: 0.3479  decode.d5.loss_dice: 0.2771  decode.d6.loss_cls: 0.1125  decode.d6.loss_mask: 0.3475  decode.d6.loss_dice: 0.2733  decode.d7.loss_cls: 0.1093  decode.d7.loss_mask: 0.3461  decode.d7.loss_dice: 0.2659  decode.d8.loss_cls: 0.1829  decode.d8.loss_mask: 0.3404  decode.d8.loss_dice: 0.2722
08/06 07:54:09 - mmengine - INFO - Iter(train) [ 40650/320000]  base_lr: 8.8491e-05 lr: 8.8491e-06  eta: 1 day, 14:11:24  time: 0.4940  data_time: 0.0112  memory: 5894  grad_norm: 86.7355  loss: 8.1697  decode.loss_cls: 0.1725  decode.loss_mask: 0.2374  decode.loss_dice: 0.3028  decode.d0.loss_cls: 0.9007  decode.d0.loss_mask: 0.2308  decode.d0.loss_dice: 0.3081  decode.d1.loss_cls: 0.2412  decode.d1.loss_mask: 0.2349  decode.d1.loss_dice: 0.2907  decode.d2.loss_cls: 0.1718  decode.d2.loss_mask: 0.2428  decode.d2.loss_dice: 0.3127  decode.d3.loss_cls: 0.2242  decode.d3.loss_mask: 0.2338  decode.d3.loss_dice: 0.2872  decode.d4.loss_cls: 0.1217  decode.d4.loss_mask: 0.2358  decode.d4.loss_dice: 0.2866  decode.d5.loss_cls: 0.2546  decode.d5.loss_mask: 0.2281  decode.d5.loss_dice: 0.2880  decode.d6.loss_cls: 0.2930  decode.d6.loss_mask: 0.2299  decode.d6.loss_dice: 0.3039  decode.d7.loss_cls: 0.2319  decode.d7.loss_mask: 0.2357  decode.d7.loss_dice: 0.2970  decode.d8.loss_cls: 0.2228  decode.d8.loss_mask: 0.2330  decode.d8.loss_dice: 0.3161
08/06 07:54:34 - mmengine - INFO - Iter(train) [ 40700/320000]  base_lr: 8.8477e-05 lr: 8.8477e-06  eta: 1 day, 14:11:00  time: 0.4935  data_time: 0.0114  memory: 5911  grad_norm: 97.2924  loss: 10.8733  decode.loss_cls: 0.2872  decode.loss_mask: 0.2981  decode.loss_dice: 0.4518  decode.d0.loss_cls: 0.9267  decode.d0.loss_mask: 0.3042  decode.d0.loss_dice: 0.4537  decode.d1.loss_cls: 0.3130  decode.d1.loss_mask: 0.3035  decode.d1.loss_dice: 0.4573  decode.d2.loss_cls: 0.2265  decode.d2.loss_mask: 0.3006  decode.d2.loss_dice: 0.4697  decode.d3.loss_cls: 0.1769  decode.d3.loss_mask: 0.2970  decode.d3.loss_dice: 0.4655  decode.d4.loss_cls: 0.2496  decode.d4.loss_mask: 0.3012  decode.d4.loss_dice: 0.4677  decode.d5.loss_cls: 0.2598  decode.d5.loss_mask: 0.3016  decode.d5.loss_dice: 0.4478  decode.d6.loss_cls: 0.2857  decode.d6.loss_mask: 0.3031  decode.d6.loss_dice: 0.5192  decode.d7.loss_cls: 0.2494  decode.d7.loss_mask: 0.3008  decode.d7.loss_dice: 0.4638  decode.d8.loss_cls: 0.2514  decode.d8.loss_mask: 0.2956  decode.d8.loss_dice: 0.4448
08/06 07:54:59 - mmengine - INFO - Iter(train) [ 40750/320000]  base_lr: 8.8463e-05 lr: 8.8463e-06  eta: 1 day, 14:10:36  time: 0.4934  data_time: 0.0110  memory: 5874  grad_norm: 55.1088  loss: 6.3112  decode.loss_cls: 0.1131  decode.loss_mask: 0.2017  decode.loss_dice: 0.2675  decode.d0.loss_cls: 0.7742  decode.d0.loss_mask: 0.2025  decode.d0.loss_dice: 0.2728  decode.d1.loss_cls: 0.0915  decode.d1.loss_mask: 0.2055  decode.d1.loss_dice: 0.2986  decode.d2.loss_cls: 0.0539  decode.d2.loss_mask: 0.2034  decode.d2.loss_dice: 0.2924  decode.d3.loss_cls: 0.0848  decode.d3.loss_mask: 0.2008  decode.d3.loss_dice: 0.2919  decode.d4.loss_cls: 0.0470  decode.d4.loss_mask: 0.2012  decode.d4.loss_dice: 0.3026  decode.d5.loss_cls: 0.0553  decode.d5.loss_mask: 0.2017  decode.d5.loss_dice: 0.2708  decode.d6.loss_cls: 0.0701  decode.d6.loss_mask: 0.2028  decode.d6.loss_dice: 0.2682  decode.d7.loss_cls: 0.0691  decode.d7.loss_mask: 0.2034  decode.d7.loss_dice: 0.3039  decode.d8.loss_cls: 0.0566  decode.d8.loss_mask: 0.2037  decode.d8.loss_dice: 0.3003
08/06 07:55:23 - mmengine - INFO - Iter(train) [ 40800/320000]  base_lr: 8.8448e-05 lr: 8.8448e-06  eta: 1 day, 14:10:12  time: 0.4937  data_time: 0.0111  memory: 5894  grad_norm: 61.6119  loss: 6.6543  decode.loss_cls: 0.1356  decode.loss_mask: 0.2210  decode.loss_dice: 0.2468  decode.d0.loss_cls: 0.8858  decode.d0.loss_mask: 0.2285  decode.d0.loss_dice: 0.2457  decode.d1.loss_cls: 0.1030  decode.d1.loss_mask: 0.2248  decode.d1.loss_dice: 0.2541  decode.d2.loss_cls: 0.0996  decode.d2.loss_mask: 0.2240  decode.d2.loss_dice: 0.2259  decode.d3.loss_cls: 0.1018  decode.d3.loss_mask: 0.2248  decode.d3.loss_dice: 0.2502  decode.d4.loss_cls: 0.1238  decode.d4.loss_mask: 0.2241  decode.d4.loss_dice: 0.2442  decode.d5.loss_cls: 0.1501  decode.d5.loss_mask: 0.2218  decode.d5.loss_dice: 0.2379  decode.d6.loss_cls: 0.1580  decode.d6.loss_mask: 0.2219  decode.d6.loss_dice: 0.2276  decode.d7.loss_cls: 0.1205  decode.d7.loss_mask: 0.2221  decode.d7.loss_dice: 0.2394  decode.d8.loss_cls: 0.1561  decode.d8.loss_mask: 0.2215  decode.d8.loss_dice: 0.2138
08/06 07:55:48 - mmengine - INFO - Iter(train) [ 40850/320000]  base_lr: 8.8434e-05 lr: 8.8434e-06  eta: 1 day, 14:09:49  time: 0.4945  data_time: 0.0110  memory: 5876  grad_norm: 60.7797  loss: 6.0118  decode.loss_cls: 0.0612  decode.loss_mask: 0.1934  decode.loss_dice: 0.2299  decode.d0.loss_cls: 0.9144  decode.d0.loss_mask: 0.1963  decode.d0.loss_dice: 0.2341  decode.d1.loss_cls: 0.1958  decode.d1.loss_mask: 0.1943  decode.d1.loss_dice: 0.2291  decode.d2.loss_cls: 0.1163  decode.d2.loss_mask: 0.1923  decode.d2.loss_dice: 0.2242  decode.d3.loss_cls: 0.0873  decode.d3.loss_mask: 0.1937  decode.d3.loss_dice: 0.2350  decode.d4.loss_cls: 0.0720  decode.d4.loss_mask: 0.1966  decode.d4.loss_dice: 0.2380  decode.d5.loss_cls: 0.0644  decode.d5.loss_mask: 0.1958  decode.d5.loss_dice: 0.2344  decode.d6.loss_cls: 0.0611  decode.d6.loss_mask: 0.1991  decode.d6.loss_dice: 0.2401  decode.d7.loss_cls: 0.0772  decode.d7.loss_mask: 0.1981  decode.d7.loss_dice: 0.2374  decode.d8.loss_cls: 0.0733  decode.d8.loss_mask: 0.1935  decode.d8.loss_dice: 0.2333
08/06 07:56:13 - mmengine - INFO - Iter(train) [ 40900/320000]  base_lr: 8.8420e-05 lr: 8.8420e-06  eta: 1 day, 14:09:25  time: 0.4947  data_time: 0.0114  memory: 5878  grad_norm: 72.2054  loss: 7.6677  decode.loss_cls: 0.1549  decode.loss_mask: 0.2185  decode.loss_dice: 0.2769  decode.d0.loss_cls: 0.9053  decode.d0.loss_mask: 0.2172  decode.d0.loss_dice: 0.3099  decode.d1.loss_cls: 0.3033  decode.d1.loss_mask: 0.2166  decode.d1.loss_dice: 0.2852  decode.d2.loss_cls: 0.2029  decode.d2.loss_mask: 0.2195  decode.d2.loss_dice: 0.2938  decode.d3.loss_cls: 0.1467  decode.d3.loss_mask: 0.2197  decode.d3.loss_dice: 0.2949  decode.d4.loss_cls: 0.1567  decode.d4.loss_mask: 0.2160  decode.d4.loss_dice: 0.2734  decode.d5.loss_cls: 0.2041  decode.d5.loss_mask: 0.2169  decode.d5.loss_dice: 0.2893  decode.d6.loss_cls: 0.1902  decode.d6.loss_mask: 0.2120  decode.d6.loss_dice: 0.2832  decode.d7.loss_cls: 0.1865  decode.d7.loss_mask: 0.2158  decode.d7.loss_dice: 0.2798  decode.d8.loss_cls: 0.1708  decode.d8.loss_mask: 0.2172  decode.d8.loss_dice: 0.2905
08/06 07:56:38 - mmengine - INFO - Iter(train) [ 40950/320000]  base_lr: 8.8406e-05 lr: 8.8406e-06  eta: 1 day, 14:09:01  time: 0.4939  data_time: 0.0113  memory: 5911  grad_norm: 170.7926  loss: 8.2665  decode.loss_cls: 0.1024  decode.loss_mask: 0.3500  decode.loss_dice: 0.2641  decode.d0.loss_cls: 0.8986  decode.d0.loss_mask: 0.3504  decode.d0.loss_dice: 0.2556  decode.d1.loss_cls: 0.1443  decode.d1.loss_mask: 0.3625  decode.d1.loss_dice: 0.2606  decode.d2.loss_cls: 0.1597  decode.d2.loss_mask: 0.3538  decode.d2.loss_dice: 0.2609  decode.d3.loss_cls: 0.1828  decode.d3.loss_mask: 0.3243  decode.d3.loss_dice: 0.2523  decode.d4.loss_cls: 0.2028  decode.d4.loss_mask: 0.3253  decode.d4.loss_dice: 0.2481  decode.d5.loss_cls: 0.1803  decode.d5.loss_mask: 0.3246  decode.d5.loss_dice: 0.2584  decode.d6.loss_cls: 0.1719  decode.d6.loss_mask: 0.3250  decode.d6.loss_dice: 0.2583  decode.d7.loss_cls: 0.1370  decode.d7.loss_mask: 0.3295  decode.d7.loss_dice: 0.2605  decode.d8.loss_cls: 0.1382  decode.d8.loss_mask: 0.3239  decode.d8.loss_dice: 0.2605
08/06 07:57:02 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 07:57:02 - mmengine - INFO - Iter(train) [ 41000/320000]  base_lr: 8.8391e-05 lr: 8.8391e-06  eta: 1 day, 14:08:37  time: 0.4939  data_time: 0.0110  memory: 5891  grad_norm: 1052.2631  loss: 9.3383  decode.loss_cls: 0.1186  decode.loss_mask: 0.2570  decode.loss_dice: 0.3542  decode.d0.loss_cls: 0.9820  decode.d0.loss_mask: 0.2571  decode.d0.loss_dice: 0.3818  decode.d1.loss_cls: 0.3040  decode.d1.loss_mask: 0.2522  decode.d1.loss_dice: 0.3698  decode.d2.loss_cls: 0.1956  decode.d2.loss_mask: 0.2572  decode.d2.loss_dice: 0.3881  decode.d3.loss_cls: 0.2524  decode.d3.loss_mask: 0.2831  decode.d3.loss_dice: 0.3956  decode.d4.loss_cls: 0.2265  decode.d4.loss_mask: 0.2875  decode.d4.loss_dice: 0.3792  decode.d5.loss_cls: 0.2060  decode.d5.loss_mask: 0.2786  decode.d5.loss_dice: 0.3832  decode.d6.loss_cls: 0.1829  decode.d6.loss_mask: 0.2727  decode.d6.loss_dice: 0.3888  decode.d7.loss_cls: 0.2061  decode.d7.loss_mask: 0.2654  decode.d7.loss_dice: 0.3930  decode.d8.loss_cls: 0.1676  decode.d8.loss_mask: 0.2636  decode.d8.loss_dice: 0.3887
08/06 07:57:27 - mmengine - INFO - Iter(train) [ 41050/320000]  base_lr: 8.8377e-05 lr: 8.8377e-06  eta: 1 day, 14:08:13  time: 0.4939  data_time: 0.0112  memory: 5911  grad_norm: 88.5666  loss: 9.1541  decode.loss_cls: 0.1715  decode.loss_mask: 0.2871  decode.loss_dice: 0.3384  decode.d0.loss_cls: 1.0037  decode.d0.loss_mask: 0.2931  decode.d0.loss_dice: 0.3243  decode.d1.loss_cls: 0.3029  decode.d1.loss_mask: 0.2852  decode.d1.loss_dice: 0.3226  decode.d2.loss_cls: 0.2536  decode.d2.loss_mask: 0.2860  decode.d2.loss_dice: 0.3577  decode.d3.loss_cls: 0.2538  decode.d3.loss_mask: 0.2859  decode.d3.loss_dice: 0.3400  decode.d4.loss_cls: 0.1990  decode.d4.loss_mask: 0.2838  decode.d4.loss_dice: 0.3419  decode.d5.loss_cls: 0.1390  decode.d5.loss_mask: 0.2855  decode.d5.loss_dice: 0.3516  decode.d6.loss_cls: 0.1362  decode.d6.loss_mask: 0.2859  decode.d6.loss_dice: 0.3397  decode.d7.loss_cls: 0.2961  decode.d7.loss_mask: 0.2851  decode.d7.loss_dice: 0.3551  decode.d8.loss_cls: 0.1218  decode.d8.loss_mask: 0.2841  decode.d8.loss_dice: 0.3435
08/06 07:57:52 - mmengine - INFO - Iter(train) [ 41100/320000]  base_lr: 8.8363e-05 lr: 8.8363e-06  eta: 1 day, 14:07:49  time: 0.4939  data_time: 0.0111  memory: 5931  grad_norm: 96.8334  loss: 6.3772  decode.loss_cls: 0.1134  decode.loss_mask: 0.1994  decode.loss_dice: 0.2586  decode.d0.loss_cls: 0.7671  decode.d0.loss_mask: 0.2039  decode.d0.loss_dice: 0.2665  decode.d1.loss_cls: 0.0945  decode.d1.loss_mask: 0.1983  decode.d1.loss_dice: 0.2571  decode.d2.loss_cls: 0.1270  decode.d2.loss_mask: 0.1996  decode.d2.loss_dice: 0.2518  decode.d3.loss_cls: 0.0911  decode.d3.loss_mask: 0.1990  decode.d3.loss_dice: 0.2559  decode.d4.loss_cls: 0.1308  decode.d4.loss_mask: 0.2011  decode.d4.loss_dice: 0.2656  decode.d5.loss_cls: 0.1101  decode.d5.loss_mask: 0.1978  decode.d5.loss_dice: 0.2540  decode.d6.loss_cls: 0.1247  decode.d6.loss_mask: 0.1987  decode.d6.loss_dice: 0.2513  decode.d7.loss_cls: 0.1150  decode.d7.loss_mask: 0.2001  decode.d7.loss_dice: 0.2641  decode.d8.loss_cls: 0.1168  decode.d8.loss_mask: 0.2014  decode.d8.loss_dice: 0.2627
08/06 07:58:16 - mmengine - INFO - Iter(train) [ 41150/320000]  base_lr: 8.8349e-05 lr: 8.8349e-06  eta: 1 day, 14:07:25  time: 0.4935  data_time: 0.0112  memory: 5894  grad_norm: 91.8807  loss: 7.5156  decode.loss_cls: 0.2577  decode.loss_mask: 0.2140  decode.loss_dice: 0.2501  decode.d0.loss_cls: 0.9122  decode.d0.loss_mask: 0.2142  decode.d0.loss_dice: 0.2204  decode.d1.loss_cls: 0.1832  decode.d1.loss_mask: 0.2098  decode.d1.loss_dice: 0.2605  decode.d2.loss_cls: 0.2048  decode.d2.loss_mask: 0.2082  decode.d2.loss_dice: 0.2792  decode.d3.loss_cls: 0.2508  decode.d3.loss_mask: 0.2065  decode.d3.loss_dice: 0.2597  decode.d4.loss_cls: 0.2229  decode.d4.loss_mask: 0.2097  decode.d4.loss_dice: 0.2473  decode.d5.loss_cls: 0.2234  decode.d5.loss_mask: 0.2131  decode.d5.loss_dice: 0.2402  decode.d6.loss_cls: 0.2156  decode.d6.loss_mask: 0.2137  decode.d6.loss_dice: 0.2280  decode.d7.loss_cls: 0.2391  decode.d7.loss_mask: 0.2158  decode.d7.loss_dice: 0.2303  decode.d8.loss_cls: 0.2307  decode.d8.loss_mask: 0.2137  decode.d8.loss_dice: 0.2408
08/06 07:58:41 - mmengine - INFO - Iter(train) [ 41200/320000]  base_lr: 8.8334e-05 lr: 8.8334e-06  eta: 1 day, 14:07:00  time: 0.4928  data_time: 0.0110  memory: 5911  grad_norm: 131.0936  loss: 6.9603  decode.loss_cls: 0.1101  decode.loss_mask: 0.2831  decode.loss_dice: 0.2393  decode.d0.loss_cls: 0.8967  decode.d0.loss_mask: 0.2966  decode.d0.loss_dice: 0.2415  decode.d1.loss_cls: 0.0901  decode.d1.loss_mask: 0.2912  decode.d1.loss_dice: 0.2520  decode.d2.loss_cls: 0.0760  decode.d2.loss_mask: 0.2864  decode.d2.loss_dice: 0.2432  decode.d3.loss_cls: 0.0701  decode.d3.loss_mask: 0.2859  decode.d3.loss_dice: 0.2438  decode.d4.loss_cls: 0.0718  decode.d4.loss_mask: 0.2838  decode.d4.loss_dice: 0.2474  decode.d5.loss_cls: 0.0751  decode.d5.loss_mask: 0.2870  decode.d5.loss_dice: 0.2473  decode.d6.loss_cls: 0.0832  decode.d6.loss_mask: 0.2885  decode.d6.loss_dice: 0.2439  decode.d7.loss_cls: 0.0808  decode.d7.loss_mask: 0.2868  decode.d7.loss_dice: 0.2415  decode.d8.loss_cls: 0.0929  decode.d8.loss_mask: 0.2847  decode.d8.loss_dice: 0.2395
08/06 07:59:06 - mmengine - INFO - Iter(train) [ 41250/320000]  base_lr: 8.8320e-05 lr: 8.8320e-06  eta: 1 day, 14:06:36  time: 0.4937  data_time: 0.0109  memory: 5928  grad_norm: 67.4219  loss: 7.3159  decode.loss_cls: 0.1431  decode.loss_mask: 0.2091  decode.loss_dice: 0.2581  decode.d0.loss_cls: 0.8861  decode.d0.loss_mask: 0.2140  decode.d0.loss_dice: 0.2997  decode.d1.loss_cls: 0.1380  decode.d1.loss_mask: 0.2137  decode.d1.loss_dice: 0.2825  decode.d2.loss_cls: 0.1662  decode.d2.loss_mask: 0.2122  decode.d2.loss_dice: 0.2955  decode.d3.loss_cls: 0.1723  decode.d3.loss_mask: 0.2113  decode.d3.loss_dice: 0.2788  decode.d4.loss_cls: 0.1568  decode.d4.loss_mask: 0.2111  decode.d4.loss_dice: 0.2878  decode.d5.loss_cls: 0.1982  decode.d5.loss_mask: 0.2127  decode.d5.loss_dice: 0.2811  decode.d6.loss_cls: 0.1883  decode.d6.loss_mask: 0.2099  decode.d6.loss_dice: 0.2676  decode.d7.loss_cls: 0.1871  decode.d7.loss_mask: 0.2102  decode.d7.loss_dice: 0.2710  decode.d8.loss_cls: 0.1499  decode.d8.loss_mask: 0.2124  decode.d8.loss_dice: 0.2912
08/06 07:59:31 - mmengine - INFO - Iter(train) [ 41300/320000]  base_lr: 8.8306e-05 lr: 8.8306e-06  eta: 1 day, 14:06:13  time: 0.4958  data_time: 0.0111  memory: 5911  grad_norm: 207.2537  loss: 8.6845  decode.loss_cls: 0.1801  decode.loss_mask: 0.2625  decode.loss_dice: 0.3137  decode.d0.loss_cls: 1.0595  decode.d0.loss_mask: 0.2629  decode.d0.loss_dice: 0.2966  decode.d1.loss_cls: 0.2636  decode.d1.loss_mask: 0.2585  decode.d1.loss_dice: 0.3304  decode.d2.loss_cls: 0.2570  decode.d2.loss_mask: 0.2557  decode.d2.loss_dice: 0.2822  decode.d3.loss_cls: 0.2777  decode.d3.loss_mask: 0.2595  decode.d3.loss_dice: 0.3188  decode.d4.loss_cls: 0.2337  decode.d4.loss_mask: 0.2601  decode.d4.loss_dice: 0.2934  decode.d5.loss_cls: 0.1800  decode.d5.loss_mask: 0.2614  decode.d5.loss_dice: 0.2994  decode.d6.loss_cls: 0.1984  decode.d6.loss_mask: 0.2612  decode.d6.loss_dice: 0.2975  decode.d7.loss_cls: 0.1691  decode.d7.loss_mask: 0.2609  decode.d7.loss_dice: 0.3081  decode.d8.loss_cls: 0.2004  decode.d8.loss_mask: 0.2637  decode.d8.loss_dice: 0.3183
08/06 07:59:55 - mmengine - INFO - Iter(train) [ 41350/320000]  base_lr: 8.8292e-05 lr: 8.8292e-06  eta: 1 day, 14:05:48  time: 0.4924  data_time: 0.0111  memory: 5894  grad_norm: 242.0918  loss: 8.8204  decode.loss_cls: 0.2158  decode.loss_mask: 0.2467  decode.loss_dice: 0.3684  decode.d0.loss_cls: 0.9307  decode.d0.loss_mask: 0.2500  decode.d0.loss_dice: 0.3620  decode.d1.loss_cls: 0.2417  decode.d1.loss_mask: 0.2388  decode.d1.loss_dice: 0.3798  decode.d2.loss_cls: 0.1629  decode.d2.loss_mask: 0.2441  decode.d2.loss_dice: 0.3351  decode.d3.loss_cls: 0.2279  decode.d3.loss_mask: 0.2546  decode.d3.loss_dice: 0.3330  decode.d4.loss_cls: 0.1994  decode.d4.loss_mask: 0.2556  decode.d4.loss_dice: 0.3272  decode.d5.loss_cls: 0.1839  decode.d5.loss_mask: 0.2495  decode.d5.loss_dice: 0.3223  decode.d6.loss_cls: 0.1983  decode.d6.loss_mask: 0.2587  decode.d6.loss_dice: 0.3539  decode.d7.loss_cls: 0.2525  decode.d7.loss_mask: 0.2423  decode.d7.loss_dice: 0.3308  decode.d8.loss_cls: 0.2551  decode.d8.loss_mask: 0.2569  decode.d8.loss_dice: 0.3424
08/06 08:00:20 - mmengine - INFO - Iter(train) [ 41400/320000]  base_lr: 8.8277e-05 lr: 8.8277e-06  eta: 1 day, 14:05:25  time: 0.4935  data_time: 0.0111  memory: 5895  grad_norm: 174.3495  loss: 7.2647  decode.loss_cls: 0.1164  decode.loss_mask: 0.2386  decode.loss_dice: 0.3008  decode.d0.loss_cls: 1.0226  decode.d0.loss_mask: 0.2068  decode.d0.loss_dice: 0.2560  decode.d1.loss_cls: 0.1262  decode.d1.loss_mask: 0.2292  decode.d1.loss_dice: 0.2839  decode.d2.loss_cls: 0.0988  decode.d2.loss_mask: 0.2354  decode.d2.loss_dice: 0.2928  decode.d3.loss_cls: 0.1295  decode.d3.loss_mask: 0.2311  decode.d3.loss_dice: 0.2821  decode.d4.loss_cls: 0.0973  decode.d4.loss_mask: 0.2319  decode.d4.loss_dice: 0.2812  decode.d5.loss_cls: 0.1169  decode.d5.loss_mask: 0.2291  decode.d5.loss_dice: 0.2815  decode.d6.loss_cls: 0.1380  decode.d6.loss_mask: 0.2275  decode.d6.loss_dice: 0.3179  decode.d7.loss_cls: 0.0923  decode.d7.loss_mask: 0.2283  decode.d7.loss_dice: 0.2839  decode.d8.loss_cls: 0.0826  decode.d8.loss_mask: 0.2699  decode.d8.loss_dice: 0.3359
08/06 08:00:45 - mmengine - INFO - Iter(train) [ 41450/320000]  base_lr: 8.8263e-05 lr: 8.8263e-06  eta: 1 day, 14:05:01  time: 0.4935  data_time: 0.0111  memory: 5891  grad_norm: 59.8094  loss: 6.3088  decode.loss_cls: 0.1224  decode.loss_mask: 0.2130  decode.loss_dice: 0.2167  decode.d0.loss_cls: 0.9313  decode.d0.loss_mask: 0.2025  decode.d0.loss_dice: 0.2296  decode.d1.loss_cls: 0.1052  decode.d1.loss_mask: 0.2032  decode.d1.loss_dice: 0.2269  decode.d2.loss_cls: 0.1219  decode.d2.loss_mask: 0.2015  decode.d2.loss_dice: 0.2146  decode.d3.loss_cls: 0.1010  decode.d3.loss_mask: 0.2004  decode.d3.loss_dice: 0.2184  decode.d4.loss_cls: 0.1243  decode.d4.loss_mask: 0.1950  decode.d4.loss_dice: 0.2174  decode.d5.loss_cls: 0.1174  decode.d5.loss_mask: 0.2212  decode.d5.loss_dice: 0.2356  decode.d6.loss_cls: 0.1208  decode.d6.loss_mask: 0.2074  decode.d6.loss_dice: 0.2226  decode.d7.loss_cls: 0.1453  decode.d7.loss_mask: 0.1978  decode.d7.loss_dice: 0.2137  decode.d8.loss_cls: 0.1406  decode.d8.loss_mask: 0.2086  decode.d8.loss_dice: 0.2326
08/06 08:01:09 - mmengine - INFO - Iter(train) [ 41500/320000]  base_lr: 8.8249e-05 lr: 8.8249e-06  eta: 1 day, 14:04:37  time: 0.4927  data_time: 0.0111  memory: 5911  grad_norm: 103.4041  loss: 9.1316  decode.loss_cls: 0.1674  decode.loss_mask: 0.3172  decode.loss_dice: 0.3548  decode.d0.loss_cls: 0.8156  decode.d0.loss_mask: 0.3294  decode.d0.loss_dice: 0.3762  decode.d1.loss_cls: 0.2111  decode.d1.loss_mask: 0.3230  decode.d1.loss_dice: 0.3321  decode.d2.loss_cls: 0.2098  decode.d2.loss_mask: 0.3245  decode.d2.loss_dice: 0.3468  decode.d3.loss_cls: 0.2229  decode.d3.loss_mask: 0.3243  decode.d3.loss_dice: 0.3567  decode.d4.loss_cls: 0.1863  decode.d4.loss_mask: 0.3162  decode.d4.loss_dice: 0.3149  decode.d5.loss_cls: 0.1474  decode.d5.loss_mask: 0.3173  decode.d5.loss_dice: 0.3485  decode.d6.loss_cls: 0.1928  decode.d6.loss_mask: 0.3170  decode.d6.loss_dice: 0.3381  decode.d7.loss_cls: 0.1316  decode.d7.loss_mask: 0.3228  decode.d7.loss_dice: 0.3605  decode.d8.loss_cls: 0.1206  decode.d8.loss_mask: 0.3203  decode.d8.loss_dice: 0.3857
08/06 08:01:34 - mmengine - INFO - Iter(train) [ 41550/320000]  base_lr: 8.8235e-05 lr: 8.8235e-06  eta: 1 day, 14:04:13  time: 0.4941  data_time: 0.0113  memory: 5894  grad_norm: 83.1203  loss: 6.3462  decode.loss_cls: 0.0385  decode.loss_mask: 0.2521  decode.loss_dice: 0.2405  decode.d0.loss_cls: 0.9070  decode.d0.loss_mask: 0.2506  decode.d0.loss_dice: 0.2613  decode.d1.loss_cls: 0.0500  decode.d1.loss_mask: 0.2470  decode.d1.loss_dice: 0.2503  decode.d2.loss_cls: 0.0491  decode.d2.loss_mask: 0.2464  decode.d2.loss_dice: 0.2498  decode.d3.loss_cls: 0.0534  decode.d3.loss_mask: 0.2479  decode.d3.loss_dice: 0.2561  decode.d4.loss_cls: 0.0505  decode.d4.loss_mask: 0.2503  decode.d4.loss_dice: 0.2630  decode.d5.loss_cls: 0.0415  decode.d5.loss_mask: 0.2495  decode.d5.loss_dice: 0.2603  decode.d6.loss_cls: 0.0431  decode.d6.loss_mask: 0.2489  decode.d6.loss_dice: 0.2600  decode.d7.loss_cls: 0.0381  decode.d7.loss_mask: 0.2474  decode.d7.loss_dice: 0.2515  decode.d8.loss_cls: 0.0368  decode.d8.loss_mask: 0.2487  decode.d8.loss_dice: 0.2567
08/06 08:01:59 - mmengine - INFO - Iter(train) [ 41600/320000]  base_lr: 8.8220e-05 lr: 8.8220e-06  eta: 1 day, 14:03:49  time: 0.4944  data_time: 0.0107  memory: 5928  grad_norm: 126.1200  loss: 5.9497  decode.loss_cls: 0.1087  decode.loss_mask: 0.1919  decode.loss_dice: 0.2216  decode.d0.loss_cls: 0.8767  decode.d0.loss_mask: 0.1967  decode.d0.loss_dice: 0.2223  decode.d1.loss_cls: 0.1291  decode.d1.loss_mask: 0.1971  decode.d1.loss_dice: 0.2337  decode.d2.loss_cls: 0.0901  decode.d2.loss_mask: 0.2020  decode.d2.loss_dice: 0.2332  decode.d3.loss_cls: 0.0639  decode.d3.loss_mask: 0.2114  decode.d3.loss_dice: 0.2355  decode.d4.loss_cls: 0.0533  decode.d4.loss_mask: 0.2057  decode.d4.loss_dice: 0.2362  decode.d5.loss_cls: 0.0419  decode.d5.loss_mask: 0.2066  decode.d5.loss_dice: 0.2333  decode.d6.loss_cls: 0.0650  decode.d6.loss_mask: 0.2175  decode.d6.loss_dice: 0.2297  decode.d7.loss_cls: 0.0899  decode.d7.loss_mask: 0.2279  decode.d7.loss_dice: 0.2369  decode.d8.loss_cls: 0.0406  decode.d8.loss_mask: 0.2147  decode.d8.loss_dice: 0.2366
08/06 08:02:24 - mmengine - INFO - Iter(train) [ 41650/320000]  base_lr: 8.8206e-05 lr: 8.8206e-06  eta: 1 day, 14:03:25  time: 0.4942  data_time: 0.0112  memory: 5895  grad_norm: 125.3922  loss: 7.9881  decode.loss_cls: 0.1406  decode.loss_mask: 0.3398  decode.loss_dice: 0.3094  decode.d0.loss_cls: 0.8805  decode.d0.loss_mask: 0.3160  decode.d0.loss_dice: 0.2583  decode.d1.loss_cls: 0.1336  decode.d1.loss_mask: 0.3103  decode.d1.loss_dice: 0.2648  decode.d2.loss_cls: 0.1432  decode.d2.loss_mask: 0.3196  decode.d2.loss_dice: 0.2658  decode.d3.loss_cls: 0.1638  decode.d3.loss_mask: 0.3068  decode.d3.loss_dice: 0.2520  decode.d4.loss_cls: 0.1455  decode.d4.loss_mask: 0.3054  decode.d4.loss_dice: 0.2565  decode.d5.loss_cls: 0.1460  decode.d5.loss_mask: 0.3204  decode.d5.loss_dice: 0.2699  decode.d6.loss_cls: 0.1664  decode.d6.loss_mask: 0.3057  decode.d6.loss_dice: 0.2709  decode.d7.loss_cls: 0.1226  decode.d7.loss_mask: 0.3065  decode.d7.loss_dice: 0.2586  decode.d8.loss_cls: 0.1469  decode.d8.loss_mask: 0.3047  decode.d8.loss_dice: 0.2574
08/06 08:02:48 - mmengine - INFO - Iter(train) [ 41700/320000]  base_lr: 8.8192e-05 lr: 8.8192e-06  eta: 1 day, 14:03:02  time: 0.4931  data_time: 0.0109  memory: 5894  grad_norm: 89.7509  loss: 6.9323  decode.loss_cls: 0.1357  decode.loss_mask: 0.1896  decode.loss_dice: 0.2544  decode.d0.loss_cls: 1.1161  decode.d0.loss_mask: 0.1909  decode.d0.loss_dice: 0.2669  decode.d1.loss_cls: 0.1688  decode.d1.loss_mask: 0.1937  decode.d1.loss_dice: 0.2749  decode.d2.loss_cls: 0.1682  decode.d2.loss_mask: 0.1882  decode.d2.loss_dice: 0.2561  decode.d3.loss_cls: 0.1648  decode.d3.loss_mask: 0.1886  decode.d3.loss_dice: 0.2580  decode.d4.loss_cls: 0.1434  decode.d4.loss_mask: 0.1900  decode.d4.loss_dice: 0.2587  decode.d5.loss_cls: 0.1594  decode.d5.loss_mask: 0.1912  decode.d5.loss_dice: 0.2626  decode.d6.loss_cls: 0.0903  decode.d6.loss_mask: 0.1887  decode.d6.loss_dice: 0.2831  decode.d7.loss_cls: 0.1278  decode.d7.loss_mask: 0.1877  decode.d7.loss_dice: 0.2566  decode.d8.loss_cls: 0.1248  decode.d8.loss_mask: 0.1903  decode.d8.loss_dice: 0.2628
08/06 08:03:13 - mmengine - INFO - Iter(train) [ 41750/320000]  base_lr: 8.8178e-05 lr: 8.8178e-06  eta: 1 day, 14:02:38  time: 0.4930  data_time: 0.0109  memory: 5895  grad_norm: 76.3474  loss: 5.4050  decode.loss_cls: 0.1110  decode.loss_mask: 0.1526  decode.loss_dice: 0.2097  decode.d0.loss_cls: 0.8243  decode.d0.loss_mask: 0.1562  decode.d0.loss_dice: 0.2139  decode.d1.loss_cls: 0.1598  decode.d1.loss_mask: 0.1527  decode.d1.loss_dice: 0.2124  decode.d2.loss_cls: 0.1124  decode.d2.loss_mask: 0.1522  decode.d2.loss_dice: 0.2079  decode.d3.loss_cls: 0.1051  decode.d3.loss_mask: 0.1527  decode.d3.loss_dice: 0.2086  decode.d4.loss_cls: 0.0855  decode.d4.loss_mask: 0.1529  decode.d4.loss_dice: 0.2202  decode.d5.loss_cls: 0.1040  decode.d5.loss_mask: 0.1524  decode.d5.loss_dice: 0.2040  decode.d6.loss_cls: 0.0956  decode.d6.loss_mask: 0.1526  decode.d6.loss_dice: 0.2082  decode.d7.loss_cls: 0.1028  decode.d7.loss_mask: 0.1516  decode.d7.loss_dice: 0.2084  decode.d8.loss_cls: 0.0761  decode.d8.loss_mask: 0.1511  decode.d8.loss_dice: 0.2082
08/06 08:03:38 - mmengine - INFO - Iter(train) [ 41800/320000]  base_lr: 8.8163e-05 lr: 8.8163e-06  eta: 1 day, 14:02:14  time: 0.4940  data_time: 0.0113  memory: 5874  grad_norm: 151.5291  loss: 6.5048  decode.loss_cls: 0.1352  decode.loss_mask: 0.2205  decode.loss_dice: 0.2284  decode.d0.loss_cls: 0.8740  decode.d0.loss_mask: 0.2224  decode.d0.loss_dice: 0.2089  decode.d1.loss_cls: 0.1801  decode.d1.loss_mask: 0.2183  decode.d1.loss_dice: 0.2392  decode.d2.loss_cls: 0.1174  decode.d2.loss_mask: 0.2230  decode.d2.loss_dice: 0.2242  decode.d3.loss_cls: 0.1011  decode.d3.loss_mask: 0.2201  decode.d3.loss_dice: 0.2256  decode.d4.loss_cls: 0.1052  decode.d4.loss_mask: 0.2197  decode.d4.loss_dice: 0.2303  decode.d5.loss_cls: 0.1437  decode.d5.loss_mask: 0.2204  decode.d5.loss_dice: 0.2269  decode.d6.loss_cls: 0.1434  decode.d6.loss_mask: 0.2192  decode.d6.loss_dice: 0.2281  decode.d7.loss_cls: 0.1257  decode.d7.loss_mask: 0.2178  decode.d7.loss_dice: 0.2155  decode.d8.loss_cls: 0.1293  decode.d8.loss_mask: 0.2186  decode.d8.loss_dice: 0.2228
08/06 08:04:02 - mmengine - INFO - Iter(train) [ 41850/320000]  base_lr: 8.8149e-05 lr: 8.8149e-06  eta: 1 day, 14:01:50  time: 0.4938  data_time: 0.0113  memory: 5894  grad_norm: 183.4131  loss: 9.0176  decode.loss_cls: 0.1360  decode.loss_mask: 0.3438  decode.loss_dice: 0.3183  decode.d0.loss_cls: 0.9458  decode.d0.loss_mask: 0.3512  decode.d0.loss_dice: 0.3466  decode.d1.loss_cls: 0.1858  decode.d1.loss_mask: 0.3441  decode.d1.loss_dice: 0.3245  decode.d2.loss_cls: 0.1700  decode.d2.loss_mask: 0.3393  decode.d2.loss_dice: 0.3218  decode.d3.loss_cls: 0.1069  decode.d3.loss_mask: 0.3448  decode.d3.loss_dice: 0.3059  decode.d4.loss_cls: 0.1820  decode.d4.loss_mask: 0.3419  decode.d4.loss_dice: 0.3074  decode.d5.loss_cls: 0.1845  decode.d5.loss_mask: 0.3421  decode.d5.loss_dice: 0.3234  decode.d6.loss_cls: 0.1491  decode.d6.loss_mask: 0.3448  decode.d6.loss_dice: 0.3192  decode.d7.loss_cls: 0.1892  decode.d7.loss_mask: 0.3443  decode.d7.loss_dice: 0.2901  decode.d8.loss_cls: 0.1165  decode.d8.loss_mask: 0.3440  decode.d8.loss_dice: 0.3543
08/06 08:04:27 - mmengine - INFO - Iter(train) [ 41900/320000]  base_lr: 8.8135e-05 lr: 8.8135e-06  eta: 1 day, 14:01:25  time: 0.4937  data_time: 0.0111  memory: 5928  grad_norm: 105.8813  loss: 8.1152  decode.loss_cls: 0.2525  decode.loss_mask: 0.2531  decode.loss_dice: 0.2784  decode.d0.loss_cls: 0.9691  decode.d0.loss_mask: 0.2589  decode.d0.loss_dice: 0.2709  decode.d1.loss_cls: 0.2330  decode.d1.loss_mask: 0.2651  decode.d1.loss_dice: 0.2662  decode.d2.loss_cls: 0.2000  decode.d2.loss_mask: 0.2588  decode.d2.loss_dice: 0.2591  decode.d3.loss_cls: 0.1738  decode.d3.loss_mask: 0.2540  decode.d3.loss_dice: 0.2663  decode.d4.loss_cls: 0.1807  decode.d4.loss_mask: 0.2564  decode.d4.loss_dice: 0.2725  decode.d5.loss_cls: 0.1943  decode.d5.loss_mask: 0.2587  decode.d5.loss_dice: 0.2872  decode.d6.loss_cls: 0.2369  decode.d6.loss_mask: 0.2541  decode.d6.loss_dice: 0.2608  decode.d7.loss_cls: 0.2132  decode.d7.loss_mask: 0.2557  decode.d7.loss_dice: 0.2571  decode.d8.loss_cls: 0.2052  decode.d8.loss_mask: 0.2512  decode.d8.loss_dice: 0.2719
08/06 08:04:52 - mmengine - INFO - Iter(train) [ 41950/320000]  base_lr: 8.8120e-05 lr: 8.8120e-06  eta: 1 day, 14:01:01  time: 0.4917  data_time: 0.0109  memory: 5931  grad_norm: 194.8167  loss: 7.2414  decode.loss_cls: 0.0423  decode.loss_mask: 0.3014  decode.loss_dice: 0.2922  decode.d0.loss_cls: 0.8133  decode.d0.loss_mask: 0.2892  decode.d0.loss_dice: 0.2653  decode.d1.loss_cls: 0.0948  decode.d1.loss_mask: 0.2925  decode.d1.loss_dice: 0.2925  decode.d2.loss_cls: 0.0639  decode.d2.loss_mask: 0.3013  decode.d2.loss_dice: 0.2980  decode.d3.loss_cls: 0.0619  decode.d3.loss_mask: 0.3007  decode.d3.loss_dice: 0.3234  decode.d4.loss_cls: 0.0460  decode.d4.loss_mask: 0.3042  decode.d4.loss_dice: 0.2863  decode.d5.loss_cls: 0.0464  decode.d5.loss_mask: 0.2953  decode.d5.loss_dice: 0.2861  decode.d6.loss_cls: 0.0513  decode.d6.loss_mask: 0.2953  decode.d6.loss_dice: 0.2860  decode.d7.loss_cls: 0.0496  decode.d7.loss_mask: 0.2965  decode.d7.loss_dice: 0.2962  decode.d8.loss_cls: 0.0704  decode.d8.loss_mask: 0.2980  decode.d8.loss_dice: 0.3010
08/06 08:05:16 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 08:05:16 - mmengine - INFO - Iter(train) [ 42000/320000]  base_lr: 8.8106e-05 lr: 8.8106e-06  eta: 1 day, 14:00:37  time: 0.4914  data_time: 0.0108  memory: 5911  grad_norm: 75.2138  loss: 6.8957  decode.loss_cls: 0.1537  decode.loss_mask: 0.2304  decode.loss_dice: 0.2303  decode.d0.loss_cls: 0.8496  decode.d0.loss_mask: 0.2288  decode.d0.loss_dice: 0.2386  decode.d1.loss_cls: 0.1407  decode.d1.loss_mask: 0.2177  decode.d1.loss_dice: 0.2318  decode.d2.loss_cls: 0.1777  decode.d2.loss_mask: 0.2253  decode.d2.loss_dice: 0.2570  decode.d3.loss_cls: 0.1220  decode.d3.loss_mask: 0.2357  decode.d3.loss_dice: 0.2394  decode.d4.loss_cls: 0.1389  decode.d4.loss_mask: 0.2272  decode.d4.loss_dice: 0.2405  decode.d5.loss_cls: 0.1649  decode.d5.loss_mask: 0.2269  decode.d5.loss_dice: 0.2256  decode.d6.loss_cls: 0.1368  decode.d6.loss_mask: 0.2325  decode.d6.loss_dice: 0.2399  decode.d7.loss_cls: 0.1788  decode.d7.loss_mask: 0.2238  decode.d7.loss_dice: 0.2357  decode.d8.loss_cls: 0.1780  decode.d8.loss_mask: 0.2264  decode.d8.loss_dice: 0.2414
08/06 08:05:41 - mmengine - INFO - Iter(train) [ 42050/320000]  base_lr: 8.8092e-05 lr: 8.8092e-06  eta: 1 day, 14:00:12  time: 0.4929  data_time: 0.0111  memory: 5928  grad_norm: 117.4524  loss: 8.5042  decode.loss_cls: 0.2221  decode.loss_mask: 0.2927  decode.loss_dice: 0.3017  decode.d0.loss_cls: 0.8406  decode.d0.loss_mask: 0.2932  decode.d0.loss_dice: 0.3013  decode.d1.loss_cls: 0.1938  decode.d1.loss_mask: 0.2941  decode.d1.loss_dice: 0.2983  decode.d2.loss_cls: 0.2021  decode.d2.loss_mask: 0.2942  decode.d2.loss_dice: 0.2636  decode.d3.loss_cls: 0.1226  decode.d3.loss_mask: 0.2939  decode.d3.loss_dice: 0.3009  decode.d4.loss_cls: 0.1541  decode.d4.loss_mask: 0.2999  decode.d4.loss_dice: 0.2581  decode.d5.loss_cls: 0.2137  decode.d5.loss_mask: 0.2953  decode.d5.loss_dice: 0.2694  decode.d6.loss_cls: 0.2577  decode.d6.loss_mask: 0.2924  decode.d6.loss_dice: 0.3008  decode.d7.loss_cls: 0.2309  decode.d7.loss_mask: 0.2927  decode.d7.loss_dice: 0.2935  decode.d8.loss_cls: 0.2184  decode.d8.loss_mask: 0.2948  decode.d8.loss_dice: 0.3178
08/06 08:06:06 - mmengine - INFO - Iter(train) [ 42100/320000]  base_lr: 8.8078e-05 lr: 8.8078e-06  eta: 1 day, 13:59:48  time: 0.4932  data_time: 0.0110  memory: 5911  grad_norm: 84.4959  loss: 7.2328  decode.loss_cls: 0.1521  decode.loss_mask: 0.2343  decode.loss_dice: 0.2466  decode.d0.loss_cls: 0.9040  decode.d0.loss_mask: 0.2329  decode.d0.loss_dice: 0.2340  decode.d1.loss_cls: 0.1645  decode.d1.loss_mask: 0.2346  decode.d1.loss_dice: 0.2316  decode.d2.loss_cls: 0.1770  decode.d2.loss_mask: 0.2350  decode.d2.loss_dice: 0.2389  decode.d3.loss_cls: 0.2132  decode.d3.loss_mask: 0.2369  decode.d3.loss_dice: 0.2424  decode.d4.loss_cls: 0.1892  decode.d4.loss_mask: 0.2319  decode.d4.loss_dice: 0.2532  decode.d5.loss_cls: 0.1734  decode.d5.loss_mask: 0.2372  decode.d5.loss_dice: 0.2526  decode.d6.loss_cls: 0.1453  decode.d6.loss_mask: 0.2309  decode.d6.loss_dice: 0.2444  decode.d7.loss_cls: 0.1506  decode.d7.loss_mask: 0.2325  decode.d7.loss_dice: 0.2464  decode.d8.loss_cls: 0.1633  decode.d8.loss_mask: 0.2375  decode.d8.loss_dice: 0.2664
08/06 08:06:31 - mmengine - INFO - Iter(train) [ 42150/320000]  base_lr: 8.8063e-05 lr: 8.8063e-06  eta: 1 day, 13:59:24  time: 0.4930  data_time: 0.0110  memory: 5891  grad_norm: 68.5293  loss: 5.8343  decode.loss_cls: 0.0077  decode.loss_mask: 0.2159  decode.loss_dice: 0.2476  decode.d0.loss_cls: 0.8641  decode.d0.loss_mask: 0.2224  decode.d0.loss_dice: 0.2669  decode.d1.loss_cls: 0.0842  decode.d1.loss_mask: 0.2150  decode.d1.loss_dice: 0.2507  decode.d2.loss_cls: 0.0293  decode.d2.loss_mask: 0.2151  decode.d2.loss_dice: 0.2509  decode.d3.loss_cls: 0.0405  decode.d3.loss_mask: 0.2167  decode.d3.loss_dice: 0.2515  decode.d4.loss_cls: 0.0571  decode.d4.loss_mask: 0.2146  decode.d4.loss_dice: 0.2437  decode.d5.loss_cls: 0.0068  decode.d5.loss_mask: 0.2144  decode.d5.loss_dice: 0.2507  decode.d6.loss_cls: 0.0083  decode.d6.loss_mask: 0.2154  decode.d6.loss_dice: 0.2590  decode.d7.loss_cls: 0.0097  decode.d7.loss_mask: 0.2147  decode.d7.loss_dice: 0.2496  decode.d8.loss_cls: 0.0425  decode.d8.loss_mask: 0.2180  decode.d8.loss_dice: 0.2510
08/06 08:06:55 - mmengine - INFO - Iter(train) [ 42200/320000]  base_lr: 8.8049e-05 lr: 8.8049e-06  eta: 1 day, 13:59:00  time: 0.4934  data_time: 0.0111  memory: 5928  grad_norm: 230.4390  loss: 6.1895  decode.loss_cls: 0.0673  decode.loss_mask: 0.2225  decode.loss_dice: 0.2453  decode.d0.loss_cls: 0.8048  decode.d0.loss_mask: 0.2224  decode.d0.loss_dice: 0.2293  decode.d1.loss_cls: 0.1273  decode.d1.loss_mask: 0.2252  decode.d1.loss_dice: 0.2674  decode.d2.loss_cls: 0.0908  decode.d2.loss_mask: 0.2259  decode.d2.loss_dice: 0.2432  decode.d3.loss_cls: 0.0847  decode.d3.loss_mask: 0.2292  decode.d3.loss_dice: 0.2431  decode.d4.loss_cls: 0.0822  decode.d4.loss_mask: 0.2208  decode.d4.loss_dice: 0.2272  decode.d5.loss_cls: 0.0629  decode.d5.loss_mask: 0.2237  decode.d5.loss_dice: 0.2417  decode.d6.loss_cls: 0.0717  decode.d6.loss_mask: 0.2338  decode.d6.loss_dice: 0.2368  decode.d7.loss_cls: 0.0630  decode.d7.loss_mask: 0.2262  decode.d7.loss_dice: 0.2406  decode.d8.loss_cls: 0.0691  decode.d8.loss_mask: 0.2287  decode.d8.loss_dice: 0.2328
08/06 08:07:20 - mmengine - INFO - Iter(train) [ 42250/320000]  base_lr: 8.8035e-05 lr: 8.8035e-06  eta: 1 day, 13:58:36  time: 0.4932  data_time: 0.0111  memory: 5894  grad_norm: 71.4823  loss: 7.1006  decode.loss_cls: 0.2135  decode.loss_mask: 0.2161  decode.loss_dice: 0.2323  decode.d0.loss_cls: 0.8431  decode.d0.loss_mask: 0.2042  decode.d0.loss_dice: 0.2309  decode.d1.loss_cls: 0.1733  decode.d1.loss_mask: 0.2211  decode.d1.loss_dice: 0.2376  decode.d2.loss_cls: 0.2150  decode.d2.loss_mask: 0.2205  decode.d2.loss_dice: 0.2311  decode.d3.loss_cls: 0.2218  decode.d3.loss_mask: 0.2168  decode.d3.loss_dice: 0.2284  decode.d4.loss_cls: 0.2187  decode.d4.loss_mask: 0.2216  decode.d4.loss_dice: 0.2163  decode.d5.loss_cls: 0.2202  decode.d5.loss_mask: 0.2135  decode.d5.loss_dice: 0.2231  decode.d6.loss_cls: 0.2029  decode.d6.loss_mask: 0.2223  decode.d6.loss_dice: 0.2269  decode.d7.loss_cls: 0.1464  decode.d7.loss_mask: 0.2258  decode.d7.loss_dice: 0.2605  decode.d8.loss_cls: 0.1488  decode.d8.loss_mask: 0.2194  decode.d8.loss_dice: 0.2282
08/06 08:07:45 - mmengine - INFO - Iter(train) [ 42300/320000]  base_lr: 8.8021e-05 lr: 8.8021e-06  eta: 1 day, 13:58:13  time: 0.4932  data_time: 0.0111  memory: 5894  grad_norm: 149.5663  loss: 6.0611  decode.loss_cls: 0.0735  decode.loss_mask: 0.2306  decode.loss_dice: 0.2351  decode.d0.loss_cls: 0.7040  decode.d0.loss_mask: 0.2280  decode.d0.loss_dice: 0.2382  decode.d1.loss_cls: 0.1349  decode.d1.loss_mask: 0.2305  decode.d1.loss_dice: 0.2438  decode.d2.loss_cls: 0.1049  decode.d2.loss_mask: 0.2294  decode.d2.loss_dice: 0.2321  decode.d3.loss_cls: 0.0760  decode.d3.loss_mask: 0.2266  decode.d3.loss_dice: 0.2311  decode.d4.loss_cls: 0.0703  decode.d4.loss_mask: 0.2287  decode.d4.loss_dice: 0.2307  decode.d5.loss_cls: 0.0733  decode.d5.loss_mask: 0.2261  decode.d5.loss_dice: 0.2378  decode.d6.loss_cls: 0.0619  decode.d6.loss_mask: 0.2256  decode.d6.loss_dice: 0.2340  decode.d7.loss_cls: 0.0665  decode.d7.loss_mask: 0.2256  decode.d7.loss_dice: 0.2343  decode.d8.loss_cls: 0.0578  decode.d8.loss_mask: 0.2278  decode.d8.loss_dice: 0.2420
08/06 08:08:09 - mmengine - INFO - Iter(train) [ 42350/320000]  base_lr: 8.8006e-05 lr: 8.8006e-06  eta: 1 day, 13:57:49  time: 0.4951  data_time: 0.0113  memory: 5874  grad_norm: 132.3416  loss: 6.4082  decode.loss_cls: 0.1160  decode.loss_mask: 0.2310  decode.loss_dice: 0.2001  decode.d0.loss_cls: 0.9299  decode.d0.loss_mask: 0.2389  decode.d0.loss_dice: 0.2176  decode.d1.loss_cls: 0.1398  decode.d1.loss_mask: 0.2279  decode.d1.loss_dice: 0.2069  decode.d2.loss_cls: 0.1533  decode.d2.loss_mask: 0.2290  decode.d2.loss_dice: 0.2064  decode.d3.loss_cls: 0.1303  decode.d3.loss_mask: 0.2297  decode.d3.loss_dice: 0.2053  decode.d4.loss_cls: 0.1526  decode.d4.loss_mask: 0.2292  decode.d4.loss_dice: 0.2114  decode.d5.loss_cls: 0.1211  decode.d5.loss_mask: 0.2302  decode.d5.loss_dice: 0.2139  decode.d6.loss_cls: 0.0790  decode.d6.loss_mask: 0.2309  decode.d6.loss_dice: 0.2071  decode.d7.loss_cls: 0.0829  decode.d7.loss_mask: 0.2302  decode.d7.loss_dice: 0.2034  decode.d8.loss_cls: 0.1220  decode.d8.loss_mask: 0.2306  decode.d8.loss_dice: 0.2014
08/06 08:08:34 - mmengine - INFO - Iter(train) [ 42400/320000]  base_lr: 8.7992e-05 lr: 8.7992e-06  eta: 1 day, 13:57:25  time: 0.4954  data_time: 0.0113  memory: 5894  grad_norm: 221.3468  loss: 6.8546  decode.loss_cls: 0.1569  decode.loss_mask: 0.2458  decode.loss_dice: 0.2376  decode.d0.loss_cls: 0.8869  decode.d0.loss_mask: 0.2138  decode.d0.loss_dice: 0.2219  decode.d1.loss_cls: 0.1691  decode.d1.loss_mask: 0.2192  decode.d1.loss_dice: 0.2210  decode.d2.loss_cls: 0.1520  decode.d2.loss_mask: 0.2169  decode.d2.loss_dice: 0.2174  decode.d3.loss_cls: 0.1491  decode.d3.loss_mask: 0.2136  decode.d3.loss_dice: 0.2188  decode.d4.loss_cls: 0.1375  decode.d4.loss_mask: 0.2217  decode.d4.loss_dice: 0.2208  decode.d5.loss_cls: 0.1506  decode.d5.loss_mask: 0.2210  decode.d5.loss_dice: 0.2325  decode.d6.loss_cls: 0.1653  decode.d6.loss_mask: 0.2437  decode.d6.loss_dice: 0.2351  decode.d7.loss_cls: 0.1510  decode.d7.loss_mask: 0.2576  decode.d7.loss_dice: 0.2316  decode.d8.loss_cls: 0.1681  decode.d8.loss_mask: 0.2444  decode.d8.loss_dice: 0.2336
08/06 08:08:59 - mmengine - INFO - Iter(train) [ 42450/320000]  base_lr: 8.7978e-05 lr: 8.7978e-06  eta: 1 day, 13:57:01  time: 0.4946  data_time: 0.0112  memory: 5895  grad_norm: 49.6504  loss: 6.0382  decode.loss_cls: 0.0437  decode.loss_mask: 0.2392  decode.loss_dice: 0.2231  decode.d0.loss_cls: 0.8724  decode.d0.loss_mask: 0.2420  decode.d0.loss_dice: 0.2455  decode.d1.loss_cls: 0.0354  decode.d1.loss_mask: 0.2397  decode.d1.loss_dice: 0.2301  decode.d2.loss_cls: 0.0367  decode.d2.loss_mask: 0.2405  decode.d2.loss_dice: 0.2456  decode.d3.loss_cls: 0.0551  decode.d3.loss_mask: 0.2362  decode.d3.loss_dice: 0.2364  decode.d4.loss_cls: 0.0568  decode.d4.loss_mask: 0.2397  decode.d4.loss_dice: 0.2291  decode.d5.loss_cls: 0.0498  decode.d5.loss_mask: 0.2407  decode.d5.loss_dice: 0.2462  decode.d6.loss_cls: 0.0306  decode.d6.loss_mask: 0.2399  decode.d6.loss_dice: 0.2388  decode.d7.loss_cls: 0.0258  decode.d7.loss_mask: 0.2398  decode.d7.loss_dice: 0.2491  decode.d8.loss_cls: 0.0614  decode.d8.loss_mask: 0.2391  decode.d8.loss_dice: 0.2297
08/06 08:09:24 - mmengine - INFO - Iter(train) [ 42500/320000]  base_lr: 8.7964e-05 lr: 8.7964e-06  eta: 1 day, 13:56:37  time: 0.4940  data_time: 0.0110  memory: 5911  grad_norm: 139.6174  loss: 6.6014  decode.loss_cls: 0.1350  decode.loss_mask: 0.1945  decode.loss_dice: 0.2597  decode.d0.loss_cls: 0.8168  decode.d0.loss_mask: 0.1954  decode.d0.loss_dice: 0.2443  decode.d1.loss_cls: 0.2257  decode.d1.loss_mask: 0.1974  decode.d1.loss_dice: 0.2771  decode.d2.loss_cls: 0.0949  decode.d2.loss_mask: 0.1988  decode.d2.loss_dice: 0.2488  decode.d3.loss_cls: 0.1181  decode.d3.loss_mask: 0.1967  decode.d3.loss_dice: 0.2552  decode.d4.loss_cls: 0.1323  decode.d4.loss_mask: 0.1963  decode.d4.loss_dice: 0.2666  decode.d5.loss_cls: 0.1225  decode.d5.loss_mask: 0.1987  decode.d5.loss_dice: 0.2788  decode.d6.loss_cls: 0.1065  decode.d6.loss_mask: 0.2009  decode.d6.loss_dice: 0.2690  decode.d7.loss_cls: 0.1165  decode.d7.loss_mask: 0.1999  decode.d7.loss_dice: 0.2640  decode.d8.loss_cls: 0.1199  decode.d8.loss_mask: 0.1992  decode.d8.loss_dice: 0.2719
08/06 08:09:48 - mmengine - INFO - Iter(train) [ 42550/320000]  base_lr: 8.7949e-05 lr: 8.7949e-06  eta: 1 day, 13:56:13  time: 0.4930  data_time: 0.0110  memory: 5859  grad_norm: 109.7251  loss: 6.0341  decode.loss_cls: 0.0471  decode.loss_mask: 0.2334  decode.loss_dice: 0.2330  decode.d0.loss_cls: 0.7668  decode.d0.loss_mask: 0.2319  decode.d0.loss_dice: 0.2349  decode.d1.loss_cls: 0.1355  decode.d1.loss_mask: 0.2312  decode.d1.loss_dice: 0.2307  decode.d2.loss_cls: 0.1217  decode.d2.loss_mask: 0.2294  decode.d2.loss_dice: 0.2243  decode.d3.loss_cls: 0.0805  decode.d3.loss_mask: 0.2313  decode.d3.loss_dice: 0.2295  decode.d4.loss_cls: 0.0502  decode.d4.loss_mask: 0.2303  decode.d4.loss_dice: 0.2307  decode.d5.loss_cls: 0.0625  decode.d5.loss_mask: 0.2281  decode.d5.loss_dice: 0.2303  decode.d6.loss_cls: 0.0595  decode.d6.loss_mask: 0.2278  decode.d6.loss_dice: 0.2271  decode.d7.loss_cls: 0.0467  decode.d7.loss_mask: 0.2316  decode.d7.loss_dice: 0.2323  decode.d8.loss_cls: 0.0550  decode.d8.loss_mask: 0.2319  decode.d8.loss_dice: 0.2289
08/06 08:10:13 - mmengine - INFO - Iter(train) [ 42600/320000]  base_lr: 8.7935e-05 lr: 8.7935e-06  eta: 1 day, 13:55:48  time: 0.4940  data_time: 0.0113  memory: 5891  grad_norm: 67.3077  loss: 7.5805  decode.loss_cls: 0.1136  decode.loss_mask: 0.2058  decode.loss_dice: 0.3139  decode.d0.loss_cls: 0.8766  decode.d0.loss_mask: 0.2113  decode.d0.loss_dice: 0.3364  decode.d1.loss_cls: 0.2913  decode.d1.loss_mask: 0.2044  decode.d1.loss_dice: 0.2993  decode.d2.loss_cls: 0.1906  decode.d2.loss_mask: 0.2079  decode.d2.loss_dice: 0.3070  decode.d3.loss_cls: 0.1517  decode.d3.loss_mask: 0.2066  decode.d3.loss_dice: 0.3038  decode.d4.loss_cls: 0.1489  decode.d4.loss_mask: 0.2049  decode.d4.loss_dice: 0.3218  decode.d5.loss_cls: 0.1573  decode.d5.loss_mask: 0.2051  decode.d5.loss_dice: 0.3191  decode.d6.loss_cls: 0.1654  decode.d6.loss_mask: 0.2058  decode.d6.loss_dice: 0.3039  decode.d7.loss_cls: 0.1428  decode.d7.loss_mask: 0.2059  decode.d7.loss_dice: 0.3195  decode.d8.loss_cls: 0.1468  decode.d8.loss_mask: 0.2078  decode.d8.loss_dice: 0.3051
08/06 08:10:38 - mmengine - INFO - Iter(train) [ 42650/320000]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 1 day, 13:55:24  time: 0.4925  data_time: 0.0108  memory: 5875  grad_norm: 102.3649  loss: 5.7307  decode.loss_cls: 0.0957  decode.loss_mask: 0.1917  decode.loss_dice: 0.2446  decode.d0.loss_cls: 0.9614  decode.d0.loss_mask: 0.1884  decode.d0.loss_dice: 0.2449  decode.d1.loss_cls: 0.0967  decode.d1.loss_mask: 0.1868  decode.d1.loss_dice: 0.2403  decode.d2.loss_cls: 0.0404  decode.d2.loss_mask: 0.1843  decode.d2.loss_dice: 0.2248  decode.d3.loss_cls: 0.0348  decode.d3.loss_mask: 0.1858  decode.d3.loss_dice: 0.2282  decode.d4.loss_cls: 0.0621  decode.d4.loss_mask: 0.1855  decode.d4.loss_dice: 0.2182  decode.d5.loss_cls: 0.0280  decode.d5.loss_mask: 0.1870  decode.d5.loss_dice: 0.2225  decode.d6.loss_cls: 0.0345  decode.d6.loss_mask: 0.1879  decode.d6.loss_dice: 0.2294  decode.d7.loss_cls: 0.0823  decode.d7.loss_mask: 0.1911  decode.d7.loss_dice: 0.2204  decode.d8.loss_cls: 0.1301  decode.d8.loss_mask: 0.1818  decode.d8.loss_dice: 0.2212
08/06 08:11:02 - mmengine - INFO - Iter(train) [ 42700/320000]  base_lr: 8.7907e-05 lr: 8.7907e-06  eta: 1 day, 13:55:00  time: 0.4936  data_time: 0.0111  memory: 5891  grad_norm: 55.7049  loss: 6.0722  decode.loss_cls: 0.0307  decode.loss_mask: 0.2368  decode.loss_dice: 0.2380  decode.d0.loss_cls: 0.7677  decode.d0.loss_mask: 0.2421  decode.d0.loss_dice: 0.2424  decode.d1.loss_cls: 0.0800  decode.d1.loss_mask: 0.2389  decode.d1.loss_dice: 0.2439  decode.d2.loss_cls: 0.0259  decode.d2.loss_mask: 0.2385  decode.d2.loss_dice: 0.2426  decode.d3.loss_cls: 0.0175  decode.d3.loss_mask: 0.2392  decode.d3.loss_dice: 0.2443  decode.d4.loss_cls: 0.0672  decode.d4.loss_mask: 0.2380  decode.d4.loss_dice: 0.2375  decode.d5.loss_cls: 0.0644  decode.d5.loss_mask: 0.2385  decode.d5.loss_dice: 0.2537  decode.d6.loss_cls: 0.0881  decode.d6.loss_mask: 0.2372  decode.d6.loss_dice: 0.2544  decode.d7.loss_cls: 0.0356  decode.d7.loss_mask: 0.2390  decode.d7.loss_dice: 0.2522  decode.d8.loss_cls: 0.0436  decode.d8.loss_mask: 0.2377  decode.d8.loss_dice: 0.2568
08/06 08:11:27 - mmengine - INFO - Iter(train) [ 42750/320000]  base_lr: 8.7892e-05 lr: 8.7892e-06  eta: 1 day, 13:54:36  time: 0.4927  data_time: 0.0111  memory: 5890  grad_norm: 98.6497  loss: 9.7065  decode.loss_cls: 0.1947  decode.loss_mask: 0.2686  decode.loss_dice: 0.3927  decode.d0.loss_cls: 0.7996  decode.d0.loss_mask: 0.2683  decode.d0.loss_dice: 0.3855  decode.d1.loss_cls: 0.2867  decode.d1.loss_mask: 0.2675  decode.d1.loss_dice: 0.3864  decode.d2.loss_cls: 0.2551  decode.d2.loss_mask: 0.2689  decode.d2.loss_dice: 0.4130  decode.d3.loss_cls: 0.2613  decode.d3.loss_mask: 0.2682  decode.d3.loss_dice: 0.3959  decode.d4.loss_cls: 0.3162  decode.d4.loss_mask: 0.2673  decode.d4.loss_dice: 0.3909  decode.d5.loss_cls: 0.2364  decode.d5.loss_mask: 0.2639  decode.d5.loss_dice: 0.4063  decode.d6.loss_cls: 0.2285  decode.d6.loss_mask: 0.2643  decode.d6.loss_dice: 0.4036  decode.d7.loss_cls: 0.2598  decode.d7.loss_mask: 0.2683  decode.d7.loss_dice: 0.4028  decode.d8.loss_cls: 0.2030  decode.d8.loss_mask: 0.2789  decode.d8.loss_dice: 0.4041
08/06 08:11:52 - mmengine - INFO - Iter(train) [ 42800/320000]  base_lr: 8.7878e-05 lr: 8.7878e-06  eta: 1 day, 13:54:13  time: 0.4938  data_time: 0.0110  memory: 5878  grad_norm: 82.3995  loss: 8.5041  decode.loss_cls: 0.0476  decode.loss_mask: 0.3585  decode.loss_dice: 0.3506  decode.d0.loss_cls: 0.8605  decode.d0.loss_mask: 0.3712  decode.d0.loss_dice: 0.3451  decode.d1.loss_cls: 0.1003  decode.d1.loss_mask: 0.3641  decode.d1.loss_dice: 0.3430  decode.d2.loss_cls: 0.0746  decode.d2.loss_mask: 0.3594  decode.d2.loss_dice: 0.3472  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 0.3601  decode.d3.loss_dice: 0.3486  decode.d4.loss_cls: 0.1077  decode.d4.loss_mask: 0.3565  decode.d4.loss_dice: 0.3419  decode.d5.loss_cls: 0.0583  decode.d5.loss_mask: 0.3552  decode.d5.loss_dice: 0.3532  decode.d6.loss_cls: 0.0411  decode.d6.loss_mask: 0.3572  decode.d6.loss_dice: 0.3491  decode.d7.loss_cls: 0.0414  decode.d7.loss_mask: 0.3606  decode.d7.loss_dice: 0.3394  decode.d8.loss_cls: 0.0495  decode.d8.loss_mask: 0.3622  decode.d8.loss_dice: 0.3371
08/06 08:12:17 - mmengine - INFO - Iter(train) [ 42850/320000]  base_lr: 8.7864e-05 lr: 8.7864e-06  eta: 1 day, 13:53:48  time: 0.4937  data_time: 0.0111  memory: 5913  grad_norm: 68.6443  loss: 6.7914  decode.loss_cls: 0.0283  decode.loss_mask: 0.2819  decode.loss_dice: 0.2758  decode.d0.loss_cls: 0.7536  decode.d0.loss_mask: 0.2903  decode.d0.loss_dice: 0.2897  decode.d1.loss_cls: 0.0924  decode.d1.loss_mask: 0.2927  decode.d1.loss_dice: 0.2760  decode.d2.loss_cls: 0.0827  decode.d2.loss_mask: 0.2854  decode.d2.loss_dice: 0.2878  decode.d3.loss_cls: 0.0643  decode.d3.loss_mask: 0.2904  decode.d3.loss_dice: 0.2791  decode.d4.loss_cls: 0.0503  decode.d4.loss_mask: 0.2740  decode.d4.loss_dice: 0.2803  decode.d5.loss_cls: 0.0185  decode.d5.loss_mask: 0.2801  decode.d5.loss_dice: 0.2783  decode.d6.loss_cls: 0.0221  decode.d6.loss_mask: 0.2818  decode.d6.loss_dice: 0.2751  decode.d7.loss_cls: 0.0217  decode.d7.loss_mask: 0.2847  decode.d7.loss_dice: 0.2748  decode.d8.loss_cls: 0.0224  decode.d8.loss_mask: 0.2838  decode.d8.loss_dice: 0.2729
08/06 08:12:41 - mmengine - INFO - Iter(train) [ 42900/320000]  base_lr: 8.7849e-05 lr: 8.7849e-06  eta: 1 day, 13:53:24  time: 0.4922  data_time: 0.0110  memory: 5891  grad_norm: 87.7933  loss: 7.5421  decode.loss_cls: 0.1119  decode.loss_mask: 0.2813  decode.loss_dice: 0.2868  decode.d0.loss_cls: 0.7559  decode.d0.loss_mask: 0.2916  decode.d0.loss_dice: 0.3044  decode.d1.loss_cls: 0.0855  decode.d1.loss_mask: 0.2820  decode.d1.loss_dice: 0.2869  decode.d2.loss_cls: 0.1315  decode.d2.loss_mask: 0.2839  decode.d2.loss_dice: 0.2918  decode.d3.loss_cls: 0.0888  decode.d3.loss_mask: 0.2852  decode.d3.loss_dice: 0.2919  decode.d4.loss_cls: 0.1079  decode.d4.loss_mask: 0.2847  decode.d4.loss_dice: 0.2882  decode.d5.loss_cls: 0.1339  decode.d5.loss_mask: 0.2845  decode.d5.loss_dice: 0.3037  decode.d6.loss_cls: 0.1390  decode.d6.loss_mask: 0.2827  decode.d6.loss_dice: 0.2957  decode.d7.loss_cls: 0.0954  decode.d7.loss_mask: 0.2843  decode.d7.loss_dice: 0.2917  decode.d8.loss_cls: 0.1232  decode.d8.loss_mask: 0.2798  decode.d8.loss_dice: 0.2884
08/06 08:13:06 - mmengine - INFO - Iter(train) [ 42950/320000]  base_lr: 8.7835e-05 lr: 8.7835e-06  eta: 1 day, 13:53:00  time: 0.4935  data_time: 0.0114  memory: 5911  grad_norm: 86.0439  loss: 7.4375  decode.loss_cls: 0.0723  decode.loss_mask: 0.2837  decode.loss_dice: 0.2796  decode.d0.loss_cls: 0.8713  decode.d0.loss_mask: 0.2869  decode.d0.loss_dice: 0.2800  decode.d1.loss_cls: 0.1301  decode.d1.loss_mask: 0.2813  decode.d1.loss_dice: 0.2830  decode.d2.loss_cls: 0.0973  decode.d2.loss_mask: 0.2857  decode.d2.loss_dice: 0.2969  decode.d3.loss_cls: 0.0909  decode.d3.loss_mask: 0.2827  decode.d3.loss_dice: 0.2807  decode.d4.loss_cls: 0.1007  decode.d4.loss_mask: 0.2864  decode.d4.loss_dice: 0.2854  decode.d5.loss_cls: 0.0998  decode.d5.loss_mask: 0.2818  decode.d5.loss_dice: 0.2900  decode.d6.loss_cls: 0.1005  decode.d6.loss_mask: 0.2811  decode.d6.loss_dice: 0.2830  decode.d7.loss_cls: 0.0982  decode.d7.loss_mask: 0.2833  decode.d7.loss_dice: 0.2868  decode.d8.loss_cls: 0.0885  decode.d8.loss_mask: 0.2867  decode.d8.loss_dice: 0.2830
08/06 08:13:31 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 08:13:31 - mmengine - INFO - Iter(train) [ 43000/320000]  base_lr: 8.7821e-05 lr: 8.7821e-06  eta: 1 day, 13:52:36  time: 0.4930  data_time: 0.0110  memory: 5894  grad_norm: 74.4115  loss: 7.1188  decode.loss_cls: 0.1167  decode.loss_mask: 0.2621  decode.loss_dice: 0.2585  decode.d0.loss_cls: 0.9338  decode.d0.loss_mask: 0.2663  decode.d0.loss_dice: 0.2485  decode.d1.loss_cls: 0.1057  decode.d1.loss_mask: 0.2647  decode.d1.loss_dice: 0.2556  decode.d2.loss_cls: 0.1288  decode.d2.loss_mask: 0.2611  decode.d2.loss_dice: 0.2436  decode.d3.loss_cls: 0.0895  decode.d3.loss_mask: 0.2678  decode.d3.loss_dice: 0.2516  decode.d4.loss_cls: 0.1553  decode.d4.loss_mask: 0.2657  decode.d4.loss_dice: 0.2494  decode.d5.loss_cls: 0.1518  decode.d5.loss_mask: 0.2670  decode.d5.loss_dice: 0.2558  decode.d6.loss_cls: 0.0984  decode.d6.loss_mask: 0.2629  decode.d6.loss_dice: 0.2433  decode.d7.loss_cls: 0.1043  decode.d7.loss_mask: 0.2642  decode.d7.loss_dice: 0.2445  decode.d8.loss_cls: 0.0980  decode.d8.loss_mask: 0.2613  decode.d8.loss_dice: 0.2426
08/06 08:13:55 - mmengine - INFO - Iter(train) [ 43050/320000]  base_lr: 8.7807e-05 lr: 8.7807e-06  eta: 1 day, 13:52:12  time: 0.4929  data_time: 0.0111  memory: 5911  grad_norm: 76.7055  loss: 6.4262  decode.loss_cls: 0.1054  decode.loss_mask: 0.2204  decode.loss_dice: 0.2664  decode.d0.loss_cls: 0.9127  decode.d0.loss_mask: 0.2227  decode.d0.loss_dice: 0.2575  decode.d1.loss_cls: 0.1006  decode.d1.loss_mask: 0.2197  decode.d1.loss_dice: 0.2580  decode.d2.loss_cls: 0.1064  decode.d2.loss_mask: 0.2184  decode.d2.loss_dice: 0.2662  decode.d3.loss_cls: 0.0486  decode.d3.loss_mask: 0.2185  decode.d3.loss_dice: 0.2721  decode.d4.loss_cls: 0.1090  decode.d4.loss_mask: 0.2179  decode.d4.loss_dice: 0.2701  decode.d5.loss_cls: 0.0457  decode.d5.loss_mask: 0.2185  decode.d5.loss_dice: 0.2702  decode.d6.loss_cls: 0.0433  decode.d6.loss_mask: 0.2176  decode.d6.loss_dice: 0.2643  decode.d7.loss_cls: 0.0493  decode.d7.loss_mask: 0.2203  decode.d7.loss_dice: 0.2764  decode.d8.loss_cls: 0.0398  decode.d8.loss_mask: 0.2204  decode.d8.loss_dice: 0.2697
08/06 08:14:20 - mmengine - INFO - Iter(train) [ 43100/320000]  base_lr: 8.7792e-05 lr: 8.7792e-06  eta: 1 day, 13:51:49  time: 0.4934  data_time: 0.0110  memory: 5931  grad_norm: 220.5141  loss: 6.9839  decode.loss_cls: 0.0831  decode.loss_mask: 0.2641  decode.loss_dice: 0.2853  decode.d0.loss_cls: 0.7999  decode.d0.loss_mask: 0.2712  decode.d0.loss_dice: 0.2813  decode.d1.loss_cls: 0.1024  decode.d1.loss_mask: 0.2640  decode.d1.loss_dice: 0.2742  decode.d2.loss_cls: 0.0430  decode.d2.loss_mask: 0.2596  decode.d2.loss_dice: 0.3126  decode.d3.loss_cls: 0.0488  decode.d3.loss_mask: 0.2674  decode.d3.loss_dice: 0.3055  decode.d4.loss_cls: 0.0879  decode.d4.loss_mask: 0.2634  decode.d4.loss_dice: 0.3126  decode.d5.loss_cls: 0.0636  decode.d5.loss_mask: 0.2508  decode.d5.loss_dice: 0.3144  decode.d6.loss_cls: 0.0471  decode.d6.loss_mask: 0.2500  decode.d6.loss_dice: 0.3104  decode.d7.loss_cls: 0.0561  decode.d7.loss_mask: 0.2614  decode.d7.loss_dice: 0.2727  decode.d8.loss_cls: 0.0521  decode.d8.loss_mask: 0.2637  decode.d8.loss_dice: 0.3154
08/06 08:14:45 - mmengine - INFO - Iter(train) [ 43150/320000]  base_lr: 8.7778e-05 lr: 8.7778e-06  eta: 1 day, 13:51:25  time: 0.4933  data_time: 0.0111  memory: 5911  grad_norm: 70.3833  loss: 5.5873  decode.loss_cls: 0.0426  decode.loss_mask: 0.2122  decode.loss_dice: 0.2274  decode.d0.loss_cls: 0.7976  decode.d0.loss_mask: 0.2154  decode.d0.loss_dice: 0.2198  decode.d1.loss_cls: 0.0582  decode.d1.loss_mask: 0.2145  decode.d1.loss_dice: 0.2226  decode.d2.loss_cls: 0.0469  decode.d2.loss_mask: 0.2118  decode.d2.loss_dice: 0.2236  decode.d3.loss_cls: 0.0425  decode.d3.loss_mask: 0.2143  decode.d3.loss_dice: 0.2226  decode.d4.loss_cls: 0.0510  decode.d4.loss_mask: 0.2125  decode.d4.loss_dice: 0.2202  decode.d5.loss_cls: 0.0654  decode.d5.loss_mask: 0.2113  decode.d5.loss_dice: 0.2221  decode.d6.loss_cls: 0.0544  decode.d6.loss_mask: 0.2147  decode.d6.loss_dice: 0.2235  decode.d7.loss_cls: 0.0327  decode.d7.loss_mask: 0.2127  decode.d7.loss_dice: 0.2337  decode.d8.loss_cls: 0.0318  decode.d8.loss_mask: 0.2136  decode.d8.loss_dice: 0.2157
08/06 08:15:10 - mmengine - INFO - Iter(train) [ 43200/320000]  base_lr: 8.7764e-05 lr: 8.7764e-06  eta: 1 day, 13:51:00  time: 0.4941  data_time: 0.0112  memory: 5891  grad_norm: 339.1559  loss: 6.6734  decode.loss_cls: 0.0454  decode.loss_mask: 0.2243  decode.loss_dice: 0.2917  decode.d0.loss_cls: 0.9880  decode.d0.loss_mask: 0.2382  decode.d0.loss_dice: 0.2970  decode.d1.loss_cls: 0.0468  decode.d1.loss_mask: 0.2277  decode.d1.loss_dice: 0.2890  decode.d2.loss_cls: 0.0715  decode.d2.loss_mask: 0.2233  decode.d2.loss_dice: 0.2937  decode.d3.loss_cls: 0.0373  decode.d3.loss_mask: 0.2244  decode.d3.loss_dice: 0.2927  decode.d4.loss_cls: 0.0507  decode.d4.loss_mask: 0.2226  decode.d4.loss_dice: 0.2892  decode.d5.loss_cls: 0.0381  decode.d5.loss_mask: 0.2253  decode.d5.loss_dice: 0.2944  decode.d6.loss_cls: 0.0734  decode.d6.loss_mask: 0.2221  decode.d6.loss_dice: 0.2854  decode.d7.loss_cls: 0.0452  decode.d7.loss_mask: 0.2270  decode.d7.loss_dice: 0.3059  decode.d8.loss_cls: 0.0754  decode.d8.loss_mask: 0.2266  decode.d8.loss_dice: 0.3010
08/06 08:15:34 - mmengine - INFO - Iter(train) [ 43250/320000]  base_lr: 8.7750e-05 lr: 8.7750e-06  eta: 1 day, 13:50:36  time: 0.4928  data_time: 0.0110  memory: 5911  grad_norm: 158.0531  loss: 6.8058  decode.loss_cls: 0.1658  decode.loss_mask: 0.2456  decode.loss_dice: 0.2584  decode.d0.loss_cls: 0.8377  decode.d0.loss_mask: 0.2613  decode.d0.loss_dice: 0.2525  decode.d1.loss_cls: 0.0689  decode.d1.loss_mask: 0.2721  decode.d1.loss_dice: 0.2592  decode.d2.loss_cls: 0.0538  decode.d2.loss_mask: 0.2608  decode.d2.loss_dice: 0.2587  decode.d3.loss_cls: 0.0888  decode.d3.loss_mask: 0.2484  decode.d3.loss_dice: 0.2565  decode.d4.loss_cls: 0.0770  decode.d4.loss_mask: 0.2357  decode.d4.loss_dice: 0.2439  decode.d5.loss_cls: 0.0776  decode.d5.loss_mask: 0.2447  decode.d5.loss_dice: 0.2534  decode.d6.loss_cls: 0.1359  decode.d6.loss_mask: 0.2438  decode.d6.loss_dice: 0.2530  decode.d7.loss_cls: 0.1428  decode.d7.loss_mask: 0.2530  decode.d7.loss_dice: 0.2509  decode.d8.loss_cls: 0.1077  decode.d8.loss_mask: 0.2568  decode.d8.loss_dice: 0.2412
08/06 08:15:59 - mmengine - INFO - Iter(train) [ 43300/320000]  base_lr: 8.7735e-05 lr: 8.7735e-06  eta: 1 day, 13:50:12  time: 0.4927  data_time: 0.0111  memory: 5891  grad_norm: 299.3355  loss: 5.7577  decode.loss_cls: 0.0772  decode.loss_mask: 0.1828  decode.loss_dice: 0.2144  decode.d0.loss_cls: 0.8186  decode.d0.loss_mask: 0.1952  decode.d0.loss_dice: 0.2334  decode.d1.loss_cls: 0.1747  decode.d1.loss_mask: 0.1813  decode.d1.loss_dice: 0.2119  decode.d2.loss_cls: 0.1567  decode.d2.loss_mask: 0.1826  decode.d2.loss_dice: 0.2189  decode.d3.loss_cls: 0.1255  decode.d3.loss_mask: 0.1829  decode.d3.loss_dice: 0.2170  decode.d4.loss_cls: 0.0922  decode.d4.loss_mask: 0.1827  decode.d4.loss_dice: 0.2159  decode.d5.loss_cls: 0.0788  decode.d5.loss_mask: 0.1813  decode.d5.loss_dice: 0.2188  decode.d6.loss_cls: 0.0755  decode.d6.loss_mask: 0.1807  decode.d6.loss_dice: 0.2172  decode.d7.loss_cls: 0.0863  decode.d7.loss_mask: 0.1823  decode.d7.loss_dice: 0.2076  decode.d8.loss_cls: 0.0692  decode.d8.loss_mask: 0.1829  decode.d8.loss_dice: 0.2132
08/06 08:16:24 - mmengine - INFO - Iter(train) [ 43350/320000]  base_lr: 8.7721e-05 lr: 8.7721e-06  eta: 1 day, 13:49:48  time: 0.4941  data_time: 0.0112  memory: 5930  grad_norm: 136.8926  loss: 7.2094  decode.loss_cls: 0.1695  decode.loss_mask: 0.2174  decode.loss_dice: 0.2732  decode.d0.loss_cls: 1.0016  decode.d0.loss_mask: 0.2238  decode.d0.loss_dice: 0.2672  decode.d1.loss_cls: 0.2271  decode.d1.loss_mask: 0.2167  decode.d1.loss_dice: 0.2714  decode.d2.loss_cls: 0.1345  decode.d2.loss_mask: 0.2200  decode.d2.loss_dice: 0.2916  decode.d3.loss_cls: 0.1161  decode.d3.loss_mask: 0.2203  decode.d3.loss_dice: 0.2677  decode.d4.loss_cls: 0.1138  decode.d4.loss_mask: 0.2211  decode.d4.loss_dice: 0.2814  decode.d5.loss_cls: 0.1093  decode.d5.loss_mask: 0.2210  decode.d5.loss_dice: 0.2748  decode.d6.loss_cls: 0.1289  decode.d6.loss_mask: 0.2187  decode.d6.loss_dice: 0.2772  decode.d7.loss_cls: 0.1243  decode.d7.loss_mask: 0.2181  decode.d7.loss_dice: 0.2816  decode.d8.loss_cls: 0.1235  decode.d8.loss_mask: 0.2174  decode.d8.loss_dice: 0.2801
08/06 08:16:48 - mmengine - INFO - Iter(train) [ 43400/320000]  base_lr: 8.7707e-05 lr: 8.7707e-06  eta: 1 day, 13:49:24  time: 0.4940  data_time: 0.0113  memory: 5875  grad_norm: 267.1391  loss: 7.9582  decode.loss_cls: 0.1956  decode.loss_mask: 0.1927  decode.loss_dice: 0.3133  decode.d0.loss_cls: 0.9572  decode.d0.loss_mask: 0.1981  decode.d0.loss_dice: 0.3230  decode.d1.loss_cls: 0.2001  decode.d1.loss_mask: 0.1926  decode.d1.loss_dice: 0.2856  decode.d2.loss_cls: 0.2614  decode.d2.loss_mask: 0.1935  decode.d2.loss_dice: 0.2947  decode.d3.loss_cls: 0.2580  decode.d3.loss_mask: 0.1912  decode.d3.loss_dice: 0.2899  decode.d4.loss_cls: 0.2295  decode.d4.loss_mask: 0.1934  decode.d4.loss_dice: 0.2908  decode.d5.loss_cls: 0.2612  decode.d5.loss_mask: 0.1904  decode.d5.loss_dice: 0.2977  decode.d6.loss_cls: 0.2103  decode.d6.loss_mask: 0.1913  decode.d6.loss_dice: 0.3013  decode.d7.loss_cls: 0.2330  decode.d7.loss_mask: 0.1919  decode.d7.loss_dice: 0.2887  decode.d8.loss_cls: 0.2301  decode.d8.loss_mask: 0.1923  decode.d8.loss_dice: 0.3093
08/06 08:17:13 - mmengine - INFO - Iter(train) [ 43450/320000]  base_lr: 8.7693e-05 lr: 8.7693e-06  eta: 1 day, 13:49:00  time: 0.4934  data_time: 0.0112  memory: 5891  grad_norm: 111.2736  loss: 8.7401  decode.loss_cls: 0.1870  decode.loss_mask: 0.2792  decode.loss_dice: 0.3269  decode.d0.loss_cls: 0.8863  decode.d0.loss_mask: 0.2933  decode.d0.loss_dice: 0.3298  decode.d1.loss_cls: 0.1896  decode.d1.loss_mask: 0.2766  decode.d1.loss_dice: 0.3319  decode.d2.loss_cls: 0.1691  decode.d2.loss_mask: 0.2774  decode.d2.loss_dice: 0.3151  decode.d3.loss_cls: 0.2107  decode.d3.loss_mask: 0.2765  decode.d3.loss_dice: 0.3302  decode.d4.loss_cls: 0.1820  decode.d4.loss_mask: 0.2826  decode.d4.loss_dice: 0.3450  decode.d5.loss_cls: 0.1797  decode.d5.loss_mask: 0.2825  decode.d5.loss_dice: 0.3419  decode.d6.loss_cls: 0.1969  decode.d6.loss_mask: 0.2767  decode.d6.loss_dice: 0.3364  decode.d7.loss_cls: 0.2056  decode.d7.loss_mask: 0.2807  decode.d7.loss_dice: 0.3415  decode.d8.loss_cls: 0.1979  decode.d8.loss_mask: 0.2784  decode.d8.loss_dice: 0.3328
08/06 08:17:38 - mmengine - INFO - Iter(train) [ 43500/320000]  base_lr: 8.7678e-05 lr: 8.7678e-06  eta: 1 day, 13:48:36  time: 0.4948  data_time: 0.0112  memory: 5911  grad_norm: 124.4360  loss: 7.1654  decode.loss_cls: 0.0987  decode.loss_mask: 0.2547  decode.loss_dice: 0.2882  decode.d0.loss_cls: 0.7882  decode.d0.loss_mask: 0.2589  decode.d0.loss_dice: 0.2899  decode.d1.loss_cls: 0.0664  decode.d1.loss_mask: 0.2541  decode.d1.loss_dice: 0.3055  decode.d2.loss_cls: 0.1331  decode.d2.loss_mask: 0.2517  decode.d2.loss_dice: 0.2961  decode.d3.loss_cls: 0.0508  decode.d3.loss_mask: 0.2505  decode.d3.loss_dice: 0.2991  decode.d4.loss_cls: 0.1227  decode.d4.loss_mask: 0.2550  decode.d4.loss_dice: 0.2832  decode.d5.loss_cls: 0.1131  decode.d5.loss_mask: 0.2575  decode.d5.loss_dice: 0.2904  decode.d6.loss_cls: 0.1011  decode.d6.loss_mask: 0.2535  decode.d6.loss_dice: 0.2910  decode.d7.loss_cls: 0.1280  decode.d7.loss_mask: 0.2553  decode.d7.loss_dice: 0.2855  decode.d8.loss_cls: 0.1094  decode.d8.loss_mask: 0.2530  decode.d8.loss_dice: 0.2807
08/06 08:18:02 - mmengine - INFO - Iter(train) [ 43550/320000]  base_lr: 8.7664e-05 lr: 8.7664e-06  eta: 1 day, 13:48:12  time: 0.4931  data_time: 0.0109  memory: 5891  grad_norm: 196.6230  loss: 6.3044  decode.loss_cls: 0.0223  decode.loss_mask: 0.2530  decode.loss_dice: 0.2483  decode.d0.loss_cls: 0.7598  decode.d0.loss_mask: 0.2532  decode.d0.loss_dice: 0.2529  decode.d1.loss_cls: 0.1137  decode.d1.loss_mask: 0.2450  decode.d1.loss_dice: 0.2492  decode.d2.loss_cls: 0.0434  decode.d2.loss_mask: 0.2547  decode.d2.loss_dice: 0.2610  decode.d3.loss_cls: 0.0919  decode.d3.loss_mask: 0.2467  decode.d3.loss_dice: 0.2453  decode.d4.loss_cls: 0.0604  decode.d4.loss_mask: 0.2585  decode.d4.loss_dice: 0.2576  decode.d5.loss_cls: 0.0734  decode.d5.loss_mask: 0.2519  decode.d5.loss_dice: 0.2491  decode.d6.loss_cls: 0.0277  decode.d6.loss_mask: 0.2509  decode.d6.loss_dice: 0.2594  decode.d7.loss_cls: 0.0313  decode.d7.loss_mask: 0.2524  decode.d7.loss_dice: 0.2551  decode.d8.loss_cls: 0.0322  decode.d8.loss_mask: 0.2516  decode.d8.loss_dice: 0.2525
08/06 08:18:27 - mmengine - INFO - Iter(train) [ 43600/320000]  base_lr: 8.7650e-05 lr: 8.7650e-06  eta: 1 day, 13:47:48  time: 0.4951  data_time: 0.0112  memory: 5895  grad_norm: 55.8807  loss: 6.2036  decode.loss_cls: 0.1795  decode.loss_mask: 0.1993  decode.loss_dice: 0.2024  decode.d0.loss_cls: 0.8601  decode.d0.loss_mask: 0.2047  decode.d0.loss_dice: 0.2077  decode.d1.loss_cls: 0.1550  decode.d1.loss_mask: 0.1998  decode.d1.loss_dice: 0.2089  decode.d2.loss_cls: 0.1698  decode.d2.loss_mask: 0.1996  decode.d2.loss_dice: 0.2076  decode.d3.loss_cls: 0.1531  decode.d3.loss_mask: 0.2008  decode.d3.loss_dice: 0.2016  decode.d4.loss_cls: 0.1572  decode.d4.loss_mask: 0.1984  decode.d4.loss_dice: 0.2072  decode.d5.loss_cls: 0.1383  decode.d5.loss_mask: 0.1987  decode.d5.loss_dice: 0.2029  decode.d6.loss_cls: 0.1062  decode.d6.loss_mask: 0.1977  decode.d6.loss_dice: 0.2132  decode.d7.loss_cls: 0.1011  decode.d7.loss_mask: 0.1986  decode.d7.loss_dice: 0.2133  decode.d8.loss_cls: 0.1097  decode.d8.loss_mask: 0.2008  decode.d8.loss_dice: 0.2102
08/06 08:18:52 - mmengine - INFO - Iter(train) [ 43650/320000]  base_lr: 8.7635e-05 lr: 8.7635e-06  eta: 1 day, 13:47:23  time: 0.4940  data_time: 0.0111  memory: 5911  grad_norm: 128.3977  loss: 8.5443  decode.loss_cls: 0.0678  decode.loss_mask: 0.2837  decode.loss_dice: 0.3557  decode.d0.loss_cls: 0.9409  decode.d0.loss_mask: 0.2931  decode.d0.loss_dice: 0.3711  decode.d1.loss_cls: 0.1881  decode.d1.loss_mask: 0.2884  decode.d1.loss_dice: 0.3689  decode.d2.loss_cls: 0.1522  decode.d2.loss_mask: 0.2869  decode.d2.loss_dice: 0.3744  decode.d3.loss_cls: 0.1545  decode.d3.loss_mask: 0.2864  decode.d3.loss_dice: 0.3782  decode.d4.loss_cls: 0.0816  decode.d4.loss_mask: 0.2850  decode.d4.loss_dice: 0.3819  decode.d5.loss_cls: 0.1094  decode.d5.loss_mask: 0.2825  decode.d5.loss_dice: 0.3727  decode.d6.loss_cls: 0.0681  decode.d6.loss_mask: 0.2843  decode.d6.loss_dice: 0.3689  decode.d7.loss_cls: 0.1095  decode.d7.loss_mask: 0.2875  decode.d7.loss_dice: 0.3721  decode.d8.loss_cls: 0.1006  decode.d8.loss_mask: 0.2843  decode.d8.loss_dice: 0.3656
08/06 08:19:17 - mmengine - INFO - Iter(train) [ 43700/320000]  base_lr: 8.7621e-05 lr: 8.7621e-06  eta: 1 day, 13:47:00  time: 0.4937  data_time: 0.0111  memory: 5894  grad_norm: 270.3574  loss: 8.2517  decode.loss_cls: 0.1857  decode.loss_mask: 0.2653  decode.loss_dice: 0.2416  decode.d0.loss_cls: 1.0726  decode.d0.loss_mask: 0.2658  decode.d0.loss_dice: 0.2632  decode.d1.loss_cls: 0.3391  decode.d1.loss_mask: 0.2615  decode.d1.loss_dice: 0.2589  decode.d2.loss_cls: 0.3074  decode.d2.loss_mask: 0.2636  decode.d2.loss_dice: 0.2488  decode.d3.loss_cls: 0.2037  decode.d3.loss_mask: 0.2625  decode.d3.loss_dice: 0.2480  decode.d4.loss_cls: 0.1961  decode.d4.loss_mask: 0.2614  decode.d4.loss_dice: 0.2518  decode.d5.loss_cls: 0.2776  decode.d5.loss_mask: 0.2607  decode.d5.loss_dice: 0.2417  decode.d6.loss_cls: 0.1817  decode.d6.loss_mask: 0.2626  decode.d6.loss_dice: 0.2477  decode.d7.loss_cls: 0.1839  decode.d7.loss_mask: 0.2593  decode.d7.loss_dice: 0.2467  decode.d8.loss_cls: 0.1856  decode.d8.loss_mask: 0.2651  decode.d8.loss_dice: 0.2423
08/06 08:19:41 - mmengine - INFO - Iter(train) [ 43750/320000]  base_lr: 8.7607e-05 lr: 8.7607e-06  eta: 1 day, 13:46:36  time: 0.4938  data_time: 0.0109  memory: 5913  grad_norm: 112.1556  loss: 6.8597  decode.loss_cls: 0.1299  decode.loss_mask: 0.2013  decode.loss_dice: 0.2605  decode.d0.loss_cls: 0.8881  decode.d0.loss_mask: 0.2013  decode.d0.loss_dice: 0.2820  decode.d1.loss_cls: 0.1810  decode.d1.loss_mask: 0.2047  decode.d1.loss_dice: 0.2763  decode.d2.loss_cls: 0.1098  decode.d2.loss_mask: 0.1994  decode.d2.loss_dice: 0.2996  decode.d3.loss_cls: 0.1614  decode.d3.loss_mask: 0.2013  decode.d3.loss_dice: 0.2798  decode.d4.loss_cls: 0.1364  decode.d4.loss_mask: 0.1994  decode.d4.loss_dice: 0.2667  decode.d5.loss_cls: 0.1110  decode.d5.loss_mask: 0.2002  decode.d5.loss_dice: 0.2767  decode.d6.loss_cls: 0.1366  decode.d6.loss_mask: 0.2013  decode.d6.loss_dice: 0.2735  decode.d7.loss_cls: 0.1071  decode.d7.loss_mask: 0.2011  decode.d7.loss_dice: 0.2783  decode.d8.loss_cls: 0.1125  decode.d8.loss_mask: 0.1995  decode.d8.loss_dice: 0.2833
08/06 08:20:06 - mmengine - INFO - Iter(train) [ 43800/320000]  base_lr: 8.7593e-05 lr: 8.7593e-06  eta: 1 day, 13:46:12  time: 0.4928  data_time: 0.0110  memory: 5891  grad_norm: 146.2196  loss: 8.9406  decode.loss_cls: 0.2174  decode.loss_mask: 0.2292  decode.loss_dice: 0.3136  decode.d0.loss_cls: 1.0520  decode.d0.loss_mask: 0.2370  decode.d0.loss_dice: 0.3161  decode.d1.loss_cls: 0.2774  decode.d1.loss_mask: 0.2284  decode.d1.loss_dice: 0.3161  decode.d2.loss_cls: 0.3124  decode.d2.loss_mask: 0.2254  decode.d2.loss_dice: 0.3136  decode.d3.loss_cls: 0.2221  decode.d3.loss_mask: 0.2255  decode.d3.loss_dice: 0.3039  decode.d4.loss_cls: 0.3147  decode.d4.loss_mask: 0.2289  decode.d4.loss_dice: 0.3180  decode.d5.loss_cls: 0.2959  decode.d5.loss_mask: 0.2272  decode.d5.loss_dice: 0.3058  decode.d6.loss_cls: 0.3248  decode.d6.loss_mask: 0.2277  decode.d6.loss_dice: 0.3147  decode.d7.loss_cls: 0.2360  decode.d7.loss_mask: 0.2303  decode.d7.loss_dice: 0.3100  decode.d8.loss_cls: 0.2714  decode.d8.loss_mask: 0.2276  decode.d8.loss_dice: 0.3175
08/06 08:20:31 - mmengine - INFO - Iter(train) [ 43850/320000]  base_lr: 8.7578e-05 lr: 8.7578e-06  eta: 1 day, 13:45:48  time: 0.4935  data_time: 0.0108  memory: 5894  grad_norm: 82.7630  loss: 6.8976  decode.loss_cls: 0.1911  decode.loss_mask: 0.1872  decode.loss_dice: 0.2361  decode.d0.loss_cls: 0.9902  decode.d0.loss_mask: 0.1884  decode.d0.loss_dice: 0.2293  decode.d1.loss_cls: 0.1955  decode.d1.loss_mask: 0.1897  decode.d1.loss_dice: 0.2412  decode.d2.loss_cls: 0.1430  decode.d2.loss_mask: 0.1921  decode.d2.loss_dice: 0.2411  decode.d3.loss_cls: 0.1771  decode.d3.loss_mask: 0.1940  decode.d3.loss_dice: 0.2347  decode.d4.loss_cls: 0.1716  decode.d4.loss_mask: 0.1892  decode.d4.loss_dice: 0.2364  decode.d5.loss_cls: 0.2632  decode.d5.loss_mask: 0.1892  decode.d5.loss_dice: 0.2232  decode.d6.loss_cls: 0.1940  decode.d6.loss_mask: 0.1875  decode.d6.loss_dice: 0.2250  decode.d7.loss_cls: 0.1782  decode.d7.loss_mask: 0.1902  decode.d7.loss_dice: 0.2349  decode.d8.loss_cls: 0.1618  decode.d8.loss_mask: 0.1892  decode.d8.loss_dice: 0.2332
08/06 08:20:55 - mmengine - INFO - Iter(train) [ 43900/320000]  base_lr: 8.7564e-05 lr: 8.7564e-06  eta: 1 day, 13:45:23  time: 0.4935  data_time: 0.0110  memory: 5930  grad_norm: 131.4929  loss: 6.4872  decode.loss_cls: 0.0659  decode.loss_mask: 0.2124  decode.loss_dice: 0.2896  decode.d0.loss_cls: 0.9155  decode.d0.loss_mask: 0.2096  decode.d0.loss_dice: 0.2995  decode.d1.loss_cls: 0.0934  decode.d1.loss_mask: 0.2067  decode.d1.loss_dice: 0.2926  decode.d2.loss_cls: 0.0658  decode.d2.loss_mask: 0.2113  decode.d2.loss_dice: 0.2862  decode.d3.loss_cls: 0.0481  decode.d3.loss_mask: 0.2050  decode.d3.loss_dice: 0.2796  decode.d4.loss_cls: 0.0460  decode.d4.loss_mask: 0.2097  decode.d4.loss_dice: 0.2933  decode.d5.loss_cls: 0.0605  decode.d5.loss_mask: 0.2113  decode.d5.loss_dice: 0.2865  decode.d6.loss_cls: 0.0602  decode.d6.loss_mask: 0.2087  decode.d6.loss_dice: 0.2915  decode.d7.loss_cls: 0.0811  decode.d7.loss_mask: 0.2125  decode.d7.loss_dice: 0.2837  decode.d8.loss_cls: 0.0637  decode.d8.loss_mask: 0.2104  decode.d8.loss_dice: 0.2869
08/06 08:21:20 - mmengine - INFO - Iter(train) [ 43950/320000]  base_lr: 8.7550e-05 lr: 8.7550e-06  eta: 1 day, 13:44:58  time: 0.4935  data_time: 0.0111  memory: 5874  grad_norm: 325.7340  loss: 6.1126  decode.loss_cls: 0.0554  decode.loss_mask: 0.2336  decode.loss_dice: 0.2338  decode.d0.loss_cls: 0.8171  decode.d0.loss_mask: 0.2277  decode.d0.loss_dice: 0.2358  decode.d1.loss_cls: 0.0535  decode.d1.loss_mask: 0.2423  decode.d1.loss_dice: 0.2495  decode.d2.loss_cls: 0.0405  decode.d2.loss_mask: 0.2403  decode.d2.loss_dice: 0.2452  decode.d3.loss_cls: 0.0957  decode.d3.loss_mask: 0.2299  decode.d3.loss_dice: 0.2357  decode.d4.loss_cls: 0.0793  decode.d4.loss_mask: 0.2273  decode.d4.loss_dice: 0.2358  decode.d5.loss_cls: 0.1363  decode.d5.loss_mask: 0.1948  decode.d5.loss_dice: 0.2237  decode.d6.loss_cls: 0.1018  decode.d6.loss_mask: 0.1970  decode.d6.loss_dice: 0.2219  decode.d7.loss_cls: 0.0402  decode.d7.loss_mask: 0.2363  decode.d7.loss_dice: 0.2404  decode.d8.loss_cls: 0.1066  decode.d8.loss_mask: 0.2038  decode.d8.loss_dice: 0.2316
08/06 08:21:45 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 08:21:45 - mmengine - INFO - Iter(train) [ 44000/320000]  base_lr: 8.7536e-05 lr: 8.7536e-06  eta: 1 day, 13:44:34  time: 0.4925  data_time: 0.0108  memory: 5967  grad_norm: 193.9981  loss: 7.8160  decode.loss_cls: 0.1582  decode.loss_mask: 0.2490  decode.loss_dice: 0.2883  decode.d0.loss_cls: 1.0680  decode.d0.loss_mask: 0.2570  decode.d0.loss_dice: 0.3290  decode.d1.loss_cls: 0.1187  decode.d1.loss_mask: 0.2597  decode.d1.loss_dice: 0.3345  decode.d2.loss_cls: 0.0974  decode.d2.loss_mask: 0.2509  decode.d2.loss_dice: 0.3054  decode.d3.loss_cls: 0.1664  decode.d3.loss_mask: 0.2525  decode.d3.loss_dice: 0.2915  decode.d4.loss_cls: 0.1804  decode.d4.loss_mask: 0.2534  decode.d4.loss_dice: 0.2838  decode.d5.loss_cls: 0.1100  decode.d5.loss_mask: 0.2486  decode.d5.loss_dice: 0.2833  decode.d6.loss_cls: 0.1278  decode.d6.loss_mask: 0.2516  decode.d6.loss_dice: 0.3030  decode.d7.loss_cls: 0.1422  decode.d7.loss_mask: 0.2518  decode.d7.loss_dice: 0.2847  decode.d8.loss_cls: 0.1148  decode.d8.loss_mask: 0.2537  decode.d8.loss_dice: 0.3006
08/06 08:22:09 - mmengine - INFO - Iter(train) [ 44050/320000]  base_lr: 8.7521e-05 lr: 8.7521e-06  eta: 1 day, 13:44:09  time: 0.4924  data_time: 0.0109  memory: 5894  grad_norm: 108.9261  loss: 7.5069  decode.loss_cls: 0.1652  decode.loss_mask: 0.3017  decode.loss_dice: 0.2759  decode.d0.loss_cls: 0.8570  decode.d0.loss_mask: 0.2934  decode.d0.loss_dice: 0.2716  decode.d1.loss_cls: 0.1827  decode.d1.loss_mask: 0.2953  decode.d1.loss_dice: 0.2530  decode.d2.loss_cls: 0.1359  decode.d2.loss_mask: 0.3037  decode.d2.loss_dice: 0.2491  decode.d3.loss_cls: 0.1081  decode.d3.loss_mask: 0.2960  decode.d3.loss_dice: 0.2469  decode.d4.loss_cls: 0.1005  decode.d4.loss_mask: 0.3069  decode.d4.loss_dice: 0.2523  decode.d5.loss_cls: 0.1009  decode.d5.loss_mask: 0.3032  decode.d5.loss_dice: 0.2591  decode.d6.loss_cls: 0.0812  decode.d6.loss_mask: 0.2994  decode.d6.loss_dice: 0.2429  decode.d7.loss_cls: 0.0835  decode.d7.loss_mask: 0.3006  decode.d7.loss_dice: 0.2490  decode.d8.loss_cls: 0.0896  decode.d8.loss_mask: 0.3238  decode.d8.loss_dice: 0.2785
08/06 08:22:34 - mmengine - INFO - Iter(train) [ 44100/320000]  base_lr: 8.7507e-05 lr: 8.7507e-06  eta: 1 day, 13:43:45  time: 0.4938  data_time: 0.0113  memory: 5928  grad_norm: 67.5821  loss: 8.5913  decode.loss_cls: 0.1977  decode.loss_mask: 0.2894  decode.loss_dice: 0.3212  decode.d0.loss_cls: 0.8095  decode.d0.loss_mask: 0.3036  decode.d0.loss_dice: 0.3484  decode.d1.loss_cls: 0.1558  decode.d1.loss_mask: 0.2954  decode.d1.loss_dice: 0.3240  decode.d2.loss_cls: 0.1814  decode.d2.loss_mask: 0.2935  decode.d2.loss_dice: 0.3326  decode.d3.loss_cls: 0.2059  decode.d3.loss_mask: 0.2958  decode.d3.loss_dice: 0.3270  decode.d4.loss_cls: 0.1689  decode.d4.loss_mask: 0.2923  decode.d4.loss_dice: 0.3324  decode.d5.loss_cls: 0.1670  decode.d5.loss_mask: 0.2912  decode.d5.loss_dice: 0.3209  decode.d6.loss_cls: 0.1613  decode.d6.loss_mask: 0.2957  decode.d6.loss_dice: 0.3237  decode.d7.loss_cls: 0.1422  decode.d7.loss_mask: 0.2944  decode.d7.loss_dice: 0.3362  decode.d8.loss_cls: 0.1719  decode.d8.loss_mask: 0.2883  decode.d8.loss_dice: 0.3235
08/06 08:22:59 - mmengine - INFO - Iter(train) [ 44150/320000]  base_lr: 8.7493e-05 lr: 8.7493e-06  eta: 1 day, 13:43:21  time: 0.4942  data_time: 0.0111  memory: 5911  grad_norm: 101.2576  loss: 8.6451  decode.loss_cls: 0.2874  decode.loss_mask: 0.2350  decode.loss_dice: 0.2836  decode.d0.loss_cls: 1.0388  decode.d0.loss_mask: 0.2392  decode.d0.loss_dice: 0.2981  decode.d1.loss_cls: 0.3498  decode.d1.loss_mask: 0.2365  decode.d1.loss_dice: 0.2772  decode.d2.loss_cls: 0.2394  decode.d2.loss_mask: 0.2385  decode.d2.loss_dice: 0.2747  decode.d3.loss_cls: 0.2788  decode.d3.loss_mask: 0.2362  decode.d3.loss_dice: 0.2799  decode.d4.loss_cls: 0.2411  decode.d4.loss_mask: 0.2369  decode.d4.loss_dice: 0.2585  decode.d5.loss_cls: 0.2739  decode.d5.loss_mask: 0.2353  decode.d5.loss_dice: 0.2785  decode.d6.loss_cls: 0.2366  decode.d6.loss_mask: 0.2349  decode.d6.loss_dice: 0.2740  decode.d7.loss_cls: 0.2578  decode.d7.loss_mask: 0.2334  decode.d7.loss_dice: 0.2664  decode.d8.loss_cls: 0.3206  decode.d8.loss_mask: 0.2366  decode.d8.loss_dice: 0.2676
08/06 08:23:23 - mmengine - INFO - Iter(train) [ 44200/320000]  base_lr: 8.7478e-05 lr: 8.7478e-06  eta: 1 day, 13:42:57  time: 0.4946  data_time: 0.0113  memory: 5894  grad_norm: 88.3079  loss: 6.4551  decode.loss_cls: 0.0458  decode.loss_mask: 0.2386  decode.loss_dice: 0.2763  decode.d0.loss_cls: 0.8464  decode.d0.loss_mask: 0.2448  decode.d0.loss_dice: 0.2681  decode.d1.loss_cls: 0.1110  decode.d1.loss_mask: 0.2383  decode.d1.loss_dice: 0.2808  decode.d2.loss_cls: 0.0547  decode.d2.loss_mask: 0.2369  decode.d2.loss_dice: 0.2753  decode.d3.loss_cls: 0.0355  decode.d3.loss_mask: 0.2394  decode.d3.loss_dice: 0.2785  decode.d4.loss_cls: 0.0548  decode.d4.loss_mask: 0.2390  decode.d4.loss_dice: 0.2791  decode.d5.loss_cls: 0.0366  decode.d5.loss_mask: 0.2374  decode.d5.loss_dice: 0.2751  decode.d6.loss_cls: 0.0327  decode.d6.loss_mask: 0.2377  decode.d6.loss_dice: 0.2764  decode.d7.loss_cls: 0.0383  decode.d7.loss_mask: 0.2385  decode.d7.loss_dice: 0.2742  decode.d8.loss_cls: 0.0441  decode.d8.loss_mask: 0.2399  decode.d8.loss_dice: 0.2809
08/06 08:23:48 - mmengine - INFO - Iter(train) [ 44250/320000]  base_lr: 8.7464e-05 lr: 8.7464e-06  eta: 1 day, 13:42:34  time: 0.4939  data_time: 0.0111  memory: 5911  grad_norm: 83.7209  loss: 6.2293  decode.loss_cls: 0.0920  decode.loss_mask: 0.2317  decode.loss_dice: 0.2267  decode.d0.loss_cls: 0.7415  decode.d0.loss_mask: 0.2380  decode.d0.loss_dice: 0.2469  decode.d1.loss_cls: 0.0787  decode.d1.loss_mask: 0.2356  decode.d1.loss_dice: 0.2366  decode.d2.loss_cls: 0.0860  decode.d2.loss_mask: 0.2327  decode.d2.loss_dice: 0.2473  decode.d3.loss_cls: 0.0901  decode.d3.loss_mask: 0.2307  decode.d3.loss_dice: 0.2381  decode.d4.loss_cls: 0.0921  decode.d4.loss_mask: 0.2343  decode.d4.loss_dice: 0.2438  decode.d5.loss_cls: 0.0842  decode.d5.loss_mask: 0.2310  decode.d5.loss_dice: 0.2382  decode.d6.loss_cls: 0.0828  decode.d6.loss_mask: 0.2339  decode.d6.loss_dice: 0.2371  decode.d7.loss_cls: 0.0784  decode.d7.loss_mask: 0.2292  decode.d7.loss_dice: 0.2351  decode.d8.loss_cls: 0.0937  decode.d8.loss_mask: 0.2322  decode.d8.loss_dice: 0.2308
08/06 08:24:13 - mmengine - INFO - Iter(train) [ 44300/320000]  base_lr: 8.7450e-05 lr: 8.7450e-06  eta: 1 day, 13:42:10  time: 0.4929  data_time: 0.0111  memory: 5874  grad_norm: 73.0578  loss: 5.3352  decode.loss_cls: 0.0422  decode.loss_mask: 0.2152  decode.loss_dice: 0.2133  decode.d0.loss_cls: 0.7254  decode.d0.loss_mask: 0.2173  decode.d0.loss_dice: 0.2368  decode.d1.loss_cls: 0.0385  decode.d1.loss_mask: 0.2102  decode.d1.loss_dice: 0.2208  decode.d2.loss_cls: 0.0298  decode.d2.loss_mask: 0.2151  decode.d2.loss_dice: 0.2196  decode.d3.loss_cls: 0.0284  decode.d3.loss_mask: 0.2124  decode.d3.loss_dice: 0.2109  decode.d4.loss_cls: 0.0236  decode.d4.loss_mask: 0.2127  decode.d4.loss_dice: 0.2180  decode.d5.loss_cls: 0.0238  decode.d5.loss_mask: 0.2135  decode.d5.loss_dice: 0.2082  decode.d6.loss_cls: 0.0258  decode.d6.loss_mask: 0.2113  decode.d6.loss_dice: 0.2131  decode.d7.loss_cls: 0.0248  decode.d7.loss_mask: 0.2128  decode.d7.loss_dice: 0.2153  decode.d8.loss_cls: 0.0645  decode.d8.loss_mask: 0.2140  decode.d8.loss_dice: 0.2179
08/06 08:24:38 - mmengine - INFO - Iter(train) [ 44350/320000]  base_lr: 8.7436e-05 lr: 8.7436e-06  eta: 1 day, 13:41:46  time: 0.4938  data_time: 0.0113  memory: 5928  grad_norm: 287.3818  loss: 7.7085  decode.loss_cls: 0.1795  decode.loss_mask: 0.2541  decode.loss_dice: 0.2851  decode.d0.loss_cls: 0.9427  decode.d0.loss_mask: 0.2599  decode.d0.loss_dice: 0.2676  decode.d1.loss_cls: 0.2519  decode.d1.loss_mask: 0.2423  decode.d1.loss_dice: 0.2594  decode.d2.loss_cls: 0.1139  decode.d2.loss_mask: 0.2542  decode.d2.loss_dice: 0.2675  decode.d3.loss_cls: 0.1403  decode.d3.loss_mask: 0.2480  decode.d3.loss_dice: 0.2783  decode.d4.loss_cls: 0.1530  decode.d4.loss_mask: 0.2461  decode.d4.loss_dice: 0.2541  decode.d5.loss_cls: 0.1730  decode.d5.loss_mask: 0.2492  decode.d5.loss_dice: 0.2680  decode.d6.loss_cls: 0.1817  decode.d6.loss_mask: 0.2521  decode.d6.loss_dice: 0.2521  decode.d7.loss_cls: 0.2117  decode.d7.loss_mask: 0.2393  decode.d7.loss_dice: 0.2515  decode.d8.loss_cls: 0.1855  decode.d8.loss_mask: 0.2538  decode.d8.loss_dice: 0.2927
08/06 08:25:02 - mmengine - INFO - Iter(train) [ 44400/320000]  base_lr: 8.7421e-05 lr: 8.7421e-06  eta: 1 day, 13:41:22  time: 0.4963  data_time: 0.0111  memory: 5909  grad_norm: 114.9730  loss: 6.2935  decode.loss_cls: 0.1308  decode.loss_mask: 0.1842  decode.loss_dice: 0.2848  decode.d0.loss_cls: 0.9604  decode.d0.loss_mask: 0.1787  decode.d0.loss_dice: 0.2360  decode.d1.loss_cls: 0.1342  decode.d1.loss_mask: 0.1754  decode.d1.loss_dice: 0.2279  decode.d2.loss_cls: 0.1295  decode.d2.loss_mask: 0.1748  decode.d2.loss_dice: 0.2262  decode.d3.loss_cls: 0.1147  decode.d3.loss_mask: 0.1784  decode.d3.loss_dice: 0.2410  decode.d4.loss_cls: 0.1202  decode.d4.loss_mask: 0.1741  decode.d4.loss_dice: 0.2491  decode.d5.loss_cls: 0.1330  decode.d5.loss_mask: 0.1758  decode.d5.loss_dice: 0.2515  decode.d6.loss_cls: 0.1225  decode.d6.loss_mask: 0.1770  decode.d6.loss_dice: 0.2533  decode.d7.loss_cls: 0.1204  decode.d7.loss_mask: 0.1771  decode.d7.loss_dice: 0.2477  decode.d8.loss_cls: 0.0875  decode.d8.loss_mask: 0.1770  decode.d8.loss_dice: 0.2503
08/06 08:25:27 - mmengine - INFO - Iter(train) [ 44450/320000]  base_lr: 8.7407e-05 lr: 8.7407e-06  eta: 1 day, 13:40:58  time: 0.4953  data_time: 0.0111  memory: 5894  grad_norm: 131.4811  loss: 5.6210  decode.loss_cls: 0.0689  decode.loss_mask: 0.1957  decode.loss_dice: 0.2340  decode.d0.loss_cls: 0.7575  decode.d0.loss_mask: 0.1992  decode.d0.loss_dice: 0.2402  decode.d1.loss_cls: 0.0343  decode.d1.loss_mask: 0.1921  decode.d1.loss_dice: 0.2287  decode.d2.loss_cls: 0.0903  decode.d2.loss_mask: 0.1933  decode.d2.loss_dice: 0.2319  decode.d3.loss_cls: 0.0530  decode.d3.loss_mask: 0.1940  decode.d3.loss_dice: 0.2272  decode.d4.loss_cls: 0.0753  decode.d4.loss_mask: 0.1940  decode.d4.loss_dice: 0.2256  decode.d5.loss_cls: 0.0758  decode.d5.loss_mask: 0.1936  decode.d5.loss_dice: 0.2354  decode.d6.loss_cls: 0.0639  decode.d6.loss_mask: 0.1939  decode.d6.loss_dice: 0.2309  decode.d7.loss_cls: 0.0756  decode.d7.loss_mask: 0.1942  decode.d7.loss_dice: 0.2306  decode.d8.loss_cls: 0.0644  decode.d8.loss_mask: 0.1956  decode.d8.loss_dice: 0.2316
08/06 08:25:52 - mmengine - INFO - Iter(train) [ 44500/320000]  base_lr: 8.7393e-05 lr: 8.7393e-06  eta: 1 day, 13:40:33  time: 0.4946  data_time: 0.0112  memory: 5928  grad_norm: 181.8349  loss: 7.4745  decode.loss_cls: 0.1484  decode.loss_mask: 0.2793  decode.loss_dice: 0.2417  decode.d0.loss_cls: 0.8850  decode.d0.loss_mask: 0.2835  decode.d0.loss_dice: 0.2547  decode.d1.loss_cls: 0.1127  decode.d1.loss_mask: 0.2900  decode.d1.loss_dice: 0.2536  decode.d2.loss_cls: 0.2108  decode.d2.loss_mask: 0.2810  decode.d2.loss_dice: 0.2394  decode.d3.loss_cls: 0.1434  decode.d3.loss_mask: 0.2768  decode.d3.loss_dice: 0.2417  decode.d4.loss_cls: 0.1274  decode.d4.loss_mask: 0.2778  decode.d4.loss_dice: 0.2453  decode.d5.loss_cls: 0.1408  decode.d5.loss_mask: 0.2815  decode.d5.loss_dice: 0.2520  decode.d6.loss_cls: 0.1394  decode.d6.loss_mask: 0.2797  decode.d6.loss_dice: 0.2428  decode.d7.loss_cls: 0.1601  decode.d7.loss_mask: 0.2822  decode.d7.loss_dice: 0.2483  decode.d8.loss_cls: 0.1301  decode.d8.loss_mask: 0.2815  decode.d8.loss_dice: 0.2437
08/06 08:26:17 - mmengine - INFO - Iter(train) [ 44550/320000]  base_lr: 8.7379e-05 lr: 8.7379e-06  eta: 1 day, 13:40:11  time: 0.4926  data_time: 0.0109  memory: 5911  grad_norm: 103.7509  loss: 7.4127  decode.loss_cls: 0.1404  decode.loss_mask: 0.2776  decode.loss_dice: 0.2875  decode.d0.loss_cls: 0.8340  decode.d0.loss_mask: 0.2700  decode.d0.loss_dice: 0.2972  decode.d1.loss_cls: 0.1234  decode.d1.loss_mask: 0.2705  decode.d1.loss_dice: 0.2871  decode.d2.loss_cls: 0.0864  decode.d2.loss_mask: 0.2736  decode.d2.loss_dice: 0.2967  decode.d3.loss_cls: 0.0588  decode.d3.loss_mask: 0.2769  decode.d3.loss_dice: 0.2947  decode.d4.loss_cls: 0.0983  decode.d4.loss_mask: 0.2698  decode.d4.loss_dice: 0.2911  decode.d5.loss_cls: 0.1054  decode.d5.loss_mask: 0.2772  decode.d5.loss_dice: 0.2945  decode.d6.loss_cls: 0.0914  decode.d6.loss_mask: 0.2750  decode.d6.loss_dice: 0.2963  decode.d7.loss_cls: 0.1042  decode.d7.loss_mask: 0.2722  decode.d7.loss_dice: 0.2941  decode.d8.loss_cls: 0.0954  decode.d8.loss_mask: 0.2702  decode.d8.loss_dice: 0.3027
08/06 08:26:41 - mmengine - INFO - Iter(train) [ 44600/320000]  base_lr: 8.7364e-05 lr: 8.7364e-06  eta: 1 day, 13:39:46  time: 0.4944  data_time: 0.0112  memory: 5911  grad_norm: 144.2970  loss: 7.3310  decode.loss_cls: 0.1072  decode.loss_mask: 0.2645  decode.loss_dice: 0.2687  decode.d0.loss_cls: 0.8330  decode.d0.loss_mask: 0.2627  decode.d0.loss_dice: 0.2756  decode.d1.loss_cls: 0.1425  decode.d1.loss_mask: 0.2690  decode.d1.loss_dice: 0.2605  decode.d2.loss_cls: 0.1110  decode.d2.loss_mask: 0.2668  decode.d2.loss_dice: 0.2751  decode.d3.loss_cls: 0.1463  decode.d3.loss_mask: 0.2676  decode.d3.loss_dice: 0.2532  decode.d4.loss_cls: 0.1268  decode.d4.loss_mask: 0.2667  decode.d4.loss_dice: 0.2612  decode.d5.loss_cls: 0.1306  decode.d5.loss_mask: 0.2722  decode.d5.loss_dice: 0.2503  decode.d6.loss_cls: 0.1373  decode.d6.loss_mask: 0.2692  decode.d6.loss_dice: 0.2615  decode.d7.loss_cls: 0.1238  decode.d7.loss_mask: 0.2681  decode.d7.loss_dice: 0.2528  decode.d8.loss_cls: 0.1921  decode.d8.loss_mask: 0.2624  decode.d8.loss_dice: 0.2522
08/06 08:27:06 - mmengine - INFO - Iter(train) [ 44650/320000]  base_lr: 8.7350e-05 lr: 8.7350e-06  eta: 1 day, 13:39:22  time: 0.4945  data_time: 0.0111  memory: 5911  grad_norm: 106.0936  loss: 6.9962  decode.loss_cls: 0.1281  decode.loss_mask: 0.2244  decode.loss_dice: 0.2735  decode.d0.loss_cls: 0.9286  decode.d0.loss_mask: 0.2322  decode.d0.loss_dice: 0.2771  decode.d1.loss_cls: 0.1376  decode.d1.loss_mask: 0.2228  decode.d1.loss_dice: 0.2740  decode.d2.loss_cls: 0.1148  decode.d2.loss_mask: 0.2207  decode.d2.loss_dice: 0.2676  decode.d3.loss_cls: 0.1271  decode.d3.loss_mask: 0.2243  decode.d3.loss_dice: 0.2645  decode.d4.loss_cls: 0.1165  decode.d4.loss_mask: 0.2228  decode.d4.loss_dice: 0.2718  decode.d5.loss_cls: 0.1140  decode.d5.loss_mask: 0.2255  decode.d5.loss_dice: 0.2811  decode.d6.loss_cls: 0.1286  decode.d6.loss_mask: 0.2232  decode.d6.loss_dice: 0.2633  decode.d7.loss_cls: 0.1228  decode.d7.loss_mask: 0.2217  decode.d7.loss_dice: 0.2764  decode.d8.loss_cls: 0.1247  decode.d8.loss_mask: 0.2208  decode.d8.loss_dice: 0.2657
08/06 08:27:31 - mmengine - INFO - Iter(train) [ 44700/320000]  base_lr: 8.7336e-05 lr: 8.7336e-06  eta: 1 day, 13:38:58  time: 0.4936  data_time: 0.0111  memory: 5913  grad_norm: 93.5721  loss: 9.1151  decode.loss_cls: 0.2046  decode.loss_mask: 0.2600  decode.loss_dice: 0.2977  decode.d0.loss_cls: 1.0882  decode.d0.loss_mask: 0.2582  decode.d0.loss_dice: 0.3400  decode.d1.loss_cls: 0.2838  decode.d1.loss_mask: 0.2629  decode.d1.loss_dice: 0.3667  decode.d2.loss_cls: 0.2590  decode.d2.loss_mask: 0.2628  decode.d2.loss_dice: 0.3422  decode.d3.loss_cls: 0.2272  decode.d3.loss_mask: 0.2782  decode.d3.loss_dice: 0.3496  decode.d4.loss_cls: 0.2573  decode.d4.loss_mask: 0.2652  decode.d4.loss_dice: 0.3243  decode.d5.loss_cls: 0.1914  decode.d5.loss_mask: 0.2630  decode.d5.loss_dice: 0.3779  decode.d6.loss_cls: 0.2093  decode.d6.loss_mask: 0.2654  decode.d6.loss_dice: 0.3203  decode.d7.loss_cls: 0.2304  decode.d7.loss_mask: 0.2644  decode.d7.loss_dice: 0.3008  decode.d8.loss_cls: 0.1812  decode.d8.loss_mask: 0.2639  decode.d8.loss_dice: 0.3190
08/06 08:27:55 - mmengine - INFO - Iter(train) [ 44750/320000]  base_lr: 8.7321e-05 lr: 8.7321e-06  eta: 1 day, 13:38:34  time: 0.4949  data_time: 0.0111  memory: 5909  grad_norm: 112.3564  loss: 6.5723  decode.loss_cls: 0.0961  decode.loss_mask: 0.2217  decode.loss_dice: 0.2415  decode.d0.loss_cls: 0.9202  decode.d0.loss_mask: 0.2326  decode.d0.loss_dice: 0.2547  decode.d1.loss_cls: 0.1899  decode.d1.loss_mask: 0.2243  decode.d1.loss_dice: 0.2378  decode.d2.loss_cls: 0.1350  decode.d2.loss_mask: 0.2229  decode.d2.loss_dice: 0.2432  decode.d3.loss_cls: 0.0913  decode.d3.loss_mask: 0.2209  decode.d3.loss_dice: 0.2318  decode.d4.loss_cls: 0.0995  decode.d4.loss_mask: 0.2227  decode.d4.loss_dice: 0.2418  decode.d5.loss_cls: 0.1127  decode.d5.loss_mask: 0.2201  decode.d5.loss_dice: 0.2482  decode.d6.loss_cls: 0.0830  decode.d6.loss_mask: 0.2190  decode.d6.loss_dice: 0.2394  decode.d7.loss_cls: 0.0949  decode.d7.loss_mask: 0.2225  decode.d7.loss_dice: 0.2388  decode.d8.loss_cls: 0.1046  decode.d8.loss_mask: 0.2209  decode.d8.loss_dice: 0.2403
08/06 08:28:20 - mmengine - INFO - Iter(train) [ 44800/320000]  base_lr: 8.7307e-05 lr: 8.7307e-06  eta: 1 day, 13:38:10  time: 0.4944  data_time: 0.0112  memory: 5891  grad_norm: 37.8155  loss: 5.9007  decode.loss_cls: 0.1129  decode.loss_mask: 0.1882  decode.loss_dice: 0.2213  decode.d0.loss_cls: 0.8504  decode.d0.loss_mask: 0.1947  decode.d0.loss_dice: 0.2212  decode.d1.loss_cls: 0.1019  decode.d1.loss_mask: 0.1909  decode.d1.loss_dice: 0.2334  decode.d2.loss_cls: 0.0755  decode.d2.loss_mask: 0.1916  decode.d2.loss_dice: 0.2363  decode.d3.loss_cls: 0.0679  decode.d3.loss_mask: 0.1907  decode.d3.loss_dice: 0.2373  decode.d4.loss_cls: 0.0715  decode.d4.loss_mask: 0.1890  decode.d4.loss_dice: 0.2337  decode.d5.loss_cls: 0.0714  decode.d5.loss_mask: 0.1929  decode.d5.loss_dice: 0.2397  decode.d6.loss_cls: 0.1293  decode.d6.loss_mask: 0.1910  decode.d6.loss_dice: 0.2260  decode.d7.loss_cls: 0.0646  decode.d7.loss_mask: 0.1905  decode.d7.loss_dice: 0.2347  decode.d8.loss_cls: 0.1362  decode.d8.loss_mask: 0.1883  decode.d8.loss_dice: 0.2277
08/06 08:28:45 - mmengine - INFO - Iter(train) [ 44850/320000]  base_lr: 8.7293e-05 lr: 8.7293e-06  eta: 1 day, 13:37:46  time: 0.4932  data_time: 0.0110  memory: 5913  grad_norm: 100.5717  loss: 6.7416  decode.loss_cls: 0.0484  decode.loss_mask: 0.2443  decode.loss_dice: 0.2861  decode.d0.loss_cls: 0.9753  decode.d0.loss_mask: 0.2491  decode.d0.loss_dice: 0.2789  decode.d1.loss_cls: 0.0426  decode.d1.loss_mask: 0.2479  decode.d1.loss_dice: 0.2824  decode.d2.loss_cls: 0.0269  decode.d2.loss_mask: 0.2470  decode.d2.loss_dice: 0.2911  decode.d3.loss_cls: 0.0676  decode.d3.loss_mask: 0.2458  decode.d3.loss_dice: 0.2823  decode.d4.loss_cls: 0.0723  decode.d4.loss_mask: 0.2435  decode.d4.loss_dice: 0.2820  decode.d5.loss_cls: 0.0339  decode.d5.loss_mask: 0.2450  decode.d5.loss_dice: 0.2796  decode.d6.loss_cls: 0.0874  decode.d6.loss_mask: 0.2440  decode.d6.loss_dice: 0.2775  decode.d7.loss_cls: 0.0697  decode.d7.loss_mask: 0.2442  decode.d7.loss_dice: 0.2783  decode.d8.loss_cls: 0.0405  decode.d8.loss_mask: 0.2453  decode.d8.loss_dice: 0.2829
08/06 08:29:10 - mmengine - INFO - Iter(train) [ 44900/320000]  base_lr: 8.7279e-05 lr: 8.7279e-06  eta: 1 day, 13:37:22  time: 0.4936  data_time: 0.0112  memory: 5874  grad_norm: 79.5806  loss: 7.1394  decode.loss_cls: 0.0646  decode.loss_mask: 0.2935  decode.loss_dice: 0.2874  decode.d0.loss_cls: 0.7708  decode.d0.loss_mask: 0.3042  decode.d0.loss_dice: 0.2805  decode.d1.loss_cls: 0.0999  decode.d1.loss_mask: 0.2923  decode.d1.loss_dice: 0.2822  decode.d2.loss_cls: 0.0635  decode.d2.loss_mask: 0.2931  decode.d2.loss_dice: 0.2871  decode.d3.loss_cls: 0.0657  decode.d3.loss_mask: 0.2946  decode.d3.loss_dice: 0.2859  decode.d4.loss_cls: 0.0699  decode.d4.loss_mask: 0.2953  decode.d4.loss_dice: 0.2873  decode.d5.loss_cls: 0.0283  decode.d5.loss_mask: 0.2973  decode.d5.loss_dice: 0.2819  decode.d6.loss_cls: 0.0359  decode.d6.loss_mask: 0.2962  decode.d6.loss_dice: 0.2937  decode.d7.loss_cls: 0.0677  decode.d7.loss_mask: 0.2944  decode.d7.loss_dice: 0.2817  decode.d8.loss_cls: 0.0576  decode.d8.loss_mask: 0.2972  decode.d8.loss_dice: 0.2897
08/06 08:29:34 - mmengine - INFO - Iter(train) [ 44950/320000]  base_lr: 8.7264e-05 lr: 8.7264e-06  eta: 1 day, 13:36:57  time: 0.4916  data_time: 0.0110  memory: 5932  grad_norm: 200.6018  loss: 9.9649  decode.loss_cls: 0.2675  decode.loss_mask: 0.3233  decode.loss_dice: 0.2869  decode.d0.loss_cls: 0.9884  decode.d0.loss_mask: 0.3004  decode.d0.loss_dice: 0.3135  decode.d1.loss_cls: 0.3141  decode.d1.loss_mask: 0.3723  decode.d1.loss_dice: 0.3370  decode.d2.loss_cls: 0.2994  decode.d2.loss_mask: 0.3268  decode.d2.loss_dice: 0.2869  decode.d3.loss_cls: 0.3402  decode.d3.loss_mask: 0.3126  decode.d3.loss_dice: 0.2953  decode.d4.loss_cls: 0.3054  decode.d4.loss_mask: 0.3314  decode.d4.loss_dice: 0.2954  decode.d5.loss_cls: 0.2787  decode.d5.loss_mask: 0.3247  decode.d5.loss_dice: 0.2746  decode.d6.loss_cls: 0.3023  decode.d6.loss_mask: 0.3176  decode.d6.loss_dice: 0.3162  decode.d7.loss_cls: 0.3093  decode.d7.loss_mask: 0.3280  decode.d7.loss_dice: 0.2904  decode.d8.loss_cls: 0.2854  decode.d8.loss_mask: 0.3301  decode.d8.loss_dice: 0.3107
08/06 08:29:59 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 08:29:59 - mmengine - INFO - Iter(train) [ 45000/320000]  base_lr: 8.7250e-05 lr: 8.7250e-06  eta: 1 day, 13:36:33  time: 0.4944  data_time: 0.0111  memory: 5909  grad_norm: 254.5319  loss: 6.8145  decode.loss_cls: 0.1308  decode.loss_mask: 0.2075  decode.loss_dice: 0.2958  decode.d0.loss_cls: 0.9468  decode.d0.loss_mask: 0.2097  decode.d0.loss_dice: 0.2964  decode.d1.loss_cls: 0.0924  decode.d1.loss_mask: 0.2073  decode.d1.loss_dice: 0.2836  decode.d2.loss_cls: 0.0672  decode.d2.loss_mask: 0.2094  decode.d2.loss_dice: 0.2960  decode.d3.loss_cls: 0.1035  decode.d3.loss_mask: 0.2121  decode.d3.loss_dice: 0.2908  decode.d4.loss_cls: 0.0696  decode.d4.loss_mask: 0.2108  decode.d4.loss_dice: 0.2979  decode.d5.loss_cls: 0.0701  decode.d5.loss_mask: 0.2100  decode.d5.loss_dice: 0.3055  decode.d6.loss_cls: 0.0869  decode.d6.loss_mask: 0.2072  decode.d6.loss_dice: 0.2906  decode.d7.loss_cls: 0.1196  decode.d7.loss_mask: 0.2057  decode.d7.loss_dice: 0.2824  decode.d8.loss_cls: 0.1078  decode.d8.loss_mask: 0.2064  decode.d8.loss_dice: 0.2950
08/06 08:30:24 - mmengine - INFO - Iter(train) [ 45050/320000]  base_lr: 8.7236e-05 lr: 8.7236e-06  eta: 1 day, 13:36:09  time: 0.4933  data_time: 0.0111  memory: 5911  grad_norm: 151.2219  loss: 8.2002  decode.loss_cls: 0.0881  decode.loss_mask: 0.2938  decode.loss_dice: 0.3387  decode.d0.loss_cls: 0.9212  decode.d0.loss_mask: 0.3028  decode.d0.loss_dice: 0.3531  decode.d1.loss_cls: 0.0859  decode.d1.loss_mask: 0.2937  decode.d1.loss_dice: 0.3443  decode.d2.loss_cls: 0.0947  decode.d2.loss_mask: 0.2986  decode.d2.loss_dice: 0.3470  decode.d3.loss_cls: 0.1577  decode.d3.loss_mask: 0.2943  decode.d3.loss_dice: 0.3490  decode.d4.loss_cls: 0.1201  decode.d4.loss_mask: 0.2946  decode.d4.loss_dice: 0.3275  decode.d5.loss_cls: 0.0936  decode.d5.loss_mask: 0.2937  decode.d5.loss_dice: 0.3376  decode.d6.loss_cls: 0.1221  decode.d6.loss_mask: 0.2884  decode.d6.loss_dice: 0.3170  decode.d7.loss_cls: 0.1062  decode.d7.loss_mask: 0.2959  decode.d7.loss_dice: 0.3333  decode.d8.loss_cls: 0.0902  decode.d8.loss_mask: 0.2931  decode.d8.loss_dice: 0.3239
08/06 08:30:48 - mmengine - INFO - Iter(train) [ 45100/320000]  base_lr: 8.7221e-05 lr: 8.7221e-06  eta: 1 day, 13:35:45  time: 0.4937  data_time: 0.0112  memory: 5911  grad_norm: 147.7748  loss: 8.7827  decode.loss_cls: 0.2234  decode.loss_mask: 0.2876  decode.loss_dice: 0.3232  decode.d0.loss_cls: 0.8985  decode.d0.loss_mask: 0.2987  decode.d0.loss_dice: 0.3323  decode.d1.loss_cls: 0.1256  decode.d1.loss_mask: 0.3090  decode.d1.loss_dice: 0.3236  decode.d2.loss_cls: 0.1985  decode.d2.loss_mask: 0.3099  decode.d2.loss_dice: 0.3156  decode.d3.loss_cls: 0.2159  decode.d3.loss_mask: 0.2870  decode.d3.loss_dice: 0.3053  decode.d4.loss_cls: 0.2237  decode.d4.loss_mask: 0.2892  decode.d4.loss_dice: 0.3149  decode.d5.loss_cls: 0.2140  decode.d5.loss_mask: 0.2870  decode.d5.loss_dice: 0.3025  decode.d6.loss_cls: 0.2297  decode.d6.loss_mask: 0.2883  decode.d6.loss_dice: 0.3079  decode.d7.loss_cls: 0.1900  decode.d7.loss_mask: 0.2864  decode.d7.loss_dice: 0.3057  decode.d8.loss_cls: 0.1946  decode.d8.loss_mask: 0.2855  decode.d8.loss_dice: 0.3094
08/06 08:31:13 - mmengine - INFO - Iter(train) [ 45150/320000]  base_lr: 8.7207e-05 lr: 8.7207e-06  eta: 1 day, 13:35:21  time: 0.4951  data_time: 0.0113  memory: 5913  grad_norm: 101.1520  loss: 7.6569  decode.loss_cls: 0.1783  decode.loss_mask: 0.2109  decode.loss_dice: 0.3002  decode.d0.loss_cls: 1.0614  decode.d0.loss_mask: 0.2071  decode.d0.loss_dice: 0.3087  decode.d1.loss_cls: 0.1905  decode.d1.loss_mask: 0.2074  decode.d1.loss_dice: 0.2745  decode.d2.loss_cls: 0.2402  decode.d2.loss_mask: 0.2078  decode.d2.loss_dice: 0.3005  decode.d3.loss_cls: 0.2117  decode.d3.loss_mask: 0.2061  decode.d3.loss_dice: 0.2812  decode.d4.loss_cls: 0.1746  decode.d4.loss_mask: 0.2065  decode.d4.loss_dice: 0.2875  decode.d5.loss_cls: 0.1347  decode.d5.loss_mask: 0.2088  decode.d5.loss_dice: 0.2693  decode.d6.loss_cls: 0.1479  decode.d6.loss_mask: 0.2102  decode.d6.loss_dice: 0.2938  decode.d7.loss_cls: 0.1794  decode.d7.loss_mask: 0.2058  decode.d7.loss_dice: 0.2760  decode.d8.loss_cls: 0.1622  decode.d8.loss_mask: 0.2090  decode.d8.loss_dice: 0.3049
08/06 08:31:38 - mmengine - INFO - Iter(train) [ 45200/320000]  base_lr: 8.7193e-05 lr: 8.7193e-06  eta: 1 day, 13:34:57  time: 0.4937  data_time: 0.0111  memory: 5891  grad_norm: 91.2295  loss: 6.4615  decode.loss_cls: 0.0290  decode.loss_mask: 0.2582  decode.loss_dice: 0.2822  decode.d0.loss_cls: 0.7909  decode.d0.loss_mask: 0.2630  decode.d0.loss_dice: 0.2918  decode.d1.loss_cls: 0.1002  decode.d1.loss_mask: 0.2585  decode.d1.loss_dice: 0.2737  decode.d2.loss_cls: 0.0135  decode.d2.loss_mask: 0.2555  decode.d2.loss_dice: 0.2801  decode.d3.loss_cls: 0.0186  decode.d3.loss_mask: 0.2580  decode.d3.loss_dice: 0.2858  decode.d4.loss_cls: 0.0127  decode.d4.loss_mask: 0.2559  decode.d4.loss_dice: 0.2874  decode.d5.loss_cls: 0.0136  decode.d5.loss_mask: 0.2563  decode.d5.loss_dice: 0.2864  decode.d6.loss_cls: 0.0228  decode.d6.loss_mask: 0.2564  decode.d6.loss_dice: 0.2858  decode.d7.loss_cls: 0.0178  decode.d7.loss_mask: 0.2592  decode.d7.loss_dice: 0.2808  decode.d8.loss_cls: 0.0254  decode.d8.loss_mask: 0.2541  decode.d8.loss_dice: 0.2878
08/06 08:32:03 - mmengine - INFO - Iter(train) [ 45250/320000]  base_lr: 8.7179e-05 lr: 8.7179e-06  eta: 1 day, 13:34:33  time: 0.4938  data_time: 0.0112  memory: 5891  grad_norm: 152.5276  loss: 8.3941  decode.loss_cls: 0.1581  decode.loss_mask: 0.3130  decode.loss_dice: 0.3043  decode.d0.loss_cls: 0.8896  decode.d0.loss_mask: 0.3171  decode.d0.loss_dice: 0.3008  decode.d1.loss_cls: 0.1822  decode.d1.loss_mask: 0.3133  decode.d1.loss_dice: 0.2894  decode.d2.loss_cls: 0.1473  decode.d2.loss_mask: 0.3155  decode.d2.loss_dice: 0.2950  decode.d3.loss_cls: 0.1707  decode.d3.loss_mask: 0.3157  decode.d3.loss_dice: 0.3126  decode.d4.loss_cls: 0.1434  decode.d4.loss_mask: 0.3114  decode.d4.loss_dice: 0.3041  decode.d5.loss_cls: 0.1446  decode.d5.loss_mask: 0.3100  decode.d5.loss_dice: 0.2835  decode.d6.loss_cls: 0.1832  decode.d6.loss_mask: 0.3162  decode.d6.loss_dice: 0.2944  decode.d7.loss_cls: 0.1517  decode.d7.loss_mask: 0.3118  decode.d7.loss_dice: 0.2779  decode.d8.loss_cls: 0.1442  decode.d8.loss_mask: 0.3132  decode.d8.loss_dice: 0.2800
08/06 08:32:27 - mmengine - INFO - Iter(train) [ 45300/320000]  base_lr: 8.7164e-05 lr: 8.7164e-06  eta: 1 day, 13:34:09  time: 0.4938  data_time: 0.0111  memory: 5894  grad_norm: 108.9337  loss: 7.7586  decode.loss_cls: 0.1794  decode.loss_mask: 0.2172  decode.loss_dice: 0.2919  decode.d0.loss_cls: 0.9291  decode.d0.loss_mask: 0.2126  decode.d0.loss_dice: 0.3030  decode.d1.loss_cls: 0.1558  decode.d1.loss_mask: 0.2099  decode.d1.loss_dice: 0.2815  decode.d2.loss_cls: 0.1674  decode.d2.loss_mask: 0.2100  decode.d2.loss_dice: 0.3029  decode.d3.loss_cls: 0.2028  decode.d3.loss_mask: 0.2086  decode.d3.loss_dice: 0.2883  decode.d4.loss_cls: 0.1923  decode.d4.loss_mask: 0.2210  decode.d4.loss_dice: 0.2930  decode.d5.loss_cls: 0.2177  decode.d5.loss_mask: 0.2107  decode.d5.loss_dice: 0.3006  decode.d6.loss_cls: 0.2303  decode.d6.loss_mask: 0.2065  decode.d6.loss_dice: 0.2851  decode.d7.loss_cls: 0.2243  decode.d7.loss_mask: 0.2083  decode.d7.loss_dice: 0.2978  decode.d8.loss_cls: 0.2051  decode.d8.loss_mask: 0.2144  decode.d8.loss_dice: 0.2916
08/06 08:32:52 - mmengine - INFO - Iter(train) [ 45350/320000]  base_lr: 8.7150e-05 lr: 8.7150e-06  eta: 1 day, 13:33:45  time: 0.4940  data_time: 0.0111  memory: 5911  grad_norm: 139.1015  loss: 7.3367  decode.loss_cls: 0.1800  decode.loss_mask: 0.2265  decode.loss_dice: 0.2756  decode.d0.loss_cls: 0.9206  decode.d0.loss_mask: 0.2345  decode.d0.loss_dice: 0.2988  decode.d1.loss_cls: 0.0839  decode.d1.loss_mask: 0.2317  decode.d1.loss_dice: 0.2878  decode.d2.loss_cls: 0.0990  decode.d2.loss_mask: 0.2282  decode.d2.loss_dice: 0.2791  decode.d3.loss_cls: 0.1490  decode.d3.loss_mask: 0.2235  decode.d3.loss_dice: 0.2819  decode.d4.loss_cls: 0.1096  decode.d4.loss_mask: 0.2265  decode.d4.loss_dice: 0.2988  decode.d5.loss_cls: 0.1728  decode.d5.loss_mask: 0.2309  decode.d5.loss_dice: 0.2865  decode.d6.loss_cls: 0.1638  decode.d6.loss_mask: 0.2217  decode.d6.loss_dice: 0.2804  decode.d7.loss_cls: 0.1684  decode.d7.loss_mask: 0.2263  decode.d7.loss_dice: 0.2772  decode.d8.loss_cls: 0.1685  decode.d8.loss_mask: 0.2293  decode.d8.loss_dice: 0.2759
08/06 08:33:17 - mmengine - INFO - Iter(train) [ 45400/320000]  base_lr: 8.7136e-05 lr: 8.7136e-06  eta: 1 day, 13:33:21  time: 0.4950  data_time: 0.0111  memory: 5894  grad_norm: 85.4082  loss: 8.4523  decode.loss_cls: 0.2453  decode.loss_mask: 0.1944  decode.loss_dice: 0.2892  decode.d0.loss_cls: 1.1466  decode.d0.loss_mask: 0.1948  decode.d0.loss_dice: 0.2769  decode.d1.loss_cls: 0.2909  decode.d1.loss_mask: 0.1941  decode.d1.loss_dice: 0.3028  decode.d2.loss_cls: 0.2749  decode.d2.loss_mask: 0.1972  decode.d2.loss_dice: 0.2682  decode.d3.loss_cls: 0.2700  decode.d3.loss_mask: 0.1959  decode.d3.loss_dice: 0.2718  decode.d4.loss_cls: 0.3103  decode.d4.loss_mask: 0.1961  decode.d4.loss_dice: 0.2992  decode.d5.loss_cls: 0.2886  decode.d5.loss_mask: 0.1952  decode.d5.loss_dice: 0.2854  decode.d6.loss_cls: 0.2447  decode.d6.loss_mask: 0.1941  decode.d6.loss_dice: 0.2817  decode.d7.loss_cls: 0.2669  decode.d7.loss_mask: 0.1960  decode.d7.loss_dice: 0.3025  decode.d8.loss_cls: 0.2744  decode.d8.loss_mask: 0.1942  decode.d8.loss_dice: 0.3101
08/06 08:33:41 - mmengine - INFO - Iter(train) [ 45450/320000]  base_lr: 8.7122e-05 lr: 8.7122e-06  eta: 1 day, 13:32:57  time: 0.4941  data_time: 0.0112  memory: 5928  grad_norm: 104.6062  loss: 6.7323  decode.loss_cls: 0.1091  decode.loss_mask: 0.2175  decode.loss_dice: 0.2514  decode.d0.loss_cls: 0.8845  decode.d0.loss_mask: 0.2262  decode.d0.loss_dice: 0.2820  decode.d1.loss_cls: 0.2020  decode.d1.loss_mask: 0.2194  decode.d1.loss_dice: 0.2802  decode.d2.loss_cls: 0.0871  decode.d2.loss_mask: 0.2193  decode.d2.loss_dice: 0.2546  decode.d3.loss_cls: 0.0990  decode.d3.loss_mask: 0.2178  decode.d3.loss_dice: 0.2572  decode.d4.loss_cls: 0.0823  decode.d4.loss_mask: 0.2203  decode.d4.loss_dice: 0.2686  decode.d5.loss_cls: 0.0876  decode.d5.loss_mask: 0.2195  decode.d5.loss_dice: 0.2535  decode.d6.loss_cls: 0.0928  decode.d6.loss_mask: 0.2170  decode.d6.loss_dice: 0.2598  decode.d7.loss_cls: 0.1321  decode.d7.loss_mask: 0.2187  decode.d7.loss_dice: 0.2436  decode.d8.loss_cls: 0.1329  decode.d8.loss_mask: 0.2242  decode.d8.loss_dice: 0.2721
08/06 08:34:06 - mmengine - INFO - Iter(train) [ 45500/320000]  base_lr: 8.7107e-05 lr: 8.7107e-06  eta: 1 day, 13:32:33  time: 0.4945  data_time: 0.0112  memory: 5895  grad_norm: 86.0045  loss: 6.8836  decode.loss_cls: 0.0856  decode.loss_mask: 0.2644  decode.loss_dice: 0.2620  decode.d0.loss_cls: 0.7628  decode.d0.loss_mask: 0.2536  decode.d0.loss_dice: 0.2584  decode.d1.loss_cls: 0.1305  decode.d1.loss_mask: 0.2543  decode.d1.loss_dice: 0.2556  decode.d2.loss_cls: 0.1176  decode.d2.loss_mask: 0.2525  decode.d2.loss_dice: 0.2509  decode.d3.loss_cls: 0.1574  decode.d3.loss_mask: 0.2760  decode.d3.loss_dice: 0.2637  decode.d4.loss_cls: 0.0997  decode.d4.loss_mask: 0.2667  decode.d4.loss_dice: 0.2635  decode.d5.loss_cls: 0.0998  decode.d5.loss_mask: 0.2596  decode.d5.loss_dice: 0.2578  decode.d6.loss_cls: 0.0881  decode.d6.loss_mask: 0.2544  decode.d6.loss_dice: 0.2613  decode.d7.loss_cls: 0.0851  decode.d7.loss_mask: 0.2477  decode.d7.loss_dice: 0.2481  decode.d8.loss_cls: 0.0912  decode.d8.loss_mask: 0.2560  decode.d8.loss_dice: 0.2592
08/06 08:34:31 - mmengine - INFO - Iter(train) [ 45550/320000]  base_lr: 8.7093e-05 lr: 8.7093e-06  eta: 1 day, 13:32:09  time: 0.4942  data_time: 0.0113  memory: 5911  grad_norm: 63.8951  loss: 6.4145  decode.loss_cls: 0.0399  decode.loss_mask: 0.2295  decode.loss_dice: 0.2522  decode.d0.loss_cls: 0.8882  decode.d0.loss_mask: 0.2351  decode.d0.loss_dice: 0.2257  decode.d1.loss_cls: 0.1231  decode.d1.loss_mask: 0.2306  decode.d1.loss_dice: 0.2597  decode.d2.loss_cls: 0.0941  decode.d2.loss_mask: 0.2329  decode.d2.loss_dice: 0.2623  decode.d3.loss_cls: 0.0764  decode.d3.loss_mask: 0.2319  decode.d3.loss_dice: 0.2524  decode.d4.loss_cls: 0.0463  decode.d4.loss_mask: 0.2324  decode.d4.loss_dice: 0.2745  decode.d5.loss_cls: 0.0568  decode.d5.loss_mask: 0.2314  decode.d5.loss_dice: 0.2643  decode.d6.loss_cls: 0.0634  decode.d6.loss_mask: 0.2331  decode.d6.loss_dice: 0.2678  decode.d7.loss_cls: 0.0574  decode.d7.loss_mask: 0.2334  decode.d7.loss_dice: 0.2698  decode.d8.loss_cls: 0.0478  decode.d8.loss_mask: 0.2327  decode.d8.loss_dice: 0.2694
08/06 08:34:55 - mmengine - INFO - Iter(train) [ 45600/320000]  base_lr: 8.7079e-05 lr: 8.7079e-06  eta: 1 day, 13:31:44  time: 0.4931  data_time: 0.0111  memory: 5931  grad_norm: 74.9455  loss: 6.8737  decode.loss_cls: 0.1245  decode.loss_mask: 0.2041  decode.loss_dice: 0.2509  decode.d0.loss_cls: 0.9433  decode.d0.loss_mask: 0.2118  decode.d0.loss_dice: 0.2639  decode.d1.loss_cls: 0.1686  decode.d1.loss_mask: 0.2102  decode.d1.loss_dice: 0.2542  decode.d2.loss_cls: 0.1698  decode.d2.loss_mask: 0.2063  decode.d2.loss_dice: 0.2470  decode.d3.loss_cls: 0.1726  decode.d3.loss_mask: 0.2093  decode.d3.loss_dice: 0.2487  decode.d4.loss_cls: 0.1457  decode.d4.loss_mask: 0.2094  decode.d4.loss_dice: 0.2608  decode.d5.loss_cls: 0.1702  decode.d5.loss_mask: 0.2074  decode.d5.loss_dice: 0.2642  decode.d6.loss_cls: 0.1251  decode.d6.loss_mask: 0.2075  decode.d6.loss_dice: 0.2455  decode.d7.loss_cls: 0.1297  decode.d7.loss_mask: 0.2067  decode.d7.loss_dice: 0.2463  decode.d8.loss_cls: 0.1155  decode.d8.loss_mask: 0.2068  decode.d8.loss_dice: 0.2477
08/06 08:35:20 - mmengine - INFO - Iter(train) [ 45650/320000]  base_lr: 8.7064e-05 lr: 8.7064e-06  eta: 1 day, 13:31:21  time: 0.4927  data_time: 0.0111  memory: 5911  grad_norm: 239.7944  loss: 8.0201  decode.loss_cls: 0.1316  decode.loss_mask: 0.2649  decode.loss_dice: 0.2915  decode.d0.loss_cls: 1.0559  decode.d0.loss_mask: 0.2584  decode.d0.loss_dice: 0.2917  decode.d1.loss_cls: 0.1572  decode.d1.loss_mask: 0.2608  decode.d1.loss_dice: 0.2909  decode.d2.loss_cls: 0.1727  decode.d2.loss_mask: 0.2548  decode.d2.loss_dice: 0.2910  decode.d3.loss_cls: 0.1356  decode.d3.loss_mask: 0.2543  decode.d3.loss_dice: 0.3028  decode.d4.loss_cls: 0.1660  decode.d4.loss_mask: 0.2708  decode.d4.loss_dice: 0.3024  decode.d5.loss_cls: 0.1540  decode.d5.loss_mask: 0.2670  decode.d5.loss_dice: 0.2985  decode.d6.loss_cls: 0.1976  decode.d6.loss_mask: 0.2624  decode.d6.loss_dice: 0.2979  decode.d7.loss_cls: 0.1374  decode.d7.loss_mask: 0.2637  decode.d7.loss_dice: 0.2940  decode.d8.loss_cls: 0.1319  decode.d8.loss_mask: 0.2663  decode.d8.loss_dice: 0.2961
08/06 08:35:45 - mmengine - INFO - Iter(train) [ 45700/320000]  base_lr: 8.7050e-05 lr: 8.7050e-06  eta: 1 day, 13:30:56  time: 0.4925  data_time: 0.0111  memory: 5894  grad_norm: 191.5546  loss: 7.3985  decode.loss_cls: 0.1100  decode.loss_mask: 0.2703  decode.loss_dice: 0.2666  decode.d0.loss_cls: 0.8179  decode.d0.loss_mask: 0.2933  decode.d0.loss_dice: 0.2937  decode.d1.loss_cls: 0.1452  decode.d1.loss_mask: 0.2592  decode.d1.loss_dice: 0.2660  decode.d2.loss_cls: 0.1329  decode.d2.loss_mask: 0.2510  decode.d2.loss_dice: 0.2425  decode.d3.loss_cls: 0.1270  decode.d3.loss_mask: 0.2623  decode.d3.loss_dice: 0.2743  decode.d4.loss_cls: 0.1233  decode.d4.loss_mask: 0.2676  decode.d4.loss_dice: 0.2829  decode.d5.loss_cls: 0.1657  decode.d5.loss_mask: 0.2859  decode.d5.loss_dice: 0.2637  decode.d6.loss_cls: 0.1590  decode.d6.loss_mask: 0.2520  decode.d6.loss_dice: 0.2746  decode.d7.loss_cls: 0.1085  decode.d7.loss_mask: 0.2934  decode.d7.loss_dice: 0.2824  decode.d8.loss_cls: 0.0566  decode.d8.loss_mask: 0.2969  decode.d8.loss_dice: 0.2736
08/06 08:36:10 - mmengine - INFO - Iter(train) [ 45750/320000]  base_lr: 8.7036e-05 lr: 8.7036e-06  eta: 1 day, 13:30:32  time: 0.4941  data_time: 0.0112  memory: 5878  grad_norm: 69.8705  loss: 8.6524  decode.loss_cls: 0.1713  decode.loss_mask: 0.2620  decode.loss_dice: 0.3531  decode.d0.loss_cls: 1.0442  decode.d0.loss_mask: 0.2694  decode.d0.loss_dice: 0.3654  decode.d1.loss_cls: 0.1574  decode.d1.loss_mask: 0.2687  decode.d1.loss_dice: 0.3336  decode.d2.loss_cls: 0.1925  decode.d2.loss_mask: 0.2647  decode.d2.loss_dice: 0.3532  decode.d3.loss_cls: 0.1488  decode.d3.loss_mask: 0.2671  decode.d3.loss_dice: 0.3544  decode.d4.loss_cls: 0.2061  decode.d4.loss_mask: 0.2649  decode.d4.loss_dice: 0.3368  decode.d5.loss_cls: 0.1618  decode.d5.loss_mask: 0.2658  decode.d5.loss_dice: 0.3309  decode.d6.loss_cls: 0.1082  decode.d6.loss_mask: 0.2659  decode.d6.loss_dice: 0.3346  decode.d7.loss_cls: 0.1585  decode.d7.loss_mask: 0.2651  decode.d7.loss_dice: 0.3528  decode.d8.loss_cls: 0.1704  decode.d8.loss_mask: 0.2654  decode.d8.loss_dice: 0.3592
08/06 08:36:34 - mmengine - INFO - Iter(train) [ 45800/320000]  base_lr: 8.7022e-05 lr: 8.7022e-06  eta: 1 day, 13:30:08  time: 0.4936  data_time: 0.0111  memory: 5928  grad_norm: 109.1102  loss: 5.2760  decode.loss_cls: 0.0384  decode.loss_mask: 0.1813  decode.loss_dice: 0.2229  decode.d0.loss_cls: 0.9008  decode.d0.loss_mask: 0.1898  decode.d0.loss_dice: 0.2361  decode.d1.loss_cls: 0.0510  decode.d1.loss_mask: 0.1827  decode.d1.loss_dice: 0.2260  decode.d2.loss_cls: 0.0326  decode.d2.loss_mask: 0.1816  decode.d2.loss_dice: 0.2216  decode.d3.loss_cls: 0.0237  decode.d3.loss_mask: 0.1813  decode.d3.loss_dice: 0.2271  decode.d4.loss_cls: 0.0188  decode.d4.loss_mask: 0.1821  decode.d4.loss_dice: 0.2261  decode.d5.loss_cls: 0.0274  decode.d5.loss_mask: 0.1819  decode.d5.loss_dice: 0.2240  decode.d6.loss_cls: 0.0247  decode.d6.loss_mask: 0.1814  decode.d6.loss_dice: 0.2210  decode.d7.loss_cls: 0.0321  decode.d7.loss_mask: 0.1823  decode.d7.loss_dice: 0.2278  decode.d8.loss_cls: 0.0443  decode.d8.loss_mask: 0.1827  decode.d8.loss_dice: 0.2224
08/06 08:36:59 - mmengine - INFO - Iter(train) [ 45850/320000]  base_lr: 8.7007e-05 lr: 8.7007e-06  eta: 1 day, 13:29:44  time: 0.4941  data_time: 0.0112  memory: 5928  grad_norm: 119.6779  loss: 6.9795  decode.loss_cls: 0.1753  decode.loss_mask: 0.1865  decode.loss_dice: 0.2957  decode.d0.loss_cls: 0.9076  decode.d0.loss_mask: 0.1850  decode.d0.loss_dice: 0.2567  decode.d1.loss_cls: 0.2670  decode.d1.loss_mask: 0.1868  decode.d1.loss_dice: 0.2390  decode.d2.loss_cls: 0.1710  decode.d2.loss_mask: 0.1857  decode.d2.loss_dice: 0.2799  decode.d3.loss_cls: 0.1309  decode.d3.loss_mask: 0.1861  decode.d3.loss_dice: 0.2860  decode.d4.loss_cls: 0.2092  decode.d4.loss_mask: 0.1850  decode.d4.loss_dice: 0.2716  decode.d5.loss_cls: 0.1253  decode.d5.loss_mask: 0.1850  decode.d5.loss_dice: 0.2706  decode.d6.loss_cls: 0.1402  decode.d6.loss_mask: 0.1837  decode.d6.loss_dice: 0.2458  decode.d7.loss_cls: 0.1766  decode.d7.loss_mask: 0.1844  decode.d7.loss_dice: 0.2745  decode.d8.loss_cls: 0.1339  decode.d8.loss_mask: 0.1849  decode.d8.loss_dice: 0.2697
08/06 08:37:24 - mmengine - INFO - Iter(train) [ 45900/320000]  base_lr: 8.6993e-05 lr: 8.6993e-06  eta: 1 day, 13:29:20  time: 0.4951  data_time: 0.0112  memory: 5909  grad_norm: 58.5530  loss: 5.6116  decode.loss_cls: 0.0516  decode.loss_mask: 0.2028  decode.loss_dice: 0.2214  decode.d0.loss_cls: 0.7638  decode.d0.loss_mask: 0.2030  decode.d0.loss_dice: 0.2254  decode.d1.loss_cls: 0.1270  decode.d1.loss_mask: 0.2023  decode.d1.loss_dice: 0.2064  decode.d2.loss_cls: 0.0549  decode.d2.loss_mask: 0.1980  decode.d2.loss_dice: 0.2094  decode.d3.loss_cls: 0.0716  decode.d3.loss_mask: 0.2006  decode.d3.loss_dice: 0.2043  decode.d4.loss_cls: 0.1057  decode.d4.loss_mask: 0.2029  decode.d4.loss_dice: 0.2236  decode.d5.loss_cls: 0.0628  decode.d5.loss_mask: 0.2027  decode.d5.loss_dice: 0.2118  decode.d6.loss_cls: 0.0514  decode.d6.loss_mask: 0.1996  decode.d6.loss_dice: 0.2251  decode.d7.loss_cls: 0.0688  decode.d7.loss_mask: 0.2034  decode.d7.loss_dice: 0.2208  decode.d8.loss_cls: 0.0652  decode.d8.loss_mask: 0.2020  decode.d8.loss_dice: 0.2231
08/06 08:37:49 - mmengine - INFO - Iter(train) [ 45950/320000]  base_lr: 8.6979e-05 lr: 8.6979e-06  eta: 1 day, 13:28:57  time: 0.4941  data_time: 0.0112  memory: 5911  grad_norm: 220.9067  loss: 10.3299  decode.loss_cls: 0.3405  decode.loss_mask: 0.2234  decode.loss_dice: 0.4027  decode.d0.loss_cls: 1.2093  decode.d0.loss_mask: 0.2197  decode.d0.loss_dice: 0.4117  decode.d1.loss_cls: 0.2590  decode.d1.loss_mask: 0.2308  decode.d1.loss_dice: 0.4228  decode.d2.loss_cls: 0.2790  decode.d2.loss_mask: 0.2204  decode.d2.loss_dice: 0.4041  decode.d3.loss_cls: 0.2425  decode.d3.loss_mask: 0.2228  decode.d3.loss_dice: 0.4206  decode.d4.loss_cls: 0.3015  decode.d4.loss_mask: 0.2268  decode.d4.loss_dice: 0.4176  decode.d5.loss_cls: 0.3277  decode.d5.loss_mask: 0.2325  decode.d5.loss_dice: 0.4079  decode.d6.loss_cls: 0.3311  decode.d6.loss_mask: 0.2339  decode.d6.loss_dice: 0.4259  decode.d7.loss_cls: 0.3226  decode.d7.loss_mask: 0.2285  decode.d7.loss_dice: 0.4042  decode.d8.loss_cls: 0.3328  decode.d8.loss_mask: 0.2272  decode.d8.loss_dice: 0.4005
08/06 08:38:13 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 08:38:13 - mmengine - INFO - Iter(train) [ 46000/320000]  base_lr: 8.6964e-05 lr: 8.6964e-06  eta: 1 day, 13:28:33  time: 0.4948  data_time: 0.0112  memory: 5894  grad_norm: 104.9927  loss: 8.9683  decode.loss_cls: 0.3363  decode.loss_mask: 0.2393  decode.loss_dice: 0.3059  decode.d0.loss_cls: 0.9763  decode.d0.loss_mask: 0.2413  decode.d0.loss_dice: 0.3058  decode.d1.loss_cls: 0.2456  decode.d1.loss_mask: 0.2382  decode.d1.loss_dice: 0.2726  decode.d2.loss_cls: 0.2319  decode.d2.loss_mask: 0.2381  decode.d2.loss_dice: 0.2996  decode.d3.loss_cls: 0.3336  decode.d3.loss_mask: 0.2373  decode.d3.loss_dice: 0.2808  decode.d4.loss_cls: 0.3117  decode.d4.loss_mask: 0.2390  decode.d4.loss_dice: 0.2816  decode.d5.loss_cls: 0.2732  decode.d5.loss_mask: 0.2363  decode.d5.loss_dice: 0.3099  decode.d6.loss_cls: 0.3120  decode.d6.loss_mask: 0.2369  decode.d6.loss_dice: 0.3160  decode.d7.loss_cls: 0.2656  decode.d7.loss_mask: 0.2401  decode.d7.loss_dice: 0.3164  decode.d8.loss_cls: 0.3050  decode.d8.loss_mask: 0.2373  decode.d8.loss_dice: 0.3044
08/06 08:38:38 - mmengine - INFO - Iter(train) [ 46050/320000]  base_lr: 8.6950e-05 lr: 8.6950e-06  eta: 1 day, 13:28:09  time: 0.4945  data_time: 0.0113  memory: 5878  grad_norm: 90.5351  loss: 6.7117  decode.loss_cls: 0.0858  decode.loss_mask: 0.2299  decode.loss_dice: 0.2879  decode.d0.loss_cls: 0.8040  decode.d0.loss_mask: 0.2383  decode.d0.loss_dice: 0.2645  decode.d1.loss_cls: 0.0781  decode.d1.loss_mask: 0.2352  decode.d1.loss_dice: 0.2832  decode.d2.loss_cls: 0.0817  decode.d2.loss_mask: 0.2297  decode.d2.loss_dice: 0.2709  decode.d3.loss_cls: 0.0971  decode.d3.loss_mask: 0.2315  decode.d3.loss_dice: 0.2818  decode.d4.loss_cls: 0.0983  decode.d4.loss_mask: 0.2289  decode.d4.loss_dice: 0.2671  decode.d5.loss_cls: 0.1114  decode.d5.loss_mask: 0.2289  decode.d5.loss_dice: 0.2732  decode.d6.loss_cls: 0.1098  decode.d6.loss_mask: 0.2287  decode.d6.loss_dice: 0.2745  decode.d7.loss_cls: 0.1006  decode.d7.loss_mask: 0.2299  decode.d7.loss_dice: 0.2698  decode.d8.loss_cls: 0.0992  decode.d8.loss_mask: 0.2326  decode.d8.loss_dice: 0.2593
08/06 08:39:03 - mmengine - INFO - Iter(train) [ 46100/320000]  base_lr: 8.6936e-05 lr: 8.6936e-06  eta: 1 day, 13:27:44  time: 0.4943  data_time: 0.0111  memory: 5911  grad_norm: 108.0862  loss: 6.4454  decode.loss_cls: 0.1343  decode.loss_mask: 0.2178  decode.loss_dice: 0.2233  decode.d0.loss_cls: 0.8102  decode.d0.loss_mask: 0.2206  decode.d0.loss_dice: 0.2401  decode.d1.loss_cls: 0.1294  decode.d1.loss_mask: 0.2232  decode.d1.loss_dice: 0.2135  decode.d2.loss_cls: 0.1336  decode.d2.loss_mask: 0.2172  decode.d2.loss_dice: 0.2173  decode.d3.loss_cls: 0.1262  decode.d3.loss_mask: 0.2174  decode.d3.loss_dice: 0.2168  decode.d4.loss_cls: 0.1223  decode.d4.loss_mask: 0.2173  decode.d4.loss_dice: 0.2115  decode.d5.loss_cls: 0.1379  decode.d5.loss_mask: 0.2139  decode.d5.loss_dice: 0.2207  decode.d6.loss_cls: 0.1590  decode.d6.loss_mask: 0.2199  decode.d6.loss_dice: 0.2175  decode.d7.loss_cls: 0.1510  decode.d7.loss_mask: 0.2167  decode.d7.loss_dice: 0.2326  decode.d8.loss_cls: 0.1372  decode.d8.loss_mask: 0.2162  decode.d8.loss_dice: 0.2308
08/06 08:39:27 - mmengine - INFO - Iter(train) [ 46150/320000]  base_lr: 8.6922e-05 lr: 8.6922e-06  eta: 1 day, 13:27:20  time: 0.4937  data_time: 0.0110  memory: 5891  grad_norm: 59.7933  loss: 6.9132  decode.loss_cls: 0.2181  decode.loss_mask: 0.2033  decode.loss_dice: 0.2322  decode.d0.loss_cls: 0.7939  decode.d0.loss_mask: 0.2047  decode.d0.loss_dice: 0.2658  decode.d1.loss_cls: 0.2045  decode.d1.loss_mask: 0.2024  decode.d1.loss_dice: 0.2321  decode.d2.loss_cls: 0.1559  decode.d2.loss_mask: 0.2023  decode.d2.loss_dice: 0.2509  decode.d3.loss_cls: 0.1345  decode.d3.loss_mask: 0.1994  decode.d3.loss_dice: 0.2475  decode.d4.loss_cls: 0.1614  decode.d4.loss_mask: 0.2026  decode.d4.loss_dice: 0.2435  decode.d5.loss_cls: 0.2120  decode.d5.loss_mask: 0.2034  decode.d5.loss_dice: 0.2567  decode.d6.loss_cls: 0.1855  decode.d6.loss_mask: 0.2010  decode.d6.loss_dice: 0.2634  decode.d7.loss_cls: 0.1672  decode.d7.loss_mask: 0.2029  decode.d7.loss_dice: 0.2281  decode.d8.loss_cls: 0.1982  decode.d8.loss_mask: 0.2051  decode.d8.loss_dice: 0.2344
08/06 08:39:52 - mmengine - INFO - Iter(train) [ 46200/320000]  base_lr: 8.6907e-05 lr: 8.6907e-06  eta: 1 day, 13:26:56  time: 0.4932  data_time: 0.0111  memory: 5909  grad_norm: 146.6779  loss: 7.1910  decode.loss_cls: 0.1316  decode.loss_mask: 0.2438  decode.loss_dice: 0.2454  decode.d0.loss_cls: 0.8971  decode.d0.loss_mask: 0.2532  decode.d0.loss_dice: 0.2595  decode.d1.loss_cls: 0.1441  decode.d1.loss_mask: 0.2520  decode.d1.loss_dice: 0.2552  decode.d2.loss_cls: 0.1475  decode.d2.loss_mask: 0.2512  decode.d2.loss_dice: 0.2503  decode.d3.loss_cls: 0.1537  decode.d3.loss_mask: 0.2467  decode.d3.loss_dice: 0.2613  decode.d4.loss_cls: 0.1262  decode.d4.loss_mask: 0.2466  decode.d4.loss_dice: 0.2559  decode.d5.loss_cls: 0.1411  decode.d5.loss_mask: 0.2456  decode.d5.loss_dice: 0.2613  decode.d6.loss_cls: 0.1375  decode.d6.loss_mask: 0.2443  decode.d6.loss_dice: 0.2612  decode.d7.loss_cls: 0.1458  decode.d7.loss_mask: 0.2401  decode.d7.loss_dice: 0.2608  decode.d8.loss_cls: 0.1204  decode.d8.loss_mask: 0.2479  decode.d8.loss_dice: 0.2637
08/06 08:40:17 - mmengine - INFO - Iter(train) [ 46250/320000]  base_lr: 8.6893e-05 lr: 8.6893e-06  eta: 1 day, 13:26:32  time: 0.4941  data_time: 0.0110  memory: 5909  grad_norm: 129.2179  loss: 8.7662  decode.loss_cls: 0.2226  decode.loss_mask: 0.2456  decode.loss_dice: 0.3078  decode.d0.loss_cls: 1.0302  decode.d0.loss_mask: 0.2547  decode.d0.loss_dice: 0.3226  decode.d1.loss_cls: 0.2582  decode.d1.loss_mask: 0.2509  decode.d1.loss_dice: 0.3250  decode.d2.loss_cls: 0.2205  decode.d2.loss_mask: 0.2444  decode.d2.loss_dice: 0.3166  decode.d3.loss_cls: 0.2397  decode.d3.loss_mask: 0.2423  decode.d3.loss_dice: 0.3276  decode.d4.loss_cls: 0.2338  decode.d4.loss_mask: 0.2472  decode.d4.loss_dice: 0.3204  decode.d5.loss_cls: 0.2335  decode.d5.loss_mask: 0.2468  decode.d5.loss_dice: 0.3259  decode.d6.loss_cls: 0.2454  decode.d6.loss_mask: 0.2435  decode.d6.loss_dice: 0.3197  decode.d7.loss_cls: 0.2015  decode.d7.loss_mask: 0.2458  decode.d7.loss_dice: 0.3153  decode.d8.loss_cls: 0.2214  decode.d8.loss_mask: 0.2461  decode.d8.loss_dice: 0.3115
08/06 08:40:42 - mmengine - INFO - Iter(train) [ 46300/320000]  base_lr: 8.6879e-05 lr: 8.6879e-06  eta: 1 day, 13:26:08  time: 0.4944  data_time: 0.0111  memory: 5878  grad_norm: 76.6807  loss: 5.4228  decode.loss_cls: 0.0251  decode.loss_mask: 0.1976  decode.loss_dice: 0.2240  decode.d0.loss_cls: 0.8817  decode.d0.loss_mask: 0.2014  decode.d0.loss_dice: 0.2258  decode.d1.loss_cls: 0.0296  decode.d1.loss_mask: 0.1989  decode.d1.loss_dice: 0.2162  decode.d2.loss_cls: 0.0510  decode.d2.loss_mask: 0.2032  decode.d2.loss_dice: 0.2320  decode.d3.loss_cls: 0.0577  decode.d3.loss_mask: 0.2012  decode.d3.loss_dice: 0.2262  decode.d4.loss_cls: 0.0166  decode.d4.loss_mask: 0.1981  decode.d4.loss_dice: 0.2250  decode.d5.loss_cls: 0.0245  decode.d5.loss_mask: 0.2003  decode.d5.loss_dice: 0.2282  decode.d6.loss_cls: 0.0491  decode.d6.loss_mask: 0.1993  decode.d6.loss_dice: 0.2223  decode.d7.loss_cls: 0.0240  decode.d7.loss_mask: 0.1978  decode.d7.loss_dice: 0.2195  decode.d8.loss_cls: 0.0256  decode.d8.loss_mask: 0.1992  decode.d8.loss_dice: 0.2219
08/06 08:41:06 - mmengine - INFO - Iter(train) [ 46350/320000]  base_lr: 8.6864e-05 lr: 8.6864e-06  eta: 1 day, 13:25:44  time: 0.4931  data_time: 0.0110  memory: 5911  grad_norm: 294.2194  loss: 8.6010  decode.loss_cls: 0.1509  decode.loss_mask: 0.3321  decode.loss_dice: 0.2723  decode.d0.loss_cls: 1.0062  decode.d0.loss_mask: 0.3608  decode.d0.loss_dice: 0.2860  decode.d1.loss_cls: 0.2226  decode.d1.loss_mask: 0.3421  decode.d1.loss_dice: 0.2720  decode.d2.loss_cls: 0.2029  decode.d2.loss_mask: 0.3380  decode.d2.loss_dice: 0.2760  decode.d3.loss_cls: 0.1348  decode.d3.loss_mask: 0.3342  decode.d3.loss_dice: 0.2701  decode.d4.loss_cls: 0.1776  decode.d4.loss_mask: 0.3343  decode.d4.loss_dice: 0.2793  decode.d5.loss_cls: 0.1305  decode.d5.loss_mask: 0.3231  decode.d5.loss_dice: 0.2694  decode.d6.loss_cls: 0.1692  decode.d6.loss_mask: 0.3304  decode.d6.loss_dice: 0.2768  decode.d7.loss_cls: 0.1469  decode.d7.loss_mask: 0.3264  decode.d7.loss_dice: 0.2782  decode.d8.loss_cls: 0.1417  decode.d8.loss_mask: 0.3341  decode.d8.loss_dice: 0.2822
08/06 08:41:31 - mmengine - INFO - Iter(train) [ 46400/320000]  base_lr: 8.6850e-05 lr: 8.6850e-06  eta: 1 day, 13:25:20  time: 0.4950  data_time: 0.0115  memory: 5928  grad_norm: 189.8842  loss: 6.7858  decode.loss_cls: 0.2118  decode.loss_mask: 0.2226  decode.loss_dice: 0.2228  decode.d0.loss_cls: 0.8092  decode.d0.loss_mask: 0.2258  decode.d0.loss_dice: 0.2619  decode.d1.loss_cls: 0.1532  decode.d1.loss_mask: 0.2204  decode.d1.loss_dice: 0.2410  decode.d2.loss_cls: 0.1311  decode.d2.loss_mask: 0.2209  decode.d2.loss_dice: 0.2560  decode.d3.loss_cls: 0.1358  decode.d3.loss_mask: 0.2242  decode.d3.loss_dice: 0.2413  decode.d4.loss_cls: 0.1168  decode.d4.loss_mask: 0.2223  decode.d4.loss_dice: 0.2559  decode.d5.loss_cls: 0.1807  decode.d5.loss_mask: 0.2212  decode.d5.loss_dice: 0.2544  decode.d6.loss_cls: 0.1090  decode.d6.loss_mask: 0.2231  decode.d6.loss_dice: 0.2520  decode.d7.loss_cls: 0.1096  decode.d7.loss_mask: 0.2213  decode.d7.loss_dice: 0.2413  decode.d8.loss_cls: 0.1370  decode.d8.loss_mask: 0.2251  decode.d8.loss_dice: 0.2377
08/06 08:41:56 - mmengine - INFO - Iter(train) [ 46450/320000]  base_lr: 8.6836e-05 lr: 8.6836e-06  eta: 1 day, 13:24:56  time: 0.4939  data_time: 0.0111  memory: 5911  grad_norm: 122.6075  loss: 6.4468  decode.loss_cls: 0.0930  decode.loss_mask: 0.2240  decode.loss_dice: 0.2331  decode.d0.loss_cls: 0.8851  decode.d0.loss_mask: 0.2292  decode.d0.loss_dice: 0.2462  decode.d1.loss_cls: 0.1563  decode.d1.loss_mask: 0.2268  decode.d1.loss_dice: 0.2385  decode.d2.loss_cls: 0.1062  decode.d2.loss_mask: 0.2288  decode.d2.loss_dice: 0.2379  decode.d3.loss_cls: 0.0879  decode.d3.loss_mask: 0.2308  decode.d3.loss_dice: 0.2428  decode.d4.loss_cls: 0.0771  decode.d4.loss_mask: 0.2311  decode.d4.loss_dice: 0.2473  decode.d5.loss_cls: 0.1011  decode.d5.loss_mask: 0.2256  decode.d5.loss_dice: 0.2339  decode.d6.loss_cls: 0.1225  decode.d6.loss_mask: 0.2245  decode.d6.loss_dice: 0.2339  decode.d7.loss_cls: 0.0805  decode.d7.loss_mask: 0.2238  decode.d7.loss_dice: 0.2334  decode.d8.loss_cls: 0.0831  decode.d8.loss_mask: 0.2278  decode.d8.loss_dice: 0.2347
08/06 08:42:20 - mmengine - INFO - Iter(train) [ 46500/320000]  base_lr: 8.6822e-05 lr: 8.6822e-06  eta: 1 day, 13:24:32  time: 0.4954  data_time: 0.0113  memory: 5894  grad_norm: 86.6955  loss: 7.3097  decode.loss_cls: 0.1683  decode.loss_mask: 0.2218  decode.loss_dice: 0.2696  decode.d0.loss_cls: 0.8409  decode.d0.loss_mask: 0.2311  decode.d0.loss_dice: 0.2814  decode.d1.loss_cls: 0.1860  decode.d1.loss_mask: 0.2216  decode.d1.loss_dice: 0.2637  decode.d2.loss_cls: 0.1417  decode.d2.loss_mask: 0.2230  decode.d2.loss_dice: 0.2829  decode.d3.loss_cls: 0.1699  decode.d3.loss_mask: 0.2223  decode.d3.loss_dice: 0.2747  decode.d4.loss_cls: 0.1755  decode.d4.loss_mask: 0.2218  decode.d4.loss_dice: 0.2754  decode.d5.loss_cls: 0.1782  decode.d5.loss_mask: 0.2210  decode.d5.loss_dice: 0.2740  decode.d6.loss_cls: 0.1778  decode.d6.loss_mask: 0.2182  decode.d6.loss_dice: 0.2777  decode.d7.loss_cls: 0.1474  decode.d7.loss_mask: 0.2197  decode.d7.loss_dice: 0.2722  decode.d8.loss_cls: 0.1733  decode.d8.loss_mask: 0.2181  decode.d8.loss_dice: 0.2604
08/06 08:42:45 - mmengine - INFO - Iter(train) [ 46550/320000]  base_lr: 8.6807e-05 lr: 8.6807e-06  eta: 1 day, 13:24:08  time: 0.4944  data_time: 0.0108  memory: 5911  grad_norm: 153.9828  loss: 9.5865  decode.loss_cls: 0.2817  decode.loss_mask: 0.2458  decode.loss_dice: 0.3648  decode.d0.loss_cls: 1.2270  decode.d0.loss_mask: 0.2042  decode.d0.loss_dice: 0.3043  decode.d1.loss_cls: 0.2894  decode.d1.loss_mask: 0.2351  decode.d1.loss_dice: 0.3372  decode.d2.loss_cls: 0.2611  decode.d2.loss_mask: 0.2459  decode.d2.loss_dice: 0.3408  decode.d3.loss_cls: 0.2662  decode.d3.loss_mask: 0.2425  decode.d3.loss_dice: 0.3572  decode.d4.loss_cls: 0.2992  decode.d4.loss_mask: 0.2457  decode.d4.loss_dice: 0.3491  decode.d5.loss_cls: 0.2757  decode.d5.loss_mask: 0.2466  decode.d5.loss_dice: 0.3586  decode.d6.loss_cls: 0.2720  decode.d6.loss_mask: 0.2570  decode.d6.loss_dice: 0.3432  decode.d7.loss_cls: 0.2549  decode.d7.loss_mask: 0.2396  decode.d7.loss_dice: 0.3439  decode.d8.loss_cls: 0.3018  decode.d8.loss_mask: 0.2491  decode.d8.loss_dice: 0.3469
08/06 08:43:10 - mmengine - INFO - Iter(train) [ 46600/320000]  base_lr: 8.6793e-05 lr: 8.6793e-06  eta: 1 day, 13:23:44  time: 0.4939  data_time: 0.0111  memory: 5928  grad_norm: 140.0036  loss: 7.3581  decode.loss_cls: 0.1347  decode.loss_mask: 0.2558  decode.loss_dice: 0.2624  decode.d0.loss_cls: 0.8894  decode.d0.loss_mask: 0.2586  decode.d0.loss_dice: 0.2617  decode.d1.loss_cls: 0.1848  decode.d1.loss_mask: 0.2481  decode.d1.loss_dice: 0.2664  decode.d2.loss_cls: 0.1645  decode.d2.loss_mask: 0.2645  decode.d2.loss_dice: 0.2676  decode.d3.loss_cls: 0.1627  decode.d3.loss_mask: 0.2691  decode.d3.loss_dice: 0.2667  decode.d4.loss_cls: 0.1482  decode.d4.loss_mask: 0.2559  decode.d4.loss_dice: 0.2568  decode.d5.loss_cls: 0.1068  decode.d5.loss_mask: 0.2577  decode.d5.loss_dice: 0.2670  decode.d6.loss_cls: 0.1254  decode.d6.loss_mask: 0.2522  decode.d6.loss_dice: 0.2648  decode.d7.loss_cls: 0.1165  decode.d7.loss_mask: 0.2509  decode.d7.loss_dice: 0.2579  decode.d8.loss_cls: 0.1233  decode.d8.loss_mask: 0.2560  decode.d8.loss_dice: 0.2620
08/06 08:43:35 - mmengine - INFO - Iter(train) [ 46650/320000]  base_lr: 8.6779e-05 lr: 8.6779e-06  eta: 1 day, 13:23:20  time: 0.4937  data_time: 0.0110  memory: 5909  grad_norm: 95.7040  loss: 6.5230  decode.loss_cls: 0.0745  decode.loss_mask: 0.2366  decode.loss_dice: 0.2422  decode.d0.loss_cls: 1.0363  decode.d0.loss_mask: 0.2416  decode.d0.loss_dice: 0.2269  decode.d1.loss_cls: 0.0840  decode.d1.loss_mask: 0.2429  decode.d1.loss_dice: 0.2488  decode.d2.loss_cls: 0.0693  decode.d2.loss_mask: 0.2392  decode.d2.loss_dice: 0.2370  decode.d3.loss_cls: 0.0588  decode.d3.loss_mask: 0.2365  decode.d3.loss_dice: 0.2497  decode.d4.loss_cls: 0.0726  decode.d4.loss_mask: 0.2409  decode.d4.loss_dice: 0.2390  decode.d5.loss_cls: 0.0755  decode.d5.loss_mask: 0.2392  decode.d5.loss_dice: 0.2405  decode.d6.loss_cls: 0.0821  decode.d6.loss_mask: 0.2358  decode.d6.loss_dice: 0.2350  decode.d7.loss_cls: 0.0807  decode.d7.loss_mask: 0.2384  decode.d7.loss_dice: 0.2403  decode.d8.loss_cls: 0.0912  decode.d8.loss_mask: 0.2376  decode.d8.loss_dice: 0.2498
08/06 08:43:59 - mmengine - INFO - Iter(train) [ 46700/320000]  base_lr: 8.6764e-05 lr: 8.6764e-06  eta: 1 day, 13:22:56  time: 0.4940  data_time: 0.0111  memory: 5909  grad_norm: 44.0051  loss: 6.1663  decode.loss_cls: 0.0040  decode.loss_mask: 0.2860  decode.loss_dice: 0.2470  decode.d0.loss_cls: 0.7271  decode.d0.loss_mask: 0.2923  decode.d0.loss_dice: 0.2521  decode.d1.loss_cls: 0.0152  decode.d1.loss_mask: 0.2853  decode.d1.loss_dice: 0.2509  decode.d2.loss_cls: 0.0194  decode.d2.loss_mask: 0.2875  decode.d2.loss_dice: 0.2505  decode.d3.loss_cls: 0.0089  decode.d3.loss_mask: 0.2883  decode.d3.loss_dice: 0.2475  decode.d4.loss_cls: 0.0066  decode.d4.loss_mask: 0.2882  decode.d4.loss_dice: 0.2493  decode.d5.loss_cls: 0.0059  decode.d5.loss_mask: 0.2847  decode.d5.loss_dice: 0.2471  decode.d6.loss_cls: 0.0067  decode.d6.loss_mask: 0.2893  decode.d6.loss_dice: 0.2472  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.2866  decode.d7.loss_dice: 0.2486  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.2884  decode.d8.loss_dice: 0.2484
08/06 08:44:24 - mmengine - INFO - Iter(train) [ 46750/320000]  base_lr: 8.6750e-05 lr: 8.6750e-06  eta: 1 day, 13:22:32  time: 0.4938  data_time: 0.0112  memory: 5874  grad_norm: 150.5117  loss: 6.2028  decode.loss_cls: 0.0558  decode.loss_mask: 0.2418  decode.loss_dice: 0.2206  decode.d0.loss_cls: 0.8433  decode.d0.loss_mask: 0.2415  decode.d0.loss_dice: 0.2201  decode.d1.loss_cls: 0.1249  decode.d1.loss_mask: 0.2402  decode.d1.loss_dice: 0.2350  decode.d2.loss_cls: 0.0674  decode.d2.loss_mask: 0.2607  decode.d2.loss_dice: 0.2456  decode.d3.loss_cls: 0.0474  decode.d3.loss_mask: 0.2689  decode.d3.loss_dice: 0.2462  decode.d4.loss_cls: 0.0320  decode.d4.loss_mask: 0.2699  decode.d4.loss_dice: 0.2507  decode.d5.loss_cls: 0.0286  decode.d5.loss_mask: 0.2429  decode.d5.loss_dice: 0.2368  decode.d6.loss_cls: 0.0265  decode.d6.loss_mask: 0.2427  decode.d6.loss_dice: 0.2324  decode.d7.loss_cls: 0.0547  decode.d7.loss_mask: 0.2398  decode.d7.loss_dice: 0.2365  decode.d8.loss_cls: 0.0676  decode.d8.loss_mask: 0.2414  decode.d8.loss_dice: 0.2412
08/06 08:44:49 - mmengine - INFO - Iter(train) [ 46800/320000]  base_lr: 8.6736e-05 lr: 8.6736e-06  eta: 1 day, 13:22:08  time: 0.4939  data_time: 0.0110  memory: 5911  grad_norm: 78.0974  loss: 7.3086  decode.loss_cls: 0.1470  decode.loss_mask: 0.2306  decode.loss_dice: 0.2911  decode.d0.loss_cls: 0.9396  decode.d0.loss_mask: 0.2225  decode.d0.loss_dice: 0.2791  decode.d1.loss_cls: 0.1876  decode.d1.loss_mask: 0.2275  decode.d1.loss_dice: 0.2860  decode.d2.loss_cls: 0.1038  decode.d2.loss_mask: 0.2277  decode.d2.loss_dice: 0.2961  decode.d3.loss_cls: 0.1874  decode.d3.loss_mask: 0.2280  decode.d3.loss_dice: 0.2835  decode.d4.loss_cls: 0.1450  decode.d4.loss_mask: 0.2252  decode.d4.loss_dice: 0.2860  decode.d5.loss_cls: 0.0796  decode.d5.loss_mask: 0.2291  decode.d5.loss_dice: 0.3077  decode.d6.loss_cls: 0.1287  decode.d6.loss_mask: 0.2324  decode.d6.loss_dice: 0.3006  decode.d7.loss_cls: 0.1048  decode.d7.loss_mask: 0.2322  decode.d7.loss_dice: 0.2982  decode.d8.loss_cls: 0.1103  decode.d8.loss_mask: 0.2280  decode.d8.loss_dice: 0.2633
08/06 08:45:14 - mmengine - INFO - Iter(train) [ 46850/320000]  base_lr: 8.6722e-05 lr: 8.6722e-06  eta: 1 day, 13:21:44  time: 0.4941  data_time: 0.0114  memory: 5876  grad_norm: 107.8193  loss: 9.5869  decode.loss_cls: 0.2222  decode.loss_mask: 0.3509  decode.loss_dice: 0.3177  decode.d0.loss_cls: 0.9829  decode.d0.loss_mask: 0.3573  decode.d0.loss_dice: 0.3309  decode.d1.loss_cls: 0.2836  decode.d1.loss_mask: 0.3597  decode.d1.loss_dice: 0.3343  decode.d2.loss_cls: 0.1924  decode.d2.loss_mask: 0.3580  decode.d2.loss_dice: 0.3340  decode.d3.loss_cls: 0.1694  decode.d3.loss_mask: 0.3534  decode.d3.loss_dice: 0.3326  decode.d4.loss_cls: 0.1454  decode.d4.loss_mask: 0.3551  decode.d4.loss_dice: 0.3327  decode.d5.loss_cls: 0.1491  decode.d5.loss_mask: 0.3677  decode.d5.loss_dice: 0.3397  decode.d6.loss_cls: 0.1302  decode.d6.loss_mask: 0.3647  decode.d6.loss_dice: 0.3311  decode.d7.loss_cls: 0.2091  decode.d7.loss_mask: 0.3627  decode.d7.loss_dice: 0.3390  decode.d8.loss_cls: 0.2025  decode.d8.loss_mask: 0.3578  decode.d8.loss_dice: 0.3208
08/06 08:45:38 - mmengine - INFO - Iter(train) [ 46900/320000]  base_lr: 8.6707e-05 lr: 8.6707e-06  eta: 1 day, 13:21:19  time: 0.4939  data_time: 0.0112  memory: 5874  grad_norm: 194.9668  loss: 9.0913  decode.loss_cls: 0.1998  decode.loss_mask: 0.2744  decode.loss_dice: 0.3432  decode.d0.loss_cls: 1.0668  decode.d0.loss_mask: 0.2753  decode.d0.loss_dice: 0.3276  decode.d1.loss_cls: 0.1662  decode.d1.loss_mask: 0.2790  decode.d1.loss_dice: 0.3424  decode.d2.loss_cls: 0.2259  decode.d2.loss_mask: 0.2737  decode.d2.loss_dice: 0.3425  decode.d3.loss_cls: 0.1947  decode.d3.loss_mask: 0.2756  decode.d3.loss_dice: 0.3140  decode.d4.loss_cls: 0.2602  decode.d4.loss_mask: 0.2769  decode.d4.loss_dice: 0.3281  decode.d5.loss_cls: 0.1898  decode.d5.loss_mask: 0.2786  decode.d5.loss_dice: 0.3390  decode.d6.loss_cls: 0.2527  decode.d6.loss_mask: 0.2745  decode.d6.loss_dice: 0.3442  decode.d7.loss_cls: 0.2432  decode.d7.loss_mask: 0.2747  decode.d7.loss_dice: 0.3144  decode.d8.loss_cls: 0.2015  decode.d8.loss_mask: 0.2760  decode.d8.loss_dice: 0.3363
08/06 08:46:03 - mmengine - INFO - Iter(train) [ 46950/320000]  base_lr: 8.6693e-05 lr: 8.6693e-06  eta: 1 day, 13:20:55  time: 0.4947  data_time: 0.0110  memory: 5875  grad_norm: 102.2899  loss: 7.0487  decode.loss_cls: 0.0548  decode.loss_mask: 0.2844  decode.loss_dice: 0.2773  decode.d0.loss_cls: 0.8170  decode.d0.loss_mask: 0.2585  decode.d0.loss_dice: 0.2640  decode.d1.loss_cls: 0.1100  decode.d1.loss_mask: 0.2751  decode.d1.loss_dice: 0.2599  decode.d2.loss_cls: 0.0766  decode.d2.loss_mask: 0.2748  decode.d2.loss_dice: 0.2604  decode.d3.loss_cls: 0.1366  decode.d3.loss_mask: 0.2595  decode.d3.loss_dice: 0.2559  decode.d4.loss_cls: 0.1450  decode.d4.loss_mask: 0.2600  decode.d4.loss_dice: 0.2531  decode.d5.loss_cls: 0.1407  decode.d5.loss_mask: 0.2611  decode.d5.loss_dice: 0.2497  decode.d6.loss_cls: 0.1224  decode.d6.loss_mask: 0.2606  decode.d6.loss_dice: 0.2553  decode.d7.loss_cls: 0.0438  decode.d7.loss_mask: 0.2857  decode.d7.loss_dice: 0.2715  decode.d8.loss_cls: 0.0992  decode.d8.loss_mask: 0.2695  decode.d8.loss_dice: 0.2663
08/06 08:46:28 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 08:46:28 - mmengine - INFO - Iter(train) [ 47000/320000]  base_lr: 8.6679e-05 lr: 8.6679e-06  eta: 1 day, 13:20:31  time: 0.4932  data_time: 0.0110  memory: 5911  grad_norm: 53.8333  loss: 5.8381  decode.loss_cls: 0.0468  decode.loss_mask: 0.2145  decode.loss_dice: 0.2163  decode.d0.loss_cls: 0.8361  decode.d0.loss_mask: 0.2159  decode.d0.loss_dice: 0.2121  decode.d1.loss_cls: 0.0809  decode.d1.loss_mask: 0.2190  decode.d1.loss_dice: 0.2252  decode.d2.loss_cls: 0.0748  decode.d2.loss_mask: 0.2164  decode.d2.loss_dice: 0.2236  decode.d3.loss_cls: 0.0764  decode.d3.loss_mask: 0.2150  decode.d3.loss_dice: 0.2222  decode.d4.loss_cls: 0.0574  decode.d4.loss_mask: 0.2156  decode.d4.loss_dice: 0.2198  decode.d5.loss_cls: 0.0782  decode.d5.loss_mask: 0.2151  decode.d5.loss_dice: 0.2191  decode.d6.loss_cls: 0.0750  decode.d6.loss_mask: 0.2157  decode.d6.loss_dice: 0.2264  decode.d7.loss_cls: 0.0692  decode.d7.loss_mask: 0.2174  decode.d7.loss_dice: 0.2195  decode.d8.loss_cls: 0.0789  decode.d8.loss_mask: 0.2155  decode.d8.loss_dice: 0.2203
08/06 08:46:52 - mmengine - INFO - Iter(train) [ 47050/320000]  base_lr: 8.6664e-05 lr: 8.6664e-06  eta: 1 day, 13:20:07  time: 0.4948  data_time: 0.0111  memory: 5911  grad_norm: 131.4881  loss: 7.0879  decode.loss_cls: 0.1078  decode.loss_mask: 0.2298  decode.loss_dice: 0.2882  decode.d0.loss_cls: 0.8119  decode.d0.loss_mask: 0.2346  decode.d0.loss_dice: 0.2851  decode.d1.loss_cls: 0.1786  decode.d1.loss_mask: 0.2307  decode.d1.loss_dice: 0.2862  decode.d2.loss_cls: 0.1288  decode.d2.loss_mask: 0.2294  decode.d2.loss_dice: 0.2946  decode.d3.loss_cls: 0.0945  decode.d3.loss_mask: 0.2288  decode.d3.loss_dice: 0.2867  decode.d4.loss_cls: 0.1301  decode.d4.loss_mask: 0.2271  decode.d4.loss_dice: 0.2811  decode.d5.loss_cls: 0.1241  decode.d5.loss_mask: 0.2267  decode.d5.loss_dice: 0.2905  decode.d6.loss_cls: 0.1154  decode.d6.loss_mask: 0.2290  decode.d6.loss_dice: 0.2803  decode.d7.loss_cls: 0.1181  decode.d7.loss_mask: 0.2336  decode.d7.loss_dice: 0.2902  decode.d8.loss_cls: 0.0973  decode.d8.loss_mask: 0.2297  decode.d8.loss_dice: 0.2988
08/06 08:47:17 - mmengine - INFO - Iter(train) [ 47100/320000]  base_lr: 8.6650e-05 lr: 8.6650e-06  eta: 1 day, 13:19:44  time: 0.4943  data_time: 0.0111  memory: 5876  grad_norm: 62.9404  loss: 5.3543  decode.loss_cls: 0.0753  decode.loss_mask: 0.2001  decode.loss_dice: 0.2028  decode.d0.loss_cls: 0.7206  decode.d0.loss_mask: 0.2017  decode.d0.loss_dice: 0.2084  decode.d1.loss_cls: 0.0535  decode.d1.loss_mask: 0.2022  decode.d1.loss_dice: 0.2036  decode.d2.loss_cls: 0.0557  decode.d2.loss_mask: 0.1972  decode.d2.loss_dice: 0.2016  decode.d3.loss_cls: 0.0441  decode.d3.loss_mask: 0.1993  decode.d3.loss_dice: 0.2113  decode.d4.loss_cls: 0.0610  decode.d4.loss_mask: 0.1981  decode.d4.loss_dice: 0.2115  decode.d5.loss_cls: 0.0654  decode.d5.loss_mask: 0.1998  decode.d5.loss_dice: 0.2105  decode.d6.loss_cls: 0.0767  decode.d6.loss_mask: 0.2000  decode.d6.loss_dice: 0.1980  decode.d7.loss_cls: 0.0779  decode.d7.loss_mask: 0.2013  decode.d7.loss_dice: 0.2018  decode.d8.loss_cls: 0.0744  decode.d8.loss_mask: 0.1996  decode.d8.loss_dice: 0.2007
08/06 08:47:42 - mmengine - INFO - Iter(train) [ 47150/320000]  base_lr: 8.6636e-05 lr: 8.6636e-06  eta: 1 day, 13:19:20  time: 0.4948  data_time: 0.0113  memory: 5896  grad_norm: 120.5001  loss: 7.1559  decode.loss_cls: 0.0746  decode.loss_mask: 0.2641  decode.loss_dice: 0.2940  decode.d0.loss_cls: 0.7732  decode.d0.loss_mask: 0.2595  decode.d0.loss_dice: 0.3103  decode.d1.loss_cls: 0.1621  decode.d1.loss_mask: 0.2573  decode.d1.loss_dice: 0.3140  decode.d2.loss_cls: 0.0460  decode.d2.loss_mask: 0.2566  decode.d2.loss_dice: 0.3110  decode.d3.loss_cls: 0.0975  decode.d3.loss_mask: 0.2529  decode.d3.loss_dice: 0.3106  decode.d4.loss_cls: 0.0549  decode.d4.loss_mask: 0.2521  decode.d4.loss_dice: 0.3008  decode.d5.loss_cls: 0.0524  decode.d5.loss_mask: 0.2567  decode.d5.loss_dice: 0.3093  decode.d6.loss_cls: 0.0488  decode.d6.loss_mask: 0.2573  decode.d6.loss_dice: 0.3062  decode.d7.loss_cls: 0.1079  decode.d7.loss_mask: 0.2596  decode.d7.loss_dice: 0.3133  decode.d8.loss_cls: 0.0725  decode.d8.loss_mask: 0.2677  decode.d8.loss_dice: 0.3128
08/06 08:48:07 - mmengine - INFO - Iter(train) [ 47200/320000]  base_lr: 8.6622e-05 lr: 8.6622e-06  eta: 1 day, 13:18:56  time: 0.4943  data_time: 0.0115  memory: 5878  grad_norm: 155.3424  loss: 5.8765  decode.loss_cls: 0.0330  decode.loss_mask: 0.2367  decode.loss_dice: 0.2294  decode.d0.loss_cls: 0.7880  decode.d0.loss_mask: 0.2516  decode.d0.loss_dice: 0.2345  decode.d1.loss_cls: 0.0472  decode.d1.loss_mask: 0.2402  decode.d1.loss_dice: 0.2303  decode.d2.loss_cls: 0.0360  decode.d2.loss_mask: 0.2312  decode.d2.loss_dice: 0.2243  decode.d3.loss_cls: 0.0356  decode.d3.loss_mask: 0.2325  decode.d3.loss_dice: 0.2304  decode.d4.loss_cls: 0.0360  decode.d4.loss_mask: 0.2333  decode.d4.loss_dice: 0.2272  decode.d5.loss_cls: 0.0415  decode.d5.loss_mask: 0.2410  decode.d5.loss_dice: 0.2484  decode.d6.loss_cls: 0.0545  decode.d6.loss_mask: 0.2371  decode.d6.loss_dice: 0.2545  decode.d7.loss_cls: 0.0405  decode.d7.loss_mask: 0.2383  decode.d7.loss_dice: 0.2369  decode.d8.loss_cls: 0.0404  decode.d8.loss_mask: 0.2366  decode.d8.loss_dice: 0.2293
08/06 08:48:31 - mmengine - INFO - Iter(train) [ 47250/320000]  base_lr: 8.6607e-05 lr: 8.6607e-06  eta: 1 day, 13:18:31  time: 0.4936  data_time: 0.0110  memory: 5911  grad_norm: 139.8892  loss: 8.5788  decode.loss_cls: 0.1696  decode.loss_mask: 0.2762  decode.loss_dice: 0.3208  decode.d0.loss_cls: 1.1426  decode.d0.loss_mask: 0.2766  decode.d0.loss_dice: 0.3518  decode.d1.loss_cls: 0.1728  decode.d1.loss_mask: 0.2830  decode.d1.loss_dice: 0.2995  decode.d2.loss_cls: 0.1700  decode.d2.loss_mask: 0.2758  decode.d2.loss_dice: 0.3080  decode.d3.loss_cls: 0.1938  decode.d3.loss_mask: 0.2718  decode.d3.loss_dice: 0.3358  decode.d4.loss_cls: 0.1892  decode.d4.loss_mask: 0.2746  decode.d4.loss_dice: 0.3041  decode.d5.loss_cls: 0.1576  decode.d5.loss_mask: 0.2735  decode.d5.loss_dice: 0.2922  decode.d6.loss_cls: 0.1814  decode.d6.loss_mask: 0.2775  decode.d6.loss_dice: 0.2929  decode.d7.loss_cls: 0.1491  decode.d7.loss_mask: 0.2735  decode.d7.loss_dice: 0.3318  decode.d8.loss_cls: 0.1422  decode.d8.loss_mask: 0.2762  decode.d8.loss_dice: 0.3149
08/06 08:48:56 - mmengine - INFO - Iter(train) [ 47300/320000]  base_lr: 8.6593e-05 lr: 8.6593e-06  eta: 1 day, 13:18:07  time: 0.4933  data_time: 0.0110  memory: 5895  grad_norm: 71.4150  loss: 9.9242  decode.loss_cls: 0.1846  decode.loss_mask: 0.3742  decode.loss_dice: 0.3403  decode.d0.loss_cls: 0.9926  decode.d0.loss_mask: 0.3258  decode.d0.loss_dice: 0.3071  decode.d1.loss_cls: 0.2656  decode.d1.loss_mask: 0.3356  decode.d1.loss_dice: 0.3171  decode.d2.loss_cls: 0.2223  decode.d2.loss_mask: 0.3454  decode.d2.loss_dice: 0.3147  decode.d3.loss_cls: 0.2009  decode.d3.loss_mask: 0.3858  decode.d3.loss_dice: 0.3482  decode.d4.loss_cls: 0.2543  decode.d4.loss_mask: 0.3409  decode.d4.loss_dice: 0.3294  decode.d5.loss_cls: 0.2037  decode.d5.loss_mask: 0.3867  decode.d5.loss_dice: 0.3487  decode.d6.loss_cls: 0.2274  decode.d6.loss_mask: 0.3753  decode.d6.loss_dice: 0.3473  decode.d7.loss_cls: 0.2210  decode.d7.loss_mask: 0.3755  decode.d7.loss_dice: 0.3519  decode.d8.loss_cls: 0.1903  decode.d8.loss_mask: 0.3723  decode.d8.loss_dice: 0.3393
08/06 08:49:21 - mmengine - INFO - Iter(train) [ 47350/320000]  base_lr: 8.6579e-05 lr: 8.6579e-06  eta: 1 day, 13:17:43  time: 0.4939  data_time: 0.0110  memory: 5928  grad_norm: 122.4816  loss: 6.7381  decode.loss_cls: 0.0681  decode.loss_mask: 0.2301  decode.loss_dice: 0.2335  decode.d0.loss_cls: 0.8771  decode.d0.loss_mask: 0.2287  decode.d0.loss_dice: 0.2454  decode.d1.loss_cls: 0.2210  decode.d1.loss_mask: 0.2125  decode.d1.loss_dice: 0.2291  decode.d2.loss_cls: 0.1915  decode.d2.loss_mask: 0.2191  decode.d2.loss_dice: 0.2673  decode.d3.loss_cls: 0.1856  decode.d3.loss_mask: 0.2095  decode.d3.loss_dice: 0.2552  decode.d4.loss_cls: 0.1977  decode.d4.loss_mask: 0.2107  decode.d4.loss_dice: 0.2318  decode.d5.loss_cls: 0.1280  decode.d5.loss_mask: 0.2246  decode.d5.loss_dice: 0.2360  decode.d6.loss_cls: 0.1296  decode.d6.loss_mask: 0.2203  decode.d6.loss_dice: 0.2231  decode.d7.loss_cls: 0.0633  decode.d7.loss_mask: 0.2320  decode.d7.loss_dice: 0.2257  decode.d8.loss_cls: 0.0499  decode.d8.loss_mask: 0.2299  decode.d8.loss_dice: 0.2619
08/06 08:49:46 - mmengine - INFO - Iter(train) [ 47400/320000]  base_lr: 8.6564e-05 lr: 8.6564e-06  eta: 1 day, 13:17:20  time: 0.4936  data_time: 0.0111  memory: 5911  grad_norm: 441.3571  loss: 8.5267  decode.loss_cls: 0.2414  decode.loss_mask: 0.2589  decode.loss_dice: 0.3313  decode.d0.loss_cls: 1.0457  decode.d0.loss_mask: 0.2636  decode.d0.loss_dice: 0.2903  decode.d1.loss_cls: 0.1847  decode.d1.loss_mask: 0.2637  decode.d1.loss_dice: 0.3313  decode.d2.loss_cls: 0.1951  decode.d2.loss_mask: 0.2665  decode.d2.loss_dice: 0.3015  decode.d3.loss_cls: 0.2044  decode.d3.loss_mask: 0.2637  decode.d3.loss_dice: 0.3164  decode.d4.loss_cls: 0.2343  decode.d4.loss_mask: 0.2631  decode.d4.loss_dice: 0.3133  decode.d5.loss_cls: 0.1779  decode.d5.loss_mask: 0.2598  decode.d5.loss_dice: 0.3022  decode.d6.loss_cls: 0.1667  decode.d6.loss_mask: 0.2638  decode.d6.loss_dice: 0.3117  decode.d7.loss_cls: 0.1668  decode.d7.loss_mask: 0.2635  decode.d7.loss_dice: 0.3160  decode.d8.loss_cls: 0.1724  decode.d8.loss_mask: 0.2629  decode.d8.loss_dice: 0.2938
08/06 08:50:10 - mmengine - INFO - Iter(train) [ 47450/320000]  base_lr: 8.6550e-05 lr: 8.6550e-06  eta: 1 day, 13:16:56  time: 0.4934  data_time: 0.0112  memory: 5928  grad_norm: 127.4477  loss: 9.4337  decode.loss_cls: 0.1926  decode.loss_mask: 0.3426  decode.loss_dice: 0.3811  decode.d0.loss_cls: 0.8792  decode.d0.loss_mask: 0.3575  decode.d0.loss_dice: 0.3776  decode.d1.loss_cls: 0.1783  decode.d1.loss_mask: 0.3405  decode.d1.loss_dice: 0.3410  decode.d2.loss_cls: 0.1761  decode.d2.loss_mask: 0.3413  decode.d2.loss_dice: 0.3301  decode.d3.loss_cls: 0.2042  decode.d3.loss_mask: 0.3381  decode.d3.loss_dice: 0.3411  decode.d4.loss_cls: 0.1925  decode.d4.loss_mask: 0.3417  decode.d4.loss_dice: 0.3351  decode.d5.loss_cls: 0.2157  decode.d5.loss_mask: 0.3448  decode.d5.loss_dice: 0.3350  decode.d6.loss_cls: 0.1825  decode.d6.loss_mask: 0.3434  decode.d6.loss_dice: 0.3369  decode.d7.loss_cls: 0.1152  decode.d7.loss_mask: 0.3437  decode.d7.loss_dice: 0.3679  decode.d8.loss_cls: 0.1699  decode.d8.loss_mask: 0.3481  decode.d8.loss_dice: 0.3402
08/06 08:50:35 - mmengine - INFO - Iter(train) [ 47500/320000]  base_lr: 8.6536e-05 lr: 8.6536e-06  eta: 1 day, 13:16:32  time: 0.4945  data_time: 0.0113  memory: 5895  grad_norm: 112.4858  loss: 7.1130  decode.loss_cls: 0.1355  decode.loss_mask: 0.2283  decode.loss_dice: 0.2830  decode.d0.loss_cls: 0.8256  decode.d0.loss_mask: 0.2351  decode.d0.loss_dice: 0.2763  decode.d1.loss_cls: 0.1678  decode.d1.loss_mask: 0.2316  decode.d1.loss_dice: 0.2599  decode.d2.loss_cls: 0.2051  decode.d2.loss_mask: 0.2292  decode.d2.loss_dice: 0.2685  decode.d3.loss_cls: 0.1369  decode.d3.loss_mask: 0.2285  decode.d3.loss_dice: 0.2605  decode.d4.loss_cls: 0.1322  decode.d4.loss_mask: 0.2301  decode.d4.loss_dice: 0.2673  decode.d5.loss_cls: 0.1251  decode.d5.loss_mask: 0.2277  decode.d5.loss_dice: 0.2671  decode.d6.loss_cls: 0.1355  decode.d6.loss_mask: 0.2281  decode.d6.loss_dice: 0.2709  decode.d7.loss_cls: 0.1336  decode.d7.loss_mask: 0.2289  decode.d7.loss_dice: 0.2708  decode.d8.loss_cls: 0.1245  decode.d8.loss_mask: 0.2323  decode.d8.loss_dice: 0.2668
08/06 08:51:00 - mmengine - INFO - Iter(train) [ 47550/320000]  base_lr: 8.6522e-05 lr: 8.6522e-06  eta: 1 day, 13:16:08  time: 0.4932  data_time: 0.0112  memory: 5894  grad_norm: 98.7596  loss: 7.7441  decode.loss_cls: 0.1091  decode.loss_mask: 0.2992  decode.loss_dice: 0.2867  decode.d0.loss_cls: 0.8712  decode.d0.loss_mask: 0.3027  decode.d0.loss_dice: 0.3243  decode.d1.loss_cls: 0.1425  decode.d1.loss_mask: 0.3031  decode.d1.loss_dice: 0.2876  decode.d2.loss_cls: 0.0870  decode.d2.loss_mask: 0.2954  decode.d2.loss_dice: 0.2959  decode.d3.loss_cls: 0.1317  decode.d3.loss_mask: 0.2968  decode.d3.loss_dice: 0.3051  decode.d4.loss_cls: 0.0797  decode.d4.loss_mask: 0.3026  decode.d4.loss_dice: 0.2872  decode.d5.loss_cls: 0.1048  decode.d5.loss_mask: 0.2987  decode.d5.loss_dice: 0.2886  decode.d6.loss_cls: 0.1009  decode.d6.loss_mask: 0.2988  decode.d6.loss_dice: 0.2824  decode.d7.loss_cls: 0.0733  decode.d7.loss_mask: 0.3000  decode.d7.loss_dice: 0.2852  decode.d8.loss_cls: 0.1092  decode.d8.loss_mask: 0.3011  decode.d8.loss_dice: 0.2931
08/06 08:51:25 - mmengine - INFO - Iter(train) [ 47600/320000]  base_lr: 8.6507e-05 lr: 8.6507e-06  eta: 1 day, 13:15:44  time: 0.4948  data_time: 0.0112  memory: 5874  grad_norm: 182.2367  loss: 7.2768  decode.loss_cls: 0.2604  decode.loss_mask: 0.1900  decode.loss_dice: 0.2077  decode.d0.loss_cls: 0.9316  decode.d0.loss_mask: 0.2068  decode.d0.loss_dice: 0.2247  decode.d1.loss_cls: 0.2386  decode.d1.loss_mask: 0.1996  decode.d1.loss_dice: 0.2140  decode.d2.loss_cls: 0.2740  decode.d2.loss_mask: 0.1912  decode.d2.loss_dice: 0.2053  decode.d3.loss_cls: 0.2866  decode.d3.loss_mask: 0.1860  decode.d3.loss_dice: 0.2114  decode.d4.loss_cls: 0.2370  decode.d4.loss_mask: 0.1888  decode.d4.loss_dice: 0.2091  decode.d5.loss_cls: 0.2537  decode.d5.loss_mask: 0.1885  decode.d5.loss_dice: 0.2101  decode.d6.loss_cls: 0.2288  decode.d6.loss_mask: 0.1912  decode.d6.loss_dice: 0.2121  decode.d7.loss_cls: 0.2395  decode.d7.loss_mask: 0.1912  decode.d7.loss_dice: 0.2123  decode.d8.loss_cls: 0.2787  decode.d8.loss_mask: 0.1914  decode.d8.loss_dice: 0.2165
08/06 08:51:49 - mmengine - INFO - Iter(train) [ 47650/320000]  base_lr: 8.6493e-05 lr: 8.6493e-06  eta: 1 day, 13:15:20  time: 0.4939  data_time: 0.0114  memory: 5894  grad_norm: 131.8685  loss: 7.3460  decode.loss_cls: 0.2228  decode.loss_mask: 0.2352  decode.loss_dice: 0.2337  decode.d0.loss_cls: 0.8778  decode.d0.loss_mask: 0.2411  decode.d0.loss_dice: 0.2442  decode.d1.loss_cls: 0.1658  decode.d1.loss_mask: 0.2364  decode.d1.loss_dice: 0.2425  decode.d2.loss_cls: 0.2008  decode.d2.loss_mask: 0.2351  decode.d2.loss_dice: 0.2204  decode.d3.loss_cls: 0.2095  decode.d3.loss_mask: 0.2350  decode.d3.loss_dice: 0.2102  decode.d4.loss_cls: 0.1707  decode.d4.loss_mask: 0.2393  decode.d4.loss_dice: 0.2427  decode.d5.loss_cls: 0.2039  decode.d5.loss_mask: 0.2341  decode.d5.loss_dice: 0.2322  decode.d6.loss_cls: 0.2226  decode.d6.loss_mask: 0.2367  decode.d6.loss_dice: 0.2106  decode.d7.loss_cls: 0.2264  decode.d7.loss_mask: 0.2356  decode.d7.loss_dice: 0.2194  decode.d8.loss_cls: 0.2080  decode.d8.loss_mask: 0.2359  decode.d8.loss_dice: 0.2175
08/06 08:52:14 - mmengine - INFO - Iter(train) [ 47700/320000]  base_lr: 8.6479e-05 lr: 8.6479e-06  eta: 1 day, 13:14:56  time: 0.4949  data_time: 0.0112  memory: 5874  grad_norm: 102.3653  loss: 8.3307  decode.loss_cls: 0.3083  decode.loss_mask: 0.1889  decode.loss_dice: 0.2653  decode.d0.loss_cls: 0.8741  decode.d0.loss_mask: 0.1908  decode.d0.loss_dice: 0.3037  decode.d1.loss_cls: 0.2969  decode.d1.loss_mask: 0.1940  decode.d1.loss_dice: 0.2626  decode.d2.loss_cls: 0.3422  decode.d2.loss_mask: 0.1865  decode.d2.loss_dice: 0.2828  decode.d3.loss_cls: 0.3046  decode.d3.loss_mask: 0.1871  decode.d3.loss_dice: 0.2765  decode.d4.loss_cls: 0.3451  decode.d4.loss_mask: 0.1844  decode.d4.loss_dice: 0.2774  decode.d5.loss_cls: 0.3047  decode.d5.loss_mask: 0.1863  decode.d5.loss_dice: 0.2576  decode.d6.loss_cls: 0.3252  decode.d6.loss_mask: 0.1891  decode.d6.loss_dice: 0.2730  decode.d7.loss_cls: 0.3131  decode.d7.loss_mask: 0.1885  decode.d7.loss_dice: 0.2808  decode.d8.loss_cls: 0.2890  decode.d8.loss_mask: 0.1866  decode.d8.loss_dice: 0.2659
08/06 08:52:39 - mmengine - INFO - Iter(train) [ 47750/320000]  base_lr: 8.6464e-05 lr: 8.6464e-06  eta: 1 day, 13:14:31  time: 0.4945  data_time: 0.0113  memory: 5911  grad_norm: 148.1004  loss: 6.0292  decode.loss_cls: 0.0830  decode.loss_mask: 0.2290  decode.loss_dice: 0.2262  decode.d0.loss_cls: 0.7379  decode.d0.loss_mask: 0.2336  decode.d0.loss_dice: 0.2330  decode.d1.loss_cls: 0.0359  decode.d1.loss_mask: 0.2344  decode.d1.loss_dice: 0.2455  decode.d2.loss_cls: 0.0313  decode.d2.loss_mask: 0.2319  decode.d2.loss_dice: 0.2506  decode.d3.loss_cls: 0.0922  decode.d3.loss_mask: 0.2318  decode.d3.loss_dice: 0.2278  decode.d4.loss_cls: 0.0770  decode.d4.loss_mask: 0.2310  decode.d4.loss_dice: 0.2326  decode.d5.loss_cls: 0.0277  decode.d5.loss_mask: 0.2346  decode.d5.loss_dice: 0.2419  decode.d6.loss_cls: 0.1026  decode.d6.loss_mask: 0.2309  decode.d6.loss_dice: 0.2308  decode.d7.loss_cls: 0.0834  decode.d7.loss_mask: 0.2289  decode.d7.loss_dice: 0.2289  decode.d8.loss_cls: 0.0863  decode.d8.loss_mask: 0.2333  decode.d8.loss_dice: 0.2352
08/06 08:53:04 - mmengine - INFO - Iter(train) [ 47800/320000]  base_lr: 8.6450e-05 lr: 8.6450e-06  eta: 1 day, 13:14:07  time: 0.4952  data_time: 0.0114  memory: 5894  grad_norm: 72.3447  loss: 8.0638  decode.loss_cls: 0.1513  decode.loss_mask: 0.2266  decode.loss_dice: 0.3575  decode.d0.loss_cls: 0.9911  decode.d0.loss_mask: 0.2207  decode.d0.loss_dice: 0.3190  decode.d1.loss_cls: 0.1668  decode.d1.loss_mask: 0.2259  decode.d1.loss_dice: 0.3316  decode.d2.loss_cls: 0.1523  decode.d2.loss_mask: 0.2229  decode.d2.loss_dice: 0.3331  decode.d3.loss_cls: 0.1795  decode.d3.loss_mask: 0.2311  decode.d3.loss_dice: 0.3620  decode.d4.loss_cls: 0.1617  decode.d4.loss_mask: 0.2297  decode.d4.loss_dice: 0.3447  decode.d5.loss_cls: 0.1804  decode.d5.loss_mask: 0.2244  decode.d5.loss_dice: 0.3330  decode.d6.loss_cls: 0.1528  decode.d6.loss_mask: 0.2229  decode.d6.loss_dice: 0.3237  decode.d7.loss_cls: 0.1804  decode.d7.loss_mask: 0.2219  decode.d7.loss_dice: 0.3166  decode.d8.loss_cls: 0.1562  decode.d8.loss_mask: 0.2230  decode.d8.loss_dice: 0.3211
08/06 08:53:28 - mmengine - INFO - Iter(train) [ 47850/320000]  base_lr: 8.6436e-05 lr: 8.6436e-06  eta: 1 day, 13:13:43  time: 0.4951  data_time: 0.0111  memory: 5911  grad_norm: 69.8777  loss: 7.0617  decode.loss_cls: 0.1562  decode.loss_mask: 0.2416  decode.loss_dice: 0.2476  decode.d0.loss_cls: 0.8105  decode.d0.loss_mask: 0.2444  decode.d0.loss_dice: 0.2854  decode.d1.loss_cls: 0.1833  decode.d1.loss_mask: 0.2405  decode.d1.loss_dice: 0.2793  decode.d2.loss_cls: 0.1463  decode.d2.loss_mask: 0.2417  decode.d2.loss_dice: 0.2631  decode.d3.loss_cls: 0.1232  decode.d3.loss_mask: 0.2410  decode.d3.loss_dice: 0.2582  decode.d4.loss_cls: 0.1727  decode.d4.loss_mask: 0.2395  decode.d4.loss_dice: 0.2612  decode.d5.loss_cls: 0.1340  decode.d5.loss_mask: 0.2435  decode.d5.loss_dice: 0.2753  decode.d6.loss_cls: 0.0816  decode.d6.loss_mask: 0.2386  decode.d6.loss_dice: 0.2626  decode.d7.loss_cls: 0.0924  decode.d7.loss_mask: 0.2385  decode.d7.loss_dice: 0.2665  decode.d8.loss_cls: 0.0942  decode.d8.loss_mask: 0.2371  decode.d8.loss_dice: 0.2616
08/06 08:53:53 - mmengine - INFO - Iter(train) [ 47900/320000]  base_lr: 8.6422e-05 lr: 8.6422e-06  eta: 1 day, 13:13:19  time: 0.4945  data_time: 0.0112  memory: 5911  grad_norm: 147.8210  loss: 8.1551  decode.loss_cls: 0.2091  decode.loss_mask: 0.2383  decode.loss_dice: 0.2825  decode.d0.loss_cls: 0.9015  decode.d0.loss_mask: 0.2456  decode.d0.loss_dice: 0.3169  decode.d1.loss_cls: 0.2538  decode.d1.loss_mask: 0.2401  decode.d1.loss_dice: 0.2766  decode.d2.loss_cls: 0.2156  decode.d2.loss_mask: 0.2392  decode.d2.loss_dice: 0.3137  decode.d3.loss_cls: 0.1989  decode.d3.loss_mask: 0.2382  decode.d3.loss_dice: 0.2947  decode.d4.loss_cls: 0.2451  decode.d4.loss_mask: 0.2382  decode.d4.loss_dice: 0.2995  decode.d5.loss_cls: 0.1949  decode.d5.loss_mask: 0.2429  decode.d5.loss_dice: 0.2809  decode.d6.loss_cls: 0.2267  decode.d6.loss_mask: 0.2387  decode.d6.loss_dice: 0.2792  decode.d7.loss_cls: 0.2378  decode.d7.loss_mask: 0.2387  decode.d7.loss_dice: 0.2622  decode.d8.loss_cls: 0.1995  decode.d8.loss_mask: 0.2388  decode.d8.loss_dice: 0.2673
08/06 08:54:18 - mmengine - INFO - Iter(train) [ 47950/320000]  base_lr: 8.6407e-05 lr: 8.6407e-06  eta: 1 day, 13:12:55  time: 0.4953  data_time: 0.0113  memory: 5894  grad_norm: 106.2573  loss: 8.7213  decode.loss_cls: 0.1475  decode.loss_mask: 0.3131  decode.loss_dice: 0.3397  decode.d0.loss_cls: 0.9813  decode.d0.loss_mask: 0.2772  decode.d0.loss_dice: 0.3172  decode.d1.loss_cls: 0.1677  decode.d1.loss_mask: 0.2997  decode.d1.loss_dice: 0.3422  decode.d2.loss_cls: 0.1676  decode.d2.loss_mask: 0.2990  decode.d2.loss_dice: 0.3321  decode.d3.loss_cls: 0.1709  decode.d3.loss_mask: 0.3059  decode.d3.loss_dice: 0.3218  decode.d4.loss_cls: 0.1622  decode.d4.loss_mask: 0.2967  decode.d4.loss_dice: 0.3436  decode.d5.loss_cls: 0.1529  decode.d5.loss_mask: 0.3051  decode.d5.loss_dice: 0.3320  decode.d6.loss_cls: 0.1587  decode.d6.loss_mask: 0.2982  decode.d6.loss_dice: 0.3263  decode.d7.loss_cls: 0.1606  decode.d7.loss_mask: 0.3042  decode.d7.loss_dice: 0.3183  decode.d8.loss_cls: 0.1537  decode.d8.loss_mask: 0.3122  decode.d8.loss_dice: 0.3136
08/06 08:54:43 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 08:54:43 - mmengine - INFO - Iter(train) [ 48000/320000]  base_lr: 8.6393e-05 lr: 8.6393e-06  eta: 1 day, 13:12:32  time: 0.4946  data_time: 0.0111  memory: 5911  grad_norm: 143.6599  loss: 9.0270  decode.loss_cls: 0.2707  decode.loss_mask: 0.3036  decode.loss_dice: 0.2707  decode.d0.loss_cls: 1.0073  decode.d0.loss_mask: 0.3124  decode.d0.loss_dice: 0.2801  decode.d1.loss_cls: 0.2923  decode.d1.loss_mask: 0.3106  decode.d1.loss_dice: 0.2727  decode.d2.loss_cls: 0.2207  decode.d2.loss_mask: 0.3462  decode.d2.loss_dice: 0.2994  decode.d3.loss_cls: 0.2306  decode.d3.loss_mask: 0.3307  decode.d3.loss_dice: 0.2981  decode.d4.loss_cls: 0.2176  decode.d4.loss_mask: 0.3029  decode.d4.loss_dice: 0.2672  decode.d5.loss_cls: 0.2058  decode.d5.loss_mask: 0.3069  decode.d5.loss_dice: 0.2673  decode.d6.loss_cls: 0.2120  decode.d6.loss_mask: 0.3068  decode.d6.loss_dice: 0.2672  decode.d7.loss_cls: 0.2322  decode.d7.loss_mask: 0.3042  decode.d7.loss_dice: 0.2686  decode.d8.loss_cls: 0.2408  decode.d8.loss_mask: 0.3095  decode.d8.loss_dice: 0.2719
08/06 08:55:07 - mmengine - INFO - Iter(train) [ 48050/320000]  base_lr: 8.6379e-05 lr: 8.6379e-06  eta: 1 day, 13:12:08  time: 0.4935  data_time: 0.0110  memory: 5909  grad_norm: 123.2397  loss: 8.0072  decode.loss_cls: 0.1703  decode.loss_mask: 0.2373  decode.loss_dice: 0.2992  decode.d0.loss_cls: 0.9293  decode.d0.loss_mask: 0.2453  decode.d0.loss_dice: 0.2995  decode.d1.loss_cls: 0.2775  decode.d1.loss_mask: 0.2379  decode.d1.loss_dice: 0.2731  decode.d2.loss_cls: 0.2206  decode.d2.loss_mask: 0.2421  decode.d2.loss_dice: 0.2912  decode.d3.loss_cls: 0.1858  decode.d3.loss_mask: 0.2403  decode.d3.loss_dice: 0.2984  decode.d4.loss_cls: 0.1693  decode.d4.loss_mask: 0.2403  decode.d4.loss_dice: 0.2878  decode.d5.loss_cls: 0.1774  decode.d5.loss_mask: 0.2399  decode.d5.loss_dice: 0.2963  decode.d6.loss_cls: 0.1826  decode.d6.loss_mask: 0.2374  decode.d6.loss_dice: 0.2919  decode.d7.loss_cls: 0.1942  decode.d7.loss_mask: 0.2380  decode.d7.loss_dice: 0.2956  decode.d8.loss_cls: 0.1660  decode.d8.loss_mask: 0.2386  decode.d8.loss_dice: 0.3041
08/06 08:55:32 - mmengine - INFO - Iter(train) [ 48100/320000]  base_lr: 8.6364e-05 lr: 8.6364e-06  eta: 1 day, 13:11:44  time: 0.4939  data_time: 0.0112  memory: 5928  grad_norm: 58.1420  loss: 6.8942  decode.loss_cls: 0.0961  decode.loss_mask: 0.2212  decode.loss_dice: 0.2580  decode.d0.loss_cls: 0.8980  decode.d0.loss_mask: 0.2257  decode.d0.loss_dice: 0.2553  decode.d1.loss_cls: 0.2214  decode.d1.loss_mask: 0.2277  decode.d1.loss_dice: 0.2762  decode.d2.loss_cls: 0.1228  decode.d2.loss_mask: 0.2211  decode.d2.loss_dice: 0.2601  decode.d3.loss_cls: 0.1433  decode.d3.loss_mask: 0.2185  decode.d3.loss_dice: 0.2643  decode.d4.loss_cls: 0.1198  decode.d4.loss_mask: 0.2198  decode.d4.loss_dice: 0.2800  decode.d5.loss_cls: 0.1132  decode.d5.loss_mask: 0.2211  decode.d5.loss_dice: 0.2599  decode.d6.loss_cls: 0.1203  decode.d6.loss_mask: 0.2201  decode.d6.loss_dice: 0.2574  decode.d7.loss_cls: 0.1141  decode.d7.loss_mask: 0.2244  decode.d7.loss_dice: 0.2546  decode.d8.loss_cls: 0.0983  decode.d8.loss_mask: 0.2226  decode.d8.loss_dice: 0.2589
08/06 08:55:57 - mmengine - INFO - Iter(train) [ 48150/320000]  base_lr: 8.6350e-05 lr: 8.6350e-06  eta: 1 day, 13:11:20  time: 0.4943  data_time: 0.0113  memory: 5931  grad_norm: 101.2881  loss: 7.9880  decode.loss_cls: 0.1269  decode.loss_mask: 0.2497  decode.loss_dice: 0.2960  decode.d0.loss_cls: 1.0661  decode.d0.loss_mask: 0.2444  decode.d0.loss_dice: 0.3273  decode.d1.loss_cls: 0.1889  decode.d1.loss_mask: 0.2565  decode.d1.loss_dice: 0.3040  decode.d2.loss_cls: 0.1529  decode.d2.loss_mask: 0.2481  decode.d2.loss_dice: 0.3245  decode.d3.loss_cls: 0.1264  decode.d3.loss_mask: 0.2534  decode.d3.loss_dice: 0.3279  decode.d4.loss_cls: 0.1145  decode.d4.loss_mask: 0.2595  decode.d4.loss_dice: 0.3136  decode.d5.loss_cls: 0.1274  decode.d5.loss_mask: 0.2629  decode.d5.loss_dice: 0.3003  decode.d6.loss_cls: 0.1668  decode.d6.loss_mask: 0.2513  decode.d6.loss_dice: 0.2986  decode.d7.loss_cls: 0.1237  decode.d7.loss_mask: 0.2551  decode.d7.loss_dice: 0.3309  decode.d8.loss_cls: 0.1451  decode.d8.loss_mask: 0.2557  decode.d8.loss_dice: 0.2894
08/06 08:56:21 - mmengine - INFO - Iter(train) [ 48200/320000]  base_lr: 8.6336e-05 lr: 8.6336e-06  eta: 1 day, 13:10:55  time: 0.4949  data_time: 0.0113  memory: 5913  grad_norm: 108.9924  loss: 6.1426  decode.loss_cls: 0.0700  decode.loss_mask: 0.2174  decode.loss_dice: 0.2337  decode.d0.loss_cls: 0.7303  decode.d0.loss_mask: 0.2206  decode.d0.loss_dice: 0.2456  decode.d1.loss_cls: 0.0444  decode.d1.loss_mask: 0.2210  decode.d1.loss_dice: 0.2505  decode.d2.loss_cls: 0.1086  decode.d2.loss_mask: 0.2191  decode.d2.loss_dice: 0.2412  decode.d3.loss_cls: 0.0793  decode.d3.loss_mask: 0.2207  decode.d3.loss_dice: 0.2493  decode.d4.loss_cls: 0.0905  decode.d4.loss_mask: 0.2349  decode.d4.loss_dice: 0.2854  decode.d5.loss_cls: 0.0826  decode.d5.loss_mask: 0.2309  decode.d5.loss_dice: 0.2571  decode.d6.loss_cls: 0.0688  decode.d6.loss_mask: 0.2193  decode.d6.loss_dice: 0.2402  decode.d7.loss_cls: 0.0664  decode.d7.loss_mask: 0.2181  decode.d7.loss_dice: 0.2587  decode.d8.loss_cls: 0.0610  decode.d8.loss_mask: 0.2187  decode.d8.loss_dice: 0.2580
08/06 08:56:46 - mmengine - INFO - Iter(train) [ 48250/320000]  base_lr: 8.6321e-05 lr: 8.6321e-06  eta: 1 day, 13:10:31  time: 0.4940  data_time: 0.0111  memory: 5911  grad_norm: 132.6103  loss: 6.2585  decode.loss_cls: 0.1319  decode.loss_mask: 0.1895  decode.loss_dice: 0.2008  decode.d0.loss_cls: 0.9843  decode.d0.loss_mask: 0.1958  decode.d0.loss_dice: 0.2194  decode.d1.loss_cls: 0.1863  decode.d1.loss_mask: 0.1908  decode.d1.loss_dice: 0.1956  decode.d2.loss_cls: 0.1943  decode.d2.loss_mask: 0.1890  decode.d2.loss_dice: 0.1991  decode.d3.loss_cls: 0.0978  decode.d3.loss_mask: 0.1914  decode.d3.loss_dice: 0.2034  decode.d4.loss_cls: 0.1637  decode.d4.loss_mask: 0.1894  decode.d4.loss_dice: 0.2006  decode.d5.loss_cls: 0.1437  decode.d5.loss_mask: 0.1893  decode.d5.loss_dice: 0.2030  decode.d6.loss_cls: 0.1467  decode.d6.loss_mask: 0.1905  decode.d6.loss_dice: 0.2011  decode.d7.loss_cls: 0.1342  decode.d7.loss_mask: 0.1880  decode.d7.loss_dice: 0.2012  decode.d8.loss_cls: 0.1407  decode.d8.loss_mask: 0.1918  decode.d8.loss_dice: 0.2049
08/06 08:57:11 - mmengine - INFO - Iter(train) [ 48300/320000]  base_lr: 8.6307e-05 lr: 8.6307e-06  eta: 1 day, 13:10:07  time: 0.4946  data_time: 0.0112  memory: 5928  grad_norm: 124.3473  loss: 7.6714  decode.loss_cls: 0.1246  decode.loss_mask: 0.2291  decode.loss_dice: 0.2773  decode.d0.loss_cls: 1.0278  decode.d0.loss_mask: 0.2396  decode.d0.loss_dice: 0.3102  decode.d1.loss_cls: 0.3377  decode.d1.loss_mask: 0.2335  decode.d1.loss_dice: 0.3134  decode.d2.loss_cls: 0.2862  decode.d2.loss_mask: 0.2232  decode.d2.loss_dice: 0.2751  decode.d3.loss_cls: 0.1483  decode.d3.loss_mask: 0.2303  decode.d3.loss_dice: 0.2818  decode.d4.loss_cls: 0.1459  decode.d4.loss_mask: 0.2310  decode.d4.loss_dice: 0.2698  decode.d5.loss_cls: 0.1290  decode.d5.loss_mask: 0.2290  decode.d5.loss_dice: 0.2708  decode.d6.loss_cls: 0.1021  decode.d6.loss_mask: 0.2291  decode.d6.loss_dice: 0.2863  decode.d7.loss_cls: 0.0938  decode.d7.loss_mask: 0.2265  decode.d7.loss_dice: 0.2753  decode.d8.loss_cls: 0.1336  decode.d8.loss_mask: 0.2299  decode.d8.loss_dice: 0.2811
08/06 08:57:36 - mmengine - INFO - Iter(train) [ 48350/320000]  base_lr: 8.6293e-05 lr: 8.6293e-06  eta: 1 day, 13:09:43  time: 0.4945  data_time: 0.0111  memory: 5894  grad_norm: 55.9767  loss: 6.3038  decode.loss_cls: 0.1176  decode.loss_mask: 0.1884  decode.loss_dice: 0.2405  decode.d0.loss_cls: 0.8401  decode.d0.loss_mask: 0.1952  decode.d0.loss_dice: 0.2390  decode.d1.loss_cls: 0.2497  decode.d1.loss_mask: 0.1858  decode.d1.loss_dice: 0.2432  decode.d2.loss_cls: 0.1778  decode.d2.loss_mask: 0.1872  decode.d2.loss_dice: 0.2376  decode.d3.loss_cls: 0.1285  decode.d3.loss_mask: 0.1861  decode.d3.loss_dice: 0.2441  decode.d4.loss_cls: 0.0882  decode.d4.loss_mask: 0.1872  decode.d4.loss_dice: 0.2369  decode.d5.loss_cls: 0.1087  decode.d5.loss_mask: 0.1883  decode.d5.loss_dice: 0.2370  decode.d6.loss_cls: 0.0941  decode.d6.loss_mask: 0.1889  decode.d6.loss_dice: 0.2345  decode.d7.loss_cls: 0.1228  decode.d7.loss_mask: 0.1881  decode.d7.loss_dice: 0.2488  decode.d8.loss_cls: 0.1040  decode.d8.loss_mask: 0.1873  decode.d8.loss_dice: 0.2285
08/06 08:58:00 - mmengine - INFO - Iter(train) [ 48400/320000]  base_lr: 8.6279e-05 lr: 8.6279e-06  eta: 1 day, 13:09:19  time: 0.4939  data_time: 0.0111  memory: 5911  grad_norm: 95.7634  loss: 5.8904  decode.loss_cls: 0.0645  decode.loss_mask: 0.2170  decode.loss_dice: 0.2207  decode.d0.loss_cls: 0.8090  decode.d0.loss_mask: 0.2201  decode.d0.loss_dice: 0.2353  decode.d1.loss_cls: 0.0585  decode.d1.loss_mask: 0.2165  decode.d1.loss_dice: 0.2257  decode.d2.loss_cls: 0.0834  decode.d2.loss_mask: 0.2128  decode.d2.loss_dice: 0.2309  decode.d3.loss_cls: 0.0705  decode.d3.loss_mask: 0.2157  decode.d3.loss_dice: 0.2296  decode.d4.loss_cls: 0.1012  decode.d4.loss_mask: 0.2166  decode.d4.loss_dice: 0.2335  decode.d5.loss_cls: 0.0565  decode.d5.loss_mask: 0.2174  decode.d5.loss_dice: 0.2337  decode.d6.loss_cls: 0.0519  decode.d6.loss_mask: 0.2170  decode.d6.loss_dice: 0.2282  decode.d7.loss_cls: 0.0812  decode.d7.loss_mask: 0.2165  decode.d7.loss_dice: 0.2253  decode.d8.loss_cls: 0.0545  decode.d8.loss_mask: 0.2152  decode.d8.loss_dice: 0.2314
08/06 08:58:25 - mmengine - INFO - Iter(train) [ 48450/320000]  base_lr: 8.6264e-05 lr: 8.6264e-06  eta: 1 day, 13:08:54  time: 0.4938  data_time: 0.0112  memory: 5859  grad_norm: 91.3331  loss: 7.3120  decode.loss_cls: 0.1349  decode.loss_mask: 0.2351  decode.loss_dice: 0.2530  decode.d0.loss_cls: 0.9923  decode.d0.loss_mask: 0.2442  decode.d0.loss_dice: 0.2671  decode.d1.loss_cls: 0.1857  decode.d1.loss_mask: 0.2419  decode.d1.loss_dice: 0.2663  decode.d2.loss_cls: 0.1859  decode.d2.loss_mask: 0.2356  decode.d2.loss_dice: 0.2620  decode.d3.loss_cls: 0.1473  decode.d3.loss_mask: 0.2375  decode.d3.loss_dice: 0.2515  decode.d4.loss_cls: 0.1341  decode.d4.loss_mask: 0.2355  decode.d4.loss_dice: 0.2482  decode.d5.loss_cls: 0.1521  decode.d5.loss_mask: 0.2355  decode.d5.loss_dice: 0.2541  decode.d6.loss_cls: 0.1783  decode.d6.loss_mask: 0.2342  decode.d6.loss_dice: 0.2538  decode.d7.loss_cls: 0.1399  decode.d7.loss_mask: 0.2378  decode.d7.loss_dice: 0.2485  decode.d8.loss_cls: 0.1380  decode.d8.loss_mask: 0.2369  decode.d8.loss_dice: 0.2450
08/06 08:58:50 - mmengine - INFO - Iter(train) [ 48500/320000]  base_lr: 8.6250e-05 lr: 8.6250e-06  eta: 1 day, 13:08:31  time: 0.4943  data_time: 0.0115  memory: 5895  grad_norm: 137.7405  loss: 6.4610  decode.loss_cls: 0.1080  decode.loss_mask: 0.2520  decode.loss_dice: 0.2442  decode.d0.loss_cls: 0.7917  decode.d0.loss_mask: 0.2631  decode.d0.loss_dice: 0.2427  decode.d1.loss_cls: 0.0668  decode.d1.loss_mask: 0.2474  decode.d1.loss_dice: 0.2552  decode.d2.loss_cls: 0.0483  decode.d2.loss_mask: 0.2490  decode.d2.loss_dice: 0.2399  decode.d3.loss_cls: 0.0961  decode.d3.loss_mask: 0.2517  decode.d3.loss_dice: 0.2434  decode.d4.loss_cls: 0.0817  decode.d4.loss_mask: 0.2528  decode.d4.loss_dice: 0.2415  decode.d5.loss_cls: 0.0825  decode.d5.loss_mask: 0.2514  decode.d5.loss_dice: 0.2545  decode.d6.loss_cls: 0.0825  decode.d6.loss_mask: 0.2543  decode.d6.loss_dice: 0.2411  decode.d7.loss_cls: 0.0607  decode.d7.loss_mask: 0.2519  decode.d7.loss_dice: 0.2387  decode.d8.loss_cls: 0.0765  decode.d8.loss_mask: 0.2505  decode.d8.loss_dice: 0.2410
08/06 08:59:15 - mmengine - INFO - Iter(train) [ 48550/320000]  base_lr: 8.6236e-05 lr: 8.6236e-06  eta: 1 day, 13:08:07  time: 0.4938  data_time: 0.0111  memory: 5909  grad_norm: 222.5043  loss: 6.7065  decode.loss_cls: 0.0499  decode.loss_mask: 0.2823  decode.loss_dice: 0.2716  decode.d0.loss_cls: 0.8414  decode.d0.loss_mask: 0.2804  decode.d0.loss_dice: 0.2539  decode.d1.loss_cls: 0.0357  decode.d1.loss_mask: 0.2822  decode.d1.loss_dice: 0.2663  decode.d2.loss_cls: 0.0391  decode.d2.loss_mask: 0.2847  decode.d2.loss_dice: 0.2743  decode.d3.loss_cls: 0.0457  decode.d3.loss_mask: 0.2828  decode.d3.loss_dice: 0.2663  decode.d4.loss_cls: 0.0481  decode.d4.loss_mask: 0.2829  decode.d4.loss_dice: 0.2653  decode.d5.loss_cls: 0.0497  decode.d5.loss_mask: 0.2785  decode.d5.loss_dice: 0.2620  decode.d6.loss_cls: 0.0410  decode.d6.loss_mask: 0.2782  decode.d6.loss_dice: 0.2637  decode.d7.loss_cls: 0.0466  decode.d7.loss_mask: 0.2818  decode.d7.loss_dice: 0.2668  decode.d8.loss_cls: 0.0380  decode.d8.loss_mask: 0.2832  decode.d8.loss_dice: 0.2640
08/06 08:59:39 - mmengine - INFO - Iter(train) [ 48600/320000]  base_lr: 8.6221e-05 lr: 8.6221e-06  eta: 1 day, 13:07:43  time: 0.4944  data_time: 0.0112  memory: 5894  grad_norm: 112.9084  loss: 8.3800  decode.loss_cls: 0.1691  decode.loss_mask: 0.2342  decode.loss_dice: 0.3455  decode.d0.loss_cls: 0.9735  decode.d0.loss_mask: 0.2400  decode.d0.loss_dice: 0.3361  decode.d1.loss_cls: 0.2520  decode.d1.loss_mask: 0.2393  decode.d1.loss_dice: 0.3381  decode.d2.loss_cls: 0.1629  decode.d2.loss_mask: 0.2382  decode.d2.loss_dice: 0.3590  decode.d3.loss_cls: 0.1662  decode.d3.loss_mask: 0.2358  decode.d3.loss_dice: 0.3577  decode.d4.loss_cls: 0.1278  decode.d4.loss_mask: 0.2358  decode.d4.loss_dice: 0.3464  decode.d5.loss_cls: 0.1992  decode.d5.loss_mask: 0.2360  decode.d5.loss_dice: 0.3457  decode.d6.loss_cls: 0.1855  decode.d6.loss_mask: 0.2355  decode.d6.loss_dice: 0.3357  decode.d7.loss_cls: 0.1699  decode.d7.loss_mask: 0.2371  decode.d7.loss_dice: 0.3464  decode.d8.loss_cls: 0.1573  decode.d8.loss_mask: 0.2373  decode.d8.loss_dice: 0.3370
08/06 09:00:04 - mmengine - INFO - Iter(train) [ 48650/320000]  base_lr: 8.6207e-05 lr: 8.6207e-06  eta: 1 day, 13:07:18  time: 0.4948  data_time: 0.0113  memory: 5891  grad_norm: 257.1022  loss: 9.4938  decode.loss_cls: 0.2481  decode.loss_mask: 0.2775  decode.loss_dice: 0.3164  decode.d0.loss_cls: 1.0757  decode.d0.loss_mask: 0.2789  decode.d0.loss_dice: 0.3101  decode.d1.loss_cls: 0.3285  decode.d1.loss_mask: 0.2786  decode.d1.loss_dice: 0.2932  decode.d2.loss_cls: 0.3347  decode.d2.loss_mask: 0.2704  decode.d2.loss_dice: 0.2881  decode.d3.loss_cls: 0.3189  decode.d3.loss_mask: 0.2688  decode.d3.loss_dice: 0.2826  decode.d4.loss_cls: 0.3183  decode.d4.loss_mask: 0.2692  decode.d4.loss_dice: 0.2906  decode.d5.loss_cls: 0.2964  decode.d5.loss_mask: 0.2716  decode.d5.loss_dice: 0.2819  decode.d6.loss_cls: 0.2820  decode.d6.loss_mask: 0.2770  decode.d6.loss_dice: 0.2952  decode.d7.loss_cls: 0.2764  decode.d7.loss_mask: 0.2816  decode.d7.loss_dice: 0.3071  decode.d8.loss_cls: 0.2858  decode.d8.loss_mask: 0.2778  decode.d8.loss_dice: 0.3124
08/06 09:00:29 - mmengine - INFO - Iter(train) [ 48700/320000]  base_lr: 8.6193e-05 lr: 8.6193e-06  eta: 1 day, 13:06:54  time: 0.4941  data_time: 0.0109  memory: 5911  grad_norm: 26.5781  loss: 4.8567  decode.loss_cls: 0.0070  decode.loss_mask: 0.1796  decode.loss_dice: 0.2143  decode.d0.loss_cls: 0.8453  decode.d0.loss_mask: 0.1823  decode.d0.loss_dice: 0.2182  decode.d1.loss_cls: 0.0158  decode.d1.loss_mask: 0.1802  decode.d1.loss_dice: 0.2106  decode.d2.loss_cls: 0.0156  decode.d2.loss_mask: 0.1800  decode.d2.loss_dice: 0.2111  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.1807  decode.d3.loss_dice: 0.2050  decode.d4.loss_cls: 0.0096  decode.d4.loss_mask: 0.1796  decode.d4.loss_dice: 0.2093  decode.d5.loss_cls: 0.0078  decode.d5.loss_mask: 0.1821  decode.d5.loss_dice: 0.2126  decode.d6.loss_cls: 0.0085  decode.d6.loss_mask: 0.1812  decode.d6.loss_dice: 0.2149  decode.d7.loss_cls: 0.0058  decode.d7.loss_mask: 0.1831  decode.d7.loss_dice: 0.2094  decode.d8.loss_cls: 0.0067  decode.d8.loss_mask: 0.1826  decode.d8.loss_dice: 0.2098
08/06 09:00:53 - mmengine - INFO - Iter(train) [ 48750/320000]  base_lr: 8.6179e-05 lr: 8.6179e-06  eta: 1 day, 13:06:30  time: 0.4949  data_time: 0.0113  memory: 5909  grad_norm: 120.3865  loss: 7.1884  decode.loss_cls: 0.1882  decode.loss_mask: 0.2613  decode.loss_dice: 0.2524  decode.d0.loss_cls: 0.9885  decode.d0.loss_mask: 0.2609  decode.d0.loss_dice: 0.2577  decode.d1.loss_cls: 0.1435  decode.d1.loss_mask: 0.2668  decode.d1.loss_dice: 0.2581  decode.d2.loss_cls: 0.1197  decode.d2.loss_mask: 0.2595  decode.d2.loss_dice: 0.2655  decode.d3.loss_cls: 0.0694  decode.d3.loss_mask: 0.2611  decode.d3.loss_dice: 0.2729  decode.d4.loss_cls: 0.0688  decode.d4.loss_mask: 0.2585  decode.d4.loss_dice: 0.2707  decode.d5.loss_cls: 0.0675  decode.d5.loss_mask: 0.2608  decode.d5.loss_dice: 0.2690  decode.d6.loss_cls: 0.1326  decode.d6.loss_mask: 0.2626  decode.d6.loss_dice: 0.2717  decode.d7.loss_cls: 0.0615  decode.d7.loss_mask: 0.2622  decode.d7.loss_dice: 0.2609  decode.d8.loss_cls: 0.1093  decode.d8.loss_mask: 0.2610  decode.d8.loss_dice: 0.2456
08/06 09:01:18 - mmengine - INFO - Iter(train) [ 48800/320000]  base_lr: 8.6164e-05 lr: 8.6164e-06  eta: 1 day, 13:06:07  time: 0.4940  data_time: 0.0113  memory: 5895  grad_norm: 127.3257  loss: 7.1458  decode.loss_cls: 0.0376  decode.loss_mask: 0.2473  decode.loss_dice: 0.3001  decode.d0.loss_cls: 0.8014  decode.d0.loss_mask: 0.2472  decode.d0.loss_dice: 0.3081  decode.d1.loss_cls: 0.1828  decode.d1.loss_mask: 0.2491  decode.d1.loss_dice: 0.2949  decode.d2.loss_cls: 0.1822  decode.d2.loss_mask: 0.2471  decode.d2.loss_dice: 0.2828  decode.d3.loss_cls: 0.1087  decode.d3.loss_mask: 0.2461  decode.d3.loss_dice: 0.2822  decode.d4.loss_cls: 0.1027  decode.d4.loss_mask: 0.2458  decode.d4.loss_dice: 0.2911  decode.d5.loss_cls: 0.1428  decode.d5.loss_mask: 0.2457  decode.d5.loss_dice: 0.2848  decode.d6.loss_cls: 0.0538  decode.d6.loss_mask: 0.2501  decode.d6.loss_dice: 0.2954  decode.d7.loss_cls: 0.0456  decode.d7.loss_mask: 0.2496  decode.d7.loss_dice: 0.2964  decode.d8.loss_cls: 0.0818  decode.d8.loss_mask: 0.2493  decode.d8.loss_dice: 0.2934
08/06 09:01:43 - mmengine - INFO - Iter(train) [ 48850/320000]  base_lr: 8.6150e-05 lr: 8.6150e-06  eta: 1 day, 13:05:43  time: 0.4932  data_time: 0.0112  memory: 5894  grad_norm: 72.5128  loss: 7.9730  decode.loss_cls: 0.1170  decode.loss_mask: 0.3104  decode.loss_dice: 0.2879  decode.d0.loss_cls: 0.8968  decode.d0.loss_mask: 0.3153  decode.d0.loss_dice: 0.3331  decode.d1.loss_cls: 0.1168  decode.d1.loss_mask: 0.3093  decode.d1.loss_dice: 0.2904  decode.d2.loss_cls: 0.1048  decode.d2.loss_mask: 0.3074  decode.d2.loss_dice: 0.3066  decode.d3.loss_cls: 0.0904  decode.d3.loss_mask: 0.3104  decode.d3.loss_dice: 0.3022  decode.d4.loss_cls: 0.0916  decode.d4.loss_mask: 0.3121  decode.d4.loss_dice: 0.3094  decode.d5.loss_cls: 0.0665  decode.d5.loss_mask: 0.3110  decode.d5.loss_dice: 0.3117  decode.d6.loss_cls: 0.0964  decode.d6.loss_mask: 0.3113  decode.d6.loss_dice: 0.3097  decode.d7.loss_cls: 0.1205  decode.d7.loss_mask: 0.3102  decode.d7.loss_dice: 0.2935  decode.d8.loss_cls: 0.1098  decode.d8.loss_mask: 0.3106  decode.d8.loss_dice: 0.3097
08/06 09:02:08 - mmengine - INFO - Iter(train) [ 48900/320000]  base_lr: 8.6136e-05 lr: 8.6136e-06  eta: 1 day, 13:05:18  time: 0.4944  data_time: 0.0110  memory: 5894  grad_norm: 61.9901  loss: 5.6433  decode.loss_cls: 0.0186  decode.loss_mask: 0.2399  decode.loss_dice: 0.2200  decode.d0.loss_cls: 0.7999  decode.d0.loss_mask: 0.2418  decode.d0.loss_dice: 0.2248  decode.d1.loss_cls: 0.0189  decode.d1.loss_mask: 0.2481  decode.d1.loss_dice: 0.2273  decode.d2.loss_cls: 0.0168  decode.d2.loss_mask: 0.2444  decode.d2.loss_dice: 0.2226  decode.d3.loss_cls: 0.0229  decode.d3.loss_mask: 0.2445  decode.d3.loss_dice: 0.2214  decode.d4.loss_cls: 0.0260  decode.d4.loss_mask: 0.2447  decode.d4.loss_dice: 0.2261  decode.d5.loss_cls: 0.0235  decode.d5.loss_mask: 0.2411  decode.d5.loss_dice: 0.2172  decode.d6.loss_cls: 0.0270  decode.d6.loss_mask: 0.2437  decode.d6.loss_dice: 0.2212  decode.d7.loss_cls: 0.0182  decode.d7.loss_mask: 0.2409  decode.d7.loss_dice: 0.2205  decode.d8.loss_cls: 0.0185  decode.d8.loss_mask: 0.2407  decode.d8.loss_dice: 0.2225
08/06 09:02:32 - mmengine - INFO - Iter(train) [ 48950/320000]  base_lr: 8.6121e-05 lr: 8.6121e-06  eta: 1 day, 13:04:54  time: 0.4939  data_time: 0.0113  memory: 5874  grad_norm: 111.5533  loss: 6.9642  decode.loss_cls: 0.0444  decode.loss_mask: 0.2811  decode.loss_dice: 0.2776  decode.d0.loss_cls: 0.8001  decode.d0.loss_mask: 0.2851  decode.d0.loss_dice: 0.2923  decode.d1.loss_cls: 0.0919  decode.d1.loss_mask: 0.2835  decode.d1.loss_dice: 0.2963  decode.d2.loss_cls: 0.0659  decode.d2.loss_mask: 0.2787  decode.d2.loss_dice: 0.2761  decode.d3.loss_cls: 0.0331  decode.d3.loss_mask: 0.2798  decode.d3.loss_dice: 0.2796  decode.d4.loss_cls: 0.0432  decode.d4.loss_mask: 0.2794  decode.d4.loss_dice: 0.2867  decode.d5.loss_cls: 0.0411  decode.d5.loss_mask: 0.2783  decode.d5.loss_dice: 0.2803  decode.d6.loss_cls: 0.0656  decode.d6.loss_mask: 0.2787  decode.d6.loss_dice: 0.2778  decode.d7.loss_cls: 0.0651  decode.d7.loss_mask: 0.2805  decode.d7.loss_dice: 0.2817  decode.d8.loss_cls: 0.0850  decode.d8.loss_mask: 0.2782  decode.d8.loss_dice: 0.2768
08/06 09:02:57 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 09:02:57 - mmengine - INFO - Iter(train) [ 49000/320000]  base_lr: 8.6107e-05 lr: 8.6107e-06  eta: 1 day, 13:04:30  time: 0.4946  data_time: 0.0113  memory: 5930  grad_norm: 49.1575  loss: 6.7742  decode.loss_cls: 0.1168  decode.loss_mask: 0.2603  decode.loss_dice: 0.2378  decode.d0.loss_cls: 0.9200  decode.d0.loss_mask: 0.2566  decode.d0.loss_dice: 0.2355  decode.d1.loss_cls: 0.1010  decode.d1.loss_mask: 0.2580  decode.d1.loss_dice: 0.2377  decode.d2.loss_cls: 0.0479  decode.d2.loss_mask: 0.2564  decode.d2.loss_dice: 0.2392  decode.d3.loss_cls: 0.1013  decode.d3.loss_mask: 0.2548  decode.d3.loss_dice: 0.2394  decode.d4.loss_cls: 0.0488  decode.d4.loss_mask: 0.2521  decode.d4.loss_dice: 0.2376  decode.d5.loss_cls: 0.0930  decode.d5.loss_mask: 0.2566  decode.d5.loss_dice: 0.2352  decode.d6.loss_cls: 0.1067  decode.d6.loss_mask: 0.2575  decode.d6.loss_dice: 0.2391  decode.d7.loss_cls: 0.1188  decode.d7.loss_mask: 0.2617  decode.d7.loss_dice: 0.2388  decode.d8.loss_cls: 0.1708  decode.d8.loss_mask: 0.2584  decode.d8.loss_dice: 0.2362
08/06 09:03:22 - mmengine - INFO - Iter(train) [ 49050/320000]  base_lr: 8.6093e-05 lr: 8.6093e-06  eta: 1 day, 13:04:06  time: 0.4931  data_time: 0.0112  memory: 5931  grad_norm: 64.5437  loss: 6.8609  decode.loss_cls: 0.0917  decode.loss_mask: 0.2431  decode.loss_dice: 0.2552  decode.d0.loss_cls: 0.7995  decode.d0.loss_mask: 0.2616  decode.d0.loss_dice: 0.2714  decode.d1.loss_cls: 0.2108  decode.d1.loss_mask: 0.2452  decode.d1.loss_dice: 0.2668  decode.d2.loss_cls: 0.1205  decode.d2.loss_mask: 0.2448  decode.d2.loss_dice: 0.2595  decode.d3.loss_cls: 0.0983  decode.d3.loss_mask: 0.2410  decode.d3.loss_dice: 0.2633  decode.d4.loss_cls: 0.0822  decode.d4.loss_mask: 0.2446  decode.d4.loss_dice: 0.2620  decode.d5.loss_cls: 0.0927  decode.d5.loss_mask: 0.2418  decode.d5.loss_dice: 0.2627  decode.d6.loss_cls: 0.0991  decode.d6.loss_mask: 0.2433  decode.d6.loss_dice: 0.2603  decode.d7.loss_cls: 0.0995  decode.d7.loss_mask: 0.2439  decode.d7.loss_dice: 0.2577  decode.d8.loss_cls: 0.0983  decode.d8.loss_mask: 0.2426  decode.d8.loss_dice: 0.2576
08/06 09:03:46 - mmengine - INFO - Iter(train) [ 49100/320000]  base_lr: 8.6078e-05 lr: 8.6078e-06  eta: 1 day, 13:03:41  time: 0.4937  data_time: 0.0112  memory: 5911  grad_norm: 115.2334  loss: 8.9859  decode.loss_cls: 0.1491  decode.loss_mask: 0.2473  decode.loss_dice: 0.3681  decode.d0.loss_cls: 1.0034  decode.d0.loss_mask: 0.2437  decode.d0.loss_dice: 0.3792  decode.d1.loss_cls: 0.2022  decode.d1.loss_mask: 0.2459  decode.d1.loss_dice: 0.3472  decode.d2.loss_cls: 0.1793  decode.d2.loss_mask: 0.2465  decode.d2.loss_dice: 0.3450  decode.d3.loss_cls: 0.1917  decode.d3.loss_mask: 0.2443  decode.d3.loss_dice: 0.3442  decode.d4.loss_cls: 0.2141  decode.d4.loss_mask: 0.2470  decode.d4.loss_dice: 0.3809  decode.d5.loss_cls: 0.2091  decode.d5.loss_mask: 0.2468  decode.d5.loss_dice: 0.3671  decode.d6.loss_cls: 0.2494  decode.d6.loss_mask: 0.2500  decode.d6.loss_dice: 0.3858  decode.d7.loss_cls: 0.2526  decode.d7.loss_mask: 0.2471  decode.d7.loss_dice: 0.3647  decode.d8.loss_cls: 0.2321  decode.d8.loss_mask: 0.2460  decode.d8.loss_dice: 0.3564
08/06 09:04:11 - mmengine - INFO - Iter(train) [ 49150/320000]  base_lr: 8.6064e-05 lr: 8.6064e-06  eta: 1 day, 13:03:17  time: 0.4950  data_time: 0.0115  memory: 5911  grad_norm: 213.5409  loss: 9.0166  decode.loss_cls: 0.2679  decode.loss_mask: 0.2488  decode.loss_dice: 0.3252  decode.d0.loss_cls: 1.1187  decode.d0.loss_mask: 0.2159  decode.d0.loss_dice: 0.3249  decode.d1.loss_cls: 0.2434  decode.d1.loss_mask: 0.2198  decode.d1.loss_dice: 0.3278  decode.d2.loss_cls: 0.1974  decode.d2.loss_mask: 0.2631  decode.d2.loss_dice: 0.3374  decode.d3.loss_cls: 0.1820  decode.d3.loss_mask: 0.2704  decode.d3.loss_dice: 0.3237  decode.d4.loss_cls: 0.1907  decode.d4.loss_mask: 0.2616  decode.d4.loss_dice: 0.3414  decode.d5.loss_cls: 0.1892  decode.d5.loss_mask: 0.2690  decode.d5.loss_dice: 0.3324  decode.d6.loss_cls: 0.2711  decode.d6.loss_mask: 0.2752  decode.d6.loss_dice: 0.3395  decode.d7.loss_cls: 0.2268  decode.d7.loss_mask: 0.2765  decode.d7.loss_dice: 0.3398  decode.d8.loss_cls: 0.2569  decode.d8.loss_mask: 0.2595  decode.d8.loss_dice: 0.3207
08/06 09:04:36 - mmengine - INFO - Iter(train) [ 49200/320000]  base_lr: 8.6050e-05 lr: 8.6050e-06  eta: 1 day, 13:02:53  time: 0.4950  data_time: 0.0112  memory: 5876  grad_norm: 106.8232  loss: 6.4062  decode.loss_cls: 0.1511  decode.loss_mask: 0.2082  decode.loss_dice: 0.2429  decode.d0.loss_cls: 0.8203  decode.d0.loss_mask: 0.2116  decode.d0.loss_dice: 0.2525  decode.d1.loss_cls: 0.1047  decode.d1.loss_mask: 0.2119  decode.d1.loss_dice: 0.2453  decode.d2.loss_cls: 0.1193  decode.d2.loss_mask: 0.2115  decode.d2.loss_dice: 0.2358  decode.d3.loss_cls: 0.1023  decode.d3.loss_mask: 0.2114  decode.d3.loss_dice: 0.2419  decode.d4.loss_cls: 0.1035  decode.d4.loss_mask: 0.2119  decode.d4.loss_dice: 0.2415  decode.d5.loss_cls: 0.1216  decode.d5.loss_mask: 0.2093  decode.d5.loss_dice: 0.2391  decode.d6.loss_cls: 0.1148  decode.d6.loss_mask: 0.2112  decode.d6.loss_dice: 0.2407  decode.d7.loss_cls: 0.1152  decode.d7.loss_mask: 0.2097  decode.d7.loss_dice: 0.2419  decode.d8.loss_cls: 0.1170  decode.d8.loss_mask: 0.2115  decode.d8.loss_dice: 0.2466
08/06 09:05:01 - mmengine - INFO - Iter(train) [ 49250/320000]  base_lr: 8.6036e-05 lr: 8.6036e-06  eta: 1 day, 13:02:29  time: 0.4958  data_time: 0.0112  memory: 5926  grad_norm: 84.2024  loss: 7.5342  decode.loss_cls: 0.1501  decode.loss_mask: 0.2237  decode.loss_dice: 0.2826  decode.d0.loss_cls: 0.8829  decode.d0.loss_mask: 0.2325  decode.d0.loss_dice: 0.2991  decode.d1.loss_cls: 0.2564  decode.d1.loss_mask: 0.2278  decode.d1.loss_dice: 0.2941  decode.d2.loss_cls: 0.1957  decode.d2.loss_mask: 0.2245  decode.d2.loss_dice: 0.2628  decode.d3.loss_cls: 0.1512  decode.d3.loss_mask: 0.2263  decode.d3.loss_dice: 0.2945  decode.d4.loss_cls: 0.1550  decode.d4.loss_mask: 0.2237  decode.d4.loss_dice: 0.2354  decode.d5.loss_cls: 0.1998  decode.d5.loss_mask: 0.2224  decode.d5.loss_dice: 0.2912  decode.d6.loss_cls: 0.1757  decode.d6.loss_mask: 0.2248  decode.d6.loss_dice: 0.2788  decode.d7.loss_cls: 0.2036  decode.d7.loss_mask: 0.2247  decode.d7.loss_dice: 0.2567  decode.d8.loss_cls: 0.1293  decode.d8.loss_mask: 0.2230  decode.d8.loss_dice: 0.2857
08/06 09:05:25 - mmengine - INFO - Iter(train) [ 49300/320000]  base_lr: 8.6021e-05 lr: 8.6021e-06  eta: 1 day, 13:02:05  time: 0.4945  data_time: 0.0111  memory: 5911  grad_norm: 76.9624  loss: 7.6169  decode.loss_cls: 0.1806  decode.loss_mask: 0.2237  decode.loss_dice: 0.2669  decode.d0.loss_cls: 0.9098  decode.d0.loss_mask: 0.2285  decode.d0.loss_dice: 0.2481  decode.d1.loss_cls: 0.2304  decode.d1.loss_mask: 0.2228  decode.d1.loss_dice: 0.2654  decode.d2.loss_cls: 0.2280  decode.d2.loss_mask: 0.2225  decode.d2.loss_dice: 0.2752  decode.d3.loss_cls: 0.1792  decode.d3.loss_mask: 0.2232  decode.d3.loss_dice: 0.2729  decode.d4.loss_cls: 0.1750  decode.d4.loss_mask: 0.2255  decode.d4.loss_dice: 0.2916  decode.d5.loss_cls: 0.2110  decode.d5.loss_mask: 0.2225  decode.d5.loss_dice: 0.2469  decode.d6.loss_cls: 0.2100  decode.d6.loss_mask: 0.2246  decode.d6.loss_dice: 0.2689  decode.d7.loss_cls: 0.1871  decode.d7.loss_mask: 0.2236  decode.d7.loss_dice: 0.2693  decode.d8.loss_cls: 0.2110  decode.d8.loss_mask: 0.2213  decode.d8.loss_dice: 0.2511
08/06 09:05:50 - mmengine - INFO - Iter(train) [ 49350/320000]  base_lr: 8.6007e-05 lr: 8.6007e-06  eta: 1 day, 13:01:40  time: 0.4945  data_time: 0.0112  memory: 5911  grad_norm: 97.9304  loss: 6.4995  decode.loss_cls: 0.0651  decode.loss_mask: 0.2189  decode.loss_dice: 0.2743  decode.d0.loss_cls: 0.9938  decode.d0.loss_mask: 0.2335  decode.d0.loss_dice: 0.2575  decode.d1.loss_cls: 0.0938  decode.d1.loss_mask: 0.2254  decode.d1.loss_dice: 0.2518  decode.d2.loss_cls: 0.0918  decode.d2.loss_mask: 0.2216  decode.d2.loss_dice: 0.2559  decode.d3.loss_cls: 0.0474  decode.d3.loss_mask: 0.2327  decode.d3.loss_dice: 0.2472  decode.d4.loss_cls: 0.0563  decode.d4.loss_mask: 0.2220  decode.d4.loss_dice: 0.2442  decode.d5.loss_cls: 0.1017  decode.d5.loss_mask: 0.2261  decode.d5.loss_dice: 0.2397  decode.d6.loss_cls: 0.1118  decode.d6.loss_mask: 0.2216  decode.d6.loss_dice: 0.2426  decode.d7.loss_cls: 0.0772  decode.d7.loss_mask: 0.2229  decode.d7.loss_dice: 0.2393  decode.d8.loss_cls: 0.1168  decode.d8.loss_mask: 0.2218  decode.d8.loss_dice: 0.2445
08/06 09:06:15 - mmengine - INFO - Iter(train) [ 49400/320000]  base_lr: 8.5993e-05 lr: 8.5993e-06  eta: 1 day, 13:01:17  time: 0.4939  data_time: 0.0112  memory: 5911  grad_norm: 99.7151  loss: 7.0872  decode.loss_cls: 0.1162  decode.loss_mask: 0.2788  decode.loss_dice: 0.2471  decode.d0.loss_cls: 0.8355  decode.d0.loss_mask: 0.2896  decode.d0.loss_dice: 0.2840  decode.d1.loss_cls: 0.0689  decode.d1.loss_mask: 0.2828  decode.d1.loss_dice: 0.3028  decode.d2.loss_cls: 0.0787  decode.d2.loss_mask: 0.2783  decode.d2.loss_dice: 0.2652  decode.d3.loss_cls: 0.0624  decode.d3.loss_mask: 0.2792  decode.d3.loss_dice: 0.2608  decode.d4.loss_cls: 0.0766  decode.d4.loss_mask: 0.2815  decode.d4.loss_dice: 0.2675  decode.d5.loss_cls: 0.0976  decode.d5.loss_mask: 0.2790  decode.d5.loss_dice: 0.2682  decode.d6.loss_cls: 0.1167  decode.d6.loss_mask: 0.2810  decode.d6.loss_dice: 0.2650  decode.d7.loss_cls: 0.0984  decode.d7.loss_mask: 0.2812  decode.d7.loss_dice: 0.2557  decode.d8.loss_cls: 0.0728  decode.d8.loss_mask: 0.2735  decode.d8.loss_dice: 0.2420
08/06 09:06:40 - mmengine - INFO - Iter(train) [ 49450/320000]  base_lr: 8.5978e-05 lr: 8.5978e-06  eta: 1 day, 13:00:53  time: 0.4948  data_time: 0.0113  memory: 5928  grad_norm: 164.0261  loss: 7.5130  decode.loss_cls: 0.1178  decode.loss_mask: 0.2790  decode.loss_dice: 0.2952  decode.d0.loss_cls: 0.8094  decode.d0.loss_mask: 0.2888  decode.d0.loss_dice: 0.2990  decode.d1.loss_cls: 0.0972  decode.d1.loss_mask: 0.2875  decode.d1.loss_dice: 0.3019  decode.d2.loss_cls: 0.1003  decode.d2.loss_mask: 0.2777  decode.d2.loss_dice: 0.3004  decode.d3.loss_cls: 0.0827  decode.d3.loss_mask: 0.2773  decode.d3.loss_dice: 0.2958  decode.d4.loss_cls: 0.0846  decode.d4.loss_mask: 0.2776  decode.d4.loss_dice: 0.2822  decode.d5.loss_cls: 0.1015  decode.d5.loss_mask: 0.2791  decode.d5.loss_dice: 0.2974  decode.d6.loss_cls: 0.1155  decode.d6.loss_mask: 0.2788  decode.d6.loss_dice: 0.2953  decode.d7.loss_cls: 0.1453  decode.d7.loss_mask: 0.2746  decode.d7.loss_dice: 0.2728  decode.d8.loss_cls: 0.1254  decode.d8.loss_mask: 0.2788  decode.d8.loss_dice: 0.2941
08/06 09:07:04 - mmengine - INFO - Iter(train) [ 49500/320000]  base_lr: 8.5964e-05 lr: 8.5964e-06  eta: 1 day, 13:00:29  time: 0.4953  data_time: 0.0115  memory: 5894  grad_norm: 116.7208  loss: 7.6032  decode.loss_cls: 0.0832  decode.loss_mask: 0.2502  decode.loss_dice: 0.2978  decode.d0.loss_cls: 1.0828  decode.d0.loss_mask: 0.2502  decode.d0.loss_dice: 0.2759  decode.d1.loss_cls: 0.1442  decode.d1.loss_mask: 0.2504  decode.d1.loss_dice: 0.3012  decode.d2.loss_cls: 0.1610  decode.d2.loss_mask: 0.2484  decode.d2.loss_dice: 0.2856  decode.d3.loss_cls: 0.1500  decode.d3.loss_mask: 0.2490  decode.d3.loss_dice: 0.2860  decode.d4.loss_cls: 0.1402  decode.d4.loss_mask: 0.2487  decode.d4.loss_dice: 0.3038  decode.d5.loss_cls: 0.1556  decode.d5.loss_mask: 0.2450  decode.d5.loss_dice: 0.2906  decode.d6.loss_cls: 0.1018  decode.d6.loss_mask: 0.2467  decode.d6.loss_dice: 0.2956  decode.d7.loss_cls: 0.0812  decode.d7.loss_mask: 0.2483  decode.d7.loss_dice: 0.2958  decode.d8.loss_cls: 0.0861  decode.d8.loss_mask: 0.2468  decode.d8.loss_dice: 0.3010
08/06 09:07:29 - mmengine - INFO - Iter(train) [ 49550/320000]  base_lr: 8.5950e-05 lr: 8.5950e-06  eta: 1 day, 13:00:05  time: 0.4940  data_time: 0.0111  memory: 5878  grad_norm: 342.0855  loss: 6.3593  decode.loss_cls: 0.0762  decode.loss_mask: 0.2259  decode.loss_dice: 0.2608  decode.d0.loss_cls: 0.8716  decode.d0.loss_mask: 0.2196  decode.d0.loss_dice: 0.2700  decode.d1.loss_cls: 0.1049  decode.d1.loss_mask: 0.2261  decode.d1.loss_dice: 0.2494  decode.d2.loss_cls: 0.1254  decode.d2.loss_mask: 0.2251  decode.d2.loss_dice: 0.2493  decode.d3.loss_cls: 0.0647  decode.d3.loss_mask: 0.2158  decode.d3.loss_dice: 0.2393  decode.d4.loss_cls: 0.0747  decode.d4.loss_mask: 0.2219  decode.d4.loss_dice: 0.2471  decode.d5.loss_cls: 0.0474  decode.d5.loss_mask: 0.2278  decode.d5.loss_dice: 0.2564  decode.d6.loss_cls: 0.0650  decode.d6.loss_mask: 0.2209  decode.d6.loss_dice: 0.2583  decode.d7.loss_cls: 0.0856  decode.d7.loss_mask: 0.2192  decode.d7.loss_dice: 0.2582  decode.d8.loss_cls: 0.0679  decode.d8.loss_mask: 0.2233  decode.d8.loss_dice: 0.2617
08/06 09:07:54 - mmengine - INFO - Iter(train) [ 49600/320000]  base_lr: 8.5935e-05 lr: 8.5935e-06  eta: 1 day, 12:59:41  time: 0.4950  data_time: 0.0112  memory: 5895  grad_norm: 139.7256  loss: 7.8959  decode.loss_cls: 0.2206  decode.loss_mask: 0.2285  decode.loss_dice: 0.2849  decode.d0.loss_cls: 0.9941  decode.d0.loss_mask: 0.2199  decode.d0.loss_dice: 0.2973  decode.d1.loss_cls: 0.2332  decode.d1.loss_mask: 0.2176  decode.d1.loss_dice: 0.2798  decode.d2.loss_cls: 0.2263  decode.d2.loss_mask: 0.2221  decode.d2.loss_dice: 0.2714  decode.d3.loss_cls: 0.1788  decode.d3.loss_mask: 0.2220  decode.d3.loss_dice: 0.2749  decode.d4.loss_cls: 0.1635  decode.d4.loss_mask: 0.2174  decode.d4.loss_dice: 0.2986  decode.d5.loss_cls: 0.2243  decode.d5.loss_mask: 0.2189  decode.d5.loss_dice: 0.2868  decode.d6.loss_cls: 0.2190  decode.d6.loss_mask: 0.2184  decode.d6.loss_dice: 0.2710  decode.d7.loss_cls: 0.1851  decode.d7.loss_mask: 0.2265  decode.d7.loss_dice: 0.3023  decode.d8.loss_cls: 0.1950  decode.d8.loss_mask: 0.2193  decode.d8.loss_dice: 0.2785
08/06 09:08:19 - mmengine - INFO - Iter(train) [ 49650/320000]  base_lr: 8.5921e-05 lr: 8.5921e-06  eta: 1 day, 12:59:17  time: 0.4943  data_time: 0.0113  memory: 5894  grad_norm: 93.1820  loss: 8.5419  decode.loss_cls: 0.2205  decode.loss_mask: 0.2222  decode.loss_dice: 0.3057  decode.d0.loss_cls: 1.0873  decode.d0.loss_mask: 0.2252  decode.d0.loss_dice: 0.3089  decode.d1.loss_cls: 0.2519  decode.d1.loss_mask: 0.2252  decode.d1.loss_dice: 0.3411  decode.d2.loss_cls: 0.2278  decode.d2.loss_mask: 0.2268  decode.d2.loss_dice: 0.3116  decode.d3.loss_cls: 0.1744  decode.d3.loss_mask: 0.2263  decode.d3.loss_dice: 0.3354  decode.d4.loss_cls: 0.2400  decode.d4.loss_mask: 0.2231  decode.d4.loss_dice: 0.3173  decode.d5.loss_cls: 0.2322  decode.d5.loss_mask: 0.2258  decode.d5.loss_dice: 0.3144  decode.d6.loss_cls: 0.2245  decode.d6.loss_mask: 0.2244  decode.d6.loss_dice: 0.2840  decode.d7.loss_cls: 0.2517  decode.d7.loss_mask: 0.2218  decode.d7.loss_dice: 0.3141  decode.d8.loss_cls: 0.2568  decode.d8.loss_mask: 0.2234  decode.d8.loss_dice: 0.2983
08/06 09:08:43 - mmengine - INFO - Iter(train) [ 49700/320000]  base_lr: 8.5907e-05 lr: 8.5907e-06  eta: 1 day, 12:58:52  time: 0.4946  data_time: 0.0115  memory: 5874  grad_norm: 84.5677  loss: 7.0832  decode.loss_cls: 0.0967  decode.loss_mask: 0.2575  decode.loss_dice: 0.2731  decode.d0.loss_cls: 0.7606  decode.d0.loss_mask: 0.2637  decode.d0.loss_dice: 0.2987  decode.d1.loss_cls: 0.0690  decode.d1.loss_mask: 0.2586  decode.d1.loss_dice: 0.2844  decode.d2.loss_cls: 0.0815  decode.d2.loss_mask: 0.2585  decode.d2.loss_dice: 0.2625  decode.d3.loss_cls: 0.0923  decode.d3.loss_mask: 0.2560  decode.d3.loss_dice: 0.2796  decode.d4.loss_cls: 0.1091  decode.d4.loss_mask: 0.2579  decode.d4.loss_dice: 0.2773  decode.d5.loss_cls: 0.0908  decode.d5.loss_mask: 0.2562  decode.d5.loss_dice: 0.2730  decode.d6.loss_cls: 0.1095  decode.d6.loss_mask: 0.2575  decode.d6.loss_dice: 0.2715  decode.d7.loss_cls: 0.1414  decode.d7.loss_mask: 0.2594  decode.d7.loss_dice: 0.3291  decode.d8.loss_cls: 0.1020  decode.d8.loss_mask: 0.2625  decode.d8.loss_dice: 0.2934
08/06 09:09:08 - mmengine - INFO - Iter(train) [ 49750/320000]  base_lr: 8.5893e-05 lr: 8.5893e-06  eta: 1 day, 12:58:28  time: 0.4953  data_time: 0.0113  memory: 5911  grad_norm: 112.6896  loss: 6.3646  decode.loss_cls: 0.1258  decode.loss_mask: 0.1962  decode.loss_dice: 0.2367  decode.d0.loss_cls: 0.8770  decode.d0.loss_mask: 0.1996  decode.d0.loss_dice: 0.2492  decode.d1.loss_cls: 0.1572  decode.d1.loss_mask: 0.1953  decode.d1.loss_dice: 0.2339  decode.d2.loss_cls: 0.1091  decode.d2.loss_mask: 0.1979  decode.d2.loss_dice: 0.2280  decode.d3.loss_cls: 0.0987  decode.d3.loss_mask: 0.1942  decode.d3.loss_dice: 0.2201  decode.d4.loss_cls: 0.1274  decode.d4.loss_mask: 0.1973  decode.d4.loss_dice: 0.2328  decode.d5.loss_cls: 0.1230  decode.d5.loss_mask: 0.1996  decode.d5.loss_dice: 0.2276  decode.d6.loss_cls: 0.1321  decode.d6.loss_mask: 0.1962  decode.d6.loss_dice: 0.2318  decode.d7.loss_cls: 0.1236  decode.d7.loss_mask: 0.2131  decode.d7.loss_dice: 0.2418  decode.d8.loss_cls: 0.1445  decode.d8.loss_mask: 0.2107  decode.d8.loss_dice: 0.2440
08/06 09:09:33 - mmengine - INFO - Iter(train) [ 49800/320000]  base_lr: 8.5878e-05 lr: 8.5878e-06  eta: 1 day, 12:58:04  time: 0.4950  data_time: 0.0112  memory: 5913  grad_norm: 82.7844  loss: 7.0677  decode.loss_cls: 0.1735  decode.loss_mask: 0.2447  decode.loss_dice: 0.2418  decode.d0.loss_cls: 0.9151  decode.d0.loss_mask: 0.2496  decode.d0.loss_dice: 0.2546  decode.d1.loss_cls: 0.1250  decode.d1.loss_mask: 0.2589  decode.d1.loss_dice: 0.2604  decode.d2.loss_cls: 0.1119  decode.d2.loss_mask: 0.2508  decode.d2.loss_dice: 0.2568  decode.d3.loss_cls: 0.1016  decode.d3.loss_mask: 0.2401  decode.d3.loss_dice: 0.2461  decode.d4.loss_cls: 0.1346  decode.d4.loss_mask: 0.2397  decode.d4.loss_dice: 0.2380  decode.d5.loss_cls: 0.1139  decode.d5.loss_mask: 0.2384  decode.d5.loss_dice: 0.2376  decode.d6.loss_cls: 0.1613  decode.d6.loss_mask: 0.2430  decode.d6.loss_dice: 0.2352  decode.d7.loss_cls: 0.1572  decode.d7.loss_mask: 0.2462  decode.d7.loss_dice: 0.2533  decode.d8.loss_cls: 0.1135  decode.d8.loss_mask: 0.2660  decode.d8.loss_dice: 0.2587
08/06 09:09:57 - mmengine - INFO - Iter(train) [ 49850/320000]  base_lr: 8.5864e-05 lr: 8.5864e-06  eta: 1 day, 12:57:40  time: 0.4940  data_time: 0.0112  memory: 5894  grad_norm: 318.4123  loss: 8.3276  decode.loss_cls: 0.1323  decode.loss_mask: 0.2840  decode.loss_dice: 0.3269  decode.d0.loss_cls: 0.9079  decode.d0.loss_mask: 0.2910  decode.d0.loss_dice: 0.3244  decode.d1.loss_cls: 0.2364  decode.d1.loss_mask: 0.2802  decode.d1.loss_dice: 0.3370  decode.d2.loss_cls: 0.1509  decode.d2.loss_mask: 0.2951  decode.d2.loss_dice: 0.3249  decode.d3.loss_cls: 0.1571  decode.d3.loss_mask: 0.2825  decode.d3.loss_dice: 0.2992  decode.d4.loss_cls: 0.1300  decode.d4.loss_mask: 0.2854  decode.d4.loss_dice: 0.3034  decode.d5.loss_cls: 0.0994  decode.d5.loss_mask: 0.2981  decode.d5.loss_dice: 0.3242  decode.d6.loss_cls: 0.1832  decode.d6.loss_mask: 0.2955  decode.d6.loss_dice: 0.3106  decode.d7.loss_cls: 0.1458  decode.d7.loss_mask: 0.2649  decode.d7.loss_dice: 0.3097  decode.d8.loss_cls: 0.1406  decode.d8.loss_mask: 0.2916  decode.d8.loss_dice: 0.3152
08/06 09:10:22 - mmengine - INFO - Iter(train) [ 49900/320000]  base_lr: 8.5850e-05 lr: 8.5850e-06  eta: 1 day, 12:57:16  time: 0.4945  data_time: 0.0111  memory: 5911  grad_norm: 123.1700  loss: 7.8516  decode.loss_cls: 0.0966  decode.loss_mask: 0.3126  decode.loss_dice: 0.3331  decode.d0.loss_cls: 0.8354  decode.d0.loss_mask: 0.3167  decode.d0.loss_dice: 0.3070  decode.d1.loss_cls: 0.1389  decode.d1.loss_mask: 0.3135  decode.d1.loss_dice: 0.3140  decode.d2.loss_cls: 0.0962  decode.d2.loss_mask: 0.3089  decode.d2.loss_dice: 0.3262  decode.d3.loss_cls: 0.0576  decode.d3.loss_mask: 0.3104  decode.d3.loss_dice: 0.2980  decode.d4.loss_cls: 0.1176  decode.d4.loss_mask: 0.3089  decode.d4.loss_dice: 0.2899  decode.d5.loss_cls: 0.0611  decode.d5.loss_mask: 0.3033  decode.d5.loss_dice: 0.2847  decode.d6.loss_cls: 0.0768  decode.d6.loss_mask: 0.3049  decode.d6.loss_dice: 0.3287  decode.d7.loss_cls: 0.0716  decode.d7.loss_mask: 0.3164  decode.d7.loss_dice: 0.3303  decode.d8.loss_cls: 0.0877  decode.d8.loss_mask: 0.3107  decode.d8.loss_dice: 0.2938
08/06 09:10:47 - mmengine - INFO - Iter(train) [ 49950/320000]  base_lr: 8.5835e-05 lr: 8.5835e-06  eta: 1 day, 12:56:52  time: 0.4941  data_time: 0.0113  memory: 5913  grad_norm: 114.1609  loss: 7.6140  decode.loss_cls: 0.1368  decode.loss_mask: 0.2621  decode.loss_dice: 0.2751  decode.d0.loss_cls: 0.8227  decode.d0.loss_mask: 0.2621  decode.d0.loss_dice: 0.2782  decode.d1.loss_cls: 0.1733  decode.d1.loss_mask: 0.2617  decode.d1.loss_dice: 0.2948  decode.d2.loss_cls: 0.1677  decode.d2.loss_mask: 0.2618  decode.d2.loss_dice: 0.2915  decode.d3.loss_cls: 0.1634  decode.d3.loss_mask: 0.2615  decode.d3.loss_dice: 0.2799  decode.d4.loss_cls: 0.1656  decode.d4.loss_mask: 0.2597  decode.d4.loss_dice: 0.2743  decode.d5.loss_cls: 0.1428  decode.d5.loss_mask: 0.2650  decode.d5.loss_dice: 0.2808  decode.d6.loss_cls: 0.1572  decode.d6.loss_mask: 0.2608  decode.d6.loss_dice: 0.2963  decode.d7.loss_cls: 0.1207  decode.d7.loss_mask: 0.2655  decode.d7.loss_dice: 0.2784  decode.d8.loss_cls: 0.1172  decode.d8.loss_mask: 0.2591  decode.d8.loss_dice: 0.2778
08/06 09:11:12 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 09:11:12 - mmengine - INFO - Iter(train) [ 50000/320000]  base_lr: 8.5821e-05 lr: 8.5821e-06  eta: 1 day, 12:56:28  time: 0.4940  data_time: 0.0113  memory: 5875  grad_norm: 123.5156  loss: 5.8778  decode.loss_cls: 0.0284  decode.loss_mask: 0.2444  decode.loss_dice: 0.2409  decode.d0.loss_cls: 0.7363  decode.d0.loss_mask: 0.2485  decode.d0.loss_dice: 0.2304  decode.d1.loss_cls: 0.0398  decode.d1.loss_mask: 0.2487  decode.d1.loss_dice: 0.2465  decode.d2.loss_cls: 0.0473  decode.d2.loss_mask: 0.2469  decode.d2.loss_dice: 0.2414  decode.d3.loss_cls: 0.0253  decode.d3.loss_mask: 0.2428  decode.d3.loss_dice: 0.2407  decode.d4.loss_cls: 0.0358  decode.d4.loss_mask: 0.2454  decode.d4.loss_dice: 0.2355  decode.d5.loss_cls: 0.0252  decode.d5.loss_mask: 0.2454  decode.d5.loss_dice: 0.2340  decode.d6.loss_cls: 0.0341  decode.d6.loss_mask: 0.2449  decode.d6.loss_dice: 0.2384  decode.d7.loss_cls: 0.0370  decode.d7.loss_mask: 0.2447  decode.d7.loss_dice: 0.2328  decode.d8.loss_cls: 0.0303  decode.d8.loss_mask: 0.2448  decode.d8.loss_dice: 0.2412
08/06 09:11:36 - mmengine - INFO - Iter(train) [ 50050/320000]  base_lr: 8.5807e-05 lr: 8.5807e-06  eta: 1 day, 12:56:04  time: 0.4941  data_time: 0.0110  memory: 5860  grad_norm: 277.8175  loss: 7.8713  decode.loss_cls: 0.1099  decode.loss_mask: 0.2939  decode.loss_dice: 0.2659  decode.d0.loss_cls: 0.8289  decode.d0.loss_mask: 0.3231  decode.d0.loss_dice: 0.2747  decode.d1.loss_cls: 0.1946  decode.d1.loss_mask: 0.3116  decode.d1.loss_dice: 0.2647  decode.d2.loss_cls: 0.1838  decode.d2.loss_mask: 0.3036  decode.d2.loss_dice: 0.2608  decode.d3.loss_cls: 0.1471  decode.d3.loss_mask: 0.3045  decode.d3.loss_dice: 0.2654  decode.d4.loss_cls: 0.1586  decode.d4.loss_mask: 0.3050  decode.d4.loss_dice: 0.2740  decode.d5.loss_cls: 0.1342  decode.d5.loss_mask: 0.3114  decode.d5.loss_dice: 0.2704  decode.d6.loss_cls: 0.1397  decode.d6.loss_mask: 0.2994  decode.d6.loss_dice: 0.2669  decode.d7.loss_cls: 0.1266  decode.d7.loss_mask: 0.2955  decode.d7.loss_dice: 0.2692  decode.d8.loss_cls: 0.1240  decode.d8.loss_mask: 0.2962  decode.d8.loss_dice: 0.2677
08/06 09:12:01 - mmengine - INFO - Iter(train) [ 50100/320000]  base_lr: 8.5792e-05 lr: 8.5792e-06  eta: 1 day, 12:55:40  time: 0.4941  data_time: 0.0113  memory: 5891  grad_norm: 358.9566  loss: 9.7962  decode.loss_cls: 0.1680  decode.loss_mask: 0.4517  decode.loss_dice: 0.3344  decode.d0.loss_cls: 0.9001  decode.d0.loss_mask: 0.4335  decode.d0.loss_dice: 0.3374  decode.d1.loss_cls: 0.1262  decode.d1.loss_mask: 0.4229  decode.d1.loss_dice: 0.3179  decode.d2.loss_cls: 0.1002  decode.d2.loss_mask: 0.4201  decode.d2.loss_dice: 0.3235  decode.d3.loss_cls: 0.1268  decode.d3.loss_mask: 0.4291  decode.d3.loss_dice: 0.3410  decode.d4.loss_cls: 0.1058  decode.d4.loss_mask: 0.4235  decode.d4.loss_dice: 0.3295  decode.d5.loss_cls: 0.1196  decode.d5.loss_mask: 0.4371  decode.d5.loss_dice: 0.3381  decode.d6.loss_cls: 0.1227  decode.d6.loss_mask: 0.4404  decode.d6.loss_dice: 0.3333  decode.d7.loss_cls: 0.1434  decode.d7.loss_mask: 0.4602  decode.d7.loss_dice: 0.3387  decode.d8.loss_cls: 0.1971  decode.d8.loss_mask: 0.4416  decode.d8.loss_dice: 0.3323
08/06 09:12:26 - mmengine - INFO - Iter(train) [ 50150/320000]  base_lr: 8.5778e-05 lr: 8.5778e-06  eta: 1 day, 12:55:16  time: 0.4940  data_time: 0.0113  memory: 5931  grad_norm: 59.5910  loss: 7.3603  decode.loss_cls: 0.1122  decode.loss_mask: 0.2337  decode.loss_dice: 0.2794  decode.d0.loss_cls: 0.8788  decode.d0.loss_mask: 0.2362  decode.d0.loss_dice: 0.2903  decode.d1.loss_cls: 0.1741  decode.d1.loss_mask: 0.2370  decode.d1.loss_dice: 0.2826  decode.d2.loss_cls: 0.1573  decode.d2.loss_mask: 0.2334  decode.d2.loss_dice: 0.2942  decode.d3.loss_cls: 0.1720  decode.d3.loss_mask: 0.2328  decode.d3.loss_dice: 0.2684  decode.d4.loss_cls: 0.2054  decode.d4.loss_mask: 0.2355  decode.d4.loss_dice: 0.2644  decode.d5.loss_cls: 0.1549  decode.d5.loss_mask: 0.2320  decode.d5.loss_dice: 0.2765  decode.d6.loss_cls: 0.0860  decode.d6.loss_mask: 0.2382  decode.d6.loss_dice: 0.2797  decode.d7.loss_cls: 0.1391  decode.d7.loss_mask: 0.2325  decode.d7.loss_dice: 0.2752  decode.d8.loss_cls: 0.1417  decode.d8.loss_mask: 0.2329  decode.d8.loss_dice: 0.2839
08/06 09:12:51 - mmengine - INFO - Iter(train) [ 50200/320000]  base_lr: 8.5764e-05 lr: 8.5764e-06  eta: 1 day, 12:54:52  time: 0.4938  data_time: 0.0110  memory: 5894  grad_norm: 179.9100  loss: 6.3106  decode.loss_cls: 0.0801  decode.loss_mask: 0.2095  decode.loss_dice: 0.2378  decode.d0.loss_cls: 0.9525  decode.d0.loss_mask: 0.2113  decode.d0.loss_dice: 0.2133  decode.d1.loss_cls: 0.1089  decode.d1.loss_mask: 0.2295  decode.d1.loss_dice: 0.2310  decode.d2.loss_cls: 0.1008  decode.d2.loss_mask: 0.2074  decode.d2.loss_dice: 0.2266  decode.d3.loss_cls: 0.1041  decode.d3.loss_mask: 0.2087  decode.d3.loss_dice: 0.2276  decode.d4.loss_cls: 0.0861  decode.d4.loss_mask: 0.2091  decode.d4.loss_dice: 0.2337  decode.d5.loss_cls: 0.1031  decode.d5.loss_mask: 0.2234  decode.d5.loss_dice: 0.2441  decode.d6.loss_cls: 0.1006  decode.d6.loss_mask: 0.2103  decode.d6.loss_dice: 0.2305  decode.d7.loss_cls: 0.1537  decode.d7.loss_mask: 0.2076  decode.d7.loss_dice: 0.2324  decode.d8.loss_cls: 0.1002  decode.d8.loss_mask: 0.2071  decode.d8.loss_dice: 0.2198
08/06 09:13:16 - mmengine - INFO - Iter(train) [ 50250/320000]  base_lr: 8.5749e-05 lr: 8.5749e-06  eta: 1 day, 12:54:29  time: 0.4943  data_time: 0.0111  memory: 5891  grad_norm: 66.7505  loss: 7.0127  decode.loss_cls: 0.0857  decode.loss_mask: 0.2328  decode.loss_dice: 0.2928  decode.d0.loss_cls: 0.8678  decode.d0.loss_mask: 0.2336  decode.d0.loss_dice: 0.2868  decode.d1.loss_cls: 0.0824  decode.d1.loss_mask: 0.2356  decode.d1.loss_dice: 0.2916  decode.d2.loss_cls: 0.0788  decode.d2.loss_mask: 0.2311  decode.d2.loss_dice: 0.2827  decode.d3.loss_cls: 0.1314  decode.d3.loss_mask: 0.2327  decode.d3.loss_dice: 0.3004  decode.d4.loss_cls: 0.1446  decode.d4.loss_mask: 0.2286  decode.d4.loss_dice: 0.2786  decode.d5.loss_cls: 0.1414  decode.d5.loss_mask: 0.2302  decode.d5.loss_dice: 0.2814  decode.d6.loss_cls: 0.0785  decode.d6.loss_mask: 0.2329  decode.d6.loss_dice: 0.2890  decode.d7.loss_cls: 0.1259  decode.d7.loss_mask: 0.2276  decode.d7.loss_dice: 0.2816  decode.d8.loss_cls: 0.0892  decode.d8.loss_mask: 0.2314  decode.d8.loss_dice: 0.2856
08/06 09:13:40 - mmengine - INFO - Iter(train) [ 50300/320000]  base_lr: 8.5735e-05 lr: 8.5735e-06  eta: 1 day, 12:54:04  time: 0.4953  data_time: 0.0112  memory: 5894  grad_norm: 92.1733  loss: 7.0422  decode.loss_cls: 0.1357  decode.loss_mask: 0.2401  decode.loss_dice: 0.2970  decode.d0.loss_cls: 0.7176  decode.d0.loss_mask: 0.2448  decode.d0.loss_dice: 0.2993  decode.d1.loss_cls: 0.1280  decode.d1.loss_mask: 0.2427  decode.d1.loss_dice: 0.2748  decode.d2.loss_cls: 0.0799  decode.d2.loss_mask: 0.2423  decode.d2.loss_dice: 0.2875  decode.d3.loss_cls: 0.0859  decode.d3.loss_mask: 0.2417  decode.d3.loss_dice: 0.2844  decode.d4.loss_cls: 0.1332  decode.d4.loss_mask: 0.2432  decode.d4.loss_dice: 0.2977  decode.d5.loss_cls: 0.0830  decode.d5.loss_mask: 0.2456  decode.d5.loss_dice: 0.2956  decode.d6.loss_cls: 0.1333  decode.d6.loss_mask: 0.2467  decode.d6.loss_dice: 0.3014  decode.d7.loss_cls: 0.1191  decode.d7.loss_mask: 0.2449  decode.d7.loss_dice: 0.2912  decode.d8.loss_cls: 0.0663  decode.d8.loss_mask: 0.2418  decode.d8.loss_dice: 0.2977
08/06 09:14:05 - mmengine - INFO - Iter(train) [ 50350/320000]  base_lr: 8.5721e-05 lr: 8.5721e-06  eta: 1 day, 12:53:40  time: 0.4942  data_time: 0.0112  memory: 5913  grad_norm: 100.0897  loss: 6.7817  decode.loss_cls: 0.1304  decode.loss_mask: 0.2237  decode.loss_dice: 0.2691  decode.d0.loss_cls: 0.9120  decode.d0.loss_mask: 0.2248  decode.d0.loss_dice: 0.2849  decode.d1.loss_cls: 0.1186  decode.d1.loss_mask: 0.2249  decode.d1.loss_dice: 0.2837  decode.d2.loss_cls: 0.1052  decode.d2.loss_mask: 0.2294  decode.d2.loss_dice: 0.2833  decode.d3.loss_cls: 0.0850  decode.d3.loss_mask: 0.2286  decode.d3.loss_dice: 0.2706  decode.d4.loss_cls: 0.0587  decode.d4.loss_mask: 0.2283  decode.d4.loss_dice: 0.2789  decode.d5.loss_cls: 0.0855  decode.d5.loss_mask: 0.2272  decode.d5.loss_dice: 0.2708  decode.d6.loss_cls: 0.0930  decode.d6.loss_mask: 0.2270  decode.d6.loss_dice: 0.2596  decode.d7.loss_cls: 0.1040  decode.d7.loss_mask: 0.2291  decode.d7.loss_dice: 0.2762  decode.d8.loss_cls: 0.0623  decode.d8.loss_mask: 0.2268  decode.d8.loss_dice: 0.2800
08/06 09:14:30 - mmengine - INFO - Iter(train) [ 50400/320000]  base_lr: 8.5707e-05 lr: 8.5707e-06  eta: 1 day, 12:53:16  time: 0.4939  data_time: 0.0112  memory: 5911  grad_norm: 140.2304  loss: 7.2876  decode.loss_cls: 0.0792  decode.loss_mask: 0.2476  decode.loss_dice: 0.3000  decode.d0.loss_cls: 0.8509  decode.d0.loss_mask: 0.2538  decode.d0.loss_dice: 0.3188  decode.d1.loss_cls: 0.1231  decode.d1.loss_mask: 0.2511  decode.d1.loss_dice: 0.3244  decode.d2.loss_cls: 0.1074  decode.d2.loss_mask: 0.2459  decode.d2.loss_dice: 0.3016  decode.d3.loss_cls: 0.1140  decode.d3.loss_mask: 0.2472  decode.d3.loss_dice: 0.2936  decode.d4.loss_cls: 0.0781  decode.d4.loss_mask: 0.2524  decode.d4.loss_dice: 0.3071  decode.d5.loss_cls: 0.0936  decode.d5.loss_mask: 0.2483  decode.d5.loss_dice: 0.3055  decode.d6.loss_cls: 0.1113  decode.d6.loss_mask: 0.2508  decode.d6.loss_dice: 0.2994  decode.d7.loss_cls: 0.1006  decode.d7.loss_mask: 0.2506  decode.d7.loss_dice: 0.2998  decode.d8.loss_cls: 0.0808  decode.d8.loss_mask: 0.2501  decode.d8.loss_dice: 0.3006
08/06 09:14:54 - mmengine - INFO - Iter(train) [ 50450/320000]  base_lr: 8.5692e-05 lr: 8.5692e-06  eta: 1 day, 12:52:52  time: 0.4946  data_time: 0.0112  memory: 5894  grad_norm: 104.3940  loss: 5.8825  decode.loss_cls: 0.0706  decode.loss_mask: 0.2045  decode.loss_dice: 0.2381  decode.d0.loss_cls: 0.8546  decode.d0.loss_mask: 0.2043  decode.d0.loss_dice: 0.2339  decode.d1.loss_cls: 0.0722  decode.d1.loss_mask: 0.2041  decode.d1.loss_dice: 0.2426  decode.d2.loss_cls: 0.0808  decode.d2.loss_mask: 0.2070  decode.d2.loss_dice: 0.2549  decode.d3.loss_cls: 0.0868  decode.d3.loss_mask: 0.2093  decode.d3.loss_dice: 0.2462  decode.d4.loss_cls: 0.0487  decode.d4.loss_mask: 0.2027  decode.d4.loss_dice: 0.2447  decode.d5.loss_cls: 0.0455  decode.d5.loss_mask: 0.2022  decode.d5.loss_dice: 0.2350  decode.d6.loss_cls: 0.0650  decode.d6.loss_mask: 0.2038  decode.d6.loss_dice: 0.2383  decode.d7.loss_cls: 0.0529  decode.d7.loss_mask: 0.2024  decode.d7.loss_dice: 0.2416  decode.d8.loss_cls: 0.0400  decode.d8.loss_mask: 0.2055  decode.d8.loss_dice: 0.2441
08/06 09:15:19 - mmengine - INFO - Iter(train) [ 50500/320000]  base_lr: 8.5678e-05 lr: 8.5678e-06  eta: 1 day, 12:52:28  time: 0.4949  data_time: 0.0112  memory: 5894  grad_norm: 130.9536  loss: 7.4094  decode.loss_cls: 0.1418  decode.loss_mask: 0.2135  decode.loss_dice: 0.2849  decode.d0.loss_cls: 1.0656  decode.d0.loss_mask: 0.1985  decode.d0.loss_dice: 0.2703  decode.d1.loss_cls: 0.1967  decode.d1.loss_mask: 0.2198  decode.d1.loss_dice: 0.2869  decode.d2.loss_cls: 0.2006  decode.d2.loss_mask: 0.1981  decode.d2.loss_dice: 0.2793  decode.d3.loss_cls: 0.1360  decode.d3.loss_mask: 0.2295  decode.d3.loss_dice: 0.2690  decode.d4.loss_cls: 0.0985  decode.d4.loss_mask: 0.2311  decode.d4.loss_dice: 0.2725  decode.d5.loss_cls: 0.1483  decode.d5.loss_mask: 0.2391  decode.d5.loss_dice: 0.2618  decode.d6.loss_cls: 0.2031  decode.d6.loss_mask: 0.1950  decode.d6.loss_dice: 0.2463  decode.d7.loss_cls: 0.1264  decode.d7.loss_mask: 0.2437  decode.d7.loss_dice: 0.2792  decode.d8.loss_cls: 0.2289  decode.d8.loss_mask: 0.1965  decode.d8.loss_dice: 0.2487
08/06 09:15:44 - mmengine - INFO - Iter(train) [ 50550/320000]  base_lr: 8.5664e-05 lr: 8.5664e-06  eta: 1 day, 12:52:04  time: 0.4946  data_time: 0.0112  memory: 5911  grad_norm: 142.4960  loss: 6.4482  decode.loss_cls: 0.1415  decode.loss_mask: 0.2163  decode.loss_dice: 0.2030  decode.d0.loss_cls: 0.8613  decode.d0.loss_mask: 0.2198  decode.d0.loss_dice: 0.2142  decode.d1.loss_cls: 0.1275  decode.d1.loss_mask: 0.2163  decode.d1.loss_dice: 0.2153  decode.d2.loss_cls: 0.1165  decode.d2.loss_mask: 0.2170  decode.d2.loss_dice: 0.2230  decode.d3.loss_cls: 0.1100  decode.d3.loss_mask: 0.2134  decode.d3.loss_dice: 0.2119  decode.d4.loss_cls: 0.1858  decode.d4.loss_mask: 0.2159  decode.d4.loss_dice: 0.2076  decode.d5.loss_cls: 0.1727  decode.d5.loss_mask: 0.2150  decode.d5.loss_dice: 0.2002  decode.d6.loss_cls: 0.1839  decode.d6.loss_mask: 0.2182  decode.d6.loss_dice: 0.2077  decode.d7.loss_cls: 0.1662  decode.d7.loss_mask: 0.2162  decode.d7.loss_dice: 0.2063  decode.d8.loss_cls: 0.1302  decode.d8.loss_mask: 0.2139  decode.d8.loss_dice: 0.2014
08/06 09:16:09 - mmengine - INFO - Iter(train) [ 50600/320000]  base_lr: 8.5649e-05 lr: 8.5649e-06  eta: 1 day, 12:51:40  time: 0.4942  data_time: 0.0114  memory: 5928  grad_norm: 223.4603  loss: 7.0885  decode.loss_cls: 0.1345  decode.loss_mask: 0.2177  decode.loss_dice: 0.2279  decode.d0.loss_cls: 0.9810  decode.d0.loss_mask: 0.2521  decode.d0.loss_dice: 0.2754  decode.d1.loss_cls: 0.2187  decode.d1.loss_mask: 0.2331  decode.d1.loss_dice: 0.2367  decode.d2.loss_cls: 0.1634  decode.d2.loss_mask: 0.2237  decode.d2.loss_dice: 0.2453  decode.d3.loss_cls: 0.1260  decode.d3.loss_mask: 0.2254  decode.d3.loss_dice: 0.2264  decode.d4.loss_cls: 0.1611  decode.d4.loss_mask: 0.2172  decode.d4.loss_dice: 0.2586  decode.d5.loss_cls: 0.1872  decode.d5.loss_mask: 0.2206  decode.d5.loss_dice: 0.2281  decode.d6.loss_cls: 0.1600  decode.d6.loss_mask: 0.2173  decode.d6.loss_dice: 0.2399  decode.d7.loss_cls: 0.1473  decode.d7.loss_mask: 0.2228  decode.d7.loss_dice: 0.2237  decode.d8.loss_cls: 0.1563  decode.d8.loss_mask: 0.2199  decode.d8.loss_dice: 0.2414
08/06 09:16:33 - mmengine - INFO - Iter(train) [ 50650/320000]  base_lr: 8.5635e-05 lr: 8.5635e-06  eta: 1 day, 12:51:16  time: 0.4940  data_time: 0.0111  memory: 5931  grad_norm: 53.0449  loss: 7.1449  decode.loss_cls: 0.1616  decode.loss_mask: 0.1961  decode.loss_dice: 0.2674  decode.d0.loss_cls: 0.9091  decode.d0.loss_mask: 0.2016  decode.d0.loss_dice: 0.2767  decode.d1.loss_cls: 0.2104  decode.d1.loss_mask: 0.1995  decode.d1.loss_dice: 0.2773  decode.d2.loss_cls: 0.1828  decode.d2.loss_mask: 0.1974  decode.d2.loss_dice: 0.2768  decode.d3.loss_cls: 0.1236  decode.d3.loss_mask: 0.1969  decode.d3.loss_dice: 0.2407  decode.d4.loss_cls: 0.1719  decode.d4.loss_mask: 0.1965  decode.d4.loss_dice: 0.2808  decode.d5.loss_cls: 0.1841  decode.d5.loss_mask: 0.1987  decode.d5.loss_dice: 0.2524  decode.d6.loss_cls: 0.1509  decode.d6.loss_mask: 0.1975  decode.d6.loss_dice: 0.2450  decode.d7.loss_cls: 0.2505  decode.d7.loss_mask: 0.1980  decode.d7.loss_dice: 0.2716  decode.d8.loss_cls: 0.1590  decode.d8.loss_mask: 0.1973  decode.d8.loss_dice: 0.2729
08/06 09:16:58 - mmengine - INFO - Iter(train) [ 50700/320000]  base_lr: 8.5621e-05 lr: 8.5621e-06  eta: 1 day, 12:50:52  time: 0.4957  data_time: 0.0113  memory: 5911  grad_norm: 82.3940  loss: 6.9031  decode.loss_cls: 0.0671  decode.loss_mask: 0.3459  decode.loss_dice: 0.2965  decode.d0.loss_cls: 0.8402  decode.d0.loss_mask: 0.2200  decode.d0.loss_dice: 0.2506  decode.d1.loss_cls: 0.1486  decode.d1.loss_mask: 0.2012  decode.d1.loss_dice: 0.2472  decode.d2.loss_cls: 0.1113  decode.d2.loss_mask: 0.2101  decode.d2.loss_dice: 0.2622  decode.d3.loss_cls: 0.1020  decode.d3.loss_mask: 0.2068  decode.d3.loss_dice: 0.2460  decode.d4.loss_cls: 0.1111  decode.d4.loss_mask: 0.2028  decode.d4.loss_dice: 0.2485  decode.d5.loss_cls: 0.0773  decode.d5.loss_mask: 0.2095  decode.d5.loss_dice: 0.2647  decode.d6.loss_cls: 0.0274  decode.d6.loss_mask: 0.3545  decode.d6.loss_dice: 0.2879  decode.d7.loss_cls: 0.1375  decode.d7.loss_mask: 0.2401  decode.d7.loss_dice: 0.2768  decode.d8.loss_cls: 0.0595  decode.d8.loss_mask: 0.3524  decode.d8.loss_dice: 0.2974
08/06 09:17:23 - mmengine - INFO - Iter(train) [ 50750/320000]  base_lr: 8.5606e-05 lr: 8.5606e-06  eta: 1 day, 12:50:28  time: 0.4953  data_time: 0.0111  memory: 5925  grad_norm: 166.1182  loss: 7.0690  decode.loss_cls: 0.2016  decode.loss_mask: 0.1800  decode.loss_dice: 0.2475  decode.d0.loss_cls: 1.0089  decode.d0.loss_mask: 0.1896  decode.d0.loss_dice: 0.2782  decode.d1.loss_cls: 0.1886  decode.d1.loss_mask: 0.1830  decode.d1.loss_dice: 0.2604  decode.d2.loss_cls: 0.2088  decode.d2.loss_mask: 0.1808  decode.d2.loss_dice: 0.2519  decode.d3.loss_cls: 0.1925  decode.d3.loss_mask: 0.1818  decode.d3.loss_dice: 0.2535  decode.d4.loss_cls: 0.1564  decode.d4.loss_mask: 0.1812  decode.d4.loss_dice: 0.2288  decode.d5.loss_cls: 0.2199  decode.d5.loss_mask: 0.1827  decode.d5.loss_dice: 0.2589  decode.d6.loss_cls: 0.1997  decode.d6.loss_mask: 0.1816  decode.d6.loss_dice: 0.2460  decode.d7.loss_cls: 0.1696  decode.d7.loss_mask: 0.1841  decode.d7.loss_dice: 0.2363  decode.d8.loss_cls: 0.1792  decode.d8.loss_mask: 0.1805  decode.d8.loss_dice: 0.2571
08/06 09:17:48 - mmengine - INFO - Iter(train) [ 50800/320000]  base_lr: 8.5592e-05 lr: 8.5592e-06  eta: 1 day, 12:50:04  time: 0.4966  data_time: 0.0113  memory: 5911  grad_norm: 151.0424  loss: 7.4561  decode.loss_cls: 0.1154  decode.loss_mask: 0.2294  decode.loss_dice: 0.2896  decode.d0.loss_cls: 0.9143  decode.d0.loss_mask: 0.2387  decode.d0.loss_dice: 0.3170  decode.d1.loss_cls: 0.1364  decode.d1.loss_mask: 0.2282  decode.d1.loss_dice: 0.2975  decode.d2.loss_cls: 0.1414  decode.d2.loss_mask: 0.2326  decode.d2.loss_dice: 0.2952  decode.d3.loss_cls: 0.1625  decode.d3.loss_mask: 0.2294  decode.d3.loss_dice: 0.2933  decode.d4.loss_cls: 0.1584  decode.d4.loss_mask: 0.2287  decode.d4.loss_dice: 0.2944  decode.d5.loss_cls: 0.1408  decode.d5.loss_mask: 0.2323  decode.d5.loss_dice: 0.2958  decode.d6.loss_cls: 0.1680  decode.d6.loss_mask: 0.2295  decode.d6.loss_dice: 0.2861  decode.d7.loss_cls: 0.1219  decode.d7.loss_mask: 0.2278  decode.d7.loss_dice: 0.2853  decode.d8.loss_cls: 0.1460  decode.d8.loss_mask: 0.2285  decode.d8.loss_dice: 0.2916
08/06 09:18:13 - mmengine - INFO - Iter(train) [ 50850/320000]  base_lr: 8.5578e-05 lr: 8.5578e-06  eta: 1 day, 12:49:41  time: 0.4955  data_time: 0.0113  memory: 5894  grad_norm: 122.2210  loss: 7.4094  decode.loss_cls: 0.1631  decode.loss_mask: 0.2120  decode.loss_dice: 0.2991  decode.d0.loss_cls: 0.9359  decode.d0.loss_mask: 0.2132  decode.d0.loss_dice: 0.3198  decode.d1.loss_cls: 0.1885  decode.d1.loss_mask: 0.2065  decode.d1.loss_dice: 0.2848  decode.d2.loss_cls: 0.1574  decode.d2.loss_mask: 0.2097  decode.d2.loss_dice: 0.2751  decode.d3.loss_cls: 0.1710  decode.d3.loss_mask: 0.2110  decode.d3.loss_dice: 0.2921  decode.d4.loss_cls: 0.1577  decode.d4.loss_mask: 0.2116  decode.d4.loss_dice: 0.3112  decode.d5.loss_cls: 0.1234  decode.d5.loss_mask: 0.2135  decode.d5.loss_dice: 0.3031  decode.d6.loss_cls: 0.1507  decode.d6.loss_mask: 0.2142  decode.d6.loss_dice: 0.2990  decode.d7.loss_cls: 0.1366  decode.d7.loss_mask: 0.2054  decode.d7.loss_dice: 0.2955  decode.d8.loss_cls: 0.1495  decode.d8.loss_mask: 0.2035  decode.d8.loss_dice: 0.2953
08/06 09:18:37 - mmengine - INFO - Iter(train) [ 50900/320000]  base_lr: 8.5564e-05 lr: 8.5564e-06  eta: 1 day, 12:49:17  time: 0.4958  data_time: 0.0114  memory: 5894  grad_norm: 129.8500  loss: 8.2711  decode.loss_cls: 0.0914  decode.loss_mask: 0.3029  decode.loss_dice: 0.2957  decode.d0.loss_cls: 0.9060  decode.d0.loss_mask: 0.3227  decode.d0.loss_dice: 0.3005  decode.d1.loss_cls: 0.1546  decode.d1.loss_mask: 0.3133  decode.d1.loss_dice: 0.3206  decode.d2.loss_cls: 0.1780  decode.d2.loss_mask: 0.3013  decode.d2.loss_dice: 0.2997  decode.d3.loss_cls: 0.1808  decode.d3.loss_mask: 0.3053  decode.d3.loss_dice: 0.3086  decode.d4.loss_cls: 0.1368  decode.d4.loss_mask: 0.3044  decode.d4.loss_dice: 0.3141  decode.d5.loss_cls: 0.1327  decode.d5.loss_mask: 0.3064  decode.d5.loss_dice: 0.2674  decode.d6.loss_cls: 0.1597  decode.d6.loss_mask: 0.3019  decode.d6.loss_dice: 0.3041  decode.d7.loss_cls: 0.1392  decode.d7.loss_mask: 0.3026  decode.d7.loss_dice: 0.2848  decode.d8.loss_cls: 0.1373  decode.d8.loss_mask: 0.3069  decode.d8.loss_dice: 0.2912
08/06 09:19:02 - mmengine - INFO - Iter(train) [ 50950/320000]  base_lr: 8.5549e-05 lr: 8.5549e-06  eta: 1 day, 12:48:54  time: 0.4968  data_time: 0.0115  memory: 5928  grad_norm: 127.1253  loss: 7.4281  decode.loss_cls: 0.1010  decode.loss_mask: 0.2723  decode.loss_dice: 0.2692  decode.d0.loss_cls: 0.8443  decode.d0.loss_mask: 0.2775  decode.d0.loss_dice: 0.2552  decode.d1.loss_cls: 0.1873  decode.d1.loss_mask: 0.2784  decode.d1.loss_dice: 0.2632  decode.d2.loss_cls: 0.1523  decode.d2.loss_mask: 0.2805  decode.d2.loss_dice: 0.2591  decode.d3.loss_cls: 0.1602  decode.d3.loss_mask: 0.2762  decode.d3.loss_dice: 0.2533  decode.d4.loss_cls: 0.1364  decode.d4.loss_mask: 0.2761  decode.d4.loss_dice: 0.2570  decode.d5.loss_cls: 0.1358  decode.d5.loss_mask: 0.2780  decode.d5.loss_dice: 0.2706  decode.d6.loss_cls: 0.1194  decode.d6.loss_mask: 0.2799  decode.d6.loss_dice: 0.2593  decode.d7.loss_cls: 0.1172  decode.d7.loss_mask: 0.2762  decode.d7.loss_dice: 0.2560  decode.d8.loss_cls: 0.1078  decode.d8.loss_mask: 0.2711  decode.d8.loss_dice: 0.2573
08/06 09:19:27 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 09:19:27 - mmengine - INFO - Iter(train) [ 51000/320000]  base_lr: 8.5535e-05 lr: 8.5535e-06  eta: 1 day, 12:48:30  time: 0.4960  data_time: 0.0114  memory: 5875  grad_norm: 196.0418  loss: 8.2876  decode.loss_cls: 0.3184  decode.loss_mask: 0.1965  decode.loss_dice: 0.2210  decode.d0.loss_cls: 1.0076  decode.d0.loss_mask: 0.2081  decode.d0.loss_dice: 0.2468  decode.d1.loss_cls: 0.2521  decode.d1.loss_mask: 0.2019  decode.d1.loss_dice: 0.2308  decode.d2.loss_cls: 0.3252  decode.d2.loss_mask: 0.1953  decode.d2.loss_dice: 0.2164  decode.d3.loss_cls: 0.3174  decode.d3.loss_mask: 0.2088  decode.d3.loss_dice: 0.2388  decode.d4.loss_cls: 0.4018  decode.d4.loss_mask: 0.1998  decode.d4.loss_dice: 0.2301  decode.d5.loss_cls: 0.3841  decode.d5.loss_mask: 0.1954  decode.d5.loss_dice: 0.2215  decode.d6.loss_cls: 0.3696  decode.d6.loss_mask: 0.1946  decode.d6.loss_dice: 0.2219  decode.d7.loss_cls: 0.3038  decode.d7.loss_mask: 0.1984  decode.d7.loss_dice: 0.2310  decode.d8.loss_cls: 0.3022  decode.d8.loss_mask: 0.2105  decode.d8.loss_dice: 0.2381
08/06 09:19:52 - mmengine - INFO - Iter(train) [ 51050/320000]  base_lr: 8.5521e-05 lr: 8.5521e-06  eta: 1 day, 12:48:06  time: 0.4958  data_time: 0.0112  memory: 5878  grad_norm: 88.3666  loss: 6.5321  decode.loss_cls: 0.0598  decode.loss_mask: 0.2631  decode.loss_dice: 0.2439  decode.d0.loss_cls: 0.8004  decode.d0.loss_mask: 0.2672  decode.d0.loss_dice: 0.2402  decode.d1.loss_cls: 0.0561  decode.d1.loss_mask: 0.2817  decode.d1.loss_dice: 0.2550  decode.d2.loss_cls: 0.0872  decode.d2.loss_mask: 0.2718  decode.d2.loss_dice: 0.2406  decode.d3.loss_cls: 0.0587  decode.d3.loss_mask: 0.2723  decode.d3.loss_dice: 0.2377  decode.d4.loss_cls: 0.0645  decode.d4.loss_mask: 0.2745  decode.d4.loss_dice: 0.2362  decode.d5.loss_cls: 0.0661  decode.d5.loss_mask: 0.2727  decode.d5.loss_dice: 0.2383  decode.d6.loss_cls: 0.0425  decode.d6.loss_mask: 0.2774  decode.d6.loss_dice: 0.2733  decode.d7.loss_cls: 0.0547  decode.d7.loss_mask: 0.2771  decode.d7.loss_dice: 0.2445  decode.d8.loss_cls: 0.0689  decode.d8.loss_mask: 0.2684  decode.d8.loss_dice: 0.2374
08/06 09:20:17 - mmengine - INFO - Iter(train) [ 51100/320000]  base_lr: 8.5506e-05 lr: 8.5506e-06  eta: 1 day, 12:47:42  time: 0.4952  data_time: 0.0113  memory: 5911  grad_norm: 74.4497  loss: 8.7508  decode.loss_cls: 0.3008  decode.loss_mask: 0.2693  decode.loss_dice: 0.2656  decode.d0.loss_cls: 1.0112  decode.d0.loss_mask: 0.2513  decode.d0.loss_dice: 0.2829  decode.d1.loss_cls: 0.2928  decode.d1.loss_mask: 0.2429  decode.d1.loss_dice: 0.2838  decode.d2.loss_cls: 0.2898  decode.d2.loss_mask: 0.2500  decode.d2.loss_dice: 0.2667  decode.d3.loss_cls: 0.2817  decode.d3.loss_mask: 0.2509  decode.d3.loss_dice: 0.3022  decode.d4.loss_cls: 0.2786  decode.d4.loss_mask: 0.2480  decode.d4.loss_dice: 0.2581  decode.d5.loss_cls: 0.2775  decode.d5.loss_mask: 0.2418  decode.d5.loss_dice: 0.2676  decode.d6.loss_cls: 0.2456  decode.d6.loss_mask: 0.2338  decode.d6.loss_dice: 0.2678  decode.d7.loss_cls: 0.3112  decode.d7.loss_mask: 0.2411  decode.d7.loss_dice: 0.2586  decode.d8.loss_cls: 0.2755  decode.d8.loss_mask: 0.2505  decode.d8.loss_dice: 0.2531
08/06 09:20:41 - mmengine - INFO - Iter(train) [ 51150/320000]  base_lr: 8.5492e-05 lr: 8.5492e-06  eta: 1 day, 12:47:18  time: 0.4941  data_time: 0.0113  memory: 5894  grad_norm: 193.1870  loss: 7.6729  decode.loss_cls: 0.1801  decode.loss_mask: 0.2455  decode.loss_dice: 0.2676  decode.d0.loss_cls: 1.0490  decode.d0.loss_mask: 0.2543  decode.d0.loss_dice: 0.2793  decode.d1.loss_cls: 0.1201  decode.d1.loss_mask: 0.2572  decode.d1.loss_dice: 0.2685  decode.d2.loss_cls: 0.2075  decode.d2.loss_mask: 0.2525  decode.d2.loss_dice: 0.2787  decode.d3.loss_cls: 0.1349  decode.d3.loss_mask: 0.2477  decode.d3.loss_dice: 0.2651  decode.d4.loss_cls: 0.1413  decode.d4.loss_mask: 0.2548  decode.d4.loss_dice: 0.2638  decode.d5.loss_cls: 0.1478  decode.d5.loss_mask: 0.2556  decode.d5.loss_dice: 0.2708  decode.d6.loss_cls: 0.1724  decode.d6.loss_mask: 0.2518  decode.d6.loss_dice: 0.2410  decode.d7.loss_cls: 0.1545  decode.d7.loss_mask: 0.2530  decode.d7.loss_dice: 0.2819  decode.d8.loss_cls: 0.1605  decode.d8.loss_mask: 0.2542  decode.d8.loss_dice: 0.2615
08/06 09:21:06 - mmengine - INFO - Iter(train) [ 51200/320000]  base_lr: 8.5478e-05 lr: 8.5478e-06  eta: 1 day, 12:46:54  time: 0.4953  data_time: 0.0113  memory: 5911  grad_norm: 238.7018  loss: 7.8469  decode.loss_cls: 0.0801  decode.loss_mask: 0.2778  decode.loss_dice: 0.3198  decode.d0.loss_cls: 0.9120  decode.d0.loss_mask: 0.2715  decode.d0.loss_dice: 0.3172  decode.d1.loss_cls: 0.1580  decode.d1.loss_mask: 0.2685  decode.d1.loss_dice: 0.3091  decode.d2.loss_cls: 0.1353  decode.d2.loss_mask: 0.2671  decode.d2.loss_dice: 0.3037  decode.d3.loss_cls: 0.1355  decode.d3.loss_mask: 0.2619  decode.d3.loss_dice: 0.3016  decode.d4.loss_cls: 0.1356  decode.d4.loss_mask: 0.2600  decode.d4.loss_dice: 0.3133  decode.d5.loss_cls: 0.1413  decode.d5.loss_mask: 0.2585  decode.d5.loss_dice: 0.3117  decode.d6.loss_cls: 0.1454  decode.d6.loss_mask: 0.2611  decode.d6.loss_dice: 0.3107  decode.d7.loss_cls: 0.0768  decode.d7.loss_mask: 0.2869  decode.d7.loss_dice: 0.3130  decode.d8.loss_cls: 0.1275  decode.d8.loss_mask: 0.2737  decode.d8.loss_dice: 0.3124
08/06 09:21:31 - mmengine - INFO - Iter(train) [ 51250/320000]  base_lr: 8.5463e-05 lr: 8.5463e-06  eta: 1 day, 12:46:30  time: 0.4948  data_time: 0.0113  memory: 5911  grad_norm: 150.4967  loss: 10.5798  decode.loss_cls: 0.2242  decode.loss_mask: 0.2936  decode.loss_dice: 0.4310  decode.d0.loss_cls: 1.0033  decode.d0.loss_mask: 0.3008  decode.d0.loss_dice: 0.4217  decode.d1.loss_cls: 0.3117  decode.d1.loss_mask: 0.3055  decode.d1.loss_dice: 0.4195  decode.d2.loss_cls: 0.3322  decode.d2.loss_mask: 0.2919  decode.d2.loss_dice: 0.3922  decode.d3.loss_cls: 0.2710  decode.d3.loss_mask: 0.2950  decode.d3.loss_dice: 0.3906  decode.d4.loss_cls: 0.2437  decode.d4.loss_mask: 0.2965  decode.d4.loss_dice: 0.4222  decode.d5.loss_cls: 0.2921  decode.d5.loss_mask: 0.2939  decode.d5.loss_dice: 0.3972  decode.d6.loss_cls: 0.2809  decode.d6.loss_mask: 0.2965  decode.d6.loss_dice: 0.3948  decode.d7.loss_cls: 0.2894  decode.d7.loss_mask: 0.2998  decode.d7.loss_dice: 0.4179  decode.d8.loss_cls: 0.2495  decode.d8.loss_mask: 0.3085  decode.d8.loss_dice: 0.4126
08/06 09:21:56 - mmengine - INFO - Iter(train) [ 51300/320000]  base_lr: 8.5449e-05 lr: 8.5449e-06  eta: 1 day, 12:46:06  time: 0.4945  data_time: 0.0112  memory: 5894  grad_norm: 154.1445  loss: 7.4518  decode.loss_cls: 0.1769  decode.loss_mask: 0.1947  decode.loss_dice: 0.2729  decode.d0.loss_cls: 0.9512  decode.d0.loss_mask: 0.1986  decode.d0.loss_dice: 0.2918  decode.d1.loss_cls: 0.2077  decode.d1.loss_mask: 0.1946  decode.d1.loss_dice: 0.2844  decode.d2.loss_cls: 0.1994  decode.d2.loss_mask: 0.1912  decode.d2.loss_dice: 0.2724  decode.d3.loss_cls: 0.1820  decode.d3.loss_mask: 0.1994  decode.d3.loss_dice: 0.2811  decode.d4.loss_cls: 0.2196  decode.d4.loss_mask: 0.1933  decode.d4.loss_dice: 0.2706  decode.d5.loss_cls: 0.1819  decode.d5.loss_mask: 0.1956  decode.d5.loss_dice: 0.2695  decode.d6.loss_cls: 0.1779  decode.d6.loss_mask: 0.1952  decode.d6.loss_dice: 0.2680  decode.d7.loss_cls: 0.2636  decode.d7.loss_mask: 0.1931  decode.d7.loss_dice: 0.2777  decode.d8.loss_cls: 0.1734  decode.d8.loss_mask: 0.1958  decode.d8.loss_dice: 0.2784
08/06 09:22:20 - mmengine - INFO - Iter(train) [ 51350/320000]  base_lr: 8.5435e-05 lr: 8.5435e-06  eta: 1 day, 12:45:42  time: 0.4948  data_time: 0.0113  memory: 5878  grad_norm: 100.1710  loss: 7.5841  decode.loss_cls: 0.0972  decode.loss_mask: 0.2857  decode.loss_dice: 0.2757  decode.d0.loss_cls: 0.8610  decode.d0.loss_mask: 0.2685  decode.d0.loss_dice: 0.2715  decode.d1.loss_cls: 0.1159  decode.d1.loss_mask: 0.2766  decode.d1.loss_dice: 0.2649  decode.d2.loss_cls: 0.1123  decode.d2.loss_mask: 0.2847  decode.d2.loss_dice: 0.2618  decode.d3.loss_cls: 0.1232  decode.d3.loss_mask: 0.3006  decode.d3.loss_dice: 0.2831  decode.d4.loss_cls: 0.1133  decode.d4.loss_mask: 0.3418  decode.d4.loss_dice: 0.2692  decode.d5.loss_cls: 0.1207  decode.d5.loss_mask: 0.3467  decode.d5.loss_dice: 0.2776  decode.d6.loss_cls: 0.1223  decode.d6.loss_mask: 0.2838  decode.d6.loss_dice: 0.2708  decode.d7.loss_cls: 0.1345  decode.d7.loss_mask: 0.2837  decode.d7.loss_dice: 0.2798  decode.d8.loss_cls: 0.1284  decode.d8.loss_mask: 0.2759  decode.d8.loss_dice: 0.2527
08/06 09:22:45 - mmengine - INFO - Iter(train) [ 51400/320000]  base_lr: 8.5420e-05 lr: 8.5420e-06  eta: 1 day, 12:45:18  time: 0.4944  data_time: 0.0112  memory: 5895  grad_norm: 53.0181  loss: 6.3206  decode.loss_cls: 0.0173  decode.loss_mask: 0.2262  decode.loss_dice: 0.2924  decode.d0.loss_cls: 0.8931  decode.d0.loss_mask: 0.2229  decode.d0.loss_dice: 0.2805  decode.d1.loss_cls: 0.0234  decode.d1.loss_mask: 0.2235  decode.d1.loss_dice: 0.2950  decode.d2.loss_cls: 0.0140  decode.d2.loss_mask: 0.2252  decode.d2.loss_dice: 0.2847  decode.d3.loss_cls: 0.0805  decode.d3.loss_mask: 0.2243  decode.d3.loss_dice: 0.2742  decode.d4.loss_cls: 0.0205  decode.d4.loss_mask: 0.2270  decode.d4.loss_dice: 0.2933  decode.d5.loss_cls: 0.0273  decode.d5.loss_mask: 0.2261  decode.d5.loss_dice: 0.2947  decode.d6.loss_cls: 0.0257  decode.d6.loss_mask: 0.2256  decode.d6.loss_dice: 0.2973  decode.d7.loss_cls: 0.0334  decode.d7.loss_mask: 0.2273  decode.d7.loss_dice: 0.2902  decode.d8.loss_cls: 0.0346  decode.d8.loss_mask: 0.2271  decode.d8.loss_dice: 0.2931
08/06 09:23:10 - mmengine - INFO - Iter(train) [ 51450/320000]  base_lr: 8.5406e-05 lr: 8.5406e-06  eta: 1 day, 12:44:54  time: 0.4950  data_time: 0.0113  memory: 5909  grad_norm: 42.4121  loss: 5.3492  decode.loss_cls: 0.0043  decode.loss_mask: 0.2303  decode.loss_dice: 0.2297  decode.d0.loss_cls: 0.7278  decode.d0.loss_mask: 0.2322  decode.d0.loss_dice: 0.2300  decode.d1.loss_cls: 0.0081  decode.d1.loss_mask: 0.2310  decode.d1.loss_dice: 0.2277  decode.d2.loss_cls: 0.0066  decode.d2.loss_mask: 0.2292  decode.d2.loss_dice: 0.2267  decode.d3.loss_cls: 0.0066  decode.d3.loss_mask: 0.2262  decode.d3.loss_dice: 0.2258  decode.d4.loss_cls: 0.0067  decode.d4.loss_mask: 0.2307  decode.d4.loss_dice: 0.2285  decode.d5.loss_cls: 0.0058  decode.d5.loss_mask: 0.2276  decode.d5.loss_dice: 0.2260  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.2274  decode.d6.loss_dice: 0.2229  decode.d7.loss_cls: 0.0046  decode.d7.loss_mask: 0.2284  decode.d7.loss_dice: 0.2270  decode.d8.loss_cls: 0.0057  decode.d8.loss_mask: 0.2275  decode.d8.loss_dice: 0.2326
08/06 09:23:35 - mmengine - INFO - Iter(train) [ 51500/320000]  base_lr: 8.5392e-05 lr: 8.5392e-06  eta: 1 day, 12:44:30  time: 0.4952  data_time: 0.0114  memory: 5894  grad_norm: 188.2159  loss: 7.6854  decode.loss_cls: 0.1215  decode.loss_mask: 0.2793  decode.loss_dice: 0.2680  decode.d0.loss_cls: 1.0435  decode.d0.loss_mask: 0.2486  decode.d0.loss_dice: 0.2415  decode.d1.loss_cls: 0.1705  decode.d1.loss_mask: 0.2571  decode.d1.loss_dice: 0.2572  decode.d2.loss_cls: 0.1563  decode.d2.loss_mask: 0.2520  decode.d2.loss_dice: 0.2458  decode.d3.loss_cls: 0.1481  decode.d3.loss_mask: 0.2852  decode.d3.loss_dice: 0.2549  decode.d4.loss_cls: 0.1844  decode.d4.loss_mask: 0.2716  decode.d4.loss_dice: 0.2697  decode.d5.loss_cls: 0.1936  decode.d5.loss_mask: 0.2723  decode.d5.loss_dice: 0.2462  decode.d6.loss_cls: 0.1501  decode.d6.loss_mask: 0.2868  decode.d6.loss_dice: 0.2476  decode.d7.loss_cls: 0.1580  decode.d7.loss_mask: 0.2723  decode.d7.loss_dice: 0.2546  decode.d8.loss_cls: 0.1612  decode.d8.loss_mask: 0.2516  decode.d8.loss_dice: 0.2360
08/06 09:23:59 - mmengine - INFO - Iter(train) [ 51550/320000]  base_lr: 8.5377e-05 lr: 8.5377e-06  eta: 1 day, 12:44:06  time: 0.4952  data_time: 0.0113  memory: 5895  grad_norm: 44.4901  loss: 5.4371  decode.loss_cls: 0.0677  decode.loss_mask: 0.2019  decode.loss_dice: 0.2312  decode.d0.loss_cls: 0.8626  decode.d0.loss_mask: 0.1917  decode.d0.loss_dice: 0.1985  decode.d1.loss_cls: 0.0744  decode.d1.loss_mask: 0.1913  decode.d1.loss_dice: 0.1949  decode.d2.loss_cls: 0.0480  decode.d2.loss_mask: 0.1922  decode.d2.loss_dice: 0.1967  decode.d3.loss_cls: 0.0446  decode.d3.loss_mask: 0.1936  decode.d3.loss_dice: 0.2055  decode.d4.loss_cls: 0.0404  decode.d4.loss_mask: 0.1913  decode.d4.loss_dice: 0.2035  decode.d5.loss_cls: 0.0496  decode.d5.loss_mask: 0.1910  decode.d5.loss_dice: 0.2060  decode.d6.loss_cls: 0.0501  decode.d6.loss_mask: 0.1925  decode.d6.loss_dice: 0.2191  decode.d7.loss_cls: 0.0577  decode.d7.loss_mask: 0.1990  decode.d7.loss_dice: 0.2343  decode.d8.loss_cls: 0.0591  decode.d8.loss_mask: 0.2058  decode.d8.loss_dice: 0.2428
08/06 09:24:24 - mmengine - INFO - Iter(train) [ 51600/320000]  base_lr: 8.5363e-05 lr: 8.5363e-06  eta: 1 day, 12:43:42  time: 0.4952  data_time: 0.0113  memory: 5909  grad_norm: 117.6416  loss: 5.8829  decode.loss_cls: 0.0914  decode.loss_mask: 0.1954  decode.loss_dice: 0.2182  decode.d0.loss_cls: 0.8766  decode.d0.loss_mask: 0.2009  decode.d0.loss_dice: 0.2325  decode.d1.loss_cls: 0.1059  decode.d1.loss_mask: 0.1956  decode.d1.loss_dice: 0.2255  decode.d2.loss_cls: 0.1264  decode.d2.loss_mask: 0.1930  decode.d2.loss_dice: 0.2130  decode.d3.loss_cls: 0.0883  decode.d3.loss_mask: 0.1939  decode.d3.loss_dice: 0.2145  decode.d4.loss_cls: 0.1029  decode.d4.loss_mask: 0.1943  decode.d4.loss_dice: 0.2207  decode.d5.loss_cls: 0.0920  decode.d5.loss_mask: 0.1930  decode.d5.loss_dice: 0.2211  decode.d6.loss_cls: 0.0795  decode.d6.loss_mask: 0.1912  decode.d6.loss_dice: 0.2121  decode.d7.loss_cls: 0.0882  decode.d7.loss_mask: 0.1942  decode.d7.loss_dice: 0.2295  decode.d8.loss_cls: 0.0907  decode.d8.loss_mask: 0.1927  decode.d8.loss_dice: 0.2096
08/06 09:24:49 - mmengine - INFO - Iter(train) [ 51650/320000]  base_lr: 8.5349e-05 lr: 8.5349e-06  eta: 1 day, 12:43:19  time: 0.4940  data_time: 0.0112  memory: 5894  grad_norm: 119.9520  loss: 6.4917  decode.loss_cls: 0.1109  decode.loss_mask: 0.2385  decode.loss_dice: 0.2323  decode.d0.loss_cls: 0.7710  decode.d0.loss_mask: 0.2373  decode.d0.loss_dice: 0.2259  decode.d1.loss_cls: 0.1394  decode.d1.loss_mask: 0.2362  decode.d1.loss_dice: 0.2308  decode.d2.loss_cls: 0.1115  decode.d2.loss_mask: 0.2379  decode.d2.loss_dice: 0.2273  decode.d3.loss_cls: 0.1070  decode.d3.loss_mask: 0.2382  decode.d3.loss_dice: 0.2251  decode.d4.loss_cls: 0.1419  decode.d4.loss_mask: 0.2347  decode.d4.loss_dice: 0.2210  decode.d5.loss_cls: 0.1129  decode.d5.loss_mask: 0.2354  decode.d5.loss_dice: 0.2270  decode.d6.loss_cls: 0.1207  decode.d6.loss_mask: 0.2361  decode.d6.loss_dice: 0.2067  decode.d7.loss_cls: 0.1499  decode.d7.loss_mask: 0.2346  decode.d7.loss_dice: 0.2243  decode.d8.loss_cls: 0.1121  decode.d8.loss_mask: 0.2347  decode.d8.loss_dice: 0.2304
08/06 09:25:14 - mmengine - INFO - Iter(train) [ 51700/320000]  base_lr: 8.5335e-05 lr: 8.5335e-06  eta: 1 day, 12:42:54  time: 0.4937  data_time: 0.0113  memory: 5911  grad_norm: 197.9579  loss: 8.2362  decode.loss_cls: 0.2061  decode.loss_mask: 0.2531  decode.loss_dice: 0.2630  decode.d0.loss_cls: 0.8287  decode.d0.loss_mask: 0.2601  decode.d0.loss_dice: 0.2973  decode.d1.loss_cls: 0.3662  decode.d1.loss_mask: 0.2535  decode.d1.loss_dice: 0.2781  decode.d2.loss_cls: 0.2451  decode.d2.loss_mask: 0.2538  decode.d2.loss_dice: 0.2640  decode.d3.loss_cls: 0.2012  decode.d3.loss_mask: 0.2568  decode.d3.loss_dice: 0.2766  decode.d4.loss_cls: 0.2264  decode.d4.loss_mask: 0.2499  decode.d4.loss_dice: 0.2768  decode.d5.loss_cls: 0.1722  decode.d5.loss_mask: 0.2795  decode.d5.loss_dice: 0.2739  decode.d6.loss_cls: 0.1805  decode.d6.loss_mask: 0.2743  decode.d6.loss_dice: 0.2737  decode.d7.loss_cls: 0.2628  decode.d7.loss_mask: 0.2584  decode.d7.loss_dice: 0.2888  decode.d8.loss_cls: 0.1742  decode.d8.loss_mask: 0.2702  decode.d8.loss_dice: 0.2712
08/06 09:25:39 - mmengine - INFO - Iter(train) [ 51750/320000]  base_lr: 8.5320e-05 lr: 8.5320e-06  eta: 1 day, 12:42:30  time: 0.4947  data_time: 0.0113  memory: 5913  grad_norm: 48.6216  loss: 6.7987  decode.loss_cls: 0.0506  decode.loss_mask: 0.2905  decode.loss_dice: 0.2583  decode.d0.loss_cls: 0.7765  decode.d0.loss_mask: 0.3042  decode.d0.loss_dice: 0.2638  decode.d1.loss_cls: 0.0451  decode.d1.loss_mask: 0.2918  decode.d1.loss_dice: 0.2603  decode.d2.loss_cls: 0.0733  decode.d2.loss_mask: 0.2915  decode.d2.loss_dice: 0.2590  decode.d3.loss_cls: 0.0631  decode.d3.loss_mask: 0.2926  decode.d3.loss_dice: 0.2591  decode.d4.loss_cls: 0.0620  decode.d4.loss_mask: 0.2894  decode.d4.loss_dice: 0.2614  decode.d5.loss_cls: 0.0565  decode.d5.loss_mask: 0.2896  decode.d5.loss_dice: 0.2609  decode.d6.loss_cls: 0.0277  decode.d6.loss_mask: 0.2942  decode.d6.loss_dice: 0.2634  decode.d7.loss_cls: 0.0489  decode.d7.loss_mask: 0.2902  decode.d7.loss_dice: 0.2616  decode.d8.loss_cls: 0.0675  decode.d8.loss_mask: 0.2897  decode.d8.loss_dice: 0.2561
08/06 09:26:03 - mmengine - INFO - Iter(train) [ 51800/320000]  base_lr: 8.5306e-05 lr: 8.5306e-06  eta: 1 day, 12:42:06  time: 0.4937  data_time: 0.0112  memory: 5874  grad_norm: 178.1431  loss: 7.4756  decode.loss_cls: 0.1630  decode.loss_mask: 0.2439  decode.loss_dice: 0.2473  decode.d0.loss_cls: 0.8062  decode.d0.loss_mask: 0.2516  decode.d0.loss_dice: 0.2790  decode.d1.loss_cls: 0.2122  decode.d1.loss_mask: 0.2446  decode.d1.loss_dice: 0.2465  decode.d2.loss_cls: 0.1645  decode.d2.loss_mask: 0.2461  decode.d2.loss_dice: 0.2628  decode.d3.loss_cls: 0.1641  decode.d3.loss_mask: 0.2445  decode.d3.loss_dice: 0.2454  decode.d4.loss_cls: 0.1817  decode.d4.loss_mask: 0.2454  decode.d4.loss_dice: 0.2626  decode.d5.loss_cls: 0.2019  decode.d5.loss_mask: 0.2440  decode.d5.loss_dice: 0.2812  decode.d6.loss_cls: 0.1709  decode.d6.loss_mask: 0.2430  decode.d6.loss_dice: 0.2307  decode.d7.loss_cls: 0.1791  decode.d7.loss_mask: 0.2439  decode.d7.loss_dice: 0.2737  decode.d8.loss_cls: 0.1935  decode.d8.loss_mask: 0.2456  decode.d8.loss_dice: 0.2567
08/06 09:26:28 - mmengine - INFO - Iter(train) [ 51850/320000]  base_lr: 8.5292e-05 lr: 8.5292e-06  eta: 1 day, 12:41:42  time: 0.4943  data_time: 0.0113  memory: 5894  grad_norm: 187.6819  loss: 8.2920  decode.loss_cls: 0.2108  decode.loss_mask: 0.2736  decode.loss_dice: 0.2954  decode.d0.loss_cls: 0.8251  decode.d0.loss_mask: 0.2846  decode.d0.loss_dice: 0.3237  decode.d1.loss_cls: 0.2013  decode.d1.loss_mask: 0.2764  decode.d1.loss_dice: 0.3105  decode.d2.loss_cls: 0.2149  decode.d2.loss_mask: 0.2719  decode.d2.loss_dice: 0.2953  decode.d3.loss_cls: 0.2210  decode.d3.loss_mask: 0.2668  decode.d3.loss_dice: 0.2833  decode.d4.loss_cls: 0.2197  decode.d4.loss_mask: 0.2738  decode.d4.loss_dice: 0.2969  decode.d5.loss_cls: 0.2198  decode.d5.loss_mask: 0.2715  decode.d5.loss_dice: 0.2964  decode.d6.loss_cls: 0.1542  decode.d6.loss_mask: 0.2800  decode.d6.loss_dice: 0.3047  decode.d7.loss_cls: 0.1573  decode.d7.loss_mask: 0.2700  decode.d7.loss_dice: 0.3099  decode.d8.loss_cls: 0.1210  decode.d8.loss_mask: 0.2772  decode.d8.loss_dice: 0.2851
08/06 09:26:53 - mmengine - INFO - Iter(train) [ 51900/320000]  base_lr: 8.5277e-05 lr: 8.5277e-06  eta: 1 day, 12:41:18  time: 0.4951  data_time: 0.0113  memory: 5911  grad_norm: 53.5333  loss: 7.5799  decode.loss_cls: 0.1770  decode.loss_mask: 0.2078  decode.loss_dice: 0.2786  decode.d0.loss_cls: 0.7819  decode.d0.loss_mask: 0.2124  decode.d0.loss_dice: 0.2963  decode.d1.loss_cls: 0.2426  decode.d1.loss_mask: 0.2082  decode.d1.loss_dice: 0.3005  decode.d2.loss_cls: 0.1558  decode.d2.loss_mask: 0.2082  decode.d2.loss_dice: 0.2844  decode.d3.loss_cls: 0.2346  decode.d3.loss_mask: 0.2090  decode.d3.loss_dice: 0.2783  decode.d4.loss_cls: 0.2227  decode.d4.loss_mask: 0.2108  decode.d4.loss_dice: 0.2840  decode.d5.loss_cls: 0.2230  decode.d5.loss_mask: 0.2087  decode.d5.loss_dice: 0.2788  decode.d6.loss_cls: 0.2539  decode.d6.loss_mask: 0.2068  decode.d6.loss_dice: 0.2990  decode.d7.loss_cls: 0.1424  decode.d7.loss_mask: 0.2107  decode.d7.loss_dice: 0.2960  decode.d8.loss_cls: 0.1669  decode.d8.loss_mask: 0.2052  decode.d8.loss_dice: 0.2954
08/06 09:27:18 - mmengine - INFO - Iter(train) [ 51950/320000]  base_lr: 8.5263e-05 lr: 8.5263e-06  eta: 1 day, 12:40:54  time: 0.4938  data_time: 0.0111  memory: 5878  grad_norm: 61.7976  loss: 7.4696  decode.loss_cls: 0.1618  decode.loss_mask: 0.2852  decode.loss_dice: 0.2234  decode.d0.loss_cls: 0.8123  decode.d0.loss_mask: 0.2929  decode.d0.loss_dice: 0.2216  decode.d1.loss_cls: 0.2031  decode.d1.loss_mask: 0.2873  decode.d1.loss_dice: 0.2230  decode.d2.loss_cls: 0.1968  decode.d2.loss_mask: 0.2859  decode.d2.loss_dice: 0.2222  decode.d3.loss_cls: 0.1769  decode.d3.loss_mask: 0.2887  decode.d3.loss_dice: 0.2319  decode.d4.loss_cls: 0.1746  decode.d4.loss_mask: 0.2865  decode.d4.loss_dice: 0.2316  decode.d5.loss_cls: 0.1734  decode.d5.loss_mask: 0.2861  decode.d5.loss_dice: 0.2264  decode.d6.loss_cls: 0.1596  decode.d6.loss_mask: 0.2866  decode.d6.loss_dice: 0.2201  decode.d7.loss_cls: 0.1372  decode.d7.loss_mask: 0.2888  decode.d7.loss_dice: 0.2370  decode.d8.loss_cls: 0.1380  decode.d8.loss_mask: 0.2852  decode.d8.loss_dice: 0.2254
08/06 09:27:42 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 09:27:42 - mmengine - INFO - Iter(train) [ 52000/320000]  base_lr: 8.5249e-05 lr: 8.5249e-06  eta: 1 day, 12:40:30  time: 0.4948  data_time: 0.0112  memory: 5878  grad_norm: 107.2322  loss: 8.2693  decode.loss_cls: 0.2068  decode.loss_mask: 0.2650  decode.loss_dice: 0.2928  decode.d0.loss_cls: 1.0164  decode.d0.loss_mask: 0.3087  decode.d0.loss_dice: 0.2950  decode.d1.loss_cls: 0.2531  decode.d1.loss_mask: 0.2744  decode.d1.loss_dice: 0.2849  decode.d2.loss_cls: 0.1667  decode.d2.loss_mask: 0.2722  decode.d2.loss_dice: 0.2568  decode.d3.loss_cls: 0.1254  decode.d3.loss_mask: 0.2754  decode.d3.loss_dice: 0.2697  decode.d4.loss_cls: 0.1672  decode.d4.loss_mask: 0.2668  decode.d4.loss_dice: 0.2746  decode.d5.loss_cls: 0.1771  decode.d5.loss_mask: 0.2725  decode.d5.loss_dice: 0.2726  decode.d6.loss_cls: 0.1883  decode.d6.loss_mask: 0.2730  decode.d6.loss_dice: 0.2624  decode.d7.loss_cls: 0.1775  decode.d7.loss_mask: 0.2738  decode.d7.loss_dice: 0.3018  decode.d8.loss_cls: 0.2307  decode.d8.loss_mask: 0.2664  decode.d8.loss_dice: 0.3013
08/06 09:28:07 - mmengine - INFO - Iter(train) [ 52050/320000]  base_lr: 8.5234e-05 lr: 8.5234e-06  eta: 1 day, 12:40:05  time: 0.4943  data_time: 0.0111  memory: 5895  grad_norm: 123.8304  loss: 5.2816  decode.loss_cls: 0.0353  decode.loss_mask: 0.2011  decode.loss_dice: 0.2156  decode.d0.loss_cls: 0.8060  decode.d0.loss_mask: 0.2023  decode.d0.loss_dice: 0.2121  decode.d1.loss_cls: 0.0327  decode.d1.loss_mask: 0.2000  decode.d1.loss_dice: 0.2172  decode.d2.loss_cls: 0.0543  decode.d2.loss_mask: 0.1990  decode.d2.loss_dice: 0.2119  decode.d3.loss_cls: 0.0364  decode.d3.loss_mask: 0.1973  decode.d3.loss_dice: 0.2153  decode.d4.loss_cls: 0.0364  decode.d4.loss_mask: 0.2003  decode.d4.loss_dice: 0.2163  decode.d5.loss_cls: 0.0375  decode.d5.loss_mask: 0.1975  decode.d5.loss_dice: 0.2159  decode.d6.loss_cls: 0.0381  decode.d6.loss_mask: 0.1996  decode.d6.loss_dice: 0.2140  decode.d7.loss_cls: 0.0354  decode.d7.loss_mask: 0.1995  decode.d7.loss_dice: 0.2151  decode.d8.loss_cls: 0.0322  decode.d8.loss_mask: 0.1961  decode.d8.loss_dice: 0.2113
08/06 09:28:32 - mmengine - INFO - Iter(train) [ 52100/320000]  base_lr: 8.5220e-05 lr: 8.5220e-06  eta: 1 day, 12:39:41  time: 0.4957  data_time: 0.0112  memory: 5895  grad_norm: 104.9466  loss: 7.0059  decode.loss_cls: 0.1436  decode.loss_mask: 0.2456  decode.loss_dice: 0.2524  decode.d0.loss_cls: 0.8639  decode.d0.loss_mask: 0.2563  decode.d0.loss_dice: 0.2755  decode.d1.loss_cls: 0.1588  decode.d1.loss_mask: 0.2364  decode.d1.loss_dice: 0.2697  decode.d2.loss_cls: 0.1309  decode.d2.loss_mask: 0.2391  decode.d2.loss_dice: 0.2545  decode.d3.loss_cls: 0.1324  decode.d3.loss_mask: 0.2429  decode.d3.loss_dice: 0.2410  decode.d4.loss_cls: 0.1332  decode.d4.loss_mask: 0.2407  decode.d4.loss_dice: 0.2657  decode.d5.loss_cls: 0.1119  decode.d5.loss_mask: 0.2427  decode.d5.loss_dice: 0.2484  decode.d6.loss_cls: 0.1007  decode.d6.loss_mask: 0.2432  decode.d6.loss_dice: 0.2598  decode.d7.loss_cls: 0.1060  decode.d7.loss_mask: 0.2435  decode.d7.loss_dice: 0.2523  decode.d8.loss_cls: 0.1128  decode.d8.loss_mask: 0.2420  decode.d8.loss_dice: 0.2597
08/06 09:28:56 - mmengine - INFO - Iter(train) [ 52150/320000]  base_lr: 8.5206e-05 lr: 8.5206e-06  eta: 1 day, 12:39:17  time: 0.4948  data_time: 0.0113  memory: 5925  grad_norm: 156.8836  loss: 8.0697  decode.loss_cls: 0.1016  decode.loss_mask: 0.2976  decode.loss_dice: 0.3367  decode.d0.loss_cls: 0.9137  decode.d0.loss_mask: 0.2932  decode.d0.loss_dice: 0.3495  decode.d1.loss_cls: 0.1133  decode.d1.loss_mask: 0.3012  decode.d1.loss_dice: 0.3277  decode.d2.loss_cls: 0.1103  decode.d2.loss_mask: 0.2957  decode.d2.loss_dice: 0.3286  decode.d3.loss_cls: 0.0898  decode.d3.loss_mask: 0.2933  decode.d3.loss_dice: 0.3301  decode.d4.loss_cls: 0.0960  decode.d4.loss_mask: 0.2969  decode.d4.loss_dice: 0.3498  decode.d5.loss_cls: 0.0715  decode.d5.loss_mask: 0.2963  decode.d5.loss_dice: 0.3423  decode.d6.loss_cls: 0.0826  decode.d6.loss_mask: 0.2975  decode.d6.loss_dice: 0.3380  decode.d7.loss_cls: 0.0793  decode.d7.loss_mask: 0.3001  decode.d7.loss_dice: 0.3459  decode.d8.loss_cls: 0.0485  decode.d8.loss_mask: 0.2962  decode.d8.loss_dice: 0.3465
08/06 09:29:21 - mmengine - INFO - Iter(train) [ 52200/320000]  base_lr: 8.5191e-05 lr: 8.5191e-06  eta: 1 day, 12:38:53  time: 0.4939  data_time: 0.0111  memory: 5913  grad_norm: 156.4799  loss: 7.7092  decode.loss_cls: 0.2172  decode.loss_mask: 0.1993  decode.loss_dice: 0.2704  decode.d0.loss_cls: 0.9512  decode.d0.loss_mask: 0.1976  decode.d0.loss_dice: 0.2604  decode.d1.loss_cls: 0.3141  decode.d1.loss_mask: 0.2017  decode.d1.loss_dice: 0.2630  decode.d2.loss_cls: 0.2353  decode.d2.loss_mask: 0.1997  decode.d2.loss_dice: 0.2617  decode.d3.loss_cls: 0.2346  decode.d3.loss_mask: 0.1989  decode.d3.loss_dice: 0.2666  decode.d4.loss_cls: 0.2104  decode.d4.loss_mask: 0.1963  decode.d4.loss_dice: 0.2637  decode.d5.loss_cls: 0.2735  decode.d5.loss_mask: 0.1966  decode.d5.loss_dice: 0.2738  decode.d6.loss_cls: 0.2744  decode.d6.loss_mask: 0.1954  decode.d6.loss_dice: 0.2622  decode.d7.loss_cls: 0.1843  decode.d7.loss_mask: 0.1974  decode.d7.loss_dice: 0.2722  decode.d8.loss_cls: 0.1566  decode.d8.loss_mask: 0.2010  decode.d8.loss_dice: 0.2797
08/06 09:29:46 - mmengine - INFO - Iter(train) [ 52250/320000]  base_lr: 8.5177e-05 lr: 8.5177e-06  eta: 1 day, 12:38:30  time: 0.4945  data_time: 0.0112  memory: 5911  grad_norm: 93.7565  loss: 7.5883  decode.loss_cls: 0.0439  decode.loss_mask: 0.3032  decode.loss_dice: 0.2853  decode.d0.loss_cls: 1.0249  decode.d0.loss_mask: 0.3095  decode.d0.loss_dice: 0.3033  decode.d1.loss_cls: 0.1249  decode.d1.loss_mask: 0.3058  decode.d1.loss_dice: 0.3130  decode.d2.loss_cls: 0.1010  decode.d2.loss_mask: 0.3031  decode.d2.loss_dice: 0.2995  decode.d3.loss_cls: 0.0491  decode.d3.loss_mask: 0.3083  decode.d3.loss_dice: 0.2778  decode.d4.loss_cls: 0.0439  decode.d4.loss_mask: 0.3049  decode.d4.loss_dice: 0.2797  decode.d5.loss_cls: 0.0480  decode.d5.loss_mask: 0.3004  decode.d5.loss_dice: 0.2912  decode.d6.loss_cls: 0.1163  decode.d6.loss_mask: 0.3024  decode.d6.loss_dice: 0.2729  decode.d7.loss_cls: 0.0549  decode.d7.loss_mask: 0.3032  decode.d7.loss_dice: 0.2857  decode.d8.loss_cls: 0.0499  decode.d8.loss_mask: 0.3011  decode.d8.loss_dice: 0.2810
08/06 09:30:11 - mmengine - INFO - Iter(train) [ 52300/320000]  base_lr: 8.5163e-05 lr: 8.5163e-06  eta: 1 day, 12:38:06  time: 0.4936  data_time: 0.0111  memory: 5928  grad_norm: 112.8116  loss: 5.5905  decode.loss_cls: 0.0140  decode.loss_mask: 0.2013  decode.loss_dice: 0.2383  decode.d0.loss_cls: 0.8674  decode.d0.loss_mask: 0.2059  decode.d0.loss_dice: 0.2638  decode.d1.loss_cls: 0.0206  decode.d1.loss_mask: 0.2012  decode.d1.loss_dice: 0.2565  decode.d2.loss_cls: 0.0179  decode.d2.loss_mask: 0.2009  decode.d2.loss_dice: 0.2523  decode.d3.loss_cls: 0.0170  decode.d3.loss_mask: 0.2028  decode.d3.loss_dice: 0.2413  decode.d4.loss_cls: 0.0161  decode.d4.loss_mask: 0.2052  decode.d4.loss_dice: 0.2513  decode.d5.loss_cls: 0.0481  decode.d5.loss_mask: 0.2048  decode.d5.loss_dice: 0.2737  decode.d6.loss_cls: 0.0149  decode.d6.loss_mask: 0.2014  decode.d6.loss_dice: 0.2501  decode.d7.loss_cls: 0.0164  decode.d7.loss_mask: 0.1998  decode.d7.loss_dice: 0.2411  decode.d8.loss_cls: 0.0150  decode.d8.loss_mask: 0.2014  decode.d8.loss_dice: 0.2501
08/06 09:30:36 - mmengine - INFO - Iter(train) [ 52350/320000]  base_lr: 8.5148e-05 lr: 8.5148e-06  eta: 1 day, 12:37:41  time: 0.4944  data_time: 0.0112  memory: 5894  grad_norm: 101.1650  loss: 7.9961  decode.loss_cls: 0.1253  decode.loss_mask: 0.2588  decode.loss_dice: 0.2736  decode.d0.loss_cls: 0.9994  decode.d0.loss_mask: 0.2683  decode.d0.loss_dice: 0.2768  decode.d1.loss_cls: 0.1812  decode.d1.loss_mask: 0.2616  decode.d1.loss_dice: 0.2796  decode.d2.loss_cls: 0.1869  decode.d2.loss_mask: 0.2599  decode.d2.loss_dice: 0.2759  decode.d3.loss_cls: 0.1812  decode.d3.loss_mask: 0.2602  decode.d3.loss_dice: 0.2675  decode.d4.loss_cls: 0.2142  decode.d4.loss_mask: 0.2602  decode.d4.loss_dice: 0.2717  decode.d5.loss_cls: 0.1956  decode.d5.loss_mask: 0.2601  decode.d5.loss_dice: 0.2722  decode.d6.loss_cls: 0.2289  decode.d6.loss_mask: 0.2594  decode.d6.loss_dice: 0.2716  decode.d7.loss_cls: 0.1907  decode.d7.loss_mask: 0.2598  decode.d7.loss_dice: 0.2678  decode.d8.loss_cls: 0.1569  decode.d8.loss_mask: 0.2603  decode.d8.loss_dice: 0.2702
08/06 09:31:00 - mmengine - INFO - Iter(train) [ 52400/320000]  base_lr: 8.5134e-05 lr: 8.5134e-06  eta: 1 day, 12:37:17  time: 0.4939  data_time: 0.0113  memory: 5894  grad_norm: 166.3745  loss: 7.3784  decode.loss_cls: 0.1090  decode.loss_mask: 0.2354  decode.loss_dice: 0.2676  decode.d0.loss_cls: 0.9205  decode.d0.loss_mask: 0.2377  decode.d0.loss_dice: 0.2790  decode.d1.loss_cls: 0.1481  decode.d1.loss_mask: 0.2411  decode.d1.loss_dice: 0.2843  decode.d2.loss_cls: 0.1293  decode.d2.loss_mask: 0.2404  decode.d2.loss_dice: 0.2789  decode.d3.loss_cls: 0.1075  decode.d3.loss_mask: 0.2350  decode.d3.loss_dice: 0.2654  decode.d4.loss_cls: 0.1693  decode.d4.loss_mask: 0.2332  decode.d4.loss_dice: 0.2647  decode.d5.loss_cls: 0.1907  decode.d5.loss_mask: 0.2349  decode.d5.loss_dice: 0.2585  decode.d6.loss_cls: 0.2232  decode.d6.loss_mask: 0.2338  decode.d6.loss_dice: 0.2547  decode.d7.loss_cls: 0.1857  decode.d7.loss_mask: 0.2371  decode.d7.loss_dice: 0.2875  decode.d8.loss_cls: 0.1032  decode.d8.loss_mask: 0.2357  decode.d8.loss_dice: 0.2869
08/06 09:31:25 - mmengine - INFO - Iter(train) [ 52450/320000]  base_lr: 8.5120e-05 lr: 8.5120e-06  eta: 1 day, 12:36:53  time: 0.4950  data_time: 0.0112  memory: 5874  grad_norm: 54.4996  loss: 6.4949  decode.loss_cls: 0.0542  decode.loss_mask: 0.2841  decode.loss_dice: 0.2330  decode.d0.loss_cls: 0.9534  decode.d0.loss_mask: 0.2117  decode.d0.loss_dice: 0.2275  decode.d1.loss_cls: 0.0632  decode.d1.loss_mask: 0.2471  decode.d1.loss_dice: 0.2291  decode.d2.loss_cls: 0.0736  decode.d2.loss_mask: 0.2565  decode.d2.loss_dice: 0.2257  decode.d3.loss_cls: 0.0638  decode.d3.loss_mask: 0.2584  decode.d3.loss_dice: 0.2234  decode.d4.loss_cls: 0.0738  decode.d4.loss_mask: 0.2705  decode.d4.loss_dice: 0.2456  decode.d5.loss_cls: 0.1141  decode.d5.loss_mask: 0.2579  decode.d5.loss_dice: 0.2305  decode.d6.loss_cls: 0.0892  decode.d6.loss_mask: 0.2533  decode.d6.loss_dice: 0.2271  decode.d7.loss_cls: 0.0799  decode.d7.loss_mask: 0.2587  decode.d7.loss_dice: 0.2240  decode.d8.loss_cls: 0.0449  decode.d8.loss_mask: 0.2886  decode.d8.loss_dice: 0.2321
08/06 09:31:50 - mmengine - INFO - Iter(train) [ 52500/320000]  base_lr: 8.5106e-05 lr: 8.5106e-06  eta: 1 day, 12:36:29  time: 0.4946  data_time: 0.0112  memory: 5931  grad_norm: 136.2722  loss: 7.9880  decode.loss_cls: 0.2503  decode.loss_mask: 0.2092  decode.loss_dice: 0.2694  decode.d0.loss_cls: 1.0098  decode.d0.loss_mask: 0.2189  decode.d0.loss_dice: 0.2605  decode.d1.loss_cls: 0.3252  decode.d1.loss_mask: 0.2129  decode.d1.loss_dice: 0.2550  decode.d2.loss_cls: 0.2552  decode.d2.loss_mask: 0.2150  decode.d2.loss_dice: 0.2674  decode.d3.loss_cls: 0.2379  decode.d3.loss_mask: 0.2097  decode.d3.loss_dice: 0.2776  decode.d4.loss_cls: 0.2086  decode.d4.loss_mask: 0.2086  decode.d4.loss_dice: 0.2591  decode.d5.loss_cls: 0.2133  decode.d5.loss_mask: 0.2110  decode.d5.loss_dice: 0.2624  decode.d6.loss_cls: 0.2392  decode.d6.loss_mask: 0.2108  decode.d6.loss_dice: 0.2723  decode.d7.loss_cls: 0.2410  decode.d7.loss_mask: 0.2106  decode.d7.loss_dice: 0.2629  decode.d8.loss_cls: 0.2323  decode.d8.loss_mask: 0.2116  decode.d8.loss_dice: 0.2704
08/06 09:32:14 - mmengine - INFO - Iter(train) [ 52550/320000]  base_lr: 8.5091e-05 lr: 8.5091e-06  eta: 1 day, 12:36:05  time: 0.4933  data_time: 0.0110  memory: 5928  grad_norm: 99.9645  loss: 6.8256  decode.loss_cls: 0.0938  decode.loss_mask: 0.2864  decode.loss_dice: 0.2571  decode.d0.loss_cls: 0.8138  decode.d0.loss_mask: 0.2630  decode.d0.loss_dice: 0.2532  decode.d1.loss_cls: 0.0287  decode.d1.loss_mask: 0.2814  decode.d1.loss_dice: 0.2583  decode.d2.loss_cls: 0.0336  decode.d2.loss_mask: 0.2858  decode.d2.loss_dice: 0.2565  decode.d3.loss_cls: 0.0678  decode.d3.loss_mask: 0.2819  decode.d3.loss_dice: 0.2465  decode.d4.loss_cls: 0.0380  decode.d4.loss_mask: 0.2869  decode.d4.loss_dice: 0.2579  decode.d5.loss_cls: 0.0932  decode.d5.loss_mask: 0.2854  decode.d5.loss_dice: 0.2476  decode.d6.loss_cls: 0.0882  decode.d6.loss_mask: 0.2850  decode.d6.loss_dice: 0.2448  decode.d7.loss_cls: 0.0843  decode.d7.loss_mask: 0.3027  decode.d7.loss_dice: 0.2732  decode.d8.loss_cls: 0.0946  decode.d8.loss_mask: 0.2832  decode.d8.loss_dice: 0.2529
08/06 09:32:39 - mmengine - INFO - Iter(train) [ 52600/320000]  base_lr: 8.5077e-05 lr: 8.5077e-06  eta: 1 day, 12:35:41  time: 0.4947  data_time: 0.0113  memory: 5911  grad_norm: 91.5052  loss: 6.6030  decode.loss_cls: 0.0542  decode.loss_mask: 0.2684  decode.loss_dice: 0.2531  decode.d0.loss_cls: 0.8426  decode.d0.loss_mask: 0.2719  decode.d0.loss_dice: 0.2531  decode.d1.loss_cls: 0.0715  decode.d1.loss_mask: 0.2698  decode.d1.loss_dice: 0.2451  decode.d2.loss_cls: 0.0670  decode.d2.loss_mask: 0.2685  decode.d2.loss_dice: 0.2487  decode.d3.loss_cls: 0.0753  decode.d3.loss_mask: 0.2682  decode.d3.loss_dice: 0.2535  decode.d4.loss_cls: 0.0778  decode.d4.loss_mask: 0.2655  decode.d4.loss_dice: 0.2482  decode.d5.loss_cls: 0.0638  decode.d5.loss_mask: 0.2655  decode.d5.loss_dice: 0.2480  decode.d6.loss_cls: 0.0555  decode.d6.loss_mask: 0.2697  decode.d6.loss_dice: 0.2516  decode.d7.loss_cls: 0.0512  decode.d7.loss_mask: 0.2686  decode.d7.loss_dice: 0.2453  decode.d8.loss_cls: 0.0646  decode.d8.loss_mask: 0.2671  decode.d8.loss_dice: 0.2497
08/06 09:33:04 - mmengine - INFO - Iter(train) [ 52650/320000]  base_lr: 8.5063e-05 lr: 8.5063e-06  eta: 1 day, 12:35:17  time: 0.4939  data_time: 0.0112  memory: 5928  grad_norm: 267.2554  loss: 6.6006  decode.loss_cls: 0.0281  decode.loss_mask: 0.2856  decode.loss_dice: 0.2718  decode.d0.loss_cls: 0.8265  decode.d0.loss_mask: 0.2776  decode.d0.loss_dice: 0.2615  decode.d1.loss_cls: 0.0660  decode.d1.loss_mask: 0.2764  decode.d1.loss_dice: 0.2474  decode.d2.loss_cls: 0.1159  decode.d2.loss_mask: 0.2696  decode.d2.loss_dice: 0.2456  decode.d3.loss_cls: 0.0511  decode.d3.loss_mask: 0.2764  decode.d3.loss_dice: 0.2434  decode.d4.loss_cls: 0.0470  decode.d4.loss_mask: 0.2794  decode.d4.loss_dice: 0.2630  decode.d5.loss_cls: 0.0411  decode.d5.loss_mask: 0.2766  decode.d5.loss_dice: 0.2504  decode.d6.loss_cls: 0.0550  decode.d6.loss_mask: 0.2766  decode.d6.loss_dice: 0.2441  decode.d7.loss_cls: 0.0381  decode.d7.loss_mask: 0.2749  decode.d7.loss_dice: 0.2483  decode.d8.loss_cls: 0.0226  decode.d8.loss_mask: 0.2796  decode.d8.loss_dice: 0.2611
08/06 09:33:29 - mmengine - INFO - Iter(train) [ 52700/320000]  base_lr: 8.5048e-05 lr: 8.5048e-06  eta: 1 day, 12:34:53  time: 0.4942  data_time: 0.0112  memory: 5968  grad_norm: 118.4680  loss: 8.8333  decode.loss_cls: 0.2582  decode.loss_mask: 0.2533  decode.loss_dice: 0.2621  decode.d0.loss_cls: 0.9307  decode.d0.loss_mask: 0.2656  decode.d0.loss_dice: 0.2778  decode.d1.loss_cls: 0.3618  decode.d1.loss_mask: 0.2598  decode.d1.loss_dice: 0.2762  decode.d2.loss_cls: 0.3075  decode.d2.loss_mask: 0.2539  decode.d2.loss_dice: 0.2611  decode.d3.loss_cls: 0.2717  decode.d3.loss_mask: 0.2590  decode.d3.loss_dice: 0.2818  decode.d4.loss_cls: 0.2497  decode.d4.loss_mask: 0.2532  decode.d4.loss_dice: 0.2697  decode.d5.loss_cls: 0.2838  decode.d5.loss_mask: 0.2560  decode.d5.loss_dice: 0.2537  decode.d6.loss_cls: 0.3530  decode.d6.loss_mask: 0.2543  decode.d6.loss_dice: 0.2616  decode.d7.loss_cls: 0.2962  decode.d7.loss_mask: 0.2532  decode.d7.loss_dice: 0.2698  decode.d8.loss_cls: 0.2718  decode.d8.loss_mask: 0.2527  decode.d8.loss_dice: 0.2741
08/06 09:33:54 - mmengine - INFO - Iter(train) [ 52750/320000]  base_lr: 8.5034e-05 lr: 8.5034e-06  eta: 1 day, 12:34:29  time: 0.4944  data_time: 0.0111  memory: 5874  grad_norm: 210.9874  loss: 6.7360  decode.loss_cls: 0.1223  decode.loss_mask: 0.1733  decode.loss_dice: 0.3084  decode.d0.loss_cls: 0.8857  decode.d0.loss_mask: 0.1570  decode.d0.loss_dice: 0.2844  decode.d1.loss_cls: 0.1797  decode.d1.loss_mask: 0.1606  decode.d1.loss_dice: 0.2755  decode.d2.loss_cls: 0.1228  decode.d2.loss_mask: 0.1747  decode.d2.loss_dice: 0.2626  decode.d3.loss_cls: 0.1075  decode.d3.loss_mask: 0.1767  decode.d3.loss_dice: 0.2662  decode.d4.loss_cls: 0.1253  decode.d4.loss_mask: 0.1683  decode.d4.loss_dice: 0.2925  decode.d5.loss_cls: 0.1274  decode.d5.loss_mask: 0.1745  decode.d5.loss_dice: 0.2974  decode.d6.loss_cls: 0.1597  decode.d6.loss_mask: 0.1734  decode.d6.loss_dice: 0.2927  decode.d7.loss_cls: 0.1963  decode.d7.loss_mask: 0.1729  decode.d7.loss_dice: 0.2936  decode.d8.loss_cls: 0.1545  decode.d8.loss_mask: 0.1778  decode.d8.loss_dice: 0.2726
08/06 09:34:18 - mmengine - INFO - Iter(train) [ 52800/320000]  base_lr: 8.5020e-05 lr: 8.5020e-06  eta: 1 day, 12:34:06  time: 0.4949  data_time: 0.0112  memory: 5911  grad_norm: 52.9981  loss: 5.9824  decode.loss_cls: 0.0960  decode.loss_mask: 0.1917  decode.loss_dice: 0.2543  decode.d0.loss_cls: 0.7758  decode.d0.loss_mask: 0.1953  decode.d0.loss_dice: 0.2468  decode.d1.loss_cls: 0.0884  decode.d1.loss_mask: 0.1934  decode.d1.loss_dice: 0.2533  decode.d2.loss_cls: 0.0712  decode.d2.loss_mask: 0.1907  decode.d2.loss_dice: 0.2480  decode.d3.loss_cls: 0.1106  decode.d3.loss_mask: 0.1918  decode.d3.loss_dice: 0.2480  decode.d4.loss_cls: 0.1138  decode.d4.loss_mask: 0.1940  decode.d4.loss_dice: 0.2440  decode.d5.loss_cls: 0.0741  decode.d5.loss_mask: 0.1895  decode.d5.loss_dice: 0.2405  decode.d6.loss_cls: 0.1218  decode.d6.loss_mask: 0.1906  decode.d6.loss_dice: 0.2388  decode.d7.loss_cls: 0.0863  decode.d7.loss_mask: 0.1925  decode.d7.loss_dice: 0.2258  decode.d8.loss_cls: 0.0866  decode.d8.loss_mask: 0.1926  decode.d8.loss_dice: 0.2361
08/06 09:34:43 - mmengine - INFO - Iter(train) [ 52850/320000]  base_lr: 8.5005e-05 lr: 8.5005e-06  eta: 1 day, 12:33:41  time: 0.4944  data_time: 0.0114  memory: 5928  grad_norm: 81.9210  loss: 6.9670  decode.loss_cls: 0.0328  decode.loss_mask: 0.3074  decode.loss_dice: 0.2866  decode.d0.loss_cls: 0.8816  decode.d0.loss_mask: 0.3127  decode.d0.loss_dice: 0.2562  decode.d1.loss_cls: 0.0809  decode.d1.loss_mask: 0.3080  decode.d1.loss_dice: 0.2552  decode.d2.loss_cls: 0.0546  decode.d2.loss_mask: 0.3013  decode.d2.loss_dice: 0.2850  decode.d3.loss_cls: 0.0442  decode.d3.loss_mask: 0.3014  decode.d3.loss_dice: 0.2537  decode.d4.loss_cls: 0.0462  decode.d4.loss_mask: 0.3026  decode.d4.loss_dice: 0.2699  decode.d5.loss_cls: 0.0367  decode.d5.loss_mask: 0.3029  decode.d5.loss_dice: 0.2570  decode.d6.loss_cls: 0.0330  decode.d6.loss_mask: 0.3021  decode.d6.loss_dice: 0.2584  decode.d7.loss_cls: 0.0331  decode.d7.loss_mask: 0.3063  decode.d7.loss_dice: 0.2608  decode.d8.loss_cls: 0.0302  decode.d8.loss_mask: 0.3041  decode.d8.loss_dice: 0.2620
08/06 09:35:08 - mmengine - INFO - Iter(train) [ 52900/320000]  base_lr: 8.4991e-05 lr: 8.4991e-06  eta: 1 day, 12:33:18  time: 0.4956  data_time: 0.0115  memory: 5894  grad_norm: 90.8541  loss: 7.5043  decode.loss_cls: 0.1660  decode.loss_mask: 0.2338  decode.loss_dice: 0.2553  decode.d0.loss_cls: 0.9637  decode.d0.loss_mask: 0.2435  decode.d0.loss_dice: 0.2331  decode.d1.loss_cls: 0.2079  decode.d1.loss_mask: 0.2329  decode.d1.loss_dice: 0.2258  decode.d2.loss_cls: 0.1492  decode.d2.loss_mask: 0.2362  decode.d2.loss_dice: 0.2604  decode.d3.loss_cls: 0.1223  decode.d3.loss_mask: 0.2366  decode.d3.loss_dice: 0.2675  decode.d4.loss_cls: 0.2077  decode.d4.loss_mask: 0.2335  decode.d4.loss_dice: 0.2704  decode.d5.loss_cls: 0.1806  decode.d5.loss_mask: 0.2337  decode.d5.loss_dice: 0.2740  decode.d6.loss_cls: 0.2395  decode.d6.loss_mask: 0.2355  decode.d6.loss_dice: 0.2514  decode.d7.loss_cls: 0.2040  decode.d7.loss_mask: 0.2353  decode.d7.loss_dice: 0.2334  decode.d8.loss_cls: 0.1869  decode.d8.loss_mask: 0.2338  decode.d8.loss_dice: 0.2505
08/06 09:35:33 - mmengine - INFO - Iter(train) [ 52950/320000]  base_lr: 8.4977e-05 lr: 8.4977e-06  eta: 1 day, 12:32:54  time: 0.4949  data_time: 0.0113  memory: 5894  grad_norm: 77.8776  loss: 5.6990  decode.loss_cls: 0.0066  decode.loss_mask: 0.2556  decode.loss_dice: 0.2275  decode.d0.loss_cls: 0.7657  decode.d0.loss_mask: 0.2691  decode.d0.loss_dice: 0.2374  decode.d1.loss_cls: 0.0111  decode.d1.loss_mask: 0.2572  decode.d1.loss_dice: 0.2291  decode.d2.loss_cls: 0.0096  decode.d2.loss_mask: 0.2544  decode.d2.loss_dice: 0.2296  decode.d3.loss_cls: 0.0079  decode.d3.loss_mask: 0.2546  decode.d3.loss_dice: 0.2266  decode.d4.loss_cls: 0.0073  decode.d4.loss_mask: 0.2570  decode.d4.loss_dice: 0.2266  decode.d5.loss_cls: 0.0073  decode.d5.loss_mask: 0.2574  decode.d5.loss_dice: 0.2310  decode.d6.loss_cls: 0.0064  decode.d6.loss_mask: 0.2579  decode.d6.loss_dice: 0.2259  decode.d7.loss_cls: 0.0066  decode.d7.loss_mask: 0.2566  decode.d7.loss_dice: 0.2281  decode.d8.loss_cls: 0.0073  decode.d8.loss_mask: 0.2563  decode.d8.loss_dice: 0.2254
08/06 09:35:57 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 09:35:57 - mmengine - INFO - Iter(train) [ 53000/320000]  base_lr: 8.4962e-05 lr: 8.4962e-06  eta: 1 day, 12:32:30  time: 0.4962  data_time: 0.0114  memory: 5911  grad_norm: 222.2619  loss: 10.9200  decode.loss_cls: 0.4053  decode.loss_mask: 0.2660  decode.loss_dice: 0.3336  decode.d0.loss_cls: 1.0468  decode.d0.loss_mask: 0.2657  decode.d0.loss_dice: 0.3749  decode.d1.loss_cls: 0.4325  decode.d1.loss_mask: 0.2739  decode.d1.loss_dice: 0.3434  decode.d2.loss_cls: 0.3885  decode.d2.loss_mask: 0.3225  decode.d2.loss_dice: 0.3395  decode.d3.loss_cls: 0.3395  decode.d3.loss_mask: 0.3153  decode.d3.loss_dice: 0.3541  decode.d4.loss_cls: 0.3738  decode.d4.loss_mask: 0.3257  decode.d4.loss_dice: 0.3569  decode.d5.loss_cls: 0.4097  decode.d5.loss_mask: 0.2720  decode.d5.loss_dice: 0.3482  decode.d6.loss_cls: 0.3305  decode.d6.loss_mask: 0.3213  decode.d6.loss_dice: 0.3365  decode.d7.loss_cls: 0.4294  decode.d7.loss_mask: 0.2661  decode.d7.loss_dice: 0.3383  decode.d8.loss_cls: 0.3977  decode.d8.loss_mask: 0.2733  decode.d8.loss_dice: 0.3390
08/06 09:36:22 - mmengine - INFO - Iter(train) [ 53050/320000]  base_lr: 8.4948e-05 lr: 8.4948e-06  eta: 1 day, 12:32:06  time: 0.4964  data_time: 0.0115  memory: 5894  grad_norm: 144.3458  loss: 7.9901  decode.loss_cls: 0.1782  decode.loss_mask: 0.2709  decode.loss_dice: 0.2721  decode.d0.loss_cls: 0.9121  decode.d0.loss_mask: 0.2773  decode.d0.loss_dice: 0.2919  decode.d1.loss_cls: 0.1891  decode.d1.loss_mask: 0.2720  decode.d1.loss_dice: 0.2512  decode.d2.loss_cls: 0.1920  decode.d2.loss_mask: 0.2724  decode.d2.loss_dice: 0.2614  decode.d3.loss_cls: 0.1694  decode.d3.loss_mask: 0.2773  decode.d3.loss_dice: 0.2839  decode.d4.loss_cls: 0.2052  decode.d4.loss_mask: 0.2698  decode.d4.loss_dice: 0.2402  decode.d5.loss_cls: 0.2287  decode.d5.loss_mask: 0.2698  decode.d5.loss_dice: 0.2713  decode.d6.loss_cls: 0.1941  decode.d6.loss_mask: 0.2716  decode.d6.loss_dice: 0.2710  decode.d7.loss_cls: 0.1836  decode.d7.loss_mask: 0.2694  decode.d7.loss_dice: 0.2633  decode.d8.loss_cls: 0.1632  decode.d8.loss_mask: 0.2688  decode.d8.loss_dice: 0.2491
08/06 09:36:47 - mmengine - INFO - Iter(train) [ 53100/320000]  base_lr: 8.4934e-05 lr: 8.4934e-06  eta: 1 day, 12:31:42  time: 0.4947  data_time: 0.0112  memory: 5928  grad_norm: 100.6270  loss: 7.1632  decode.loss_cls: 0.1426  decode.loss_mask: 0.2034  decode.loss_dice: 0.2866  decode.d0.loss_cls: 0.9189  decode.d0.loss_mask: 0.1962  decode.d0.loss_dice: 0.2780  decode.d1.loss_cls: 0.2325  decode.d1.loss_mask: 0.2035  decode.d1.loss_dice: 0.2793  decode.d2.loss_cls: 0.1496  decode.d2.loss_mask: 0.2055  decode.d2.loss_dice: 0.2841  decode.d3.loss_cls: 0.1816  decode.d3.loss_mask: 0.1920  decode.d3.loss_dice: 0.2720  decode.d4.loss_cls: 0.1348  decode.d4.loss_mask: 0.2040  decode.d4.loss_dice: 0.2805  decode.d5.loss_cls: 0.1460  decode.d5.loss_mask: 0.1993  decode.d5.loss_dice: 0.2726  decode.d6.loss_cls: 0.1459  decode.d6.loss_mask: 0.2013  decode.d6.loss_dice: 0.2845  decode.d7.loss_cls: 0.1621  decode.d7.loss_mask: 0.2003  decode.d7.loss_dice: 0.2787  decode.d8.loss_cls: 0.1432  decode.d8.loss_mask: 0.1992  decode.d8.loss_dice: 0.2850
08/06 09:37:12 - mmengine - INFO - Iter(train) [ 53150/320000]  base_lr: 8.4919e-05 lr: 8.4919e-06  eta: 1 day, 12:31:18  time: 0.4948  data_time: 0.0113  memory: 5911  grad_norm: 89.2431  loss: 7.0864  decode.loss_cls: 0.0504  decode.loss_mask: 0.2399  decode.loss_dice: 0.2749  decode.d0.loss_cls: 0.8521  decode.d0.loss_mask: 0.2399  decode.d0.loss_dice: 0.2886  decode.d1.loss_cls: 0.1572  decode.d1.loss_mask: 0.2417  decode.d1.loss_dice: 0.2829  decode.d2.loss_cls: 0.1308  decode.d2.loss_mask: 0.2434  decode.d2.loss_dice: 0.2841  decode.d3.loss_cls: 0.1356  decode.d3.loss_mask: 0.2256  decode.d3.loss_dice: 0.2771  decode.d4.loss_cls: 0.1445  decode.d4.loss_mask: 0.2324  decode.d4.loss_dice: 0.2805  decode.d5.loss_cls: 0.1164  decode.d5.loss_mask: 0.2328  decode.d5.loss_dice: 0.2794  decode.d6.loss_cls: 0.1065  decode.d6.loss_mask: 0.2471  decode.d6.loss_dice: 0.2607  decode.d7.loss_cls: 0.1176  decode.d7.loss_mask: 0.2350  decode.d7.loss_dice: 0.2783  decode.d8.loss_cls: 0.1380  decode.d8.loss_mask: 0.2277  decode.d8.loss_dice: 0.2649
08/06 09:37:37 - mmengine - INFO - Iter(train) [ 53200/320000]  base_lr: 8.4905e-05 lr: 8.4905e-06  eta: 1 day, 12:30:54  time: 0.4954  data_time: 0.0115  memory: 5911  grad_norm: 69.7149  loss: 5.3146  decode.loss_cls: 0.0664  decode.loss_mask: 0.1614  decode.loss_dice: 0.1926  decode.d0.loss_cls: 0.8118  decode.d0.loss_mask: 0.1654  decode.d0.loss_dice: 0.2009  decode.d1.loss_cls: 0.1519  decode.d1.loss_mask: 0.1633  decode.d1.loss_dice: 0.1920  decode.d2.loss_cls: 0.1303  decode.d2.loss_mask: 0.1637  decode.d2.loss_dice: 0.1926  decode.d3.loss_cls: 0.1556  decode.d3.loss_mask: 0.1638  decode.d3.loss_dice: 0.1910  decode.d4.loss_cls: 0.1080  decode.d4.loss_mask: 0.1641  decode.d4.loss_dice: 0.1943  decode.d5.loss_cls: 0.0945  decode.d5.loss_mask: 0.1634  decode.d5.loss_dice: 0.1977  decode.d6.loss_cls: 0.0874  decode.d6.loss_mask: 0.1624  decode.d6.loss_dice: 0.1918  decode.d7.loss_cls: 0.0698  decode.d7.loss_mask: 0.1647  decode.d7.loss_dice: 0.1940  decode.d8.loss_cls: 0.0643  decode.d8.loss_mask: 0.1640  decode.d8.loss_dice: 0.1915
08/06 09:38:01 - mmengine - INFO - Iter(train) [ 53250/320000]  base_lr: 8.4891e-05 lr: 8.4891e-06  eta: 1 day, 12:30:30  time: 0.4937  data_time: 0.0113  memory: 5895  grad_norm: 126.8604  loss: 6.7220  decode.loss_cls: 0.0805  decode.loss_mask: 0.2591  decode.loss_dice: 0.2455  decode.d0.loss_cls: 0.7966  decode.d0.loss_mask: 0.2766  decode.d0.loss_dice: 0.2769  decode.d1.loss_cls: 0.1036  decode.d1.loss_mask: 0.2598  decode.d1.loss_dice: 0.2474  decode.d2.loss_cls: 0.1032  decode.d2.loss_mask: 0.2587  decode.d2.loss_dice: 0.2375  decode.d3.loss_cls: 0.1036  decode.d3.loss_mask: 0.2579  decode.d3.loss_dice: 0.2434  decode.d4.loss_cls: 0.0984  decode.d4.loss_mask: 0.2613  decode.d4.loss_dice: 0.2432  decode.d5.loss_cls: 0.0723  decode.d5.loss_mask: 0.2596  decode.d5.loss_dice: 0.2409  decode.d6.loss_cls: 0.0977  decode.d6.loss_mask: 0.2585  decode.d6.loss_dice: 0.2378  decode.d7.loss_cls: 0.1226  decode.d7.loss_mask: 0.2591  decode.d7.loss_dice: 0.2510  decode.d8.loss_cls: 0.0625  decode.d8.loss_mask: 0.2601  decode.d8.loss_dice: 0.2469
08/06 09:38:26 - mmengine - INFO - Iter(train) [ 53300/320000]  base_lr: 8.4876e-05 lr: 8.4876e-06  eta: 1 day, 12:30:06  time: 0.4947  data_time: 0.0113  memory: 5913  grad_norm: 61.4191  loss: 5.9638  decode.loss_cls: 0.0697  decode.loss_mask: 0.1757  decode.loss_dice: 0.2261  decode.d0.loss_cls: 0.8976  decode.d0.loss_mask: 0.1767  decode.d0.loss_dice: 0.2455  decode.d1.loss_cls: 0.2187  decode.d1.loss_mask: 0.1751  decode.d1.loss_dice: 0.2278  decode.d2.loss_cls: 0.1536  decode.d2.loss_mask: 0.1746  decode.d2.loss_dice: 0.2324  decode.d3.loss_cls: 0.1203  decode.d3.loss_mask: 0.1765  decode.d3.loss_dice: 0.2317  decode.d4.loss_cls: 0.0821  decode.d4.loss_mask: 0.1743  decode.d4.loss_dice: 0.2359  decode.d5.loss_cls: 0.0797  decode.d5.loss_mask: 0.1749  decode.d5.loss_dice: 0.2266  decode.d6.loss_cls: 0.0657  decode.d6.loss_mask: 0.1752  decode.d6.loss_dice: 0.2246  decode.d7.loss_cls: 0.0970  decode.d7.loss_mask: 0.1768  decode.d7.loss_dice: 0.2373  decode.d8.loss_cls: 0.0913  decode.d8.loss_mask: 0.1743  decode.d8.loss_dice: 0.2457
08/06 09:38:51 - mmengine - INFO - Iter(train) [ 53350/320000]  base_lr: 8.4862e-05 lr: 8.4862e-06  eta: 1 day, 12:29:42  time: 0.4953  data_time: 0.0115  memory: 5894  grad_norm: 68.4260  loss: 8.0279  decode.loss_cls: 0.1893  decode.loss_mask: 0.2371  decode.loss_dice: 0.2551  decode.d0.loss_cls: 1.0123  decode.d0.loss_mask: 0.2416  decode.d0.loss_dice: 0.2918  decode.d1.loss_cls: 0.3136  decode.d1.loss_mask: 0.2406  decode.d1.loss_dice: 0.2700  decode.d2.loss_cls: 0.2336  decode.d2.loss_mask: 0.2401  decode.d2.loss_dice: 0.2616  decode.d3.loss_cls: 0.2462  decode.d3.loss_mask: 0.2363  decode.d3.loss_dice: 0.2686  decode.d4.loss_cls: 0.2323  decode.d4.loss_mask: 0.2395  decode.d4.loss_dice: 0.2660  decode.d5.loss_cls: 0.2210  decode.d5.loss_mask: 0.2396  decode.d5.loss_dice: 0.2424  decode.d6.loss_cls: 0.2014  decode.d6.loss_mask: 0.2354  decode.d6.loss_dice: 0.2463  decode.d7.loss_cls: 0.1747  decode.d7.loss_mask: 0.2380  decode.d7.loss_dice: 0.2458  decode.d8.loss_cls: 0.2086  decode.d8.loss_mask: 0.2383  decode.d8.loss_dice: 0.2608
08/06 09:39:16 - mmengine - INFO - Iter(train) [ 53400/320000]  base_lr: 8.4848e-05 lr: 8.4848e-06  eta: 1 day, 12:29:18  time: 0.4958  data_time: 0.0114  memory: 5894  grad_norm: 90.9954  loss: 5.3745  decode.loss_cls: 0.0544  decode.loss_mask: 0.1666  decode.loss_dice: 0.2547  decode.d0.loss_cls: 0.7370  decode.d0.loss_mask: 0.1653  decode.d0.loss_dice: 0.2547  decode.d1.loss_cls: 0.0555  decode.d1.loss_mask: 0.1680  decode.d1.loss_dice: 0.2511  decode.d2.loss_cls: 0.0437  decode.d2.loss_mask: 0.1682  decode.d2.loss_dice: 0.2548  decode.d3.loss_cls: 0.0378  decode.d3.loss_mask: 0.1687  decode.d3.loss_dice: 0.2469  decode.d4.loss_cls: 0.0472  decode.d4.loss_mask: 0.1670  decode.d4.loss_dice: 0.2522  decode.d5.loss_cls: 0.0438  decode.d5.loss_mask: 0.1673  decode.d5.loss_dice: 0.2512  decode.d6.loss_cls: 0.0465  decode.d6.loss_mask: 0.1669  decode.d6.loss_dice: 0.2602  decode.d7.loss_cls: 0.0436  decode.d7.loss_mask: 0.1656  decode.d7.loss_dice: 0.2605  decode.d8.loss_cls: 0.0476  decode.d8.loss_mask: 0.1679  decode.d8.loss_dice: 0.2596
08/06 09:39:41 - mmengine - INFO - Iter(train) [ 53450/320000]  base_lr: 8.4833e-05 lr: 8.4833e-06  eta: 1 day, 12:28:54  time: 0.4950  data_time: 0.0113  memory: 5894  grad_norm: 51.5806  loss: 7.8765  decode.loss_cls: 0.0842  decode.loss_mask: 0.3028  decode.loss_dice: 0.2688  decode.d0.loss_cls: 0.9150  decode.d0.loss_mask: 0.3052  decode.d0.loss_dice: 0.2939  decode.d1.loss_cls: 0.1263  decode.d1.loss_mask: 0.3107  decode.d1.loss_dice: 0.2776  decode.d2.loss_cls: 0.1078  decode.d2.loss_mask: 0.3012  decode.d2.loss_dice: 0.2724  decode.d3.loss_cls: 0.1032  decode.d3.loss_mask: 0.3120  decode.d3.loss_dice: 0.2691  decode.d4.loss_cls: 0.1366  decode.d4.loss_mask: 0.3237  decode.d4.loss_dice: 0.2785  decode.d5.loss_cls: 0.1533  decode.d5.loss_mask: 0.3237  decode.d5.loss_dice: 0.2971  decode.d6.loss_cls: 0.1366  decode.d6.loss_mask: 0.3139  decode.d6.loss_dice: 0.2824  decode.d7.loss_cls: 0.0713  decode.d7.loss_mask: 0.3137  decode.d7.loss_dice: 0.2780  decode.d8.loss_cls: 0.1279  decode.d8.loss_mask: 0.3104  decode.d8.loss_dice: 0.2793
08/06 09:40:05 - mmengine - INFO - Iter(train) [ 53500/320000]  base_lr: 8.4819e-05 lr: 8.4819e-06  eta: 1 day, 12:28:30  time: 0.4953  data_time: 0.0111  memory: 5894  grad_norm: 160.7518  loss: 6.2127  decode.loss_cls: 0.0949  decode.loss_mask: 0.1733  decode.loss_dice: 0.2545  decode.d0.loss_cls: 0.8950  decode.d0.loss_mask: 0.1697  decode.d0.loss_dice: 0.2857  decode.d1.loss_cls: 0.1038  decode.d1.loss_mask: 0.1696  decode.d1.loss_dice: 0.2709  decode.d2.loss_cls: 0.1127  decode.d2.loss_mask: 0.1741  decode.d2.loss_dice: 0.2462  decode.d3.loss_cls: 0.1179  decode.d3.loss_mask: 0.1727  decode.d3.loss_dice: 0.2474  decode.d4.loss_cls: 0.1129  decode.d4.loss_mask: 0.1726  decode.d4.loss_dice: 0.2504  decode.d5.loss_cls: 0.1003  decode.d5.loss_mask: 0.1742  decode.d5.loss_dice: 0.2482  decode.d6.loss_cls: 0.1353  decode.d6.loss_mask: 0.1750  decode.d6.loss_dice: 0.2543  decode.d7.loss_cls: 0.1271  decode.d7.loss_mask: 0.1761  decode.d7.loss_dice: 0.2636  decode.d8.loss_cls: 0.1065  decode.d8.loss_mask: 0.1755  decode.d8.loss_dice: 0.2522
08/06 09:40:30 - mmengine - INFO - Iter(train) [ 53550/320000]  base_lr: 8.4805e-05 lr: 8.4805e-06  eta: 1 day, 12:28:06  time: 0.4951  data_time: 0.0112  memory: 5894  grad_norm: 86.7762  loss: 6.8978  decode.loss_cls: 0.0513  decode.loss_mask: 0.2625  decode.loss_dice: 0.2750  decode.d0.loss_cls: 0.8674  decode.d0.loss_mask: 0.2610  decode.d0.loss_dice: 0.2849  decode.d1.loss_cls: 0.1421  decode.d1.loss_mask: 0.2589  decode.d1.loss_dice: 0.2745  decode.d2.loss_cls: 0.0700  decode.d2.loss_mask: 0.2603  decode.d2.loss_dice: 0.2763  decode.d3.loss_cls: 0.0663  decode.d3.loss_mask: 0.2634  decode.d3.loss_dice: 0.2816  decode.d4.loss_cls: 0.1022  decode.d4.loss_mask: 0.2648  decode.d4.loss_dice: 0.2735  decode.d5.loss_cls: 0.0596  decode.d5.loss_mask: 0.2618  decode.d5.loss_dice: 0.2693  decode.d6.loss_cls: 0.0539  decode.d6.loss_mask: 0.2618  decode.d6.loss_dice: 0.2681  decode.d7.loss_cls: 0.0591  decode.d7.loss_mask: 0.2604  decode.d7.loss_dice: 0.2769  decode.d8.loss_cls: 0.0617  decode.d8.loss_mask: 0.2618  decode.d8.loss_dice: 0.2676
08/06 09:40:55 - mmengine - INFO - Iter(train) [ 53600/320000]  base_lr: 8.4790e-05 lr: 8.4790e-06  eta: 1 day, 12:27:42  time: 0.4951  data_time: 0.0113  memory: 5895  grad_norm: 88.4104  loss: 5.3098  decode.loss_cls: 0.0079  decode.loss_mask: 0.2383  decode.loss_dice: 0.2087  decode.d0.loss_cls: 0.7116  decode.d0.loss_mask: 0.2437  decode.d0.loss_dice: 0.2111  decode.d1.loss_cls: 0.0136  decode.d1.loss_mask: 0.2398  decode.d1.loss_dice: 0.2107  decode.d2.loss_cls: 0.0147  decode.d2.loss_mask: 0.2333  decode.d2.loss_dice: 0.2154  decode.d3.loss_cls: 0.0122  decode.d3.loss_mask: 0.2358  decode.d3.loss_dice: 0.2123  decode.d4.loss_cls: 0.0075  decode.d4.loss_mask: 0.2409  decode.d4.loss_dice: 0.2182  decode.d5.loss_cls: 0.0072  decode.d5.loss_mask: 0.2352  decode.d5.loss_dice: 0.2122  decode.d6.loss_cls: 0.0087  decode.d6.loss_mask: 0.2377  decode.d6.loss_dice: 0.2106  decode.d7.loss_cls: 0.0118  decode.d7.loss_mask: 0.2398  decode.d7.loss_dice: 0.2147  decode.d8.loss_cls: 0.0092  decode.d8.loss_mask: 0.2369  decode.d8.loss_dice: 0.2103
08/06 09:41:20 - mmengine - INFO - Iter(train) [ 53650/320000]  base_lr: 8.4776e-05 lr: 8.4776e-06  eta: 1 day, 12:27:18  time: 0.4945  data_time: 0.0111  memory: 5894  grad_norm: 102.4932  loss: 6.6357  decode.loss_cls: 0.0785  decode.loss_mask: 0.2244  decode.loss_dice: 0.2641  decode.d0.loss_cls: 0.8429  decode.d0.loss_mask: 0.2332  decode.d0.loss_dice: 0.2996  decode.d1.loss_cls: 0.0819  decode.d1.loss_mask: 0.2270  decode.d1.loss_dice: 0.2593  decode.d2.loss_cls: 0.0881  decode.d2.loss_mask: 0.2285  decode.d2.loss_dice: 0.2627  decode.d3.loss_cls: 0.0895  decode.d3.loss_mask: 0.2292  decode.d3.loss_dice: 0.2584  decode.d4.loss_cls: 0.0821  decode.d4.loss_mask: 0.2286  decode.d4.loss_dice: 0.2774  decode.d5.loss_cls: 0.0986  decode.d5.loss_mask: 0.2266  decode.d5.loss_dice: 0.2755  decode.d6.loss_cls: 0.1235  decode.d6.loss_mask: 0.2245  decode.d6.loss_dice: 0.2557  decode.d7.loss_cls: 0.1105  decode.d7.loss_mask: 0.2257  decode.d7.loss_dice: 0.2505  decode.d8.loss_cls: 0.1081  decode.d8.loss_mask: 0.2271  decode.d8.loss_dice: 0.2540
08/06 09:41:44 - mmengine - INFO - Iter(train) [ 53700/320000]  base_lr: 8.4762e-05 lr: 8.4762e-06  eta: 1 day, 12:26:54  time: 0.4957  data_time: 0.0112  memory: 5891  grad_norm: 64.0392  loss: 5.9892  decode.loss_cls: 0.0301  decode.loss_mask: 0.2371  decode.loss_dice: 0.2325  decode.d0.loss_cls: 0.7832  decode.d0.loss_mask: 0.2336  decode.d0.loss_dice: 0.2386  decode.d1.loss_cls: 0.0934  decode.d1.loss_mask: 0.2422  decode.d1.loss_dice: 0.2565  decode.d2.loss_cls: 0.0411  decode.d2.loss_mask: 0.2394  decode.d2.loss_dice: 0.2436  decode.d3.loss_cls: 0.0566  decode.d3.loss_mask: 0.2375  decode.d3.loss_dice: 0.2379  decode.d4.loss_cls: 0.0142  decode.d4.loss_mask: 0.2331  decode.d4.loss_dice: 0.2515  decode.d5.loss_cls: 0.0546  decode.d5.loss_mask: 0.2379  decode.d5.loss_dice: 0.2389  decode.d6.loss_cls: 0.0140  decode.d6.loss_mask: 0.2370  decode.d6.loss_dice: 0.2516  decode.d7.loss_cls: 0.0474  decode.d7.loss_mask: 0.2350  decode.d7.loss_dice: 0.2480  decode.d8.loss_cls: 0.0651  decode.d8.loss_mask: 0.2325  decode.d8.loss_dice: 0.2250
08/06 09:42:09 - mmengine - INFO - Iter(train) [ 53750/320000]  base_lr: 8.4748e-05 lr: 8.4748e-06  eta: 1 day, 12:26:30  time: 0.4950  data_time: 0.0113  memory: 5876  grad_norm: 57.0801  loss: 6.4200  decode.loss_cls: 0.0376  decode.loss_mask: 0.2617  decode.loss_dice: 0.2483  decode.d0.loss_cls: 0.8344  decode.d0.loss_mask: 0.2577  decode.d0.loss_dice: 0.2370  decode.d1.loss_cls: 0.0746  decode.d1.loss_mask: 0.2603  decode.d1.loss_dice: 0.2413  decode.d2.loss_cls: 0.0622  decode.d2.loss_mask: 0.2570  decode.d2.loss_dice: 0.2412  decode.d3.loss_cls: 0.0339  decode.d3.loss_mask: 0.2610  decode.d3.loss_dice: 0.2471  decode.d4.loss_cls: 0.0786  decode.d4.loss_mask: 0.2630  decode.d4.loss_dice: 0.2499  decode.d5.loss_cls: 0.0804  decode.d5.loss_mask: 0.2589  decode.d5.loss_dice: 0.2478  decode.d6.loss_cls: 0.0854  decode.d6.loss_mask: 0.2604  decode.d6.loss_dice: 0.2404  decode.d7.loss_cls: 0.0806  decode.d7.loss_mask: 0.2573  decode.d7.loss_dice: 0.2314  decode.d8.loss_cls: 0.0184  decode.d8.loss_mask: 0.2627  decode.d8.loss_dice: 0.2495
08/06 09:42:34 - mmengine - INFO - Iter(train) [ 53800/320000]  base_lr: 8.4733e-05 lr: 8.4733e-06  eta: 1 day, 12:26:06  time: 0.4941  data_time: 0.0112  memory: 5911  grad_norm: 79.6998  loss: 5.8383  decode.loss_cls: 0.0459  decode.loss_mask: 0.2077  decode.loss_dice: 0.2237  decode.d0.loss_cls: 0.8285  decode.d0.loss_mask: 0.2094  decode.d0.loss_dice: 0.2573  decode.d1.loss_cls: 0.0809  decode.d1.loss_mask: 0.2093  decode.d1.loss_dice: 0.2329  decode.d2.loss_cls: 0.0534  decode.d2.loss_mask: 0.2099  decode.d2.loss_dice: 0.2278  decode.d3.loss_cls: 0.0506  decode.d3.loss_mask: 0.2049  decode.d3.loss_dice: 0.2397  decode.d4.loss_cls: 0.0713  decode.d4.loss_mask: 0.2073  decode.d4.loss_dice: 0.2563  decode.d5.loss_cls: 0.0657  decode.d5.loss_mask: 0.2060  decode.d5.loss_dice: 0.2218  decode.d6.loss_cls: 0.0765  decode.d6.loss_mask: 0.2087  decode.d6.loss_dice: 0.2422  decode.d7.loss_cls: 0.0543  decode.d7.loss_mask: 0.2063  decode.d7.loss_dice: 0.2475  decode.d8.loss_cls: 0.0551  decode.d8.loss_mask: 0.2095  decode.d8.loss_dice: 0.2278
08/06 09:42:59 - mmengine - INFO - Iter(train) [ 53850/320000]  base_lr: 8.4719e-05 lr: 8.4719e-06  eta: 1 day, 12:25:42  time: 0.4957  data_time: 0.0112  memory: 5894  grad_norm: 76.2308  loss: 5.8171  decode.loss_cls: 0.0260  decode.loss_mask: 0.2395  decode.loss_dice: 0.2150  decode.d0.loss_cls: 0.9036  decode.d0.loss_mask: 0.2486  decode.d0.loss_dice: 0.2219  decode.d1.loss_cls: 0.0771  decode.d1.loss_mask: 0.2428  decode.d1.loss_dice: 0.2181  decode.d2.loss_cls: 0.0342  decode.d2.loss_mask: 0.2364  decode.d2.loss_dice: 0.2172  decode.d3.loss_cls: 0.0738  decode.d3.loss_mask: 0.2401  decode.d3.loss_dice: 0.2180  decode.d4.loss_cls: 0.0314  decode.d4.loss_mask: 0.2380  decode.d4.loss_dice: 0.2139  decode.d5.loss_cls: 0.0293  decode.d5.loss_mask: 0.2358  decode.d5.loss_dice: 0.2181  decode.d6.loss_cls: 0.0258  decode.d6.loss_mask: 0.2355  decode.d6.loss_dice: 0.2103  decode.d7.loss_cls: 0.0254  decode.d7.loss_mask: 0.2389  decode.d7.loss_dice: 0.2150  decode.d8.loss_cls: 0.0310  decode.d8.loss_mask: 0.2409  decode.d8.loss_dice: 0.2154
08/06 09:43:23 - mmengine - INFO - Iter(train) [ 53900/320000]  base_lr: 8.4705e-05 lr: 8.4705e-06  eta: 1 day, 12:25:18  time: 0.4943  data_time: 0.0112  memory: 5894  grad_norm: 128.5332  loss: 6.0717  decode.loss_cls: 0.0320  decode.loss_mask: 0.2035  decode.loss_dice: 0.2757  decode.d0.loss_cls: 0.9021  decode.d0.loss_mask: 0.2124  decode.d0.loss_dice: 0.2815  decode.d1.loss_cls: 0.0626  decode.d1.loss_mask: 0.2076  decode.d1.loss_dice: 0.2981  decode.d2.loss_cls: 0.0602  decode.d2.loss_mask: 0.2052  decode.d2.loss_dice: 0.2604  decode.d3.loss_cls: 0.0219  decode.d3.loss_mask: 0.2048  decode.d3.loss_dice: 0.2750  decode.d4.loss_cls: 0.0429  decode.d4.loss_mask: 0.2031  decode.d4.loss_dice: 0.2492  decode.d5.loss_cls: 0.0438  decode.d5.loss_mask: 0.2020  decode.d5.loss_dice: 0.2510  decode.d6.loss_cls: 0.0627  decode.d6.loss_mask: 0.2064  decode.d6.loss_dice: 0.2687  decode.d7.loss_cls: 0.0528  decode.d7.loss_mask: 0.2033  decode.d7.loss_dice: 0.2696  decode.d8.loss_cls: 0.0540  decode.d8.loss_mask: 0.2035  decode.d8.loss_dice: 0.2556
08/06 09:43:48 - mmengine - INFO - Iter(train) [ 53950/320000]  base_lr: 8.4690e-05 lr: 8.4690e-06  eta: 1 day, 12:24:53  time: 0.4941  data_time: 0.0112  memory: 5911  grad_norm: 100.4406  loss: 6.2477  decode.loss_cls: 0.1328  decode.loss_mask: 0.1935  decode.loss_dice: 0.2390  decode.d0.loss_cls: 0.7722  decode.d0.loss_mask: 0.2124  decode.d0.loss_dice: 0.2458  decode.d1.loss_cls: 0.1954  decode.d1.loss_mask: 0.2001  decode.d1.loss_dice: 0.2443  decode.d2.loss_cls: 0.1466  decode.d2.loss_mask: 0.1982  decode.d2.loss_dice: 0.2344  decode.d3.loss_cls: 0.0849  decode.d3.loss_mask: 0.1973  decode.d3.loss_dice: 0.2341  decode.d4.loss_cls: 0.0803  decode.d4.loss_mask: 0.1988  decode.d4.loss_dice: 0.2347  decode.d5.loss_cls: 0.1436  decode.d5.loss_mask: 0.1985  decode.d5.loss_dice: 0.2437  decode.d6.loss_cls: 0.0702  decode.d6.loss_mask: 0.1964  decode.d6.loss_dice: 0.2406  decode.d7.loss_cls: 0.0978  decode.d7.loss_mask: 0.2000  decode.d7.loss_dice: 0.2345  decode.d8.loss_cls: 0.1476  decode.d8.loss_mask: 0.1933  decode.d8.loss_dice: 0.2367
08/06 09:44:13 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 09:44:13 - mmengine - INFO - Iter(train) [ 54000/320000]  base_lr: 8.4676e-05 lr: 8.4676e-06  eta: 1 day, 12:24:29  time: 0.4941  data_time: 0.0113  memory: 5895  grad_norm: 63.6969  loss: 7.1193  decode.loss_cls: 0.0642  decode.loss_mask: 0.2741  decode.loss_dice: 0.2903  decode.d0.loss_cls: 0.8608  decode.d0.loss_mask: 0.2791  decode.d0.loss_dice: 0.2823  decode.d1.loss_cls: 0.0572  decode.d1.loss_mask: 0.2787  decode.d1.loss_dice: 0.2808  decode.d2.loss_cls: 0.0733  decode.d2.loss_mask: 0.2796  decode.d2.loss_dice: 0.2768  decode.d3.loss_cls: 0.0724  decode.d3.loss_mask: 0.2809  decode.d3.loss_dice: 0.2850  decode.d4.loss_cls: 0.0806  decode.d4.loss_mask: 0.2781  decode.d4.loss_dice: 0.2851  decode.d5.loss_cls: 0.0853  decode.d5.loss_mask: 0.2790  decode.d5.loss_dice: 0.2904  decode.d6.loss_cls: 0.0594  decode.d6.loss_mask: 0.2769  decode.d6.loss_dice: 0.2909  decode.d7.loss_cls: 0.0669  decode.d7.loss_mask: 0.2760  decode.d7.loss_dice: 0.2835  decode.d8.loss_cls: 0.0693  decode.d8.loss_mask: 0.2776  decode.d8.loss_dice: 0.2848
08/06 09:44:38 - mmengine - INFO - Iter(train) [ 54050/320000]  base_lr: 8.4662e-05 lr: 8.4662e-06  eta: 1 day, 12:24:05  time: 0.4958  data_time: 0.0112  memory: 5911  grad_norm: 222.1240  loss: 5.7506  decode.loss_cls: 0.0579  decode.loss_mask: 0.2241  decode.loss_dice: 0.2485  decode.d0.loss_cls: 0.9130  decode.d0.loss_mask: 0.2213  decode.d0.loss_dice: 0.2243  decode.d1.loss_cls: 0.0234  decode.d1.loss_mask: 0.2197  decode.d1.loss_dice: 0.2363  decode.d2.loss_cls: 0.0258  decode.d2.loss_mask: 0.2226  decode.d2.loss_dice: 0.2328  decode.d3.loss_cls: 0.0293  decode.d3.loss_mask: 0.2171  decode.d3.loss_dice: 0.2279  decode.d4.loss_cls: 0.0323  decode.d4.loss_mask: 0.2221  decode.d4.loss_dice: 0.2398  decode.d5.loss_cls: 0.0345  decode.d5.loss_mask: 0.2203  decode.d5.loss_dice: 0.2266  decode.d6.loss_cls: 0.0318  decode.d6.loss_mask: 0.2197  decode.d6.loss_dice: 0.2236  decode.d7.loss_cls: 0.0272  decode.d7.loss_mask: 0.2233  decode.d7.loss_dice: 0.2310  decode.d8.loss_cls: 0.0404  decode.d8.loss_mask: 0.2237  decode.d8.loss_dice: 0.2302
08/06 09:45:02 - mmengine - INFO - Iter(train) [ 54100/320000]  base_lr: 8.4647e-05 lr: 8.4647e-06  eta: 1 day, 12:23:41  time: 0.4952  data_time: 0.0112  memory: 5878  grad_norm: 152.5196  loss: 6.8971  decode.loss_cls: 0.1106  decode.loss_mask: 0.2488  decode.loss_dice: 0.2802  decode.d0.loss_cls: 0.8647  decode.d0.loss_mask: 0.2563  decode.d0.loss_dice: 0.2736  decode.d1.loss_cls: 0.1140  decode.d1.loss_mask: 0.2500  decode.d1.loss_dice: 0.2818  decode.d2.loss_cls: 0.0494  decode.d2.loss_mask: 0.2486  decode.d2.loss_dice: 0.2696  decode.d3.loss_cls: 0.0768  decode.d3.loss_mask: 0.2464  decode.d3.loss_dice: 0.2761  decode.d4.loss_cls: 0.0837  decode.d4.loss_mask: 0.2441  decode.d4.loss_dice: 0.2590  decode.d5.loss_cls: 0.0792  decode.d5.loss_mask: 0.2458  decode.d5.loss_dice: 0.2652  decode.d6.loss_cls: 0.0876  decode.d6.loss_mask: 0.2485  decode.d6.loss_dice: 0.2873  decode.d7.loss_cls: 0.1186  decode.d7.loss_mask: 0.2499  decode.d7.loss_dice: 0.2842  decode.d8.loss_cls: 0.0849  decode.d8.loss_mask: 0.2488  decode.d8.loss_dice: 0.2632
08/06 09:45:27 - mmengine - INFO - Iter(train) [ 54150/320000]  base_lr: 8.4633e-05 lr: 8.4633e-06  eta: 1 day, 12:23:17  time: 0.4944  data_time: 0.0111  memory: 5895  grad_norm: 109.4273  loss: 7.0486  decode.loss_cls: 0.0942  decode.loss_mask: 0.2445  decode.loss_dice: 0.2654  decode.d0.loss_cls: 0.9032  decode.d0.loss_mask: 0.2437  decode.d0.loss_dice: 0.2625  decode.d1.loss_cls: 0.1404  decode.d1.loss_mask: 0.2500  decode.d1.loss_dice: 0.2714  decode.d2.loss_cls: 0.1455  decode.d2.loss_mask: 0.2490  decode.d2.loss_dice: 0.2671  decode.d3.loss_cls: 0.1187  decode.d3.loss_mask: 0.2525  decode.d3.loss_dice: 0.2673  decode.d4.loss_cls: 0.1001  decode.d4.loss_mask: 0.2478  decode.d4.loss_dice: 0.2544  decode.d5.loss_cls: 0.0828  decode.d5.loss_mask: 0.2498  decode.d5.loss_dice: 0.2889  decode.d6.loss_cls: 0.1055  decode.d6.loss_mask: 0.2441  decode.d6.loss_dice: 0.2619  decode.d7.loss_cls: 0.1159  decode.d7.loss_mask: 0.2483  decode.d7.loss_dice: 0.2569  decode.d8.loss_cls: 0.0876  decode.d8.loss_mask: 0.2450  decode.d8.loss_dice: 0.2843
08/06 09:45:52 - mmengine - INFO - Iter(train) [ 54200/320000]  base_lr: 8.4619e-05 lr: 8.4619e-06  eta: 1 day, 12:22:53  time: 0.4948  data_time: 0.0113  memory: 5894  grad_norm: 93.9258  loss: 9.4891  decode.loss_cls: 0.1263  decode.loss_mask: 0.3316  decode.loss_dice: 0.3902  decode.d0.loss_cls: 0.8456  decode.d0.loss_mask: 0.3441  decode.d0.loss_dice: 0.3978  decode.d1.loss_cls: 0.1860  decode.d1.loss_mask: 0.3280  decode.d1.loss_dice: 0.3622  decode.d2.loss_cls: 0.1984  decode.d2.loss_mask: 0.3275  decode.d2.loss_dice: 0.3560  decode.d3.loss_cls: 0.2247  decode.d3.loss_mask: 0.3393  decode.d3.loss_dice: 0.3781  decode.d4.loss_cls: 0.1697  decode.d4.loss_mask: 0.3348  decode.d4.loss_dice: 0.3876  decode.d5.loss_cls: 0.1552  decode.d5.loss_mask: 0.3344  decode.d5.loss_dice: 0.3800  decode.d6.loss_cls: 0.1678  decode.d6.loss_mask: 0.3285  decode.d6.loss_dice: 0.3829  decode.d7.loss_cls: 0.1834  decode.d7.loss_mask: 0.3304  decode.d7.loss_dice: 0.3786  decode.d8.loss_cls: 0.1164  decode.d8.loss_mask: 0.3306  decode.d8.loss_dice: 0.3728
08/06 09:46:17 - mmengine - INFO - Iter(train) [ 54250/320000]  base_lr: 8.4604e-05 lr: 8.4604e-06  eta: 1 day, 12:22:29  time: 0.4948  data_time: 0.0111  memory: 5911  grad_norm: 55.2623  loss: 6.3343  decode.loss_cls: 0.1000  decode.loss_mask: 0.1904  decode.loss_dice: 0.2558  decode.d0.loss_cls: 0.8578  decode.d0.loss_mask: 0.1967  decode.d0.loss_dice: 0.2861  decode.d1.loss_cls: 0.1151  decode.d1.loss_mask: 0.1894  decode.d1.loss_dice: 0.2614  decode.d2.loss_cls: 0.1035  decode.d2.loss_mask: 0.1892  decode.d2.loss_dice: 0.2715  decode.d3.loss_cls: 0.0943  decode.d3.loss_mask: 0.1889  decode.d3.loss_dice: 0.2550  decode.d4.loss_cls: 0.1068  decode.d4.loss_mask: 0.1919  decode.d4.loss_dice: 0.2684  decode.d5.loss_cls: 0.1125  decode.d5.loss_mask: 0.1906  decode.d5.loss_dice: 0.2628  decode.d6.loss_cls: 0.0989  decode.d6.loss_mask: 0.1924  decode.d6.loss_dice: 0.2558  decode.d7.loss_cls: 0.0972  decode.d7.loss_mask: 0.1911  decode.d7.loss_dice: 0.2580  decode.d8.loss_cls: 0.1071  decode.d8.loss_mask: 0.1877  decode.d8.loss_dice: 0.2580
08/06 09:46:41 - mmengine - INFO - Iter(train) [ 54300/320000]  base_lr: 8.4590e-05 lr: 8.4590e-06  eta: 1 day, 12:22:05  time: 0.4955  data_time: 0.0114  memory: 5876  grad_norm: 71.2970  loss: 5.9042  decode.loss_cls: 0.1048  decode.loss_mask: 0.1678  decode.loss_dice: 0.2133  decode.d0.loss_cls: 0.9397  decode.d0.loss_mask: 0.1678  decode.d0.loss_dice: 0.2202  decode.d1.loss_cls: 0.0973  decode.d1.loss_mask: 0.1701  decode.d1.loss_dice: 0.2234  decode.d2.loss_cls: 0.1386  decode.d2.loss_mask: 0.1684  decode.d2.loss_dice: 0.2165  decode.d3.loss_cls: 0.1499  decode.d3.loss_mask: 0.1696  decode.d3.loss_dice: 0.2123  decode.d4.loss_cls: 0.1312  decode.d4.loss_mask: 0.1674  decode.d4.loss_dice: 0.2176  decode.d5.loss_cls: 0.1059  decode.d5.loss_mask: 0.1703  decode.d5.loss_dice: 0.2184  decode.d6.loss_cls: 0.1297  decode.d6.loss_mask: 0.1701  decode.d6.loss_dice: 0.2120  decode.d7.loss_cls: 0.1210  decode.d7.loss_mask: 0.1724  decode.d7.loss_dice: 0.2213  decode.d8.loss_cls: 0.1214  decode.d8.loss_mask: 0.1689  decode.d8.loss_dice: 0.2169
08/06 09:47:06 - mmengine - INFO - Iter(train) [ 54350/320000]  base_lr: 8.4576e-05 lr: 8.4576e-06  eta: 1 day, 12:21:41  time: 0.4950  data_time: 0.0111  memory: 5876  grad_norm: 253.8486  loss: 7.9761  decode.loss_cls: 0.2213  decode.loss_mask: 0.2136  decode.loss_dice: 0.2986  decode.d0.loss_cls: 0.9612  decode.d0.loss_mask: 0.2136  decode.d0.loss_dice: 0.2854  decode.d1.loss_cls: 0.1942  decode.d1.loss_mask: 0.2123  decode.d1.loss_dice: 0.2988  decode.d2.loss_cls: 0.2455  decode.d2.loss_mask: 0.2068  decode.d2.loss_dice: 0.2704  decode.d3.loss_cls: 0.2271  decode.d3.loss_mask: 0.2052  decode.d3.loss_dice: 0.2826  decode.d4.loss_cls: 0.2195  decode.d4.loss_mask: 0.2091  decode.d4.loss_dice: 0.2715  decode.d5.loss_cls: 0.2455  decode.d5.loss_mask: 0.2088  decode.d5.loss_dice: 0.2729  decode.d6.loss_cls: 0.2262  decode.d6.loss_mask: 0.2109  decode.d6.loss_dice: 0.2926  decode.d7.loss_cls: 0.2854  decode.d7.loss_mask: 0.2073  decode.d7.loss_dice: 0.2972  decode.d8.loss_cls: 0.2346  decode.d8.loss_mask: 0.2055  decode.d8.loss_dice: 0.2524
08/06 09:47:31 - mmengine - INFO - Iter(train) [ 54400/320000]  base_lr: 8.4561e-05 lr: 8.4561e-06  eta: 1 day, 12:21:17  time: 0.4957  data_time: 0.0113  memory: 5891  grad_norm: 115.5573  loss: 7.0790  decode.loss_cls: 0.1412  decode.loss_mask: 0.2111  decode.loss_dice: 0.2524  decode.d0.loss_cls: 0.8838  decode.d0.loss_mask: 0.2179  decode.d0.loss_dice: 0.2599  decode.d1.loss_cls: 0.2333  decode.d1.loss_mask: 0.2136  decode.d1.loss_dice: 0.2524  decode.d2.loss_cls: 0.1738  decode.d2.loss_mask: 0.2142  decode.d2.loss_dice: 0.2686  decode.d3.loss_cls: 0.1717  decode.d3.loss_mask: 0.2131  decode.d3.loss_dice: 0.2569  decode.d4.loss_cls: 0.1649  decode.d4.loss_mask: 0.2142  decode.d4.loss_dice: 0.2672  decode.d5.loss_cls: 0.1550  decode.d5.loss_mask: 0.2111  decode.d5.loss_dice: 0.2636  decode.d6.loss_cls: 0.1291  decode.d6.loss_mask: 0.2118  decode.d6.loss_dice: 0.2640  decode.d7.loss_cls: 0.1328  decode.d7.loss_mask: 0.2091  decode.d7.loss_dice: 0.2661  decode.d8.loss_cls: 0.1532  decode.d8.loss_mask: 0.2129  decode.d8.loss_dice: 0.2603
08/06 09:47:56 - mmengine - INFO - Iter(train) [ 54450/320000]  base_lr: 8.4547e-05 lr: 8.4547e-06  eta: 1 day, 12:20:53  time: 0.4946  data_time: 0.0111  memory: 5928  grad_norm: 70.4046  loss: 7.1807  decode.loss_cls: 0.1050  decode.loss_mask: 0.2355  decode.loss_dice: 0.2967  decode.d0.loss_cls: 0.7634  decode.d0.loss_mask: 0.2366  decode.d0.loss_dice: 0.3037  decode.d1.loss_cls: 0.1229  decode.d1.loss_mask: 0.2335  decode.d1.loss_dice: 0.3046  decode.d2.loss_cls: 0.1365  decode.d2.loss_mask: 0.2333  decode.d2.loss_dice: 0.3007  decode.d3.loss_cls: 0.1542  decode.d3.loss_mask: 0.2321  decode.d3.loss_dice: 0.2933  decode.d4.loss_cls: 0.1127  decode.d4.loss_mask: 0.2361  decode.d4.loss_dice: 0.2900  decode.d5.loss_cls: 0.1430  decode.d5.loss_mask: 0.2307  decode.d5.loss_dice: 0.2916  decode.d6.loss_cls: 0.1464  decode.d6.loss_mask: 0.2320  decode.d6.loss_dice: 0.2837  decode.d7.loss_cls: 0.1085  decode.d7.loss_mask: 0.2317  decode.d7.loss_dice: 0.2922  decode.d8.loss_cls: 0.1019  decode.d8.loss_mask: 0.2325  decode.d8.loss_dice: 0.2956
08/06 09:48:21 - mmengine - INFO - Iter(train) [ 54500/320000]  base_lr: 8.4533e-05 lr: 8.4533e-06  eta: 1 day, 12:20:29  time: 0.4946  data_time: 0.0111  memory: 5894  grad_norm: 57.7131  loss: 6.9938  decode.loss_cls: 0.0891  decode.loss_mask: 0.2307  decode.loss_dice: 0.3159  decode.d0.loss_cls: 0.8222  decode.d0.loss_mask: 0.2308  decode.d0.loss_dice: 0.3140  decode.d1.loss_cls: 0.1118  decode.d1.loss_mask: 0.2303  decode.d1.loss_dice: 0.3040  decode.d2.loss_cls: 0.0822  decode.d2.loss_mask: 0.2315  decode.d2.loss_dice: 0.3264  decode.d3.loss_cls: 0.1100  decode.d3.loss_mask: 0.2281  decode.d3.loss_dice: 0.2962  decode.d4.loss_cls: 0.0822  decode.d4.loss_mask: 0.2294  decode.d4.loss_dice: 0.2989  decode.d5.loss_cls: 0.0823  decode.d5.loss_mask: 0.2265  decode.d5.loss_dice: 0.3118  decode.d6.loss_cls: 0.0883  decode.d6.loss_mask: 0.2286  decode.d6.loss_dice: 0.2953  decode.d7.loss_cls: 0.0796  decode.d7.loss_mask: 0.2259  decode.d7.loss_dice: 0.3150  decode.d8.loss_cls: 0.0646  decode.d8.loss_mask: 0.2306  decode.d8.loss_dice: 0.3118
08/06 09:48:45 - mmengine - INFO - Iter(train) [ 54550/320000]  base_lr: 8.4518e-05 lr: 8.4518e-06  eta: 1 day, 12:20:05  time: 0.4953  data_time: 0.0110  memory: 5894  grad_norm: 54.7294  loss: 7.0762  decode.loss_cls: 0.0990  decode.loss_mask: 0.2493  decode.loss_dice: 0.2601  decode.d0.loss_cls: 0.8443  decode.d0.loss_mask: 0.2506  decode.d0.loss_dice: 0.2596  decode.d1.loss_cls: 0.1409  decode.d1.loss_mask: 0.2375  decode.d1.loss_dice: 0.2604  decode.d2.loss_cls: 0.1349  decode.d2.loss_mask: 0.2472  decode.d2.loss_dice: 0.2646  decode.d3.loss_cls: 0.1825  decode.d3.loss_mask: 0.2402  decode.d3.loss_dice: 0.2611  decode.d4.loss_cls: 0.1187  decode.d4.loss_mask: 0.2505  decode.d4.loss_dice: 0.2572  decode.d5.loss_cls: 0.1191  decode.d5.loss_mask: 0.2557  decode.d5.loss_dice: 0.2624  decode.d6.loss_cls: 0.1622  decode.d6.loss_mask: 0.2445  decode.d6.loss_dice: 0.2585  decode.d7.loss_cls: 0.0852  decode.d7.loss_mask: 0.2481  decode.d7.loss_dice: 0.2611  decode.d8.loss_cls: 0.1126  decode.d8.loss_mask: 0.2509  decode.d8.loss_dice: 0.2574
08/06 09:49:10 - mmengine - INFO - Iter(train) [ 54600/320000]  base_lr: 8.4504e-05 lr: 8.4504e-06  eta: 1 day, 12:19:41  time: 0.4956  data_time: 0.0110  memory: 5891  grad_norm: 36.6617  loss: 6.6057  decode.loss_cls: 0.1684  decode.loss_mask: 0.1546  decode.loss_dice: 0.2877  decode.d0.loss_cls: 0.7918  decode.d0.loss_mask: 0.1577  decode.d0.loss_dice: 0.2944  decode.d1.loss_cls: 0.1293  decode.d1.loss_mask: 0.1529  decode.d1.loss_dice: 0.2739  decode.d2.loss_cls: 0.1547  decode.d2.loss_mask: 0.1601  decode.d2.loss_dice: 0.2852  decode.d3.loss_cls: 0.1758  decode.d3.loss_mask: 0.1562  decode.d3.loss_dice: 0.2713  decode.d4.loss_cls: 0.1362  decode.d4.loss_mask: 0.1557  decode.d4.loss_dice: 0.2854  decode.d5.loss_cls: 0.1581  decode.d5.loss_mask: 0.1563  decode.d5.loss_dice: 0.3018  decode.d6.loss_cls: 0.1470  decode.d6.loss_mask: 0.1571  decode.d6.loss_dice: 0.2721  decode.d7.loss_cls: 0.1737  decode.d7.loss_mask: 0.1575  decode.d7.loss_dice: 0.2867  decode.d8.loss_cls: 0.1700  decode.d8.loss_mask: 0.1546  decode.d8.loss_dice: 0.2795
08/06 09:49:35 - mmengine - INFO - Iter(train) [ 54650/320000]  base_lr: 8.4490e-05 lr: 8.4490e-06  eta: 1 day, 12:19:17  time: 0.4952  data_time: 0.0114  memory: 5911  grad_norm: 100.4834  loss: 6.9764  decode.loss_cls: 0.1101  decode.loss_mask: 0.2274  decode.loss_dice: 0.2584  decode.d0.loss_cls: 1.0184  decode.d0.loss_mask: 0.2320  decode.d0.loss_dice: 0.2448  decode.d1.loss_cls: 0.2148  decode.d1.loss_mask: 0.2312  decode.d1.loss_dice: 0.2601  decode.d2.loss_cls: 0.1259  decode.d2.loss_mask: 0.2318  decode.d2.loss_dice: 0.2711  decode.d3.loss_cls: 0.1145  decode.d3.loss_mask: 0.2312  decode.d3.loss_dice: 0.2654  decode.d4.loss_cls: 0.1299  decode.d4.loss_mask: 0.2284  decode.d4.loss_dice: 0.2521  decode.d5.loss_cls: 0.1199  decode.d5.loss_mask: 0.2278  decode.d5.loss_dice: 0.2410  decode.d6.loss_cls: 0.1157  decode.d6.loss_mask: 0.2270  decode.d6.loss_dice: 0.2432  decode.d7.loss_cls: 0.1083  decode.d7.loss_mask: 0.2260  decode.d7.loss_dice: 0.2483  decode.d8.loss_cls: 0.0814  decode.d8.loss_mask: 0.2277  decode.d8.loss_dice: 0.2627
08/06 09:50:00 - mmengine - INFO - Iter(train) [ 54700/320000]  base_lr: 8.4475e-05 lr: 8.4475e-06  eta: 1 day, 12:18:53  time: 0.4961  data_time: 0.0114  memory: 5930  grad_norm: 98.4780  loss: 7.1378  decode.loss_cls: 0.1455  decode.loss_mask: 0.2180  decode.loss_dice: 0.2871  decode.d0.loss_cls: 0.7708  decode.d0.loss_mask: 0.2233  decode.d0.loss_dice: 0.2633  decode.d1.loss_cls: 0.1835  decode.d1.loss_mask: 0.2191  decode.d1.loss_dice: 0.2834  decode.d2.loss_cls: 0.1660  decode.d2.loss_mask: 0.2215  decode.d2.loss_dice: 0.2777  decode.d3.loss_cls: 0.1322  decode.d3.loss_mask: 0.2179  decode.d3.loss_dice: 0.2766  decode.d4.loss_cls: 0.1455  decode.d4.loss_mask: 0.2169  decode.d4.loss_dice: 0.2822  decode.d5.loss_cls: 0.1669  decode.d5.loss_mask: 0.2160  decode.d5.loss_dice: 0.2968  decode.d6.loss_cls: 0.1461  decode.d6.loss_mask: 0.2184  decode.d6.loss_dice: 0.2783  decode.d7.loss_cls: 0.1649  decode.d7.loss_mask: 0.2170  decode.d7.loss_dice: 0.2764  decode.d8.loss_cls: 0.1367  decode.d8.loss_mask: 0.2162  decode.d8.loss_dice: 0.2736
08/06 09:50:24 - mmengine - INFO - Iter(train) [ 54750/320000]  base_lr: 8.4461e-05 lr: 8.4461e-06  eta: 1 day, 12:18:29  time: 0.4963  data_time: 0.0113  memory: 5911  grad_norm: 57.9529  loss: 7.3714  decode.loss_cls: 0.1719  decode.loss_mask: 0.2104  decode.loss_dice: 0.2989  decode.d0.loss_cls: 1.0154  decode.d0.loss_mask: 0.2099  decode.d0.loss_dice: 0.2886  decode.d1.loss_cls: 0.1638  decode.d1.loss_mask: 0.2053  decode.d1.loss_dice: 0.2852  decode.d2.loss_cls: 0.1029  decode.d2.loss_mask: 0.2099  decode.d2.loss_dice: 0.2900  decode.d3.loss_cls: 0.1023  decode.d3.loss_mask: 0.2122  decode.d3.loss_dice: 0.3050  decode.d4.loss_cls: 0.1244  decode.d4.loss_mask: 0.2119  decode.d4.loss_dice: 0.2886  decode.d5.loss_cls: 0.1146  decode.d5.loss_mask: 0.2085  decode.d5.loss_dice: 0.2897  decode.d6.loss_cls: 0.2086  decode.d6.loss_mask: 0.2064  decode.d6.loss_dice: 0.2645  decode.d7.loss_cls: 0.2248  decode.d7.loss_mask: 0.2087  decode.d7.loss_dice: 0.2987  decode.d8.loss_cls: 0.1312  decode.d8.loss_mask: 0.2129  decode.d8.loss_dice: 0.3061
08/06 09:50:49 - mmengine - INFO - Iter(train) [ 54800/320000]  base_lr: 8.4447e-05 lr: 8.4447e-06  eta: 1 day, 12:18:04  time: 0.4946  data_time: 0.0111  memory: 5928  grad_norm: 88.1902  loss: 5.6767  decode.loss_cls: 0.0561  decode.loss_mask: 0.1905  decode.loss_dice: 0.2536  decode.d0.loss_cls: 0.6476  decode.d0.loss_mask: 0.1921  decode.d0.loss_dice: 0.2403  decode.d1.loss_cls: 0.0306  decode.d1.loss_mask: 0.1933  decode.d1.loss_dice: 0.2468  decode.d2.loss_cls: 0.1178  decode.d2.loss_mask: 0.1914  decode.d2.loss_dice: 0.2336  decode.d3.loss_cls: 0.1498  decode.d3.loss_mask: 0.1903  decode.d3.loss_dice: 0.2346  decode.d4.loss_cls: 0.1052  decode.d4.loss_mask: 0.1922  decode.d4.loss_dice: 0.2341  decode.d5.loss_cls: 0.0599  decode.d5.loss_mask: 0.1918  decode.d5.loss_dice: 0.2432  decode.d6.loss_cls: 0.0668  decode.d6.loss_mask: 0.1892  decode.d6.loss_dice: 0.2433  decode.d7.loss_cls: 0.0681  decode.d7.loss_mask: 0.1900  decode.d7.loss_dice: 0.2361  decode.d8.loss_cls: 0.0526  decode.d8.loss_mask: 0.1917  decode.d8.loss_dice: 0.2443
08/06 09:51:14 - mmengine - INFO - Iter(train) [ 54850/320000]  base_lr: 8.4432e-05 lr: 8.4432e-06  eta: 1 day, 12:17:40  time: 0.4956  data_time: 0.0112  memory: 5894  grad_norm: 93.2401  loss: 6.5474  decode.loss_cls: 0.0543  decode.loss_mask: 0.2662  decode.loss_dice: 0.2357  decode.d0.loss_cls: 0.8673  decode.d0.loss_mask: 0.2621  decode.d0.loss_dice: 0.2398  decode.d1.loss_cls: 0.0761  decode.d1.loss_mask: 0.2635  decode.d1.loss_dice: 0.2419  decode.d2.loss_cls: 0.0648  decode.d2.loss_mask: 0.2608  decode.d2.loss_dice: 0.2364  decode.d3.loss_cls: 0.1324  decode.d3.loss_mask: 0.2581  decode.d3.loss_dice: 0.2323  decode.d4.loss_cls: 0.0821  decode.d4.loss_mask: 0.2651  decode.d4.loss_dice: 0.2421  decode.d5.loss_cls: 0.0520  decode.d5.loss_mask: 0.2639  decode.d5.loss_dice: 0.2383  decode.d6.loss_cls: 0.0581  decode.d6.loss_mask: 0.2631  decode.d6.loss_dice: 0.2349  decode.d7.loss_cls: 0.1195  decode.d7.loss_mask: 0.2585  decode.d7.loss_dice: 0.2265  decode.d8.loss_cls: 0.0531  decode.d8.loss_mask: 0.2629  decode.d8.loss_dice: 0.2358
08/06 09:51:39 - mmengine - INFO - Iter(train) [ 54900/320000]  base_lr: 8.4418e-05 lr: 8.4418e-06  eta: 1 day, 12:17:16  time: 0.4959  data_time: 0.0114  memory: 5895  grad_norm: 45.2626  loss: 6.8911  decode.loss_cls: 0.1187  decode.loss_mask: 0.2392  decode.loss_dice: 0.2910  decode.d0.loss_cls: 0.7788  decode.d0.loss_mask: 0.2391  decode.d0.loss_dice: 0.2881  decode.d1.loss_cls: 0.1043  decode.d1.loss_mask: 0.2375  decode.d1.loss_dice: 0.2699  decode.d2.loss_cls: 0.1082  decode.d2.loss_mask: 0.2398  decode.d2.loss_dice: 0.2867  decode.d3.loss_cls: 0.0958  decode.d3.loss_mask: 0.2426  decode.d3.loss_dice: 0.2662  decode.d4.loss_cls: 0.0882  decode.d4.loss_mask: 0.2372  decode.d4.loss_dice: 0.2803  decode.d5.loss_cls: 0.0810  decode.d5.loss_mask: 0.2423  decode.d5.loss_dice: 0.2901  decode.d6.loss_cls: 0.0929  decode.d6.loss_mask: 0.2366  decode.d6.loss_dice: 0.2945  decode.d7.loss_cls: 0.0977  decode.d7.loss_mask: 0.2369  decode.d7.loss_dice: 0.2656  decode.d8.loss_cls: 0.1313  decode.d8.loss_mask: 0.2397  decode.d8.loss_dice: 0.2708
08/06 09:52:03 - mmengine - INFO - Iter(train) [ 54950/320000]  base_lr: 8.4404e-05 lr: 8.4404e-06  eta: 1 day, 12:16:52  time: 0.4946  data_time: 0.0112  memory: 5928  grad_norm: 173.4396  loss: 7.5086  decode.loss_cls: 0.0830  decode.loss_mask: 0.2881  decode.loss_dice: 0.3167  decode.d0.loss_cls: 0.8093  decode.d0.loss_mask: 0.2925  decode.d0.loss_dice: 0.2963  decode.d1.loss_cls: 0.0872  decode.d1.loss_mask: 0.2841  decode.d1.loss_dice: 0.2913  decode.d2.loss_cls: 0.0678  decode.d2.loss_mask: 0.2822  decode.d2.loss_dice: 0.2927  decode.d3.loss_cls: 0.0924  decode.d3.loss_mask: 0.2812  decode.d3.loss_dice: 0.2908  decode.d4.loss_cls: 0.1052  decode.d4.loss_mask: 0.2842  decode.d4.loss_dice: 0.3120  decode.d5.loss_cls: 0.1008  decode.d5.loss_mask: 0.2823  decode.d5.loss_dice: 0.3101  decode.d6.loss_cls: 0.1067  decode.d6.loss_mask: 0.2826  decode.d6.loss_dice: 0.3201  decode.d7.loss_cls: 0.0809  decode.d7.loss_mask: 0.2872  decode.d7.loss_dice: 0.3161  decode.d8.loss_cls: 0.0770  decode.d8.loss_mask: 0.2877  decode.d8.loss_dice: 0.3002
08/06 09:52:28 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 09:52:28 - mmengine - INFO - Iter(train) [ 55000/320000]  base_lr: 8.4389e-05 lr: 8.4389e-06  eta: 1 day, 12:16:28  time: 0.4949  data_time: 0.0113  memory: 5894  grad_norm: 74.3781  loss: 6.4589  decode.loss_cls: 0.0750  decode.loss_mask: 0.2201  decode.loss_dice: 0.2681  decode.d0.loss_cls: 0.8431  decode.d0.loss_mask: 0.2246  decode.d0.loss_dice: 0.2735  decode.d1.loss_cls: 0.0551  decode.d1.loss_mask: 0.2206  decode.d1.loss_dice: 0.2811  decode.d2.loss_cls: 0.0888  decode.d2.loss_mask: 0.2211  decode.d2.loss_dice: 0.2679  decode.d3.loss_cls: 0.0944  decode.d3.loss_mask: 0.2208  decode.d3.loss_dice: 0.2616  decode.d4.loss_cls: 0.1019  decode.d4.loss_mask: 0.2207  decode.d4.loss_dice: 0.2678  decode.d5.loss_cls: 0.0898  decode.d5.loss_mask: 0.2215  decode.d5.loss_dice: 0.2518  decode.d6.loss_cls: 0.0785  decode.d6.loss_mask: 0.2206  decode.d6.loss_dice: 0.2660  decode.d7.loss_cls: 0.0854  decode.d7.loss_mask: 0.2201  decode.d7.loss_dice: 0.2567  decode.d8.loss_cls: 0.0765  decode.d8.loss_mask: 0.2210  decode.d8.loss_dice: 0.2648
08/06 09:52:53 - mmengine - INFO - Iter(train) [ 55050/320000]  base_lr: 8.4375e-05 lr: 8.4375e-06  eta: 1 day, 12:16:03  time: 0.4950  data_time: 0.0110  memory: 5891  grad_norm: 94.0898  loss: 5.8260  decode.loss_cls: 0.0651  decode.loss_mask: 0.2075  decode.loss_dice: 0.2286  decode.d0.loss_cls: 0.7602  decode.d0.loss_mask: 0.2157  decode.d0.loss_dice: 0.2297  decode.d1.loss_cls: 0.0771  decode.d1.loss_mask: 0.2116  decode.d1.loss_dice: 0.2414  decode.d2.loss_cls: 0.0533  decode.d2.loss_mask: 0.2099  decode.d2.loss_dice: 0.2264  decode.d3.loss_cls: 0.0796  decode.d3.loss_mask: 0.2030  decode.d3.loss_dice: 0.2262  decode.d4.loss_cls: 0.0810  decode.d4.loss_mask: 0.2081  decode.d4.loss_dice: 0.2268  decode.d5.loss_cls: 0.0876  decode.d5.loss_mask: 0.2100  decode.d5.loss_dice: 0.2275  decode.d6.loss_cls: 0.0816  decode.d6.loss_mask: 0.2085  decode.d6.loss_dice: 0.2276  decode.d7.loss_cls: 0.0837  decode.d7.loss_mask: 0.2087  decode.d7.loss_dice: 0.2259  decode.d8.loss_cls: 0.0743  decode.d8.loss_mask: 0.2120  decode.d8.loss_dice: 0.2276
08/06 09:53:18 - mmengine - INFO - Iter(train) [ 55100/320000]  base_lr: 8.4361e-05 lr: 8.4361e-06  eta: 1 day, 12:15:40  time: 0.4951  data_time: 0.0111  memory: 5909  grad_norm: 172.7748  loss: 7.6578  decode.loss_cls: 0.1339  decode.loss_mask: 0.2498  decode.loss_dice: 0.2956  decode.d0.loss_cls: 0.9613  decode.d0.loss_mask: 0.2565  decode.d0.loss_dice: 0.3113  decode.d1.loss_cls: 0.0991  decode.d1.loss_mask: 0.2539  decode.d1.loss_dice: 0.3095  decode.d2.loss_cls: 0.1042  decode.d2.loss_mask: 0.2605  decode.d2.loss_dice: 0.3016  decode.d3.loss_cls: 0.0982  decode.d3.loss_mask: 0.2553  decode.d3.loss_dice: 0.2922  decode.d4.loss_cls: 0.1013  decode.d4.loss_mask: 0.2537  decode.d4.loss_dice: 0.2770  decode.d5.loss_cls: 0.1414  decode.d5.loss_mask: 0.2539  decode.d5.loss_dice: 0.2923  decode.d6.loss_cls: 0.1917  decode.d6.loss_mask: 0.2538  decode.d6.loss_dice: 0.3138  decode.d7.loss_cls: 0.1393  decode.d7.loss_mask: 0.2519  decode.d7.loss_dice: 0.3040  decode.d8.loss_cls: 0.1476  decode.d8.loss_mask: 0.2536  decode.d8.loss_dice: 0.2996
08/06 09:53:42 - mmengine - INFO - Iter(train) [ 55150/320000]  base_lr: 8.4346e-05 lr: 8.4346e-06  eta: 1 day, 12:15:16  time: 0.4963  data_time: 0.0113  memory: 5930  grad_norm: 148.2740  loss: 6.7501  decode.loss_cls: 0.1649  decode.loss_mask: 0.1908  decode.loss_dice: 0.2532  decode.d0.loss_cls: 0.9500  decode.d0.loss_mask: 0.1736  decode.d0.loss_dice: 0.2409  decode.d1.loss_cls: 0.1104  decode.d1.loss_mask: 0.1761  decode.d1.loss_dice: 0.2250  decode.d2.loss_cls: 0.2310  decode.d2.loss_mask: 0.1730  decode.d2.loss_dice: 0.2436  decode.d3.loss_cls: 0.1981  decode.d3.loss_mask: 0.1805  decode.d3.loss_dice: 0.2418  decode.d4.loss_cls: 0.1520  decode.d4.loss_mask: 0.1838  decode.d4.loss_dice: 0.2569  decode.d5.loss_cls: 0.1549  decode.d5.loss_mask: 0.1795  decode.d5.loss_dice: 0.2529  decode.d6.loss_cls: 0.2324  decode.d6.loss_mask: 0.1764  decode.d6.loss_dice: 0.2403  decode.d7.loss_cls: 0.1582  decode.d7.loss_mask: 0.1861  decode.d7.loss_dice: 0.2624  decode.d8.loss_cls: 0.1403  decode.d8.loss_mask: 0.1846  decode.d8.loss_dice: 0.2362
08/06 09:54:07 - mmengine - INFO - Iter(train) [ 55200/320000]  base_lr: 8.4332e-05 lr: 8.4332e-06  eta: 1 day, 12:14:51  time: 0.4948  data_time: 0.0112  memory: 5894  grad_norm: 164.6216  loss: 7.3550  decode.loss_cls: 0.1408  decode.loss_mask: 0.2206  decode.loss_dice: 0.3012  decode.d0.loss_cls: 0.9578  decode.d0.loss_mask: 0.2157  decode.d0.loss_dice: 0.3160  decode.d1.loss_cls: 0.1533  decode.d1.loss_mask: 0.2118  decode.d1.loss_dice: 0.3001  decode.d2.loss_cls: 0.1609  decode.d2.loss_mask: 0.2137  decode.d2.loss_dice: 0.3017  decode.d3.loss_cls: 0.1375  decode.d3.loss_mask: 0.2097  decode.d3.loss_dice: 0.3045  decode.d4.loss_cls: 0.1522  decode.d4.loss_mask: 0.2127  decode.d4.loss_dice: 0.2941  decode.d5.loss_cls: 0.1659  decode.d5.loss_mask: 0.2093  decode.d5.loss_dice: 0.2852  decode.d6.loss_cls: 0.1326  decode.d6.loss_mask: 0.2167  decode.d6.loss_dice: 0.2825  decode.d7.loss_cls: 0.0934  decode.d7.loss_mask: 0.2142  decode.d7.loss_dice: 0.3023  decode.d8.loss_cls: 0.1303  decode.d8.loss_mask: 0.2159  decode.d8.loss_dice: 0.3024
08/06 09:54:32 - mmengine - INFO - Iter(train) [ 55250/320000]  base_lr: 8.4318e-05 lr: 8.4318e-06  eta: 1 day, 12:14:27  time: 0.4954  data_time: 0.0115  memory: 5968  grad_norm: 76.4711  loss: 6.6579  decode.loss_cls: 0.1062  decode.loss_mask: 0.2349  decode.loss_dice: 0.2416  decode.d0.loss_cls: 0.7763  decode.d0.loss_mask: 0.2410  decode.d0.loss_dice: 0.2592  decode.d1.loss_cls: 0.1272  decode.d1.loss_mask: 0.2354  decode.d1.loss_dice: 0.2411  decode.d2.loss_cls: 0.1286  decode.d2.loss_mask: 0.2445  decode.d2.loss_dice: 0.2396  decode.d3.loss_cls: 0.1144  decode.d3.loss_mask: 0.2431  decode.d3.loss_dice: 0.2450  decode.d4.loss_cls: 0.1157  decode.d4.loss_mask: 0.2351  decode.d4.loss_dice: 0.2465  decode.d5.loss_cls: 0.1096  decode.d5.loss_mask: 0.2317  decode.d5.loss_dice: 0.2404  decode.d6.loss_cls: 0.1306  decode.d6.loss_mask: 0.2326  decode.d6.loss_dice: 0.2389  decode.d7.loss_cls: 0.1133  decode.d7.loss_mask: 0.2356  decode.d7.loss_dice: 0.2443  decode.d8.loss_cls: 0.1272  decode.d8.loss_mask: 0.2332  decode.d8.loss_dice: 0.2451
08/06 09:54:57 - mmengine - INFO - Iter(train) [ 55300/320000]  base_lr: 8.4303e-05 lr: 8.4303e-06  eta: 1 day, 12:14:03  time: 0.4946  data_time: 0.0111  memory: 5928  grad_norm: 84.1116  loss: 6.4163  decode.loss_cls: 0.1086  decode.loss_mask: 0.1886  decode.loss_dice: 0.2604  decode.d0.loss_cls: 0.8481  decode.d0.loss_mask: 0.1886  decode.d0.loss_dice: 0.2340  decode.d1.loss_cls: 0.1122  decode.d1.loss_mask: 0.1846  decode.d1.loss_dice: 0.2354  decode.d2.loss_cls: 0.1834  decode.d2.loss_mask: 0.1843  decode.d2.loss_dice: 0.2456  decode.d3.loss_cls: 0.1523  decode.d3.loss_mask: 0.1874  decode.d3.loss_dice: 0.2247  decode.d4.loss_cls: 0.1228  decode.d4.loss_mask: 0.1854  decode.d4.loss_dice: 0.2332  decode.d5.loss_cls: 0.1628  decode.d5.loss_mask: 0.1853  decode.d5.loss_dice: 0.2359  decode.d6.loss_cls: 0.1536  decode.d6.loss_mask: 0.1886  decode.d6.loss_dice: 0.2494  decode.d7.loss_cls: 0.1718  decode.d7.loss_mask: 0.1901  decode.d7.loss_dice: 0.2517  decode.d8.loss_cls: 0.0990  decode.d8.loss_mask: 0.1884  decode.d8.loss_dice: 0.2602
08/06 09:55:21 - mmengine - INFO - Iter(train) [ 55350/320000]  base_lr: 8.4289e-05 lr: 8.4289e-06  eta: 1 day, 12:13:39  time: 0.4944  data_time: 0.0113  memory: 5894  grad_norm: 136.5227  loss: 9.2449  decode.loss_cls: 0.1043  decode.loss_mask: 0.3251  decode.loss_dice: 0.3452  decode.d0.loss_cls: 0.7975  decode.d0.loss_mask: 0.3339  decode.d0.loss_dice: 0.3613  decode.d1.loss_cls: 0.1794  decode.d1.loss_mask: 0.3255  decode.d1.loss_dice: 0.3200  decode.d2.loss_cls: 0.1605  decode.d2.loss_mask: 0.3200  decode.d2.loss_dice: 0.3523  decode.d3.loss_cls: 0.1891  decode.d3.loss_mask: 0.3210  decode.d3.loss_dice: 0.3723  decode.d4.loss_cls: 0.1876  decode.d4.loss_mask: 0.3182  decode.d4.loss_dice: 0.3711  decode.d5.loss_cls: 0.1657  decode.d5.loss_mask: 0.3214  decode.d5.loss_dice: 0.3902  decode.d6.loss_cls: 0.2172  decode.d6.loss_mask: 0.3302  decode.d6.loss_dice: 0.4156  decode.d7.loss_cls: 0.1874  decode.d7.loss_mask: 0.3236  decode.d7.loss_dice: 0.3400  decode.d8.loss_cls: 0.1881  decode.d8.loss_mask: 0.3233  decode.d8.loss_dice: 0.3579
08/06 09:55:46 - mmengine - INFO - Iter(train) [ 55400/320000]  base_lr: 8.4275e-05 lr: 8.4275e-06  eta: 1 day, 12:13:15  time: 0.4956  data_time: 0.0113  memory: 5875  grad_norm: 123.2622  loss: 8.9146  decode.loss_cls: 0.1534  decode.loss_mask: 0.3171  decode.loss_dice: 0.3634  decode.d0.loss_cls: 0.9710  decode.d0.loss_mask: 0.2915  decode.d0.loss_dice: 0.3273  decode.d1.loss_cls: 0.1148  decode.d1.loss_mask: 0.3344  decode.d1.loss_dice: 0.3492  decode.d2.loss_cls: 0.1647  decode.d2.loss_mask: 0.3384  decode.d2.loss_dice: 0.3773  decode.d3.loss_cls: 0.1416  decode.d3.loss_mask: 0.3358  decode.d3.loss_dice: 0.3502  decode.d4.loss_cls: 0.1398  decode.d4.loss_mask: 0.3293  decode.d4.loss_dice: 0.3292  decode.d5.loss_cls: 0.1722  decode.d5.loss_mask: 0.3246  decode.d5.loss_dice: 0.3510  decode.d6.loss_cls: 0.1277  decode.d6.loss_mask: 0.3123  decode.d6.loss_dice: 0.3239  decode.d7.loss_cls: 0.1381  decode.d7.loss_mask: 0.3152  decode.d7.loss_dice: 0.3450  decode.d8.loss_cls: 0.1257  decode.d8.loss_mask: 0.3136  decode.d8.loss_dice: 0.3370
08/06 09:56:11 - mmengine - INFO - Iter(train) [ 55450/320000]  base_lr: 8.4260e-05 lr: 8.4260e-06  eta: 1 day, 12:12:51  time: 0.4931  data_time: 0.0111  memory: 5913  grad_norm: 117.2442  loss: 6.2105  decode.loss_cls: 0.0211  decode.loss_mask: 0.2396  decode.loss_dice: 0.2742  decode.d0.loss_cls: 0.7959  decode.d0.loss_mask: 0.2438  decode.d0.loss_dice: 0.2689  decode.d1.loss_cls: 0.0140  decode.d1.loss_mask: 0.2442  decode.d1.loss_dice: 0.2778  decode.d2.loss_cls: 0.0185  decode.d2.loss_mask: 0.2451  decode.d2.loss_dice: 0.2773  decode.d3.loss_cls: 0.0255  decode.d3.loss_mask: 0.2442  decode.d3.loss_dice: 0.2730  decode.d4.loss_cls: 0.0241  decode.d4.loss_mask: 0.2423  decode.d4.loss_dice: 0.2808  decode.d5.loss_cls: 0.0224  decode.d5.loss_mask: 0.2414  decode.d5.loss_dice: 0.2710  decode.d6.loss_cls: 0.0588  decode.d6.loss_mask: 0.2419  decode.d6.loss_dice: 0.2925  decode.d7.loss_cls: 0.0164  decode.d7.loss_mask: 0.2421  decode.d7.loss_dice: 0.2753  decode.d8.loss_cls: 0.0176  decode.d8.loss_mask: 0.2434  decode.d8.loss_dice: 0.2773
08/06 09:56:36 - mmengine - INFO - Iter(train) [ 55500/320000]  base_lr: 8.4246e-05 lr: 8.4246e-06  eta: 1 day, 12:12:26  time: 0.4945  data_time: 0.0114  memory: 5891  grad_norm: 76.8626  loss: 8.2644  decode.loss_cls: 0.1391  decode.loss_mask: 0.2913  decode.loss_dice: 0.3204  decode.d0.loss_cls: 0.9889  decode.d0.loss_mask: 0.3074  decode.d0.loss_dice: 0.3366  decode.d1.loss_cls: 0.1508  decode.d1.loss_mask: 0.2991  decode.d1.loss_dice: 0.3182  decode.d2.loss_cls: 0.1267  decode.d2.loss_mask: 0.2917  decode.d2.loss_dice: 0.3200  decode.d3.loss_cls: 0.0997  decode.d3.loss_mask: 0.2932  decode.d3.loss_dice: 0.3375  decode.d4.loss_cls: 0.1262  decode.d4.loss_mask: 0.2947  decode.d4.loss_dice: 0.3325  decode.d5.loss_cls: 0.1268  decode.d5.loss_mask: 0.2985  decode.d5.loss_dice: 0.3390  decode.d6.loss_cls: 0.0822  decode.d6.loss_mask: 0.2936  decode.d6.loss_dice: 0.3307  decode.d7.loss_cls: 0.1046  decode.d7.loss_mask: 0.2966  decode.d7.loss_dice: 0.3323  decode.d8.loss_cls: 0.0921  decode.d8.loss_mask: 0.2922  decode.d8.loss_dice: 0.3017
08/06 09:57:00 - mmengine - INFO - Iter(train) [ 55550/320000]  base_lr: 8.4232e-05 lr: 8.4232e-06  eta: 1 day, 12:12:02  time: 0.4958  data_time: 0.0112  memory: 5968  grad_norm: 100.6922  loss: 6.3289  decode.loss_cls: 0.0966  decode.loss_mask: 0.2335  decode.loss_dice: 0.2465  decode.d0.loss_cls: 0.8366  decode.d0.loss_mask: 0.2299  decode.d0.loss_dice: 0.2425  decode.d1.loss_cls: 0.0951  decode.d1.loss_mask: 0.2310  decode.d1.loss_dice: 0.2541  decode.d2.loss_cls: 0.0969  decode.d2.loss_mask: 0.2297  decode.d2.loss_dice: 0.2345  decode.d3.loss_cls: 0.0494  decode.d3.loss_mask: 0.2315  decode.d3.loss_dice: 0.2370  decode.d4.loss_cls: 0.0883  decode.d4.loss_mask: 0.2347  decode.d4.loss_dice: 0.2367  decode.d5.loss_cls: 0.0608  decode.d5.loss_mask: 0.2334  decode.d5.loss_dice: 0.2428  decode.d6.loss_cls: 0.0548  decode.d6.loss_mask: 0.2338  decode.d6.loss_dice: 0.2547  decode.d7.loss_cls: 0.0967  decode.d7.loss_mask: 0.2350  decode.d7.loss_dice: 0.2512  decode.d8.loss_cls: 0.0618  decode.d8.loss_mask: 0.2349  decode.d8.loss_dice: 0.2642
08/06 09:57:25 - mmengine - INFO - Iter(train) [ 55600/320000]  base_lr: 8.4217e-05 lr: 8.4217e-06  eta: 1 day, 12:11:38  time: 0.4953  data_time: 0.0112  memory: 5911  grad_norm: 152.0858  loss: 6.9915  decode.loss_cls: 0.1679  decode.loss_mask: 0.2079  decode.loss_dice: 0.2170  decode.d0.loss_cls: 0.8837  decode.d0.loss_mask: 0.2072  decode.d0.loss_dice: 0.2106  decode.d1.loss_cls: 0.1883  decode.d1.loss_mask: 0.2038  decode.d1.loss_dice: 0.2063  decode.d2.loss_cls: 0.2360  decode.d2.loss_mask: 0.2021  decode.d2.loss_dice: 0.2064  decode.d3.loss_cls: 0.2288  decode.d3.loss_mask: 0.2081  decode.d3.loss_dice: 0.2164  decode.d4.loss_cls: 0.2294  decode.d4.loss_mask: 0.2058  decode.d4.loss_dice: 0.2197  decode.d5.loss_cls: 0.2125  decode.d5.loss_mask: 0.2089  decode.d5.loss_dice: 0.2152  decode.d6.loss_cls: 0.1950  decode.d6.loss_mask: 0.2106  decode.d6.loss_dice: 0.2134  decode.d7.loss_cls: 0.2366  decode.d7.loss_mask: 0.2056  decode.d7.loss_dice: 0.2234  decode.d8.loss_cls: 0.2062  decode.d8.loss_mask: 0.2057  decode.d8.loss_dice: 0.2131
08/06 09:57:50 - mmengine - INFO - Iter(train) [ 55650/320000]  base_lr: 8.4203e-05 lr: 8.4203e-06  eta: 1 day, 12:11:15  time: 0.4965  data_time: 0.0113  memory: 5928  grad_norm: 199.9799  loss: 7.1466  decode.loss_cls: 0.0747  decode.loss_mask: 0.2729  decode.loss_dice: 0.2865  decode.d0.loss_cls: 0.9622  decode.d0.loss_mask: 0.2638  decode.d0.loss_dice: 0.2883  decode.d1.loss_cls: 0.0988  decode.d1.loss_mask: 0.2656  decode.d1.loss_dice: 0.2728  decode.d2.loss_cls: 0.0426  decode.d2.loss_mask: 0.2715  decode.d2.loss_dice: 0.2759  decode.d3.loss_cls: 0.0835  decode.d3.loss_mask: 0.2733  decode.d3.loss_dice: 0.2884  decode.d4.loss_cls: 0.0812  decode.d4.loss_mask: 0.2733  decode.d4.loss_dice: 0.2791  decode.d5.loss_cls: 0.0780  decode.d5.loss_mask: 0.2676  decode.d5.loss_dice: 0.2815  decode.d6.loss_cls: 0.0557  decode.d6.loss_mask: 0.2727  decode.d6.loss_dice: 0.2909  decode.d7.loss_cls: 0.0655  decode.d7.loss_mask: 0.2691  decode.d7.loss_dice: 0.2796  decode.d8.loss_cls: 0.0735  decode.d8.loss_mask: 0.2734  decode.d8.loss_dice: 0.2848
08/06 09:58:15 - mmengine - INFO - Iter(train) [ 55700/320000]  base_lr: 8.4189e-05 lr: 8.4189e-06  eta: 1 day, 12:10:51  time: 0.4955  data_time: 0.0111  memory: 5928  grad_norm: 131.1868  loss: 8.9175  decode.loss_cls: 0.2084  decode.loss_mask: 0.2891  decode.loss_dice: 0.3348  decode.d0.loss_cls: 1.0926  decode.d0.loss_mask: 0.2529  decode.d0.loss_dice: 0.3096  decode.d1.loss_cls: 0.2774  decode.d1.loss_mask: 0.2453  decode.d1.loss_dice: 0.3038  decode.d2.loss_cls: 0.2391  decode.d2.loss_mask: 0.2461  decode.d2.loss_dice: 0.2903  decode.d3.loss_cls: 0.2354  decode.d3.loss_mask: 0.2579  decode.d3.loss_dice: 0.3002  decode.d4.loss_cls: 0.2330  decode.d4.loss_mask: 0.2491  decode.d4.loss_dice: 0.2927  decode.d5.loss_cls: 0.2397  decode.d5.loss_mask: 0.2574  decode.d5.loss_dice: 0.3075  decode.d6.loss_cls: 0.2499  decode.d6.loss_mask: 0.2631  decode.d6.loss_dice: 0.3060  decode.d7.loss_cls: 0.2162  decode.d7.loss_mask: 0.2665  decode.d7.loss_dice: 0.3382  decode.d8.loss_cls: 0.2096  decode.d8.loss_mask: 0.2726  decode.d8.loss_dice: 0.3331
08/06 09:58:40 - mmengine - INFO - Iter(train) [ 55750/320000]  base_lr: 8.4174e-05 lr: 8.4174e-06  eta: 1 day, 12:10:27  time: 0.4951  data_time: 0.0114  memory: 5891  grad_norm: 175.8727  loss: 8.4801  decode.loss_cls: 0.2163  decode.loss_mask: 0.3289  decode.loss_dice: 0.2994  decode.d0.loss_cls: 0.9223  decode.d0.loss_mask: 0.2854  decode.d0.loss_dice: 0.2673  decode.d1.loss_cls: 0.0927  decode.d1.loss_mask: 0.3215  decode.d1.loss_dice: 0.2798  decode.d2.loss_cls: 0.1807  decode.d2.loss_mask: 0.2858  decode.d2.loss_dice: 0.2640  decode.d3.loss_cls: 0.2205  decode.d3.loss_mask: 0.2818  decode.d3.loss_dice: 0.2659  decode.d4.loss_cls: 0.1943  decode.d4.loss_mask: 0.2792  decode.d4.loss_dice: 0.2681  decode.d5.loss_cls: 0.2417  decode.d5.loss_mask: 0.2780  decode.d5.loss_dice: 0.2718  decode.d6.loss_cls: 0.1880  decode.d6.loss_mask: 0.3041  decode.d6.loss_dice: 0.3019  decode.d7.loss_cls: 0.1975  decode.d7.loss_mask: 0.3337  decode.d7.loss_dice: 0.2919  decode.d8.loss_cls: 0.1997  decode.d8.loss_mask: 0.3308  decode.d8.loss_dice: 0.2872
08/06 09:59:04 - mmengine - INFO - Iter(train) [ 55800/320000]  base_lr: 8.4160e-05 lr: 8.4160e-06  eta: 1 day, 12:10:02  time: 0.4945  data_time: 0.0113  memory: 5895  grad_norm: 123.8620  loss: 6.5032  decode.loss_cls: 0.0838  decode.loss_mask: 0.2360  decode.loss_dice: 0.2351  decode.d0.loss_cls: 0.8044  decode.d0.loss_mask: 0.2378  decode.d0.loss_dice: 0.2408  decode.d1.loss_cls: 0.1282  decode.d1.loss_mask: 0.2367  decode.d1.loss_dice: 0.2397  decode.d2.loss_cls: 0.1299  decode.d2.loss_mask: 0.2355  decode.d2.loss_dice: 0.2359  decode.d3.loss_cls: 0.1119  decode.d3.loss_mask: 0.2360  decode.d3.loss_dice: 0.2354  decode.d4.loss_cls: 0.0936  decode.d4.loss_mask: 0.2352  decode.d4.loss_dice: 0.2354  decode.d5.loss_cls: 0.0942  decode.d5.loss_mask: 0.2362  decode.d5.loss_dice: 0.2271  decode.d6.loss_cls: 0.1410  decode.d6.loss_mask: 0.2359  decode.d6.loss_dice: 0.2541  decode.d7.loss_cls: 0.0870  decode.d7.loss_mask: 0.2363  decode.d7.loss_dice: 0.2334  decode.d8.loss_cls: 0.0795  decode.d8.loss_mask: 0.2348  decode.d8.loss_dice: 0.2526
08/06 09:59:29 - mmengine - INFO - Iter(train) [ 55850/320000]  base_lr: 8.4146e-05 lr: 8.4146e-06  eta: 1 day, 12:09:38  time: 0.4947  data_time: 0.0111  memory: 5874  grad_norm: 118.1507  loss: 6.6854  decode.loss_cls: 0.0284  decode.loss_mask: 0.2589  decode.loss_dice: 0.2734  decode.d0.loss_cls: 0.8893  decode.d0.loss_mask: 0.2642  decode.d0.loss_dice: 0.2859  decode.d1.loss_cls: 0.1459  decode.d1.loss_mask: 0.2522  decode.d1.loss_dice: 0.2778  decode.d2.loss_cls: 0.0476  decode.d2.loss_mask: 0.2591  decode.d2.loss_dice: 0.2716  decode.d3.loss_cls: 0.0312  decode.d3.loss_mask: 0.2593  decode.d3.loss_dice: 0.2649  decode.d4.loss_cls: 0.0514  decode.d4.loss_mask: 0.2606  decode.d4.loss_dice: 0.2663  decode.d5.loss_cls: 0.0323  decode.d5.loss_mask: 0.2657  decode.d5.loss_dice: 0.2809  decode.d6.loss_cls: 0.0233  decode.d6.loss_mask: 0.2606  decode.d6.loss_dice: 0.2882  decode.d7.loss_cls: 0.0393  decode.d7.loss_mask: 0.2559  decode.d7.loss_dice: 0.2790  decode.d8.loss_cls: 0.0404  decode.d8.loss_mask: 0.2569  decode.d8.loss_dice: 0.2748
08/06 09:59:54 - mmengine - INFO - Iter(train) [ 55900/320000]  base_lr: 8.4131e-05 lr: 8.4131e-06  eta: 1 day, 12:09:14  time: 0.4944  data_time: 0.0111  memory: 5894  grad_norm: 86.5582  loss: 7.9802  decode.loss_cls: 0.1714  decode.loss_mask: 0.2425  decode.loss_dice: 0.2905  decode.d0.loss_cls: 0.9675  decode.d0.loss_mask: 0.2375  decode.d0.loss_dice: 0.2551  decode.d1.loss_cls: 0.2589  decode.d1.loss_mask: 0.2390  decode.d1.loss_dice: 0.2707  decode.d2.loss_cls: 0.2332  decode.d2.loss_mask: 0.2447  decode.d2.loss_dice: 0.2677  decode.d3.loss_cls: 0.2147  decode.d3.loss_mask: 0.2403  decode.d3.loss_dice: 0.2768  decode.d4.loss_cls: 0.1950  decode.d4.loss_mask: 0.2392  decode.d4.loss_dice: 0.2700  decode.d5.loss_cls: 0.1867  decode.d5.loss_mask: 0.2459  decode.d5.loss_dice: 0.2602  decode.d6.loss_cls: 0.1967  decode.d6.loss_mask: 0.2374  decode.d6.loss_dice: 0.2808  decode.d7.loss_cls: 0.1878  decode.d7.loss_mask: 0.2387  decode.d7.loss_dice: 0.2852  decode.d8.loss_cls: 0.2289  decode.d8.loss_mask: 0.2406  decode.d8.loss_dice: 0.2764
08/06 10:00:19 - mmengine - INFO - Iter(train) [ 55950/320000]  base_lr: 8.4117e-05 lr: 8.4117e-06  eta: 1 day, 12:08:51  time: 0.4954  data_time: 0.0112  memory: 5875  grad_norm: 63.2899  loss: 5.3531  decode.loss_cls: 0.0340  decode.loss_mask: 0.2100  decode.loss_dice: 0.2291  decode.d0.loss_cls: 0.6514  decode.d0.loss_mask: 0.2178  decode.d0.loss_dice: 0.2355  decode.d1.loss_cls: 0.0205  decode.d1.loss_mask: 0.2091  decode.d1.loss_dice: 0.2351  decode.d2.loss_cls: 0.0196  decode.d2.loss_mask: 0.2108  decode.d2.loss_dice: 0.2283  decode.d3.loss_cls: 0.0332  decode.d3.loss_mask: 0.2082  decode.d3.loss_dice: 0.2338  decode.d4.loss_cls: 0.0371  decode.d4.loss_mask: 0.2114  decode.d4.loss_dice: 0.2404  decode.d5.loss_cls: 0.0241  decode.d5.loss_mask: 0.2102  decode.d5.loss_dice: 0.2366  decode.d6.loss_cls: 0.0272  decode.d6.loss_mask: 0.2096  decode.d6.loss_dice: 0.2330  decode.d7.loss_cls: 0.0283  decode.d7.loss_mask: 0.2089  decode.d7.loss_dice: 0.2345  decode.d8.loss_cls: 0.0343  decode.d8.loss_mask: 0.2078  decode.d8.loss_dice: 0.2334
08/06 10:00:44 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 10:00:44 - mmengine - INFO - Iter(train) [ 56000/320000]  base_lr: 8.4103e-05 lr: 8.4103e-06  eta: 1 day, 12:08:27  time: 0.4953  data_time: 0.0112  memory: 5878  grad_norm: 85.6287  loss: 6.1010  decode.loss_cls: 0.0994  decode.loss_mask: 0.2249  decode.loss_dice: 0.2224  decode.d0.loss_cls: 0.8616  decode.d0.loss_mask: 0.2278  decode.d0.loss_dice: 0.2348  decode.d1.loss_cls: 0.0864  decode.d1.loss_mask: 0.2209  decode.d1.loss_dice: 0.2245  decode.d2.loss_cls: 0.1118  decode.d2.loss_mask: 0.2227  decode.d2.loss_dice: 0.2221  decode.d3.loss_cls: 0.0760  decode.d3.loss_mask: 0.2249  decode.d3.loss_dice: 0.2244  decode.d4.loss_cls: 0.0800  decode.d4.loss_mask: 0.2236  decode.d4.loss_dice: 0.2212  decode.d5.loss_cls: 0.0911  decode.d5.loss_mask: 0.2234  decode.d5.loss_dice: 0.2217  decode.d6.loss_cls: 0.0608  decode.d6.loss_mask: 0.2218  decode.d6.loss_dice: 0.2260  decode.d7.loss_cls: 0.0750  decode.d7.loss_mask: 0.2226  decode.d7.loss_dice: 0.2255  decode.d8.loss_cls: 0.0712  decode.d8.loss_mask: 0.2247  decode.d8.loss_dice: 0.2278
08/06 10:01:08 - mmengine - INFO - Iter(train) [ 56050/320000]  base_lr: 8.4088e-05 lr: 8.4088e-06  eta: 1 day, 12:08:03  time: 0.4947  data_time: 0.0113  memory: 5875  grad_norm: 116.1346  loss: 7.6783  decode.loss_cls: 0.1887  decode.loss_mask: 0.2515  decode.loss_dice: 0.3473  decode.d0.loss_cls: 0.8189  decode.d0.loss_mask: 0.2422  decode.d0.loss_dice: 0.3152  decode.d1.loss_cls: 0.1329  decode.d1.loss_mask: 0.2436  decode.d1.loss_dice: 0.3193  decode.d2.loss_cls: 0.1292  decode.d2.loss_mask: 0.2406  decode.d2.loss_dice: 0.2994  decode.d3.loss_cls: 0.1114  decode.d3.loss_mask: 0.2431  decode.d3.loss_dice: 0.3080  decode.d4.loss_cls: 0.1363  decode.d4.loss_mask: 0.2412  decode.d4.loss_dice: 0.3115  decode.d5.loss_cls: 0.1217  decode.d5.loss_mask: 0.2383  decode.d5.loss_dice: 0.3060  decode.d6.loss_cls: 0.0994  decode.d6.loss_mask: 0.2384  decode.d6.loss_dice: 0.3127  decode.d7.loss_cls: 0.1334  decode.d7.loss_mask: 0.2486  decode.d7.loss_dice: 0.3370  decode.d8.loss_cls: 0.1672  decode.d8.loss_mask: 0.2504  decode.d8.loss_dice: 0.3449
08/06 10:01:33 - mmengine - INFO - Iter(train) [ 56100/320000]  base_lr: 8.4074e-05 lr: 8.4074e-06  eta: 1 day, 12:07:39  time: 0.4950  data_time: 0.0111  memory: 5911  grad_norm: 99.8117  loss: 7.0000  decode.loss_cls: 0.0516  decode.loss_mask: 0.2360  decode.loss_dice: 0.2723  decode.d0.loss_cls: 0.8671  decode.d0.loss_mask: 0.2399  decode.d0.loss_dice: 0.2871  decode.d1.loss_cls: 0.1109  decode.d1.loss_mask: 0.2346  decode.d1.loss_dice: 0.2959  decode.d2.loss_cls: 0.0873  decode.d2.loss_mask: 0.2335  decode.d2.loss_dice: 0.2935  decode.d3.loss_cls: 0.0926  decode.d3.loss_mask: 0.2380  decode.d3.loss_dice: 0.3117  decode.d4.loss_cls: 0.1464  decode.d4.loss_mask: 0.2305  decode.d4.loss_dice: 0.2926  decode.d5.loss_cls: 0.1221  decode.d5.loss_mask: 0.2325  decode.d5.loss_dice: 0.2909  decode.d6.loss_cls: 0.0865  decode.d6.loss_mask: 0.2368  decode.d6.loss_dice: 0.2940  decode.d7.loss_cls: 0.0842  decode.d7.loss_mask: 0.2351  decode.d7.loss_dice: 0.2778  decode.d8.loss_cls: 0.0875  decode.d8.loss_mask: 0.2316  decode.d8.loss_dice: 0.2994
08/06 10:01:58 - mmengine - INFO - Iter(train) [ 56150/320000]  base_lr: 8.4060e-05 lr: 8.4060e-06  eta: 1 day, 12:07:15  time: 0.4944  data_time: 0.0113  memory: 5874  grad_norm: 235.7172  loss: 8.6337  decode.loss_cls: 0.0953  decode.loss_mask: 0.3704  decode.loss_dice: 0.3025  decode.d0.loss_cls: 0.9350  decode.d0.loss_mask: 0.3798  decode.d0.loss_dice: 0.2648  decode.d1.loss_cls: 0.2263  decode.d1.loss_mask: 0.3578  decode.d1.loss_dice: 0.2477  decode.d2.loss_cls: 0.1328  decode.d2.loss_mask: 0.3600  decode.d2.loss_dice: 0.2944  decode.d3.loss_cls: 0.1467  decode.d3.loss_mask: 0.3716  decode.d3.loss_dice: 0.2984  decode.d4.loss_cls: 0.1561  decode.d4.loss_mask: 0.3551  decode.d4.loss_dice: 0.2597  decode.d5.loss_cls: 0.1367  decode.d5.loss_mask: 0.3617  decode.d5.loss_dice: 0.2574  decode.d6.loss_cls: 0.1104  decode.d6.loss_mask: 0.3660  decode.d6.loss_dice: 0.2820  decode.d7.loss_cls: 0.1381  decode.d7.loss_mask: 0.3661  decode.d7.loss_dice: 0.2779  decode.d8.loss_cls: 0.0948  decode.d8.loss_mask: 0.3779  decode.d8.loss_dice: 0.3105
08/06 10:02:23 - mmengine - INFO - Iter(train) [ 56200/320000]  base_lr: 8.4045e-05 lr: 8.4045e-06  eta: 1 day, 12:06:51  time: 0.4957  data_time: 0.0112  memory: 5911  grad_norm: 151.2631  loss: 8.4540  decode.loss_cls: 0.2359  decode.loss_mask: 0.2542  decode.loss_dice: 0.2951  decode.d0.loss_cls: 0.9756  decode.d0.loss_mask: 0.2522  decode.d0.loss_dice: 0.2984  decode.d1.loss_cls: 0.2239  decode.d1.loss_mask: 0.2514  decode.d1.loss_dice: 0.2757  decode.d2.loss_cls: 0.2303  decode.d2.loss_mask: 0.2539  decode.d2.loss_dice: 0.2831  decode.d3.loss_cls: 0.2066  decode.d3.loss_mask: 0.2537  decode.d3.loss_dice: 0.2975  decode.d4.loss_cls: 0.1829  decode.d4.loss_mask: 0.2505  decode.d4.loss_dice: 0.2900  decode.d5.loss_cls: 0.2324  decode.d5.loss_mask: 0.2486  decode.d5.loss_dice: 0.2979  decode.d6.loss_cls: 0.2548  decode.d6.loss_mask: 0.2590  decode.d6.loss_dice: 0.2957  decode.d7.loss_cls: 0.2122  decode.d7.loss_mask: 0.2553  decode.d7.loss_dice: 0.2993  decode.d8.loss_cls: 0.2361  decode.d8.loss_mask: 0.2554  decode.d8.loss_dice: 0.2967
08/06 10:02:47 - mmengine - INFO - Iter(train) [ 56250/320000]  base_lr: 8.4031e-05 lr: 8.4031e-06  eta: 1 day, 12:06:27  time: 0.4949  data_time: 0.0112  memory: 5894  grad_norm: 38.2018  loss: 5.5712  decode.loss_cls: 0.0517  decode.loss_mask: 0.2030  decode.loss_dice: 0.2586  decode.d0.loss_cls: 0.7317  decode.d0.loss_mask: 0.2095  decode.d0.loss_dice: 0.2612  decode.d1.loss_cls: 0.0085  decode.d1.loss_mask: 0.2107  decode.d1.loss_dice: 0.2661  decode.d2.loss_cls: 0.0148  decode.d2.loss_mask: 0.2044  decode.d2.loss_dice: 0.2579  decode.d3.loss_cls: 0.0257  decode.d3.loss_mask: 0.2040  decode.d3.loss_dice: 0.2515  decode.d4.loss_cls: 0.0250  decode.d4.loss_mask: 0.2020  decode.d4.loss_dice: 0.2535  decode.d5.loss_cls: 0.0228  decode.d5.loss_mask: 0.2050  decode.d5.loss_dice: 0.2610  decode.d6.loss_cls: 0.0279  decode.d6.loss_mask: 0.2040  decode.d6.loss_dice: 0.2539  decode.d7.loss_cls: 0.0156  decode.d7.loss_mask: 0.2074  decode.d7.loss_dice: 0.2634  decode.d8.loss_cls: 0.0146  decode.d8.loss_mask: 0.2036  decode.d8.loss_dice: 0.2521
08/06 10:03:12 - mmengine - INFO - Iter(train) [ 56300/320000]  base_lr: 8.4017e-05 lr: 8.4017e-06  eta: 1 day, 12:06:02  time: 0.4936  data_time: 0.0107  memory: 5895  grad_norm: 108.7962  loss: 6.8413  decode.loss_cls: 0.0415  decode.loss_mask: 0.2407  decode.loss_dice: 0.3076  decode.d0.loss_cls: 0.9610  decode.d0.loss_mask: 0.2410  decode.d0.loss_dice: 0.3092  decode.d1.loss_cls: 0.0759  decode.d1.loss_mask: 0.2384  decode.d1.loss_dice: 0.2917  decode.d2.loss_cls: 0.0695  decode.d2.loss_mask: 0.2389  decode.d2.loss_dice: 0.2948  decode.d3.loss_cls: 0.0597  decode.d3.loss_mask: 0.2411  decode.d3.loss_dice: 0.3191  decode.d4.loss_cls: 0.0497  decode.d4.loss_mask: 0.2401  decode.d4.loss_dice: 0.2725  decode.d5.loss_cls: 0.0473  decode.d5.loss_mask: 0.2376  decode.d5.loss_dice: 0.2680  decode.d6.loss_cls: 0.0627  decode.d6.loss_mask: 0.2403  decode.d6.loss_dice: 0.3026  decode.d7.loss_cls: 0.0406  decode.d7.loss_mask: 0.2412  decode.d7.loss_dice: 0.3088  decode.d8.loss_cls: 0.0760  decode.d8.loss_mask: 0.2386  decode.d8.loss_dice: 0.2851
08/06 10:03:37 - mmengine - INFO - Iter(train) [ 56350/320000]  base_lr: 8.4002e-05 lr: 8.4002e-06  eta: 1 day, 12:05:38  time: 0.4952  data_time: 0.0113  memory: 5878  grad_norm: 141.0825  loss: 6.6157  decode.loss_cls: 0.0848  decode.loss_mask: 0.2365  decode.loss_dice: 0.2236  decode.d0.loss_cls: 0.9306  decode.d0.loss_mask: 0.2480  decode.d0.loss_dice: 0.2494  decode.d1.loss_cls: 0.1083  decode.d1.loss_mask: 0.2399  decode.d1.loss_dice: 0.2399  decode.d2.loss_cls: 0.0832  decode.d2.loss_mask: 0.2390  decode.d2.loss_dice: 0.2388  decode.d3.loss_cls: 0.1373  decode.d3.loss_mask: 0.2371  decode.d3.loss_dice: 0.2404  decode.d4.loss_cls: 0.1201  decode.d4.loss_mask: 0.2400  decode.d4.loss_dice: 0.2507  decode.d5.loss_cls: 0.1268  decode.d5.loss_mask: 0.2353  decode.d5.loss_dice: 0.2330  decode.d6.loss_cls: 0.0686  decode.d6.loss_mask: 0.2396  decode.d6.loss_dice: 0.2449  decode.d7.loss_cls: 0.0857  decode.d7.loss_mask: 0.2411  decode.d7.loss_dice: 0.2428  decode.d8.loss_cls: 0.0874  decode.d8.loss_mask: 0.2394  decode.d8.loss_dice: 0.2235
08/06 10:04:02 - mmengine - INFO - Iter(train) [ 56400/320000]  base_lr: 8.3988e-05 lr: 8.3988e-06  eta: 1 day, 12:05:14  time: 0.4939  data_time: 0.0111  memory: 5913  grad_norm: 287.6264  loss: 9.7313  decode.loss_cls: 0.3620  decode.loss_mask: 0.2205  decode.loss_dice: 0.2402  decode.d0.loss_cls: 1.1093  decode.d0.loss_mask: 0.2259  decode.d0.loss_dice: 0.2447  decode.d1.loss_cls: 0.4486  decode.d1.loss_mask: 0.2185  decode.d1.loss_dice: 0.2470  decode.d2.loss_cls: 0.4655  decode.d2.loss_mask: 0.2204  decode.d2.loss_dice: 0.2474  decode.d3.loss_cls: 0.4231  decode.d3.loss_mask: 0.2487  decode.d3.loss_dice: 0.2649  decode.d4.loss_cls: 0.4531  decode.d4.loss_mask: 0.2381  decode.d4.loss_dice: 0.2462  decode.d5.loss_cls: 0.4027  decode.d5.loss_mask: 0.2493  decode.d5.loss_dice: 0.2632  decode.d6.loss_cls: 0.4459  decode.d6.loss_mask: 0.2716  decode.d6.loss_dice: 0.2592  decode.d7.loss_cls: 0.3908  decode.d7.loss_mask: 0.2219  decode.d7.loss_dice: 0.2355  decode.d8.loss_cls: 0.3872  decode.d8.loss_mask: 0.2300  decode.d8.loss_dice: 0.2498
08/06 10:04:26 - mmengine - INFO - Iter(train) [ 56450/320000]  base_lr: 8.3974e-05 lr: 8.3974e-06  eta: 1 day, 12:04:50  time: 0.4959  data_time: 0.0111  memory: 5913  grad_norm: 86.9522  loss: 7.2395  decode.loss_cls: 0.1182  decode.loss_mask: 0.2405  decode.loss_dice: 0.2811  decode.d0.loss_cls: 0.7645  decode.d0.loss_mask: 0.2443  decode.d0.loss_dice: 0.2689  decode.d1.loss_cls: 0.2424  decode.d1.loss_mask: 0.2456  decode.d1.loss_dice: 0.2666  decode.d2.loss_cls: 0.2083  decode.d2.loss_mask: 0.2416  decode.d2.loss_dice: 0.2716  decode.d3.loss_cls: 0.1420  decode.d3.loss_mask: 0.2425  decode.d3.loss_dice: 0.2428  decode.d4.loss_cls: 0.1389  decode.d4.loss_mask: 0.2405  decode.d4.loss_dice: 0.2556  decode.d5.loss_cls: 0.1640  decode.d5.loss_mask: 0.2403  decode.d5.loss_dice: 0.2494  decode.d6.loss_cls: 0.1571  decode.d6.loss_mask: 0.2407  decode.d6.loss_dice: 0.2493  decode.d7.loss_cls: 0.1545  decode.d7.loss_mask: 0.2457  decode.d7.loss_dice: 0.2536  decode.d8.loss_cls: 0.1224  decode.d8.loss_mask: 0.2428  decode.d8.loss_dice: 0.2636
08/06 10:04:51 - mmengine - INFO - Iter(train) [ 56500/320000]  base_lr: 8.3959e-05 lr: 8.3959e-06  eta: 1 day, 12:04:25  time: 0.4947  data_time: 0.0112  memory: 5894  grad_norm: 176.7651  loss: 7.5702  decode.loss_cls: 0.1524  decode.loss_mask: 0.2420  decode.loss_dice: 0.2818  decode.d0.loss_cls: 1.0200  decode.d0.loss_mask: 0.2038  decode.d0.loss_dice: 0.2880  decode.d1.loss_cls: 0.2780  decode.d1.loss_mask: 0.2356  decode.d1.loss_dice: 0.3003  decode.d2.loss_cls: 0.1471  decode.d2.loss_mask: 0.2529  decode.d2.loss_dice: 0.2906  decode.d3.loss_cls: 0.1139  decode.d3.loss_mask: 0.1966  decode.d3.loss_dice: 0.2750  decode.d4.loss_cls: 0.1183  decode.d4.loss_mask: 0.1960  decode.d4.loss_dice: 0.2788  decode.d5.loss_cls: 0.1102  decode.d5.loss_mask: 0.2256  decode.d5.loss_dice: 0.2833  decode.d6.loss_cls: 0.1488  decode.d6.loss_mask: 0.2415  decode.d6.loss_dice: 0.2824  decode.d7.loss_cls: 0.1657  decode.d7.loss_mask: 0.2416  decode.d7.loss_dice: 0.2854  decode.d8.loss_cls: 0.1792  decode.d8.loss_mask: 0.2409  decode.d8.loss_dice: 0.2942
08/06 10:05:16 - mmengine - INFO - Iter(train) [ 56550/320000]  base_lr: 8.3945e-05 lr: 8.3945e-06  eta: 1 day, 12:04:02  time: 0.4943  data_time: 0.0112  memory: 5911  grad_norm: 117.6287  loss: 7.0048  decode.loss_cls: 0.0587  decode.loss_mask: 0.2872  decode.loss_dice: 0.2769  decode.d0.loss_cls: 0.7889  decode.d0.loss_mask: 0.2866  decode.d0.loss_dice: 0.2638  decode.d1.loss_cls: 0.1081  decode.d1.loss_mask: 0.2854  decode.d1.loss_dice: 0.2547  decode.d2.loss_cls: 0.0677  decode.d2.loss_mask: 0.2809  decode.d2.loss_dice: 0.2601  decode.d3.loss_cls: 0.0708  decode.d3.loss_mask: 0.2857  decode.d3.loss_dice: 0.2765  decode.d4.loss_cls: 0.0800  decode.d4.loss_mask: 0.2863  decode.d4.loss_dice: 0.2860  decode.d5.loss_cls: 0.0726  decode.d5.loss_mask: 0.2884  decode.d5.loss_dice: 0.2790  decode.d6.loss_cls: 0.0686  decode.d6.loss_mask: 0.2875  decode.d6.loss_dice: 0.2835  decode.d7.loss_cls: 0.0588  decode.d7.loss_mask: 0.2875  decode.d7.loss_dice: 0.2771  decode.d8.loss_cls: 0.0576  decode.d8.loss_mask: 0.2850  decode.d8.loss_dice: 0.2548
08/06 10:05:41 - mmengine - INFO - Iter(train) [ 56600/320000]  base_lr: 8.3931e-05 lr: 8.3931e-06  eta: 1 day, 12:03:38  time: 0.4956  data_time: 0.0114  memory: 5928  grad_norm: 92.4845  loss: 8.2093  decode.loss_cls: 0.1711  decode.loss_mask: 0.2459  decode.loss_dice: 0.3638  decode.d0.loss_cls: 0.7895  decode.d0.loss_mask: 0.2099  decode.d0.loss_dice: 0.3199  decode.d1.loss_cls: 0.1871  decode.d1.loss_mask: 0.2117  decode.d1.loss_dice: 0.3136  decode.d2.loss_cls: 0.1961  decode.d2.loss_mask: 0.2168  decode.d2.loss_dice: 0.3255  decode.d3.loss_cls: 0.2283  decode.d3.loss_mask: 0.2210  decode.d3.loss_dice: 0.3189  decode.d4.loss_cls: 0.2106  decode.d4.loss_mask: 0.2176  decode.d4.loss_dice: 0.3321  decode.d5.loss_cls: 0.1947  decode.d5.loss_mask: 0.2232  decode.d5.loss_dice: 0.3384  decode.d6.loss_cls: 0.1809  decode.d6.loss_mask: 0.2665  decode.d6.loss_dice: 0.3484  decode.d7.loss_cls: 0.1817  decode.d7.loss_mask: 0.2383  decode.d7.loss_dice: 0.3513  decode.d8.loss_cls: 0.1868  decode.d8.loss_mask: 0.2476  decode.d8.loss_dice: 0.3723
08/06 10:06:05 - mmengine - INFO - Iter(train) [ 56650/320000]  base_lr: 8.3916e-05 lr: 8.3916e-06  eta: 1 day, 12:03:14  time: 0.4949  data_time: 0.0112  memory: 5894  grad_norm: 83.8147  loss: 6.8599  decode.loss_cls: 0.1221  decode.loss_mask: 0.1826  decode.loss_dice: 0.2755  decode.d0.loss_cls: 1.0453  decode.d0.loss_mask: 0.1843  decode.d0.loss_dice: 0.2759  decode.d1.loss_cls: 0.1307  decode.d1.loss_mask: 0.1829  decode.d1.loss_dice: 0.2799  decode.d2.loss_cls: 0.1321  decode.d2.loss_mask: 0.1805  decode.d2.loss_dice: 0.2747  decode.d3.loss_cls: 0.1639  decode.d3.loss_mask: 0.1791  decode.d3.loss_dice: 0.2767  decode.d4.loss_cls: 0.1485  decode.d4.loss_mask: 0.1822  decode.d4.loss_dice: 0.2821  decode.d5.loss_cls: 0.1624  decode.d5.loss_mask: 0.1816  decode.d5.loss_dice: 0.2713  decode.d6.loss_cls: 0.1318  decode.d6.loss_mask: 0.1800  decode.d6.loss_dice: 0.2710  decode.d7.loss_cls: 0.1300  decode.d7.loss_mask: 0.1812  decode.d7.loss_dice: 0.2768  decode.d8.loss_cls: 0.1235  decode.d8.loss_mask: 0.1800  decode.d8.loss_dice: 0.2711
08/06 10:06:30 - mmengine - INFO - Iter(train) [ 56700/320000]  base_lr: 8.3902e-05 lr: 8.3902e-06  eta: 1 day, 12:02:49  time: 0.4957  data_time: 0.0110  memory: 5911  grad_norm: 236.5337  loss: 5.6315  decode.loss_cls: 0.0170  decode.loss_mask: 0.1966  decode.loss_dice: 0.2293  decode.d0.loss_cls: 0.9575  decode.d0.loss_mask: 0.1979  decode.d0.loss_dice: 0.2367  decode.d1.loss_cls: 0.1141  decode.d1.loss_mask: 0.1980  decode.d1.loss_dice: 0.2425  decode.d2.loss_cls: 0.0572  decode.d2.loss_mask: 0.1989  decode.d2.loss_dice: 0.2432  decode.d3.loss_cls: 0.0512  decode.d3.loss_mask: 0.1960  decode.d3.loss_dice: 0.2294  decode.d4.loss_cls: 0.0443  decode.d4.loss_mask: 0.1964  decode.d4.loss_dice: 0.2272  decode.d5.loss_cls: 0.0268  decode.d5.loss_mask: 0.1938  decode.d5.loss_dice: 0.2309  decode.d6.loss_cls: 0.0331  decode.d6.loss_mask: 0.1951  decode.d6.loss_dice: 0.2301  decode.d7.loss_cls: 0.0200  decode.d7.loss_mask: 0.1957  decode.d7.loss_dice: 0.2267  decode.d8.loss_cls: 0.0172  decode.d8.loss_mask: 0.1963  decode.d8.loss_dice: 0.2324
08/06 10:06:55 - mmengine - INFO - Iter(train) [ 56750/320000]  base_lr: 8.3888e-05 lr: 8.3888e-06  eta: 1 day, 12:02:25  time: 0.4953  data_time: 0.0112  memory: 5930  grad_norm: 74.2253  loss: 6.6863  decode.loss_cls: 0.0891  decode.loss_mask: 0.2320  decode.loss_dice: 0.2715  decode.d0.loss_cls: 0.9671  decode.d0.loss_mask: 0.2325  decode.d0.loss_dice: 0.2847  decode.d1.loss_cls: 0.0845  decode.d1.loss_mask: 0.2277  decode.d1.loss_dice: 0.2638  decode.d2.loss_cls: 0.0868  decode.d2.loss_mask: 0.2230  decode.d2.loss_dice: 0.2579  decode.d3.loss_cls: 0.0853  decode.d3.loss_mask: 0.2260  decode.d3.loss_dice: 0.2660  decode.d4.loss_cls: 0.0811  decode.d4.loss_mask: 0.2270  decode.d4.loss_dice: 0.2718  decode.d5.loss_cls: 0.0817  decode.d5.loss_mask: 0.2267  decode.d5.loss_dice: 0.2751  decode.d6.loss_cls: 0.0747  decode.d6.loss_mask: 0.2276  decode.d6.loss_dice: 0.2677  decode.d7.loss_cls: 0.0941  decode.d7.loss_mask: 0.2294  decode.d7.loss_dice: 0.2641  decode.d8.loss_cls: 0.0743  decode.d8.loss_mask: 0.2318  decode.d8.loss_dice: 0.2613
08/06 10:07:20 - mmengine - INFO - Iter(train) [ 56800/320000]  base_lr: 8.3873e-05 lr: 8.3873e-06  eta: 1 day, 12:02:01  time: 0.4930  data_time: 0.0113  memory: 5891  grad_norm: 97.4522  loss: 7.8431  decode.loss_cls: 0.1804  decode.loss_mask: 0.2855  decode.loss_dice: 0.2577  decode.d0.loss_cls: 0.8512  decode.d0.loss_mask: 0.3068  decode.d0.loss_dice: 0.2694  decode.d1.loss_cls: 0.2968  decode.d1.loss_mask: 0.2750  decode.d1.loss_dice: 0.2525  decode.d2.loss_cls: 0.1413  decode.d2.loss_mask: 0.2893  decode.d2.loss_dice: 0.2665  decode.d3.loss_cls: 0.1358  decode.d3.loss_mask: 0.2893  decode.d3.loss_dice: 0.2778  decode.d4.loss_cls: 0.1816  decode.d4.loss_mask: 0.2890  decode.d4.loss_dice: 0.2530  decode.d5.loss_cls: 0.1259  decode.d5.loss_mask: 0.2871  decode.d5.loss_dice: 0.2594  decode.d6.loss_cls: 0.1246  decode.d6.loss_mask: 0.2828  decode.d6.loss_dice: 0.2569  decode.d7.loss_cls: 0.1437  decode.d7.loss_mask: 0.2898  decode.d7.loss_dice: 0.2611  decode.d8.loss_cls: 0.1528  decode.d8.loss_mask: 0.2881  decode.d8.loss_dice: 0.2718
08/06 10:07:44 - mmengine - INFO - Iter(train) [ 56850/320000]  base_lr: 8.3859e-05 lr: 8.3859e-06  eta: 1 day, 12:01:37  time: 0.4943  data_time: 0.0110  memory: 5911  grad_norm: 187.6791  loss: 6.9259  decode.loss_cls: 0.2162  decode.loss_mask: 0.2034  decode.loss_dice: 0.2132  decode.d0.loss_cls: 0.9821  decode.d0.loss_mask: 0.1812  decode.d0.loss_dice: 0.2021  decode.d1.loss_cls: 0.1935  decode.d1.loss_mask: 0.1758  decode.d1.loss_dice: 0.2329  decode.d2.loss_cls: 0.2109  decode.d2.loss_mask: 0.1776  decode.d2.loss_dice: 0.2003  decode.d3.loss_cls: 0.2127  decode.d3.loss_mask: 0.1791  decode.d3.loss_dice: 0.2114  decode.d4.loss_cls: 0.2188  decode.d4.loss_mask: 0.1765  decode.d4.loss_dice: 0.2123  decode.d5.loss_cls: 0.2320  decode.d5.loss_mask: 0.1802  decode.d5.loss_dice: 0.2135  decode.d6.loss_cls: 0.2342  decode.d6.loss_mask: 0.1875  decode.d6.loss_dice: 0.2421  decode.d7.loss_cls: 0.2008  decode.d7.loss_mask: 0.1971  decode.d7.loss_dice: 0.2116  decode.d8.loss_cls: 0.2133  decode.d8.loss_mask: 0.2018  decode.d8.loss_dice: 0.2118
08/06 10:08:09 - mmengine - INFO - Iter(train) [ 56900/320000]  base_lr: 8.3845e-05 lr: 8.3845e-06  eta: 1 day, 12:01:13  time: 0.4953  data_time: 0.0112  memory: 5894  grad_norm: 165.2792  loss: 7.2070  decode.loss_cls: 0.1707  decode.loss_mask: 0.2207  decode.loss_dice: 0.2381  decode.d0.loss_cls: 1.1198  decode.d0.loss_mask: 0.2281  decode.d0.loss_dice: 0.2446  decode.d1.loss_cls: 0.2541  decode.d1.loss_mask: 0.2284  decode.d1.loss_dice: 0.2366  decode.d2.loss_cls: 0.1562  decode.d2.loss_mask: 0.2232  decode.d2.loss_dice: 0.2412  decode.d3.loss_cls: 0.1312  decode.d3.loss_mask: 0.2225  decode.d3.loss_dice: 0.2309  decode.d4.loss_cls: 0.1812  decode.d4.loss_mask: 0.2218  decode.d4.loss_dice: 0.2214  decode.d5.loss_cls: 0.1798  decode.d5.loss_mask: 0.2261  decode.d5.loss_dice: 0.2288  decode.d6.loss_cls: 0.1714  decode.d6.loss_mask: 0.2264  decode.d6.loss_dice: 0.2426  decode.d7.loss_cls: 0.1384  decode.d7.loss_mask: 0.2199  decode.d7.loss_dice: 0.2311  decode.d8.loss_cls: 0.1159  decode.d8.loss_mask: 0.2233  decode.d8.loss_dice: 0.2327
08/06 10:08:34 - mmengine - INFO - Iter(train) [ 56950/320000]  base_lr: 8.3830e-05 lr: 8.3830e-06  eta: 1 day, 12:00:49  time: 0.4951  data_time: 0.0116  memory: 5895  grad_norm: 74.2897  loss: 7.2171  decode.loss_cls: 0.0656  decode.loss_mask: 0.2663  decode.loss_dice: 0.2704  decode.d0.loss_cls: 0.8743  decode.d0.loss_mask: 0.2746  decode.d0.loss_dice: 0.2890  decode.d1.loss_cls: 0.1524  decode.d1.loss_mask: 0.2734  decode.d1.loss_dice: 0.3017  decode.d2.loss_cls: 0.0924  decode.d2.loss_mask: 0.2743  decode.d2.loss_dice: 0.2835  decode.d3.loss_cls: 0.0878  decode.d3.loss_mask: 0.2689  decode.d3.loss_dice: 0.2752  decode.d4.loss_cls: 0.0618  decode.d4.loss_mask: 0.2691  decode.d4.loss_dice: 0.2759  decode.d5.loss_cls: 0.0859  decode.d5.loss_mask: 0.2703  decode.d5.loss_dice: 0.2731  decode.d6.loss_cls: 0.0947  decode.d6.loss_mask: 0.2700  decode.d6.loss_dice: 0.2794  decode.d7.loss_cls: 0.0880  decode.d7.loss_mask: 0.2712  decode.d7.loss_dice: 0.2697  decode.d8.loss_cls: 0.0882  decode.d8.loss_mask: 0.2725  decode.d8.loss_dice: 0.2972
08/06 10:08:59 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 10:08:59 - mmengine - INFO - Iter(train) [ 57000/320000]  base_lr: 8.3816e-05 lr: 8.3816e-06  eta: 1 day, 12:00:24  time: 0.4944  data_time: 0.0112  memory: 5911  grad_norm: 167.3832  loss: 10.1717  decode.loss_cls: 0.2899  decode.loss_mask: 0.3019  decode.loss_dice: 0.3658  decode.d0.loss_cls: 0.9177  decode.d0.loss_mask: 0.2911  decode.d0.loss_dice: 0.3346  decode.d1.loss_cls: 0.3294  decode.d1.loss_mask: 0.2915  decode.d1.loss_dice: 0.3835  decode.d2.loss_cls: 0.2761  decode.d2.loss_mask: 0.2884  decode.d2.loss_dice: 0.3691  decode.d3.loss_cls: 0.2949  decode.d3.loss_mask: 0.2874  decode.d3.loss_dice: 0.3727  decode.d4.loss_cls: 0.2721  decode.d4.loss_mask: 0.2861  decode.d4.loss_dice: 0.3598  decode.d5.loss_cls: 0.3115  decode.d5.loss_mask: 0.2973  decode.d5.loss_dice: 0.3681  decode.d6.loss_cls: 0.3248  decode.d6.loss_mask: 0.2875  decode.d6.loss_dice: 0.3522  decode.d7.loss_cls: 0.2981  decode.d7.loss_mask: 0.2931  decode.d7.loss_dice: 0.3612  decode.d8.loss_cls: 0.2832  decode.d8.loss_mask: 0.2988  decode.d8.loss_dice: 0.3835
08/06 10:09:24 - mmengine - INFO - Iter(train) [ 57050/320000]  base_lr: 8.3802e-05 lr: 8.3802e-06  eta: 1 day, 12:00:01  time: 0.4940  data_time: 0.0112  memory: 5911  grad_norm: 54.2256  loss: 6.8246  decode.loss_cls: 0.0982  decode.loss_mask: 0.2301  decode.loss_dice: 0.2663  decode.d0.loss_cls: 0.9663  decode.d0.loss_mask: 0.2285  decode.d0.loss_dice: 0.2523  decode.d1.loss_cls: 0.1170  decode.d1.loss_mask: 0.2279  decode.d1.loss_dice: 0.2710  decode.d2.loss_cls: 0.0879  decode.d2.loss_mask: 0.2287  decode.d2.loss_dice: 0.2400  decode.d3.loss_cls: 0.0968  decode.d3.loss_mask: 0.2285  decode.d3.loss_dice: 0.2575  decode.d4.loss_cls: 0.1074  decode.d4.loss_mask: 0.2267  decode.d4.loss_dice: 0.2625  decode.d5.loss_cls: 0.1042  decode.d5.loss_mask: 0.2272  decode.d5.loss_dice: 0.2582  decode.d6.loss_cls: 0.1077  decode.d6.loss_mask: 0.2290  decode.d6.loss_dice: 0.2874  decode.d7.loss_cls: 0.1243  decode.d7.loss_mask: 0.2286  decode.d7.loss_dice: 0.2641  decode.d8.loss_cls: 0.0841  decode.d8.loss_mask: 0.2318  decode.d8.loss_dice: 0.2843
08/06 10:09:48 - mmengine - INFO - Iter(train) [ 57100/320000]  base_lr: 8.3787e-05 lr: 8.3787e-06  eta: 1 day, 11:59:36  time: 0.4949  data_time: 0.0113  memory: 5911  grad_norm: 101.6547  loss: 5.1976  decode.loss_cls: 0.0326  decode.loss_mask: 0.1960  decode.loss_dice: 0.2215  decode.d0.loss_cls: 0.7381  decode.d0.loss_mask: 0.2047  decode.d0.loss_dice: 0.2372  decode.d1.loss_cls: 0.0191  decode.d1.loss_mask: 0.2025  decode.d1.loss_dice: 0.2325  decode.d2.loss_cls: 0.0123  decode.d2.loss_mask: 0.1965  decode.d2.loss_dice: 0.2214  decode.d3.loss_cls: 0.0166  decode.d3.loss_mask: 0.1999  decode.d3.loss_dice: 0.2309  decode.d4.loss_cls: 0.0156  decode.d4.loss_mask: 0.1985  decode.d4.loss_dice: 0.2316  decode.d5.loss_cls: 0.0165  decode.d5.loss_mask: 0.1960  decode.d5.loss_dice: 0.2321  decode.d6.loss_cls: 0.0191  decode.d6.loss_mask: 0.1994  decode.d6.loss_dice: 0.2261  decode.d7.loss_cls: 0.0235  decode.d7.loss_mask: 0.1969  decode.d7.loss_dice: 0.2277  decode.d8.loss_cls: 0.0304  decode.d8.loss_mask: 0.1949  decode.d8.loss_dice: 0.2276
08/06 10:10:13 - mmengine - INFO - Iter(train) [ 57150/320000]  base_lr: 8.3773e-05 lr: 8.3773e-06  eta: 1 day, 11:59:12  time: 0.4942  data_time: 0.0112  memory: 5894  grad_norm: 46.1782  loss: 5.4824  decode.loss_cls: 0.0228  decode.loss_mask: 0.2310  decode.loss_dice: 0.2234  decode.d0.loss_cls: 0.7482  decode.d0.loss_mask: 0.2339  decode.d0.loss_dice: 0.2221  decode.d1.loss_cls: 0.0263  decode.d1.loss_mask: 0.2296  decode.d1.loss_dice: 0.2221  decode.d2.loss_cls: 0.0168  decode.d2.loss_mask: 0.2323  decode.d2.loss_dice: 0.2225  decode.d3.loss_cls: 0.0151  decode.d3.loss_mask: 0.2302  decode.d3.loss_dice: 0.2205  decode.d4.loss_cls: 0.0214  decode.d4.loss_mask: 0.2293  decode.d4.loss_dice: 0.2192  decode.d5.loss_cls: 0.0272  decode.d5.loss_mask: 0.2305  decode.d5.loss_dice: 0.2202  decode.d6.loss_cls: 0.0272  decode.d6.loss_mask: 0.2313  decode.d6.loss_dice: 0.2224  decode.d7.loss_cls: 0.0231  decode.d7.loss_mask: 0.2313  decode.d7.loss_dice: 0.2231  decode.d8.loss_cls: 0.0185  decode.d8.loss_mask: 0.2319  decode.d8.loss_dice: 0.2292
08/06 10:10:38 - mmengine - INFO - Iter(train) [ 57200/320000]  base_lr: 8.3759e-05 lr: 8.3759e-06  eta: 1 day, 11:58:48  time: 0.4946  data_time: 0.0114  memory: 5895  grad_norm: 95.4448  loss: 6.8816  decode.loss_cls: 0.1338  decode.loss_mask: 0.2147  decode.loss_dice: 0.2580  decode.d0.loss_cls: 0.8380  decode.d0.loss_mask: 0.2190  decode.d0.loss_dice: 0.2771  decode.d1.loss_cls: 0.1359  decode.d1.loss_mask: 0.2148  decode.d1.loss_dice: 0.2958  decode.d2.loss_cls: 0.1644  decode.d2.loss_mask: 0.2104  decode.d2.loss_dice: 0.3163  decode.d3.loss_cls: 0.1152  decode.d3.loss_mask: 0.2129  decode.d3.loss_dice: 0.2948  decode.d4.loss_cls: 0.1314  decode.d4.loss_mask: 0.2111  decode.d4.loss_dice: 0.2371  decode.d5.loss_cls: 0.1146  decode.d5.loss_mask: 0.2100  decode.d5.loss_dice: 0.2277  decode.d6.loss_cls: 0.1319  decode.d6.loss_mask: 0.2090  decode.d6.loss_dice: 0.2510  decode.d7.loss_cls: 0.1088  decode.d7.loss_mask: 0.2090  decode.d7.loss_dice: 0.3088  decode.d8.loss_cls: 0.1410  decode.d8.loss_mask: 0.2121  decode.d8.loss_dice: 0.2771
08/06 10:11:03 - mmengine - INFO - Iter(train) [ 57250/320000]  base_lr: 8.3744e-05 lr: 8.3744e-06  eta: 1 day, 11:58:24  time: 0.4948  data_time: 0.0111  memory: 5928  grad_norm: 68.8327  loss: 6.8305  decode.loss_cls: 0.0606  decode.loss_mask: 0.1756  decode.loss_dice: 0.2947  decode.d0.loss_cls: 0.9221  decode.d0.loss_mask: 0.1780  decode.d0.loss_dice: 0.2650  decode.d1.loss_cls: 0.3185  decode.d1.loss_mask: 0.1748  decode.d1.loss_dice: 0.2635  decode.d2.loss_cls: 0.1966  decode.d2.loss_mask: 0.1731  decode.d2.loss_dice: 0.2601  decode.d3.loss_cls: 0.1466  decode.d3.loss_mask: 0.1742  decode.d3.loss_dice: 0.2876  decode.d4.loss_cls: 0.1095  decode.d4.loss_mask: 0.1764  decode.d4.loss_dice: 0.2882  decode.d5.loss_cls: 0.0745  decode.d5.loss_mask: 0.1768  decode.d5.loss_dice: 0.3167  decode.d6.loss_cls: 0.1805  decode.d6.loss_mask: 0.1751  decode.d6.loss_dice: 0.2921  decode.d7.loss_cls: 0.0690  decode.d7.loss_mask: 0.1745  decode.d7.loss_dice: 0.2860  decode.d8.loss_cls: 0.1564  decode.d8.loss_mask: 0.1744  decode.d8.loss_dice: 0.2893
08/06 10:11:27 - mmengine - INFO - Iter(train) [ 57300/320000]  base_lr: 8.3730e-05 lr: 8.3730e-06  eta: 1 day, 11:58:00  time: 0.4952  data_time: 0.0113  memory: 5911  grad_norm: 59.4014  loss: 7.4956  decode.loss_cls: 0.1759  decode.loss_mask: 0.2728  decode.loss_dice: 0.2242  decode.d0.loss_cls: 0.8761  decode.d0.loss_mask: 0.2756  decode.d0.loss_dice: 0.2184  decode.d1.loss_cls: 0.1959  decode.d1.loss_mask: 0.2484  decode.d1.loss_dice: 0.2216  decode.d2.loss_cls: 0.1958  decode.d2.loss_mask: 0.2725  decode.d2.loss_dice: 0.2297  decode.d3.loss_cls: 0.1691  decode.d3.loss_mask: 0.2787  decode.d3.loss_dice: 0.2373  decode.d4.loss_cls: 0.1910  decode.d4.loss_mask: 0.2749  decode.d4.loss_dice: 0.2440  decode.d5.loss_cls: 0.1961  decode.d5.loss_mask: 0.2965  decode.d5.loss_dice: 0.2418  decode.d6.loss_cls: 0.1169  decode.d6.loss_mask: 0.2811  decode.d6.loss_dice: 0.2300  decode.d7.loss_cls: 0.1702  decode.d7.loss_mask: 0.2961  decode.d7.loss_dice: 0.2468  decode.d8.loss_cls: 0.1069  decode.d8.loss_mask: 0.2813  decode.d8.loss_dice: 0.2302
08/06 10:11:52 - mmengine - INFO - Iter(train) [ 57350/320000]  base_lr: 8.3716e-05 lr: 8.3716e-06  eta: 1 day, 11:57:36  time: 0.4938  data_time: 0.0110  memory: 5928  grad_norm: 305.5188  loss: 8.1915  decode.loss_cls: 0.1500  decode.loss_mask: 0.2862  decode.loss_dice: 0.2839  decode.d0.loss_cls: 0.9102  decode.d0.loss_mask: 0.3071  decode.d0.loss_dice: 0.2957  decode.d1.loss_cls: 0.2353  decode.d1.loss_mask: 0.2887  decode.d1.loss_dice: 0.2847  decode.d2.loss_cls: 0.2002  decode.d2.loss_mask: 0.2915  decode.d2.loss_dice: 0.2873  decode.d3.loss_cls: 0.1997  decode.d3.loss_mask: 0.2889  decode.d3.loss_dice: 0.2725  decode.d4.loss_cls: 0.1772  decode.d4.loss_mask: 0.2881  decode.d4.loss_dice: 0.3008  decode.d5.loss_cls: 0.1580  decode.d5.loss_mask: 0.2821  decode.d5.loss_dice: 0.2885  decode.d6.loss_cls: 0.1270  decode.d6.loss_mask: 0.2830  decode.d6.loss_dice: 0.2809  decode.d7.loss_cls: 0.1362  decode.d7.loss_mask: 0.2841  decode.d7.loss_dice: 0.2881  decode.d8.loss_cls: 0.1492  decode.d8.loss_mask: 0.2855  decode.d8.loss_dice: 0.2811
08/06 10:12:17 - mmengine - INFO - Iter(train) [ 57400/320000]  base_lr: 8.3701e-05 lr: 8.3701e-06  eta: 1 day, 11:57:12  time: 0.4935  data_time: 0.0111  memory: 5911  grad_norm: 84.0480  loss: 8.9139  decode.loss_cls: 0.2648  decode.loss_mask: 0.2635  decode.loss_dice: 0.3378  decode.d0.loss_cls: 0.9430  decode.d0.loss_mask: 0.2670  decode.d0.loss_dice: 0.3663  decode.d1.loss_cls: 0.1845  decode.d1.loss_mask: 0.2685  decode.d1.loss_dice: 0.3569  decode.d2.loss_cls: 0.1811  decode.d2.loss_mask: 0.2635  decode.d2.loss_dice: 0.3478  decode.d3.loss_cls: 0.1592  decode.d3.loss_mask: 0.2674  decode.d3.loss_dice: 0.3474  decode.d4.loss_cls: 0.2050  decode.d4.loss_mask: 0.2702  decode.d4.loss_dice: 0.3515  decode.d5.loss_cls: 0.2280  decode.d5.loss_mask: 0.2623  decode.d5.loss_dice: 0.3410  decode.d6.loss_cls: 0.1929  decode.d6.loss_mask: 0.2672  decode.d6.loss_dice: 0.3540  decode.d7.loss_cls: 0.2161  decode.d7.loss_mask: 0.2680  decode.d7.loss_dice: 0.3501  decode.d8.loss_cls: 0.1737  decode.d8.loss_mask: 0.2696  decode.d8.loss_dice: 0.3456
08/06 10:12:42 - mmengine - INFO - Iter(train) [ 57450/320000]  base_lr: 8.3687e-05 lr: 8.3687e-06  eta: 1 day, 11:56:48  time: 0.4948  data_time: 0.0109  memory: 5930  grad_norm: 150.1713  loss: 7.2669  decode.loss_cls: 0.0715  decode.loss_mask: 0.2444  decode.loss_dice: 0.3126  decode.d0.loss_cls: 0.9863  decode.d0.loss_mask: 0.2473  decode.d0.loss_dice: 0.2917  decode.d1.loss_cls: 0.0826  decode.d1.loss_mask: 0.2620  decode.d1.loss_dice: 0.3340  decode.d2.loss_cls: 0.0941  decode.d2.loss_mask: 0.2413  decode.d2.loss_dice: 0.2990  decode.d3.loss_cls: 0.0989  decode.d3.loss_mask: 0.2448  decode.d3.loss_dice: 0.3082  decode.d4.loss_cls: 0.0426  decode.d4.loss_mask: 0.2483  decode.d4.loss_dice: 0.3168  decode.d5.loss_cls: 0.1126  decode.d5.loss_mask: 0.2404  decode.d5.loss_dice: 0.3038  decode.d6.loss_cls: 0.0866  decode.d6.loss_mask: 0.2407  decode.d6.loss_dice: 0.2971  decode.d7.loss_cls: 0.0952  decode.d7.loss_mask: 0.2422  decode.d7.loss_dice: 0.3073  decode.d8.loss_cls: 0.0717  decode.d8.loss_mask: 0.2444  decode.d8.loss_dice: 0.2986
08/06 10:13:06 - mmengine - INFO - Iter(train) [ 57500/320000]  base_lr: 8.3672e-05 lr: 8.3672e-06  eta: 1 day, 11:56:24  time: 0.4960  data_time: 0.0110  memory: 5878  grad_norm: 65.6435  loss: 5.6224  decode.loss_cls: 0.0252  decode.loss_mask: 0.1871  decode.loss_dice: 0.2619  decode.d0.loss_cls: 0.8676  decode.d0.loss_mask: 0.1859  decode.d0.loss_dice: 0.2458  decode.d1.loss_cls: 0.0259  decode.d1.loss_mask: 0.1904  decode.d1.loss_dice: 0.2559  decode.d2.loss_cls: 0.0197  decode.d2.loss_mask: 0.1903  decode.d2.loss_dice: 0.2521  decode.d3.loss_cls: 0.0276  decode.d3.loss_mask: 0.1889  decode.d3.loss_dice: 0.2568  decode.d4.loss_cls: 0.0664  decode.d4.loss_mask: 0.1878  decode.d4.loss_dice: 0.2612  decode.d5.loss_cls: 0.0376  decode.d5.loss_mask: 0.1876  decode.d5.loss_dice: 0.2603  decode.d6.loss_cls: 0.0348  decode.d6.loss_mask: 0.1872  decode.d6.loss_dice: 0.2596  decode.d7.loss_cls: 0.0568  decode.d7.loss_mask: 0.1910  decode.d7.loss_dice: 0.2503  decode.d8.loss_cls: 0.0288  decode.d8.loss_mask: 0.1875  decode.d8.loss_dice: 0.2443
08/06 10:13:31 - mmengine - INFO - Iter(train) [ 57550/320000]  base_lr: 8.3658e-05 lr: 8.3658e-06  eta: 1 day, 11:55:59  time: 0.4951  data_time: 0.0112  memory: 5913  grad_norm: 313.5721  loss: 7.5796  decode.loss_cls: 0.1059  decode.loss_mask: 0.2750  decode.loss_dice: 0.2875  decode.d0.loss_cls: 0.8780  decode.d0.loss_mask: 0.2866  decode.d0.loss_dice: 0.2951  decode.d1.loss_cls: 0.1292  decode.d1.loss_mask: 0.2769  decode.d1.loss_dice: 0.2834  decode.d2.loss_cls: 0.1582  decode.d2.loss_mask: 0.2759  decode.d2.loss_dice: 0.3055  decode.d3.loss_cls: 0.1148  decode.d3.loss_mask: 0.2745  decode.d3.loss_dice: 0.2862  decode.d4.loss_cls: 0.1276  decode.d4.loss_mask: 0.2718  decode.d4.loss_dice: 0.2829  decode.d5.loss_cls: 0.1155  decode.d5.loss_mask: 0.2722  decode.d5.loss_dice: 0.2843  decode.d6.loss_cls: 0.1030  decode.d6.loss_mask: 0.2733  decode.d6.loss_dice: 0.2810  decode.d7.loss_cls: 0.1002  decode.d7.loss_mask: 0.2753  decode.d7.loss_dice: 0.2886  decode.d8.loss_cls: 0.1143  decode.d8.loss_mask: 0.2739  decode.d8.loss_dice: 0.2831
08/06 10:13:56 - mmengine - INFO - Iter(train) [ 57600/320000]  base_lr: 8.3644e-05 lr: 8.3644e-06  eta: 1 day, 11:55:35  time: 0.4946  data_time: 0.0111  memory: 5894  grad_norm: 91.3276  loss: 9.3842  decode.loss_cls: 0.2002  decode.loss_mask: 0.2884  decode.loss_dice: 0.3605  decode.d0.loss_cls: 0.9577  decode.d0.loss_mask: 0.2904  decode.d0.loss_dice: 0.3752  decode.d1.loss_cls: 0.2266  decode.d1.loss_mask: 0.2887  decode.d1.loss_dice: 0.3766  decode.d2.loss_cls: 0.1813  decode.d2.loss_mask: 0.2924  decode.d2.loss_dice: 0.3739  decode.d3.loss_cls: 0.1639  decode.d3.loss_mask: 0.2878  decode.d3.loss_dice: 0.4021  decode.d4.loss_cls: 0.1976  decode.d4.loss_mask: 0.2889  decode.d4.loss_dice: 0.3329  decode.d5.loss_cls: 0.1880  decode.d5.loss_mask: 0.2875  decode.d5.loss_dice: 0.3807  decode.d6.loss_cls: 0.2078  decode.d6.loss_mask: 0.2838  decode.d6.loss_dice: 0.3542  decode.d7.loss_cls: 0.2501  decode.d7.loss_mask: 0.2884  decode.d7.loss_dice: 0.3822  decode.d8.loss_cls: 0.2422  decode.d8.loss_mask: 0.2846  decode.d8.loss_dice: 0.3496
08/06 10:14:21 - mmengine - INFO - Iter(train) [ 57650/320000]  base_lr: 8.3629e-05 lr: 8.3629e-06  eta: 1 day, 11:55:11  time: 0.4965  data_time: 0.0113  memory: 5931  grad_norm: 87.0838  loss: 6.9491  decode.loss_cls: 0.1911  decode.loss_mask: 0.2180  decode.loss_dice: 0.2464  decode.d0.loss_cls: 0.8342  decode.d0.loss_mask: 0.2157  decode.d0.loss_dice: 0.2377  decode.d1.loss_cls: 0.1467  decode.d1.loss_mask: 0.2112  decode.d1.loss_dice: 0.2431  decode.d2.loss_cls: 0.1189  decode.d2.loss_mask: 0.2152  decode.d2.loss_dice: 0.2531  decode.d3.loss_cls: 0.1428  decode.d3.loss_mask: 0.2123  decode.d3.loss_dice: 0.2372  decode.d4.loss_cls: 0.1780  decode.d4.loss_mask: 0.2145  decode.d4.loss_dice: 0.2470  decode.d5.loss_cls: 0.1894  decode.d5.loss_mask: 0.2141  decode.d5.loss_dice: 0.2726  decode.d6.loss_cls: 0.1847  decode.d6.loss_mask: 0.2133  decode.d6.loss_dice: 0.2540  decode.d7.loss_cls: 0.1426  decode.d7.loss_mask: 0.2135  decode.d7.loss_dice: 0.2540  decode.d8.loss_cls: 0.1820  decode.d8.loss_mask: 0.2123  decode.d8.loss_dice: 0.2535
08/06 10:14:46 - mmengine - INFO - Iter(train) [ 57700/320000]  base_lr: 8.3615e-05 lr: 8.3615e-06  eta: 1 day, 11:54:47  time: 0.4954  data_time: 0.0112  memory: 5875  grad_norm: 166.4842  loss: 7.6074  decode.loss_cls: 0.1772  decode.loss_mask: 0.2049  decode.loss_dice: 0.2749  decode.d0.loss_cls: 1.1074  decode.d0.loss_mask: 0.1996  decode.d0.loss_dice: 0.2468  decode.d1.loss_cls: 0.3055  decode.d1.loss_mask: 0.2016  decode.d1.loss_dice: 0.2531  decode.d2.loss_cls: 0.2584  decode.d2.loss_mask: 0.1990  decode.d2.loss_dice: 0.2626  decode.d3.loss_cls: 0.2111  decode.d3.loss_mask: 0.2042  decode.d3.loss_dice: 0.2624  decode.d4.loss_cls: 0.1870  decode.d4.loss_mask: 0.1980  decode.d4.loss_dice: 0.2495  decode.d5.loss_cls: 0.1830  decode.d5.loss_mask: 0.2226  decode.d5.loss_dice: 0.2611  decode.d6.loss_cls: 0.2520  decode.d6.loss_mask: 0.1929  decode.d6.loss_dice: 0.2349  decode.d7.loss_cls: 0.1414  decode.d7.loss_mask: 0.2064  decode.d7.loss_dice: 0.2755  decode.d8.loss_cls: 0.1713  decode.d8.loss_mask: 0.1969  decode.d8.loss_dice: 0.2659
08/06 10:15:10 - mmengine - INFO - Iter(train) [ 57750/320000]  base_lr: 8.3601e-05 lr: 8.3601e-06  eta: 1 day, 11:54:23  time: 0.4961  data_time: 0.0114  memory: 5928  grad_norm: 86.7398  loss: 6.2701  decode.loss_cls: 0.1010  decode.loss_mask: 0.2195  decode.loss_dice: 0.2370  decode.d0.loss_cls: 0.8129  decode.d0.loss_mask: 0.2194  decode.d0.loss_dice: 0.2317  decode.d1.loss_cls: 0.1192  decode.d1.loss_mask: 0.2188  decode.d1.loss_dice: 0.2540  decode.d2.loss_cls: 0.1047  decode.d2.loss_mask: 0.2184  decode.d2.loss_dice: 0.2469  decode.d3.loss_cls: 0.0874  decode.d3.loss_mask: 0.2168  decode.d3.loss_dice: 0.2395  decode.d4.loss_cls: 0.0913  decode.d4.loss_mask: 0.2189  decode.d4.loss_dice: 0.2380  decode.d5.loss_cls: 0.1019  decode.d5.loss_mask: 0.2208  decode.d5.loss_dice: 0.2376  decode.d6.loss_cls: 0.0800  decode.d6.loss_mask: 0.2205  decode.d6.loss_dice: 0.2564  decode.d7.loss_cls: 0.0762  decode.d7.loss_mask: 0.2207  decode.d7.loss_dice: 0.2404  decode.d8.loss_cls: 0.0752  decode.d8.loss_mask: 0.2206  decode.d8.loss_dice: 0.2443
08/06 10:15:35 - mmengine - INFO - Iter(train) [ 57800/320000]  base_lr: 8.3586e-05 lr: 8.3586e-06  eta: 1 day, 11:53:59  time: 0.4963  data_time: 0.0114  memory: 5911  grad_norm: 50.8547  loss: 5.7217  decode.loss_cls: 0.0180  decode.loss_mask: 0.1978  decode.loss_dice: 0.2266  decode.d0.loss_cls: 0.9266  decode.d0.loss_mask: 0.1982  decode.d0.loss_dice: 0.2301  decode.d1.loss_cls: 0.1227  decode.d1.loss_mask: 0.1993  decode.d1.loss_dice: 0.2282  decode.d2.loss_cls: 0.1264  decode.d2.loss_mask: 0.1954  decode.d2.loss_dice: 0.2364  decode.d3.loss_cls: 0.1109  decode.d3.loss_mask: 0.1954  decode.d3.loss_dice: 0.2329  decode.d4.loss_cls: 0.0300  decode.d4.loss_mask: 0.1969  decode.d4.loss_dice: 0.2309  decode.d5.loss_cls: 0.0336  decode.d5.loss_mask: 0.1979  decode.d5.loss_dice: 0.2263  decode.d6.loss_cls: 0.0306  decode.d6.loss_mask: 0.1986  decode.d6.loss_dice: 0.2263  decode.d7.loss_cls: 0.0570  decode.d7.loss_mask: 0.1957  decode.d7.loss_dice: 0.2229  decode.d8.loss_cls: 0.0176  decode.d8.loss_mask: 0.1960  decode.d8.loss_dice: 0.2164
08/06 10:16:00 - mmengine - INFO - Iter(train) [ 57850/320000]  base_lr: 8.3572e-05 lr: 8.3572e-06  eta: 1 day, 11:53:35  time: 0.4957  data_time: 0.0112  memory: 5894  grad_norm: 145.0655  loss: 9.9383  decode.loss_cls: 0.2532  decode.loss_mask: 0.3395  decode.loss_dice: 0.3592  decode.d0.loss_cls: 1.0233  decode.d0.loss_mask: 0.3569  decode.d0.loss_dice: 0.3616  decode.d1.loss_cls: 0.1459  decode.d1.loss_mask: 0.3404  decode.d1.loss_dice: 0.3505  decode.d2.loss_cls: 0.1936  decode.d2.loss_mask: 0.3351  decode.d2.loss_dice: 0.3551  decode.d3.loss_cls: 0.1831  decode.d3.loss_mask: 0.3621  decode.d3.loss_dice: 0.3786  decode.d4.loss_cls: 0.1954  decode.d4.loss_mask: 0.3642  decode.d4.loss_dice: 0.3926  decode.d5.loss_cls: 0.0970  decode.d5.loss_mask: 0.3672  decode.d5.loss_dice: 0.3868  decode.d6.loss_cls: 0.2048  decode.d6.loss_mask: 0.3501  decode.d6.loss_dice: 0.3772  decode.d7.loss_cls: 0.1882  decode.d7.loss_mask: 0.3702  decode.d7.loss_dice: 0.3790  decode.d8.loss_cls: 0.2294  decode.d8.loss_mask: 0.3337  decode.d8.loss_dice: 0.3642
08/06 10:16:25 - mmengine - INFO - Iter(train) [ 57900/320000]  base_lr: 8.3558e-05 lr: 8.3558e-06  eta: 1 day, 11:53:11  time: 0.4961  data_time: 0.0112  memory: 5911  grad_norm: 59.5767  loss: 6.0720  decode.loss_cls: 0.1214  decode.loss_mask: 0.1729  decode.loss_dice: 0.2474  decode.d0.loss_cls: 0.7873  decode.d0.loss_mask: 0.1768  decode.d0.loss_dice: 0.2705  decode.d1.loss_cls: 0.1234  decode.d1.loss_mask: 0.1726  decode.d1.loss_dice: 0.2476  decode.d2.loss_cls: 0.1000  decode.d2.loss_mask: 0.1724  decode.d2.loss_dice: 0.2539  decode.d3.loss_cls: 0.1190  decode.d3.loss_mask: 0.1703  decode.d3.loss_dice: 0.2417  decode.d4.loss_cls: 0.1219  decode.d4.loss_mask: 0.1720  decode.d4.loss_dice: 0.2380  decode.d5.loss_cls: 0.1181  decode.d5.loss_mask: 0.1724  decode.d5.loss_dice: 0.2559  decode.d6.loss_cls: 0.1323  decode.d6.loss_mask: 0.1703  decode.d6.loss_dice: 0.2383  decode.d7.loss_cls: 0.0923  decode.d7.loss_mask: 0.1733  decode.d7.loss_dice: 0.2541  decode.d8.loss_cls: 0.1383  decode.d8.loss_mask: 0.1727  decode.d8.loss_dice: 0.2448
08/06 10:16:50 - mmengine - INFO - Iter(train) [ 57950/320000]  base_lr: 8.3543e-05 lr: 8.3543e-06  eta: 1 day, 11:52:48  time: 0.4964  data_time: 0.0111  memory: 5891  grad_norm: 87.3671  loss: 7.2177  decode.loss_cls: 0.1324  decode.loss_mask: 0.2373  decode.loss_dice: 0.2351  decode.d0.loss_cls: 0.9145  decode.d0.loss_mask: 0.2428  decode.d0.loss_dice: 0.2627  decode.d1.loss_cls: 0.1712  decode.d1.loss_mask: 0.2340  decode.d1.loss_dice: 0.2544  decode.d2.loss_cls: 0.1684  decode.d2.loss_mask: 0.2359  decode.d2.loss_dice: 0.2358  decode.d3.loss_cls: 0.1924  decode.d3.loss_mask: 0.2363  decode.d3.loss_dice: 0.2331  decode.d4.loss_cls: 0.2085  decode.d4.loss_mask: 0.2333  decode.d4.loss_dice: 0.2370  decode.d5.loss_cls: 0.1627  decode.d5.loss_mask: 0.2361  decode.d5.loss_dice: 0.2290  decode.d6.loss_cls: 0.1413  decode.d6.loss_mask: 0.2344  decode.d6.loss_dice: 0.2318  decode.d7.loss_cls: 0.1702  decode.d7.loss_mask: 0.2365  decode.d7.loss_dice: 0.2700  decode.d8.loss_cls: 0.1587  decode.d8.loss_mask: 0.2361  decode.d8.loss_dice: 0.2456
08/06 10:17:14 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 10:17:14 - mmengine - INFO - Iter(train) [ 58000/320000]  base_lr: 8.3529e-05 lr: 8.3529e-06  eta: 1 day, 11:52:24  time: 0.4959  data_time: 0.0115  memory: 5911  grad_norm: 112.2818  loss: 6.7196  decode.loss_cls: 0.0332  decode.loss_mask: 0.2436  decode.loss_dice: 0.2965  decode.d0.loss_cls: 0.9433  decode.d0.loss_mask: 0.2450  decode.d0.loss_dice: 0.2858  decode.d1.loss_cls: 0.1622  decode.d1.loss_mask: 0.2344  decode.d1.loss_dice: 0.2640  decode.d2.loss_cls: 0.0898  decode.d2.loss_mask: 0.2373  decode.d2.loss_dice: 0.2666  decode.d3.loss_cls: 0.0746  decode.d3.loss_mask: 0.2376  decode.d3.loss_dice: 0.2796  decode.d4.loss_cls: 0.0700  decode.d4.loss_mask: 0.2361  decode.d4.loss_dice: 0.2824  decode.d5.loss_cls: 0.0864  decode.d5.loss_mask: 0.2396  decode.d5.loss_dice: 0.2711  decode.d6.loss_cls: 0.0307  decode.d6.loss_mask: 0.2372  decode.d6.loss_dice: 0.2880  decode.d7.loss_cls: 0.0338  decode.d7.loss_mask: 0.2390  decode.d7.loss_dice: 0.2487  decode.d8.loss_cls: 0.0321  decode.d8.loss_mask: 0.2410  decode.d8.loss_dice: 0.2898
08/06 10:17:39 - mmengine - INFO - Iter(train) [ 58050/320000]  base_lr: 8.3515e-05 lr: 8.3515e-06  eta: 1 day, 11:52:00  time: 0.4965  data_time: 0.0113  memory: 5895  grad_norm: 65.1833  loss: 5.6846  decode.loss_cls: 0.0684  decode.loss_mask: 0.2297  decode.loss_dice: 0.2178  decode.d0.loss_cls: 0.7719  decode.d0.loss_mask: 0.2328  decode.d0.loss_dice: 0.2179  decode.d1.loss_cls: 0.0513  decode.d1.loss_mask: 0.2278  decode.d1.loss_dice: 0.2166  decode.d2.loss_cls: 0.0251  decode.d2.loss_mask: 0.2262  decode.d2.loss_dice: 0.2248  decode.d3.loss_cls: 0.0496  decode.d3.loss_mask: 0.2263  decode.d3.loss_dice: 0.2179  decode.d4.loss_cls: 0.0754  decode.d4.loss_mask: 0.2281  decode.d4.loss_dice: 0.2173  decode.d5.loss_cls: 0.0396  decode.d5.loss_mask: 0.2274  decode.d5.loss_dice: 0.2137  decode.d6.loss_cls: 0.0375  decode.d6.loss_mask: 0.2280  decode.d6.loss_dice: 0.2196  decode.d7.loss_cls: 0.0503  decode.d7.loss_mask: 0.2264  decode.d7.loss_dice: 0.2158  decode.d8.loss_cls: 0.0497  decode.d8.loss_mask: 0.2280  decode.d8.loss_dice: 0.2236
08/06 10:18:04 - mmengine - INFO - Iter(train) [ 58100/320000]  base_lr: 8.3500e-05 lr: 8.3500e-06  eta: 1 day, 11:51:36  time: 0.4954  data_time: 0.0111  memory: 5928  grad_norm: 145.1858  loss: 8.4553  decode.loss_cls: 0.2474  decode.loss_mask: 0.1998  decode.loss_dice: 0.2617  decode.d0.loss_cls: 1.1334  decode.d0.loss_mask: 0.2087  decode.d0.loss_dice: 0.3077  decode.d1.loss_cls: 0.2913  decode.d1.loss_mask: 0.2083  decode.d1.loss_dice: 0.2728  decode.d2.loss_cls: 0.2674  decode.d2.loss_mask: 0.1985  decode.d2.loss_dice: 0.2727  decode.d3.loss_cls: 0.2555  decode.d3.loss_mask: 0.1987  decode.d3.loss_dice: 0.2839  decode.d4.loss_cls: 0.2395  decode.d4.loss_mask: 0.2026  decode.d4.loss_dice: 0.2775  decode.d5.loss_cls: 0.2776  decode.d5.loss_mask: 0.2009  decode.d5.loss_dice: 0.2834  decode.d6.loss_cls: 0.2535  decode.d6.loss_mask: 0.2022  decode.d6.loss_dice: 0.2952  decode.d7.loss_cls: 0.3085  decode.d7.loss_mask: 0.1969  decode.d7.loss_dice: 0.2922  decode.d8.loss_cls: 0.3337  decode.d8.loss_mask: 0.1998  decode.d8.loss_dice: 0.2841
08/06 10:18:29 - mmengine - INFO - Iter(train) [ 58150/320000]  base_lr: 8.3486e-05 lr: 8.3486e-06  eta: 1 day, 11:51:11  time: 0.4956  data_time: 0.0114  memory: 5896  grad_norm: 469.6750  loss: 6.8634  decode.loss_cls: 0.0855  decode.loss_mask: 0.2830  decode.loss_dice: 0.2562  decode.d0.loss_cls: 0.8383  decode.d0.loss_mask: 0.2866  decode.d0.loss_dice: 0.2714  decode.d1.loss_cls: 0.0571  decode.d1.loss_mask: 0.2981  decode.d1.loss_dice: 0.2785  decode.d2.loss_cls: 0.0789  decode.d2.loss_mask: 0.2873  decode.d2.loss_dice: 0.2479  decode.d3.loss_cls: 0.0287  decode.d3.loss_mask: 0.2888  decode.d3.loss_dice: 0.2639  decode.d4.loss_cls: 0.0322  decode.d4.loss_mask: 0.2842  decode.d4.loss_dice: 0.2708  decode.d5.loss_cls: 0.0843  decode.d5.loss_mask: 0.2820  decode.d5.loss_dice: 0.2798  decode.d6.loss_cls: 0.0662  decode.d6.loss_mask: 0.2775  decode.d6.loss_dice: 0.2421  decode.d7.loss_cls: 0.0247  decode.d7.loss_mask: 0.2955  decode.d7.loss_dice: 0.2741  decode.d8.loss_cls: 0.0316  decode.d8.loss_mask: 0.2984  decode.d8.loss_dice: 0.2698
08/06 10:18:54 - mmengine - INFO - Iter(train) [ 58200/320000]  base_lr: 8.3472e-05 lr: 8.3472e-06  eta: 1 day, 11:50:47  time: 0.4953  data_time: 0.0112  memory: 5911  grad_norm: 48.7121  loss: 6.6202  decode.loss_cls: 0.1213  decode.loss_mask: 0.1893  decode.loss_dice: 0.2460  decode.d0.loss_cls: 1.0436  decode.d0.loss_mask: 0.1929  decode.d0.loss_dice: 0.2535  decode.d1.loss_cls: 0.1958  decode.d1.loss_mask: 0.1931  decode.d1.loss_dice: 0.2360  decode.d2.loss_cls: 0.1265  decode.d2.loss_mask: 0.1883  decode.d2.loss_dice: 0.2360  decode.d3.loss_cls: 0.1530  decode.d3.loss_mask: 0.1914  decode.d3.loss_dice: 0.2465  decode.d4.loss_cls: 0.1536  decode.d4.loss_mask: 0.1916  decode.d4.loss_dice: 0.2432  decode.d5.loss_cls: 0.1291  decode.d5.loss_mask: 0.1893  decode.d5.loss_dice: 0.2391  decode.d6.loss_cls: 0.1293  decode.d6.loss_mask: 0.1911  decode.d6.loss_dice: 0.2302  decode.d7.loss_cls: 0.1303  decode.d7.loss_mask: 0.1920  decode.d7.loss_dice: 0.2456  decode.d8.loss_cls: 0.1190  decode.d8.loss_mask: 0.1888  decode.d8.loss_dice: 0.2348
08/06 10:19:18 - mmengine - INFO - Iter(train) [ 58250/320000]  base_lr: 8.3457e-05 lr: 8.3457e-06  eta: 1 day, 11:50:23  time: 0.4944  data_time: 0.0113  memory: 5878  grad_norm: 66.2499  loss: 6.4312  decode.loss_cls: 0.0918  decode.loss_mask: 0.2011  decode.loss_dice: 0.2804  decode.d0.loss_cls: 0.8270  decode.d0.loss_mask: 0.2015  decode.d0.loss_dice: 0.2889  decode.d1.loss_cls: 0.1235  decode.d1.loss_mask: 0.2038  decode.d1.loss_dice: 0.2785  decode.d2.loss_cls: 0.1075  decode.d2.loss_mask: 0.1989  decode.d2.loss_dice: 0.2556  decode.d3.loss_cls: 0.1153  decode.d3.loss_mask: 0.2031  decode.d3.loss_dice: 0.2739  decode.d4.loss_cls: 0.0857  decode.d4.loss_mask: 0.2012  decode.d4.loss_dice: 0.2785  decode.d5.loss_cls: 0.0701  decode.d5.loss_mask: 0.2014  decode.d5.loss_dice: 0.2796  decode.d6.loss_cls: 0.0756  decode.d6.loss_mask: 0.2004  decode.d6.loss_dice: 0.2864  decode.d7.loss_cls: 0.0707  decode.d7.loss_mask: 0.2022  decode.d7.loss_dice: 0.2649  decode.d8.loss_cls: 0.1054  decode.d8.loss_mask: 0.2010  decode.d8.loss_dice: 0.2574
08/06 10:19:43 - mmengine - INFO - Iter(train) [ 58300/320000]  base_lr: 8.3443e-05 lr: 8.3443e-06  eta: 1 day, 11:49:59  time: 0.4961  data_time: 0.0115  memory: 5911  grad_norm: 67.6064  loss: 6.7150  decode.loss_cls: 0.0852  decode.loss_mask: 0.2110  decode.loss_dice: 0.2570  decode.d0.loss_cls: 0.9030  decode.d0.loss_mask: 0.2138  decode.d0.loss_dice: 0.2549  decode.d1.loss_cls: 0.1891  decode.d1.loss_mask: 0.2132  decode.d1.loss_dice: 0.2529  decode.d2.loss_cls: 0.1609  decode.d2.loss_mask: 0.2130  decode.d2.loss_dice: 0.2518  decode.d3.loss_cls: 0.1402  decode.d3.loss_mask: 0.2087  decode.d3.loss_dice: 0.2574  decode.d4.loss_cls: 0.1382  decode.d4.loss_mask: 0.2070  decode.d4.loss_dice: 0.2547  decode.d5.loss_cls: 0.1421  decode.d5.loss_mask: 0.2082  decode.d5.loss_dice: 0.2456  decode.d6.loss_cls: 0.1227  decode.d6.loss_mask: 0.2122  decode.d6.loss_dice: 0.2471  decode.d7.loss_cls: 0.1026  decode.d7.loss_mask: 0.2116  decode.d7.loss_dice: 0.2542  decode.d8.loss_cls: 0.0914  decode.d8.loss_mask: 0.2108  decode.d8.loss_dice: 0.2546
08/06 10:20:08 - mmengine - INFO - Iter(train) [ 58350/320000]  base_lr: 8.3429e-05 lr: 8.3429e-06  eta: 1 day, 11:49:35  time: 0.4949  data_time: 0.0112  memory: 5894  grad_norm: 66.8638  loss: 6.0764  decode.loss_cls: 0.0846  decode.loss_mask: 0.2192  decode.loss_dice: 0.2523  decode.d0.loss_cls: 0.7848  decode.d0.loss_mask: 0.2209  decode.d0.loss_dice: 0.2576  decode.d1.loss_cls: 0.0720  decode.d1.loss_mask: 0.2203  decode.d1.loss_dice: 0.2703  decode.d2.loss_cls: 0.0500  decode.d2.loss_mask: 0.2209  decode.d2.loss_dice: 0.2619  decode.d3.loss_cls: 0.0499  decode.d3.loss_mask: 0.2227  decode.d3.loss_dice: 0.2554  decode.d4.loss_cls: 0.0665  decode.d4.loss_mask: 0.2199  decode.d4.loss_dice: 0.2519  decode.d5.loss_cls: 0.0550  decode.d5.loss_mask: 0.2204  decode.d5.loss_dice: 0.2550  decode.d6.loss_cls: 0.0517  decode.d6.loss_mask: 0.2186  decode.d6.loss_dice: 0.2522  decode.d7.loss_cls: 0.0470  decode.d7.loss_mask: 0.2224  decode.d7.loss_dice: 0.2588  decode.d8.loss_cls: 0.0471  decode.d8.loss_mask: 0.2196  decode.d8.loss_dice: 0.2475
08/06 10:20:33 - mmengine - INFO - Iter(train) [ 58400/320000]  base_lr: 8.3414e-05 lr: 8.3414e-06  eta: 1 day, 11:49:11  time: 0.4958  data_time: 0.0112  memory: 5895  grad_norm: 103.1572  loss: 7.5900  decode.loss_cls: 0.2094  decode.loss_mask: 0.2074  decode.loss_dice: 0.2565  decode.d0.loss_cls: 0.9941  decode.d0.loss_mask: 0.2170  decode.d0.loss_dice: 0.2864  decode.d1.loss_cls: 0.1696  decode.d1.loss_mask: 0.2043  decode.d1.loss_dice: 0.2591  decode.d2.loss_cls: 0.2094  decode.d2.loss_mask: 0.2082  decode.d2.loss_dice: 0.2668  decode.d3.loss_cls: 0.1980  decode.d3.loss_mask: 0.2074  decode.d3.loss_dice: 0.2707  decode.d4.loss_cls: 0.1879  decode.d4.loss_mask: 0.2082  decode.d4.loss_dice: 0.2706  decode.d5.loss_cls: 0.2484  decode.d5.loss_mask: 0.2065  decode.d5.loss_dice: 0.2620  decode.d6.loss_cls: 0.2459  decode.d6.loss_mask: 0.2037  decode.d6.loss_dice: 0.2401  decode.d7.loss_cls: 0.2110  decode.d7.loss_mask: 0.2079  decode.d7.loss_dice: 0.2554  decode.d8.loss_cls: 0.1965  decode.d8.loss_mask: 0.2085  decode.d8.loss_dice: 0.2731
08/06 10:20:57 - mmengine - INFO - Iter(train) [ 58450/320000]  base_lr: 8.3400e-05 lr: 8.3400e-06  eta: 1 day, 11:48:47  time: 0.4947  data_time: 0.0111  memory: 5913  grad_norm: 72.0190  loss: 5.2132  decode.loss_cls: 0.0264  decode.loss_mask: 0.1878  decode.loss_dice: 0.2190  decode.d0.loss_cls: 0.8936  decode.d0.loss_mask: 0.1888  decode.d0.loss_dice: 0.2149  decode.d1.loss_cls: 0.0245  decode.d1.loss_mask: 0.1884  decode.d1.loss_dice: 0.2253  decode.d2.loss_cls: 0.0279  decode.d2.loss_mask: 0.1886  decode.d2.loss_dice: 0.2141  decode.d3.loss_cls: 0.0365  decode.d3.loss_mask: 0.1868  decode.d3.loss_dice: 0.2199  decode.d4.loss_cls: 0.0302  decode.d4.loss_mask: 0.1908  decode.d4.loss_dice: 0.2225  decode.d5.loss_cls: 0.0307  decode.d5.loss_mask: 0.1865  decode.d5.loss_dice: 0.2157  decode.d6.loss_cls: 0.0280  decode.d6.loss_mask: 0.1865  decode.d6.loss_dice: 0.2160  decode.d7.loss_cls: 0.0298  decode.d7.loss_mask: 0.1865  decode.d7.loss_dice: 0.2184  decode.d8.loss_cls: 0.0264  decode.d8.loss_mask: 0.1864  decode.d8.loss_dice: 0.2162
08/06 10:21:22 - mmengine - INFO - Iter(train) [ 58500/320000]  base_lr: 8.3386e-05 lr: 8.3386e-06  eta: 1 day, 11:48:23  time: 0.4964  data_time: 0.0114  memory: 5928  grad_norm: 58.2187  loss: 5.9160  decode.loss_cls: 0.0522  decode.loss_mask: 0.1857  decode.loss_dice: 0.2421  decode.d0.loss_cls: 0.9739  decode.d0.loss_mask: 0.1856  decode.d0.loss_dice: 0.2603  decode.d1.loss_cls: 0.0743  decode.d1.loss_mask: 0.1861  decode.d1.loss_dice: 0.2489  decode.d2.loss_cls: 0.0722  decode.d2.loss_mask: 0.1861  decode.d2.loss_dice: 0.2499  decode.d3.loss_cls: 0.0527  decode.d3.loss_mask: 0.1862  decode.d3.loss_dice: 0.2566  decode.d4.loss_cls: 0.0717  decode.d4.loss_mask: 0.1874  decode.d4.loss_dice: 0.2545  decode.d5.loss_cls: 0.0650  decode.d5.loss_mask: 0.1874  decode.d5.loss_dice: 0.2518  decode.d6.loss_cls: 0.0542  decode.d6.loss_mask: 0.1848  decode.d6.loss_dice: 0.2521  decode.d7.loss_cls: 0.0526  decode.d7.loss_mask: 0.1869  decode.d7.loss_dice: 0.2533  decode.d8.loss_cls: 0.0676  decode.d8.loss_mask: 0.1873  decode.d8.loss_dice: 0.2467
08/06 10:21:47 - mmengine - INFO - Iter(train) [ 58550/320000]  base_lr: 8.3371e-05 lr: 8.3371e-06  eta: 1 day, 11:47:59  time: 0.4960  data_time: 0.0114  memory: 5894  grad_norm: 56.7491  loss: 6.4453  decode.loss_cls: 0.0742  decode.loss_mask: 0.2463  decode.loss_dice: 0.2571  decode.d0.loss_cls: 0.7792  decode.d0.loss_mask: 0.2577  decode.d0.loss_dice: 0.2857  decode.d1.loss_cls: 0.0967  decode.d1.loss_mask: 0.2506  decode.d1.loss_dice: 0.2545  decode.d2.loss_cls: 0.0897  decode.d2.loss_mask: 0.2498  decode.d2.loss_dice: 0.2665  decode.d3.loss_cls: 0.0382  decode.d3.loss_mask: 0.2477  decode.d3.loss_dice: 0.2652  decode.d4.loss_cls: 0.0287  decode.d4.loss_mask: 0.2482  decode.d4.loss_dice: 0.2664  decode.d5.loss_cls: 0.0313  decode.d5.loss_mask: 0.2513  decode.d5.loss_dice: 0.2658  decode.d6.loss_cls: 0.0433  decode.d6.loss_mask: 0.2492  decode.d6.loss_dice: 0.2659  decode.d7.loss_cls: 0.0756  decode.d7.loss_mask: 0.2476  decode.d7.loss_dice: 0.2668  decode.d8.loss_cls: 0.0369  decode.d8.loss_mask: 0.2477  decode.d8.loss_dice: 0.2615
08/06 10:22:12 - mmengine - INFO - Iter(train) [ 58600/320000]  base_lr: 8.3357e-05 lr: 8.3357e-06  eta: 1 day, 11:47:35  time: 0.4953  data_time: 0.0113  memory: 5894  grad_norm: 338.4896  loss: 8.9168  decode.loss_cls: 0.2520  decode.loss_mask: 0.2579  decode.loss_dice: 0.2779  decode.d0.loss_cls: 0.8683  decode.d0.loss_mask: 0.2796  decode.d0.loss_dice: 0.3234  decode.d1.loss_cls: 0.2809  decode.d1.loss_mask: 0.2662  decode.d1.loss_dice: 0.2821  decode.d2.loss_cls: 0.2701  decode.d2.loss_mask: 0.2613  decode.d2.loss_dice: 0.2718  decode.d3.loss_cls: 0.2669  decode.d3.loss_mask: 0.2674  decode.d3.loss_dice: 0.2873  decode.d4.loss_cls: 0.2968  decode.d4.loss_mask: 0.2646  decode.d4.loss_dice: 0.3061  decode.d5.loss_cls: 0.3147  decode.d5.loss_mask: 0.2600  decode.d5.loss_dice: 0.2864  decode.d6.loss_cls: 0.3069  decode.d6.loss_mask: 0.2559  decode.d6.loss_dice: 0.2968  decode.d7.loss_cls: 0.2527  decode.d7.loss_mask: 0.2568  decode.d7.loss_dice: 0.2900  decode.d8.loss_cls: 0.2756  decode.d8.loss_mask: 0.2593  decode.d8.loss_dice: 0.2814
08/06 10:22:37 - mmengine - INFO - Iter(train) [ 58650/320000]  base_lr: 8.3342e-05 lr: 8.3342e-06  eta: 1 day, 11:47:11  time: 0.4951  data_time: 0.0113  memory: 5909  grad_norm: 178.3709  loss: 10.4606  decode.loss_cls: 0.2545  decode.loss_mask: 0.3462  decode.loss_dice: 0.4133  decode.d0.loss_cls: 0.9785  decode.d0.loss_mask: 0.3641  decode.d0.loss_dice: 0.3960  decode.d1.loss_cls: 0.2688  decode.d1.loss_mask: 0.3523  decode.d1.loss_dice: 0.4088  decode.d2.loss_cls: 0.2212  decode.d2.loss_mask: 0.3428  decode.d2.loss_dice: 0.3925  decode.d3.loss_cls: 0.2332  decode.d3.loss_mask: 0.3419  decode.d3.loss_dice: 0.3790  decode.d4.loss_cls: 0.2292  decode.d4.loss_mask: 0.3421  decode.d4.loss_dice: 0.4073  decode.d5.loss_cls: 0.2027  decode.d5.loss_mask: 0.3449  decode.d5.loss_dice: 0.3769  decode.d6.loss_cls: 0.2407  decode.d6.loss_mask: 0.3341  decode.d6.loss_dice: 0.3813  decode.d7.loss_cls: 0.2393  decode.d7.loss_mask: 0.3391  decode.d7.loss_dice: 0.3970  decode.d8.loss_cls: 0.1703  decode.d8.loss_mask: 0.3406  decode.d8.loss_dice: 0.4221
08/06 10:23:01 - mmengine - INFO - Iter(train) [ 58700/320000]  base_lr: 8.3328e-05 lr: 8.3328e-06  eta: 1 day, 11:46:46  time: 0.4947  data_time: 0.0113  memory: 5894  grad_norm: 75.3610  loss: 6.2536  decode.loss_cls: 0.0809  decode.loss_mask: 0.2362  decode.loss_dice: 0.2223  decode.d0.loss_cls: 0.7476  decode.d0.loss_mask: 0.2378  decode.d0.loss_dice: 0.2251  decode.d1.loss_cls: 0.0860  decode.d1.loss_mask: 0.2365  decode.d1.loss_dice: 0.2475  decode.d2.loss_cls: 0.0861  decode.d2.loss_mask: 0.2348  decode.d2.loss_dice: 0.2278  decode.d3.loss_cls: 0.0785  decode.d3.loss_mask: 0.2356  decode.d3.loss_dice: 0.2272  decode.d4.loss_cls: 0.1513  decode.d4.loss_mask: 0.2381  decode.d4.loss_dice: 0.2214  decode.d5.loss_cls: 0.1081  decode.d5.loss_mask: 0.2362  decode.d5.loss_dice: 0.2174  decode.d6.loss_cls: 0.0768  decode.d6.loss_mask: 0.2357  decode.d6.loss_dice: 0.2209  decode.d7.loss_cls: 0.0967  decode.d7.loss_mask: 0.2405  decode.d7.loss_dice: 0.2233  decode.d8.loss_cls: 0.0825  decode.d8.loss_mask: 0.2357  decode.d8.loss_dice: 0.2590
08/06 10:23:26 - mmengine - INFO - Iter(train) [ 58750/320000]  base_lr: 8.3314e-05 lr: 8.3314e-06  eta: 1 day, 11:46:22  time: 0.4952  data_time: 0.0114  memory: 5894  grad_norm: 122.9730  loss: 8.0148  decode.loss_cls: 0.1608  decode.loss_mask: 0.2274  decode.loss_dice: 0.3123  decode.d0.loss_cls: 0.9014  decode.d0.loss_mask: 0.2296  decode.d0.loss_dice: 0.2786  decode.d1.loss_cls: 0.2031  decode.d1.loss_mask: 0.2293  decode.d1.loss_dice: 0.2784  decode.d2.loss_cls: 0.1853  decode.d2.loss_mask: 0.2285  decode.d2.loss_dice: 0.2952  decode.d3.loss_cls: 0.2346  decode.d3.loss_mask: 0.2272  decode.d3.loss_dice: 0.2905  decode.d4.loss_cls: 0.1925  decode.d4.loss_mask: 0.2279  decode.d4.loss_dice: 0.2854  decode.d5.loss_cls: 0.2208  decode.d5.loss_mask: 0.2293  decode.d5.loss_dice: 0.2796  decode.d6.loss_cls: 0.2373  decode.d6.loss_mask: 0.2291  decode.d6.loss_dice: 0.3056  decode.d7.loss_cls: 0.2527  decode.d7.loss_mask: 0.2264  decode.d7.loss_dice: 0.3208  decode.d8.loss_cls: 0.2170  decode.d8.loss_mask: 0.2281  decode.d8.loss_dice: 0.2803
08/06 10:23:51 - mmengine - INFO - Iter(train) [ 58800/320000]  base_lr: 8.3299e-05 lr: 8.3299e-06  eta: 1 day, 11:45:59  time: 0.4956  data_time: 0.0113  memory: 5878  grad_norm: 49.8436  loss: 6.1795  decode.loss_cls: 0.0584  decode.loss_mask: 0.2026  decode.loss_dice: 0.2444  decode.d0.loss_cls: 0.8491  decode.d0.loss_mask: 0.2100  decode.d0.loss_dice: 0.2707  decode.d1.loss_cls: 0.1599  decode.d1.loss_mask: 0.2085  decode.d1.loss_dice: 0.2794  decode.d2.loss_cls: 0.0841  decode.d2.loss_mask: 0.2059  decode.d2.loss_dice: 0.2604  decode.d3.loss_cls: 0.0394  decode.d3.loss_mask: 0.2069  decode.d3.loss_dice: 0.2968  decode.d4.loss_cls: 0.0400  decode.d4.loss_mask: 0.2040  decode.d4.loss_dice: 0.2660  decode.d5.loss_cls: 0.0760  decode.d5.loss_mask: 0.2071  decode.d5.loss_dice: 0.2575  decode.d6.loss_cls: 0.0262  decode.d6.loss_mask: 0.2051  decode.d6.loss_dice: 0.2802  decode.d7.loss_cls: 0.0247  decode.d7.loss_mask: 0.2060  decode.d7.loss_dice: 0.2846  decode.d8.loss_cls: 0.0489  decode.d8.loss_mask: 0.2045  decode.d8.loss_dice: 0.2723
08/06 10:24:16 - mmengine - INFO - Iter(train) [ 58850/320000]  base_lr: 8.3285e-05 lr: 8.3285e-06  eta: 1 day, 11:45:35  time: 0.4953  data_time: 0.0112  memory: 5874  grad_norm: 352.2620  loss: 6.3306  decode.loss_cls: 0.0434  decode.loss_mask: 0.2443  decode.loss_dice: 0.2533  decode.d0.loss_cls: 0.8579  decode.d0.loss_mask: 0.2453  decode.d0.loss_dice: 0.2535  decode.d1.loss_cls: 0.0969  decode.d1.loss_mask: 0.2364  decode.d1.loss_dice: 0.2491  decode.d2.loss_cls: 0.0195  decode.d2.loss_mask: 0.2484  decode.d2.loss_dice: 0.2519  decode.d3.loss_cls: 0.0856  decode.d3.loss_mask: 0.2380  decode.d3.loss_dice: 0.2480  decode.d4.loss_cls: 0.0883  decode.d4.loss_mask: 0.2356  decode.d4.loss_dice: 0.2511  decode.d5.loss_cls: 0.0759  decode.d5.loss_mask: 0.2430  decode.d5.loss_dice: 0.2446  decode.d6.loss_cls: 0.0721  decode.d6.loss_mask: 0.2399  decode.d6.loss_dice: 0.2496  decode.d7.loss_cls: 0.0481  decode.d7.loss_mask: 0.2381  decode.d7.loss_dice: 0.2481  decode.d8.loss_cls: 0.0380  decode.d8.loss_mask: 0.2422  decode.d8.loss_dice: 0.2447
08/06 10:24:41 - mmengine - INFO - Iter(train) [ 58900/320000]  base_lr: 8.3271e-05 lr: 8.3271e-06  eta: 1 day, 11:45:10  time: 0.4949  data_time: 0.0111  memory: 5911  grad_norm: 91.3702  loss: 7.9623  decode.loss_cls: 0.1534  decode.loss_mask: 0.2262  decode.loss_dice: 0.2748  decode.d0.loss_cls: 1.0352  decode.d0.loss_mask: 0.2274  decode.d0.loss_dice: 0.3144  decode.d1.loss_cls: 0.2169  decode.d1.loss_mask: 0.2288  decode.d1.loss_dice: 0.2868  decode.d2.loss_cls: 0.2030  decode.d2.loss_mask: 0.2256  decode.d2.loss_dice: 0.2721  decode.d3.loss_cls: 0.2328  decode.d3.loss_mask: 0.2298  decode.d3.loss_dice: 0.2682  decode.d4.loss_cls: 0.1876  decode.d4.loss_mask: 0.2293  decode.d4.loss_dice: 0.2927  decode.d5.loss_cls: 0.1620  decode.d5.loss_mask: 0.2274  decode.d5.loss_dice: 0.2860  decode.d6.loss_cls: 0.2380  decode.d6.loss_mask: 0.2265  decode.d6.loss_dice: 0.2862  decode.d7.loss_cls: 0.1864  decode.d7.loss_mask: 0.2251  decode.d7.loss_dice: 0.2748  decode.d8.loss_cls: 0.2249  decode.d8.loss_mask: 0.2274  decode.d8.loss_dice: 0.2926
08/06 10:25:05 - mmengine - INFO - Iter(train) [ 58950/320000]  base_lr: 8.3256e-05 lr: 8.3256e-06  eta: 1 day, 11:44:46  time: 0.4952  data_time: 0.0112  memory: 5890  grad_norm: 64.5603  loss: 6.7120  decode.loss_cls: 0.1386  decode.loss_mask: 0.1787  decode.loss_dice: 0.3024  decode.d0.loss_cls: 0.8431  decode.d0.loss_mask: 0.1781  decode.d0.loss_dice: 0.2901  decode.d1.loss_cls: 0.1692  decode.d1.loss_mask: 0.1755  decode.d1.loss_dice: 0.2724  decode.d2.loss_cls: 0.1282  decode.d2.loss_mask: 0.1754  decode.d2.loss_dice: 0.2805  decode.d3.loss_cls: 0.1258  decode.d3.loss_mask: 0.1756  decode.d3.loss_dice: 0.2748  decode.d4.loss_cls: 0.1166  decode.d4.loss_mask: 0.1736  decode.d4.loss_dice: 0.2720  decode.d5.loss_cls: 0.1323  decode.d5.loss_mask: 0.1758  decode.d5.loss_dice: 0.3015  decode.d6.loss_cls: 0.1004  decode.d6.loss_mask: 0.1782  decode.d6.loss_dice: 0.3016  decode.d7.loss_cls: 0.1556  decode.d7.loss_mask: 0.1752  decode.d7.loss_dice: 0.2871  decode.d8.loss_cls: 0.1534  decode.d8.loss_mask: 0.1798  decode.d8.loss_dice: 0.3001
08/06 10:25:30 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 10:25:30 - mmengine - INFO - Iter(train) [ 59000/320000]  base_lr: 8.3242e-05 lr: 8.3242e-06  eta: 1 day, 11:44:22  time: 0.4959  data_time: 0.0113  memory: 5911  grad_norm: 89.0489  loss: 7.2107  decode.loss_cls: 0.1289  decode.loss_mask: 0.2318  decode.loss_dice: 0.2587  decode.d0.loss_cls: 1.0149  decode.d0.loss_mask: 0.2325  decode.d0.loss_dice: 0.2578  decode.d1.loss_cls: 0.1936  decode.d1.loss_mask: 0.2352  decode.d1.loss_dice: 0.2475  decode.d2.loss_cls: 0.1495  decode.d2.loss_mask: 0.2351  decode.d2.loss_dice: 0.2489  decode.d3.loss_cls: 0.1525  decode.d3.loss_mask: 0.2299  decode.d3.loss_dice: 0.2511  decode.d4.loss_cls: 0.1493  decode.d4.loss_mask: 0.2322  decode.d4.loss_dice: 0.2454  decode.d5.loss_cls: 0.1533  decode.d5.loss_mask: 0.2334  decode.d5.loss_dice: 0.2481  decode.d6.loss_cls: 0.1594  decode.d6.loss_mask: 0.2282  decode.d6.loss_dice: 0.2463  decode.d7.loss_cls: 0.1346  decode.d7.loss_mask: 0.2319  decode.d7.loss_dice: 0.2475  decode.d8.loss_cls: 0.1579  decode.d8.loss_mask: 0.2294  decode.d8.loss_dice: 0.2461
08/06 10:25:55 - mmengine - INFO - Iter(train) [ 59050/320000]  base_lr: 8.3228e-05 lr: 8.3228e-06  eta: 1 day, 11:43:58  time: 0.4946  data_time: 0.0113  memory: 5894  grad_norm: 241.6439  loss: 6.4439  decode.loss_cls: 0.1668  decode.loss_mask: 0.1941  decode.loss_dice: 0.2468  decode.d0.loss_cls: 0.8350  decode.d0.loss_mask: 0.1980  decode.d0.loss_dice: 0.2768  decode.d1.loss_cls: 0.1252  decode.d1.loss_mask: 0.1980  decode.d1.loss_dice: 0.2669  decode.d2.loss_cls: 0.1452  decode.d2.loss_mask: 0.1959  decode.d2.loss_dice: 0.2550  decode.d3.loss_cls: 0.1026  decode.d3.loss_mask: 0.1979  decode.d3.loss_dice: 0.2580  decode.d4.loss_cls: 0.0917  decode.d4.loss_mask: 0.1961  decode.d4.loss_dice: 0.2598  decode.d5.loss_cls: 0.1589  decode.d5.loss_mask: 0.1910  decode.d5.loss_dice: 0.2460  decode.d6.loss_cls: 0.0844  decode.d6.loss_mask: 0.1981  decode.d6.loss_dice: 0.2578  decode.d7.loss_cls: 0.0841  decode.d7.loss_mask: 0.1990  decode.d7.loss_dice: 0.2612  decode.d8.loss_cls: 0.0956  decode.d8.loss_mask: 0.1982  decode.d8.loss_dice: 0.2598
08/06 10:26:20 - mmengine - INFO - Iter(train) [ 59100/320000]  base_lr: 8.3213e-05 lr: 8.3213e-06  eta: 1 day, 11:43:34  time: 0.4956  data_time: 0.0113  memory: 5894  grad_norm: 172.7658  loss: 8.5004  decode.loss_cls: 0.2300  decode.loss_mask: 0.2748  decode.loss_dice: 0.3199  decode.d0.loss_cls: 0.9339  decode.d0.loss_mask: 0.2970  decode.d0.loss_dice: 0.3111  decode.d1.loss_cls: 0.1930  decode.d1.loss_mask: 0.2852  decode.d1.loss_dice: 0.3240  decode.d2.loss_cls: 0.1061  decode.d2.loss_mask: 0.2818  decode.d2.loss_dice: 0.3364  decode.d3.loss_cls: 0.1772  decode.d3.loss_mask: 0.2882  decode.d3.loss_dice: 0.3359  decode.d4.loss_cls: 0.1496  decode.d4.loss_mask: 0.2883  decode.d4.loss_dice: 0.3381  decode.d5.loss_cls: 0.1572  decode.d5.loss_mask: 0.2837  decode.d5.loss_dice: 0.3067  decode.d6.loss_cls: 0.1305  decode.d6.loss_mask: 0.2826  decode.d6.loss_dice: 0.3108  decode.d7.loss_cls: 0.2374  decode.d7.loss_mask: 0.2759  decode.d7.loss_dice: 0.2971  decode.d8.loss_cls: 0.1986  decode.d8.loss_mask: 0.2765  decode.d8.loss_dice: 0.2729
08/06 10:26:44 - mmengine - INFO - Iter(train) [ 59150/320000]  base_lr: 8.3199e-05 lr: 8.3199e-06  eta: 1 day, 11:43:10  time: 0.4951  data_time: 0.0111  memory: 5909  grad_norm: 155.2808  loss: 8.4903  decode.loss_cls: 0.1982  decode.loss_mask: 0.2669  decode.loss_dice: 0.3277  decode.d0.loss_cls: 0.9144  decode.d0.loss_mask: 0.2754  decode.d0.loss_dice: 0.3154  decode.d1.loss_cls: 0.2244  decode.d1.loss_mask: 0.2676  decode.d1.loss_dice: 0.3094  decode.d2.loss_cls: 0.1692  decode.d2.loss_mask: 0.2621  decode.d2.loss_dice: 0.3129  decode.d3.loss_cls: 0.2032  decode.d3.loss_mask: 0.2690  decode.d3.loss_dice: 0.3105  decode.d4.loss_cls: 0.1831  decode.d4.loss_mask: 0.2633  decode.d4.loss_dice: 0.3135  decode.d5.loss_cls: 0.2290  decode.d5.loss_mask: 0.2599  decode.d5.loss_dice: 0.3114  decode.d6.loss_cls: 0.1964  decode.d6.loss_mask: 0.2646  decode.d6.loss_dice: 0.3122  decode.d7.loss_cls: 0.1941  decode.d7.loss_mask: 0.2656  decode.d7.loss_dice: 0.3011  decode.d8.loss_cls: 0.1982  decode.d8.loss_mask: 0.2655  decode.d8.loss_dice: 0.3058
08/06 10:27:09 - mmengine - INFO - Iter(train) [ 59200/320000]  base_lr: 8.3185e-05 lr: 8.3185e-06  eta: 1 day, 11:42:46  time: 0.4958  data_time: 0.0114  memory: 5894  grad_norm: 86.9685  loss: 6.7417  decode.loss_cls: 0.1458  decode.loss_mask: 0.2202  decode.loss_dice: 0.2179  decode.d0.loss_cls: 0.9134  decode.d0.loss_mask: 0.2216  decode.d0.loss_dice: 0.2262  decode.d1.loss_cls: 0.1573  decode.d1.loss_mask: 0.2220  decode.d1.loss_dice: 0.2212  decode.d2.loss_cls: 0.1638  decode.d2.loss_mask: 0.2225  decode.d2.loss_dice: 0.2154  decode.d3.loss_cls: 0.1381  decode.d3.loss_mask: 0.2220  decode.d3.loss_dice: 0.2195  decode.d4.loss_cls: 0.1491  decode.d4.loss_mask: 0.2216  decode.d4.loss_dice: 0.2179  decode.d5.loss_cls: 0.1509  decode.d5.loss_mask: 0.2200  decode.d5.loss_dice: 0.2121  decode.d6.loss_cls: 0.1695  decode.d6.loss_mask: 0.2214  decode.d6.loss_dice: 0.2167  decode.d7.loss_cls: 0.1674  decode.d7.loss_mask: 0.2223  decode.d7.loss_dice: 0.2181  decode.d8.loss_cls: 0.1895  decode.d8.loss_mask: 0.2203  decode.d8.loss_dice: 0.2182
08/06 10:27:34 - mmengine - INFO - Iter(train) [ 59250/320000]  base_lr: 8.3170e-05 lr: 8.3170e-06  eta: 1 day, 11:42:22  time: 0.4950  data_time: 0.0111  memory: 5909  grad_norm: 131.6119  loss: 6.5889  decode.loss_cls: 0.1175  decode.loss_mask: 0.2261  decode.loss_dice: 0.2314  decode.d0.loss_cls: 0.8762  decode.d0.loss_mask: 0.2297  decode.d0.loss_dice: 0.2443  decode.d1.loss_cls: 0.1235  decode.d1.loss_mask: 0.2318  decode.d1.loss_dice: 0.2361  decode.d2.loss_cls: 0.1321  decode.d2.loss_mask: 0.2276  decode.d2.loss_dice: 0.2397  decode.d3.loss_cls: 0.1230  decode.d3.loss_mask: 0.2263  decode.d3.loss_dice: 0.2285  decode.d4.loss_cls: 0.1361  decode.d4.loss_mask: 0.2272  decode.d4.loss_dice: 0.2362  decode.d5.loss_cls: 0.1114  decode.d5.loss_mask: 0.2266  decode.d5.loss_dice: 0.2338  decode.d6.loss_cls: 0.1114  decode.d6.loss_mask: 0.2274  decode.d6.loss_dice: 0.2364  decode.d7.loss_cls: 0.1193  decode.d7.loss_mask: 0.2245  decode.d7.loss_dice: 0.2322  decode.d8.loss_cls: 0.1088  decode.d8.loss_mask: 0.2257  decode.d8.loss_dice: 0.2382
08/06 10:27:59 - mmengine - INFO - Iter(train) [ 59300/320000]  base_lr: 8.3156e-05 lr: 8.3156e-06  eta: 1 day, 11:41:58  time: 0.4956  data_time: 0.0112  memory: 5874  grad_norm: 96.5965  loss: 7.8883  decode.loss_cls: 0.1765  decode.loss_mask: 0.2592  decode.loss_dice: 0.2785  decode.d0.loss_cls: 0.9001  decode.d0.loss_mask: 0.2647  decode.d0.loss_dice: 0.3035  decode.d1.loss_cls: 0.1756  decode.d1.loss_mask: 0.2684  decode.d1.loss_dice: 0.2896  decode.d2.loss_cls: 0.1588  decode.d2.loss_mask: 0.2612  decode.d2.loss_dice: 0.2784  decode.d3.loss_cls: 0.1553  decode.d3.loss_mask: 0.2655  decode.d3.loss_dice: 0.2828  decode.d4.loss_cls: 0.1537  decode.d4.loss_mask: 0.2612  decode.d4.loss_dice: 0.2792  decode.d5.loss_cls: 0.1979  decode.d5.loss_mask: 0.2630  decode.d5.loss_dice: 0.2772  decode.d6.loss_cls: 0.1605  decode.d6.loss_mask: 0.2624  decode.d6.loss_dice: 0.2806  decode.d7.loss_cls: 0.1783  decode.d7.loss_mask: 0.2618  decode.d7.loss_dice: 0.2800  decode.d8.loss_cls: 0.1745  decode.d8.loss_mask: 0.2583  decode.d8.loss_dice: 0.2817
08/06 10:28:24 - mmengine - INFO - Iter(train) [ 59350/320000]  base_lr: 8.3142e-05 lr: 8.3142e-06  eta: 1 day, 11:41:34  time: 0.4956  data_time: 0.0114  memory: 5894  grad_norm: 59.7347  loss: 6.8786  decode.loss_cls: 0.1157  decode.loss_mask: 0.2307  decode.loss_dice: 0.2530  decode.d0.loss_cls: 0.9290  decode.d0.loss_mask: 0.2308  decode.d0.loss_dice: 0.2886  decode.d1.loss_cls: 0.1156  decode.d1.loss_mask: 0.2334  decode.d1.loss_dice: 0.2564  decode.d2.loss_cls: 0.1079  decode.d2.loss_mask: 0.2358  decode.d2.loss_dice: 0.2520  decode.d3.loss_cls: 0.1091  decode.d3.loss_mask: 0.2330  decode.d3.loss_dice: 0.2610  decode.d4.loss_cls: 0.1253  decode.d4.loss_mask: 0.2313  decode.d4.loss_dice: 0.2717  decode.d5.loss_cls: 0.1007  decode.d5.loss_mask: 0.2339  decode.d5.loss_dice: 0.2744  decode.d6.loss_cls: 0.1009  decode.d6.loss_mask: 0.2342  decode.d6.loss_dice: 0.2920  decode.d7.loss_cls: 0.0970  decode.d7.loss_mask: 0.2322  decode.d7.loss_dice: 0.2584  decode.d8.loss_cls: 0.0908  decode.d8.loss_mask: 0.2294  decode.d8.loss_dice: 0.2545
08/06 10:28:49 - mmengine - INFO - Iter(train) [ 59400/320000]  base_lr: 8.3127e-05 lr: 8.3127e-06  eta: 1 day, 11:41:10  time: 0.4941  data_time: 0.0113  memory: 5911  grad_norm: 69.4629  loss: 7.2785  decode.loss_cls: 0.0412  decode.loss_mask: 0.2683  decode.loss_dice: 0.3500  decode.d0.loss_cls: 0.7673  decode.d0.loss_mask: 0.2675  decode.d0.loss_dice: 0.3186  decode.d1.loss_cls: 0.0722  decode.d1.loss_mask: 0.2660  decode.d1.loss_dice: 0.3417  decode.d2.loss_cls: 0.0261  decode.d2.loss_mask: 0.2652  decode.d2.loss_dice: 0.3461  decode.d3.loss_cls: 0.0189  decode.d3.loss_mask: 0.2678  decode.d3.loss_dice: 0.3576  decode.d4.loss_cls: 0.0228  decode.d4.loss_mask: 0.2683  decode.d4.loss_dice: 0.3529  decode.d5.loss_cls: 0.0260  decode.d5.loss_mask: 0.2696  decode.d5.loss_dice: 0.3575  decode.d6.loss_cls: 0.0875  decode.d6.loss_mask: 0.2677  decode.d6.loss_dice: 0.3306  decode.d7.loss_cls: 0.1118  decode.d7.loss_mask: 0.2684  decode.d7.loss_dice: 0.3094  decode.d8.loss_cls: 0.0162  decode.d8.loss_mask: 0.2652  decode.d8.loss_dice: 0.3500
08/06 10:29:13 - mmengine - INFO - Iter(train) [ 59450/320000]  base_lr: 8.3113e-05 lr: 8.3113e-06  eta: 1 day, 11:40:46  time: 0.4943  data_time: 0.0110  memory: 5894  grad_norm: 178.8950  loss: 7.3026  decode.loss_cls: 0.1334  decode.loss_mask: 0.2051  decode.loss_dice: 0.2942  decode.d0.loss_cls: 0.9473  decode.d0.loss_mask: 0.2221  decode.d0.loss_dice: 0.3367  decode.d1.loss_cls: 0.1484  decode.d1.loss_mask: 0.2069  decode.d1.loss_dice: 0.3208  decode.d2.loss_cls: 0.1008  decode.d2.loss_mask: 0.2039  decode.d2.loss_dice: 0.3089  decode.d3.loss_cls: 0.0776  decode.d3.loss_mask: 0.2031  decode.d3.loss_dice: 0.3263  decode.d4.loss_cls: 0.1170  decode.d4.loss_mask: 0.2055  decode.d4.loss_dice: 0.3110  decode.d5.loss_cls: 0.1193  decode.d5.loss_mask: 0.2023  decode.d5.loss_dice: 0.3159  decode.d6.loss_cls: 0.1653  decode.d6.loss_mask: 0.2010  decode.d6.loss_dice: 0.2989  decode.d7.loss_cls: 0.1699  decode.d7.loss_mask: 0.2025  decode.d7.loss_dice: 0.2969  decode.d8.loss_cls: 0.1663  decode.d8.loss_mask: 0.2056  decode.d8.loss_dice: 0.2898
08/06 10:29:38 - mmengine - INFO - Iter(train) [ 59500/320000]  base_lr: 8.3099e-05 lr: 8.3099e-06  eta: 1 day, 11:40:22  time: 0.4951  data_time: 0.0112  memory: 5874  grad_norm: 59.8187  loss: 5.8980  decode.loss_cls: 0.0206  decode.loss_mask: 0.2512  decode.loss_dice: 0.2229  decode.d0.loss_cls: 0.7932  decode.d0.loss_mask: 0.2572  decode.d0.loss_dice: 0.2221  decode.d1.loss_cls: 0.0497  decode.d1.loss_mask: 0.2500  decode.d1.loss_dice: 0.2312  decode.d2.loss_cls: 0.0686  decode.d2.loss_mask: 0.2543  decode.d2.loss_dice: 0.2266  decode.d3.loss_cls: 0.0251  decode.d3.loss_mask: 0.2537  decode.d3.loss_dice: 0.2406  decode.d4.loss_cls: 0.0438  decode.d4.loss_mask: 0.2498  decode.d4.loss_dice: 0.2204  decode.d5.loss_cls: 0.0308  decode.d5.loss_mask: 0.2522  decode.d5.loss_dice: 0.2292  decode.d6.loss_cls: 0.0202  decode.d6.loss_mask: 0.2554  decode.d6.loss_dice: 0.2299  decode.d7.loss_cls: 0.0162  decode.d7.loss_mask: 0.2501  decode.d7.loss_dice: 0.2327  decode.d8.loss_cls: 0.0179  decode.d8.loss_mask: 0.2533  decode.d8.loss_dice: 0.2292
08/06 10:30:03 - mmengine - INFO - Iter(train) [ 59550/320000]  base_lr: 8.3084e-05 lr: 8.3084e-06  eta: 1 day, 11:39:58  time: 0.4957  data_time: 0.0111  memory: 5891  grad_norm: 74.0761  loss: 6.9107  decode.loss_cls: 0.1491  decode.loss_mask: 0.2196  decode.loss_dice: 0.2561  decode.d0.loss_cls: 0.8748  decode.d0.loss_mask: 0.2278  decode.d0.loss_dice: 0.2422  decode.d1.loss_cls: 0.1390  decode.d1.loss_mask: 0.2188  decode.d1.loss_dice: 0.2582  decode.d2.loss_cls: 0.1229  decode.d2.loss_mask: 0.2146  decode.d2.loss_dice: 0.2360  decode.d3.loss_cls: 0.1416  decode.d3.loss_mask: 0.2188  decode.d3.loss_dice: 0.2529  decode.d4.loss_cls: 0.1508  decode.d4.loss_mask: 0.2188  decode.d4.loss_dice: 0.2338  decode.d5.loss_cls: 0.1908  decode.d5.loss_mask: 0.2166  decode.d5.loss_dice: 0.2403  decode.d6.loss_cls: 0.2034  decode.d6.loss_mask: 0.2182  decode.d6.loss_dice: 0.2439  decode.d7.loss_cls: 0.1179  decode.d7.loss_mask: 0.2181  decode.d7.loss_dice: 0.2507  decode.d8.loss_cls: 0.1763  decode.d8.loss_mask: 0.2184  decode.d8.loss_dice: 0.2400
08/06 10:30:28 - mmengine - INFO - Iter(train) [ 59600/320000]  base_lr: 8.3070e-05 lr: 8.3070e-06  eta: 1 day, 11:39:34  time: 0.4954  data_time: 0.0113  memory: 5876  grad_norm: 79.2084  loss: 6.3293  decode.loss_cls: 0.1280  decode.loss_mask: 0.2140  decode.loss_dice: 0.2391  decode.d0.loss_cls: 0.8756  decode.d0.loss_mask: 0.2140  decode.d0.loss_dice: 0.2473  decode.d1.loss_cls: 0.0610  decode.d1.loss_mask: 0.2135  decode.d1.loss_dice: 0.2364  decode.d2.loss_cls: 0.0682  decode.d2.loss_mask: 0.2127  decode.d2.loss_dice: 0.2389  decode.d3.loss_cls: 0.0895  decode.d3.loss_mask: 0.2115  decode.d3.loss_dice: 0.2541  decode.d4.loss_cls: 0.0847  decode.d4.loss_mask: 0.2080  decode.d4.loss_dice: 0.2464  decode.d5.loss_cls: 0.0859  decode.d5.loss_mask: 0.2117  decode.d5.loss_dice: 0.2472  decode.d6.loss_cls: 0.1183  decode.d6.loss_mask: 0.2093  decode.d6.loss_dice: 0.2427  decode.d7.loss_cls: 0.1072  decode.d7.loss_mask: 0.2104  decode.d7.loss_dice: 0.2391  decode.d8.loss_cls: 0.1479  decode.d8.loss_mask: 0.2133  decode.d8.loss_dice: 0.2536
08/06 10:30:52 - mmengine - INFO - Iter(train) [ 59650/320000]  base_lr: 8.3055e-05 lr: 8.3055e-06  eta: 1 day, 11:39:10  time: 0.4942  data_time: 0.0110  memory: 5928  grad_norm: 108.8191  loss: 6.5358  decode.loss_cls: 0.0792  decode.loss_mask: 0.2482  decode.loss_dice: 0.2429  decode.d0.loss_cls: 0.7909  decode.d0.loss_mask: 0.2589  decode.d0.loss_dice: 0.2631  decode.d1.loss_cls: 0.1174  decode.d1.loss_mask: 0.2508  decode.d1.loss_dice: 0.2411  decode.d2.loss_cls: 0.0796  decode.d2.loss_mask: 0.2501  decode.d2.loss_dice: 0.2437  decode.d3.loss_cls: 0.0784  decode.d3.loss_mask: 0.2484  decode.d3.loss_dice: 0.2496  decode.d4.loss_cls: 0.0958  decode.d4.loss_mask: 0.2496  decode.d4.loss_dice: 0.2402  decode.d5.loss_cls: 0.0840  decode.d5.loss_mask: 0.2488  decode.d5.loss_dice: 0.2441  decode.d6.loss_cls: 0.0664  decode.d6.loss_mask: 0.2519  decode.d6.loss_dice: 0.2317  decode.d7.loss_cls: 0.0719  decode.d7.loss_mask: 0.2552  decode.d7.loss_dice: 0.2462  decode.d8.loss_cls: 0.0929  decode.d8.loss_mask: 0.2524  decode.d8.loss_dice: 0.2625
08/06 10:31:17 - mmengine - INFO - Iter(train) [ 59700/320000]  base_lr: 8.3041e-05 lr: 8.3041e-06  eta: 1 day, 11:38:46  time: 0.4952  data_time: 0.0113  memory: 5878  grad_norm: 88.6096  loss: 5.5249  decode.loss_cls: 0.0076  decode.loss_mask: 0.2436  decode.loss_dice: 0.2225  decode.d0.loss_cls: 0.7774  decode.d0.loss_mask: 0.2492  decode.d0.loss_dice: 0.2195  decode.d1.loss_cls: 0.0176  decode.d1.loss_mask: 0.2480  decode.d1.loss_dice: 0.2200  decode.d2.loss_cls: 0.0096  decode.d2.loss_mask: 0.2437  decode.d2.loss_dice: 0.2213  decode.d3.loss_cls: 0.0153  decode.d3.loss_mask: 0.2434  decode.d3.loss_dice: 0.2202  decode.d4.loss_cls: 0.0082  decode.d4.loss_mask: 0.2489  decode.d4.loss_dice: 0.2241  decode.d5.loss_cls: 0.0064  decode.d5.loss_mask: 0.2436  decode.d5.loss_dice: 0.2150  decode.d6.loss_cls: 0.0070  decode.d6.loss_mask: 0.2458  decode.d6.loss_dice: 0.2216  decode.d7.loss_cls: 0.0055  decode.d7.loss_mask: 0.2464  decode.d7.loss_dice: 0.2237  decode.d8.loss_cls: 0.0060  decode.d8.loss_mask: 0.2426  decode.d8.loss_dice: 0.2212
08/06 10:31:42 - mmengine - INFO - Iter(train) [ 59750/320000]  base_lr: 8.3027e-05 lr: 8.3027e-06  eta: 1 day, 11:38:22  time: 0.4953  data_time: 0.0112  memory: 5895  grad_norm: 61.8940  loss: 6.2989  decode.loss_cls: 0.0905  decode.loss_mask: 0.2124  decode.loss_dice: 0.2412  decode.d0.loss_cls: 1.0397  decode.d0.loss_mask: 0.2060  decode.d0.loss_dice: 0.2221  decode.d1.loss_cls: 0.1432  decode.d1.loss_mask: 0.2061  decode.d1.loss_dice: 0.2295  decode.d2.loss_cls: 0.0853  decode.d2.loss_mask: 0.2053  decode.d2.loss_dice: 0.2260  decode.d3.loss_cls: 0.1296  decode.d3.loss_mask: 0.2062  decode.d3.loss_dice: 0.2258  decode.d4.loss_cls: 0.0881  decode.d4.loss_mask: 0.2092  decode.d4.loss_dice: 0.2294  decode.d5.loss_cls: 0.1163  decode.d5.loss_mask: 0.2070  decode.d5.loss_dice: 0.2219  decode.d6.loss_cls: 0.1107  decode.d6.loss_mask: 0.2080  decode.d6.loss_dice: 0.2311  decode.d7.loss_cls: 0.0599  decode.d7.loss_mask: 0.2075  decode.d7.loss_dice: 0.2353  decode.d8.loss_cls: 0.0681  decode.d8.loss_mask: 0.2071  decode.d8.loss_dice: 0.2305
08/06 10:32:07 - mmengine - INFO - Iter(train) [ 59800/320000]  base_lr: 8.3012e-05 lr: 8.3012e-06  eta: 1 day, 11:37:57  time: 0.4959  data_time: 0.0113  memory: 5894  grad_norm: 126.0857  loss: 7.7571  decode.loss_cls: 0.1703  decode.loss_mask: 0.2350  decode.loss_dice: 0.2658  decode.d0.loss_cls: 0.9003  decode.d0.loss_mask: 0.2426  decode.d0.loss_dice: 0.2559  decode.d1.loss_cls: 0.2012  decode.d1.loss_mask: 0.2333  decode.d1.loss_dice: 0.2733  decode.d2.loss_cls: 0.2381  decode.d2.loss_mask: 0.2401  decode.d2.loss_dice: 0.2829  decode.d3.loss_cls: 0.2684  decode.d3.loss_mask: 0.2345  decode.d3.loss_dice: 0.2704  decode.d4.loss_cls: 0.2048  decode.d4.loss_mask: 0.2417  decode.d4.loss_dice: 0.2757  decode.d5.loss_cls: 0.1505  decode.d5.loss_mask: 0.2356  decode.d5.loss_dice: 0.2651  decode.d6.loss_cls: 0.1879  decode.d6.loss_mask: 0.2325  decode.d6.loss_dice: 0.2637  decode.d7.loss_cls: 0.1897  decode.d7.loss_mask: 0.2317  decode.d7.loss_dice: 0.2566  decode.d8.loss_cls: 0.2055  decode.d8.loss_mask: 0.2339  decode.d8.loss_dice: 0.2700
08/06 10:32:32 - mmengine - INFO - Iter(train) [ 59850/320000]  base_lr: 8.2998e-05 lr: 8.2998e-06  eta: 1 day, 11:37:33  time: 0.4941  data_time: 0.0112  memory: 5911  grad_norm: 44.9999  loss: 5.9704  decode.loss_cls: 0.0486  decode.loss_mask: 0.2011  decode.loss_dice: 0.2510  decode.d0.loss_cls: 0.8233  decode.d0.loss_mask: 0.2106  decode.d0.loss_dice: 0.2656  decode.d1.loss_cls: 0.0996  decode.d1.loss_mask: 0.2017  decode.d1.loss_dice: 0.2705  decode.d2.loss_cls: 0.1073  decode.d2.loss_mask: 0.2006  decode.d2.loss_dice: 0.2590  decode.d3.loss_cls: 0.0446  decode.d3.loss_mask: 0.2037  decode.d3.loss_dice: 0.2494  decode.d4.loss_cls: 0.0701  decode.d4.loss_mask: 0.2066  decode.d4.loss_dice: 0.2195  decode.d5.loss_cls: 0.0395  decode.d5.loss_mask: 0.2045  decode.d5.loss_dice: 0.2533  decode.d6.loss_cls: 0.0484  decode.d6.loss_mask: 0.2036  decode.d6.loss_dice: 0.2569  decode.d7.loss_cls: 0.0730  decode.d7.loss_mask: 0.2014  decode.d7.loss_dice: 0.2215  decode.d8.loss_cls: 0.0866  decode.d8.loss_mask: 0.2003  decode.d8.loss_dice: 0.2485
08/06 10:32:56 - mmengine - INFO - Iter(train) [ 59900/320000]  base_lr: 8.2984e-05 lr: 8.2984e-06  eta: 1 day, 11:37:10  time: 0.4962  data_time: 0.0112  memory: 5891  grad_norm: 78.5397  loss: 6.3563  decode.loss_cls: 0.0134  decode.loss_mask: 0.2615  decode.loss_dice: 0.2573  decode.d0.loss_cls: 0.8720  decode.d0.loss_mask: 0.2684  decode.d0.loss_dice: 0.2562  decode.d1.loss_cls: 0.0405  decode.d1.loss_mask: 0.2636  decode.d1.loss_dice: 0.2610  decode.d2.loss_cls: 0.0192  decode.d2.loss_mask: 0.2643  decode.d2.loss_dice: 0.2648  decode.d3.loss_cls: 0.0762  decode.d3.loss_mask: 0.2577  decode.d3.loss_dice: 0.2475  decode.d4.loss_cls: 0.0891  decode.d4.loss_mask: 0.2609  decode.d4.loss_dice: 0.2599  decode.d5.loss_cls: 0.0122  decode.d5.loss_mask: 0.2576  decode.d5.loss_dice: 0.2512  decode.d6.loss_cls: 0.0099  decode.d6.loss_mask: 0.2588  decode.d6.loss_dice: 0.2594  decode.d7.loss_cls: 0.0169  decode.d7.loss_mask: 0.2599  decode.d7.loss_dice: 0.2611  decode.d8.loss_cls: 0.0124  decode.d8.loss_mask: 0.2604  decode.d8.loss_dice: 0.2630
08/06 10:33:21 - mmengine - INFO - Iter(train) [ 59950/320000]  base_lr: 8.2969e-05 lr: 8.2969e-06  eta: 1 day, 11:36:46  time: 0.4948  data_time: 0.0114  memory: 5894  grad_norm: 94.2956  loss: 6.6630  decode.loss_cls: 0.1401  decode.loss_mask: 0.2376  decode.loss_dice: 0.2462  decode.d0.loss_cls: 0.6801  decode.d0.loss_mask: 0.2415  decode.d0.loss_dice: 0.2762  decode.d1.loss_cls: 0.1344  decode.d1.loss_mask: 0.2365  decode.d1.loss_dice: 0.2482  decode.d2.loss_cls: 0.1182  decode.d2.loss_mask: 0.2373  decode.d2.loss_dice: 0.2593  decode.d3.loss_cls: 0.1329  decode.d3.loss_mask: 0.2363  decode.d3.loss_dice: 0.2501  decode.d4.loss_cls: 0.0885  decode.d4.loss_mask: 0.2374  decode.d4.loss_dice: 0.2459  decode.d5.loss_cls: 0.1620  decode.d5.loss_mask: 0.2393  decode.d5.loss_dice: 0.2418  decode.d6.loss_cls: 0.1417  decode.d6.loss_mask: 0.2357  decode.d6.loss_dice: 0.2380  decode.d7.loss_cls: 0.0876  decode.d7.loss_mask: 0.2376  decode.d7.loss_dice: 0.2415  decode.d8.loss_cls: 0.1096  decode.d8.loss_mask: 0.2371  decode.d8.loss_dice: 0.2441
08/06 10:33:46 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 10:33:46 - mmengine - INFO - Iter(train) [ 60000/320000]  base_lr: 8.2955e-05 lr: 8.2955e-06  eta: 1 day, 11:36:22  time: 0.4960  data_time: 0.0113  memory: 5894  grad_norm: 70.5633  loss: 6.2173  decode.loss_cls: 0.0037  decode.loss_mask: 0.2593  decode.loss_dice: 0.2541  decode.d0.loss_cls: 0.8285  decode.d0.loss_mask: 0.2620  decode.d0.loss_dice: 0.2616  decode.d1.loss_cls: 0.0310  decode.d1.loss_mask: 0.2565  decode.d1.loss_dice: 0.2615  decode.d2.loss_cls: 0.0480  decode.d2.loss_mask: 0.2614  decode.d2.loss_dice: 0.2688  decode.d3.loss_cls: 0.0327  decode.d3.loss_mask: 0.2600  decode.d3.loss_dice: 0.2645  decode.d4.loss_cls: 0.0192  decode.d4.loss_mask: 0.2619  decode.d4.loss_dice: 0.2662  decode.d5.loss_cls: 0.0226  decode.d5.loss_mask: 0.2598  decode.d5.loss_dice: 0.2579  decode.d6.loss_cls: 0.0159  decode.d6.loss_mask: 0.2622  decode.d6.loss_dice: 0.2616  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.2568  decode.d7.loss_dice: 0.2594  decode.d8.loss_cls: 0.0038  decode.d8.loss_mask: 0.2589  decode.d8.loss_dice: 0.2535
08/06 10:34:11 - mmengine - INFO - Iter(train) [ 60050/320000]  base_lr: 8.2941e-05 lr: 8.2941e-06  eta: 1 day, 11:35:57  time: 0.4956  data_time: 0.0111  memory: 5913  grad_norm: 111.2463  loss: 6.3524  decode.loss_cls: 0.1439  decode.loss_mask: 0.2056  decode.loss_dice: 0.2530  decode.d0.loss_cls: 0.9106  decode.d0.loss_mask: 0.2114  decode.d0.loss_dice: 0.2329  decode.d1.loss_cls: 0.1226  decode.d1.loss_mask: 0.1986  decode.d1.loss_dice: 0.2300  decode.d2.loss_cls: 0.1230  decode.d2.loss_mask: 0.1974  decode.d2.loss_dice: 0.2188  decode.d3.loss_cls: 0.0936  decode.d3.loss_mask: 0.2029  decode.d3.loss_dice: 0.2399  decode.d4.loss_cls: 0.0840  decode.d4.loss_mask: 0.2014  decode.d4.loss_dice: 0.2442  decode.d5.loss_cls: 0.1091  decode.d5.loss_mask: 0.2018  decode.d5.loss_dice: 0.2355  decode.d6.loss_cls: 0.1318  decode.d6.loss_mask: 0.2034  decode.d6.loss_dice: 0.2372  decode.d7.loss_cls: 0.1149  decode.d7.loss_mask: 0.2022  decode.d7.loss_dice: 0.2439  decode.d8.loss_cls: 0.1075  decode.d8.loss_mask: 0.2030  decode.d8.loss_dice: 0.2481
08/06 10:34:36 - mmengine - INFO - Iter(train) [ 60100/320000]  base_lr: 8.2926e-05 lr: 8.2926e-06  eta: 1 day, 11:35:33  time: 0.4960  data_time: 0.0113  memory: 5928  grad_norm: 78.3413  loss: 6.7334  decode.loss_cls: 0.1537  decode.loss_mask: 0.1876  decode.loss_dice: 0.2377  decode.d0.loss_cls: 0.9103  decode.d0.loss_mask: 0.1905  decode.d0.loss_dice: 0.2477  decode.d1.loss_cls: 0.1940  decode.d1.loss_mask: 0.1897  decode.d1.loss_dice: 0.2463  decode.d2.loss_cls: 0.1527  decode.d2.loss_mask: 0.1884  decode.d2.loss_dice: 0.2501  decode.d3.loss_cls: 0.1224  decode.d3.loss_mask: 0.1899  decode.d3.loss_dice: 0.2480  decode.d4.loss_cls: 0.1287  decode.d4.loss_mask: 0.1865  decode.d4.loss_dice: 0.2407  decode.d5.loss_cls: 0.1793  decode.d5.loss_mask: 0.1852  decode.d5.loss_dice: 0.2394  decode.d6.loss_cls: 0.2088  decode.d6.loss_mask: 0.1860  decode.d6.loss_dice: 0.2458  decode.d7.loss_cls: 0.2035  decode.d7.loss_mask: 0.1864  decode.d7.loss_dice: 0.2430  decode.d8.loss_cls: 0.1682  decode.d8.loss_mask: 0.1852  decode.d8.loss_dice: 0.2377
08/06 10:35:00 - mmengine - INFO - Iter(train) [ 60150/320000]  base_lr: 8.2912e-05 lr: 8.2912e-06  eta: 1 day, 11:35:09  time: 0.4965  data_time: 0.0115  memory: 5913  grad_norm: 140.0383  loss: 10.3464  decode.loss_cls: 0.3363  decode.loss_mask: 0.2878  decode.loss_dice: 0.3815  decode.d0.loss_cls: 0.9018  decode.d0.loss_mask: 0.2835  decode.d0.loss_dice: 0.4364  decode.d1.loss_cls: 0.3258  decode.d1.loss_mask: 0.2874  decode.d1.loss_dice: 0.3631  decode.d2.loss_cls: 0.3631  decode.d2.loss_mask: 0.2818  decode.d2.loss_dice: 0.3458  decode.d3.loss_cls: 0.3017  decode.d3.loss_mask: 0.2845  decode.d3.loss_dice: 0.3834  decode.d4.loss_cls: 0.2928  decode.d4.loss_mask: 0.2876  decode.d4.loss_dice: 0.3671  decode.d5.loss_cls: 0.3038  decode.d5.loss_mask: 0.2865  decode.d5.loss_dice: 0.3804  decode.d6.loss_cls: 0.2763  decode.d6.loss_mask: 0.2834  decode.d6.loss_dice: 0.3640  decode.d7.loss_cls: 0.2902  decode.d7.loss_mask: 0.2846  decode.d7.loss_dice: 0.4070  decode.d8.loss_cls: 0.3162  decode.d8.loss_mask: 0.2843  decode.d8.loss_dice: 0.3584
08/06 10:35:25 - mmengine - INFO - Iter(train) [ 60200/320000]  base_lr: 8.2898e-05 lr: 8.2898e-06  eta: 1 day, 11:34:46  time: 0.4964  data_time: 0.0112  memory: 5894  grad_norm: 84.7872  loss: 5.2411  decode.loss_cls: 0.0812  decode.loss_mask: 0.1748  decode.loss_dice: 0.1991  decode.d0.loss_cls: 0.8864  decode.d0.loss_mask: 0.1740  decode.d0.loss_dice: 0.1927  decode.d1.loss_cls: 0.0734  decode.d1.loss_mask: 0.1762  decode.d1.loss_dice: 0.1994  decode.d2.loss_cls: 0.0541  decode.d2.loss_mask: 0.1746  decode.d2.loss_dice: 0.1978  decode.d3.loss_cls: 0.0505  decode.d3.loss_mask: 0.1748  decode.d3.loss_dice: 0.1999  decode.d4.loss_cls: 0.0481  decode.d4.loss_mask: 0.1739  decode.d4.loss_dice: 0.1966  decode.d5.loss_cls: 0.0755  decode.d5.loss_mask: 0.1744  decode.d5.loss_dice: 0.2005  decode.d6.loss_cls: 0.0722  decode.d6.loss_mask: 0.1743  decode.d6.loss_dice: 0.1938  decode.d7.loss_cls: 0.1022  decode.d7.loss_mask: 0.1748  decode.d7.loss_dice: 0.1952  decode.d8.loss_cls: 0.0755  decode.d8.loss_mask: 0.1740  decode.d8.loss_dice: 0.2012
08/06 10:35:50 - mmengine - INFO - Iter(train) [ 60250/320000]  base_lr: 8.2883e-05 lr: 8.2883e-06  eta: 1 day, 11:34:22  time: 0.4957  data_time: 0.0114  memory: 5876  grad_norm: 120.2897  loss: 8.2725  decode.loss_cls: 0.3030  decode.loss_mask: 0.2341  decode.loss_dice: 0.2454  decode.d0.loss_cls: 0.9339  decode.d0.loss_mask: 0.2315  decode.d0.loss_dice: 0.2498  decode.d1.loss_cls: 0.2561  decode.d1.loss_mask: 0.2306  decode.d1.loss_dice: 0.2526  decode.d2.loss_cls: 0.2734  decode.d2.loss_mask: 0.2288  decode.d2.loss_dice: 0.2643  decode.d3.loss_cls: 0.3185  decode.d3.loss_mask: 0.2296  decode.d3.loss_dice: 0.2638  decode.d4.loss_cls: 0.2531  decode.d4.loss_mask: 0.2300  decode.d4.loss_dice: 0.2750  decode.d5.loss_cls: 0.2703  decode.d5.loss_mask: 0.2310  decode.d5.loss_dice: 0.2550  decode.d6.loss_cls: 0.2317  decode.d6.loss_mask: 0.2317  decode.d6.loss_dice: 0.2661  decode.d7.loss_cls: 0.2836  decode.d7.loss_mask: 0.2312  decode.d7.loss_dice: 0.2560  decode.d8.loss_cls: 0.2633  decode.d8.loss_mask: 0.2326  decode.d8.loss_dice: 0.2465
08/06 10:36:15 - mmengine - INFO - Iter(train) [ 60300/320000]  base_lr: 8.2869e-05 lr: 8.2869e-06  eta: 1 day, 11:33:58  time: 0.4979  data_time: 0.0115  memory: 5913  grad_norm: 101.2749  loss: 6.2708  decode.loss_cls: 0.0314  decode.loss_mask: 0.2222  decode.loss_dice: 0.2574  decode.d0.loss_cls: 0.9612  decode.d0.loss_mask: 0.2227  decode.d0.loss_dice: 0.2516  decode.d1.loss_cls: 0.0947  decode.d1.loss_mask: 0.2207  decode.d1.loss_dice: 0.2356  decode.d2.loss_cls: 0.0760  decode.d2.loss_mask: 0.2211  decode.d2.loss_dice: 0.2412  decode.d3.loss_cls: 0.0751  decode.d3.loss_mask: 0.2190  decode.d3.loss_dice: 0.2475  decode.d4.loss_cls: 0.0707  decode.d4.loss_mask: 0.2218  decode.d4.loss_dice: 0.2379  decode.d5.loss_cls: 0.0918  decode.d5.loss_mask: 0.2204  decode.d5.loss_dice: 0.2366  decode.d6.loss_cls: 0.0864  decode.d6.loss_mask: 0.2186  decode.d6.loss_dice: 0.2421  decode.d7.loss_cls: 0.0785  decode.d7.loss_mask: 0.2175  decode.d7.loss_dice: 0.2411  decode.d8.loss_cls: 0.0664  decode.d8.loss_mask: 0.2196  decode.d8.loss_dice: 0.2441
08/06 10:36:40 - mmengine - INFO - Iter(train) [ 60350/320000]  base_lr: 8.2854e-05 lr: 8.2854e-06  eta: 1 day, 11:33:34  time: 0.4953  data_time: 0.0112  memory: 5913  grad_norm: 105.9558  loss: 6.9677  decode.loss_cls: 0.1144  decode.loss_mask: 0.2271  decode.loss_dice: 0.2618  decode.d0.loss_cls: 0.7916  decode.d0.loss_mask: 0.2287  decode.d0.loss_dice: 0.2891  decode.d1.loss_cls: 0.1199  decode.d1.loss_mask: 0.2241  decode.d1.loss_dice: 0.2799  decode.d2.loss_cls: 0.1515  decode.d2.loss_mask: 0.2253  decode.d2.loss_dice: 0.2668  decode.d3.loss_cls: 0.1664  decode.d3.loss_mask: 0.2258  decode.d3.loss_dice: 0.2652  decode.d4.loss_cls: 0.1295  decode.d4.loss_mask: 0.2250  decode.d4.loss_dice: 0.2778  decode.d5.loss_cls: 0.1381  decode.d5.loss_mask: 0.2247  decode.d5.loss_dice: 0.2623  decode.d6.loss_cls: 0.1785  decode.d6.loss_mask: 0.2235  decode.d6.loss_dice: 0.2580  decode.d7.loss_cls: 0.1455  decode.d7.loss_mask: 0.2263  decode.d7.loss_dice: 0.2551  decode.d8.loss_cls: 0.0867  decode.d8.loss_mask: 0.2254  decode.d8.loss_dice: 0.2738
08/06 10:37:05 - mmengine - INFO - Iter(train) [ 60400/320000]  base_lr: 8.2840e-05 lr: 8.2840e-06  eta: 1 day, 11:33:10  time: 0.4954  data_time: 0.0114  memory: 5894  grad_norm: 61.6249  loss: 7.4112  decode.loss_cls: 0.1042  decode.loss_mask: 0.3030  decode.loss_dice: 0.2588  decode.d0.loss_cls: 0.8147  decode.d0.loss_mask: 0.3079  decode.d0.loss_dice: 0.2605  decode.d1.loss_cls: 0.0895  decode.d1.loss_mask: 0.2994  decode.d1.loss_dice: 0.2720  decode.d2.loss_cls: 0.1429  decode.d2.loss_mask: 0.2974  decode.d2.loss_dice: 0.2641  decode.d3.loss_cls: 0.1169  decode.d3.loss_mask: 0.3044  decode.d3.loss_dice: 0.2650  decode.d4.loss_cls: 0.0729  decode.d4.loss_mask: 0.2973  decode.d4.loss_dice: 0.2688  decode.d5.loss_cls: 0.0858  decode.d5.loss_mask: 0.3004  decode.d5.loss_dice: 0.2610  decode.d6.loss_cls: 0.0958  decode.d6.loss_mask: 0.3067  decode.d6.loss_dice: 0.2691  decode.d7.loss_cls: 0.0939  decode.d7.loss_mask: 0.3026  decode.d7.loss_dice: 0.2739  decode.d8.loss_cls: 0.1064  decode.d8.loss_mask: 0.3049  decode.d8.loss_dice: 0.2710
08/06 10:37:29 - mmengine - INFO - Iter(train) [ 60450/320000]  base_lr: 8.2826e-05 lr: 8.2826e-06  eta: 1 day, 11:32:46  time: 0.4957  data_time: 0.0113  memory: 5909  grad_norm: 85.9488  loss: 8.2462  decode.loss_cls: 0.0879  decode.loss_mask: 0.2848  decode.loss_dice: 0.3187  decode.d0.loss_cls: 1.0216  decode.d0.loss_mask: 0.2817  decode.d0.loss_dice: 0.3135  decode.d1.loss_cls: 0.1003  decode.d1.loss_mask: 0.2933  decode.d1.loss_dice: 0.3206  decode.d2.loss_cls: 0.0821  decode.d2.loss_mask: 0.2879  decode.d2.loss_dice: 0.3070  decode.d3.loss_cls: 0.1358  decode.d3.loss_mask: 0.2935  decode.d3.loss_dice: 0.3137  decode.d4.loss_cls: 0.1984  decode.d4.loss_mask: 0.2793  decode.d4.loss_dice: 0.3099  decode.d5.loss_cls: 0.2452  decode.d5.loss_mask: 0.2752  decode.d5.loss_dice: 0.3046  decode.d6.loss_cls: 0.1405  decode.d6.loss_mask: 0.2750  decode.d6.loss_dice: 0.3040  decode.d7.loss_cls: 0.1701  decode.d7.loss_mask: 0.2715  decode.d7.loss_dice: 0.3096  decode.d8.loss_cls: 0.1232  decode.d8.loss_mask: 0.2772  decode.d8.loss_dice: 0.3203
08/06 10:37:54 - mmengine - INFO - Iter(train) [ 60500/320000]  base_lr: 8.2811e-05 lr: 8.2811e-06  eta: 1 day, 11:32:21  time: 0.4959  data_time: 0.0115  memory: 5911  grad_norm: 88.5934  loss: 9.1401  decode.loss_cls: 0.2963  decode.loss_mask: 0.2224  decode.loss_dice: 0.2946  decode.d0.loss_cls: 1.0839  decode.d0.loss_mask: 0.2191  decode.d0.loss_dice: 0.3236  decode.d1.loss_cls: 0.2865  decode.d1.loss_mask: 0.2177  decode.d1.loss_dice: 0.2991  decode.d2.loss_cls: 0.3299  decode.d2.loss_mask: 0.2219  decode.d2.loss_dice: 0.2907  decode.d3.loss_cls: 0.3228  decode.d3.loss_mask: 0.2205  decode.d3.loss_dice: 0.3297  decode.d4.loss_cls: 0.3104  decode.d4.loss_mask: 0.2216  decode.d4.loss_dice: 0.2936  decode.d5.loss_cls: 0.3479  decode.d5.loss_mask: 0.2181  decode.d5.loss_dice: 0.3151  decode.d6.loss_cls: 0.3244  decode.d6.loss_mask: 0.2211  decode.d6.loss_dice: 0.2681  decode.d7.loss_cls: 0.3545  decode.d7.loss_mask: 0.2215  decode.d7.loss_dice: 0.2722  decode.d8.loss_cls: 0.3149  decode.d8.loss_mask: 0.2171  decode.d8.loss_dice: 0.2811
08/06 10:38:19 - mmengine - INFO - Iter(train) [ 60550/320000]  base_lr: 8.2797e-05 lr: 8.2797e-06  eta: 1 day, 11:31:57  time: 0.4951  data_time: 0.0112  memory: 5896  grad_norm: 353.8707  loss: 9.7952  decode.loss_cls: 0.1698  decode.loss_mask: 0.3418  decode.loss_dice: 0.3891  decode.d0.loss_cls: 1.1380  decode.d0.loss_mask: 0.2991  decode.d0.loss_dice: 0.3781  decode.d1.loss_cls: 0.2381  decode.d1.loss_mask: 0.3085  decode.d1.loss_dice: 0.3429  decode.d2.loss_cls: 0.1833  decode.d2.loss_mask: 0.3121  decode.d2.loss_dice: 0.3629  decode.d3.loss_cls: 0.1203  decode.d3.loss_mask: 0.3603  decode.d3.loss_dice: 0.3821  decode.d4.loss_cls: 0.2147  decode.d4.loss_mask: 0.3372  decode.d4.loss_dice: 0.3741  decode.d5.loss_cls: 0.1734  decode.d5.loss_mask: 0.3180  decode.d5.loss_dice: 0.3566  decode.d6.loss_cls: 0.2244  decode.d6.loss_mask: 0.3171  decode.d6.loss_dice: 0.3734  decode.d7.loss_cls: 0.1648  decode.d7.loss_mask: 0.3212  decode.d7.loss_dice: 0.3952  decode.d8.loss_cls: 0.1961  decode.d8.loss_mask: 0.3309  decode.d8.loss_dice: 0.3718
08/06 10:38:44 - mmengine - INFO - Iter(train) [ 60600/320000]  base_lr: 8.2783e-05 lr: 8.2783e-06  eta: 1 day, 11:31:33  time: 0.4953  data_time: 0.0112  memory: 5895  grad_norm: 50.4269  loss: 6.1540  decode.loss_cls: 0.0179  decode.loss_mask: 0.2680  decode.loss_dice: 0.2514  decode.d0.loss_cls: 0.7263  decode.d0.loss_mask: 0.2804  decode.d0.loss_dice: 0.2395  decode.d1.loss_cls: 0.0743  decode.d1.loss_mask: 0.2688  decode.d1.loss_dice: 0.2461  decode.d2.loss_cls: 0.0319  decode.d2.loss_mask: 0.2730  decode.d2.loss_dice: 0.2526  decode.d3.loss_cls: 0.0142  decode.d3.loss_mask: 0.2715  decode.d3.loss_dice: 0.2540  decode.d4.loss_cls: 0.0150  decode.d4.loss_mask: 0.2718  decode.d4.loss_dice: 0.2526  decode.d5.loss_cls: 0.0187  decode.d5.loss_mask: 0.2686  decode.d5.loss_dice: 0.2464  decode.d6.loss_cls: 0.0128  decode.d6.loss_mask: 0.2694  decode.d6.loss_dice: 0.2480  decode.d7.loss_cls: 0.0180  decode.d7.loss_mask: 0.2707  decode.d7.loss_dice: 0.2542  decode.d8.loss_cls: 0.0188  decode.d8.loss_mask: 0.2739  decode.d8.loss_dice: 0.2454
08/06 10:39:08 - mmengine - INFO - Iter(train) [ 60650/320000]  base_lr: 8.2768e-05 lr: 8.2768e-06  eta: 1 day, 11:31:09  time: 0.4947  data_time: 0.0110  memory: 5913  grad_norm: 132.8345  loss: 7.7333  decode.loss_cls: 0.1584  decode.loss_mask: 0.2427  decode.loss_dice: 0.2710  decode.d0.loss_cls: 0.9345  decode.d0.loss_mask: 0.2583  decode.d0.loss_dice: 0.2733  decode.d1.loss_cls: 0.2591  decode.d1.loss_mask: 0.2387  decode.d1.loss_dice: 0.2582  decode.d2.loss_cls: 0.1987  decode.d2.loss_mask: 0.2396  decode.d2.loss_dice: 0.2717  decode.d3.loss_cls: 0.1856  decode.d3.loss_mask: 0.2454  decode.d3.loss_dice: 0.2764  decode.d4.loss_cls: 0.1617  decode.d4.loss_mask: 0.2425  decode.d4.loss_dice: 0.2893  decode.d5.loss_cls: 0.1602  decode.d5.loss_mask: 0.2448  decode.d5.loss_dice: 0.2781  decode.d6.loss_cls: 0.1593  decode.d6.loss_mask: 0.2474  decode.d6.loss_dice: 0.2792  decode.d7.loss_cls: 0.1504  decode.d7.loss_mask: 0.2471  decode.d7.loss_dice: 0.2710  decode.d8.loss_cls: 0.1620  decode.d8.loss_mask: 0.2460  decode.d8.loss_dice: 0.2827
08/06 10:39:33 - mmengine - INFO - Iter(train) [ 60700/320000]  base_lr: 8.2754e-05 lr: 8.2754e-06  eta: 1 day, 11:30:45  time: 0.4959  data_time: 0.0113  memory: 5930  grad_norm: 66.7028  loss: 6.2492  decode.loss_cls: 0.0681  decode.loss_mask: 0.2097  decode.loss_dice: 0.2384  decode.d0.loss_cls: 0.8788  decode.d0.loss_mask: 0.2124  decode.d0.loss_dice: 0.2507  decode.d1.loss_cls: 0.1262  decode.d1.loss_mask: 0.2084  decode.d1.loss_dice: 0.2436  decode.d2.loss_cls: 0.1147  decode.d2.loss_mask: 0.2097  decode.d2.loss_dice: 0.2518  decode.d3.loss_cls: 0.0978  decode.d3.loss_mask: 0.2101  decode.d3.loss_dice: 0.2474  decode.d4.loss_cls: 0.0886  decode.d4.loss_mask: 0.2098  decode.d4.loss_dice: 0.2450  decode.d5.loss_cls: 0.0987  decode.d5.loss_mask: 0.2081  decode.d5.loss_dice: 0.2486  decode.d6.loss_cls: 0.0697  decode.d6.loss_mask: 0.2085  decode.d6.loss_dice: 0.2449  decode.d7.loss_cls: 0.0722  decode.d7.loss_mask: 0.2097  decode.d7.loss_dice: 0.2523  decode.d8.loss_cls: 0.0731  decode.d8.loss_mask: 0.2084  decode.d8.loss_dice: 0.2439
08/06 10:39:58 - mmengine - INFO - Iter(train) [ 60750/320000]  base_lr: 8.2740e-05 lr: 8.2740e-06  eta: 1 day, 11:30:21  time: 0.4957  data_time: 0.0114  memory: 5895  grad_norm: 71.0989  loss: 6.4216  decode.loss_cls: 0.1091  decode.loss_mask: 0.2405  decode.loss_dice: 0.2334  decode.d0.loss_cls: 0.8528  decode.d0.loss_mask: 0.2390  decode.d0.loss_dice: 0.2404  decode.d1.loss_cls: 0.0854  decode.d1.loss_mask: 0.2350  decode.d1.loss_dice: 0.2457  decode.d2.loss_cls: 0.0802  decode.d2.loss_mask: 0.2365  decode.d2.loss_dice: 0.2423  decode.d3.loss_cls: 0.0821  decode.d3.loss_mask: 0.2352  decode.d3.loss_dice: 0.2386  decode.d4.loss_cls: 0.0800  decode.d4.loss_mask: 0.2358  decode.d4.loss_dice: 0.2412  decode.d5.loss_cls: 0.0881  decode.d5.loss_mask: 0.2354  decode.d5.loss_dice: 0.2370  decode.d6.loss_cls: 0.0851  decode.d6.loss_mask: 0.2345  decode.d6.loss_dice: 0.2398  decode.d7.loss_cls: 0.1133  decode.d7.loss_mask: 0.2352  decode.d7.loss_dice: 0.2238  decode.d8.loss_cls: 0.0898  decode.d8.loss_mask: 0.2375  decode.d8.loss_dice: 0.2488
08/06 10:40:23 - mmengine - INFO - Iter(train) [ 60800/320000]  base_lr: 8.2725e-05 lr: 8.2725e-06  eta: 1 day, 11:29:57  time: 0.4957  data_time: 0.0114  memory: 5911  grad_norm: 97.3749  loss: 7.0677  decode.loss_cls: 0.0973  decode.loss_mask: 0.2444  decode.loss_dice: 0.2811  decode.d0.loss_cls: 0.7833  decode.d0.loss_mask: 0.2521  decode.d0.loss_dice: 0.3061  decode.d1.loss_cls: 0.1330  decode.d1.loss_mask: 0.2456  decode.d1.loss_dice: 0.2817  decode.d2.loss_cls: 0.1252  decode.d2.loss_mask: 0.2486  decode.d2.loss_dice: 0.2659  decode.d3.loss_cls: 0.1015  decode.d3.loss_mask: 0.2476  decode.d3.loss_dice: 0.2906  decode.d4.loss_cls: 0.0830  decode.d4.loss_mask: 0.2460  decode.d4.loss_dice: 0.3051  decode.d5.loss_cls: 0.1210  decode.d5.loss_mask: 0.2471  decode.d5.loss_dice: 0.2676  decode.d6.loss_cls: 0.1335  decode.d6.loss_mask: 0.2437  decode.d6.loss_dice: 0.2606  decode.d7.loss_cls: 0.0897  decode.d7.loss_mask: 0.2445  decode.d7.loss_dice: 0.3012  decode.d8.loss_cls: 0.0918  decode.d8.loss_mask: 0.2438  decode.d8.loss_dice: 0.2850
08/06 10:40:48 - mmengine - INFO - Iter(train) [ 60850/320000]  base_lr: 8.2711e-05 lr: 8.2711e-06  eta: 1 day, 11:29:33  time: 0.4948  data_time: 0.0112  memory: 5878  grad_norm: 128.9970  loss: 7.8784  decode.loss_cls: 0.1590  decode.loss_mask: 0.2395  decode.loss_dice: 0.2752  decode.d0.loss_cls: 0.9450  decode.d0.loss_mask: 0.2488  decode.d0.loss_dice: 0.2941  decode.d1.loss_cls: 0.2193  decode.d1.loss_mask: 0.2430  decode.d1.loss_dice: 0.3020  decode.d2.loss_cls: 0.2025  decode.d2.loss_mask: 0.2436  decode.d2.loss_dice: 0.2759  decode.d3.loss_cls: 0.1394  decode.d3.loss_mask: 0.2389  decode.d3.loss_dice: 0.2783  decode.d4.loss_cls: 0.1930  decode.d4.loss_mask: 0.2394  decode.d4.loss_dice: 0.2890  decode.d5.loss_cls: 0.1616  decode.d5.loss_mask: 0.2401  decode.d5.loss_dice: 0.3073  decode.d6.loss_cls: 0.1662  decode.d6.loss_mask: 0.2421  decode.d6.loss_dice: 0.2933  decode.d7.loss_cls: 0.2288  decode.d7.loss_mask: 0.2397  decode.d7.loss_dice: 0.2775  decode.d8.loss_cls: 0.1743  decode.d8.loss_mask: 0.2412  decode.d8.loss_dice: 0.2805
08/06 10:41:13 - mmengine - INFO - Iter(train) [ 60900/320000]  base_lr: 8.2696e-05 lr: 8.2696e-06  eta: 1 day, 11:29:09  time: 0.4946  data_time: 0.0115  memory: 5911  grad_norm: 134.9757  loss: 9.4923  decode.loss_cls: 0.3050  decode.loss_mask: 0.3180  decode.loss_dice: 0.3133  decode.d0.loss_cls: 1.0014  decode.d0.loss_mask: 0.2937  decode.d0.loss_dice: 0.3105  decode.d1.loss_cls: 0.2186  decode.d1.loss_mask: 0.2862  decode.d1.loss_dice: 0.3187  decode.d2.loss_cls: 0.2714  decode.d2.loss_mask: 0.2815  decode.d2.loss_dice: 0.3051  decode.d3.loss_cls: 0.2498  decode.d3.loss_mask: 0.2825  decode.d3.loss_dice: 0.2960  decode.d4.loss_cls: 0.2533  decode.d4.loss_mask: 0.2857  decode.d4.loss_dice: 0.2977  decode.d5.loss_cls: 0.2549  decode.d5.loss_mask: 0.2883  decode.d5.loss_dice: 0.3120  decode.d6.loss_cls: 0.2760  decode.d6.loss_mask: 0.2858  decode.d6.loss_dice: 0.3179  decode.d7.loss_cls: 0.2764  decode.d7.loss_mask: 0.3429  decode.d7.loss_dice: 0.3123  decode.d8.loss_cls: 0.2799  decode.d8.loss_mask: 0.3270  decode.d8.loss_dice: 0.3307
08/06 10:41:37 - mmengine - INFO - Iter(train) [ 60950/320000]  base_lr: 8.2682e-05 lr: 8.2682e-06  eta: 1 day, 11:28:45  time: 0.4975  data_time: 0.0114  memory: 5913  grad_norm: 84.6246  loss: 7.0719  decode.loss_cls: 0.1958  decode.loss_mask: 0.2000  decode.loss_dice: 0.3051  decode.d0.loss_cls: 0.8854  decode.d0.loss_mask: 0.1896  decode.d0.loss_dice: 0.2983  decode.d1.loss_cls: 0.2219  decode.d1.loss_mask: 0.1792  decode.d1.loss_dice: 0.2838  decode.d2.loss_cls: 0.1788  decode.d2.loss_mask: 0.1812  decode.d2.loss_dice: 0.3046  decode.d3.loss_cls: 0.1747  decode.d3.loss_mask: 0.1814  decode.d3.loss_dice: 0.3046  decode.d4.loss_cls: 0.1188  decode.d4.loss_mask: 0.1793  decode.d4.loss_dice: 0.2836  decode.d5.loss_cls: 0.1191  decode.d5.loss_mask: 0.1800  decode.d5.loss_dice: 0.2674  decode.d6.loss_cls: 0.1317  decode.d6.loss_mask: 0.1805  decode.d6.loss_dice: 0.2739  decode.d7.loss_cls: 0.1650  decode.d7.loss_mask: 0.1820  decode.d7.loss_dice: 0.2958  decode.d8.loss_cls: 0.1383  decode.d8.loss_mask: 0.1787  decode.d8.loss_dice: 0.2934
08/06 10:42:02 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 10:42:02 - mmengine - INFO - Iter(train) [ 61000/320000]  base_lr: 8.2668e-05 lr: 8.2668e-06  eta: 1 day, 11:28:21  time: 0.4967  data_time: 0.0112  memory: 5874  grad_norm: 178.8108  loss: 8.4130  decode.loss_cls: 0.2604  decode.loss_mask: 0.2330  decode.loss_dice: 0.2568  decode.d0.loss_cls: 1.0101  decode.d0.loss_mask: 0.2507  decode.d0.loss_dice: 0.3227  decode.d1.loss_cls: 0.2511  decode.d1.loss_mask: 0.2292  decode.d1.loss_dice: 0.2939  decode.d2.loss_cls: 0.2843  decode.d2.loss_mask: 0.2414  decode.d2.loss_dice: 0.2848  decode.d3.loss_cls: 0.2631  decode.d3.loss_mask: 0.2255  decode.d3.loss_dice: 0.2638  decode.d4.loss_cls: 0.2394  decode.d4.loss_mask: 0.2355  decode.d4.loss_dice: 0.2793  decode.d5.loss_cls: 0.2050  decode.d5.loss_mask: 0.2328  decode.d5.loss_dice: 0.2737  decode.d6.loss_cls: 0.2498  decode.d6.loss_mask: 0.2325  decode.d6.loss_dice: 0.2958  decode.d7.loss_cls: 0.2578  decode.d7.loss_mask: 0.2319  decode.d7.loss_dice: 0.2666  decode.d8.loss_cls: 0.2120  decode.d8.loss_mask: 0.2362  decode.d8.loss_dice: 0.2941
08/06 10:42:27 - mmengine - INFO - Iter(train) [ 61050/320000]  base_lr: 8.2653e-05 lr: 8.2653e-06  eta: 1 day, 11:27:57  time: 0.4968  data_time: 0.0113  memory: 5911  grad_norm: 112.7022  loss: 7.5591  decode.loss_cls: 0.1139  decode.loss_mask: 0.2993  decode.loss_dice: 0.2581  decode.d0.loss_cls: 0.7769  decode.d0.loss_mask: 0.3113  decode.d0.loss_dice: 0.2505  decode.d1.loss_cls: 0.1248  decode.d1.loss_mask: 0.2984  decode.d1.loss_dice: 0.2577  decode.d2.loss_cls: 0.1499  decode.d2.loss_mask: 0.2980  decode.d2.loss_dice: 0.2550  decode.d3.loss_cls: 0.1372  decode.d3.loss_mask: 0.3058  decode.d3.loss_dice: 0.2521  decode.d4.loss_cls: 0.1182  decode.d4.loss_mask: 0.2990  decode.d4.loss_dice: 0.2410  decode.d5.loss_cls: 0.1344  decode.d5.loss_mask: 0.2997  decode.d5.loss_dice: 0.2449  decode.d6.loss_cls: 0.1238  decode.d6.loss_mask: 0.3138  decode.d6.loss_dice: 0.2639  decode.d7.loss_cls: 0.1344  decode.d7.loss_mask: 0.2942  decode.d7.loss_dice: 0.2617  decode.d8.loss_cls: 0.1336  decode.d8.loss_mask: 0.3290  decode.d8.loss_dice: 0.2787
08/06 10:42:52 - mmengine - INFO - Iter(train) [ 61100/320000]  base_lr: 8.2639e-05 lr: 8.2639e-06  eta: 1 day, 11:27:33  time: 0.4966  data_time: 0.0112  memory: 5911  grad_norm: 78.0610  loss: 6.2971  decode.loss_cls: 0.1208  decode.loss_mask: 0.1763  decode.loss_dice: 0.2385  decode.d0.loss_cls: 1.0204  decode.d0.loss_mask: 0.1793  decode.d0.loss_dice: 0.2469  decode.d1.loss_cls: 0.1418  decode.d1.loss_mask: 0.1774  decode.d1.loss_dice: 0.2515  decode.d2.loss_cls: 0.1514  decode.d2.loss_mask: 0.1768  decode.d2.loss_dice: 0.2327  decode.d3.loss_cls: 0.1277  decode.d3.loss_mask: 0.1794  decode.d3.loss_dice: 0.2408  decode.d4.loss_cls: 0.1165  decode.d4.loss_mask: 0.1800  decode.d4.loss_dice: 0.2351  decode.d5.loss_cls: 0.1084  decode.d5.loss_mask: 0.1777  decode.d5.loss_dice: 0.2337  decode.d6.loss_cls: 0.1138  decode.d6.loss_mask: 0.1775  decode.d6.loss_dice: 0.2448  decode.d7.loss_cls: 0.1194  decode.d7.loss_mask: 0.1784  decode.d7.loss_dice: 0.2379  decode.d8.loss_cls: 0.0986  decode.d8.loss_mask: 0.1780  decode.d8.loss_dice: 0.2356
08/06 10:43:17 - mmengine - INFO - Iter(train) [ 61150/320000]  base_lr: 8.2625e-05 lr: 8.2625e-06  eta: 1 day, 11:27:09  time: 0.4960  data_time: 0.0111  memory: 5895  grad_norm: 42.5612  loss: 4.9874  decode.loss_cls: 0.0158  decode.loss_mask: 0.1991  decode.loss_dice: 0.2061  decode.d0.loss_cls: 0.7284  decode.d0.loss_mask: 0.1996  decode.d0.loss_dice: 0.2076  decode.d1.loss_cls: 0.0682  decode.d1.loss_mask: 0.1977  decode.d1.loss_dice: 0.2021  decode.d2.loss_cls: 0.0153  decode.d2.loss_mask: 0.1962  decode.d2.loss_dice: 0.2061  decode.d3.loss_cls: 0.0140  decode.d3.loss_mask: 0.1956  decode.d3.loss_dice: 0.2045  decode.d4.loss_cls: 0.0254  decode.d4.loss_mask: 0.1960  decode.d4.loss_dice: 0.2047  decode.d5.loss_cls: 0.0239  decode.d5.loss_mask: 0.1976  decode.d5.loss_dice: 0.2081  decode.d6.loss_cls: 0.0237  decode.d6.loss_mask: 0.1947  decode.d6.loss_dice: 0.2067  decode.d7.loss_cls: 0.0171  decode.d7.loss_mask: 0.1999  decode.d7.loss_dice: 0.2069  decode.d8.loss_cls: 0.0206  decode.d8.loss_mask: 0.1982  decode.d8.loss_dice: 0.2078
08/06 10:43:41 - mmengine - INFO - Iter(train) [ 61200/320000]  base_lr: 8.2610e-05 lr: 8.2610e-06  eta: 1 day, 11:26:45  time: 0.4970  data_time: 0.0113  memory: 5911  grad_norm: 108.2516  loss: 6.9540  decode.loss_cls: 0.1528  decode.loss_mask: 0.2205  decode.loss_dice: 0.2581  decode.d0.loss_cls: 0.9520  decode.d0.loss_mask: 0.2101  decode.d0.loss_dice: 0.2390  decode.d1.loss_cls: 0.1946  decode.d1.loss_mask: 0.2142  decode.d1.loss_dice: 0.2294  decode.d2.loss_cls: 0.1486  decode.d2.loss_mask: 0.2140  decode.d2.loss_dice: 0.2389  decode.d3.loss_cls: 0.1540  decode.d3.loss_mask: 0.2282  decode.d3.loss_dice: 0.2755  decode.d4.loss_cls: 0.1469  decode.d4.loss_mask: 0.2516  decode.d4.loss_dice: 0.2530  decode.d5.loss_cls: 0.1457  decode.d5.loss_mask: 0.2174  decode.d5.loss_dice: 0.2397  decode.d6.loss_cls: 0.1380  decode.d6.loss_mask: 0.2185  decode.d6.loss_dice: 0.2221  decode.d7.loss_cls: 0.1715  decode.d7.loss_mask: 0.2185  decode.d7.loss_dice: 0.2235  decode.d8.loss_cls: 0.1482  decode.d8.loss_mask: 0.2174  decode.d8.loss_dice: 0.2122
08/06 10:44:06 - mmengine - INFO - Iter(train) [ 61250/320000]  base_lr: 8.2596e-05 lr: 8.2596e-06  eta: 1 day, 11:26:21  time: 0.4960  data_time: 0.0114  memory: 5911  grad_norm: 141.3917  loss: 9.6118  decode.loss_cls: 0.2036  decode.loss_mask: 0.2737  decode.loss_dice: 0.3219  decode.d0.loss_cls: 0.9874  decode.d0.loss_mask: 0.2769  decode.d0.loss_dice: 0.3428  decode.d1.loss_cls: 0.4041  decode.d1.loss_mask: 0.2726  decode.d1.loss_dice: 0.3206  decode.d2.loss_cls: 0.2973  decode.d2.loss_mask: 0.2721  decode.d2.loss_dice: 0.3280  decode.d3.loss_cls: 0.3058  decode.d3.loss_mask: 0.2740  decode.d3.loss_dice: 0.3222  decode.d4.loss_cls: 0.3074  decode.d4.loss_mask: 0.2759  decode.d4.loss_dice: 0.3110  decode.d5.loss_cls: 0.2802  decode.d5.loss_mask: 0.2740  decode.d5.loss_dice: 0.3266  decode.d6.loss_cls: 0.2807  decode.d6.loss_mask: 0.2767  decode.d6.loss_dice: 0.3362  decode.d7.loss_cls: 0.2698  decode.d7.loss_mask: 0.2735  decode.d7.loss_dice: 0.3273  decode.d8.loss_cls: 0.2649  decode.d8.loss_mask: 0.2730  decode.d8.loss_dice: 0.3317
08/06 10:44:31 - mmengine - INFO - Iter(train) [ 61300/320000]  base_lr: 8.2582e-05 lr: 8.2582e-06  eta: 1 day, 11:25:57  time: 0.4948  data_time: 0.0110  memory: 5894  grad_norm: 94.3477  loss: 7.4996  decode.loss_cls: 0.1235  decode.loss_mask: 0.2606  decode.loss_dice: 0.2564  decode.d0.loss_cls: 0.9316  decode.d0.loss_mask: 0.2669  decode.d0.loss_dice: 0.2462  decode.d1.loss_cls: 0.1978  decode.d1.loss_mask: 0.2665  decode.d1.loss_dice: 0.2562  decode.d2.loss_cls: 0.1516  decode.d2.loss_mask: 0.2633  decode.d2.loss_dice: 0.2491  decode.d3.loss_cls: 0.1593  decode.d3.loss_mask: 0.2611  decode.d3.loss_dice: 0.2652  decode.d4.loss_cls: 0.1743  decode.d4.loss_mask: 0.2621  decode.d4.loss_dice: 0.2688  decode.d5.loss_cls: 0.1693  decode.d5.loss_mask: 0.2618  decode.d5.loss_dice: 0.2383  decode.d6.loss_cls: 0.1672  decode.d6.loss_mask: 0.2607  decode.d6.loss_dice: 0.2273  decode.d7.loss_cls: 0.1785  decode.d7.loss_mask: 0.2647  decode.d7.loss_dice: 0.2442  decode.d8.loss_cls: 0.1174  decode.d8.loss_mask: 0.2624  decode.d8.loss_dice: 0.2473
08/06 10:44:56 - mmengine - INFO - Iter(train) [ 61350/320000]  base_lr: 8.2567e-05 lr: 8.2567e-06  eta: 1 day, 11:25:33  time: 0.4949  data_time: 0.0112  memory: 5913  grad_norm: 95.5815  loss: 7.6710  decode.loss_cls: 0.0622  decode.loss_mask: 0.3300  decode.loss_dice: 0.2943  decode.d0.loss_cls: 0.7723  decode.d0.loss_mask: 0.3254  decode.d0.loss_dice: 0.2691  decode.d1.loss_cls: 0.1134  decode.d1.loss_mask: 0.3247  decode.d1.loss_dice: 0.2819  decode.d2.loss_cls: 0.1054  decode.d2.loss_mask: 0.3267  decode.d2.loss_dice: 0.2667  decode.d3.loss_cls: 0.1340  decode.d3.loss_mask: 0.3234  decode.d3.loss_dice: 0.2736  decode.d4.loss_cls: 0.1237  decode.d4.loss_mask: 0.3195  decode.d4.loss_dice: 0.2576  decode.d5.loss_cls: 0.1220  decode.d5.loss_mask: 0.3262  decode.d5.loss_dice: 0.2621  decode.d6.loss_cls: 0.1193  decode.d6.loss_mask: 0.3193  decode.d6.loss_dice: 0.2629  decode.d7.loss_cls: 0.0634  decode.d7.loss_mask: 0.3291  decode.d7.loss_dice: 0.2991  decode.d8.loss_cls: 0.0541  decode.d8.loss_mask: 0.3256  decode.d8.loss_dice: 0.2843
08/06 10:45:21 - mmengine - INFO - Iter(train) [ 61400/320000]  base_lr: 8.2553e-05 lr: 8.2553e-06  eta: 1 day, 11:25:09  time: 0.4970  data_time: 0.0112  memory: 5891  grad_norm: 140.7145  loss: 7.4480  decode.loss_cls: 0.0788  decode.loss_mask: 0.2568  decode.loss_dice: 0.3028  decode.d0.loss_cls: 0.9023  decode.d0.loss_mask: 0.2605  decode.d0.loss_dice: 0.3220  decode.d1.loss_cls: 0.1138  decode.d1.loss_mask: 0.2597  decode.d1.loss_dice: 0.3252  decode.d2.loss_cls: 0.0769  decode.d2.loss_mask: 0.2566  decode.d2.loss_dice: 0.3287  decode.d3.loss_cls: 0.0657  decode.d3.loss_mask: 0.2582  decode.d3.loss_dice: 0.3307  decode.d4.loss_cls: 0.0736  decode.d4.loss_mask: 0.2575  decode.d4.loss_dice: 0.3241  decode.d5.loss_cls: 0.0708  decode.d5.loss_mask: 0.2574  decode.d5.loss_dice: 0.3261  decode.d6.loss_cls: 0.1071  decode.d6.loss_mask: 0.2581  decode.d6.loss_dice: 0.3107  decode.d7.loss_cls: 0.0928  decode.d7.loss_mask: 0.2602  decode.d7.loss_dice: 0.3130  decode.d8.loss_cls: 0.0832  decode.d8.loss_mask: 0.2575  decode.d8.loss_dice: 0.3173
08/06 10:45:46 - mmengine - INFO - Iter(train) [ 61450/320000]  base_lr: 8.2538e-05 lr: 8.2538e-06  eta: 1 day, 11:24:45  time: 0.4967  data_time: 0.0109  memory: 5928  grad_norm: 97.8953  loss: 6.5385  decode.loss_cls: 0.1681  decode.loss_mask: 0.1740  decode.loss_dice: 0.2549  decode.d0.loss_cls: 0.8155  decode.d0.loss_mask: 0.1730  decode.d0.loss_dice: 0.2455  decode.d1.loss_cls: 0.1267  decode.d1.loss_mask: 0.1753  decode.d1.loss_dice: 0.2524  decode.d2.loss_cls: 0.1378  decode.d2.loss_mask: 0.1761  decode.d2.loss_dice: 0.2585  decode.d3.loss_cls: 0.1385  decode.d3.loss_mask: 0.1744  decode.d3.loss_dice: 0.2548  decode.d4.loss_cls: 0.1557  decode.d4.loss_mask: 0.1782  decode.d4.loss_dice: 0.2588  decode.d5.loss_cls: 0.1823  decode.d5.loss_mask: 0.1721  decode.d5.loss_dice: 0.2500  decode.d6.loss_cls: 0.1805  decode.d6.loss_mask: 0.1755  decode.d6.loss_dice: 0.2521  decode.d7.loss_cls: 0.1937  decode.d7.loss_mask: 0.1726  decode.d7.loss_dice: 0.2502  decode.d8.loss_cls: 0.1653  decode.d8.loss_mask: 0.1706  decode.d8.loss_dice: 0.2554
08/06 10:46:10 - mmengine - INFO - Iter(train) [ 61500/320000]  base_lr: 8.2524e-05 lr: 8.2524e-06  eta: 1 day, 11:24:22  time: 0.4973  data_time: 0.0112  memory: 5913  grad_norm: 77.2030  loss: 7.8648  decode.loss_cls: 0.2525  decode.loss_mask: 0.2455  decode.loss_dice: 0.2844  decode.d0.loss_cls: 0.9844  decode.d0.loss_mask: 0.2257  decode.d0.loss_dice: 0.2643  decode.d1.loss_cls: 0.1734  decode.d1.loss_mask: 0.2234  decode.d1.loss_dice: 0.2532  decode.d2.loss_cls: 0.1664  decode.d2.loss_mask: 0.2239  decode.d2.loss_dice: 0.2667  decode.d3.loss_cls: 0.2142  decode.d3.loss_mask: 0.2234  decode.d3.loss_dice: 0.2648  decode.d4.loss_cls: 0.2100  decode.d4.loss_mask: 0.2189  decode.d4.loss_dice: 0.2638  decode.d5.loss_cls: 0.2133  decode.d5.loss_mask: 0.2221  decode.d5.loss_dice: 0.2631  decode.d6.loss_cls: 0.1912  decode.d6.loss_mask: 0.2301  decode.d6.loss_dice: 0.2911  decode.d7.loss_cls: 0.1653  decode.d7.loss_mask: 0.2326  decode.d7.loss_dice: 0.2924  decode.d8.loss_cls: 0.2636  decode.d8.loss_mask: 0.2381  decode.d8.loss_dice: 0.3031
08/06 10:46:35 - mmengine - INFO - Iter(train) [ 61550/320000]  base_lr: 8.2510e-05 lr: 8.2510e-06  eta: 1 day, 11:23:58  time: 0.4976  data_time: 0.0115  memory: 5894  grad_norm: 172.1212  loss: 7.7606  decode.loss_cls: 0.1428  decode.loss_mask: 0.2918  decode.loss_dice: 0.2563  decode.d0.loss_cls: 0.8979  decode.d0.loss_mask: 0.2855  decode.d0.loss_dice: 0.2684  decode.d1.loss_cls: 0.1728  decode.d1.loss_mask: 0.2952  decode.d1.loss_dice: 0.2557  decode.d2.loss_cls: 0.1357  decode.d2.loss_mask: 0.2783  decode.d2.loss_dice: 0.2494  decode.d3.loss_cls: 0.1032  decode.d3.loss_mask: 0.2668  decode.d3.loss_dice: 0.2507  decode.d4.loss_cls: 0.1403  decode.d4.loss_mask: 0.3305  decode.d4.loss_dice: 0.2724  decode.d5.loss_cls: 0.1239  decode.d5.loss_mask: 0.2703  decode.d5.loss_dice: 0.2564  decode.d6.loss_cls: 0.1174  decode.d6.loss_mask: 0.3463  decode.d6.loss_dice: 0.2656  decode.d7.loss_cls: 0.1518  decode.d7.loss_mask: 0.3058  decode.d7.loss_dice: 0.2796  decode.d8.loss_cls: 0.1321  decode.d8.loss_mask: 0.3330  decode.d8.loss_dice: 0.2846
08/06 10:47:00 - mmengine - INFO - Iter(train) [ 61600/320000]  base_lr: 8.2495e-05 lr: 8.2495e-06  eta: 1 day, 11:23:34  time: 0.4974  data_time: 0.0112  memory: 5911  grad_norm: 68.1816  loss: 6.5713  decode.loss_cls: 0.1233  decode.loss_mask: 0.2191  decode.loss_dice: 0.2139  decode.d0.loss_cls: 0.8995  decode.d0.loss_mask: 0.2177  decode.d0.loss_dice: 0.2223  decode.d1.loss_cls: 0.1504  decode.d1.loss_mask: 0.2215  decode.d1.loss_dice: 0.2221  decode.d2.loss_cls: 0.1208  decode.d2.loss_mask: 0.2198  decode.d2.loss_dice: 0.2267  decode.d3.loss_cls: 0.1351  decode.d3.loss_mask: 0.2189  decode.d3.loss_dice: 0.2224  decode.d4.loss_cls: 0.1529  decode.d4.loss_mask: 0.2198  decode.d4.loss_dice: 0.2181  decode.d5.loss_cls: 0.1548  decode.d5.loss_mask: 0.2210  decode.d5.loss_dice: 0.2245  decode.d6.loss_cls: 0.1412  decode.d6.loss_mask: 0.2191  decode.d6.loss_dice: 0.2201  decode.d7.loss_cls: 0.1293  decode.d7.loss_mask: 0.2213  decode.d7.loss_dice: 0.2275  decode.d8.loss_cls: 0.1322  decode.d8.loss_mask: 0.2199  decode.d8.loss_dice: 0.2363
08/06 10:47:25 - mmengine - INFO - Iter(train) [ 61650/320000]  base_lr: 8.2481e-05 lr: 8.2481e-06  eta: 1 day, 11:23:11  time: 0.4955  data_time: 0.0111  memory: 5911  grad_norm: 266.4669  loss: 8.1322  decode.loss_cls: 0.1204  decode.loss_mask: 0.2928  decode.loss_dice: 0.2799  decode.d0.loss_cls: 0.9811  decode.d0.loss_mask: 0.2593  decode.d0.loss_dice: 0.3058  decode.d1.loss_cls: 0.2822  decode.d1.loss_mask: 0.2903  decode.d1.loss_dice: 0.2908  decode.d2.loss_cls: 0.1762  decode.d2.loss_mask: 0.2675  decode.d2.loss_dice: 0.2780  decode.d3.loss_cls: 0.1932  decode.d3.loss_mask: 0.2600  decode.d3.loss_dice: 0.2710  decode.d4.loss_cls: 0.1936  decode.d4.loss_mask: 0.2658  decode.d4.loss_dice: 0.2682  decode.d5.loss_cls: 0.1759  decode.d5.loss_mask: 0.2841  decode.d5.loss_dice: 0.2903  decode.d6.loss_cls: 0.1274  decode.d6.loss_mask: 0.2885  decode.d6.loss_dice: 0.2985  decode.d7.loss_cls: 0.1480  decode.d7.loss_mask: 0.2720  decode.d7.loss_dice: 0.2718  decode.d8.loss_cls: 0.1412  decode.d8.loss_mask: 0.2748  decode.d8.loss_dice: 0.2837
08/06 10:47:50 - mmengine - INFO - Iter(train) [ 61700/320000]  base_lr: 8.2467e-05 lr: 8.2467e-06  eta: 1 day, 11:22:47  time: 0.4971  data_time: 0.0113  memory: 5911  grad_norm: 210.9775  loss: 9.3662  decode.loss_cls: 0.2280  decode.loss_mask: 0.2852  decode.loss_dice: 0.3450  decode.d0.loss_cls: 0.9351  decode.d0.loss_mask: 0.2738  decode.d0.loss_dice: 0.3427  decode.d1.loss_cls: 0.2819  decode.d1.loss_mask: 0.2857  decode.d1.loss_dice: 0.3443  decode.d2.loss_cls: 0.2785  decode.d2.loss_mask: 0.2904  decode.d2.loss_dice: 0.3429  decode.d3.loss_cls: 0.2465  decode.d3.loss_mask: 0.2754  decode.d3.loss_dice: 0.3499  decode.d4.loss_cls: 0.2228  decode.d4.loss_mask: 0.2812  decode.d4.loss_dice: 0.3413  decode.d5.loss_cls: 0.2018  decode.d5.loss_mask: 0.2912  decode.d5.loss_dice: 0.3468  decode.d6.loss_cls: 0.2261  decode.d6.loss_mask: 0.2817  decode.d6.loss_dice: 0.3465  decode.d7.loss_cls: 0.2375  decode.d7.loss_mask: 0.2720  decode.d7.loss_dice: 0.3486  decode.d8.loss_cls: 0.2342  decode.d8.loss_mask: 0.2900  decode.d8.loss_dice: 0.3393
08/06 10:48:15 - mmengine - INFO - Iter(train) [ 61750/320000]  base_lr: 8.2452e-05 lr: 8.2452e-06  eta: 1 day, 11:22:23  time: 0.4972  data_time: 0.0113  memory: 5911  grad_norm: 61.0096  loss: 6.0726  decode.loss_cls: 0.0678  decode.loss_mask: 0.2303  decode.loss_dice: 0.2369  decode.d0.loss_cls: 0.8392  decode.d0.loss_mask: 0.2363  decode.d0.loss_dice: 0.2314  decode.d1.loss_cls: 0.0812  decode.d1.loss_mask: 0.2340  decode.d1.loss_dice: 0.2382  decode.d2.loss_cls: 0.0620  decode.d2.loss_mask: 0.2331  decode.d2.loss_dice: 0.2301  decode.d3.loss_cls: 0.0380  decode.d3.loss_mask: 0.2326  decode.d3.loss_dice: 0.2312  decode.d4.loss_cls: 0.0509  decode.d4.loss_mask: 0.2338  decode.d4.loss_dice: 0.2275  decode.d5.loss_cls: 0.0503  decode.d5.loss_mask: 0.2348  decode.d5.loss_dice: 0.2478  decode.d6.loss_cls: 0.0539  decode.d6.loss_mask: 0.2311  decode.d6.loss_dice: 0.2326  decode.d7.loss_cls: 0.0738  decode.d7.loss_mask: 0.2344  decode.d7.loss_dice: 0.2297  decode.d8.loss_cls: 0.0804  decode.d8.loss_mask: 0.2318  decode.d8.loss_dice: 0.2372
08/06 10:48:40 - mmengine - INFO - Iter(train) [ 61800/320000]  base_lr: 8.2438e-05 lr: 8.2438e-06  eta: 1 day, 11:21:59  time: 0.4955  data_time: 0.0110  memory: 5909  grad_norm: 245.6779  loss: 8.6559  decode.loss_cls: 0.1569  decode.loss_mask: 0.4397  decode.loss_dice: 0.2766  decode.d0.loss_cls: 0.8818  decode.d0.loss_mask: 0.2995  decode.d0.loss_dice: 0.2696  decode.d1.loss_cls: 0.2163  decode.d1.loss_mask: 0.2944  decode.d1.loss_dice: 0.2658  decode.d2.loss_cls: 0.2417  decode.d2.loss_mask: 0.3200  decode.d2.loss_dice: 0.2655  decode.d3.loss_cls: 0.1724  decode.d3.loss_mask: 0.3237  decode.d3.loss_dice: 0.2569  decode.d4.loss_cls: 0.1998  decode.d4.loss_mask: 0.3255  decode.d4.loss_dice: 0.2545  decode.d5.loss_cls: 0.1554  decode.d5.loss_mask: 0.3530  decode.d5.loss_dice: 0.2612  decode.d6.loss_cls: 0.2866  decode.d6.loss_mask: 0.2668  decode.d6.loss_dice: 0.2651  decode.d7.loss_cls: 0.1527  decode.d7.loss_mask: 0.3630  decode.d7.loss_dice: 0.2705  decode.d8.loss_cls: 0.0962  decode.d8.loss_mask: 0.4491  decode.d8.loss_dice: 0.2758
08/06 10:49:05 - mmengine - INFO - Iter(train) [ 61850/320000]  base_lr: 8.2424e-05 lr: 8.2424e-06  eta: 1 day, 11:21:35  time: 0.4964  data_time: 0.0112  memory: 5911  grad_norm: 82.5957  loss: 7.1815  decode.loss_cls: 0.0961  decode.loss_mask: 0.2860  decode.loss_dice: 0.2542  decode.d0.loss_cls: 0.8677  decode.d0.loss_mask: 0.2894  decode.d0.loss_dice: 0.2625  decode.d1.loss_cls: 0.1206  decode.d1.loss_mask: 0.2896  decode.d1.loss_dice: 0.2736  decode.d2.loss_cls: 0.0891  decode.d2.loss_mask: 0.2898  decode.d2.loss_dice: 0.2513  decode.d3.loss_cls: 0.0725  decode.d3.loss_mask: 0.2887  decode.d3.loss_dice: 0.2471  decode.d4.loss_cls: 0.0841  decode.d4.loss_mask: 0.2905  decode.d4.loss_dice: 0.2634  decode.d5.loss_cls: 0.0723  decode.d5.loss_mask: 0.2881  decode.d5.loss_dice: 0.2519  decode.d6.loss_cls: 0.0859  decode.d6.loss_mask: 0.2905  decode.d6.loss_dice: 0.2669  decode.d7.loss_cls: 0.1072  decode.d7.loss_mask: 0.2898  decode.d7.loss_dice: 0.2414  decode.d8.loss_cls: 0.1271  decode.d8.loss_mask: 0.2900  decode.d8.loss_dice: 0.2538
08/06 10:49:29 - mmengine - INFO - Iter(train) [ 61900/320000]  base_lr: 8.2409e-05 lr: 8.2409e-06  eta: 1 day, 11:21:11  time: 0.4970  data_time: 0.0115  memory: 5895  grad_norm: 91.5537  loss: 7.5369  decode.loss_cls: 0.0770  decode.loss_mask: 0.2737  decode.loss_dice: 0.3047  decode.d0.loss_cls: 0.8763  decode.d0.loss_mask: 0.2777  decode.d0.loss_dice: 0.3096  decode.d1.loss_cls: 0.0818  decode.d1.loss_mask: 0.2756  decode.d1.loss_dice: 0.2942  decode.d2.loss_cls: 0.1100  decode.d2.loss_mask: 0.2669  decode.d2.loss_dice: 0.2729  decode.d3.loss_cls: 0.1456  decode.d3.loss_mask: 0.2693  decode.d3.loss_dice: 0.2669  decode.d4.loss_cls: 0.1376  decode.d4.loss_mask: 0.2700  decode.d4.loss_dice: 0.2753  decode.d5.loss_cls: 0.1590  decode.d5.loss_mask: 0.2683  decode.d5.loss_dice: 0.2696  decode.d6.loss_cls: 0.1514  decode.d6.loss_mask: 0.2679  decode.d6.loss_dice: 0.2669  decode.d7.loss_cls: 0.1291  decode.d7.loss_mask: 0.2743  decode.d7.loss_dice: 0.2901  decode.d8.loss_cls: 0.1204  decode.d8.loss_mask: 0.2686  decode.d8.loss_dice: 0.2863
08/06 10:49:54 - mmengine - INFO - Iter(train) [ 61950/320000]  base_lr: 8.2395e-05 lr: 8.2395e-06  eta: 1 day, 11:20:47  time: 0.4961  data_time: 0.0110  memory: 5911  grad_norm: 95.9935  loss: 5.5041  decode.loss_cls: 0.0674  decode.loss_mask: 0.1758  decode.loss_dice: 0.2269  decode.d0.loss_cls: 0.9020  decode.d0.loss_mask: 0.1777  decode.d0.loss_dice: 0.2212  decode.d1.loss_cls: 0.1251  decode.d1.loss_mask: 0.1766  decode.d1.loss_dice: 0.2117  decode.d2.loss_cls: 0.0199  decode.d2.loss_mask: 0.1794  decode.d2.loss_dice: 0.2215  decode.d3.loss_cls: 0.0743  decode.d3.loss_mask: 0.1797  decode.d3.loss_dice: 0.2125  decode.d4.loss_cls: 0.0690  decode.d4.loss_mask: 0.1755  decode.d4.loss_dice: 0.2152  decode.d5.loss_cls: 0.0685  decode.d5.loss_mask: 0.1745  decode.d5.loss_dice: 0.2132  decode.d6.loss_cls: 0.0707  decode.d6.loss_mask: 0.1757  decode.d6.loss_dice: 0.2193  decode.d7.loss_cls: 0.0749  decode.d7.loss_mask: 0.1783  decode.d7.loss_dice: 0.2227  decode.d8.loss_cls: 0.0616  decode.d8.loss_mask: 0.1794  decode.d8.loss_dice: 0.2340
08/06 10:50:19 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 10:50:19 - mmengine - INFO - Iter(train) [ 62000/320000]  base_lr: 8.2380e-05 lr: 8.2380e-06  eta: 1 day, 11:20:23  time: 0.4953  data_time: 0.0112  memory: 5928  grad_norm: 128.6911  loss: 7.2019  decode.loss_cls: 0.1964  decode.loss_mask: 0.2500  decode.loss_dice: 0.2632  decode.d0.loss_cls: 0.8012  decode.d0.loss_mask: 0.2524  decode.d0.loss_dice: 0.2515  decode.d1.loss_cls: 0.1158  decode.d1.loss_mask: 0.2507  decode.d1.loss_dice: 0.2559  decode.d2.loss_cls: 0.0992  decode.d2.loss_mask: 0.2501  decode.d2.loss_dice: 0.2662  decode.d3.loss_cls: 0.1349  decode.d3.loss_mask: 0.2489  decode.d3.loss_dice: 0.2358  decode.d4.loss_cls: 0.1424  decode.d4.loss_mask: 0.2446  decode.d4.loss_dice: 0.2545  decode.d5.loss_cls: 0.1421  decode.d5.loss_mask: 0.2496  decode.d5.loss_dice: 0.2651  decode.d6.loss_cls: 0.1811  decode.d6.loss_mask: 0.2474  decode.d6.loss_dice: 0.2458  decode.d7.loss_cls: 0.1621  decode.d7.loss_mask: 0.2513  decode.d7.loss_dice: 0.2338  decode.d8.loss_cls: 0.1906  decode.d8.loss_mask: 0.2468  decode.d8.loss_dice: 0.2725
08/06 10:50:44 - mmengine - INFO - Iter(train) [ 62050/320000]  base_lr: 8.2366e-05 lr: 8.2366e-06  eta: 1 day, 11:19:59  time: 0.4959  data_time: 0.0110  memory: 5928  grad_norm: 111.7551  loss: 6.7099  decode.loss_cls: 0.0999  decode.loss_mask: 0.2248  decode.loss_dice: 0.2627  decode.d0.loss_cls: 0.8204  decode.d0.loss_mask: 0.2298  decode.d0.loss_dice: 0.2657  decode.d1.loss_cls: 0.1306  decode.d1.loss_mask: 0.2299  decode.d1.loss_dice: 0.2647  decode.d2.loss_cls: 0.1314  decode.d2.loss_mask: 0.2256  decode.d2.loss_dice: 0.2326  decode.d3.loss_cls: 0.1463  decode.d3.loss_mask: 0.2268  decode.d3.loss_dice: 0.2555  decode.d4.loss_cls: 0.1328  decode.d4.loss_mask: 0.2269  decode.d4.loss_dice: 0.2389  decode.d5.loss_cls: 0.1309  decode.d5.loss_mask: 0.2265  decode.d5.loss_dice: 0.2548  decode.d6.loss_cls: 0.1338  decode.d6.loss_mask: 0.2285  decode.d6.loss_dice: 0.2396  decode.d7.loss_cls: 0.1200  decode.d7.loss_mask: 0.2259  decode.d7.loss_dice: 0.2324  decode.d8.loss_cls: 0.1024  decode.d8.loss_mask: 0.2256  decode.d8.loss_dice: 0.2443
08/06 10:51:09 - mmengine - INFO - Iter(train) [ 62100/320000]  base_lr: 8.2352e-05 lr: 8.2352e-06  eta: 1 day, 11:19:35  time: 0.4957  data_time: 0.0113  memory: 5911  grad_norm: 185.6975  loss: 6.8070  decode.loss_cls: 0.0742  decode.loss_mask: 0.2568  decode.loss_dice: 0.2726  decode.d0.loss_cls: 0.8689  decode.d0.loss_mask: 0.2549  decode.d0.loss_dice: 0.2349  decode.d1.loss_cls: 0.0213  decode.d1.loss_mask: 0.2566  decode.d1.loss_dice: 0.2925  decode.d2.loss_cls: 0.0235  decode.d2.loss_mask: 0.2680  decode.d2.loss_dice: 0.3024  decode.d3.loss_cls: 0.0592  decode.d3.loss_mask: 0.2717  decode.d3.loss_dice: 0.2687  decode.d4.loss_cls: 0.0382  decode.d4.loss_mask: 0.2730  decode.d4.loss_dice: 0.2836  decode.d5.loss_cls: 0.0367  decode.d5.loss_mask: 0.2754  decode.d5.loss_dice: 0.2801  decode.d6.loss_cls: 0.0688  decode.d6.loss_mask: 0.2750  decode.d6.loss_dice: 0.2762  decode.d7.loss_cls: 0.0742  decode.d7.loss_mask: 0.2861  decode.d7.loss_dice: 0.2849  decode.d8.loss_cls: 0.0691  decode.d8.loss_mask: 0.2733  decode.d8.loss_dice: 0.2864
08/06 10:51:34 - mmengine - INFO - Iter(train) [ 62150/320000]  base_lr: 8.2337e-05 lr: 8.2337e-06  eta: 1 day, 11:19:11  time: 0.4964  data_time: 0.0112  memory: 5909  grad_norm: 62.0262  loss: 6.6828  decode.loss_cls: 0.1727  decode.loss_mask: 0.1899  decode.loss_dice: 0.2625  decode.d0.loss_cls: 0.8863  decode.d0.loss_mask: 0.1948  decode.d0.loss_dice: 0.2717  decode.d1.loss_cls: 0.1588  decode.d1.loss_mask: 0.1918  decode.d1.loss_dice: 0.2684  decode.d2.loss_cls: 0.1514  decode.d2.loss_mask: 0.1878  decode.d2.loss_dice: 0.2669  decode.d3.loss_cls: 0.1149  decode.d3.loss_mask: 0.1938  decode.d3.loss_dice: 0.2732  decode.d4.loss_cls: 0.1225  decode.d4.loss_mask: 0.1916  decode.d4.loss_dice: 0.2669  decode.d5.loss_cls: 0.1180  decode.d5.loss_mask: 0.1923  decode.d5.loss_dice: 0.2717  decode.d6.loss_cls: 0.1061  decode.d6.loss_mask: 0.1905  decode.d6.loss_dice: 0.2704  decode.d7.loss_cls: 0.1419  decode.d7.loss_mask: 0.1868  decode.d7.loss_dice: 0.2339  decode.d8.loss_cls: 0.1374  decode.d8.loss_mask: 0.1895  decode.d8.loss_dice: 0.2786
08/06 10:51:58 - mmengine - INFO - Iter(train) [ 62200/320000]  base_lr: 8.2323e-05 lr: 8.2323e-06  eta: 1 day, 11:18:47  time: 0.4964  data_time: 0.0113  memory: 5895  grad_norm: 231.0385  loss: 8.1209  decode.loss_cls: 0.2608  decode.loss_mask: 0.2116  decode.loss_dice: 0.3116  decode.d0.loss_cls: 0.9359  decode.d0.loss_mask: 0.1969  decode.d0.loss_dice: 0.2770  decode.d1.loss_cls: 0.1135  decode.d1.loss_mask: 0.2634  decode.d1.loss_dice: 0.3008  decode.d2.loss_cls: 0.2168  decode.d2.loss_mask: 0.2603  decode.d2.loss_dice: 0.3238  decode.d3.loss_cls: 0.1577  decode.d3.loss_mask: 0.2615  decode.d3.loss_dice: 0.3043  decode.d4.loss_cls: 0.1876  decode.d4.loss_mask: 0.2584  decode.d4.loss_dice: 0.2751  decode.d5.loss_cls: 0.2080  decode.d5.loss_mask: 0.2700  decode.d5.loss_dice: 0.3068  decode.d6.loss_cls: 0.1886  decode.d6.loss_mask: 0.2639  decode.d6.loss_dice: 0.2935  decode.d7.loss_cls: 0.1716  decode.d7.loss_mask: 0.2612  decode.d7.loss_dice: 0.3089  decode.d8.loss_cls: 0.2337  decode.d8.loss_mask: 0.2092  decode.d8.loss_dice: 0.2884
08/06 10:52:23 - mmengine - INFO - Iter(train) [ 62250/320000]  base_lr: 8.2309e-05 lr: 8.2309e-06  eta: 1 day, 11:18:24  time: 0.4962  data_time: 0.0114  memory: 5891  grad_norm: 79.7591  loss: 5.5088  decode.loss_cls: 0.0656  decode.loss_mask: 0.1994  decode.loss_dice: 0.2189  decode.d0.loss_cls: 0.8138  decode.d0.loss_mask: 0.2006  decode.d0.loss_dice: 0.2531  decode.d1.loss_cls: 0.0471  decode.d1.loss_mask: 0.1985  decode.d1.loss_dice: 0.2277  decode.d2.loss_cls: 0.0505  decode.d2.loss_mask: 0.1988  decode.d2.loss_dice: 0.2157  decode.d3.loss_cls: 0.0681  decode.d3.loss_mask: 0.2001  decode.d3.loss_dice: 0.2245  decode.d4.loss_cls: 0.0581  decode.d4.loss_mask: 0.1999  decode.d4.loss_dice: 0.2103  decode.d5.loss_cls: 0.0412  decode.d5.loss_mask: 0.1992  decode.d5.loss_dice: 0.2135  decode.d6.loss_cls: 0.0606  decode.d6.loss_mask: 0.2000  decode.d6.loss_dice: 0.2213  decode.d7.loss_cls: 0.0462  decode.d7.loss_mask: 0.1995  decode.d7.loss_dice: 0.2174  decode.d8.loss_cls: 0.0464  decode.d8.loss_mask: 0.2011  decode.d8.loss_dice: 0.2118
08/06 10:52:48 - mmengine - INFO - Iter(train) [ 62300/320000]  base_lr: 8.2294e-05 lr: 8.2294e-06  eta: 1 day, 11:18:00  time: 0.4961  data_time: 0.0113  memory: 5895  grad_norm: 486.3014  loss: 7.8627  decode.loss_cls: 0.0828  decode.loss_mask: 0.3225  decode.loss_dice: 0.3218  decode.d0.loss_cls: 0.8120  decode.d0.loss_mask: 0.2871  decode.d0.loss_dice: 0.2909  decode.d1.loss_cls: 0.0932  decode.d1.loss_mask: 0.3269  decode.d1.loss_dice: 0.3209  decode.d2.loss_cls: 0.1253  decode.d2.loss_mask: 0.3170  decode.d2.loss_dice: 0.3007  decode.d3.loss_cls: 0.1253  decode.d3.loss_mask: 0.3064  decode.d3.loss_dice: 0.2994  decode.d4.loss_cls: 0.0871  decode.d4.loss_mask: 0.3042  decode.d4.loss_dice: 0.3054  decode.d5.loss_cls: 0.0667  decode.d5.loss_mask: 0.3248  decode.d5.loss_dice: 0.3115  decode.d6.loss_cls: 0.1371  decode.d6.loss_mask: 0.2956  decode.d6.loss_dice: 0.2993  decode.d7.loss_cls: 0.0571  decode.d7.loss_mask: 0.3255  decode.d7.loss_dice: 0.3161  decode.d8.loss_cls: 0.0678  decode.d8.loss_mask: 0.3205  decode.d8.loss_dice: 0.3116
08/06 10:53:13 - mmengine - INFO - Iter(train) [ 62350/320000]  base_lr: 8.2280e-05 lr: 8.2280e-06  eta: 1 day, 11:17:35  time: 0.4960  data_time: 0.0114  memory: 5911  grad_norm: 59.7302  loss: 7.2967  decode.loss_cls: 0.1123  decode.loss_mask: 0.2809  decode.loss_dice: 0.2692  decode.d0.loss_cls: 0.8804  decode.d0.loss_mask: 0.2845  decode.d0.loss_dice: 0.2649  decode.d1.loss_cls: 0.1448  decode.d1.loss_mask: 0.2771  decode.d1.loss_dice: 0.2597  decode.d2.loss_cls: 0.0736  decode.d2.loss_mask: 0.2752  decode.d2.loss_dice: 0.2604  decode.d3.loss_cls: 0.1169  decode.d3.loss_mask: 0.2756  decode.d3.loss_dice: 0.2632  decode.d4.loss_cls: 0.1139  decode.d4.loss_mask: 0.2795  decode.d4.loss_dice: 0.2648  decode.d5.loss_cls: 0.1089  decode.d5.loss_mask: 0.2766  decode.d5.loss_dice: 0.2629  decode.d6.loss_cls: 0.1014  decode.d6.loss_mask: 0.2744  decode.d6.loss_dice: 0.2643  decode.d7.loss_cls: 0.1085  decode.d7.loss_mask: 0.2758  decode.d7.loss_dice: 0.2642  decode.d8.loss_cls: 0.1153  decode.d8.loss_mask: 0.2784  decode.d8.loss_dice: 0.2692
08/06 10:53:38 - mmengine - INFO - Iter(train) [ 62400/320000]  base_lr: 8.2265e-05 lr: 8.2265e-06  eta: 1 day, 11:17:11  time: 0.4962  data_time: 0.0111  memory: 5909  grad_norm: 183.8413  loss: 5.5639  decode.loss_cls: 0.0599  decode.loss_mask: 0.1929  decode.loss_dice: 0.2140  decode.d0.loss_cls: 0.7894  decode.d0.loss_mask: 0.1989  decode.d0.loss_dice: 0.2151  decode.d1.loss_cls: 0.1183  decode.d1.loss_mask: 0.1966  decode.d1.loss_dice: 0.2105  decode.d2.loss_cls: 0.0826  decode.d2.loss_mask: 0.1975  decode.d2.loss_dice: 0.2150  decode.d3.loss_cls: 0.0676  decode.d3.loss_mask: 0.1969  decode.d3.loss_dice: 0.2119  decode.d4.loss_cls: 0.1051  decode.d4.loss_mask: 0.1934  decode.d4.loss_dice: 0.2134  decode.d5.loss_cls: 0.0775  decode.d5.loss_mask: 0.1956  decode.d5.loss_dice: 0.2113  decode.d6.loss_cls: 0.0836  decode.d6.loss_mask: 0.1956  decode.d6.loss_dice: 0.2108  decode.d7.loss_cls: 0.0472  decode.d7.loss_mask: 0.1957  decode.d7.loss_dice: 0.2122  decode.d8.loss_cls: 0.0472  decode.d8.loss_mask: 0.1945  decode.d8.loss_dice: 0.2134
08/06 10:54:02 - mmengine - INFO - Iter(train) [ 62450/320000]  base_lr: 8.2251e-05 lr: 8.2251e-06  eta: 1 day, 11:16:47  time: 0.4954  data_time: 0.0111  memory: 5891  grad_norm: 57.8627  loss: 5.6509  decode.loss_cls: 0.0570  decode.loss_mask: 0.2084  decode.loss_dice: 0.2318  decode.d0.loss_cls: 0.7463  decode.d0.loss_mask: 0.2142  decode.d0.loss_dice: 0.2411  decode.d1.loss_cls: 0.0752  decode.d1.loss_mask: 0.2108  decode.d1.loss_dice: 0.2401  decode.d2.loss_cls: 0.0342  decode.d2.loss_mask: 0.2076  decode.d2.loss_dice: 0.2217  decode.d3.loss_cls: 0.0548  decode.d3.loss_mask: 0.2097  decode.d3.loss_dice: 0.2259  decode.d4.loss_cls: 0.0456  decode.d4.loss_mask: 0.2043  decode.d4.loss_dice: 0.2287  decode.d5.loss_cls: 0.0465  decode.d5.loss_mask: 0.2082  decode.d5.loss_dice: 0.2199  decode.d6.loss_cls: 0.0629  decode.d6.loss_mask: 0.2089  decode.d6.loss_dice: 0.2361  decode.d7.loss_cls: 0.0643  decode.d7.loss_mask: 0.2057  decode.d7.loss_dice: 0.2385  decode.d8.loss_cls: 0.0635  decode.d8.loss_mask: 0.2065  decode.d8.loss_dice: 0.2325
08/06 10:54:27 - mmengine - INFO - Iter(train) [ 62500/320000]  base_lr: 8.2237e-05 lr: 8.2237e-06  eta: 1 day, 11:16:23  time: 0.4954  data_time: 0.0113  memory: 5911  grad_norm: 111.9320  loss: 7.7248  decode.loss_cls: 0.2046  decode.loss_mask: 0.2737  decode.loss_dice: 0.2627  decode.d0.loss_cls: 0.8673  decode.d0.loss_mask: 0.2746  decode.d0.loss_dice: 0.2531  decode.d1.loss_cls: 0.1208  decode.d1.loss_mask: 0.2747  decode.d1.loss_dice: 0.2704  decode.d2.loss_cls: 0.1450  decode.d2.loss_mask: 0.2692  decode.d2.loss_dice: 0.2389  decode.d3.loss_cls: 0.1587  decode.d3.loss_mask: 0.2708  decode.d3.loss_dice: 0.2618  decode.d4.loss_cls: 0.1598  decode.d4.loss_mask: 0.2714  decode.d4.loss_dice: 0.2568  decode.d5.loss_cls: 0.1742  decode.d5.loss_mask: 0.2725  decode.d5.loss_dice: 0.2654  decode.d6.loss_cls: 0.1889  decode.d6.loss_mask: 0.2716  decode.d6.loss_dice: 0.2649  decode.d7.loss_cls: 0.1840  decode.d7.loss_mask: 0.2718  decode.d7.loss_dice: 0.2594  decode.d8.loss_cls: 0.1990  decode.d8.loss_mask: 0.2727  decode.d8.loss_dice: 0.2659
08/06 10:54:52 - mmengine - INFO - Iter(train) [ 62550/320000]  base_lr: 8.2222e-05 lr: 8.2222e-06  eta: 1 day, 11:15:59  time: 0.4958  data_time: 0.0111  memory: 5894  grad_norm: 163.2342  loss: 5.4220  decode.loss_cls: 0.0146  decode.loss_mask: 0.2079  decode.loss_dice: 0.2385  decode.d0.loss_cls: 0.8542  decode.d0.loss_mask: 0.2130  decode.d0.loss_dice: 0.2425  decode.d1.loss_cls: 0.0116  decode.d1.loss_mask: 0.2052  decode.d1.loss_dice: 0.2329  decode.d2.loss_cls: 0.0204  decode.d2.loss_mask: 0.2053  decode.d2.loss_dice: 0.2338  decode.d3.loss_cls: 0.0257  decode.d3.loss_mask: 0.2041  decode.d3.loss_dice: 0.2383  decode.d4.loss_cls: 0.0189  decode.d4.loss_mask: 0.2058  decode.d4.loss_dice: 0.2352  decode.d5.loss_cls: 0.0158  decode.d5.loss_mask: 0.2056  decode.d5.loss_dice: 0.2347  decode.d6.loss_cls: 0.0138  decode.d6.loss_mask: 0.2069  decode.d6.loss_dice: 0.2299  decode.d7.loss_cls: 0.0085  decode.d7.loss_mask: 0.2074  decode.d7.loss_dice: 0.2319  decode.d8.loss_cls: 0.0133  decode.d8.loss_mask: 0.2076  decode.d8.loss_dice: 0.2386
08/06 10:55:17 - mmengine - INFO - Iter(train) [ 62600/320000]  base_lr: 8.2208e-05 lr: 8.2208e-06  eta: 1 day, 11:15:35  time: 0.4946  data_time: 0.0112  memory: 5894  grad_norm: 109.8714  loss: 6.5635  decode.loss_cls: 0.0584  decode.loss_mask: 0.2550  decode.loss_dice: 0.2319  decode.d0.loss_cls: 0.8276  decode.d0.loss_mask: 0.2594  decode.d0.loss_dice: 0.2453  decode.d1.loss_cls: 0.0804  decode.d1.loss_mask: 0.2569  decode.d1.loss_dice: 0.2375  decode.d2.loss_cls: 0.0771  decode.d2.loss_mask: 0.2559  decode.d2.loss_dice: 0.2347  decode.d3.loss_cls: 0.0974  decode.d3.loss_mask: 0.2555  decode.d3.loss_dice: 0.2388  decode.d4.loss_cls: 0.0836  decode.d4.loss_mask: 0.2565  decode.d4.loss_dice: 0.2375  decode.d5.loss_cls: 0.0597  decode.d5.loss_mask: 0.2548  decode.d5.loss_dice: 0.2388  decode.d6.loss_cls: 0.1320  decode.d6.loss_mask: 0.2552  decode.d6.loss_dice: 0.2336  decode.d7.loss_cls: 0.0775  decode.d7.loss_mask: 0.2561  decode.d7.loss_dice: 0.2445  decode.d8.loss_cls: 0.1320  decode.d8.loss_mask: 0.2560  decode.d8.loss_dice: 0.2337
08/06 10:55:42 - mmengine - INFO - Iter(train) [ 62650/320000]  base_lr: 8.2194e-05 lr: 8.2194e-06  eta: 1 day, 11:15:11  time: 0.4947  data_time: 0.0110  memory: 5891  grad_norm: 78.6740  loss: 5.4257  decode.loss_cls: 0.0232  decode.loss_mask: 0.1989  decode.loss_dice: 0.2334  decode.d0.loss_cls: 0.7609  decode.d0.loss_mask: 0.2037  decode.d0.loss_dice: 0.2376  decode.d1.loss_cls: 0.0232  decode.d1.loss_mask: 0.1999  decode.d1.loss_dice: 0.2453  decode.d2.loss_cls: 0.0572  decode.d2.loss_mask: 0.1983  decode.d2.loss_dice: 0.2344  decode.d3.loss_cls: 0.0650  decode.d3.loss_mask: 0.1989  decode.d3.loss_dice: 0.2399  decode.d4.loss_cls: 0.0391  decode.d4.loss_mask: 0.1991  decode.d4.loss_dice: 0.2391  decode.d5.loss_cls: 0.0228  decode.d5.loss_mask: 0.1983  decode.d5.loss_dice: 0.2396  decode.d6.loss_cls: 0.0205  decode.d6.loss_mask: 0.1982  decode.d6.loss_dice: 0.2369  decode.d7.loss_cls: 0.0204  decode.d7.loss_mask: 0.1992  decode.d7.loss_dice: 0.2395  decode.d8.loss_cls: 0.0142  decode.d8.loss_mask: 0.2001  decode.d8.loss_dice: 0.2388
08/06 10:56:06 - mmengine - INFO - Iter(train) [ 62700/320000]  base_lr: 8.2179e-05 lr: 8.2179e-06  eta: 1 day, 11:14:46  time: 0.4954  data_time: 0.0112  memory: 5895  grad_norm: 95.3579  loss: 6.3037  decode.loss_cls: 0.0358  decode.loss_mask: 0.2398  decode.loss_dice: 0.2552  decode.d0.loss_cls: 0.7702  decode.d0.loss_mask: 0.2424  decode.d0.loss_dice: 0.2412  decode.d1.loss_cls: 0.1647  decode.d1.loss_mask: 0.2442  decode.d1.loss_dice: 0.2460  decode.d2.loss_cls: 0.1160  decode.d2.loss_mask: 0.2421  decode.d2.loss_dice: 0.2500  decode.d3.loss_cls: 0.0218  decode.d3.loss_mask: 0.2409  decode.d3.loss_dice: 0.2652  decode.d4.loss_cls: 0.0567  decode.d4.loss_mask: 0.2380  decode.d4.loss_dice: 0.2527  decode.d5.loss_cls: 0.0838  decode.d5.loss_mask: 0.2412  decode.d5.loss_dice: 0.2555  decode.d6.loss_cls: 0.0524  decode.d6.loss_mask: 0.2370  decode.d6.loss_dice: 0.2549  decode.d7.loss_cls: 0.0276  decode.d7.loss_mask: 0.2407  decode.d7.loss_dice: 0.2515  decode.d8.loss_cls: 0.0479  decode.d8.loss_mask: 0.2409  decode.d8.loss_dice: 0.2474
08/06 10:56:31 - mmengine - INFO - Iter(train) [ 62750/320000]  base_lr: 8.2165e-05 lr: 8.2165e-06  eta: 1 day, 11:14:23  time: 0.4955  data_time: 0.0114  memory: 5891  grad_norm: 61.3786  loss: 7.3177  decode.loss_cls: 0.0680  decode.loss_mask: 0.2788  decode.loss_dice: 0.3184  decode.d0.loss_cls: 0.7338  decode.d0.loss_mask: 0.2835  decode.d0.loss_dice: 0.3121  decode.d1.loss_cls: 0.0670  decode.d1.loss_mask: 0.2756  decode.d1.loss_dice: 0.3210  decode.d2.loss_cls: 0.0704  decode.d2.loss_mask: 0.2773  decode.d2.loss_dice: 0.3203  decode.d3.loss_cls: 0.0722  decode.d3.loss_mask: 0.2754  decode.d3.loss_dice: 0.3181  decode.d4.loss_cls: 0.0724  decode.d4.loss_mask: 0.2755  decode.d4.loss_dice: 0.3169  decode.d5.loss_cls: 0.0647  decode.d5.loss_mask: 0.2764  decode.d5.loss_dice: 0.3209  decode.d6.loss_cls: 0.0706  decode.d6.loss_mask: 0.2758  decode.d6.loss_dice: 0.3209  decode.d7.loss_cls: 0.0714  decode.d7.loss_mask: 0.2771  decode.d7.loss_dice: 0.3193  decode.d8.loss_cls: 0.0707  decode.d8.loss_mask: 0.2767  decode.d8.loss_dice: 0.3166
08/06 10:56:56 - mmengine - INFO - Iter(train) [ 62800/320000]  base_lr: 8.2150e-05 lr: 8.2150e-06  eta: 1 day, 11:13:59  time: 0.4959  data_time: 0.0114  memory: 5878  grad_norm: 63.6072  loss: 5.6330  decode.loss_cls: 0.0768  decode.loss_mask: 0.2000  decode.loss_dice: 0.1987  decode.d0.loss_cls: 0.8857  decode.d0.loss_mask: 0.1991  decode.d0.loss_dice: 0.1990  decode.d1.loss_cls: 0.0922  decode.d1.loss_mask: 0.1996  decode.d1.loss_dice: 0.1908  decode.d2.loss_cls: 0.1046  decode.d2.loss_mask: 0.2010  decode.d2.loss_dice: 0.1993  decode.d3.loss_cls: 0.1075  decode.d3.loss_mask: 0.1988  decode.d3.loss_dice: 0.1993  decode.d4.loss_cls: 0.0971  decode.d4.loss_mask: 0.1965  decode.d4.loss_dice: 0.1928  decode.d5.loss_cls: 0.0943  decode.d5.loss_mask: 0.1972  decode.d5.loss_dice: 0.1980  decode.d6.loss_cls: 0.0642  decode.d6.loss_mask: 0.1991  decode.d6.loss_dice: 0.1946  decode.d7.loss_cls: 0.0867  decode.d7.loss_mask: 0.1985  decode.d7.loss_dice: 0.2155  decode.d8.loss_cls: 0.0540  decode.d8.loss_mask: 0.1949  decode.d8.loss_dice: 0.1970
08/06 10:57:21 - mmengine - INFO - Iter(train) [ 62850/320000]  base_lr: 8.2136e-05 lr: 8.2136e-06  eta: 1 day, 11:13:35  time: 0.4944  data_time: 0.0111  memory: 5911  grad_norm: 122.3388  loss: 6.8102  decode.loss_cls: 0.0861  decode.loss_mask: 0.2757  decode.loss_dice: 0.2346  decode.d0.loss_cls: 0.8305  decode.d0.loss_mask: 0.2719  decode.d0.loss_dice: 0.2644  decode.d1.loss_cls: 0.1484  decode.d1.loss_mask: 0.2609  decode.d1.loss_dice: 0.2238  decode.d2.loss_cls: 0.0849  decode.d2.loss_mask: 0.2726  decode.d2.loss_dice: 0.2598  decode.d3.loss_cls: 0.0732  decode.d3.loss_mask: 0.2684  decode.d3.loss_dice: 0.2463  decode.d4.loss_cls: 0.0835  decode.d4.loss_mask: 0.2759  decode.d4.loss_dice: 0.2481  decode.d5.loss_cls: 0.0853  decode.d5.loss_mask: 0.2744  decode.d5.loss_dice: 0.2466  decode.d6.loss_cls: 0.0767  decode.d6.loss_mask: 0.2634  decode.d6.loss_dice: 0.2310  decode.d7.loss_cls: 0.1058  decode.d7.loss_mask: 0.2668  decode.d7.loss_dice: 0.2296  decode.d8.loss_cls: 0.1020  decode.d8.loss_mask: 0.2732  decode.d8.loss_dice: 0.2465
08/06 10:57:46 - mmengine - INFO - Iter(train) [ 62900/320000]  base_lr: 8.2122e-05 lr: 8.2122e-06  eta: 1 day, 11:13:10  time: 0.4951  data_time: 0.0113  memory: 5911  grad_norm: 108.2526  loss: 7.1230  decode.loss_cls: 0.1750  decode.loss_mask: 0.2833  decode.loss_dice: 0.2529  decode.d0.loss_cls: 0.8302  decode.d0.loss_mask: 0.2902  decode.d0.loss_dice: 0.2464  decode.d1.loss_cls: 0.1275  decode.d1.loss_mask: 0.2827  decode.d1.loss_dice: 0.2495  decode.d2.loss_cls: 0.1282  decode.d2.loss_mask: 0.2849  decode.d2.loss_dice: 0.2559  decode.d3.loss_cls: 0.1186  decode.d3.loss_mask: 0.2833  decode.d3.loss_dice: 0.2498  decode.d4.loss_cls: 0.0698  decode.d4.loss_mask: 0.2863  decode.d4.loss_dice: 0.2526  decode.d5.loss_cls: 0.0658  decode.d5.loss_mask: 0.2882  decode.d5.loss_dice: 0.2480  decode.d6.loss_cls: 0.0912  decode.d6.loss_mask: 0.2886  decode.d6.loss_dice: 0.2504  decode.d7.loss_cls: 0.0794  decode.d7.loss_mask: 0.2891  decode.d7.loss_dice: 0.2291  decode.d8.loss_cls: 0.0937  decode.d8.loss_mask: 0.2863  decode.d8.loss_dice: 0.2462
08/06 10:58:11 - mmengine - INFO - Iter(train) [ 62950/320000]  base_lr: 8.2107e-05 lr: 8.2107e-06  eta: 1 day, 11:12:46  time: 0.4949  data_time: 0.0112  memory: 5911  grad_norm: 101.7221  loss: 6.7692  decode.loss_cls: 0.1156  decode.loss_mask: 0.2427  decode.loss_dice: 0.2451  decode.d0.loss_cls: 0.8146  decode.d0.loss_mask: 0.2532  decode.d0.loss_dice: 0.2546  decode.d1.loss_cls: 0.1284  decode.d1.loss_mask: 0.2437  decode.d1.loss_dice: 0.2588  decode.d2.loss_cls: 0.0900  decode.d2.loss_mask: 0.2403  decode.d2.loss_dice: 0.2448  decode.d3.loss_cls: 0.0934  decode.d3.loss_mask: 0.2408  decode.d3.loss_dice: 0.2592  decode.d4.loss_cls: 0.0812  decode.d4.loss_mask: 0.2419  decode.d4.loss_dice: 0.2426  decode.d5.loss_cls: 0.1147  decode.d5.loss_mask: 0.2445  decode.d5.loss_dice: 0.2439  decode.d6.loss_cls: 0.1422  decode.d6.loss_mask: 0.2413  decode.d6.loss_dice: 0.2447  decode.d7.loss_cls: 0.1274  decode.d7.loss_mask: 0.2446  decode.d7.loss_dice: 0.2547  decode.d8.loss_cls: 0.1226  decode.d8.loss_mask: 0.2446  decode.d8.loss_dice: 0.2531
08/06 10:58:35 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 10:58:35 - mmengine - INFO - Iter(train) [ 63000/320000]  base_lr: 8.2093e-05 lr: 8.2093e-06  eta: 1 day, 11:12:22  time: 0.4955  data_time: 0.0113  memory: 5874  grad_norm: 168.2910  loss: 7.6127  decode.loss_cls: 0.1296  decode.loss_mask: 0.2957  decode.loss_dice: 0.2857  decode.d0.loss_cls: 0.9966  decode.d0.loss_mask: 0.3009  decode.d0.loss_dice: 0.3020  decode.d1.loss_cls: 0.1077  decode.d1.loss_mask: 0.3010  decode.d1.loss_dice: 0.2979  decode.d2.loss_cls: 0.0936  decode.d2.loss_mask: 0.2976  decode.d2.loss_dice: 0.2865  decode.d3.loss_cls: 0.0949  decode.d3.loss_mask: 0.2988  decode.d3.loss_dice: 0.2946  decode.d4.loss_cls: 0.0607  decode.d4.loss_mask: 0.2962  decode.d4.loss_dice: 0.2896  decode.d5.loss_cls: 0.0521  decode.d5.loss_mask: 0.2960  decode.d5.loss_dice: 0.2962  decode.d6.loss_cls: 0.0505  decode.d6.loss_mask: 0.2940  decode.d6.loss_dice: 0.2867  decode.d7.loss_cls: 0.0584  decode.d7.loss_mask: 0.2978  decode.d7.loss_dice: 0.2889  decode.d8.loss_cls: 0.0872  decode.d8.loss_mask: 0.2963  decode.d8.loss_dice: 0.2789
08/06 10:59:00 - mmengine - INFO - Iter(train) [ 63050/320000]  base_lr: 8.2079e-05 lr: 8.2079e-06  eta: 1 day, 11:11:59  time: 0.4959  data_time: 0.0114  memory: 5894  grad_norm: 166.1581  loss: 8.3644  decode.loss_cls: 0.2021  decode.loss_mask: 0.2229  decode.loss_dice: 0.2913  decode.d0.loss_cls: 1.0325  decode.d0.loss_mask: 0.2296  decode.d0.loss_dice: 0.3132  decode.d1.loss_cls: 0.2450  decode.d1.loss_mask: 0.2262  decode.d1.loss_dice: 0.2759  decode.d2.loss_cls: 0.3085  decode.d2.loss_mask: 0.2285  decode.d2.loss_dice: 0.3022  decode.d3.loss_cls: 0.2625  decode.d3.loss_mask: 0.2234  decode.d3.loss_dice: 0.2748  decode.d4.loss_cls: 0.2662  decode.d4.loss_mask: 0.2248  decode.d4.loss_dice: 0.2782  decode.d5.loss_cls: 0.2404  decode.d5.loss_mask: 0.2264  decode.d5.loss_dice: 0.2863  decode.d6.loss_cls: 0.2207  decode.d6.loss_mask: 0.2224  decode.d6.loss_dice: 0.3083  decode.d7.loss_cls: 0.2044  decode.d7.loss_mask: 0.2236  decode.d7.loss_dice: 0.3031  decode.d8.loss_cls: 0.1955  decode.d8.loss_mask: 0.2240  decode.d8.loss_dice: 0.3015
08/06 10:59:25 - mmengine - INFO - Iter(train) [ 63100/320000]  base_lr: 8.2064e-05 lr: 8.2064e-06  eta: 1 day, 11:11:35  time: 0.4949  data_time: 0.0112  memory: 5876  grad_norm: 99.8427  loss: 6.1459  decode.loss_cls: 0.0735  decode.loss_mask: 0.2218  decode.loss_dice: 0.2260  decode.d0.loss_cls: 0.8484  decode.d0.loss_mask: 0.2249  decode.d0.loss_dice: 0.2311  decode.d1.loss_cls: 0.0709  decode.d1.loss_mask: 0.2206  decode.d1.loss_dice: 0.2310  decode.d2.loss_cls: 0.0488  decode.d2.loss_mask: 0.2226  decode.d2.loss_dice: 0.2421  decode.d3.loss_cls: 0.0690  decode.d3.loss_mask: 0.2250  decode.d3.loss_dice: 0.2304  decode.d4.loss_cls: 0.0813  decode.d4.loss_mask: 0.2230  decode.d4.loss_dice: 0.2230  decode.d5.loss_cls: 0.0938  decode.d5.loss_mask: 0.2237  decode.d5.loss_dice: 0.2383  decode.d6.loss_cls: 0.1127  decode.d6.loss_mask: 0.2256  decode.d6.loss_dice: 0.2316  decode.d7.loss_cls: 0.0860  decode.d7.loss_mask: 0.2222  decode.d7.loss_dice: 0.2449  decode.d8.loss_cls: 0.0825  decode.d8.loss_mask: 0.2234  decode.d8.loss_dice: 0.2479
08/06 10:59:50 - mmengine - INFO - Iter(train) [ 63150/320000]  base_lr: 8.2050e-05 lr: 8.2050e-06  eta: 1 day, 11:11:11  time: 0.4948  data_time: 0.0115  memory: 5891  grad_norm: 84.1094  loss: 7.9991  decode.loss_cls: 0.1478  decode.loss_mask: 0.2645  decode.loss_dice: 0.2909  decode.d0.loss_cls: 0.7964  decode.d0.loss_mask: 0.2730  decode.d0.loss_dice: 0.2762  decode.d1.loss_cls: 0.2274  decode.d1.loss_mask: 0.2655  decode.d1.loss_dice: 0.2773  decode.d2.loss_cls: 0.2230  decode.d2.loss_mask: 0.2633  decode.d2.loss_dice: 0.2722  decode.d3.loss_cls: 0.1999  decode.d3.loss_mask: 0.2685  decode.d3.loss_dice: 0.2718  decode.d4.loss_cls: 0.2095  decode.d4.loss_mask: 0.2645  decode.d4.loss_dice: 0.2602  decode.d5.loss_cls: 0.1993  decode.d5.loss_mask: 0.2662  decode.d5.loss_dice: 0.2922  decode.d6.loss_cls: 0.1987  decode.d6.loss_mask: 0.2638  decode.d6.loss_dice: 0.2675  decode.d7.loss_cls: 0.1678  decode.d7.loss_mask: 0.2606  decode.d7.loss_dice: 0.2828  decode.d8.loss_cls: 0.1910  decode.d8.loss_mask: 0.2629  decode.d8.loss_dice: 0.2944
08/06 11:00:15 - mmengine - INFO - Iter(train) [ 63200/320000]  base_lr: 8.2035e-05 lr: 8.2035e-06  eta: 1 day, 11:10:47  time: 0.4953  data_time: 0.0113  memory: 5876  grad_norm: 102.8138  loss: 6.7153  decode.loss_cls: 0.1052  decode.loss_mask: 0.1957  decode.loss_dice: 0.2766  decode.d0.loss_cls: 0.8481  decode.d0.loss_mask: 0.1993  decode.d0.loss_dice: 0.3022  decode.d1.loss_cls: 0.1041  decode.d1.loss_mask: 0.1973  decode.d1.loss_dice: 0.2847  decode.d2.loss_cls: 0.1076  decode.d2.loss_mask: 0.1981  decode.d2.loss_dice: 0.2854  decode.d3.loss_cls: 0.1101  decode.d3.loss_mask: 0.1970  decode.d3.loss_dice: 0.2846  decode.d4.loss_cls: 0.1259  decode.d4.loss_mask: 0.1991  decode.d4.loss_dice: 0.2872  decode.d5.loss_cls: 0.1404  decode.d5.loss_mask: 0.1985  decode.d5.loss_dice: 0.2856  decode.d6.loss_cls: 0.1323  decode.d6.loss_mask: 0.1956  decode.d6.loss_dice: 0.2623  decode.d7.loss_cls: 0.1096  decode.d7.loss_mask: 0.1972  decode.d7.loss_dice: 0.2695  decode.d8.loss_cls: 0.1420  decode.d8.loss_mask: 0.1969  decode.d8.loss_dice: 0.2774
08/06 11:00:39 - mmengine - INFO - Iter(train) [ 63250/320000]  base_lr: 8.2021e-05 lr: 8.2021e-06  eta: 1 day, 11:10:22  time: 0.4954  data_time: 0.0114  memory: 5911  grad_norm: 74.8730  loss: 6.0042  decode.loss_cls: 0.0245  decode.loss_mask: 0.2299  decode.loss_dice: 0.2465  decode.d0.loss_cls: 0.8678  decode.d0.loss_mask: 0.2335  decode.d0.loss_dice: 0.2782  decode.d1.loss_cls: 0.0378  decode.d1.loss_mask: 0.2297  decode.d1.loss_dice: 0.2526  decode.d2.loss_cls: 0.0450  decode.d2.loss_mask: 0.2373  decode.d2.loss_dice: 0.2644  decode.d3.loss_cls: 0.0235  decode.d3.loss_mask: 0.2279  decode.d3.loss_dice: 0.2456  decode.d4.loss_cls: 0.0354  decode.d4.loss_mask: 0.2226  decode.d4.loss_dice: 0.2489  decode.d5.loss_cls: 0.0315  decode.d5.loss_mask: 0.2284  decode.d5.loss_dice: 0.2493  decode.d6.loss_cls: 0.0336  decode.d6.loss_mask: 0.2298  decode.d6.loss_dice: 0.2632  decode.d7.loss_cls: 0.0326  decode.d7.loss_mask: 0.2309  decode.d7.loss_dice: 0.2515  decode.d8.loss_cls: 0.0254  decode.d8.loss_mask: 0.2309  decode.d8.loss_dice: 0.2459
08/06 11:01:04 - mmengine - INFO - Iter(train) [ 63300/320000]  base_lr: 8.2007e-05 lr: 8.2007e-06  eta: 1 day, 11:09:58  time: 0.4952  data_time: 0.0113  memory: 5875  grad_norm: 127.5811  loss: 5.3306  decode.loss_cls: 0.1126  decode.loss_mask: 0.1715  decode.loss_dice: 0.2079  decode.d0.loss_cls: 0.8222  decode.d0.loss_mask: 0.1740  decode.d0.loss_dice: 0.2195  decode.d1.loss_cls: 0.0514  decode.d1.loss_mask: 0.1748  decode.d1.loss_dice: 0.2138  decode.d2.loss_cls: 0.0603  decode.d2.loss_mask: 0.1717  decode.d2.loss_dice: 0.1991  decode.d3.loss_cls: 0.1287  decode.d3.loss_mask: 0.1724  decode.d3.loss_dice: 0.2089  decode.d4.loss_cls: 0.1095  decode.d4.loss_mask: 0.1733  decode.d4.loss_dice: 0.2111  decode.d5.loss_cls: 0.0536  decode.d5.loss_mask: 0.1725  decode.d5.loss_dice: 0.2045  decode.d6.loss_cls: 0.0451  decode.d6.loss_mask: 0.1737  decode.d6.loss_dice: 0.2162  decode.d7.loss_cls: 0.0730  decode.d7.loss_mask: 0.1713  decode.d7.loss_dice: 0.2160  decode.d8.loss_cls: 0.0380  decode.d8.loss_mask: 0.1729  decode.d8.loss_dice: 0.2112
08/06 11:01:29 - mmengine - INFO - Iter(train) [ 63350/320000]  base_lr: 8.1992e-05 lr: 8.1992e-06  eta: 1 day, 11:09:34  time: 0.4960  data_time: 0.0111  memory: 5911  grad_norm: 65.4240  loss: 6.3604  decode.loss_cls: 0.1018  decode.loss_mask: 0.2089  decode.loss_dice: 0.2607  decode.d0.loss_cls: 0.7453  decode.d0.loss_mask: 0.2132  decode.d0.loss_dice: 0.2739  decode.d1.loss_cls: 0.0774  decode.d1.loss_mask: 0.2074  decode.d1.loss_dice: 0.2533  decode.d2.loss_cls: 0.0909  decode.d2.loss_mask: 0.2068  decode.d2.loss_dice: 0.2568  decode.d3.loss_cls: 0.0974  decode.d3.loss_mask: 0.2082  decode.d3.loss_dice: 0.2629  decode.d4.loss_cls: 0.1135  decode.d4.loss_mask: 0.2082  decode.d4.loss_dice: 0.2630  decode.d5.loss_cls: 0.0889  decode.d5.loss_mask: 0.2079  decode.d5.loss_dice: 0.2740  decode.d6.loss_cls: 0.1162  decode.d6.loss_mask: 0.2064  decode.d6.loss_dice: 0.2615  decode.d7.loss_cls: 0.0818  decode.d7.loss_mask: 0.2067  decode.d7.loss_dice: 0.2664  decode.d8.loss_cls: 0.1206  decode.d8.loss_mask: 0.2102  decode.d8.loss_dice: 0.2703
08/06 11:01:54 - mmengine - INFO - Iter(train) [ 63400/320000]  base_lr: 8.1978e-05 lr: 8.1978e-06  eta: 1 day, 11:09:10  time: 0.4959  data_time: 0.0114  memory: 5891  grad_norm: 69.9823  loss: 7.9891  decode.loss_cls: 0.1572  decode.loss_mask: 0.2421  decode.loss_dice: 0.3214  decode.d0.loss_cls: 0.8780  decode.d0.loss_mask: 0.2456  decode.d0.loss_dice: 0.3313  decode.d1.loss_cls: 0.1718  decode.d1.loss_mask: 0.2432  decode.d1.loss_dice: 0.3171  decode.d2.loss_cls: 0.1417  decode.d2.loss_mask: 0.2397  decode.d2.loss_dice: 0.3345  decode.d3.loss_cls: 0.1795  decode.d3.loss_mask: 0.2428  decode.d3.loss_dice: 0.3364  decode.d4.loss_cls: 0.1946  decode.d4.loss_mask: 0.2391  decode.d4.loss_dice: 0.3306  decode.d5.loss_cls: 0.1331  decode.d5.loss_mask: 0.2408  decode.d5.loss_dice: 0.3241  decode.d6.loss_cls: 0.1688  decode.d6.loss_mask: 0.2422  decode.d6.loss_dice: 0.3075  decode.d7.loss_cls: 0.1567  decode.d7.loss_mask: 0.2426  decode.d7.loss_dice: 0.3273  decode.d8.loss_cls: 0.1539  decode.d8.loss_mask: 0.2413  decode.d8.loss_dice: 0.3040
08/06 11:02:19 - mmengine - INFO - Iter(train) [ 63450/320000]  base_lr: 8.1964e-05 lr: 8.1964e-06  eta: 1 day, 11:08:46  time: 0.4968  data_time: 0.0112  memory: 5911  grad_norm: 50.5050  loss: 5.8820  decode.loss_cls: 0.0254  decode.loss_mask: 0.2652  decode.loss_dice: 0.2314  decode.d0.loss_cls: 0.6823  decode.d0.loss_mask: 0.2699  decode.d0.loss_dice: 0.2295  decode.d1.loss_cls: 0.0374  decode.d1.loss_mask: 0.2657  decode.d1.loss_dice: 0.2286  decode.d2.loss_cls: 0.0291  decode.d2.loss_mask: 0.2697  decode.d2.loss_dice: 0.2328  decode.d3.loss_cls: 0.0373  decode.d3.loss_mask: 0.2647  decode.d3.loss_dice: 0.2284  decode.d4.loss_cls: 0.0256  decode.d4.loss_mask: 0.2660  decode.d4.loss_dice: 0.2326  decode.d5.loss_cls: 0.0234  decode.d5.loss_mask: 0.2666  decode.d5.loss_dice: 0.2273  decode.d6.loss_cls: 0.0162  decode.d6.loss_mask: 0.2662  decode.d6.loss_dice: 0.2309  decode.d7.loss_cls: 0.0146  decode.d7.loss_mask: 0.2617  decode.d7.loss_dice: 0.2294  decode.d8.loss_cls: 0.0283  decode.d8.loss_mask: 0.2647  decode.d8.loss_dice: 0.2311
08/06 11:02:43 - mmengine - INFO - Iter(train) [ 63500/320000]  base_lr: 8.1949e-05 lr: 8.1949e-06  eta: 1 day, 11:08:22  time: 0.4957  data_time: 0.0115  memory: 5911  grad_norm: 73.7326  loss: 7.1568  decode.loss_cls: 0.0922  decode.loss_mask: 0.2397  decode.loss_dice: 0.2961  decode.d0.loss_cls: 0.8955  decode.d0.loss_mask: 0.2365  decode.d0.loss_dice: 0.2961  decode.d1.loss_cls: 0.1141  decode.d1.loss_mask: 0.2368  decode.d1.loss_dice: 0.2784  decode.d2.loss_cls: 0.0977  decode.d2.loss_mask: 0.2366  decode.d2.loss_dice: 0.2803  decode.d3.loss_cls: 0.1157  decode.d3.loss_mask: 0.2347  decode.d3.loss_dice: 0.2732  decode.d4.loss_cls: 0.1357  decode.d4.loss_mask: 0.2389  decode.d4.loss_dice: 0.2908  decode.d5.loss_cls: 0.1120  decode.d5.loss_mask: 0.2358  decode.d5.loss_dice: 0.2890  decode.d6.loss_cls: 0.1175  decode.d6.loss_mask: 0.2372  decode.d6.loss_dice: 0.2998  decode.d7.loss_cls: 0.1038  decode.d7.loss_mask: 0.2383  decode.d7.loss_dice: 0.2934  decode.d8.loss_cls: 0.1046  decode.d8.loss_mask: 0.2398  decode.d8.loss_dice: 0.2966
08/06 11:03:08 - mmengine - INFO - Iter(train) [ 63550/320000]  base_lr: 8.1935e-05 lr: 8.1935e-06  eta: 1 day, 11:07:57  time: 0.4943  data_time: 0.0112  memory: 5874  grad_norm: 110.5428  loss: 7.3402  decode.loss_cls: 0.1321  decode.loss_mask: 0.2479  decode.loss_dice: 0.2712  decode.d0.loss_cls: 0.7770  decode.d0.loss_mask: 0.2647  decode.d0.loss_dice: 0.2779  decode.d1.loss_cls: 0.1389  decode.d1.loss_mask: 0.2447  decode.d1.loss_dice: 0.2744  decode.d2.loss_cls: 0.1118  decode.d2.loss_mask: 0.2441  decode.d2.loss_dice: 0.3036  decode.d3.loss_cls: 0.1370  decode.d3.loss_mask: 0.2424  decode.d3.loss_dice: 0.2530  decode.d4.loss_cls: 0.1405  decode.d4.loss_mask: 0.2431  decode.d4.loss_dice: 0.2806  decode.d5.loss_cls: 0.1875  decode.d5.loss_mask: 0.2456  decode.d5.loss_dice: 0.2855  decode.d6.loss_cls: 0.1261  decode.d6.loss_mask: 0.2438  decode.d6.loss_dice: 0.3017  decode.d7.loss_cls: 0.1721  decode.d7.loss_mask: 0.2445  decode.d7.loss_dice: 0.2803  decode.d8.loss_cls: 0.1713  decode.d8.loss_mask: 0.2407  decode.d8.loss_dice: 0.2562
08/06 11:03:33 - mmengine - INFO - Iter(train) [ 63600/320000]  base_lr: 8.1920e-05 lr: 8.1920e-06  eta: 1 day, 11:07:33  time: 0.4964  data_time: 0.0115  memory: 5928  grad_norm: 95.5379  loss: 7.1161  decode.loss_cls: 0.1022  decode.loss_mask: 0.2489  decode.loss_dice: 0.2449  decode.d0.loss_cls: 0.9370  decode.d0.loss_mask: 0.2484  decode.d0.loss_dice: 0.2621  decode.d1.loss_cls: 0.1325  decode.d1.loss_mask: 0.2419  decode.d1.loss_dice: 0.2556  decode.d2.loss_cls: 0.1343  decode.d2.loss_mask: 0.2444  decode.d2.loss_dice: 0.2483  decode.d3.loss_cls: 0.1272  decode.d3.loss_mask: 0.2415  decode.d3.loss_dice: 0.2500  decode.d4.loss_cls: 0.1575  decode.d4.loss_mask: 0.2442  decode.d4.loss_dice: 0.2498  decode.d5.loss_cls: 0.1494  decode.d5.loss_mask: 0.2433  decode.d5.loss_dice: 0.2461  decode.d6.loss_cls: 0.1512  decode.d6.loss_mask: 0.2535  decode.d6.loss_dice: 0.2528  decode.d7.loss_cls: 0.1160  decode.d7.loss_mask: 0.2474  decode.d7.loss_dice: 0.2450  decode.d8.loss_cls: 0.1189  decode.d8.loss_mask: 0.2605  decode.d8.loss_dice: 0.2612
08/06 11:03:58 - mmengine - INFO - Iter(train) [ 63650/320000]  base_lr: 8.1906e-05 lr: 8.1906e-06  eta: 1 day, 11:07:10  time: 0.4966  data_time: 0.0116  memory: 5909  grad_norm: 225.9459  loss: 9.4328  decode.loss_cls: 0.1924  decode.loss_mask: 0.3255  decode.loss_dice: 0.3432  decode.d0.loss_cls: 0.9456  decode.d0.loss_mask: 0.3218  decode.d0.loss_dice: 0.3212  decode.d1.loss_cls: 0.2401  decode.d1.loss_mask: 0.3173  decode.d1.loss_dice: 0.3300  decode.d2.loss_cls: 0.2069  decode.d2.loss_mask: 0.3261  decode.d2.loss_dice: 0.3419  decode.d3.loss_cls: 0.1871  decode.d3.loss_mask: 0.3263  decode.d3.loss_dice: 0.3372  decode.d4.loss_cls: 0.2224  decode.d4.loss_mask: 0.3311  decode.d4.loss_dice: 0.3495  decode.d5.loss_cls: 0.2018  decode.d5.loss_mask: 0.3267  decode.d5.loss_dice: 0.3430  decode.d6.loss_cls: 0.1780  decode.d6.loss_mask: 0.3249  decode.d6.loss_dice: 0.3524  decode.d7.loss_cls: 0.2337  decode.d7.loss_mask: 0.3194  decode.d7.loss_dice: 0.3276  decode.d8.loss_cls: 0.2189  decode.d8.loss_mask: 0.3203  decode.d8.loss_dice: 0.3206
08/06 11:04:23 - mmengine - INFO - Iter(train) [ 63700/320000]  base_lr: 8.1892e-05 lr: 8.1892e-06  eta: 1 day, 11:06:46  time: 0.4965  data_time: 0.0113  memory: 5913  grad_norm: 161.8209  loss: 9.6796  decode.loss_cls: 0.3249  decode.loss_mask: 0.2877  decode.loss_dice: 0.3322  decode.d0.loss_cls: 0.9720  decode.d0.loss_mask: 0.2864  decode.d0.loss_dice: 0.3654  decode.d1.loss_cls: 0.2232  decode.d1.loss_mask: 0.2856  decode.d1.loss_dice: 0.3417  decode.d2.loss_cls: 0.3496  decode.d2.loss_mask: 0.2869  decode.d2.loss_dice: 0.3351  decode.d3.loss_cls: 0.2793  decode.d3.loss_mask: 0.2856  decode.d3.loss_dice: 0.3290  decode.d4.loss_cls: 0.2690  decode.d4.loss_mask: 0.2893  decode.d4.loss_dice: 0.3412  decode.d5.loss_cls: 0.2198  decode.d5.loss_mask: 0.2866  decode.d5.loss_dice: 0.3515  decode.d6.loss_cls: 0.3073  decode.d6.loss_mask: 0.2834  decode.d6.loss_dice: 0.3449  decode.d7.loss_cls: 0.2455  decode.d7.loss_mask: 0.2862  decode.d7.loss_dice: 0.3204  decode.d8.loss_cls: 0.2342  decode.d8.loss_mask: 0.2887  decode.d8.loss_dice: 0.3272
08/06 11:04:48 - mmengine - INFO - Iter(train) [ 63750/320000]  base_lr: 8.1877e-05 lr: 8.1877e-06  eta: 1 day, 11:06:22  time: 0.4957  data_time: 0.0113  memory: 5911  grad_norm: 67.2557  loss: 5.9203  decode.loss_cls: 0.0176  decode.loss_mask: 0.2405  decode.loss_dice: 0.2442  decode.d0.loss_cls: 0.9176  decode.d0.loss_mask: 0.2449  decode.d0.loss_dice: 0.2381  decode.d1.loss_cls: 0.0202  decode.d1.loss_mask: 0.2415  decode.d1.loss_dice: 0.2458  decode.d2.loss_cls: 0.0168  decode.d2.loss_mask: 0.2390  decode.d2.loss_dice: 0.2357  decode.d3.loss_cls: 0.0365  decode.d3.loss_mask: 0.2403  decode.d3.loss_dice: 0.2629  decode.d4.loss_cls: 0.0192  decode.d4.loss_mask: 0.2419  decode.d4.loss_dice: 0.2325  decode.d5.loss_cls: 0.0249  decode.d5.loss_mask: 0.2394  decode.d5.loss_dice: 0.2317  decode.d6.loss_cls: 0.0218  decode.d6.loss_mask: 0.2402  decode.d6.loss_dice: 0.2311  decode.d7.loss_cls: 0.0165  decode.d7.loss_mask: 0.2429  decode.d7.loss_dice: 0.2330  decode.d8.loss_cls: 0.0167  decode.d8.loss_mask: 0.2418  decode.d8.loss_dice: 0.2452
08/06 11:05:12 - mmengine - INFO - Iter(train) [ 63800/320000]  base_lr: 8.1863e-05 lr: 8.1863e-06  eta: 1 day, 11:05:58  time: 0.4963  data_time: 0.0114  memory: 5911  grad_norm: 133.8310  loss: 6.9057  decode.loss_cls: 0.1097  decode.loss_mask: 0.2181  decode.loss_dice: 0.2642  decode.d0.loss_cls: 0.9233  decode.d0.loss_mask: 0.2142  decode.d0.loss_dice: 0.2761  decode.d1.loss_cls: 0.1142  decode.d1.loss_mask: 0.2133  decode.d1.loss_dice: 0.3012  decode.d2.loss_cls: 0.1141  decode.d2.loss_mask: 0.2158  decode.d2.loss_dice: 0.2994  decode.d3.loss_cls: 0.1025  decode.d3.loss_mask: 0.2146  decode.d3.loss_dice: 0.3020  decode.d4.loss_cls: 0.1078  decode.d4.loss_mask: 0.2145  decode.d4.loss_dice: 0.2897  decode.d5.loss_cls: 0.0654  decode.d5.loss_mask: 0.2164  decode.d5.loss_dice: 0.2777  decode.d6.loss_cls: 0.1039  decode.d6.loss_mask: 0.2161  decode.d6.loss_dice: 0.2659  decode.d7.loss_cls: 0.1349  decode.d7.loss_mask: 0.2212  decode.d7.loss_dice: 0.2918  decode.d8.loss_cls: 0.1321  decode.d8.loss_mask: 0.2206  decode.d8.loss_dice: 0.2652
08/06 11:05:37 - mmengine - INFO - Iter(train) [ 63850/320000]  base_lr: 8.1849e-05 lr: 8.1849e-06  eta: 1 day, 11:05:34  time: 0.4955  data_time: 0.0114  memory: 5895  grad_norm: 88.3293  loss: 6.0301  decode.loss_cls: 0.0316  decode.loss_mask: 0.2508  decode.loss_dice: 0.2314  decode.d0.loss_cls: 0.7609  decode.d0.loss_mask: 0.2578  decode.d0.loss_dice: 0.2379  decode.d1.loss_cls: 0.0520  decode.d1.loss_mask: 0.2564  decode.d1.loss_dice: 0.2476  decode.d2.loss_cls: 0.0294  decode.d2.loss_mask: 0.2559  decode.d2.loss_dice: 0.2512  decode.d3.loss_cls: 0.0554  decode.d3.loss_mask: 0.2533  decode.d3.loss_dice: 0.2339  decode.d4.loss_cls: 0.0350  decode.d4.loss_mask: 0.2542  decode.d4.loss_dice: 0.2423  decode.d5.loss_cls: 0.0378  decode.d5.loss_mask: 0.2559  decode.d5.loss_dice: 0.2456  decode.d6.loss_cls: 0.0272  decode.d6.loss_mask: 0.2513  decode.d6.loss_dice: 0.2342  decode.d7.loss_cls: 0.0231  decode.d7.loss_mask: 0.2550  decode.d7.loss_dice: 0.2373  decode.d8.loss_cls: 0.0317  decode.d8.loss_mask: 0.2576  decode.d8.loss_dice: 0.2364
08/06 11:06:02 - mmengine - INFO - Iter(train) [ 63900/320000]  base_lr: 8.1834e-05 lr: 8.1834e-06  eta: 1 day, 11:05:10  time: 0.4955  data_time: 0.0112  memory: 5913  grad_norm: 130.7458  loss: 9.0285  decode.loss_cls: 0.2805  decode.loss_mask: 0.2369  decode.loss_dice: 0.3115  decode.d0.loss_cls: 0.9603  decode.d0.loss_mask: 0.2384  decode.d0.loss_dice: 0.3083  decode.d1.loss_cls: 0.3443  decode.d1.loss_mask: 0.2439  decode.d1.loss_dice: 0.2949  decode.d2.loss_cls: 0.2958  decode.d2.loss_mask: 0.2360  decode.d2.loss_dice: 0.2985  decode.d3.loss_cls: 0.2994  decode.d3.loss_mask: 0.2339  decode.d3.loss_dice: 0.3233  decode.d4.loss_cls: 0.3236  decode.d4.loss_mask: 0.2368  decode.d4.loss_dice: 0.3021  decode.d5.loss_cls: 0.3115  decode.d5.loss_mask: 0.2332  decode.d5.loss_dice: 0.3178  decode.d6.loss_cls: 0.2813  decode.d6.loss_mask: 0.2348  decode.d6.loss_dice: 0.3056  decode.d7.loss_cls: 0.2536  decode.d7.loss_mask: 0.2343  decode.d7.loss_dice: 0.2864  decode.d8.loss_cls: 0.2575  decode.d8.loss_mask: 0.2367  decode.d8.loss_dice: 0.3076
08/06 11:06:27 - mmengine - INFO - Iter(train) [ 63950/320000]  base_lr: 8.1820e-05 lr: 8.1820e-06  eta: 1 day, 11:04:45  time: 0.4954  data_time: 0.0112  memory: 5894  grad_norm: 150.2935  loss: 5.4702  decode.loss_cls: 0.0644  decode.loss_mask: 0.1919  decode.loss_dice: 0.2364  decode.d0.loss_cls: 0.8148  decode.d0.loss_mask: 0.1830  decode.d0.loss_dice: 0.2046  decode.d1.loss_cls: 0.0751  decode.d1.loss_mask: 0.1895  decode.d1.loss_dice: 0.2282  decode.d2.loss_cls: 0.0358  decode.d2.loss_mask: 0.1875  decode.d2.loss_dice: 0.2222  decode.d3.loss_cls: 0.0715  decode.d3.loss_mask: 0.1853  decode.d3.loss_dice: 0.2179  decode.d4.loss_cls: 0.0583  decode.d4.loss_mask: 0.1858  decode.d4.loss_dice: 0.2187  decode.d5.loss_cls: 0.0592  decode.d5.loss_mask: 0.1850  decode.d5.loss_dice: 0.2204  decode.d6.loss_cls: 0.0655  decode.d6.loss_mask: 0.1845  decode.d6.loss_dice: 0.2195  decode.d7.loss_cls: 0.0717  decode.d7.loss_mask: 0.1825  decode.d7.loss_dice: 0.2203  decode.d8.loss_cls: 0.0599  decode.d8.loss_mask: 0.1928  decode.d8.loss_dice: 0.2377
08/06 11:06:52 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 11:06:52 - mmengine - INFO - Iter(train) [ 64000/320000]  base_lr: 8.1805e-05 lr: 8.1805e-06  eta: 1 day, 11:04:21  time: 0.4954  data_time: 0.0112  memory: 5891  grad_norm: 117.6285  loss: 9.0994  decode.loss_cls: 0.2393  decode.loss_mask: 0.3025  decode.loss_dice: 0.2867  decode.d0.loss_cls: 0.8802  decode.d0.loss_mask: 0.3158  decode.d0.loss_dice: 0.2879  decode.d1.loss_cls: 0.1886  decode.d1.loss_mask: 0.3214  decode.d1.loss_dice: 0.3136  decode.d2.loss_cls: 0.2356  decode.d2.loss_mask: 0.3116  decode.d2.loss_dice: 0.2865  decode.d3.loss_cls: 0.2592  decode.d3.loss_mask: 0.3132  decode.d3.loss_dice: 0.3084  decode.d4.loss_cls: 0.2220  decode.d4.loss_mask: 0.3148  decode.d4.loss_dice: 0.3069  decode.d5.loss_cls: 0.2470  decode.d5.loss_mask: 0.3051  decode.d5.loss_dice: 0.2993  decode.d6.loss_cls: 0.2411  decode.d6.loss_mask: 0.3038  decode.d6.loss_dice: 0.2795  decode.d7.loss_cls: 0.2672  decode.d7.loss_mask: 0.3044  decode.d7.loss_dice: 0.2900  decode.d8.loss_cls: 0.2661  decode.d8.loss_mask: 0.3058  decode.d8.loss_dice: 0.2959
08/06 11:07:16 - mmengine - INFO - Iter(train) [ 64050/320000]  base_lr: 8.1791e-05 lr: 8.1791e-06  eta: 1 day, 11:03:57  time: 0.4962  data_time: 0.0113  memory: 5909  grad_norm: 61.3322  loss: 7.4831  decode.loss_cls: 0.0855  decode.loss_mask: 0.2747  decode.loss_dice: 0.3173  decode.d0.loss_cls: 0.8265  decode.d0.loss_mask: 0.2785  decode.d0.loss_dice: 0.3044  decode.d1.loss_cls: 0.0872  decode.d1.loss_mask: 0.2764  decode.d1.loss_dice: 0.2718  decode.d2.loss_cls: 0.0900  decode.d2.loss_mask: 0.2747  decode.d2.loss_dice: 0.3083  decode.d3.loss_cls: 0.0938  decode.d3.loss_mask: 0.2774  decode.d3.loss_dice: 0.3210  decode.d4.loss_cls: 0.0950  decode.d4.loss_mask: 0.2706  decode.d4.loss_dice: 0.3150  decode.d5.loss_cls: 0.0957  decode.d5.loss_mask: 0.2742  decode.d5.loss_dice: 0.3091  decode.d6.loss_cls: 0.1037  decode.d6.loss_mask: 0.2713  decode.d6.loss_dice: 0.2967  decode.d7.loss_cls: 0.1205  decode.d7.loss_mask: 0.2678  decode.d7.loss_dice: 0.2799  decode.d8.loss_cls: 0.0818  decode.d8.loss_mask: 0.2760  decode.d8.loss_dice: 0.3384
08/06 11:07:41 - mmengine - INFO - Iter(train) [ 64100/320000]  base_lr: 8.1777e-05 lr: 8.1777e-06  eta: 1 day, 11:03:33  time: 0.4969  data_time: 0.0115  memory: 5911  grad_norm: 97.9839  loss: 5.8950  decode.loss_cls: 0.0094  decode.loss_mask: 0.2610  decode.loss_dice: 0.2153  decode.d0.loss_cls: 0.8799  decode.d0.loss_mask: 0.2713  decode.d0.loss_dice: 0.2118  decode.d1.loss_cls: 0.0833  decode.d1.loss_mask: 0.2428  decode.d1.loss_dice: 0.2130  decode.d2.loss_cls: 0.0232  decode.d2.loss_mask: 0.2666  decode.d2.loss_dice: 0.2187  decode.d3.loss_cls: 0.0197  decode.d3.loss_mask: 0.2592  decode.d3.loss_dice: 0.2139  decode.d4.loss_cls: 0.0139  decode.d4.loss_mask: 0.2641  decode.d4.loss_dice: 0.2130  decode.d5.loss_cls: 0.0261  decode.d5.loss_mask: 0.2684  decode.d5.loss_dice: 0.2191  decode.d6.loss_cls: 0.0249  decode.d6.loss_mask: 0.2642  decode.d6.loss_dice: 0.2203  decode.d7.loss_cls: 0.0183  decode.d7.loss_mask: 0.2660  decode.d7.loss_dice: 0.2162  decode.d8.loss_cls: 0.0091  decode.d8.loss_mask: 0.2653  decode.d8.loss_dice: 0.2170
08/06 11:08:06 - mmengine - INFO - Iter(train) [ 64150/320000]  base_lr: 8.1762e-05 lr: 8.1762e-06  eta: 1 day, 11:03:09  time: 0.4977  data_time: 0.0115  memory: 5894  grad_norm: 305.3397  loss: 6.7181  decode.loss_cls: 0.0966  decode.loss_mask: 0.2103  decode.loss_dice: 0.2645  decode.d0.loss_cls: 0.8724  decode.d0.loss_mask: 0.2139  decode.d0.loss_dice: 0.2837  decode.d1.loss_cls: 0.1463  decode.d1.loss_mask: 0.2102  decode.d1.loss_dice: 0.2453  decode.d2.loss_cls: 0.1439  decode.d2.loss_mask: 0.2083  decode.d2.loss_dice: 0.2488  decode.d3.loss_cls: 0.1497  decode.d3.loss_mask: 0.2129  decode.d3.loss_dice: 0.2519  decode.d4.loss_cls: 0.1606  decode.d4.loss_mask: 0.2083  decode.d4.loss_dice: 0.2496  decode.d5.loss_cls: 0.1205  decode.d5.loss_mask: 0.2101  decode.d5.loss_dice: 0.2676  decode.d6.loss_cls: 0.1277  decode.d6.loss_mask: 0.2084  decode.d6.loss_dice: 0.2550  decode.d7.loss_cls: 0.1289  decode.d7.loss_mask: 0.2075  decode.d7.loss_dice: 0.2633  decode.d8.loss_cls: 0.0967  decode.d8.loss_mask: 0.2092  decode.d8.loss_dice: 0.2460
08/06 11:08:31 - mmengine - INFO - Iter(train) [ 64200/320000]  base_lr: 8.1748e-05 lr: 8.1748e-06  eta: 1 day, 11:02:45  time: 0.4963  data_time: 0.0114  memory: 5909  grad_norm: 53.4428  loss: 6.4385  decode.loss_cls: 0.1218  decode.loss_mask: 0.2281  decode.loss_dice: 0.2498  decode.d0.loss_cls: 0.7642  decode.d0.loss_mask: 0.2299  decode.d0.loss_dice: 0.2491  decode.d1.loss_cls: 0.1178  decode.d1.loss_mask: 0.2306  decode.d1.loss_dice: 0.2402  decode.d2.loss_cls: 0.0909  decode.d2.loss_mask: 0.2302  decode.d2.loss_dice: 0.2302  decode.d3.loss_cls: 0.0969  decode.d3.loss_mask: 0.2321  decode.d3.loss_dice: 0.2474  decode.d4.loss_cls: 0.0735  decode.d4.loss_mask: 0.2318  decode.d4.loss_dice: 0.2495  decode.d5.loss_cls: 0.0919  decode.d5.loss_mask: 0.2301  decode.d5.loss_dice: 0.2424  decode.d6.loss_cls: 0.1082  decode.d6.loss_mask: 0.2261  decode.d6.loss_dice: 0.2425  decode.d7.loss_cls: 0.1143  decode.d7.loss_mask: 0.2275  decode.d7.loss_dice: 0.2389  decode.d8.loss_cls: 0.1258  decode.d8.loss_mask: 0.2280  decode.d8.loss_dice: 0.2488
08/06 11:08:56 - mmengine - INFO - Iter(train) [ 64250/320000]  base_lr: 8.1734e-05 lr: 8.1734e-06  eta: 1 day, 11:02:22  time: 0.4972  data_time: 0.0113  memory: 5891  grad_norm: 208.0770  loss: 4.7031  decode.loss_cls: 0.0344  decode.loss_mask: 0.1570  decode.loss_dice: 0.1993  decode.d0.loss_cls: 0.8336  decode.d0.loss_mask: 0.1571  decode.d0.loss_dice: 0.2077  decode.d1.loss_cls: 0.0328  decode.d1.loss_mask: 0.1577  decode.d1.loss_dice: 0.2042  decode.d2.loss_cls: 0.0267  decode.d2.loss_mask: 0.1580  decode.d2.loss_dice: 0.1940  decode.d3.loss_cls: 0.0260  decode.d3.loss_mask: 0.1573  decode.d3.loss_dice: 0.1891  decode.d4.loss_cls: 0.0283  decode.d4.loss_mask: 0.1575  decode.d4.loss_dice: 0.1944  decode.d5.loss_cls: 0.0374  decode.d5.loss_mask: 0.1573  decode.d5.loss_dice: 0.2003  decode.d6.loss_cls: 0.0370  decode.d6.loss_mask: 0.1573  decode.d6.loss_dice: 0.2026  decode.d7.loss_cls: 0.0281  decode.d7.loss_mask: 0.1579  decode.d7.loss_dice: 0.2124  decode.d8.loss_cls: 0.0338  decode.d8.loss_mask: 0.1585  decode.d8.loss_dice: 0.2056
08/06 11:09:21 - mmengine - INFO - Iter(train) [ 64300/320000]  base_lr: 8.1719e-05 lr: 8.1719e-06  eta: 1 day, 11:01:57  time: 0.4957  data_time: 0.0112  memory: 5928  grad_norm: 159.2738  loss: 8.1565  decode.loss_cls: 0.2156  decode.loss_mask: 0.1948  decode.loss_dice: 0.3450  decode.d0.loss_cls: 0.8604  decode.d0.loss_mask: 0.2071  decode.d0.loss_dice: 0.3651  decode.d1.loss_cls: 0.1557  decode.d1.loss_mask: 0.1996  decode.d1.loss_dice: 0.3632  decode.d2.loss_cls: 0.1418  decode.d2.loss_mask: 0.1988  decode.d2.loss_dice: 0.4189  decode.d3.loss_cls: 0.1471  decode.d3.loss_mask: 0.2009  decode.d3.loss_dice: 0.4018  decode.d4.loss_cls: 0.1867  decode.d4.loss_mask: 0.1979  decode.d4.loss_dice: 0.3568  decode.d5.loss_cls: 0.1640  decode.d5.loss_mask: 0.1973  decode.d5.loss_dice: 0.3838  decode.d6.loss_cls: 0.2010  decode.d6.loss_mask: 0.1971  decode.d6.loss_dice: 0.3141  decode.d7.loss_cls: 0.2117  decode.d7.loss_mask: 0.1985  decode.d7.loss_dice: 0.3924  decode.d8.loss_cls: 0.1883  decode.d8.loss_mask: 0.1972  decode.d8.loss_dice: 0.3540
08/06 11:09:46 - mmengine - INFO - Iter(train) [ 64350/320000]  base_lr: 8.1705e-05 lr: 8.1705e-06  eta: 1 day, 11:01:33  time: 0.4953  data_time: 0.0112  memory: 5894  grad_norm: 89.8028  loss: 7.3309  decode.loss_cls: 0.2048  decode.loss_mask: 0.2136  decode.loss_dice: 0.2639  decode.d0.loss_cls: 0.8620  decode.d0.loss_mask: 0.2210  decode.d0.loss_dice: 0.2796  decode.d1.loss_cls: 0.1961  decode.d1.loss_mask: 0.2149  decode.d1.loss_dice: 0.2489  decode.d2.loss_cls: 0.1855  decode.d2.loss_mask: 0.2180  decode.d2.loss_dice: 0.2825  decode.d3.loss_cls: 0.1735  decode.d3.loss_mask: 0.2120  decode.d3.loss_dice: 0.2690  decode.d4.loss_cls: 0.1696  decode.d4.loss_mask: 0.2157  decode.d4.loss_dice: 0.2434  decode.d5.loss_cls: 0.2003  decode.d5.loss_mask: 0.2156  decode.d5.loss_dice: 0.2464  decode.d6.loss_cls: 0.1984  decode.d6.loss_mask: 0.2141  decode.d6.loss_dice: 0.2682  decode.d7.loss_cls: 0.1914  decode.d7.loss_mask: 0.2159  decode.d7.loss_dice: 0.2571  decode.d8.loss_cls: 0.1968  decode.d8.loss_mask: 0.2146  decode.d8.loss_dice: 0.2380
08/06 11:10:10 - mmengine - INFO - Iter(train) [ 64400/320000]  base_lr: 8.1690e-05 lr: 8.1690e-06  eta: 1 day, 11:01:09  time: 0.4958  data_time: 0.0112  memory: 5894  grad_norm: 77.7225  loss: 8.1991  decode.loss_cls: 0.2121  decode.loss_mask: 0.2689  decode.loss_dice: 0.2878  decode.d0.loss_cls: 0.7213  decode.d0.loss_mask: 0.2738  decode.d0.loss_dice: 0.2856  decode.d1.loss_cls: 0.1992  decode.d1.loss_mask: 0.2741  decode.d1.loss_dice: 0.2674  decode.d2.loss_cls: 0.1913  decode.d2.loss_mask: 0.2693  decode.d2.loss_dice: 0.2736  decode.d3.loss_cls: 0.2047  decode.d3.loss_mask: 0.2683  decode.d3.loss_dice: 0.2779  decode.d4.loss_cls: 0.2517  decode.d4.loss_mask: 0.2681  decode.d4.loss_dice: 0.2891  decode.d5.loss_cls: 0.2292  decode.d5.loss_mask: 0.2679  decode.d5.loss_dice: 0.2736  decode.d6.loss_cls: 0.2197  decode.d6.loss_mask: 0.2671  decode.d6.loss_dice: 0.2778  decode.d7.loss_cls: 0.2582  decode.d7.loss_mask: 0.2689  decode.d7.loss_dice: 0.2866  decode.d8.loss_cls: 0.2153  decode.d8.loss_mask: 0.2669  decode.d8.loss_dice: 0.2836
08/06 11:10:35 - mmengine - INFO - Iter(train) [ 64450/320000]  base_lr: 8.1676e-05 lr: 8.1676e-06  eta: 1 day, 11:00:45  time: 0.4981  data_time: 0.0113  memory: 5909  grad_norm: 48.0887  loss: 5.5512  decode.loss_cls: 0.0653  decode.loss_mask: 0.1751  decode.loss_dice: 0.2437  decode.d0.loss_cls: 0.8341  decode.d0.loss_mask: 0.1760  decode.d0.loss_dice: 0.2505  decode.d1.loss_cls: 0.0632  decode.d1.loss_mask: 0.1742  decode.d1.loss_dice: 0.2334  decode.d2.loss_cls: 0.0525  decode.d2.loss_mask: 0.1753  decode.d2.loss_dice: 0.2373  decode.d3.loss_cls: 0.0563  decode.d3.loss_mask: 0.1749  decode.d3.loss_dice: 0.2353  decode.d4.loss_cls: 0.0554  decode.d4.loss_mask: 0.1725  decode.d4.loss_dice: 0.2442  decode.d5.loss_cls: 0.0654  decode.d5.loss_mask: 0.1741  decode.d5.loss_dice: 0.2414  decode.d6.loss_cls: 0.0601  decode.d6.loss_mask: 0.1756  decode.d6.loss_dice: 0.2579  decode.d7.loss_cls: 0.0713  decode.d7.loss_mask: 0.1761  decode.d7.loss_dice: 0.2355  decode.d8.loss_cls: 0.0672  decode.d8.loss_mask: 0.1732  decode.d8.loss_dice: 0.2342
08/06 11:11:00 - mmengine - INFO - Iter(train) [ 64500/320000]  base_lr: 8.1662e-05 lr: 8.1662e-06  eta: 1 day, 11:00:22  time: 0.4963  data_time: 0.0113  memory: 5894  grad_norm: 232.1972  loss: 6.6572  decode.loss_cls: 0.1291  decode.loss_mask: 0.2304  decode.loss_dice: 0.2360  decode.d0.loss_cls: 0.8100  decode.d0.loss_mask: 0.2335  decode.d0.loss_dice: 0.2365  decode.d1.loss_cls: 0.1372  decode.d1.loss_mask: 0.2310  decode.d1.loss_dice: 0.2425  decode.d2.loss_cls: 0.1767  decode.d2.loss_mask: 0.2312  decode.d2.loss_dice: 0.2384  decode.d3.loss_cls: 0.1220  decode.d3.loss_mask: 0.2268  decode.d3.loss_dice: 0.2371  decode.d4.loss_cls: 0.1286  decode.d4.loss_mask: 0.2293  decode.d4.loss_dice: 0.2382  decode.d5.loss_cls: 0.1124  decode.d5.loss_mask: 0.2311  decode.d5.loss_dice: 0.2387  decode.d6.loss_cls: 0.1189  decode.d6.loss_mask: 0.2287  decode.d6.loss_dice: 0.2407  decode.d7.loss_cls: 0.1211  decode.d7.loss_mask: 0.2282  decode.d7.loss_dice: 0.2318  decode.d8.loss_cls: 0.1265  decode.d8.loss_mask: 0.2297  decode.d8.loss_dice: 0.2349
08/06 11:11:25 - mmengine - INFO - Iter(train) [ 64550/320000]  base_lr: 8.1647e-05 lr: 8.1647e-06  eta: 1 day, 10:59:58  time: 0.4967  data_time: 0.0114  memory: 5891  grad_norm: 51.6231  loss: 5.9428  decode.loss_cls: 0.0495  decode.loss_mask: 0.2273  decode.loss_dice: 0.2406  decode.d0.loss_cls: 0.7190  decode.d0.loss_mask: 0.2245  decode.d0.loss_dice: 0.2422  decode.d1.loss_cls: 0.0667  decode.d1.loss_mask: 0.2242  decode.d1.loss_dice: 0.2483  decode.d2.loss_cls: 0.0528  decode.d2.loss_mask: 0.2237  decode.d2.loss_dice: 0.2399  decode.d3.loss_cls: 0.0400  decode.d3.loss_mask: 0.2236  decode.d3.loss_dice: 0.2625  decode.d4.loss_cls: 0.0433  decode.d4.loss_mask: 0.2258  decode.d4.loss_dice: 0.2637  decode.d5.loss_cls: 0.0464  decode.d5.loss_mask: 0.2263  decode.d5.loss_dice: 0.2408  decode.d6.loss_cls: 0.0723  decode.d6.loss_mask: 0.2226  decode.d6.loss_dice: 0.2798  decode.d7.loss_cls: 0.0456  decode.d7.loss_mask: 0.2254  decode.d7.loss_dice: 0.2477  decode.d8.loss_cls: 0.0556  decode.d8.loss_mask: 0.2243  decode.d8.loss_dice: 0.2382
08/06 11:11:50 - mmengine - INFO - Iter(train) [ 64600/320000]  base_lr: 8.1633e-05 lr: 8.1633e-06  eta: 1 day, 10:59:34  time: 0.4962  data_time: 0.0114  memory: 5891  grad_norm: 56.8027  loss: 6.6288  decode.loss_cls: 0.1190  decode.loss_mask: 0.2364  decode.loss_dice: 0.2163  decode.d0.loss_cls: 0.8743  decode.d0.loss_mask: 0.2459  decode.d0.loss_dice: 0.2213  decode.d1.loss_cls: 0.1513  decode.d1.loss_mask: 0.2387  decode.d1.loss_dice: 0.2192  decode.d2.loss_cls: 0.1610  decode.d2.loss_mask: 0.2349  decode.d2.loss_dice: 0.2164  decode.d3.loss_cls: 0.1459  decode.d3.loss_mask: 0.2344  decode.d3.loss_dice: 0.2167  decode.d4.loss_cls: 0.1462  decode.d4.loss_mask: 0.2362  decode.d4.loss_dice: 0.2175  decode.d5.loss_cls: 0.1261  decode.d5.loss_mask: 0.2343  decode.d5.loss_dice: 0.2139  decode.d6.loss_cls: 0.1174  decode.d6.loss_mask: 0.2350  decode.d6.loss_dice: 0.2178  decode.d7.loss_cls: 0.1145  decode.d7.loss_mask: 0.2341  decode.d7.loss_dice: 0.2212  decode.d8.loss_cls: 0.1322  decode.d8.loss_mask: 0.2368  decode.d8.loss_dice: 0.2141
08/06 11:12:15 - mmengine - INFO - Iter(train) [ 64650/320000]  base_lr: 8.1618e-05 lr: 8.1618e-06  eta: 1 day, 10:59:10  time: 0.4958  data_time: 0.0114  memory: 5909  grad_norm: 71.4766  loss: 7.2646  decode.loss_cls: 0.2183  decode.loss_mask: 0.2087  decode.loss_dice: 0.2371  decode.d0.loss_cls: 0.9161  decode.d0.loss_mask: 0.2131  decode.d0.loss_dice: 0.2347  decode.d1.loss_cls: 0.2474  decode.d1.loss_mask: 0.2138  decode.d1.loss_dice: 0.2486  decode.d2.loss_cls: 0.2557  decode.d2.loss_mask: 0.2089  decode.d2.loss_dice: 0.2168  decode.d3.loss_cls: 0.2275  decode.d3.loss_mask: 0.2108  decode.d3.loss_dice: 0.2161  decode.d4.loss_cls: 0.2329  decode.d4.loss_mask: 0.2146  decode.d4.loss_dice: 0.2194  decode.d5.loss_cls: 0.2043  decode.d5.loss_mask: 0.2094  decode.d5.loss_dice: 0.2378  decode.d6.loss_cls: 0.1919  decode.d6.loss_mask: 0.2109  decode.d6.loss_dice: 0.2382  decode.d7.loss_cls: 0.1673  decode.d7.loss_mask: 0.2144  decode.d7.loss_dice: 0.2252  decode.d8.loss_cls: 0.1839  decode.d8.loss_mask: 0.2128  decode.d8.loss_dice: 0.2282
08/06 11:12:40 - mmengine - INFO - Iter(train) [ 64700/320000]  base_lr: 8.1604e-05 lr: 8.1604e-06  eta: 1 day, 10:58:46  time: 0.4960  data_time: 0.0113  memory: 5878  grad_norm: 75.4669  loss: 6.3917  decode.loss_cls: 0.0319  decode.loss_mask: 0.2447  decode.loss_dice: 0.2770  decode.d0.loss_cls: 0.7939  decode.d0.loss_mask: 0.2473  decode.d0.loss_dice: 0.2635  decode.d1.loss_cls: 0.0734  decode.d1.loss_mask: 0.2400  decode.d1.loss_dice: 0.2637  decode.d2.loss_cls: 0.0679  decode.d2.loss_mask: 0.2401  decode.d2.loss_dice: 0.2824  decode.d3.loss_cls: 0.0344  decode.d3.loss_mask: 0.2402  decode.d3.loss_dice: 0.2842  decode.d4.loss_cls: 0.0693  decode.d4.loss_mask: 0.2392  decode.d4.loss_dice: 0.2657  decode.d5.loss_cls: 0.0204  decode.d5.loss_mask: 0.2435  decode.d5.loss_dice: 0.2725  decode.d6.loss_cls: 0.0268  decode.d6.loss_mask: 0.2392  decode.d6.loss_dice: 0.2765  decode.d7.loss_cls: 0.0307  decode.d7.loss_mask: 0.2392  decode.d7.loss_dice: 0.2739  decode.d8.loss_cls: 0.0913  decode.d8.loss_mask: 0.2390  decode.d8.loss_dice: 0.2800
08/06 11:13:04 - mmengine - INFO - Iter(train) [ 64750/320000]  base_lr: 8.1590e-05 lr: 8.1590e-06  eta: 1 day, 10:58:22  time: 0.4962  data_time: 0.0113  memory: 5891  grad_norm: 62.3851  loss: 6.1153  decode.loss_cls: 0.0859  decode.loss_mask: 0.2161  decode.loss_dice: 0.2291  decode.d0.loss_cls: 0.8746  decode.d0.loss_mask: 0.2168  decode.d0.loss_dice: 0.2252  decode.d1.loss_cls: 0.0910  decode.d1.loss_mask: 0.2140  decode.d1.loss_dice: 0.2284  decode.d2.loss_cls: 0.0862  decode.d2.loss_mask: 0.2120  decode.d2.loss_dice: 0.2224  decode.d3.loss_cls: 0.0868  decode.d3.loss_mask: 0.2115  decode.d3.loss_dice: 0.2235  decode.d4.loss_cls: 0.0938  decode.d4.loss_mask: 0.2135  decode.d4.loss_dice: 0.2227  decode.d5.loss_cls: 0.1061  decode.d5.loss_mask: 0.2156  decode.d5.loss_dice: 0.2427  decode.d6.loss_cls: 0.0809  decode.d6.loss_mask: 0.2157  decode.d6.loss_dice: 0.2262  decode.d7.loss_cls: 0.1031  decode.d7.loss_mask: 0.2154  decode.d7.loss_dice: 0.2232  decode.d8.loss_cls: 0.0981  decode.d8.loss_mask: 0.2125  decode.d8.loss_dice: 0.2222
08/06 11:13:29 - mmengine - INFO - Iter(train) [ 64800/320000]  base_lr: 8.1575e-05 lr: 8.1575e-06  eta: 1 day, 10:57:58  time: 0.4967  data_time: 0.0113  memory: 5890  grad_norm: 52.7421  loss: 5.5593  decode.loss_cls: 0.0122  decode.loss_mask: 0.2366  decode.loss_dice: 0.2255  decode.d0.loss_cls: 0.7625  decode.d0.loss_mask: 0.2383  decode.d0.loss_dice: 0.2298  decode.d1.loss_cls: 0.0124  decode.d1.loss_mask: 0.2388  decode.d1.loss_dice: 0.2294  decode.d2.loss_cls: 0.0118  decode.d2.loss_mask: 0.2374  decode.d2.loss_dice: 0.2365  decode.d3.loss_cls: 0.0098  decode.d3.loss_mask: 0.2378  decode.d3.loss_dice: 0.2326  decode.d4.loss_cls: 0.0086  decode.d4.loss_mask: 0.2389  decode.d4.loss_dice: 0.2333  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.2356  decode.d5.loss_dice: 0.2283  decode.d6.loss_cls: 0.0116  decode.d6.loss_mask: 0.2409  decode.d6.loss_dice: 0.2341  decode.d7.loss_cls: 0.0138  decode.d7.loss_mask: 0.2398  decode.d7.loss_dice: 0.2312  decode.d8.loss_cls: 0.0107  decode.d8.loss_mask: 0.2399  decode.d8.loss_dice: 0.2306
08/06 11:13:54 - mmengine - INFO - Iter(train) [ 64850/320000]  base_lr: 8.1561e-05 lr: 8.1561e-06  eta: 1 day, 10:57:34  time: 0.4975  data_time: 0.0114  memory: 5928  grad_norm: 31.0552  loss: 4.6668  decode.loss_cls: 0.0056  decode.loss_mask: 0.1848  decode.loss_dice: 0.1987  decode.d0.loss_cls: 0.7245  decode.d0.loss_mask: 0.1881  decode.d0.loss_dice: 0.1980  decode.d1.loss_cls: 0.0065  decode.d1.loss_mask: 0.1848  decode.d1.loss_dice: 0.2016  decode.d2.loss_cls: 0.0084  decode.d2.loss_mask: 0.1863  decode.d2.loss_dice: 0.1987  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.1884  decode.d3.loss_dice: 0.2054  decode.d4.loss_cls: 0.0063  decode.d4.loss_mask: 0.1876  decode.d4.loss_dice: 0.2054  decode.d5.loss_cls: 0.0067  decode.d5.loss_mask: 0.1847  decode.d5.loss_dice: 0.2033  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.1862  decode.d6.loss_dice: 0.2029  decode.d7.loss_cls: 0.0065  decode.d7.loss_mask: 0.1868  decode.d7.loss_dice: 0.2042  decode.d8.loss_cls: 0.0050  decode.d8.loss_mask: 0.1854  decode.d8.loss_dice: 0.2054
08/06 11:14:19 - mmengine - INFO - Iter(train) [ 64900/320000]  base_lr: 8.1547e-05 lr: 8.1547e-06  eta: 1 day, 10:57:10  time: 0.4963  data_time: 0.0113  memory: 5891  grad_norm: 136.4075  loss: 9.0195  decode.loss_cls: 0.2862  decode.loss_mask: 0.2811  decode.loss_dice: 0.3068  decode.d0.loss_cls: 0.8468  decode.d0.loss_mask: 0.2889  decode.d0.loss_dice: 0.2994  decode.d1.loss_cls: 0.2785  decode.d1.loss_mask: 0.2862  decode.d1.loss_dice: 0.2920  decode.d2.loss_cls: 0.2782  decode.d2.loss_mask: 0.2838  decode.d2.loss_dice: 0.2954  decode.d3.loss_cls: 0.2461  decode.d3.loss_mask: 0.2812  decode.d3.loss_dice: 0.2916  decode.d4.loss_cls: 0.2637  decode.d4.loss_mask: 0.2822  decode.d4.loss_dice: 0.2891  decode.d5.loss_cls: 0.2415  decode.d5.loss_mask: 0.2832  decode.d5.loss_dice: 0.2913  decode.d6.loss_cls: 0.2460  decode.d6.loss_mask: 0.2856  decode.d6.loss_dice: 0.2962  decode.d7.loss_cls: 0.2818  decode.d7.loss_mask: 0.2859  decode.d7.loss_dice: 0.2974  decode.d8.loss_cls: 0.2614  decode.d8.loss_mask: 0.2766  decode.d8.loss_dice: 0.2954
08/06 11:14:44 - mmengine - INFO - Iter(train) [ 64950/320000]  base_lr: 8.1532e-05 lr: 8.1532e-06  eta: 1 day, 10:56:45  time: 0.4965  data_time: 0.0113  memory: 5891  grad_norm: 107.3236  loss: 8.7359  decode.loss_cls: 0.2213  decode.loss_mask: 0.2621  decode.loss_dice: 0.3035  decode.d0.loss_cls: 0.9767  decode.d0.loss_mask: 0.2643  decode.d0.loss_dice: 0.2975  decode.d1.loss_cls: 0.2355  decode.d1.loss_mask: 0.2626  decode.d1.loss_dice: 0.3031  decode.d2.loss_cls: 0.2089  decode.d2.loss_mask: 0.2657  decode.d2.loss_dice: 0.3161  decode.d3.loss_cls: 0.2408  decode.d3.loss_mask: 0.2603  decode.d3.loss_dice: 0.3109  decode.d4.loss_cls: 0.2261  decode.d4.loss_mask: 0.2604  decode.d4.loss_dice: 0.2912  decode.d5.loss_cls: 0.2551  decode.d5.loss_mask: 0.2615  decode.d5.loss_dice: 0.3231  decode.d6.loss_cls: 0.2366  decode.d6.loss_mask: 0.2613  decode.d6.loss_dice: 0.3186  decode.d7.loss_cls: 0.2002  decode.d7.loss_mask: 0.2577  decode.d7.loss_dice: 0.3159  decode.d8.loss_cls: 0.2243  decode.d8.loss_mask: 0.2637  decode.d8.loss_dice: 0.3109
08/06 11:15:08 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 11:15:08 - mmengine - INFO - Iter(train) [ 65000/320000]  base_lr: 8.1518e-05 lr: 8.1518e-06  eta: 1 day, 10:56:21  time: 0.4967  data_time: 0.0111  memory: 5894  grad_norm: 85.8108  loss: 6.9028  decode.loss_cls: 0.0693  decode.loss_mask: 0.3044  decode.loss_dice: 0.2448  decode.d0.loss_cls: 0.8638  decode.d0.loss_mask: 0.3114  decode.d0.loss_dice: 0.2490  decode.d1.loss_cls: 0.0306  decode.d1.loss_mask: 0.3079  decode.d1.loss_dice: 0.2438  decode.d2.loss_cls: 0.0651  decode.d2.loss_mask: 0.3060  decode.d2.loss_dice: 0.2487  decode.d3.loss_cls: 0.0212  decode.d3.loss_mask: 0.3058  decode.d3.loss_dice: 0.2446  decode.d4.loss_cls: 0.0276  decode.d4.loss_mask: 0.3050  decode.d4.loss_dice: 0.2526  decode.d5.loss_cls: 0.0812  decode.d5.loss_mask: 0.3016  decode.d5.loss_dice: 0.2438  decode.d6.loss_cls: 0.0420  decode.d6.loss_mask: 0.3050  decode.d6.loss_dice: 0.2385  decode.d7.loss_cls: 0.0831  decode.d7.loss_mask: 0.3061  decode.d7.loss_dice: 0.2481  decode.d8.loss_cls: 0.0985  decode.d8.loss_mask: 0.3069  decode.d8.loss_dice: 0.2463
08/06 11:15:33 - mmengine - INFO - Iter(train) [ 65050/320000]  base_lr: 8.1503e-05 lr: 8.1503e-06  eta: 1 day, 10:55:57  time: 0.4966  data_time: 0.0114  memory: 5967  grad_norm: 40.3432  loss: 5.5276  decode.loss_cls: 0.0116  decode.loss_mask: 0.2422  decode.loss_dice: 0.2243  decode.d0.loss_cls: 0.7960  decode.d0.loss_mask: 0.2290  decode.d0.loss_dice: 0.2272  decode.d1.loss_cls: 0.0093  decode.d1.loss_mask: 0.2359  decode.d1.loss_dice: 0.2231  decode.d2.loss_cls: 0.0122  decode.d2.loss_mask: 0.2355  decode.d2.loss_dice: 0.2210  decode.d3.loss_cls: 0.0128  decode.d3.loss_mask: 0.2400  decode.d3.loss_dice: 0.2232  decode.d4.loss_cls: 0.0142  decode.d4.loss_mask: 0.2465  decode.d4.loss_dice: 0.2251  decode.d5.loss_cls: 0.0158  decode.d5.loss_mask: 0.2385  decode.d5.loss_dice: 0.2207  decode.d6.loss_cls: 0.0137  decode.d6.loss_mask: 0.2380  decode.d6.loss_dice: 0.2192  decode.d7.loss_cls: 0.0111  decode.d7.loss_mask: 0.2408  decode.d7.loss_dice: 0.2244  decode.d8.loss_cls: 0.0107  decode.d8.loss_mask: 0.2413  decode.d8.loss_dice: 0.2243
08/06 11:15:58 - mmengine - INFO - Iter(train) [ 65100/320000]  base_lr: 8.1489e-05 lr: 8.1489e-06  eta: 1 day, 10:55:34  time: 0.4963  data_time: 0.0114  memory: 5874  grad_norm: 88.5641  loss: 5.6616  decode.loss_cls: 0.0873  decode.loss_mask: 0.1747  decode.loss_dice: 0.2289  decode.d0.loss_cls: 0.7316  decode.d0.loss_mask: 0.1747  decode.d0.loss_dice: 0.2372  decode.d1.loss_cls: 0.0851  decode.d1.loss_mask: 0.1745  decode.d1.loss_dice: 0.2451  decode.d2.loss_cls: 0.1052  decode.d2.loss_mask: 0.1761  decode.d2.loss_dice: 0.2333  decode.d3.loss_cls: 0.1365  decode.d3.loss_mask: 0.1741  decode.d3.loss_dice: 0.2346  decode.d4.loss_cls: 0.1049  decode.d4.loss_mask: 0.1757  decode.d4.loss_dice: 0.2333  decode.d5.loss_cls: 0.0761  decode.d5.loss_mask: 0.1789  decode.d5.loss_dice: 0.2211  decode.d6.loss_cls: 0.0791  decode.d6.loss_mask: 0.1752  decode.d6.loss_dice: 0.2394  decode.d7.loss_cls: 0.0872  decode.d7.loss_mask: 0.1756  decode.d7.loss_dice: 0.2232  decode.d8.loss_cls: 0.0768  decode.d8.loss_mask: 0.1787  decode.d8.loss_dice: 0.2377
08/06 11:16:23 - mmengine - INFO - Iter(train) [ 65150/320000]  base_lr: 8.1475e-05 lr: 8.1475e-06  eta: 1 day, 10:55:09  time: 0.4962  data_time: 0.0112  memory: 5894  grad_norm: 132.4023  loss: 8.2550  decode.loss_cls: 0.1422  decode.loss_mask: 0.3089  decode.loss_dice: 0.3032  decode.d0.loss_cls: 0.9596  decode.d0.loss_mask: 0.3105  decode.d0.loss_dice: 0.3137  decode.d1.loss_cls: 0.1705  decode.d1.loss_mask: 0.3091  decode.d1.loss_dice: 0.2843  decode.d2.loss_cls: 0.1337  decode.d2.loss_mask: 0.3070  decode.d2.loss_dice: 0.3067  decode.d3.loss_cls: 0.1539  decode.d3.loss_mask: 0.3064  decode.d3.loss_dice: 0.2899  decode.d4.loss_cls: 0.1299  decode.d4.loss_mask: 0.3067  decode.d4.loss_dice: 0.2939  decode.d5.loss_cls: 0.1319  decode.d5.loss_mask: 0.3069  decode.d5.loss_dice: 0.2935  decode.d6.loss_cls: 0.1346  decode.d6.loss_mask: 0.3087  decode.d6.loss_dice: 0.2870  decode.d7.loss_cls: 0.1321  decode.d7.loss_mask: 0.3099  decode.d7.loss_dice: 0.3163  decode.d8.loss_cls: 0.1250  decode.d8.loss_mask: 0.3098  decode.d8.loss_dice: 0.2695
08/06 11:16:48 - mmengine - INFO - Iter(train) [ 65200/320000]  base_lr: 8.1460e-05 lr: 8.1460e-06  eta: 1 day, 10:54:45  time: 0.4967  data_time: 0.0116  memory: 5894  grad_norm: 81.1199  loss: 5.9699  decode.loss_cls: 0.0280  decode.loss_mask: 0.2182  decode.loss_dice: 0.2444  decode.d0.loss_cls: 0.8416  decode.d0.loss_mask: 0.2230  decode.d0.loss_dice: 0.2379  decode.d1.loss_cls: 0.0961  decode.d1.loss_mask: 0.2187  decode.d1.loss_dice: 0.2476  decode.d2.loss_cls: 0.0612  decode.d2.loss_mask: 0.2160  decode.d2.loss_dice: 0.2575  decode.d3.loss_cls: 0.0589  decode.d3.loss_mask: 0.2148  decode.d3.loss_dice: 0.2436  decode.d4.loss_cls: 0.0928  decode.d4.loss_mask: 0.2129  decode.d4.loss_dice: 0.2459  decode.d5.loss_cls: 0.0512  decode.d5.loss_mask: 0.2169  decode.d5.loss_dice: 0.2410  decode.d6.loss_cls: 0.0574  decode.d6.loss_mask: 0.2193  decode.d6.loss_dice: 0.2472  decode.d7.loss_cls: 0.0302  decode.d7.loss_mask: 0.2167  decode.d7.loss_dice: 0.2428  decode.d8.loss_cls: 0.0302  decode.d8.loss_mask: 0.2192  decode.d8.loss_dice: 0.2389
08/06 11:17:13 - mmengine - INFO - Iter(train) [ 65250/320000]  base_lr: 8.1446e-05 lr: 8.1446e-06  eta: 1 day, 10:54:21  time: 0.4959  data_time: 0.0110  memory: 5891  grad_norm: 129.7820  loss: 6.7960  decode.loss_cls: 0.1513  decode.loss_mask: 0.2218  decode.loss_dice: 0.2285  decode.d0.loss_cls: 0.8937  decode.d0.loss_mask: 0.2135  decode.d0.loss_dice: 0.2466  decode.d1.loss_cls: 0.1971  decode.d1.loss_mask: 0.2118  decode.d1.loss_dice: 0.2194  decode.d2.loss_cls: 0.2088  decode.d2.loss_mask: 0.2109  decode.d2.loss_dice: 0.2237  decode.d3.loss_cls: 0.1609  decode.d3.loss_mask: 0.2071  decode.d3.loss_dice: 0.2190  decode.d4.loss_cls: 0.1248  decode.d4.loss_mask: 0.2226  decode.d4.loss_dice: 0.2251  decode.d5.loss_cls: 0.1801  decode.d5.loss_mask: 0.2197  decode.d5.loss_dice: 0.2293  decode.d6.loss_cls: 0.1474  decode.d6.loss_mask: 0.2183  decode.d6.loss_dice: 0.2274  decode.d7.loss_cls: 0.1626  decode.d7.loss_mask: 0.2137  decode.d7.loss_dice: 0.2238  decode.d8.loss_cls: 0.1533  decode.d8.loss_mask: 0.2103  decode.d8.loss_dice: 0.2235
08/06 11:17:37 - mmengine - INFO - Iter(train) [ 65300/320000]  base_lr: 8.1431e-05 lr: 8.1431e-06  eta: 1 day, 10:53:57  time: 0.4961  data_time: 0.0113  memory: 5891  grad_norm: 61.7929  loss: 7.2549  decode.loss_cls: 0.1355  decode.loss_mask: 0.2554  decode.loss_dice: 0.3088  decode.d0.loss_cls: 0.8415  decode.d0.loss_mask: 0.2645  decode.d0.loss_dice: 0.2932  decode.d1.loss_cls: 0.1118  decode.d1.loss_mask: 0.2558  decode.d1.loss_dice: 0.2518  decode.d2.loss_cls: 0.1048  decode.d2.loss_mask: 0.2600  decode.d2.loss_dice: 0.2690  decode.d3.loss_cls: 0.1079  decode.d3.loss_mask: 0.2588  decode.d3.loss_dice: 0.2747  decode.d4.loss_cls: 0.1074  decode.d4.loss_mask: 0.2585  decode.d4.loss_dice: 0.2578  decode.d5.loss_cls: 0.1019  decode.d5.loss_mask: 0.2594  decode.d5.loss_dice: 0.2793  decode.d6.loss_cls: 0.1441  decode.d6.loss_mask: 0.2586  decode.d6.loss_dice: 0.2890  decode.d7.loss_cls: 0.1254  decode.d7.loss_mask: 0.2557  decode.d7.loss_dice: 0.2681  decode.d8.loss_cls: 0.1223  decode.d8.loss_mask: 0.2565  decode.d8.loss_dice: 0.2773
08/06 11:18:02 - mmengine - INFO - Iter(train) [ 65350/320000]  base_lr: 8.1417e-05 lr: 8.1417e-06  eta: 1 day, 10:53:33  time: 0.4953  data_time: 0.0115  memory: 5928  grad_norm: 217.2060  loss: 9.9970  decode.loss_cls: 0.2285  decode.loss_mask: 0.3369  decode.loss_dice: 0.3432  decode.d0.loss_cls: 1.0636  decode.d0.loss_mask: 0.3294  decode.d0.loss_dice: 0.3312  decode.d1.loss_cls: 0.2897  decode.d1.loss_mask: 0.3373  decode.d1.loss_dice: 0.3407  decode.d2.loss_cls: 0.2435  decode.d2.loss_mask: 0.3341  decode.d2.loss_dice: 0.3211  decode.d3.loss_cls: 0.2068  decode.d3.loss_mask: 0.3431  decode.d3.loss_dice: 0.3445  decode.d4.loss_cls: 0.2263  decode.d4.loss_mask: 0.3360  decode.d4.loss_dice: 0.3255  decode.d5.loss_cls: 0.2494  decode.d5.loss_mask: 0.3416  decode.d5.loss_dice: 0.3099  decode.d6.loss_cls: 0.2609  decode.d6.loss_mask: 0.3372  decode.d6.loss_dice: 0.3262  decode.d7.loss_cls: 0.2364  decode.d7.loss_mask: 0.3441  decode.d7.loss_dice: 0.3263  decode.d8.loss_cls: 0.2791  decode.d8.loss_mask: 0.3486  decode.d8.loss_dice: 0.3561
08/06 11:18:27 - mmengine - INFO - Iter(train) [ 65400/320000]  base_lr: 8.1403e-05 lr: 8.1403e-06  eta: 1 day, 10:53:09  time: 0.4960  data_time: 0.0115  memory: 5894  grad_norm: 93.6933  loss: 7.6885  decode.loss_cls: 0.0887  decode.loss_mask: 0.2818  decode.loss_dice: 0.2899  decode.d0.loss_cls: 1.0012  decode.d0.loss_mask: 0.2763  decode.d0.loss_dice: 0.2566  decode.d1.loss_cls: 0.1654  decode.d1.loss_mask: 0.2764  decode.d1.loss_dice: 0.2852  decode.d2.loss_cls: 0.2032  decode.d2.loss_mask: 0.2762  decode.d2.loss_dice: 0.2740  decode.d3.loss_cls: 0.0928  decode.d3.loss_mask: 0.2832  decode.d3.loss_dice: 0.2837  decode.d4.loss_cls: 0.1031  decode.d4.loss_mask: 0.2835  decode.d4.loss_dice: 0.3105  decode.d5.loss_cls: 0.1196  decode.d5.loss_mask: 0.2798  decode.d5.loss_dice: 0.2581  decode.d6.loss_cls: 0.1148  decode.d6.loss_mask: 0.2846  decode.d6.loss_dice: 0.2672  decode.d7.loss_cls: 0.0949  decode.d7.loss_mask: 0.2911  decode.d7.loss_dice: 0.2818  decode.d8.loss_cls: 0.1058  decode.d8.loss_mask: 0.2797  decode.d8.loss_dice: 0.2793
08/06 11:18:52 - mmengine - INFO - Iter(train) [ 65450/320000]  base_lr: 8.1388e-05 lr: 8.1388e-06  eta: 1 day, 10:52:45  time: 0.4952  data_time: 0.0112  memory: 5911  grad_norm: 67.7542  loss: 6.3354  decode.loss_cls: 0.0763  decode.loss_mask: 0.2371  decode.loss_dice: 0.2346  decode.d0.loss_cls: 0.9530  decode.d0.loss_mask: 0.2447  decode.d0.loss_dice: 0.2221  decode.d1.loss_cls: 0.0961  decode.d1.loss_mask: 0.2331  decode.d1.loss_dice: 0.2323  decode.d2.loss_cls: 0.0785  decode.d2.loss_mask: 0.2306  decode.d2.loss_dice: 0.2368  decode.d3.loss_cls: 0.0822  decode.d3.loss_mask: 0.2337  decode.d3.loss_dice: 0.2332  decode.d4.loss_cls: 0.0684  decode.d4.loss_mask: 0.2341  decode.d4.loss_dice: 0.2371  decode.d5.loss_cls: 0.0791  decode.d5.loss_mask: 0.2337  decode.d5.loss_dice: 0.2345  decode.d6.loss_cls: 0.0718  decode.d6.loss_mask: 0.2313  decode.d6.loss_dice: 0.2288  decode.d7.loss_cls: 0.0778  decode.d7.loss_mask: 0.2332  decode.d7.loss_dice: 0.2262  decode.d8.loss_cls: 0.0818  decode.d8.loss_mask: 0.2370  decode.d8.loss_dice: 0.2365
08/06 11:19:17 - mmengine - INFO - Iter(train) [ 65500/320000]  base_lr: 8.1374e-05 lr: 8.1374e-06  eta: 1 day, 10:52:21  time: 0.4970  data_time: 0.0113  memory: 5891  grad_norm: 51.4274  loss: 5.5118  decode.loss_cls: 0.0307  decode.loss_mask: 0.2132  decode.loss_dice: 0.2218  decode.d0.loss_cls: 0.7791  decode.d0.loss_mask: 0.2125  decode.d0.loss_dice: 0.2140  decode.d1.loss_cls: 0.0622  decode.d1.loss_mask: 0.2144  decode.d1.loss_dice: 0.2215  decode.d2.loss_cls: 0.0476  decode.d2.loss_mask: 0.2153  decode.d2.loss_dice: 0.2188  decode.d3.loss_cls: 0.0298  decode.d3.loss_mask: 0.2134  decode.d3.loss_dice: 0.2183  decode.d4.loss_cls: 0.0320  decode.d4.loss_mask: 0.2126  decode.d4.loss_dice: 0.2105  decode.d5.loss_cls: 0.0482  decode.d5.loss_mask: 0.2152  decode.d5.loss_dice: 0.2206  decode.d6.loss_cls: 0.0393  decode.d6.loss_mask: 0.2144  decode.d6.loss_dice: 0.2192  decode.d7.loss_cls: 0.0454  decode.d7.loss_mask: 0.2133  decode.d7.loss_dice: 0.2197  decode.d8.loss_cls: 0.0751  decode.d8.loss_mask: 0.2144  decode.d8.loss_dice: 0.2191
08/06 11:19:41 - mmengine - INFO - Iter(train) [ 65550/320000]  base_lr: 8.1360e-05 lr: 8.1360e-06  eta: 1 day, 10:51:56  time: 0.4954  data_time: 0.0111  memory: 5911  grad_norm: 44.4702  loss: 5.2076  decode.loss_cls: 0.0216  decode.loss_mask: 0.1894  decode.loss_dice: 0.2310  decode.d0.loss_cls: 0.7555  decode.d0.loss_mask: 0.1933  decode.d0.loss_dice: 0.2268  decode.d1.loss_cls: 0.0516  decode.d1.loss_mask: 0.1896  decode.d1.loss_dice: 0.2316  decode.d2.loss_cls: 0.0160  decode.d2.loss_mask: 0.1896  decode.d2.loss_dice: 0.2284  decode.d3.loss_cls: 0.0226  decode.d3.loss_mask: 0.1888  decode.d3.loss_dice: 0.2265  decode.d4.loss_cls: 0.0315  decode.d4.loss_mask: 0.1890  decode.d4.loss_dice: 0.2348  decode.d5.loss_cls: 0.0278  decode.d5.loss_mask: 0.1890  decode.d5.loss_dice: 0.2293  decode.d6.loss_cls: 0.0306  decode.d6.loss_mask: 0.1893  decode.d6.loss_dice: 0.2286  decode.d7.loss_cls: 0.0390  decode.d7.loss_mask: 0.1892  decode.d7.loss_dice: 0.2202  decode.d8.loss_cls: 0.0323  decode.d8.loss_mask: 0.1895  decode.d8.loss_dice: 0.2254
08/06 11:20:06 - mmengine - INFO - Iter(train) [ 65600/320000]  base_lr: 8.1345e-05 lr: 8.1345e-06  eta: 1 day, 10:51:33  time: 0.4957  data_time: 0.0113  memory: 5928  grad_norm: 180.4853  loss: 7.2495  decode.loss_cls: 0.1482  decode.loss_mask: 0.2517  decode.loss_dice: 0.2364  decode.d0.loss_cls: 0.9195  decode.d0.loss_mask: 0.2530  decode.d0.loss_dice: 0.2708  decode.d1.loss_cls: 0.1218  decode.d1.loss_mask: 0.2524  decode.d1.loss_dice: 0.2746  decode.d2.loss_cls: 0.1620  decode.d2.loss_mask: 0.2501  decode.d2.loss_dice: 0.2628  decode.d3.loss_cls: 0.0909  decode.d3.loss_mask: 0.2500  decode.d3.loss_dice: 0.2582  decode.d4.loss_cls: 0.0618  decode.d4.loss_mask: 0.2611  decode.d4.loss_dice: 0.2640  decode.d5.loss_cls: 0.1020  decode.d5.loss_mask: 0.2485  decode.d5.loss_dice: 0.2592  decode.d6.loss_cls: 0.1516  decode.d6.loss_mask: 0.2473  decode.d6.loss_dice: 0.2454  decode.d7.loss_cls: 0.1840  decode.d7.loss_mask: 0.2520  decode.d7.loss_dice: 0.2712  decode.d8.loss_cls: 0.1917  decode.d8.loss_mask: 0.2512  decode.d8.loss_dice: 0.2561
08/06 11:20:31 - mmengine - INFO - Iter(train) [ 65650/320000]  base_lr: 8.1331e-05 lr: 8.1331e-06  eta: 1 day, 10:51:09  time: 0.4961  data_time: 0.0113  memory: 5928  grad_norm: 176.7137  loss: 7.3208  decode.loss_cls: 0.2375  decode.loss_mask: 0.2266  decode.loss_dice: 0.2317  decode.d0.loss_cls: 0.9109  decode.d0.loss_mask: 0.2282  decode.d0.loss_dice: 0.2294  decode.d1.loss_cls: 0.1357  decode.d1.loss_mask: 0.2287  decode.d1.loss_dice: 0.2328  decode.d2.loss_cls: 0.1360  decode.d2.loss_mask: 0.2400  decode.d2.loss_dice: 0.2459  decode.d3.loss_cls: 0.1743  decode.d3.loss_mask: 0.2311  decode.d3.loss_dice: 0.2351  decode.d4.loss_cls: 0.2297  decode.d4.loss_mask: 0.2285  decode.d4.loss_dice: 0.2399  decode.d5.loss_cls: 0.2158  decode.d5.loss_mask: 0.2278  decode.d5.loss_dice: 0.2410  decode.d6.loss_cls: 0.2512  decode.d6.loss_mask: 0.2312  decode.d6.loss_dice: 0.2327  decode.d7.loss_cls: 0.1805  decode.d7.loss_mask: 0.2306  decode.d7.loss_dice: 0.2301  decode.d8.loss_cls: 0.1958  decode.d8.loss_mask: 0.2283  decode.d8.loss_dice: 0.2336
08/06 11:20:56 - mmengine - INFO - Iter(train) [ 65700/320000]  base_lr: 8.1316e-05 lr: 8.1316e-06  eta: 1 day, 10:50:45  time: 0.4959  data_time: 0.0114  memory: 5895  grad_norm: 188.1432  loss: 8.9052  decode.loss_cls: 0.2525  decode.loss_mask: 0.2691  decode.loss_dice: 0.2892  decode.d0.loss_cls: 1.1427  decode.d0.loss_mask: 0.2626  decode.d0.loss_dice: 0.3025  decode.d1.loss_cls: 0.2312  decode.d1.loss_mask: 0.2595  decode.d1.loss_dice: 0.2973  decode.d2.loss_cls: 0.2628  decode.d2.loss_mask: 0.2726  decode.d2.loss_dice: 0.2941  decode.d3.loss_cls: 0.2093  decode.d3.loss_mask: 0.2613  decode.d3.loss_dice: 0.2992  decode.d4.loss_cls: 0.2131  decode.d4.loss_mask: 0.2589  decode.d4.loss_dice: 0.3013  decode.d5.loss_cls: 0.2523  decode.d5.loss_mask: 0.2646  decode.d5.loss_dice: 0.2946  decode.d6.loss_cls: 0.2716  decode.d6.loss_mask: 0.2718  decode.d6.loss_dice: 0.2832  decode.d7.loss_cls: 0.2271  decode.d7.loss_mask: 0.2720  decode.d7.loss_dice: 0.2931  decode.d8.loss_cls: 0.2327  decode.d8.loss_mask: 0.2694  decode.d8.loss_dice: 0.2936
08/06 11:21:21 - mmengine - INFO - Iter(train) [ 65750/320000]  base_lr: 8.1302e-05 lr: 8.1302e-06  eta: 1 day, 10:50:21  time: 0.4968  data_time: 0.0116  memory: 5894  grad_norm: 79.6287  loss: 7.2567  decode.loss_cls: 0.0673  decode.loss_mask: 0.3063  decode.loss_dice: 0.3021  decode.d0.loss_cls: 0.7986  decode.d0.loss_mask: 0.3081  decode.d0.loss_dice: 0.2952  decode.d1.loss_cls: 0.0315  decode.d1.loss_mask: 0.3012  decode.d1.loss_dice: 0.2911  decode.d2.loss_cls: 0.0286  decode.d2.loss_mask: 0.3001  decode.d2.loss_dice: 0.2965  decode.d3.loss_cls: 0.0360  decode.d3.loss_mask: 0.3059  decode.d3.loss_dice: 0.2950  decode.d4.loss_cls: 0.0649  decode.d4.loss_mask: 0.3042  decode.d4.loss_dice: 0.3039  decode.d5.loss_cls: 0.0711  decode.d5.loss_mask: 0.3047  decode.d5.loss_dice: 0.2918  decode.d6.loss_cls: 0.0386  decode.d6.loss_mask: 0.3097  decode.d6.loss_dice: 0.2957  decode.d7.loss_cls: 0.0394  decode.d7.loss_mask: 0.3087  decode.d7.loss_dice: 0.3006  decode.d8.loss_cls: 0.0583  decode.d8.loss_mask: 0.3052  decode.d8.loss_dice: 0.2965
08/06 11:21:46 - mmengine - INFO - Iter(train) [ 65800/320000]  base_lr: 8.1288e-05 lr: 8.1288e-06  eta: 1 day, 10:49:56  time: 0.4959  data_time: 0.0112  memory: 5894  grad_norm: 83.2477  loss: 6.3864  decode.loss_cls: 0.0875  decode.loss_mask: 0.1992  decode.loss_dice: 0.2312  decode.d0.loss_cls: 0.8764  decode.d0.loss_mask: 0.1983  decode.d0.loss_dice: 0.2229  decode.d1.loss_cls: 0.1551  decode.d1.loss_mask: 0.1988  decode.d1.loss_dice: 0.2591  decode.d2.loss_cls: 0.1020  decode.d2.loss_mask: 0.2010  decode.d2.loss_dice: 0.2345  decode.d3.loss_cls: 0.1528  decode.d3.loss_mask: 0.2009  decode.d3.loss_dice: 0.2313  decode.d4.loss_cls: 0.1739  decode.d4.loss_mask: 0.2012  decode.d4.loss_dice: 0.2241  decode.d5.loss_cls: 0.1522  decode.d5.loss_mask: 0.2000  decode.d5.loss_dice: 0.2230  decode.d6.loss_cls: 0.1575  decode.d6.loss_mask: 0.1981  decode.d6.loss_dice: 0.2205  decode.d7.loss_cls: 0.1407  decode.d7.loss_mask: 0.2018  decode.d7.loss_dice: 0.2279  decode.d8.loss_cls: 0.0794  decode.d8.loss_mask: 0.1982  decode.d8.loss_dice: 0.2369
08/06 11:22:10 - mmengine - INFO - Iter(train) [ 65850/320000]  base_lr: 8.1273e-05 lr: 8.1273e-06  eta: 1 day, 10:49:32  time: 0.4956  data_time: 0.0109  memory: 5875  grad_norm: 182.2599  loss: 8.0317  decode.loss_cls: 0.1388  decode.loss_mask: 0.2651  decode.loss_dice: 0.3159  decode.d0.loss_cls: 1.0535  decode.d0.loss_mask: 0.2762  decode.d0.loss_dice: 0.2982  decode.d1.loss_cls: 0.1460  decode.d1.loss_mask: 0.2636  decode.d1.loss_dice: 0.3187  decode.d2.loss_cls: 0.1209  decode.d2.loss_mask: 0.2558  decode.d2.loss_dice: 0.3041  decode.d3.loss_cls: 0.1130  decode.d3.loss_mask: 0.2626  decode.d3.loss_dice: 0.3247  decode.d4.loss_cls: 0.1347  decode.d4.loss_mask: 0.2672  decode.d4.loss_dice: 0.3141  decode.d5.loss_cls: 0.1245  decode.d5.loss_mask: 0.2632  decode.d5.loss_dice: 0.3099  decode.d6.loss_cls: 0.1448  decode.d6.loss_mask: 0.2569  decode.d6.loss_dice: 0.2959  decode.d7.loss_cls: 0.1472  decode.d7.loss_mask: 0.2603  decode.d7.loss_dice: 0.3123  decode.d8.loss_cls: 0.1717  decode.d8.loss_mask: 0.2584  decode.d8.loss_dice: 0.3133
08/06 11:22:35 - mmengine - INFO - Iter(train) [ 65900/320000]  base_lr: 8.1259e-05 lr: 8.1259e-06  eta: 1 day, 10:49:09  time: 0.4964  data_time: 0.0116  memory: 5928  grad_norm: 135.5807  loss: 7.2430  decode.loss_cls: 0.1907  decode.loss_mask: 0.2721  decode.loss_dice: 0.2712  decode.d0.loss_cls: 0.9368  decode.d0.loss_mask: 0.2242  decode.d0.loss_dice: 0.2946  decode.d1.loss_cls: 0.1132  decode.d1.loss_mask: 0.2242  decode.d1.loss_dice: 0.2758  decode.d2.loss_cls: 0.0488  decode.d2.loss_mask: 0.2341  decode.d2.loss_dice: 0.2997  decode.d3.loss_cls: 0.1108  decode.d3.loss_mask: 0.2324  decode.d3.loss_dice: 0.2905  decode.d4.loss_cls: 0.1165  decode.d4.loss_mask: 0.2433  decode.d4.loss_dice: 0.2949  decode.d5.loss_cls: 0.1210  decode.d5.loss_mask: 0.2287  decode.d5.loss_dice: 0.2914  decode.d6.loss_cls: 0.1191  decode.d6.loss_mask: 0.2245  decode.d6.loss_dice: 0.2956  decode.d7.loss_cls: 0.1338  decode.d7.loss_mask: 0.2234  decode.d7.loss_dice: 0.2763  decode.d8.loss_cls: 0.1292  decode.d8.loss_mask: 0.2301  decode.d8.loss_dice: 0.2961
08/06 11:23:00 - mmengine - INFO - Iter(train) [ 65950/320000]  base_lr: 8.1244e-05 lr: 8.1244e-06  eta: 1 day, 10:48:45  time: 0.4967  data_time: 0.0115  memory: 5911  grad_norm: 147.9175  loss: 6.4691  decode.loss_cls: 0.1344  decode.loss_mask: 0.2090  decode.loss_dice: 0.2517  decode.d0.loss_cls: 0.8985  decode.d0.loss_mask: 0.2095  decode.d0.loss_dice: 0.2514  decode.d1.loss_cls: 0.1344  decode.d1.loss_mask: 0.2074  decode.d1.loss_dice: 0.2440  decode.d2.loss_cls: 0.1042  decode.d2.loss_mask: 0.2082  decode.d2.loss_dice: 0.2553  decode.d3.loss_cls: 0.0935  decode.d3.loss_mask: 0.2091  decode.d3.loss_dice: 0.2338  decode.d4.loss_cls: 0.1157  decode.d4.loss_mask: 0.2074  decode.d4.loss_dice: 0.2406  decode.d5.loss_cls: 0.1017  decode.d5.loss_mask: 0.2084  decode.d5.loss_dice: 0.2484  decode.d6.loss_cls: 0.1318  decode.d6.loss_mask: 0.2087  decode.d6.loss_dice: 0.2407  decode.d7.loss_cls: 0.1120  decode.d7.loss_mask: 0.2065  decode.d7.loss_dice: 0.2399  decode.d8.loss_cls: 0.1018  decode.d8.loss_mask: 0.2085  decode.d8.loss_dice: 0.2525
08/06 11:23:25 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 11:23:25 - mmengine - INFO - Iter(train) [ 66000/320000]  base_lr: 8.1230e-05 lr: 8.1230e-06  eta: 1 day, 10:48:21  time: 0.4960  data_time: 0.0115  memory: 5891  grad_norm: 218.0125  loss: 6.6593  decode.loss_cls: 0.1368  decode.loss_mask: 0.2111  decode.loss_dice: 0.2625  decode.d0.loss_cls: 0.8951  decode.d0.loss_mask: 0.2144  decode.d0.loss_dice: 0.2656  decode.d1.loss_cls: 0.1578  decode.d1.loss_mask: 0.2093  decode.d1.loss_dice: 0.2508  decode.d2.loss_cls: 0.1317  decode.d2.loss_mask: 0.2088  decode.d2.loss_dice: 0.2563  decode.d3.loss_cls: 0.1153  decode.d3.loss_mask: 0.2130  decode.d3.loss_dice: 0.2563  decode.d4.loss_cls: 0.1211  decode.d4.loss_mask: 0.2158  decode.d4.loss_dice: 0.2585  decode.d5.loss_cls: 0.1110  decode.d5.loss_mask: 0.2189  decode.d5.loss_dice: 0.2526  decode.d6.loss_cls: 0.0980  decode.d6.loss_mask: 0.2171  decode.d6.loss_dice: 0.2577  decode.d7.loss_cls: 0.0782  decode.d7.loss_mask: 0.2314  decode.d7.loss_dice: 0.2591  decode.d8.loss_cls: 0.0889  decode.d8.loss_mask: 0.2084  decode.d8.loss_dice: 0.2578
08/06 11:23:50 - mmengine - INFO - Iter(train) [ 66050/320000]  base_lr: 8.1216e-05 lr: 8.1216e-06  eta: 1 day, 10:47:56  time: 0.4956  data_time: 0.0115  memory: 5891  grad_norm: 78.5670  loss: 7.1108  decode.loss_cls: 0.0399  decode.loss_mask: 0.2808  decode.loss_dice: 0.2933  decode.d0.loss_cls: 0.8843  decode.d0.loss_mask: 0.2858  decode.d0.loss_dice: 0.2749  decode.d1.loss_cls: 0.0345  decode.d1.loss_mask: 0.2813  decode.d1.loss_dice: 0.2809  decode.d2.loss_cls: 0.0619  decode.d2.loss_mask: 0.2794  decode.d2.loss_dice: 0.2741  decode.d3.loss_cls: 0.0831  decode.d3.loss_mask: 0.2789  decode.d3.loss_dice: 0.2656  decode.d4.loss_cls: 0.0836  decode.d4.loss_mask: 0.2841  decode.d4.loss_dice: 0.2799  decode.d5.loss_cls: 0.0360  decode.d5.loss_mask: 0.2784  decode.d5.loss_dice: 0.2878  decode.d6.loss_cls: 0.0799  decode.d6.loss_mask: 0.2785  decode.d6.loss_dice: 0.2849  decode.d7.loss_cls: 0.0514  decode.d7.loss_mask: 0.2819  decode.d7.loss_dice: 0.2982  decode.d8.loss_cls: 0.1370  decode.d8.loss_mask: 0.2835  decode.d8.loss_dice: 0.2669
08/06 11:24:15 - mmengine - INFO - Iter(train) [ 66100/320000]  base_lr: 8.1201e-05 lr: 8.1201e-06  eta: 1 day, 10:47:32  time: 0.4957  data_time: 0.0115  memory: 5894  grad_norm: 82.6114  loss: 7.1000  decode.loss_cls: 0.0352  decode.loss_mask: 0.3150  decode.loss_dice: 0.2961  decode.d0.loss_cls: 0.7893  decode.d0.loss_mask: 0.2912  decode.d0.loss_dice: 0.2794  decode.d1.loss_cls: 0.1015  decode.d1.loss_mask: 0.2965  decode.d1.loss_dice: 0.2865  decode.d2.loss_cls: 0.0468  decode.d2.loss_mask: 0.2921  decode.d2.loss_dice: 0.2756  decode.d3.loss_cls: 0.0403  decode.d3.loss_mask: 0.2970  decode.d3.loss_dice: 0.2726  decode.d4.loss_cls: 0.0450  decode.d4.loss_mask: 0.2932  decode.d4.loss_dice: 0.2957  decode.d5.loss_cls: 0.0700  decode.d5.loss_mask: 0.2908  decode.d5.loss_dice: 0.2937  decode.d6.loss_cls: 0.0402  decode.d6.loss_mask: 0.2921  decode.d6.loss_dice: 0.2721  decode.d7.loss_cls: 0.0424  decode.d7.loss_mask: 0.2911  decode.d7.loss_dice: 0.3035  decode.d8.loss_cls: 0.0400  decode.d8.loss_mask: 0.3004  decode.d8.loss_dice: 0.3149
08/06 11:24:40 - mmengine - INFO - Iter(train) [ 66150/320000]  base_lr: 8.1187e-05 lr: 8.1187e-06  eta: 1 day, 10:47:08  time: 0.4955  data_time: 0.0114  memory: 5878  grad_norm: 175.3502  loss: 6.4422  decode.loss_cls: 0.0580  decode.loss_mask: 0.2711  decode.loss_dice: 0.2432  decode.d0.loss_cls: 0.8264  decode.d0.loss_mask: 0.2764  decode.d0.loss_dice: 0.2560  decode.d1.loss_cls: 0.0590  decode.d1.loss_mask: 0.2730  decode.d1.loss_dice: 0.2423  decode.d2.loss_cls: 0.0376  decode.d2.loss_mask: 0.2776  decode.d2.loss_dice: 0.2379  decode.d3.loss_cls: 0.0304  decode.d3.loss_mask: 0.2717  decode.d3.loss_dice: 0.2411  decode.d4.loss_cls: 0.1127  decode.d4.loss_mask: 0.2655  decode.d4.loss_dice: 0.2339  decode.d5.loss_cls: 0.0429  decode.d5.loss_mask: 0.2665  decode.d5.loss_dice: 0.2475  decode.d6.loss_cls: 0.0365  decode.d6.loss_mask: 0.2656  decode.d6.loss_dice: 0.2436  decode.d7.loss_cls: 0.0225  decode.d7.loss_mask: 0.2689  decode.d7.loss_dice: 0.2502  decode.d8.loss_cls: 0.0588  decode.d8.loss_mask: 0.2742  decode.d8.loss_dice: 0.2511
08/06 11:25:04 - mmengine - INFO - Iter(train) [ 66200/320000]  base_lr: 8.1172e-05 lr: 8.1172e-06  eta: 1 day, 10:46:44  time: 0.4967  data_time: 0.0115  memory: 5911  grad_norm: 141.8784  loss: 6.6727  decode.loss_cls: 0.0849  decode.loss_mask: 0.2755  decode.loss_dice: 0.2568  decode.d0.loss_cls: 0.7095  decode.d0.loss_mask: 0.2793  decode.d0.loss_dice: 0.2416  decode.d1.loss_cls: 0.0655  decode.d1.loss_mask: 0.2754  decode.d1.loss_dice: 0.2477  decode.d2.loss_cls: 0.0868  decode.d2.loss_mask: 0.2729  decode.d2.loss_dice: 0.2438  decode.d3.loss_cls: 0.0840  decode.d3.loss_mask: 0.2736  decode.d3.loss_dice: 0.2464  decode.d4.loss_cls: 0.0819  decode.d4.loss_mask: 0.2722  decode.d4.loss_dice: 0.2442  decode.d5.loss_cls: 0.0761  decode.d5.loss_mask: 0.2737  decode.d5.loss_dice: 0.2494  decode.d6.loss_cls: 0.0930  decode.d6.loss_mask: 0.2741  decode.d6.loss_dice: 0.2465  decode.d7.loss_cls: 0.0756  decode.d7.loss_mask: 0.2741  decode.d7.loss_dice: 0.2536  decode.d8.loss_cls: 0.0883  decode.d8.loss_mask: 0.2734  decode.d8.loss_dice: 0.2533
08/06 11:25:29 - mmengine - INFO - Iter(train) [ 66250/320000]  base_lr: 8.1158e-05 lr: 8.1158e-06  eta: 1 day, 10:46:20  time: 0.4959  data_time: 0.0117  memory: 5911  grad_norm: 59.2094  loss: 5.9981  decode.loss_cls: 0.0086  decode.loss_mask: 0.2677  decode.loss_dice: 0.2564  decode.d0.loss_cls: 0.6937  decode.d0.loss_mask: 0.2661  decode.d0.loss_dice: 0.2475  decode.d1.loss_cls: 0.0136  decode.d1.loss_mask: 0.2638  decode.d1.loss_dice: 0.2531  decode.d2.loss_cls: 0.0125  decode.d2.loss_mask: 0.2656  decode.d2.loss_dice: 0.2544  decode.d3.loss_cls: 0.0127  decode.d3.loss_mask: 0.2674  decode.d3.loss_dice: 0.2589  decode.d4.loss_cls: 0.0136  decode.d4.loss_mask: 0.2654  decode.d4.loss_dice: 0.2531  decode.d5.loss_cls: 0.0123  decode.d5.loss_mask: 0.2633  decode.d5.loss_dice: 0.2545  decode.d6.loss_cls: 0.0163  decode.d6.loss_mask: 0.2644  decode.d6.loss_dice: 0.2549  decode.d7.loss_cls: 0.0122  decode.d7.loss_mask: 0.2646  decode.d7.loss_dice: 0.2523  decode.d8.loss_cls: 0.0109  decode.d8.loss_mask: 0.2651  decode.d8.loss_dice: 0.2530
08/06 11:25:54 - mmengine - INFO - Iter(train) [ 66300/320000]  base_lr: 8.1144e-05 lr: 8.1144e-06  eta: 1 day, 10:45:56  time: 0.4970  data_time: 0.0116  memory: 5911  grad_norm: 126.2844  loss: 7.3109  decode.loss_cls: 0.1732  decode.loss_mask: 0.2272  decode.loss_dice: 0.2569  decode.d0.loss_cls: 0.9401  decode.d0.loss_mask: 0.2214  decode.d0.loss_dice: 0.2563  decode.d1.loss_cls: 0.1346  decode.d1.loss_mask: 0.2411  decode.d1.loss_dice: 0.2771  decode.d2.loss_cls: 0.1844  decode.d2.loss_mask: 0.2368  decode.d2.loss_dice: 0.2903  decode.d3.loss_cls: 0.1578  decode.d3.loss_mask: 0.2330  decode.d3.loss_dice: 0.2747  decode.d4.loss_cls: 0.1512  decode.d4.loss_mask: 0.2333  decode.d4.loss_dice: 0.2658  decode.d5.loss_cls: 0.1278  decode.d5.loss_mask: 0.2345  decode.d5.loss_dice: 0.2621  decode.d6.loss_cls: 0.1169  decode.d6.loss_mask: 0.2428  decode.d6.loss_dice: 0.2818  decode.d7.loss_cls: 0.1312  decode.d7.loss_mask: 0.2317  decode.d7.loss_dice: 0.2607  decode.d8.loss_cls: 0.1745  decode.d8.loss_mask: 0.2334  decode.d8.loss_dice: 0.2586
08/06 11:26:19 - mmengine - INFO - Iter(train) [ 66350/320000]  base_lr: 8.1129e-05 lr: 8.1129e-06  eta: 1 day, 10:45:32  time: 0.4964  data_time: 0.0114  memory: 5876  grad_norm: 60.3732  loss: 6.4810  decode.loss_cls: 0.0961  decode.loss_mask: 0.2535  decode.loss_dice: 0.2437  decode.d0.loss_cls: 0.7641  decode.d0.loss_mask: 0.2584  decode.d0.loss_dice: 0.2433  decode.d1.loss_cls: 0.0851  decode.d1.loss_mask: 0.2511  decode.d1.loss_dice: 0.2425  decode.d2.loss_cls: 0.1325  decode.d2.loss_mask: 0.2523  decode.d2.loss_dice: 0.2372  decode.d3.loss_cls: 0.0868  decode.d3.loss_mask: 0.2494  decode.d3.loss_dice: 0.2408  decode.d4.loss_cls: 0.0819  decode.d4.loss_mask: 0.2488  decode.d4.loss_dice: 0.2359  decode.d5.loss_cls: 0.0834  decode.d5.loss_mask: 0.2498  decode.d5.loss_dice: 0.2408  decode.d6.loss_cls: 0.0522  decode.d6.loss_mask: 0.2503  decode.d6.loss_dice: 0.2379  decode.d7.loss_cls: 0.0576  decode.d7.loss_mask: 0.2520  decode.d7.loss_dice: 0.2378  decode.d8.loss_cls: 0.1276  decode.d8.loss_mask: 0.2508  decode.d8.loss_dice: 0.2372
08/06 11:26:44 - mmengine - INFO - Iter(train) [ 66400/320000]  base_lr: 8.1115e-05 lr: 8.1115e-06  eta: 1 day, 10:45:07  time: 0.4968  data_time: 0.0114  memory: 5894  grad_norm: 72.9341  loss: 6.1697  decode.loss_cls: 0.0537  decode.loss_mask: 0.1909  decode.loss_dice: 0.2720  decode.d0.loss_cls: 0.8768  decode.d0.loss_mask: 0.1933  decode.d0.loss_dice: 0.2658  decode.d1.loss_cls: 0.0826  decode.d1.loss_mask: 0.1892  decode.d1.loss_dice: 0.2710  decode.d2.loss_cls: 0.0715  decode.d2.loss_mask: 0.1899  decode.d2.loss_dice: 0.2862  decode.d3.loss_cls: 0.0692  decode.d3.loss_mask: 0.1887  decode.d3.loss_dice: 0.2492  decode.d4.loss_cls: 0.0648  decode.d4.loss_mask: 0.1911  decode.d4.loss_dice: 0.2750  decode.d5.loss_cls: 0.0796  decode.d5.loss_mask: 0.1897  decode.d5.loss_dice: 0.2626  decode.d6.loss_cls: 0.0890  decode.d6.loss_mask: 0.1915  decode.d6.loss_dice: 0.2760  decode.d7.loss_cls: 0.0606  decode.d7.loss_mask: 0.1889  decode.d7.loss_dice: 0.2802  decode.d8.loss_cls: 0.0965  decode.d8.loss_mask: 0.1900  decode.d8.loss_dice: 0.2839
08/06 11:27:08 - mmengine - INFO - Iter(train) [ 66450/320000]  base_lr: 8.1100e-05 lr: 8.1100e-06  eta: 1 day, 10:44:43  time: 0.4976  data_time: 0.0114  memory: 5909  grad_norm: 80.6165  loss: 7.3150  decode.loss_cls: 0.0956  decode.loss_mask: 0.2523  decode.loss_dice: 0.2677  decode.d0.loss_cls: 0.9173  decode.d0.loss_mask: 0.2560  decode.d0.loss_dice: 0.2784  decode.d1.loss_cls: 0.1245  decode.d1.loss_mask: 0.2545  decode.d1.loss_dice: 0.2684  decode.d2.loss_cls: 0.1483  decode.d2.loss_mask: 0.2493  decode.d2.loss_dice: 0.2578  decode.d3.loss_cls: 0.1323  decode.d3.loss_mask: 0.2497  decode.d3.loss_dice: 0.2555  decode.d4.loss_cls: 0.1823  decode.d4.loss_mask: 0.2500  decode.d4.loss_dice: 0.2782  decode.d5.loss_cls: 0.1644  decode.d5.loss_mask: 0.2506  decode.d5.loss_dice: 0.2605  decode.d6.loss_cls: 0.1417  decode.d6.loss_mask: 0.2515  decode.d6.loss_dice: 0.2624  decode.d7.loss_cls: 0.1232  decode.d7.loss_mask: 0.2524  decode.d7.loss_dice: 0.2711  decode.d8.loss_cls: 0.1151  decode.d8.loss_mask: 0.2499  decode.d8.loss_dice: 0.2539
08/06 11:27:33 - mmengine - INFO - Iter(train) [ 66500/320000]  base_lr: 8.1086e-05 lr: 8.1086e-06  eta: 1 day, 10:44:20  time: 0.4964  data_time: 0.0115  memory: 5875  grad_norm: 180.3992  loss: 6.2901  decode.loss_cls: 0.0388  decode.loss_mask: 0.2497  decode.loss_dice: 0.2558  decode.d0.loss_cls: 0.7876  decode.d0.loss_mask: 0.2481  decode.d0.loss_dice: 0.2651  decode.d1.loss_cls: 0.0658  decode.d1.loss_mask: 0.2483  decode.d1.loss_dice: 0.2648  decode.d2.loss_cls: 0.0488  decode.d2.loss_mask: 0.2499  decode.d2.loss_dice: 0.2439  decode.d3.loss_cls: 0.0424  decode.d3.loss_mask: 0.2465  decode.d3.loss_dice: 0.2503  decode.d4.loss_cls: 0.0389  decode.d4.loss_mask: 0.2502  decode.d4.loss_dice: 0.2596  decode.d5.loss_cls: 0.0509  decode.d5.loss_mask: 0.2484  decode.d5.loss_dice: 0.2497  decode.d6.loss_cls: 0.0528  decode.d6.loss_mask: 0.2534  decode.d6.loss_dice: 0.2592  decode.d7.loss_cls: 0.0838  decode.d7.loss_mask: 0.2476  decode.d7.loss_dice: 0.2504  decode.d8.loss_cls: 0.0378  decode.d8.loss_mask: 0.2489  decode.d8.loss_dice: 0.2528
08/06 11:27:58 - mmengine - INFO - Iter(train) [ 66550/320000]  base_lr: 8.1072e-05 lr: 8.1072e-06  eta: 1 day, 10:43:56  time: 0.4962  data_time: 0.0114  memory: 5878  grad_norm: 263.5399  loss: 10.9152  decode.loss_cls: 0.2923  decode.loss_mask: 0.3713  decode.loss_dice: 0.3391  decode.d0.loss_cls: 1.0601  decode.d0.loss_mask: 0.3479  decode.d0.loss_dice: 0.3519  decode.d1.loss_cls: 0.3147  decode.d1.loss_mask: 0.3227  decode.d1.loss_dice: 0.2906  decode.d2.loss_cls: 0.3236  decode.d2.loss_mask: 0.3296  decode.d2.loss_dice: 0.3179  decode.d3.loss_cls: 0.3101  decode.d3.loss_mask: 0.3945  decode.d3.loss_dice: 0.3477  decode.d4.loss_cls: 0.3406  decode.d4.loss_mask: 0.3765  decode.d4.loss_dice: 0.3712  decode.d5.loss_cls: 0.3559  decode.d5.loss_mask: 0.3887  decode.d5.loss_dice: 0.3537  decode.d6.loss_cls: 0.2979  decode.d6.loss_mask: 0.3135  decode.d6.loss_dice: 0.3233  decode.d7.loss_cls: 0.2815  decode.d7.loss_mask: 0.3970  decode.d7.loss_dice: 0.3432  decode.d8.loss_cls: 0.3184  decode.d8.loss_mask: 0.3751  decode.d8.loss_dice: 0.3648
08/06 11:28:23 - mmengine - INFO - Iter(train) [ 66600/320000]  base_lr: 8.1057e-05 lr: 8.1057e-06  eta: 1 day, 10:43:31  time: 0.4962  data_time: 0.0112  memory: 5878  grad_norm: 116.0823  loss: 8.2994  decode.loss_cls: 0.1484  decode.loss_mask: 0.3151  decode.loss_dice: 0.2759  decode.d0.loss_cls: 0.9428  decode.d0.loss_mask: 0.2840  decode.d0.loss_dice: 0.2737  decode.d1.loss_cls: 0.2136  decode.d1.loss_mask: 0.2723  decode.d1.loss_dice: 0.2698  decode.d2.loss_cls: 0.1760  decode.d2.loss_mask: 0.2773  decode.d2.loss_dice: 0.2700  decode.d3.loss_cls: 0.1564  decode.d3.loss_mask: 0.2853  decode.d3.loss_dice: 0.2697  decode.d4.loss_cls: 0.2184  decode.d4.loss_mask: 0.2790  decode.d4.loss_dice: 0.2687  decode.d5.loss_cls: 0.2227  decode.d5.loss_mask: 0.2932  decode.d5.loss_dice: 0.2644  decode.d6.loss_cls: 0.2421  decode.d6.loss_mask: 0.2991  decode.d6.loss_dice: 0.3061  decode.d7.loss_cls: 0.1716  decode.d7.loss_mask: 0.2859  decode.d7.loss_dice: 0.2648  decode.d8.loss_cls: 0.1710  decode.d8.loss_mask: 0.2973  decode.d8.loss_dice: 0.2846
08/06 11:28:48 - mmengine - INFO - Iter(train) [ 66650/320000]  base_lr: 8.1043e-05 lr: 8.1043e-06  eta: 1 day, 10:43:07  time: 0.4964  data_time: 0.0113  memory: 5874  grad_norm: 203.8748  loss: 7.4984  decode.loss_cls: 0.1610  decode.loss_mask: 0.2347  decode.loss_dice: 0.2573  decode.d0.loss_cls: 1.0479  decode.d0.loss_mask: 0.2300  decode.d0.loss_dice: 0.2294  decode.d1.loss_cls: 0.1668  decode.d1.loss_mask: 0.2329  decode.d1.loss_dice: 0.2553  decode.d2.loss_cls: 0.1286  decode.d2.loss_mask: 0.2351  decode.d2.loss_dice: 0.2633  decode.d3.loss_cls: 0.1870  decode.d3.loss_mask: 0.2354  decode.d3.loss_dice: 0.2596  decode.d4.loss_cls: 0.1845  decode.d4.loss_mask: 0.2367  decode.d4.loss_dice: 0.2708  decode.d5.loss_cls: 0.1818  decode.d5.loss_mask: 0.2393  decode.d5.loss_dice: 0.2625  decode.d6.loss_cls: 0.1406  decode.d6.loss_mask: 0.2345  decode.d6.loss_dice: 0.2720  decode.d7.loss_cls: 0.1493  decode.d7.loss_mask: 0.2348  decode.d7.loss_dice: 0.2716  decode.d8.loss_cls: 0.2023  decode.d8.loss_mask: 0.2352  decode.d8.loss_dice: 0.2580
08/06 11:29:13 - mmengine - INFO - Iter(train) [ 66700/320000]  base_lr: 8.1029e-05 lr: 8.1029e-06  eta: 1 day, 10:42:43  time: 0.4962  data_time: 0.0113  memory: 5891  grad_norm: 99.0689  loss: 7.9411  decode.loss_cls: 0.2812  decode.loss_mask: 0.2311  decode.loss_dice: 0.3077  decode.d0.loss_cls: 0.7910  decode.d0.loss_mask: 0.2060  decode.d0.loss_dice: 0.2664  decode.d1.loss_cls: 0.2261  decode.d1.loss_mask: 0.2270  decode.d1.loss_dice: 0.2490  decode.d2.loss_cls: 0.2496  decode.d2.loss_mask: 0.2254  decode.d2.loss_dice: 0.2381  decode.d3.loss_cls: 0.2602  decode.d3.loss_mask: 0.2132  decode.d3.loss_dice: 0.2463  decode.d4.loss_cls: 0.2602  decode.d4.loss_mask: 0.2398  decode.d4.loss_dice: 0.2667  decode.d5.loss_cls: 0.2633  decode.d5.loss_mask: 0.2389  decode.d5.loss_dice: 0.2415  decode.d6.loss_cls: 0.3038  decode.d6.loss_mask: 0.2369  decode.d6.loss_dice: 0.2298  decode.d7.loss_cls: 0.2563  decode.d7.loss_mask: 0.2176  decode.d7.loss_dice: 0.2363  decode.d8.loss_cls: 0.2545  decode.d8.loss_mask: 0.2290  decode.d8.loss_dice: 0.2483
08/06 11:29:37 - mmengine - INFO - Iter(train) [ 66750/320000]  base_lr: 8.1014e-05 lr: 8.1014e-06  eta: 1 day, 10:42:19  time: 0.4959  data_time: 0.0112  memory: 5894  grad_norm: 102.9349  loss: 8.3100  decode.loss_cls: 0.1254  decode.loss_mask: 0.2856  decode.loss_dice: 0.2913  decode.d0.loss_cls: 1.0221  decode.d0.loss_mask: 0.2778  decode.d0.loss_dice: 0.2972  decode.d1.loss_cls: 0.1837  decode.d1.loss_mask: 0.2717  decode.d1.loss_dice: 0.2994  decode.d2.loss_cls: 0.1791  decode.d2.loss_mask: 0.2770  decode.d2.loss_dice: 0.2999  decode.d3.loss_cls: 0.1152  decode.d3.loss_mask: 0.2744  decode.d3.loss_dice: 0.2868  decode.d4.loss_cls: 0.0831  decode.d4.loss_mask: 0.2861  decode.d4.loss_dice: 0.3143  decode.d5.loss_cls: 0.2223  decode.d5.loss_mask: 0.2739  decode.d5.loss_dice: 0.3155  decode.d6.loss_cls: 0.2038  decode.d6.loss_mask: 0.2869  decode.d6.loss_dice: 0.3057  decode.d7.loss_cls: 0.1915  decode.d7.loss_mask: 0.2727  decode.d7.loss_dice: 0.2798  decode.d8.loss_cls: 0.2134  decode.d8.loss_mask: 0.2783  decode.d8.loss_dice: 0.2963
08/06 11:30:02 - mmengine - INFO - Iter(train) [ 66800/320000]  base_lr: 8.1000e-05 lr: 8.1000e-06  eta: 1 day, 10:41:55  time: 0.4958  data_time: 0.0114  memory: 5894  grad_norm: 111.7629  loss: 7.0468  decode.loss_cls: 0.1027  decode.loss_mask: 0.2326  decode.loss_dice: 0.2863  decode.d0.loss_cls: 0.9580  decode.d0.loss_mask: 0.2289  decode.d0.loss_dice: 0.3098  decode.d1.loss_cls: 0.1464  decode.d1.loss_mask: 0.2279  decode.d1.loss_dice: 0.2894  decode.d2.loss_cls: 0.1086  decode.d2.loss_mask: 0.2295  decode.d2.loss_dice: 0.2653  decode.d3.loss_cls: 0.0967  decode.d3.loss_mask: 0.2304  decode.d3.loss_dice: 0.2908  decode.d4.loss_cls: 0.0982  decode.d4.loss_mask: 0.2266  decode.d4.loss_dice: 0.2746  decode.d5.loss_cls: 0.0839  decode.d5.loss_mask: 0.2294  decode.d5.loss_dice: 0.2717  decode.d6.loss_cls: 0.1097  decode.d6.loss_mask: 0.2264  decode.d6.loss_dice: 0.2807  decode.d7.loss_cls: 0.1083  decode.d7.loss_mask: 0.2289  decode.d7.loss_dice: 0.2795  decode.d8.loss_cls: 0.1078  decode.d8.loss_mask: 0.2296  decode.d8.loss_dice: 0.2884
08/06 11:30:27 - mmengine - INFO - Iter(train) [ 66850/320000]  base_lr: 8.0985e-05 lr: 8.0985e-06  eta: 1 day, 10:41:31  time: 0.4967  data_time: 0.0111  memory: 5911  grad_norm: 66.3694  loss: 6.8270  decode.loss_cls: 0.1437  decode.loss_mask: 0.2025  decode.loss_dice: 0.2217  decode.d0.loss_cls: 1.0057  decode.d0.loss_mask: 0.2045  decode.d0.loss_dice: 0.2721  decode.d1.loss_cls: 0.1253  decode.d1.loss_mask: 0.2002  decode.d1.loss_dice: 0.2433  decode.d2.loss_cls: 0.1248  decode.d2.loss_mask: 0.2019  decode.d2.loss_dice: 0.2480  decode.d3.loss_cls: 0.1751  decode.d3.loss_mask: 0.2030  decode.d3.loss_dice: 0.2488  decode.d4.loss_cls: 0.1497  decode.d4.loss_mask: 0.2034  decode.d4.loss_dice: 0.2527  decode.d5.loss_cls: 0.1463  decode.d5.loss_mask: 0.2016  decode.d5.loss_dice: 0.2431  decode.d6.loss_cls: 0.1614  decode.d6.loss_mask: 0.2043  decode.d6.loss_dice: 0.2528  decode.d7.loss_cls: 0.1401  decode.d7.loss_mask: 0.2019  decode.d7.loss_dice: 0.2641  decode.d8.loss_cls: 0.1392  decode.d8.loss_mask: 0.2016  decode.d8.loss_dice: 0.2442
08/06 11:30:52 - mmengine - INFO - Iter(train) [ 66900/320000]  base_lr: 8.0971e-05 lr: 8.0971e-06  eta: 1 day, 10:41:07  time: 0.4965  data_time: 0.0114  memory: 5894  grad_norm: 186.9936  loss: 8.1620  decode.loss_cls: 0.1249  decode.loss_mask: 0.2972  decode.loss_dice: 0.3124  decode.d0.loss_cls: 0.8787  decode.d0.loss_mask: 0.3120  decode.d0.loss_dice: 0.3257  decode.d1.loss_cls: 0.0932  decode.d1.loss_mask: 0.3012  decode.d1.loss_dice: 0.3134  decode.d2.loss_cls: 0.1018  decode.d2.loss_mask: 0.3054  decode.d2.loss_dice: 0.3291  decode.d3.loss_cls: 0.1143  decode.d3.loss_mask: 0.2974  decode.d3.loss_dice: 0.3138  decode.d4.loss_cls: 0.1216  decode.d4.loss_mask: 0.3015  decode.d4.loss_dice: 0.3116  decode.d5.loss_cls: 0.1178  decode.d5.loss_mask: 0.3101  decode.d5.loss_dice: 0.3334  decode.d6.loss_cls: 0.1218  decode.d6.loss_mask: 0.3002  decode.d6.loss_dice: 0.3179  decode.d7.loss_cls: 0.1414  decode.d7.loss_mask: 0.3034  decode.d7.loss_dice: 0.3236  decode.d8.loss_cls: 0.1190  decode.d8.loss_mask: 0.3028  decode.d8.loss_dice: 0.3151
08/06 11:31:17 - mmengine - INFO - Iter(train) [ 66950/320000]  base_lr: 8.0957e-05 lr: 8.0957e-06  eta: 1 day, 10:40:43  time: 0.4975  data_time: 0.0115  memory: 5911  grad_norm: 105.5186  loss: 7.9547  decode.loss_cls: 0.1087  decode.loss_mask: 0.2592  decode.loss_dice: 0.3348  decode.d0.loss_cls: 0.8439  decode.d0.loss_mask: 0.2576  decode.d0.loss_dice: 0.3421  decode.d1.loss_cls: 0.2214  decode.d1.loss_mask: 0.2559  decode.d1.loss_dice: 0.3229  decode.d2.loss_cls: 0.1305  decode.d2.loss_mask: 0.2511  decode.d2.loss_dice: 0.3236  decode.d3.loss_cls: 0.1379  decode.d3.loss_mask: 0.2518  decode.d3.loss_dice: 0.3188  decode.d4.loss_cls: 0.1502  decode.d4.loss_mask: 0.2542  decode.d4.loss_dice: 0.3250  decode.d5.loss_cls: 0.2233  decode.d5.loss_mask: 0.2533  decode.d5.loss_dice: 0.3145  decode.d6.loss_cls: 0.1400  decode.d6.loss_mask: 0.2515  decode.d6.loss_dice: 0.3086  decode.d7.loss_cls: 0.1187  decode.d7.loss_mask: 0.2538  decode.d7.loss_dice: 0.3279  decode.d8.loss_cls: 0.0971  decode.d8.loss_mask: 0.2564  decode.d8.loss_dice: 0.3200
08/06 11:31:42 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 11:31:42 - mmengine - INFO - Iter(train) [ 67000/320000]  base_lr: 8.0942e-05 lr: 8.0942e-06  eta: 1 day, 10:40:19  time: 0.4971  data_time: 0.0115  memory: 5928  grad_norm: 56.4213  loss: 6.4545  decode.loss_cls: 0.0898  decode.loss_mask: 0.2500  decode.loss_dice: 0.2200  decode.d0.loss_cls: 0.8820  decode.d0.loss_mask: 0.2564  decode.d0.loss_dice: 0.2088  decode.d1.loss_cls: 0.1497  decode.d1.loss_mask: 0.2485  decode.d1.loss_dice: 0.2151  decode.d2.loss_cls: 0.1025  decode.d2.loss_mask: 0.2477  decode.d2.loss_dice: 0.2125  decode.d3.loss_cls: 0.1096  decode.d3.loss_mask: 0.2507  decode.d3.loss_dice: 0.2186  decode.d4.loss_cls: 0.0919  decode.d4.loss_mask: 0.2513  decode.d4.loss_dice: 0.2200  decode.d5.loss_cls: 0.0929  decode.d5.loss_mask: 0.2483  decode.d5.loss_dice: 0.2161  decode.d6.loss_cls: 0.0834  decode.d6.loss_mask: 0.2517  decode.d6.loss_dice: 0.2138  decode.d7.loss_cls: 0.1001  decode.d7.loss_mask: 0.2513  decode.d7.loss_dice: 0.2200  decode.d8.loss_cls: 0.0813  decode.d8.loss_mask: 0.2515  decode.d8.loss_dice: 0.2191
08/06 11:32:07 - mmengine - INFO - Iter(train) [ 67050/320000]  base_lr: 8.0928e-05 lr: 8.0928e-06  eta: 1 day, 10:39:55  time: 0.4966  data_time: 0.0113  memory: 5909  grad_norm: 48.5652  loss: 5.8132  decode.loss_cls: 0.0326  decode.loss_mask: 0.2423  decode.loss_dice: 0.2228  decode.d0.loss_cls: 0.8127  decode.d0.loss_mask: 0.2393  decode.d0.loss_dice: 0.2312  decode.d1.loss_cls: 0.0176  decode.d1.loss_mask: 0.2392  decode.d1.loss_dice: 0.2308  decode.d2.loss_cls: 0.0234  decode.d2.loss_mask: 0.2411  decode.d2.loss_dice: 0.2297  decode.d3.loss_cls: 0.0354  decode.d3.loss_mask: 0.2412  decode.d3.loss_dice: 0.2312  decode.d4.loss_cls: 0.0302  decode.d4.loss_mask: 0.2383  decode.d4.loss_dice: 0.2395  decode.d5.loss_cls: 0.0253  decode.d5.loss_mask: 0.2392  decode.d5.loss_dice: 0.2378  decode.d6.loss_cls: 0.0361  decode.d6.loss_mask: 0.2407  decode.d6.loss_dice: 0.2470  decode.d7.loss_cls: 0.0310  decode.d7.loss_mask: 0.2405  decode.d7.loss_dice: 0.2533  decode.d8.loss_cls: 0.0269  decode.d8.loss_mask: 0.2382  decode.d8.loss_dice: 0.2188
08/06 11:32:31 - mmengine - INFO - Iter(train) [ 67100/320000]  base_lr: 8.0913e-05 lr: 8.0913e-06  eta: 1 day, 10:39:31  time: 0.4970  data_time: 0.0115  memory: 5895  grad_norm: 123.1162  loss: 7.0186  decode.loss_cls: 0.0935  decode.loss_mask: 0.2298  decode.loss_dice: 0.3170  decode.d0.loss_cls: 0.8458  decode.d0.loss_mask: 0.2296  decode.d0.loss_dice: 0.3143  decode.d1.loss_cls: 0.1230  decode.d1.loss_mask: 0.2301  decode.d1.loss_dice: 0.3051  decode.d2.loss_cls: 0.1269  decode.d2.loss_mask: 0.2299  decode.d2.loss_dice: 0.3229  decode.d3.loss_cls: 0.0785  decode.d3.loss_mask: 0.2301  decode.d3.loss_dice: 0.2921  decode.d4.loss_cls: 0.0636  decode.d4.loss_mask: 0.2310  decode.d4.loss_dice: 0.2959  decode.d5.loss_cls: 0.0583  decode.d5.loss_mask: 0.2312  decode.d5.loss_dice: 0.3032  decode.d6.loss_cls: 0.0686  decode.d6.loss_mask: 0.2303  decode.d6.loss_dice: 0.2992  decode.d7.loss_cls: 0.0750  decode.d7.loss_mask: 0.2308  decode.d7.loss_dice: 0.2945  decode.d8.loss_cls: 0.1288  decode.d8.loss_mask: 0.2297  decode.d8.loss_dice: 0.3102
08/06 11:32:56 - mmengine - INFO - Iter(train) [ 67150/320000]  base_lr: 8.0899e-05 lr: 8.0899e-06  eta: 1 day, 10:39:07  time: 0.4962  data_time: 0.0113  memory: 5911  grad_norm: 81.3592  loss: 7.5151  decode.loss_cls: 0.0646  decode.loss_mask: 0.2583  decode.loss_dice: 0.2855  decode.d0.loss_cls: 0.9170  decode.d0.loss_mask: 0.2607  decode.d0.loss_dice: 0.2925  decode.d1.loss_cls: 0.1903  decode.d1.loss_mask: 0.2653  decode.d1.loss_dice: 0.2986  decode.d2.loss_cls: 0.1522  decode.d2.loss_mask: 0.2586  decode.d2.loss_dice: 0.2853  decode.d3.loss_cls: 0.1088  decode.d3.loss_mask: 0.2574  decode.d3.loss_dice: 0.3058  decode.d4.loss_cls: 0.1389  decode.d4.loss_mask: 0.2607  decode.d4.loss_dice: 0.2950  decode.d5.loss_cls: 0.0888  decode.d5.loss_mask: 0.2618  decode.d5.loss_dice: 0.2951  decode.d6.loss_cls: 0.0686  decode.d6.loss_mask: 0.2602  decode.d6.loss_dice: 0.2726  decode.d7.loss_cls: 0.0988  decode.d7.loss_mask: 0.2596  decode.d7.loss_dice: 0.3000  decode.d8.loss_cls: 0.1555  decode.d8.loss_mask: 0.2589  decode.d8.loss_dice: 0.2997
08/06 11:33:21 - mmengine - INFO - Iter(train) [ 67200/320000]  base_lr: 8.0885e-05 lr: 8.0885e-06  eta: 1 day, 10:38:43  time: 0.4953  data_time: 0.0112  memory: 5911  grad_norm: 177.8591  loss: 5.7517  decode.loss_cls: 0.0313  decode.loss_mask: 0.1967  decode.loss_dice: 0.2620  decode.d0.loss_cls: 0.8682  decode.d0.loss_mask: 0.2062  decode.d0.loss_dice: 0.2569  decode.d1.loss_cls: 0.0467  decode.d1.loss_mask: 0.1972  decode.d1.loss_dice: 0.2485  decode.d2.loss_cls: 0.0391  decode.d2.loss_mask: 0.1981  decode.d2.loss_dice: 0.2401  decode.d3.loss_cls: 0.0339  decode.d3.loss_mask: 0.1982  decode.d3.loss_dice: 0.2353  decode.d4.loss_cls: 0.0566  decode.d4.loss_mask: 0.1963  decode.d4.loss_dice: 0.2466  decode.d5.loss_cls: 0.0448  decode.d5.loss_mask: 0.1965  decode.d5.loss_dice: 0.2488  decode.d6.loss_cls: 0.0512  decode.d6.loss_mask: 0.1966  decode.d6.loss_dice: 0.2564  decode.d7.loss_cls: 0.0484  decode.d7.loss_mask: 0.1949  decode.d7.loss_dice: 0.2654  decode.d8.loss_cls: 0.0316  decode.d8.loss_mask: 0.1961  decode.d8.loss_dice: 0.2631
08/06 11:33:46 - mmengine - INFO - Iter(train) [ 67250/320000]  base_lr: 8.0870e-05 lr: 8.0870e-06  eta: 1 day, 10:38:19  time: 0.4969  data_time: 0.0114  memory: 5894  grad_norm: 85.1841  loss: 5.9651  decode.loss_cls: 0.1155  decode.loss_mask: 0.2202  decode.loss_dice: 0.2576  decode.d0.loss_cls: 0.7659  decode.d0.loss_mask: 0.2078  decode.d0.loss_dice: 0.2580  decode.d1.loss_cls: 0.0593  decode.d1.loss_mask: 0.2042  decode.d1.loss_dice: 0.2254  decode.d2.loss_cls: 0.0457  decode.d2.loss_mask: 0.2021  decode.d2.loss_dice: 0.2320  decode.d3.loss_cls: 0.0350  decode.d3.loss_mask: 0.2012  decode.d3.loss_dice: 0.2307  decode.d4.loss_cls: 0.0562  decode.d4.loss_mask: 0.2044  decode.d4.loss_dice: 0.2390  decode.d5.loss_cls: 0.0668  decode.d5.loss_mask: 0.2093  decode.d5.loss_dice: 0.2452  decode.d6.loss_cls: 0.0897  decode.d6.loss_mask: 0.2055  decode.d6.loss_dice: 0.2507  decode.d7.loss_cls: 0.0962  decode.d7.loss_mask: 0.2187  decode.d7.loss_dice: 0.2556  decode.d8.loss_cls: 0.0978  decode.d8.loss_mask: 0.2148  decode.d8.loss_dice: 0.2547
08/06 11:34:11 - mmengine - INFO - Iter(train) [ 67300/320000]  base_lr: 8.0856e-05 lr: 8.0856e-06  eta: 1 day, 10:37:55  time: 0.4970  data_time: 0.0116  memory: 5894  grad_norm: 143.7915  loss: 7.1932  decode.loss_cls: 0.1445  decode.loss_mask: 0.2316  decode.loss_dice: 0.2603  decode.d0.loss_cls: 1.0186  decode.d0.loss_mask: 0.2386  decode.d0.loss_dice: 0.2601  decode.d1.loss_cls: 0.1740  decode.d1.loss_mask: 0.2415  decode.d1.loss_dice: 0.2557  decode.d2.loss_cls: 0.1495  decode.d2.loss_mask: 0.2335  decode.d2.loss_dice: 0.2571  decode.d3.loss_cls: 0.1199  decode.d3.loss_mask: 0.2306  decode.d3.loss_dice: 0.2575  decode.d4.loss_cls: 0.1230  decode.d4.loss_mask: 0.2374  decode.d4.loss_dice: 0.2634  decode.d5.loss_cls: 0.1267  decode.d5.loss_mask: 0.2342  decode.d5.loss_dice: 0.2540  decode.d6.loss_cls: 0.1138  decode.d6.loss_mask: 0.2369  decode.d6.loss_dice: 0.2686  decode.d7.loss_cls: 0.1407  decode.d7.loss_mask: 0.2359  decode.d7.loss_dice: 0.2602  decode.d8.loss_cls: 0.1385  decode.d8.loss_mask: 0.2309  decode.d8.loss_dice: 0.2560
08/06 11:34:36 - mmengine - INFO - Iter(train) [ 67350/320000]  base_lr: 8.0841e-05 lr: 8.0841e-06  eta: 1 day, 10:37:31  time: 0.4962  data_time: 0.0119  memory: 5911  grad_norm: 355.7072  loss: 6.3381  decode.loss_cls: 0.0862  decode.loss_mask: 0.2349  decode.loss_dice: 0.2544  decode.d0.loss_cls: 0.9058  decode.d0.loss_mask: 0.2445  decode.d0.loss_dice: 0.2539  decode.d1.loss_cls: 0.0248  decode.d1.loss_mask: 0.2437  decode.d1.loss_dice: 0.2459  decode.d2.loss_cls: 0.0358  decode.d2.loss_mask: 0.2417  decode.d2.loss_dice: 0.2608  decode.d3.loss_cls: 0.0430  decode.d3.loss_mask: 0.2359  decode.d3.loss_dice: 0.2460  decode.d4.loss_cls: 0.0511  decode.d4.loss_mask: 0.2370  decode.d4.loss_dice: 0.2506  decode.d5.loss_cls: 0.0649  decode.d5.loss_mask: 0.2364  decode.d5.loss_dice: 0.2424  decode.d6.loss_cls: 0.0887  decode.d6.loss_mask: 0.2368  decode.d6.loss_dice: 0.2528  decode.d7.loss_cls: 0.0735  decode.d7.loss_mask: 0.2353  decode.d7.loss_dice: 0.2488  decode.d8.loss_cls: 0.0830  decode.d8.loss_mask: 0.2338  decode.d8.loss_dice: 0.2457
08/06 11:35:01 - mmengine - INFO - Iter(train) [ 67400/320000]  base_lr: 8.0827e-05 lr: 8.0827e-06  eta: 1 day, 10:37:07  time: 0.4956  data_time: 0.0112  memory: 5891  grad_norm: 837.5486  loss: 9.3678  decode.loss_cls: 0.1577  decode.loss_mask: 0.3389  decode.loss_dice: 0.3828  decode.d0.loss_cls: 0.8038  decode.d0.loss_mask: 0.3421  decode.d0.loss_dice: 0.3303  decode.d1.loss_cls: 0.2314  decode.d1.loss_mask: 0.3424  decode.d1.loss_dice: 0.3446  decode.d2.loss_cls: 0.1942  decode.d2.loss_mask: 0.3303  decode.d2.loss_dice: 0.3414  decode.d3.loss_cls: 0.1876  decode.d3.loss_mask: 0.3356  decode.d3.loss_dice: 0.3211  decode.d4.loss_cls: 0.1711  decode.d4.loss_mask: 0.3293  decode.d4.loss_dice: 0.3644  decode.d5.loss_cls: 0.2385  decode.d5.loss_mask: 0.3311  decode.d5.loss_dice: 0.3694  decode.d6.loss_cls: 0.1925  decode.d6.loss_mask: 0.3284  decode.d6.loss_dice: 0.3270  decode.d7.loss_cls: 0.1564  decode.d7.loss_mask: 0.3356  decode.d7.loss_dice: 0.3750  decode.d8.loss_cls: 0.1719  decode.d8.loss_mask: 0.3363  decode.d8.loss_dice: 0.3567
08/06 11:35:25 - mmengine - INFO - Iter(train) [ 67450/320000]  base_lr: 8.0813e-05 lr: 8.0813e-06  eta: 1 day, 10:36:43  time: 0.4970  data_time: 0.0115  memory: 5894  grad_norm: 261.2179  loss: 8.5493  decode.loss_cls: 0.2431  decode.loss_mask: 0.2267  decode.loss_dice: 0.2714  decode.d0.loss_cls: 1.1140  decode.d0.loss_mask: 0.2333  decode.d0.loss_dice: 0.2576  decode.d1.loss_cls: 0.2472  decode.d1.loss_mask: 0.2323  decode.d1.loss_dice: 0.2846  decode.d2.loss_cls: 0.2799  decode.d2.loss_mask: 0.2241  decode.d2.loss_dice: 0.2685  decode.d3.loss_cls: 0.2424  decode.d3.loss_mask: 0.2298  decode.d3.loss_dice: 0.2646  decode.d4.loss_cls: 0.2849  decode.d4.loss_mask: 0.2319  decode.d4.loss_dice: 0.2650  decode.d5.loss_cls: 0.3313  decode.d5.loss_mask: 0.2328  decode.d5.loss_dice: 0.2651  decode.d6.loss_cls: 0.2804  decode.d6.loss_mask: 0.2370  decode.d6.loss_dice: 0.2508  decode.d7.loss_cls: 0.2396  decode.d7.loss_mask: 0.2347  decode.d7.loss_dice: 0.2681  decode.d8.loss_cls: 0.3162  decode.d8.loss_mask: 0.2293  decode.d8.loss_dice: 0.2626
08/06 11:35:50 - mmengine - INFO - Iter(train) [ 67500/320000]  base_lr: 8.0798e-05 lr: 8.0798e-06  eta: 1 day, 10:36:19  time: 0.4969  data_time: 0.0112  memory: 5913  grad_norm: 165.9019  loss: 8.9828  decode.loss_cls: 0.1743  decode.loss_mask: 0.3222  decode.loss_dice: 0.3129  decode.d0.loss_cls: 0.9642  decode.d0.loss_mask: 0.3220  decode.d0.loss_dice: 0.3333  decode.d1.loss_cls: 0.1903  decode.d1.loss_mask: 0.3007  decode.d1.loss_dice: 0.3023  decode.d2.loss_cls: 0.1660  decode.d2.loss_mask: 0.3341  decode.d2.loss_dice: 0.3094  decode.d3.loss_cls: 0.1547  decode.d3.loss_mask: 0.3324  decode.d3.loss_dice: 0.3178  decode.d4.loss_cls: 0.1348  decode.d4.loss_mask: 0.3298  decode.d4.loss_dice: 0.3100  decode.d5.loss_cls: 0.1562  decode.d5.loss_mask: 0.3287  decode.d5.loss_dice: 0.3179  decode.d6.loss_cls: 0.2015  decode.d6.loss_mask: 0.3458  decode.d6.loss_dice: 0.3285  decode.d7.loss_cls: 0.1896  decode.d7.loss_mask: 0.3314  decode.d7.loss_dice: 0.3480  decode.d8.loss_cls: 0.1843  decode.d8.loss_mask: 0.3250  decode.d8.loss_dice: 0.3151
08/06 11:36:15 - mmengine - INFO - Iter(train) [ 67550/320000]  base_lr: 8.0784e-05 lr: 8.0784e-06  eta: 1 day, 10:35:55  time: 0.4963  data_time: 0.0113  memory: 5909  grad_norm: 101.8547  loss: 7.1189  decode.loss_cls: 0.2166  decode.loss_mask: 0.2372  decode.loss_dice: 0.2469  decode.d0.loss_cls: 0.8711  decode.d0.loss_mask: 0.2344  decode.d0.loss_dice: 0.2383  decode.d1.loss_cls: 0.0528  decode.d1.loss_mask: 0.2704  decode.d1.loss_dice: 0.2428  decode.d2.loss_cls: 0.0845  decode.d2.loss_mask: 0.2628  decode.d2.loss_dice: 0.2471  decode.d3.loss_cls: 0.1470  decode.d3.loss_mask: 0.2319  decode.d3.loss_dice: 0.2374  decode.d4.loss_cls: 0.1586  decode.d4.loss_mask: 0.2332  decode.d4.loss_dice: 0.2317  decode.d5.loss_cls: 0.1818  decode.d5.loss_mask: 0.2344  decode.d5.loss_dice: 0.2322  decode.d6.loss_cls: 0.2165  decode.d6.loss_mask: 0.2380  decode.d6.loss_dice: 0.2390  decode.d7.loss_cls: 0.1881  decode.d7.loss_mask: 0.2328  decode.d7.loss_dice: 0.2326  decode.d8.loss_cls: 0.2075  decode.d8.loss_mask: 0.2374  decode.d8.loss_dice: 0.2339
08/06 11:36:40 - mmengine - INFO - Iter(train) [ 67600/320000]  base_lr: 8.0769e-05 lr: 8.0769e-06  eta: 1 day, 10:35:31  time: 0.4966  data_time: 0.0114  memory: 5894  grad_norm: 94.1850  loss: 7.8383  decode.loss_cls: 0.1785  decode.loss_mask: 0.2684  decode.loss_dice: 0.2667  decode.d0.loss_cls: 0.8229  decode.d0.loss_mask: 0.2639  decode.d0.loss_dice: 0.2724  decode.d1.loss_cls: 0.2023  decode.d1.loss_mask: 0.2657  decode.d1.loss_dice: 0.2765  decode.d2.loss_cls: 0.2070  decode.d2.loss_mask: 0.2608  decode.d2.loss_dice: 0.2677  decode.d3.loss_cls: 0.1618  decode.d3.loss_mask: 0.2573  decode.d3.loss_dice: 0.2629  decode.d4.loss_cls: 0.1729  decode.d4.loss_mask: 0.2547  decode.d4.loss_dice: 0.2747  decode.d5.loss_cls: 0.1824  decode.d5.loss_mask: 0.2612  decode.d5.loss_dice: 0.2674  decode.d6.loss_cls: 0.2256  decode.d6.loss_mask: 0.2681  decode.d6.loss_dice: 0.2792  decode.d7.loss_cls: 0.1912  decode.d7.loss_mask: 0.2589  decode.d7.loss_dice: 0.2660  decode.d8.loss_cls: 0.1806  decode.d8.loss_mask: 0.2632  decode.d8.loss_dice: 0.2575
08/06 11:37:05 - mmengine - INFO - Iter(train) [ 67650/320000]  base_lr: 8.0755e-05 lr: 8.0755e-06  eta: 1 day, 10:35:07  time: 0.4973  data_time: 0.0114  memory: 5894  grad_norm: 129.5999  loss: 9.7952  decode.loss_cls: 0.2741  decode.loss_mask: 0.3335  decode.loss_dice: 0.2967  decode.d0.loss_cls: 1.0299  decode.d0.loss_mask: 0.2978  decode.d0.loss_dice: 0.3046  decode.d1.loss_cls: 0.2953  decode.d1.loss_mask: 0.3208  decode.d1.loss_dice: 0.3017  decode.d2.loss_cls: 0.3086  decode.d2.loss_mask: 0.3031  decode.d2.loss_dice: 0.2963  decode.d3.loss_cls: 0.3190  decode.d3.loss_mask: 0.3190  decode.d3.loss_dice: 0.3032  decode.d4.loss_cls: 0.3372  decode.d4.loss_mask: 0.3254  decode.d4.loss_dice: 0.3239  decode.d5.loss_cls: 0.2581  decode.d5.loss_mask: 0.3585  decode.d5.loss_dice: 0.2972  decode.d6.loss_cls: 0.2533  decode.d6.loss_mask: 0.3900  decode.d6.loss_dice: 0.2830  decode.d7.loss_cls: 0.2772  decode.d7.loss_mask: 0.3291  decode.d7.loss_dice: 0.3184  decode.d8.loss_cls: 0.1663  decode.d8.loss_mask: 0.3181  decode.d8.loss_dice: 0.2560
08/06 11:37:30 - mmengine - INFO - Iter(train) [ 67700/320000]  base_lr: 8.0741e-05 lr: 8.0741e-06  eta: 1 day, 10:34:43  time: 0.4971  data_time: 0.0111  memory: 5895  grad_norm: 85.8336  loss: 6.6364  decode.loss_cls: 0.1222  decode.loss_mask: 0.1929  decode.loss_dice: 0.2687  decode.d0.loss_cls: 0.8486  decode.d0.loss_mask: 0.1883  decode.d0.loss_dice: 0.2426  decode.d1.loss_cls: 0.1730  decode.d1.loss_mask: 0.1877  decode.d1.loss_dice: 0.2476  decode.d2.loss_cls: 0.1478  decode.d2.loss_mask: 0.1870  decode.d2.loss_dice: 0.2323  decode.d3.loss_cls: 0.1565  decode.d3.loss_mask: 0.1928  decode.d3.loss_dice: 0.2509  decode.d4.loss_cls: 0.1702  decode.d4.loss_mask: 0.1945  decode.d4.loss_dice: 0.2568  decode.d5.loss_cls: 0.1343  decode.d5.loss_mask: 0.1916  decode.d5.loss_dice: 0.2475  decode.d6.loss_cls: 0.1398  decode.d6.loss_mask: 0.1873  decode.d6.loss_dice: 0.2429  decode.d7.loss_cls: 0.1689  decode.d7.loss_mask: 0.1884  decode.d7.loss_dice: 0.2816  decode.d8.loss_cls: 0.1233  decode.d8.loss_mask: 0.1933  decode.d8.loss_dice: 0.2770
08/06 11:37:55 - mmengine - INFO - Iter(train) [ 67750/320000]  base_lr: 8.0726e-05 lr: 8.0726e-06  eta: 1 day, 10:34:19  time: 0.4962  data_time: 0.0115  memory: 5894  grad_norm: 76.9585  loss: 8.9201  decode.loss_cls: 0.1479  decode.loss_mask: 0.3354  decode.loss_dice: 0.3857  decode.d0.loss_cls: 0.7979  decode.d0.loss_mask: 0.3191  decode.d0.loss_dice: 0.3441  decode.d1.loss_cls: 0.1648  decode.d1.loss_mask: 0.3112  decode.d1.loss_dice: 0.3376  decode.d2.loss_cls: 0.1111  decode.d2.loss_mask: 0.3097  decode.d2.loss_dice: 0.3449  decode.d3.loss_cls: 0.1715  decode.d3.loss_mask: 0.3151  decode.d3.loss_dice: 0.3488  decode.d4.loss_cls: 0.1646  decode.d4.loss_mask: 0.3341  decode.d4.loss_dice: 0.3686  decode.d5.loss_cls: 0.1397  decode.d5.loss_mask: 0.3381  decode.d5.loss_dice: 0.3492  decode.d6.loss_cls: 0.1438  decode.d6.loss_mask: 0.3317  decode.d6.loss_dice: 0.3500  decode.d7.loss_cls: 0.1279  decode.d7.loss_mask: 0.3361  decode.d7.loss_dice: 0.3427  decode.d8.loss_cls: 0.1555  decode.d8.loss_mask: 0.3388  decode.d8.loss_dice: 0.3546
08/06 11:38:19 - mmengine - INFO - Iter(train) [ 67800/320000]  base_lr: 8.0712e-05 lr: 8.0712e-06  eta: 1 day, 10:33:55  time: 0.4985  data_time: 0.0116  memory: 5911  grad_norm: 90.2460  loss: 5.1138  decode.loss_cls: 0.0094  decode.loss_mask: 0.1894  decode.loss_dice: 0.2307  decode.d0.loss_cls: 0.8614  decode.d0.loss_mask: 0.1803  decode.d0.loss_dice: 0.2271  decode.d1.loss_cls: 0.0153  decode.d1.loss_mask: 0.1847  decode.d1.loss_dice: 0.2307  decode.d2.loss_cls: 0.0136  decode.d2.loss_mask: 0.1838  decode.d2.loss_dice: 0.2347  decode.d3.loss_cls: 0.0114  decode.d3.loss_mask: 0.1821  decode.d3.loss_dice: 0.2284  decode.d4.loss_cls: 0.0074  decode.d4.loss_mask: 0.1821  decode.d4.loss_dice: 0.2321  decode.d5.loss_cls: 0.0071  decode.d5.loss_mask: 0.1843  decode.d5.loss_dice: 0.2187  decode.d6.loss_cls: 0.0086  decode.d6.loss_mask: 0.1838  decode.d6.loss_dice: 0.2260  decode.d7.loss_cls: 0.0566  decode.d7.loss_mask: 0.1807  decode.d7.loss_dice: 0.2291  decode.d8.loss_cls: 0.0092  decode.d8.loss_mask: 0.1834  decode.d8.loss_dice: 0.2217
08/06 11:38:44 - mmengine - INFO - Iter(train) [ 67850/320000]  base_lr: 8.0697e-05 lr: 8.0697e-06  eta: 1 day, 10:33:31  time: 0.4971  data_time: 0.0115  memory: 5913  grad_norm: 118.1606  loss: 7.2718  decode.loss_cls: 0.0798  decode.loss_mask: 0.2291  decode.loss_dice: 0.2604  decode.d0.loss_cls: 0.9862  decode.d0.loss_mask: 0.2320  decode.d0.loss_dice: 0.2803  decode.d1.loss_cls: 0.1956  decode.d1.loss_mask: 0.2299  decode.d1.loss_dice: 0.2665  decode.d2.loss_cls: 0.2370  decode.d2.loss_mask: 0.2279  decode.d2.loss_dice: 0.2785  decode.d3.loss_cls: 0.1344  decode.d3.loss_mask: 0.2307  decode.d3.loss_dice: 0.2819  decode.d4.loss_cls: 0.2037  decode.d4.loss_mask: 0.2255  decode.d4.loss_dice: 0.2651  decode.d5.loss_cls: 0.1507  decode.d5.loss_mask: 0.2276  decode.d5.loss_dice: 0.2594  decode.d6.loss_cls: 0.1286  decode.d6.loss_mask: 0.2285  decode.d6.loss_dice: 0.2539  decode.d7.loss_cls: 0.1011  decode.d7.loss_mask: 0.2300  decode.d7.loss_dice: 0.2643  decode.d8.loss_cls: 0.0885  decode.d8.loss_mask: 0.2295  decode.d8.loss_dice: 0.2654
08/06 11:39:09 - mmengine - INFO - Iter(train) [ 67900/320000]  base_lr: 8.0683e-05 lr: 8.0683e-06  eta: 1 day, 10:33:07  time: 0.4963  data_time: 0.0115  memory: 5894  grad_norm: 73.7639  loss: 7.5837  decode.loss_cls: 0.0983  decode.loss_mask: 0.2905  decode.loss_dice: 0.2728  decode.d0.loss_cls: 0.9155  decode.d0.loss_mask: 0.2346  decode.d0.loss_dice: 0.2708  decode.d1.loss_cls: 0.2002  decode.d1.loss_mask: 0.2412  decode.d1.loss_dice: 0.2700  decode.d2.loss_cls: 0.1915  decode.d2.loss_mask: 0.2406  decode.d2.loss_dice: 0.2836  decode.d3.loss_cls: 0.1186  decode.d3.loss_mask: 0.2981  decode.d3.loss_dice: 0.2740  decode.d4.loss_cls: 0.1204  decode.d4.loss_mask: 0.2321  decode.d4.loss_dice: 0.2538  decode.d5.loss_cls: 0.1257  decode.d5.loss_mask: 0.2404  decode.d5.loss_dice: 0.2826  decode.d6.loss_cls: 0.1721  decode.d6.loss_mask: 0.2731  decode.d6.loss_dice: 0.2928  decode.d7.loss_cls: 0.1510  decode.d7.loss_mask: 0.2614  decode.d7.loss_dice: 0.2897  decode.d8.loss_cls: 0.1720  decode.d8.loss_mask: 0.2390  decode.d8.loss_dice: 0.2774
08/06 11:39:34 - mmengine - INFO - Iter(train) [ 67950/320000]  base_lr: 8.0669e-05 lr: 8.0669e-06  eta: 1 day, 10:32:43  time: 0.4970  data_time: 0.0114  memory: 5878  grad_norm: 49.8623  loss: 7.1909  decode.loss_cls: 0.1621  decode.loss_mask: 0.2194  decode.loss_dice: 0.2579  decode.d0.loss_cls: 0.9285  decode.d0.loss_mask: 0.2285  decode.d0.loss_dice: 0.2448  decode.d1.loss_cls: 0.1597  decode.d1.loss_mask: 0.2173  decode.d1.loss_dice: 0.2501  decode.d2.loss_cls: 0.1516  decode.d2.loss_mask: 0.2181  decode.d2.loss_dice: 0.2703  decode.d3.loss_cls: 0.1869  decode.d3.loss_mask: 0.2175  decode.d3.loss_dice: 0.2324  decode.d4.loss_cls: 0.1900  decode.d4.loss_mask: 0.2182  decode.d4.loss_dice: 0.2355  decode.d5.loss_cls: 0.1593  decode.d5.loss_mask: 0.2197  decode.d5.loss_dice: 0.2411  decode.d6.loss_cls: 0.1559  decode.d6.loss_mask: 0.2198  decode.d6.loss_dice: 0.2440  decode.d7.loss_cls: 0.1996  decode.d7.loss_mask: 0.2240  decode.d7.loss_dice: 0.2577  decode.d8.loss_cls: 0.1840  decode.d8.loss_mask: 0.2214  decode.d8.loss_dice: 0.2755
08/06 11:39:59 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 11:39:59 - mmengine - INFO - Iter(train) [ 68000/320000]  base_lr: 8.0654e-05 lr: 8.0654e-06  eta: 1 day, 10:32:19  time: 0.4959  data_time: 0.0111  memory: 5911  grad_norm: 93.5472  loss: 7.6085  decode.loss_cls: 0.1172  decode.loss_mask: 0.2256  decode.loss_dice: 0.3136  decode.d0.loss_cls: 1.0285  decode.d0.loss_mask: 0.2253  decode.d0.loss_dice: 0.3044  decode.d1.loss_cls: 0.1653  decode.d1.loss_mask: 0.2184  decode.d1.loss_dice: 0.2861  decode.d2.loss_cls: 0.1556  decode.d2.loss_mask: 0.2156  decode.d2.loss_dice: 0.2872  decode.d3.loss_cls: 0.1877  decode.d3.loss_mask: 0.2227  decode.d3.loss_dice: 0.3004  decode.d4.loss_cls: 0.1596  decode.d4.loss_mask: 0.2194  decode.d4.loss_dice: 0.2988  decode.d5.loss_cls: 0.1412  decode.d5.loss_mask: 0.2189  decode.d5.loss_dice: 0.3180  decode.d6.loss_cls: 0.1156  decode.d6.loss_mask: 0.2202  decode.d6.loss_dice: 0.3003  decode.d7.loss_cls: 0.1386  decode.d7.loss_mask: 0.2179  decode.d7.loss_dice: 0.3063  decode.d8.loss_cls: 0.1612  decode.d8.loss_mask: 0.2204  decode.d8.loss_dice: 0.3186
08/06 11:40:24 - mmengine - INFO - Iter(train) [ 68050/320000]  base_lr: 8.0640e-05 lr: 8.0640e-06  eta: 1 day, 10:31:55  time: 0.4972  data_time: 0.0115  memory: 5878  grad_norm: 98.3824  loss: 6.8889  decode.loss_cls: 0.0711  decode.loss_mask: 0.2239  decode.loss_dice: 0.2779  decode.d0.loss_cls: 0.9058  decode.d0.loss_mask: 0.2267  decode.d0.loss_dice: 0.2606  decode.d1.loss_cls: 0.1965  decode.d1.loss_mask: 0.2226  decode.d1.loss_dice: 0.2644  decode.d2.loss_cls: 0.1308  decode.d2.loss_mask: 0.2219  decode.d2.loss_dice: 0.2662  decode.d3.loss_cls: 0.1317  decode.d3.loss_mask: 0.2201  decode.d3.loss_dice: 0.2695  decode.d4.loss_cls: 0.0965  decode.d4.loss_mask: 0.2225  decode.d4.loss_dice: 0.2690  decode.d5.loss_cls: 0.0986  decode.d5.loss_mask: 0.2240  decode.d5.loss_dice: 0.2653  decode.d6.loss_cls: 0.1099  decode.d6.loss_mask: 0.2245  decode.d6.loss_dice: 0.2863  decode.d7.loss_cls: 0.1142  decode.d7.loss_mask: 0.2238  decode.d7.loss_dice: 0.2757  decode.d8.loss_cls: 0.0907  decode.d8.loss_mask: 0.2218  decode.d8.loss_dice: 0.2767
08/06 11:40:49 - mmengine - INFO - Iter(train) [ 68100/320000]  base_lr: 8.0625e-05 lr: 8.0625e-06  eta: 1 day, 10:31:31  time: 0.4970  data_time: 0.0114  memory: 5874  grad_norm: 81.2011  loss: 6.1912  decode.loss_cls: 0.0657  decode.loss_mask: 0.2373  decode.loss_dice: 0.2095  decode.d0.loss_cls: 0.7798  decode.d0.loss_mask: 0.2408  decode.d0.loss_dice: 0.2043  decode.d1.loss_cls: 0.1650  decode.d1.loss_mask: 0.2391  decode.d1.loss_dice: 0.2131  decode.d2.loss_cls: 0.1295  decode.d2.loss_mask: 0.2373  decode.d2.loss_dice: 0.2141  decode.d3.loss_cls: 0.1221  decode.d3.loss_mask: 0.2432  decode.d3.loss_dice: 0.2137  decode.d4.loss_cls: 0.0702  decode.d4.loss_mask: 0.2376  decode.d4.loss_dice: 0.2133  decode.d5.loss_cls: 0.0984  decode.d5.loss_mask: 0.2391  decode.d5.loss_dice: 0.2118  decode.d6.loss_cls: 0.1100  decode.d6.loss_mask: 0.2368  decode.d6.loss_dice: 0.2123  decode.d7.loss_cls: 0.0897  decode.d7.loss_mask: 0.2359  decode.d7.loss_dice: 0.2115  decode.d8.loss_cls: 0.0635  decode.d8.loss_mask: 0.2374  decode.d8.loss_dice: 0.2093
08/06 11:41:13 - mmengine - INFO - Iter(train) [ 68150/320000]  base_lr: 8.0611e-05 lr: 8.0611e-06  eta: 1 day, 10:31:07  time: 0.4957  data_time: 0.0110  memory: 5911  grad_norm: 90.4539  loss: 7.3997  decode.loss_cls: 0.1367  decode.loss_mask: 0.2229  decode.loss_dice: 0.2921  decode.d0.loss_cls: 0.7368  decode.d0.loss_mask: 0.2174  decode.d0.loss_dice: 0.2926  decode.d1.loss_cls: 0.1656  decode.d1.loss_mask: 0.2157  decode.d1.loss_dice: 0.2571  decode.d2.loss_cls: 0.1233  decode.d2.loss_mask: 0.2158  decode.d2.loss_dice: 0.2532  decode.d3.loss_cls: 0.1400  decode.d3.loss_mask: 0.2423  decode.d3.loss_dice: 0.2948  decode.d4.loss_cls: 0.2343  decode.d4.loss_mask: 0.2194  decode.d4.loss_dice: 0.2627  decode.d5.loss_cls: 0.2285  decode.d5.loss_mask: 0.2322  decode.d5.loss_dice: 0.2868  decode.d6.loss_cls: 0.2171  decode.d6.loss_mask: 0.2651  decode.d6.loss_dice: 0.2926  decode.d7.loss_cls: 0.2009  decode.d7.loss_mask: 0.2215  decode.d7.loss_dice: 0.2667  decode.d8.loss_cls: 0.1421  decode.d8.loss_mask: 0.2201  decode.d8.loss_dice: 0.3036
08/06 11:41:38 - mmengine - INFO - Iter(train) [ 68200/320000]  base_lr: 8.0597e-05 lr: 8.0597e-06  eta: 1 day, 10:30:43  time: 0.4971  data_time: 0.0113  memory: 5895  grad_norm: 52.5130  loss: 5.7894  decode.loss_cls: 0.0570  decode.loss_mask: 0.1844  decode.loss_dice: 0.2425  decode.d0.loss_cls: 0.8152  decode.d0.loss_mask: 0.1826  decode.d0.loss_dice: 0.2605  decode.d1.loss_cls: 0.1110  decode.d1.loss_mask: 0.1844  decode.d1.loss_dice: 0.2573  decode.d2.loss_cls: 0.0648  decode.d2.loss_mask: 0.1834  decode.d2.loss_dice: 0.2573  decode.d3.loss_cls: 0.0685  decode.d3.loss_mask: 0.1822  decode.d3.loss_dice: 0.2489  decode.d4.loss_cls: 0.0615  decode.d4.loss_mask: 0.1823  decode.d4.loss_dice: 0.2622  decode.d5.loss_cls: 0.0548  decode.d5.loss_mask: 0.1808  decode.d5.loss_dice: 0.2462  decode.d6.loss_cls: 0.0420  decode.d6.loss_mask: 0.1835  decode.d6.loss_dice: 0.2655  decode.d7.loss_cls: 0.0681  decode.d7.loss_mask: 0.1808  decode.d7.loss_dice: 0.2540  decode.d8.loss_cls: 0.0866  decode.d8.loss_mask: 0.1814  decode.d8.loss_dice: 0.2397
08/06 11:42:03 - mmengine - INFO - Iter(train) [ 68250/320000]  base_lr: 8.0582e-05 lr: 8.0582e-06  eta: 1 day, 10:30:19  time: 0.4959  data_time: 0.0113  memory: 5911  grad_norm: 97.4718  loss: 5.6104  decode.loss_cls: 0.0917  decode.loss_mask: 0.2001  decode.loss_dice: 0.2039  decode.d0.loss_cls: 0.7642  decode.d0.loss_mask: 0.2013  decode.d0.loss_dice: 0.2030  decode.d1.loss_cls: 0.0791  decode.d1.loss_mask: 0.2000  decode.d1.loss_dice: 0.2093  decode.d2.loss_cls: 0.0673  decode.d2.loss_mask: 0.2005  decode.d2.loss_dice: 0.2139  decode.d3.loss_cls: 0.0788  decode.d3.loss_mask: 0.2037  decode.d3.loss_dice: 0.2097  decode.d4.loss_cls: 0.0846  decode.d4.loss_mask: 0.2034  decode.d4.loss_dice: 0.2102  decode.d5.loss_cls: 0.0752  decode.d5.loss_mask: 0.2017  decode.d5.loss_dice: 0.2071  decode.d6.loss_cls: 0.0733  decode.d6.loss_mask: 0.2015  decode.d6.loss_dice: 0.2033  decode.d7.loss_cls: 0.0955  decode.d7.loss_mask: 0.2018  decode.d7.loss_dice: 0.2060  decode.d8.loss_cls: 0.1061  decode.d8.loss_mask: 0.2024  decode.d8.loss_dice: 0.2117
08/06 11:42:28 - mmengine - INFO - Iter(train) [ 68300/320000]  base_lr: 8.0568e-05 lr: 8.0568e-06  eta: 1 day, 10:29:55  time: 0.4970  data_time: 0.0114  memory: 5911  grad_norm: 93.8661  loss: 6.5090  decode.loss_cls: 0.0614  decode.loss_mask: 0.2655  decode.loss_dice: 0.2631  decode.d0.loss_cls: 0.8895  decode.d0.loss_mask: 0.2476  decode.d0.loss_dice: 0.2509  decode.d1.loss_cls: 0.0981  decode.d1.loss_mask: 0.2365  decode.d1.loss_dice: 0.2356  decode.d2.loss_cls: 0.0245  decode.d2.loss_mask: 0.2902  decode.d2.loss_dice: 0.2683  decode.d3.loss_cls: 0.0259  decode.d3.loss_mask: 0.2706  decode.d3.loss_dice: 0.2697  decode.d4.loss_cls: 0.0285  decode.d4.loss_mask: 0.2646  decode.d4.loss_dice: 0.2744  decode.d5.loss_cls: 0.0218  decode.d5.loss_mask: 0.2829  decode.d5.loss_dice: 0.2700  decode.d6.loss_cls: 0.0284  decode.d6.loss_mask: 0.2821  decode.d6.loss_dice: 0.2678  decode.d7.loss_cls: 0.0210  decode.d7.loss_mask: 0.2568  decode.d7.loss_dice: 0.2640  decode.d8.loss_cls: 0.0251  decode.d8.loss_mask: 0.2625  decode.d8.loss_dice: 0.2614
08/06 11:42:53 - mmengine - INFO - Iter(train) [ 68350/320000]  base_lr: 8.0553e-05 lr: 8.0553e-06  eta: 1 day, 10:29:31  time: 0.4970  data_time: 0.0115  memory: 5911  grad_norm: 75.5239  loss: 6.8769  decode.loss_cls: 0.0591  decode.loss_mask: 0.2718  decode.loss_dice: 0.2730  decode.d0.loss_cls: 0.7830  decode.d0.loss_mask: 0.2741  decode.d0.loss_dice: 0.2682  decode.d1.loss_cls: 0.0694  decode.d1.loss_mask: 0.2743  decode.d1.loss_dice: 0.2870  decode.d2.loss_cls: 0.0663  decode.d2.loss_mask: 0.2702  decode.d2.loss_dice: 0.2883  decode.d3.loss_cls: 0.0792  decode.d3.loss_mask: 0.2739  decode.d3.loss_dice: 0.2742  decode.d4.loss_cls: 0.0715  decode.d4.loss_mask: 0.2688  decode.d4.loss_dice: 0.2775  decode.d5.loss_cls: 0.0625  decode.d5.loss_mask: 0.2727  decode.d5.loss_dice: 0.2744  decode.d6.loss_cls: 0.0702  decode.d6.loss_mask: 0.2729  decode.d6.loss_dice: 0.2821  decode.d7.loss_cls: 0.0549  decode.d7.loss_mask: 0.2719  decode.d7.loss_dice: 0.2846  decode.d8.loss_cls: 0.0537  decode.d8.loss_mask: 0.2752  decode.d8.loss_dice: 0.2722
08/06 11:43:18 - mmengine - INFO - Iter(train) [ 68400/320000]  base_lr: 8.0539e-05 lr: 8.0539e-06  eta: 1 day, 10:29:07  time: 0.4964  data_time: 0.0114  memory: 5911  grad_norm: 58.8370  loss: 7.2191  decode.loss_cls: 0.0858  decode.loss_mask: 0.2402  decode.loss_dice: 0.3620  decode.d0.loss_cls: 0.8844  decode.d0.loss_mask: 0.2410  decode.d0.loss_dice: 0.3206  decode.d1.loss_cls: 0.0223  decode.d1.loss_mask: 0.2439  decode.d1.loss_dice: 0.3523  decode.d2.loss_cls: 0.0599  decode.d2.loss_mask: 0.2439  decode.d2.loss_dice: 0.3471  decode.d3.loss_cls: 0.0371  decode.d3.loss_mask: 0.2463  decode.d3.loss_dice: 0.3626  decode.d4.loss_cls: 0.0321  decode.d4.loss_mask: 0.2424  decode.d4.loss_dice: 0.3601  decode.d5.loss_cls: 0.0629  decode.d5.loss_mask: 0.2412  decode.d5.loss_dice: 0.3375  decode.d6.loss_cls: 0.0675  decode.d6.loss_mask: 0.2431  decode.d6.loss_dice: 0.3572  decode.d7.loss_cls: 0.0205  decode.d7.loss_mask: 0.2416  decode.d7.loss_dice: 0.3407  decode.d8.loss_cls: 0.0254  decode.d8.loss_mask: 0.2442  decode.d8.loss_dice: 0.3534
08/06 11:43:43 - mmengine - INFO - Iter(train) [ 68450/320000]  base_lr: 8.0525e-05 lr: 8.0525e-06  eta: 1 day, 10:28:43  time: 0.4978  data_time: 0.0114  memory: 5891  grad_norm: 110.4612  loss: 5.5073  decode.loss_cls: 0.0372  decode.loss_mask: 0.2059  decode.loss_dice: 0.2328  decode.d0.loss_cls: 0.7257  decode.d0.loss_mask: 0.2087  decode.d0.loss_dice: 0.2284  decode.d1.loss_cls: 0.1176  decode.d1.loss_mask: 0.2121  decode.d1.loss_dice: 0.2313  decode.d2.loss_cls: 0.0333  decode.d2.loss_mask: 0.2089  decode.d2.loss_dice: 0.2331  decode.d3.loss_cls: 0.0219  decode.d3.loss_mask: 0.2048  decode.d3.loss_dice: 0.2278  decode.d4.loss_cls: 0.0106  decode.d4.loss_mask: 0.2081  decode.d4.loss_dice: 0.2302  decode.d5.loss_cls: 0.0272  decode.d5.loss_mask: 0.2044  decode.d5.loss_dice: 0.2329  decode.d6.loss_cls: 0.0568  decode.d6.loss_mask: 0.2034  decode.d6.loss_dice: 0.2274  decode.d7.loss_cls: 0.0289  decode.d7.loss_mask: 0.2060  decode.d7.loss_dice: 0.2425  decode.d8.loss_cls: 0.0620  decode.d8.loss_mask: 0.2039  decode.d8.loss_dice: 0.2334
08/06 11:44:07 - mmengine - INFO - Iter(train) [ 68500/320000]  base_lr: 8.0510e-05 lr: 8.0510e-06  eta: 1 day, 10:28:19  time: 0.4956  data_time: 0.0111  memory: 5911  grad_norm: 181.5182  loss: 7.8939  decode.loss_cls: 0.2417  decode.loss_mask: 0.2096  decode.loss_dice: 0.2846  decode.d0.loss_cls: 0.9327  decode.d0.loss_mask: 0.2132  decode.d0.loss_dice: 0.2880  decode.d1.loss_cls: 0.2110  decode.d1.loss_mask: 0.2132  decode.d1.loss_dice: 0.2920  decode.d2.loss_cls: 0.2432  decode.d2.loss_mask: 0.2090  decode.d2.loss_dice: 0.2752  decode.d3.loss_cls: 0.1798  decode.d3.loss_mask: 0.2099  decode.d3.loss_dice: 0.2939  decode.d4.loss_cls: 0.2050  decode.d4.loss_mask: 0.2135  decode.d4.loss_dice: 0.2922  decode.d5.loss_cls: 0.1887  decode.d5.loss_mask: 0.2123  decode.d5.loss_dice: 0.2986  decode.d6.loss_cls: 0.1925  decode.d6.loss_mask: 0.2104  decode.d6.loss_dice: 0.2824  decode.d7.loss_cls: 0.2506  decode.d7.loss_mask: 0.2112  decode.d7.loss_dice: 0.3115  decode.d8.loss_cls: 0.2257  decode.d8.loss_mask: 0.2119  decode.d8.loss_dice: 0.2904
08/06 11:44:32 - mmengine - INFO - Iter(train) [ 68550/320000]  base_lr: 8.0496e-05 lr: 8.0496e-06  eta: 1 day, 10:27:55  time: 0.4972  data_time: 0.0114  memory: 5928  grad_norm: 51.6992  loss: 6.8648  decode.loss_cls: 0.0601  decode.loss_mask: 0.2489  decode.loss_dice: 0.2614  decode.d0.loss_cls: 0.9326  decode.d0.loss_mask: 0.2491  decode.d0.loss_dice: 0.2693  decode.d1.loss_cls: 0.1337  decode.d1.loss_mask: 0.2457  decode.d1.loss_dice: 0.2502  decode.d2.loss_cls: 0.0935  decode.d2.loss_mask: 0.2465  decode.d2.loss_dice: 0.2545  decode.d3.loss_cls: 0.0928  decode.d3.loss_mask: 0.2490  decode.d3.loss_dice: 0.2603  decode.d4.loss_cls: 0.1312  decode.d4.loss_mask: 0.2495  decode.d4.loss_dice: 0.2519  decode.d5.loss_cls: 0.0751  decode.d5.loss_mask: 0.2468  decode.d5.loss_dice: 0.2555  decode.d6.loss_cls: 0.0762  decode.d6.loss_mask: 0.2472  decode.d6.loss_dice: 0.2551  decode.d7.loss_cls: 0.1201  decode.d7.loss_mask: 0.2479  decode.d7.loss_dice: 0.2539  decode.d8.loss_cls: 0.1035  decode.d8.loss_mask: 0.2486  decode.d8.loss_dice: 0.2547
08/06 11:44:57 - mmengine - INFO - Iter(train) [ 68600/320000]  base_lr: 8.0481e-05 lr: 8.0481e-06  eta: 1 day, 10:27:31  time: 0.4978  data_time: 0.0116  memory: 5911  grad_norm: 49.4457  loss: 7.5089  decode.loss_cls: 0.0478  decode.loss_mask: 0.3440  decode.loss_dice: 0.2805  decode.d0.loss_cls: 0.8337  decode.d0.loss_mask: 0.3687  decode.d0.loss_dice: 0.2885  decode.d1.loss_cls: 0.0561  decode.d1.loss_mask: 0.3561  decode.d1.loss_dice: 0.2754  decode.d2.loss_cls: 0.0814  decode.d2.loss_mask: 0.3500  decode.d2.loss_dice: 0.2694  decode.d3.loss_cls: 0.0265  decode.d3.loss_mask: 0.3479  decode.d3.loss_dice: 0.2815  decode.d4.loss_cls: 0.0267  decode.d4.loss_mask: 0.3471  decode.d4.loss_dice: 0.2852  decode.d5.loss_cls: 0.0222  decode.d5.loss_mask: 0.3442  decode.d5.loss_dice: 0.2765  decode.d6.loss_cls: 0.0643  decode.d6.loss_mask: 0.3447  decode.d6.loss_dice: 0.2921  decode.d7.loss_cls: 0.0183  decode.d7.loss_mask: 0.3428  decode.d7.loss_dice: 0.2814  decode.d8.loss_cls: 0.0222  decode.d8.loss_mask: 0.3455  decode.d8.loss_dice: 0.2883
08/06 11:45:22 - mmengine - INFO - Iter(train) [ 68650/320000]  base_lr: 8.0467e-05 lr: 8.0467e-06  eta: 1 day, 10:27:07  time: 0.4973  data_time: 0.0116  memory: 5891  grad_norm: 206.2670  loss: 7.8428  decode.loss_cls: 0.1442  decode.loss_mask: 0.2718  decode.loss_dice: 0.2629  decode.d0.loss_cls: 0.9590  decode.d0.loss_mask: 0.2837  decode.d0.loss_dice: 0.3094  decode.d1.loss_cls: 0.1389  decode.d1.loss_mask: 0.2719  decode.d1.loss_dice: 0.2831  decode.d2.loss_cls: 0.1716  decode.d2.loss_mask: 0.2728  decode.d2.loss_dice: 0.2867  decode.d3.loss_cls: 0.1003  decode.d3.loss_mask: 0.2879  decode.d3.loss_dice: 0.3199  decode.d4.loss_cls: 0.0931  decode.d4.loss_mask: 0.2845  decode.d4.loss_dice: 0.2995  decode.d5.loss_cls: 0.1473  decode.d5.loss_mask: 0.2713  decode.d5.loss_dice: 0.2844  decode.d6.loss_cls: 0.1496  decode.d6.loss_mask: 0.2707  decode.d6.loss_dice: 0.2736  decode.d7.loss_cls: 0.1537  decode.d7.loss_mask: 0.2692  decode.d7.loss_dice: 0.2874  decode.d8.loss_cls: 0.1354  decode.d8.loss_mask: 0.2715  decode.d8.loss_dice: 0.2875
08/06 11:45:47 - mmengine - INFO - Iter(train) [ 68700/320000]  base_lr: 8.0452e-05 lr: 8.0452e-06  eta: 1 day, 10:26:43  time: 0.4957  data_time: 0.0114  memory: 5895  grad_norm: 251.7480  loss: 5.8209  decode.loss_cls: 0.0552  decode.loss_mask: 0.2129  decode.loss_dice: 0.2009  decode.d0.loss_cls: 0.8469  decode.d0.loss_mask: 0.2168  decode.d0.loss_dice: 0.2063  decode.d1.loss_cls: 0.0787  decode.d1.loss_mask: 0.2161  decode.d1.loss_dice: 0.2138  decode.d2.loss_cls: 0.0693  decode.d2.loss_mask: 0.2114  decode.d2.loss_dice: 0.2073  decode.d3.loss_cls: 0.1396  decode.d3.loss_mask: 0.2094  decode.d3.loss_dice: 0.2028  decode.d4.loss_cls: 0.1083  decode.d4.loss_mask: 0.2099  decode.d4.loss_dice: 0.2065  decode.d5.loss_cls: 0.0950  decode.d5.loss_mask: 0.2086  decode.d5.loss_dice: 0.2057  decode.d6.loss_cls: 0.1037  decode.d6.loss_mask: 0.2121  decode.d6.loss_dice: 0.2039  decode.d7.loss_cls: 0.0536  decode.d7.loss_mask: 0.2117  decode.d7.loss_dice: 0.2069  decode.d8.loss_cls: 0.0885  decode.d8.loss_mask: 0.2138  decode.d8.loss_dice: 0.2049
08/06 11:46:12 - mmengine - INFO - Iter(train) [ 68750/320000]  base_lr: 8.0438e-05 lr: 8.0438e-06  eta: 1 day, 10:26:19  time: 0.4973  data_time: 0.0114  memory: 5911  grad_norm: 60.3668  loss: 5.7032  decode.loss_cls: 0.0661  decode.loss_mask: 0.1964  decode.loss_dice: 0.2353  decode.d0.loss_cls: 0.8162  decode.d0.loss_mask: 0.1923  decode.d0.loss_dice: 0.2359  decode.d1.loss_cls: 0.0655  decode.d1.loss_mask: 0.1919  decode.d1.loss_dice: 0.2283  decode.d2.loss_cls: 0.0706  decode.d2.loss_mask: 0.1910  decode.d2.loss_dice: 0.2143  decode.d3.loss_cls: 0.0467  decode.d3.loss_mask: 0.1909  decode.d3.loss_dice: 0.2204  decode.d4.loss_cls: 0.0626  decode.d4.loss_mask: 0.1906  decode.d4.loss_dice: 0.2235  decode.d5.loss_cls: 0.0707  decode.d5.loss_mask: 0.1958  decode.d5.loss_dice: 0.2390  decode.d6.loss_cls: 0.0980  decode.d6.loss_mask: 0.1935  decode.d6.loss_dice: 0.2145  decode.d7.loss_cls: 0.1303  decode.d7.loss_mask: 0.1914  decode.d7.loss_dice: 0.2249  decode.d8.loss_cls: 0.0863  decode.d8.loss_mask: 0.1942  decode.d8.loss_dice: 0.2262
08/06 11:46:37 - mmengine - INFO - Iter(train) [ 68800/320000]  base_lr: 8.0424e-05 lr: 8.0424e-06  eta: 1 day, 10:25:55  time: 0.4967  data_time: 0.0113  memory: 5911  grad_norm: 76.4985  loss: 6.2185  decode.loss_cls: 0.0508  decode.loss_mask: 0.1966  decode.loss_dice: 0.2587  decode.d0.loss_cls: 0.9153  decode.d0.loss_mask: 0.1943  decode.d0.loss_dice: 0.2758  decode.d1.loss_cls: 0.0885  decode.d1.loss_mask: 0.2015  decode.d1.loss_dice: 0.2484  decode.d2.loss_cls: 0.1144  decode.d2.loss_mask: 0.1955  decode.d2.loss_dice: 0.2382  decode.d3.loss_cls: 0.1077  decode.d3.loss_mask: 0.1989  decode.d3.loss_dice: 0.2484  decode.d4.loss_cls: 0.0977  decode.d4.loss_mask: 0.1968  decode.d4.loss_dice: 0.2494  decode.d5.loss_cls: 0.0962  decode.d5.loss_mask: 0.1948  decode.d5.loss_dice: 0.2332  decode.d6.loss_cls: 0.0694  decode.d6.loss_mask: 0.1981  decode.d6.loss_dice: 0.2505  decode.d7.loss_cls: 0.0990  decode.d7.loss_mask: 0.1949  decode.d7.loss_dice: 0.2493  decode.d8.loss_cls: 0.1110  decode.d8.loss_mask: 0.1927  decode.d8.loss_dice: 0.2526
08/06 11:47:01 - mmengine - INFO - Iter(train) [ 68850/320000]  base_lr: 8.0409e-05 lr: 8.0409e-06  eta: 1 day, 10:25:31  time: 0.4973  data_time: 0.0113  memory: 5928  grad_norm: 154.9587  loss: 7.4087  decode.loss_cls: 0.0344  decode.loss_mask: 0.2785  decode.loss_dice: 0.2898  decode.d0.loss_cls: 1.0258  decode.d0.loss_mask: 0.2338  decode.d0.loss_dice: 0.3073  decode.d1.loss_cls: 0.1526  decode.d1.loss_mask: 0.2345  decode.d1.loss_dice: 0.2953  decode.d2.loss_cls: 0.0815  decode.d2.loss_mask: 0.2763  decode.d2.loss_dice: 0.3082  decode.d3.loss_cls: 0.0930  decode.d3.loss_mask: 0.2695  decode.d3.loss_dice: 0.3122  decode.d4.loss_cls: 0.0469  decode.d4.loss_mask: 0.2647  decode.d4.loss_dice: 0.3400  decode.d5.loss_cls: 0.1111  decode.d5.loss_mask: 0.2600  decode.d5.loss_dice: 0.2924  decode.d6.loss_cls: 0.0961  decode.d6.loss_mask: 0.2614  decode.d6.loss_dice: 0.2961  decode.d7.loss_cls: 0.0351  decode.d7.loss_mask: 0.2624  decode.d7.loss_dice: 0.3273  decode.d8.loss_cls: 0.0731  decode.d8.loss_mask: 0.2648  decode.d8.loss_dice: 0.2843
08/06 11:47:26 - mmengine - INFO - Iter(train) [ 68900/320000]  base_lr: 8.0395e-05 lr: 8.0395e-06  eta: 1 day, 10:25:07  time: 0.4979  data_time: 0.0114  memory: 5894  grad_norm: 98.8525  loss: 6.5103  decode.loss_cls: 0.1050  decode.loss_mask: 0.2316  decode.loss_dice: 0.2220  decode.d0.loss_cls: 0.9242  decode.d0.loss_mask: 0.2353  decode.d0.loss_dice: 0.2266  decode.d1.loss_cls: 0.1186  decode.d1.loss_mask: 0.2319  decode.d1.loss_dice: 0.2290  decode.d2.loss_cls: 0.1345  decode.d2.loss_mask: 0.2312  decode.d2.loss_dice: 0.2313  decode.d3.loss_cls: 0.1187  decode.d3.loss_mask: 0.2314  decode.d3.loss_dice: 0.2322  decode.d4.loss_cls: 0.1047  decode.d4.loss_mask: 0.2310  decode.d4.loss_dice: 0.2322  decode.d5.loss_cls: 0.1065  decode.d5.loss_mask: 0.2301  decode.d5.loss_dice: 0.2285  decode.d6.loss_cls: 0.1007  decode.d6.loss_mask: 0.2305  decode.d6.loss_dice: 0.2258  decode.d7.loss_cls: 0.0935  decode.d7.loss_mask: 0.2309  decode.d7.loss_dice: 0.2241  decode.d8.loss_cls: 0.1069  decode.d8.loss_mask: 0.2347  decode.d8.loss_dice: 0.2268
08/06 11:47:51 - mmengine - INFO - Iter(train) [ 68950/320000]  base_lr: 8.0380e-05 lr: 8.0380e-06  eta: 1 day, 10:24:43  time: 0.4972  data_time: 0.0113  memory: 5895  grad_norm: 152.1476  loss: 6.7592  decode.loss_cls: 0.1921  decode.loss_mask: 0.1989  decode.loss_dice: 0.2578  decode.d0.loss_cls: 0.9811  decode.d0.loss_mask: 0.2004  decode.d0.loss_dice: 0.2502  decode.d1.loss_cls: 0.1088  decode.d1.loss_mask: 0.1957  decode.d1.loss_dice: 0.2534  decode.d2.loss_cls: 0.1282  decode.d2.loss_mask: 0.1974  decode.d2.loss_dice: 0.2397  decode.d3.loss_cls: 0.1389  decode.d3.loss_mask: 0.1997  decode.d3.loss_dice: 0.2272  decode.d4.loss_cls: 0.1069  decode.d4.loss_mask: 0.1965  decode.d4.loss_dice: 0.2364  decode.d5.loss_cls: 0.1196  decode.d5.loss_mask: 0.2032  decode.d5.loss_dice: 0.2542  decode.d6.loss_cls: 0.1581  decode.d6.loss_mask: 0.2021  decode.d6.loss_dice: 0.2503  decode.d7.loss_cls: 0.1751  decode.d7.loss_mask: 0.2020  decode.d7.loss_dice: 0.2567  decode.d8.loss_cls: 0.1596  decode.d8.loss_mask: 0.2028  decode.d8.loss_dice: 0.2661
08/06 11:48:16 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 11:48:16 - mmengine - INFO - Iter(train) [ 69000/320000]  base_lr: 8.0366e-05 lr: 8.0366e-06  eta: 1 day, 10:24:19  time: 0.4974  data_time: 0.0115  memory: 5874  grad_norm: 246.5781  loss: 7.8691  decode.loss_cls: 0.2472  decode.loss_mask: 0.2166  decode.loss_dice: 0.2882  decode.d0.loss_cls: 0.9403  decode.d0.loss_mask: 0.2134  decode.d0.loss_dice: 0.2747  decode.d1.loss_cls: 0.2115  decode.d1.loss_mask: 0.2047  decode.d1.loss_dice: 0.2791  decode.d2.loss_cls: 0.1620  decode.d2.loss_mask: 0.2046  decode.d2.loss_dice: 0.2888  decode.d3.loss_cls: 0.1861  decode.d3.loss_mask: 0.2038  decode.d3.loss_dice: 0.2776  decode.d4.loss_cls: 0.2406  decode.d4.loss_mask: 0.2022  decode.d4.loss_dice: 0.2743  decode.d5.loss_cls: 0.1774  decode.d5.loss_mask: 0.2091  decode.d5.loss_dice: 0.2871  decode.d6.loss_cls: 0.2775  decode.d6.loss_mask: 0.2139  decode.d6.loss_dice: 0.2909  decode.d7.loss_cls: 0.2655  decode.d7.loss_mask: 0.2161  decode.d7.loss_dice: 0.2931  decode.d8.loss_cls: 0.2072  decode.d8.loss_mask: 0.2172  decode.d8.loss_dice: 0.2982
08/06 11:48:41 - mmengine - INFO - Iter(train) [ 69050/320000]  base_lr: 8.0352e-05 lr: 8.0352e-06  eta: 1 day, 10:23:55  time: 0.4968  data_time: 0.0113  memory: 5891  grad_norm: 46.2573  loss: 5.6537  decode.loss_cls: 0.0764  decode.loss_mask: 0.2055  decode.loss_dice: 0.2280  decode.d0.loss_cls: 0.7559  decode.d0.loss_mask: 0.2096  decode.d0.loss_dice: 0.2387  decode.d1.loss_cls: 0.0866  decode.d1.loss_mask: 0.2102  decode.d1.loss_dice: 0.2376  decode.d2.loss_cls: 0.0476  decode.d2.loss_mask: 0.2072  decode.d2.loss_dice: 0.2400  decode.d3.loss_cls: 0.0349  decode.d3.loss_mask: 0.2082  decode.d3.loss_dice: 0.2403  decode.d4.loss_cls: 0.0331  decode.d4.loss_mask: 0.2092  decode.d4.loss_dice: 0.2382  decode.d5.loss_cls: 0.0320  decode.d5.loss_mask: 0.2091  decode.d5.loss_dice: 0.2275  decode.d6.loss_cls: 0.0360  decode.d6.loss_mask: 0.2098  decode.d6.loss_dice: 0.2324  decode.d7.loss_cls: 0.0375  decode.d7.loss_mask: 0.2069  decode.d7.loss_dice: 0.2417  decode.d8.loss_cls: 0.0765  decode.d8.loss_mask: 0.2059  decode.d8.loss_dice: 0.2312
08/06 11:49:06 - mmengine - INFO - Iter(train) [ 69100/320000]  base_lr: 8.0337e-05 lr: 8.0337e-06  eta: 1 day, 10:23:31  time: 0.4974  data_time: 0.0115  memory: 5913  grad_norm: 46.3582  loss: 6.3791  decode.loss_cls: 0.0706  decode.loss_mask: 0.2159  decode.loss_dice: 0.2634  decode.d0.loss_cls: 0.9293  decode.d0.loss_mask: 0.2212  decode.d0.loss_dice: 0.2807  decode.d1.loss_cls: 0.1102  decode.d1.loss_mask: 0.2159  decode.d1.loss_dice: 0.2809  decode.d2.loss_cls: 0.0447  decode.d2.loss_mask: 0.2140  decode.d2.loss_dice: 0.2553  decode.d3.loss_cls: 0.0927  decode.d3.loss_mask: 0.2148  decode.d3.loss_dice: 0.2619  decode.d4.loss_cls: 0.0737  decode.d4.loss_mask: 0.2166  decode.d4.loss_dice: 0.3005  decode.d5.loss_cls: 0.0565  decode.d5.loss_mask: 0.2167  decode.d5.loss_dice: 0.2607  decode.d6.loss_cls: 0.0659  decode.d6.loss_mask: 0.2130  decode.d6.loss_dice: 0.2343  decode.d7.loss_cls: 0.0470  decode.d7.loss_mask: 0.2163  decode.d7.loss_dice: 0.2532  decode.d8.loss_cls: 0.0867  decode.d8.loss_mask: 0.2165  decode.d8.loss_dice: 0.2501
08/06 11:49:31 - mmengine - INFO - Iter(train) [ 69150/320000]  base_lr: 8.0323e-05 lr: 8.0323e-06  eta: 1 day, 10:23:07  time: 0.4974  data_time: 0.0114  memory: 5913  grad_norm: 201.7155  loss: 6.1866  decode.loss_cls: 0.1335  decode.loss_mask: 0.1999  decode.loss_dice: 0.2014  decode.d0.loss_cls: 0.7415  decode.d0.loss_mask: 0.2144  decode.d0.loss_dice: 0.2129  decode.d1.loss_cls: 0.0971  decode.d1.loss_mask: 0.2057  decode.d1.loss_dice: 0.2065  decode.d2.loss_cls: 0.1321  decode.d2.loss_mask: 0.2037  decode.d2.loss_dice: 0.2065  decode.d3.loss_cls: 0.1767  decode.d3.loss_mask: 0.2033  decode.d3.loss_dice: 0.2040  decode.d4.loss_cls: 0.1529  decode.d4.loss_mask: 0.2035  decode.d4.loss_dice: 0.2002  decode.d5.loss_cls: 0.1492  decode.d5.loss_mask: 0.2075  decode.d5.loss_dice: 0.2031  decode.d6.loss_cls: 0.1989  decode.d6.loss_mask: 0.2057  decode.d6.loss_dice: 0.2000  decode.d7.loss_cls: 0.1613  decode.d7.loss_mask: 0.2013  decode.d7.loss_dice: 0.2016  decode.d8.loss_cls: 0.1613  decode.d8.loss_mask: 0.1994  decode.d8.loss_dice: 0.2015
08/06 11:49:56 - mmengine - INFO - Iter(train) [ 69200/320000]  base_lr: 8.0308e-05 lr: 8.0308e-06  eta: 1 day, 10:22:43  time: 0.4964  data_time: 0.0115  memory: 5911  grad_norm: 145.5254  loss: 7.9978  decode.loss_cls: 0.1022  decode.loss_mask: 0.2922  decode.loss_dice: 0.3219  decode.d0.loss_cls: 0.8414  decode.d0.loss_mask: 0.2949  decode.d0.loss_dice: 0.3494  decode.d1.loss_cls: 0.1225  decode.d1.loss_mask: 0.2963  decode.d1.loss_dice: 0.3349  decode.d2.loss_cls: 0.1424  decode.d2.loss_mask: 0.2953  decode.d2.loss_dice: 0.3210  decode.d3.loss_cls: 0.1273  decode.d3.loss_mask: 0.2890  decode.d3.loss_dice: 0.3237  decode.d4.loss_cls: 0.0993  decode.d4.loss_mask: 0.2936  decode.d4.loss_dice: 0.3018  decode.d5.loss_cls: 0.0855  decode.d5.loss_mask: 0.2900  decode.d5.loss_dice: 0.3067  decode.d6.loss_cls: 0.1252  decode.d6.loss_mask: 0.2888  decode.d6.loss_dice: 0.2951  decode.d7.loss_cls: 0.1346  decode.d7.loss_mask: 0.2926  decode.d7.loss_dice: 0.2758  decode.d8.loss_cls: 0.1611  decode.d8.loss_mask: 0.2917  decode.d8.loss_dice: 0.3018
08/06 11:50:20 - mmengine - INFO - Iter(train) [ 69250/320000]  base_lr: 8.0294e-05 lr: 8.0294e-06  eta: 1 day, 10:22:19  time: 0.4971  data_time: 0.0114  memory: 5913  grad_norm: 111.3426  loss: 7.0733  decode.loss_cls: 0.1879  decode.loss_mask: 0.2050  decode.loss_dice: 0.2454  decode.d0.loss_cls: 0.7252  decode.d0.loss_mask: 0.2251  decode.d0.loss_dice: 0.2764  decode.d1.loss_cls: 0.1907  decode.d1.loss_mask: 0.2122  decode.d1.loss_dice: 0.2479  decode.d2.loss_cls: 0.2240  decode.d2.loss_mask: 0.2076  decode.d2.loss_dice: 0.2502  decode.d3.loss_cls: 0.1052  decode.d3.loss_mask: 0.2332  decode.d3.loss_dice: 0.2696  decode.d4.loss_cls: 0.2050  decode.d4.loss_mask: 0.2119  decode.d4.loss_dice: 0.2491  decode.d5.loss_cls: 0.1589  decode.d5.loss_mask: 0.2276  decode.d5.loss_dice: 0.2611  decode.d6.loss_cls: 0.1854  decode.d6.loss_mask: 0.2089  decode.d6.loss_dice: 0.2515  decode.d7.loss_cls: 0.1855  decode.d7.loss_mask: 0.2071  decode.d7.loss_dice: 0.2471  decode.d8.loss_cls: 0.2061  decode.d8.loss_mask: 0.2090  decode.d8.loss_dice: 0.2535
08/06 11:50:45 - mmengine - INFO - Iter(train) [ 69300/320000]  base_lr: 8.0280e-05 lr: 8.0280e-06  eta: 1 day, 10:21:55  time: 0.4969  data_time: 0.0114  memory: 5911  grad_norm: 61.1903  loss: 6.5825  decode.loss_cls: 0.0926  decode.loss_mask: 0.2238  decode.loss_dice: 0.2499  decode.d0.loss_cls: 0.7761  decode.d0.loss_mask: 0.2308  decode.d0.loss_dice: 0.2616  decode.d1.loss_cls: 0.1623  decode.d1.loss_mask: 0.2278  decode.d1.loss_dice: 0.2557  decode.d2.loss_cls: 0.0940  decode.d2.loss_mask: 0.2278  decode.d2.loss_dice: 0.2593  decode.d3.loss_cls: 0.1007  decode.d3.loss_mask: 0.2306  decode.d3.loss_dice: 0.2454  decode.d4.loss_cls: 0.1412  decode.d4.loss_mask: 0.2244  decode.d4.loss_dice: 0.2549  decode.d5.loss_cls: 0.1126  decode.d5.loss_mask: 0.2248  decode.d5.loss_dice: 0.2569  decode.d6.loss_cls: 0.0971  decode.d6.loss_mask: 0.2269  decode.d6.loss_dice: 0.2437  decode.d7.loss_cls: 0.1253  decode.d7.loss_mask: 0.2245  decode.d7.loss_dice: 0.2465  decode.d8.loss_cls: 0.0894  decode.d8.loss_mask: 0.2284  decode.d8.loss_dice: 0.2474
08/06 11:51:10 - mmengine - INFO - Iter(train) [ 69350/320000]  base_lr: 8.0265e-05 lr: 8.0265e-06  eta: 1 day, 10:21:31  time: 0.4964  data_time: 0.0115  memory: 5895  grad_norm: 150.9885  loss: 6.5025  decode.loss_cls: 0.0658  decode.loss_mask: 0.2590  decode.loss_dice: 0.2439  decode.d0.loss_cls: 0.7820  decode.d0.loss_mask: 0.2631  decode.d0.loss_dice: 0.2574  decode.d1.loss_cls: 0.0509  decode.d1.loss_mask: 0.2625  decode.d1.loss_dice: 0.2396  decode.d2.loss_cls: 0.0658  decode.d2.loss_mask: 0.2575  decode.d2.loss_dice: 0.2524  decode.d3.loss_cls: 0.0452  decode.d3.loss_mask: 0.2581  decode.d3.loss_dice: 0.2554  decode.d4.loss_cls: 0.0577  decode.d4.loss_mask: 0.2610  decode.d4.loss_dice: 0.2540  decode.d5.loss_cls: 0.0533  decode.d5.loss_mask: 0.2592  decode.d5.loss_dice: 0.3033  decode.d6.loss_cls: 0.0568  decode.d6.loss_mask: 0.2607  decode.d6.loss_dice: 0.2380  decode.d7.loss_cls: 0.0624  decode.d7.loss_mask: 0.2563  decode.d7.loss_dice: 0.2716  decode.d8.loss_cls: 0.0634  decode.d8.loss_mask: 0.2552  decode.d8.loss_dice: 0.2910
08/06 11:51:35 - mmengine - INFO - Iter(train) [ 69400/320000]  base_lr: 8.0251e-05 lr: 8.0251e-06  eta: 1 day, 10:21:07  time: 0.4974  data_time: 0.0114  memory: 5891  grad_norm: 111.5242  loss: 8.0635  decode.loss_cls: 0.0940  decode.loss_mask: 0.2977  decode.loss_dice: 0.3140  decode.d0.loss_cls: 0.8271  decode.d0.loss_mask: 0.2900  decode.d0.loss_dice: 0.3127  decode.d1.loss_cls: 0.1058  decode.d1.loss_mask: 0.3002  decode.d1.loss_dice: 0.3152  decode.d2.loss_cls: 0.1160  decode.d2.loss_mask: 0.2904  decode.d2.loss_dice: 0.3085  decode.d3.loss_cls: 0.1078  decode.d3.loss_mask: 0.2894  decode.d3.loss_dice: 0.3135  decode.d4.loss_cls: 0.1001  decode.d4.loss_mask: 0.2936  decode.d4.loss_dice: 0.3281  decode.d5.loss_cls: 0.1440  decode.d5.loss_mask: 0.2952  decode.d5.loss_dice: 0.3117  decode.d6.loss_cls: 0.1452  decode.d6.loss_mask: 0.2990  decode.d6.loss_dice: 0.3223  decode.d7.loss_cls: 0.1658  decode.d7.loss_mask: 0.2918  decode.d7.loss_dice: 0.3023  decode.d8.loss_cls: 0.1666  decode.d8.loss_mask: 0.2967  decode.d8.loss_dice: 0.3188
08/06 11:52:00 - mmengine - INFO - Iter(train) [ 69450/320000]  base_lr: 8.0236e-05 lr: 8.0236e-06  eta: 1 day, 10:20:43  time: 0.4981  data_time: 0.0114  memory: 5911  grad_norm: 51.4239  loss: 6.8582  decode.loss_cls: 0.1301  decode.loss_mask: 0.2280  decode.loss_dice: 0.2745  decode.d0.loss_cls: 0.7890  decode.d0.loss_mask: 0.2320  decode.d0.loss_dice: 0.2887  decode.d1.loss_cls: 0.1152  decode.d1.loss_mask: 0.2292  decode.d1.loss_dice: 0.2647  decode.d2.loss_cls: 0.1082  decode.d2.loss_mask: 0.2287  decode.d2.loss_dice: 0.2895  decode.d3.loss_cls: 0.1199  decode.d3.loss_mask: 0.2283  decode.d3.loss_dice: 0.2582  decode.d4.loss_cls: 0.1234  decode.d4.loss_mask: 0.2276  decode.d4.loss_dice: 0.2679  decode.d5.loss_cls: 0.1311  decode.d5.loss_mask: 0.2284  decode.d5.loss_dice: 0.2564  decode.d6.loss_cls: 0.1073  decode.d6.loss_mask: 0.2281  decode.d6.loss_dice: 0.2775  decode.d7.loss_cls: 0.1003  decode.d7.loss_mask: 0.2300  decode.d7.loss_dice: 0.2840  decode.d8.loss_cls: 0.1040  decode.d8.loss_mask: 0.2282  decode.d8.loss_dice: 0.2798
08/06 11:52:25 - mmengine - INFO - Iter(train) [ 69500/320000]  base_lr: 8.0222e-05 lr: 8.0222e-06  eta: 1 day, 10:20:19  time: 0.4963  data_time: 0.0111  memory: 5967  grad_norm: 78.7367  loss: 6.8966  decode.loss_cls: 0.1709  decode.loss_mask: 0.2078  decode.loss_dice: 0.2598  decode.d0.loss_cls: 0.9735  decode.d0.loss_mask: 0.2096  decode.d0.loss_dice: 0.2623  decode.d1.loss_cls: 0.1256  decode.d1.loss_mask: 0.2105  decode.d1.loss_dice: 0.2488  decode.d2.loss_cls: 0.1017  decode.d2.loss_mask: 0.2071  decode.d2.loss_dice: 0.2586  decode.d3.loss_cls: 0.1127  decode.d3.loss_mask: 0.2099  decode.d3.loss_dice: 0.2339  decode.d4.loss_cls: 0.1258  decode.d4.loss_mask: 0.2066  decode.d4.loss_dice: 0.2605  decode.d5.loss_cls: 0.1397  decode.d5.loss_mask: 0.2078  decode.d5.loss_dice: 0.2623  decode.d6.loss_cls: 0.1529  decode.d6.loss_mask: 0.2086  decode.d6.loss_dice: 0.2451  decode.d7.loss_cls: 0.1945  decode.d7.loss_mask: 0.2111  decode.d7.loss_dice: 0.2478  decode.d8.loss_cls: 0.1974  decode.d8.loss_mask: 0.2112  decode.d8.loss_dice: 0.2325
08/06 11:52:50 - mmengine - INFO - Iter(train) [ 69550/320000]  base_lr: 8.0208e-05 lr: 8.0208e-06  eta: 1 day, 10:19:55  time: 0.4977  data_time: 0.0117  memory: 5911  grad_norm: 64.4744  loss: 7.0098  decode.loss_cls: 0.1042  decode.loss_mask: 0.1980  decode.loss_dice: 0.2758  decode.d0.loss_cls: 0.9124  decode.d0.loss_mask: 0.1934  decode.d0.loss_dice: 0.2689  decode.d1.loss_cls: 0.2946  decode.d1.loss_mask: 0.1948  decode.d1.loss_dice: 0.2848  decode.d2.loss_cls: 0.2120  decode.d2.loss_mask: 0.1979  decode.d2.loss_dice: 0.2932  decode.d3.loss_cls: 0.1258  decode.d3.loss_mask: 0.1945  decode.d3.loss_dice: 0.2632  decode.d4.loss_cls: 0.1273  decode.d4.loss_mask: 0.1956  decode.d4.loss_dice: 0.2799  decode.d5.loss_cls: 0.1409  decode.d5.loss_mask: 0.1972  decode.d5.loss_dice: 0.2652  decode.d6.loss_cls: 0.1297  decode.d6.loss_mask: 0.1970  decode.d6.loss_dice: 0.2685  decode.d7.loss_cls: 0.1252  decode.d7.loss_mask: 0.1970  decode.d7.loss_dice: 0.2763  decode.d8.loss_cls: 0.1260  decode.d8.loss_mask: 0.1985  decode.d8.loss_dice: 0.2721
08/06 11:53:15 - mmengine - INFO - Iter(train) [ 69600/320000]  base_lr: 8.0193e-05 lr: 8.0193e-06  eta: 1 day, 10:19:31  time: 0.4975  data_time: 0.0114  memory: 5911  grad_norm: 267.0077  loss: 8.1200  decode.loss_cls: 0.2032  decode.loss_mask: 0.2204  decode.loss_dice: 0.3087  decode.d0.loss_cls: 0.9863  decode.d0.loss_mask: 0.2441  decode.d0.loss_dice: 0.3057  decode.d1.loss_cls: 0.1866  decode.d1.loss_mask: 0.2532  decode.d1.loss_dice: 0.3249  decode.d2.loss_cls: 0.2022  decode.d2.loss_mask: 0.2398  decode.d2.loss_dice: 0.3133  decode.d3.loss_cls: 0.2305  decode.d3.loss_mask: 0.2315  decode.d3.loss_dice: 0.3192  decode.d4.loss_cls: 0.1407  decode.d4.loss_mask: 0.2283  decode.d4.loss_dice: 0.3043  decode.d5.loss_cls: 0.2210  decode.d5.loss_mask: 0.2347  decode.d5.loss_dice: 0.3088  decode.d6.loss_cls: 0.1708  decode.d6.loss_mask: 0.2386  decode.d6.loss_dice: 0.3177  decode.d7.loss_cls: 0.1247  decode.d7.loss_mask: 0.2269  decode.d7.loss_dice: 0.3059  decode.d8.loss_cls: 0.2390  decode.d8.loss_mask: 0.2119  decode.d8.loss_dice: 0.2768
08/06 11:53:39 - mmengine - INFO - Iter(train) [ 69650/320000]  base_lr: 8.0179e-05 lr: 8.0179e-06  eta: 1 day, 10:19:07  time: 0.4966  data_time: 0.0111  memory: 5895  grad_norm: 195.7552  loss: 6.8863  decode.loss_cls: 0.0661  decode.loss_mask: 0.2535  decode.loss_dice: 0.2526  decode.d0.loss_cls: 0.8675  decode.d0.loss_mask: 0.2621  decode.d0.loss_dice: 0.2434  decode.d1.loss_cls: 0.1737  decode.d1.loss_mask: 0.2505  decode.d1.loss_dice: 0.2523  decode.d2.loss_cls: 0.1158  decode.d2.loss_mask: 0.2515  decode.d2.loss_dice: 0.2554  decode.d3.loss_cls: 0.0795  decode.d3.loss_mask: 0.2713  decode.d3.loss_dice: 0.2573  decode.d4.loss_cls: 0.1159  decode.d4.loss_mask: 0.2512  decode.d4.loss_dice: 0.2501  decode.d5.loss_cls: 0.0743  decode.d5.loss_mask: 0.2646  decode.d5.loss_dice: 0.2557  decode.d6.loss_cls: 0.1258  decode.d6.loss_mask: 0.2488  decode.d6.loss_dice: 0.2521  decode.d7.loss_cls: 0.1005  decode.d7.loss_mask: 0.2613  decode.d7.loss_dice: 0.2599  decode.d8.loss_cls: 0.0540  decode.d8.loss_mask: 0.2627  decode.d8.loss_dice: 0.2570
08/06 11:54:04 - mmengine - INFO - Iter(train) [ 69700/320000]  base_lr: 8.0164e-05 lr: 8.0164e-06  eta: 1 day, 10:18:43  time: 0.4974  data_time: 0.0113  memory: 5874  grad_norm: 103.6151  loss: 7.7618  decode.loss_cls: 0.1721  decode.loss_mask: 0.2639  decode.loss_dice: 0.2976  decode.d0.loss_cls: 0.8954  decode.d0.loss_mask: 0.2701  decode.d0.loss_dice: 0.3012  decode.d1.loss_cls: 0.1139  decode.d1.loss_mask: 0.2597  decode.d1.loss_dice: 0.3059  decode.d2.loss_cls: 0.0953  decode.d2.loss_mask: 0.2625  decode.d2.loss_dice: 0.3108  decode.d3.loss_cls: 0.1153  decode.d3.loss_mask: 0.2610  decode.d3.loss_dice: 0.2698  decode.d4.loss_cls: 0.1464  decode.d4.loss_mask: 0.2578  decode.d4.loss_dice: 0.2948  decode.d5.loss_cls: 0.1524  decode.d5.loss_mask: 0.2563  decode.d5.loss_dice: 0.2929  decode.d6.loss_cls: 0.1200  decode.d6.loss_mask: 0.2622  decode.d6.loss_dice: 0.2952  decode.d7.loss_cls: 0.1960  decode.d7.loss_mask: 0.2592  decode.d7.loss_dice: 0.3002  decode.d8.loss_cls: 0.1659  decode.d8.loss_mask: 0.2728  decode.d8.loss_dice: 0.2953
08/06 11:54:29 - mmengine - INFO - Iter(train) [ 69750/320000]  base_lr: 8.0150e-05 lr: 8.0150e-06  eta: 1 day, 10:18:19  time: 0.4976  data_time: 0.0115  memory: 5891  grad_norm: 46.4496  loss: 6.3443  decode.loss_cls: 0.0717  decode.loss_mask: 0.2675  decode.loss_dice: 0.2462  decode.d0.loss_cls: 0.8019  decode.d0.loss_mask: 0.2727  decode.d0.loss_dice: 0.2264  decode.d1.loss_cls: 0.0290  decode.d1.loss_mask: 0.2678  decode.d1.loss_dice: 0.2462  decode.d2.loss_cls: 0.0369  decode.d2.loss_mask: 0.2689  decode.d2.loss_dice: 0.2468  decode.d3.loss_cls: 0.0464  decode.d3.loss_mask: 0.2685  decode.d3.loss_dice: 0.2421  decode.d4.loss_cls: 0.0475  decode.d4.loss_mask: 0.2669  decode.d4.loss_dice: 0.2409  decode.d5.loss_cls: 0.0719  decode.d5.loss_mask: 0.2685  decode.d5.loss_dice: 0.2461  decode.d6.loss_cls: 0.0599  decode.d6.loss_mask: 0.2670  decode.d6.loss_dice: 0.2410  decode.d7.loss_cls: 0.0420  decode.d7.loss_mask: 0.2636  decode.d7.loss_dice: 0.2407  decode.d8.loss_cls: 0.0448  decode.d8.loss_mask: 0.2647  decode.d8.loss_dice: 0.2396
08/06 11:54:54 - mmengine - INFO - Iter(train) [ 69800/320000]  base_lr: 8.0135e-05 lr: 8.0135e-06  eta: 1 day, 10:17:55  time: 0.4969  data_time: 0.0113  memory: 5928  grad_norm: 55.5065  loss: 7.0314  decode.loss_cls: 0.0835  decode.loss_mask: 0.2593  decode.loss_dice: 0.2674  decode.d0.loss_cls: 1.0426  decode.d0.loss_mask: 0.2641  decode.d0.loss_dice: 0.2603  decode.d1.loss_cls: 0.1066  decode.d1.loss_mask: 0.2613  decode.d1.loss_dice: 0.2681  decode.d2.loss_cls: 0.0872  decode.d2.loss_mask: 0.2589  decode.d2.loss_dice: 0.2731  decode.d3.loss_cls: 0.0831  decode.d3.loss_mask: 0.2600  decode.d3.loss_dice: 0.2608  decode.d4.loss_cls: 0.0768  decode.d4.loss_mask: 0.2580  decode.d4.loss_dice: 0.2684  decode.d5.loss_cls: 0.0798  decode.d5.loss_mask: 0.2584  decode.d5.loss_dice: 0.2630  decode.d6.loss_cls: 0.0602  decode.d6.loss_mask: 0.2585  decode.d6.loss_dice: 0.2667  decode.d7.loss_cls: 0.0700  decode.d7.loss_mask: 0.2588  decode.d7.loss_dice: 0.2723  decode.d8.loss_cls: 0.0730  decode.d8.loss_mask: 0.2558  decode.d8.loss_dice: 0.2755
08/06 11:55:19 - mmengine - INFO - Iter(train) [ 69850/320000]  base_lr: 8.0121e-05 lr: 8.0121e-06  eta: 1 day, 10:17:31  time: 0.4959  data_time: 0.0111  memory: 5911  grad_norm: 57.3423  loss: 5.7502  decode.loss_cls: 0.0359  decode.loss_mask: 0.2103  decode.loss_dice: 0.2433  decode.d0.loss_cls: 0.8743  decode.d0.loss_mask: 0.2135  decode.d0.loss_dice: 0.2468  decode.d1.loss_cls: 0.0180  decode.d1.loss_mask: 0.2136  decode.d1.loss_dice: 0.2544  decode.d2.loss_cls: 0.0171  decode.d2.loss_mask: 0.2116  decode.d2.loss_dice: 0.2477  decode.d3.loss_cls: 0.0196  decode.d3.loss_mask: 0.2132  decode.d3.loss_dice: 0.2605  decode.d4.loss_cls: 0.0223  decode.d4.loss_mask: 0.2109  decode.d4.loss_dice: 0.2524  decode.d5.loss_cls: 0.0266  decode.d5.loss_mask: 0.2115  decode.d5.loss_dice: 0.2442  decode.d6.loss_cls: 0.0375  decode.d6.loss_mask: 0.2112  decode.d6.loss_dice: 0.2535  decode.d7.loss_cls: 0.0462  decode.d7.loss_mask: 0.2109  decode.d7.loss_dice: 0.2458  decode.d8.loss_cls: 0.0416  decode.d8.loss_mask: 0.2099  decode.d8.loss_dice: 0.2460
08/06 11:55:44 - mmengine - INFO - Iter(train) [ 69900/320000]  base_lr: 8.0107e-05 lr: 8.0107e-06  eta: 1 day, 10:17:07  time: 0.4967  data_time: 0.0111  memory: 5875  grad_norm: 162.3487  loss: 5.5532  decode.loss_cls: 0.0184  decode.loss_mask: 0.1937  decode.loss_dice: 0.2419  decode.d0.loss_cls: 0.8448  decode.d0.loss_mask: 0.2012  decode.d0.loss_dice: 0.2599  decode.d1.loss_cls: 0.0285  decode.d1.loss_mask: 0.1949  decode.d1.loss_dice: 0.2452  decode.d2.loss_cls: 0.0729  decode.d2.loss_mask: 0.1847  decode.d2.loss_dice: 0.2199  decode.d3.loss_cls: 0.0616  decode.d3.loss_mask: 0.1877  decode.d3.loss_dice: 0.2287  decode.d4.loss_cls: 0.0518  decode.d4.loss_mask: 0.1902  decode.d4.loss_dice: 0.2406  decode.d5.loss_cls: 0.0295  decode.d5.loss_mask: 0.1959  decode.d5.loss_dice: 0.2468  decode.d6.loss_cls: 0.0737  decode.d6.loss_mask: 0.1879  decode.d6.loss_dice: 0.2329  decode.d7.loss_cls: 0.0566  decode.d7.loss_mask: 0.1854  decode.d7.loss_dice: 0.2278  decode.d8.loss_cls: 0.0192  decode.d8.loss_mask: 0.1890  decode.d8.loss_dice: 0.2418
08/06 11:56:09 - mmengine - INFO - Iter(train) [ 69950/320000]  base_lr: 8.0092e-05 lr: 8.0092e-06  eta: 1 day, 10:16:43  time: 0.4983  data_time: 0.0112  memory: 5894  grad_norm: 116.6454  loss: 8.1943  decode.loss_cls: 0.2030  decode.loss_mask: 0.2125  decode.loss_dice: 0.3078  decode.d0.loss_cls: 0.9877  decode.d0.loss_mask: 0.2219  decode.d0.loss_dice: 0.2921  decode.d1.loss_cls: 0.1939  decode.d1.loss_mask: 0.2148  decode.d1.loss_dice: 0.2797  decode.d2.loss_cls: 0.2388  decode.d2.loss_mask: 0.2139  decode.d2.loss_dice: 0.2820  decode.d3.loss_cls: 0.2712  decode.d3.loss_mask: 0.2134  decode.d3.loss_dice: 0.2938  decode.d4.loss_cls: 0.2527  decode.d4.loss_mask: 0.2160  decode.d4.loss_dice: 0.2993  decode.d5.loss_cls: 0.2603  decode.d5.loss_mask: 0.2151  decode.d5.loss_dice: 0.2998  decode.d6.loss_cls: 0.2346  decode.d6.loss_mask: 0.2144  decode.d6.loss_dice: 0.2987  decode.d7.loss_cls: 0.2824  decode.d7.loss_mask: 0.2139  decode.d7.loss_dice: 0.2818  decode.d8.loss_cls: 0.1727  decode.d8.loss_mask: 0.2123  decode.d8.loss_dice: 0.3138
08/06 11:56:34 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 11:56:34 - mmengine - INFO - Iter(train) [ 70000/320000]  base_lr: 8.0078e-05 lr: 8.0078e-06  eta: 1 day, 10:16:20  time: 0.4983  data_time: 0.0114  memory: 5968  grad_norm: 117.9323  loss: 7.3813  decode.loss_cls: 0.1806  decode.loss_mask: 0.2056  decode.loss_dice: 0.2451  decode.d0.loss_cls: 0.9852  decode.d0.loss_mask: 0.2048  decode.d0.loss_dice: 0.2639  decode.d1.loss_cls: 0.2206  decode.d1.loss_mask: 0.2045  decode.d1.loss_dice: 0.2477  decode.d2.loss_cls: 0.2096  decode.d2.loss_mask: 0.2037  decode.d2.loss_dice: 0.2434  decode.d3.loss_cls: 0.2135  decode.d3.loss_mask: 0.2066  decode.d3.loss_dice: 0.2605  decode.d4.loss_cls: 0.1915  decode.d4.loss_mask: 0.2064  decode.d4.loss_dice: 0.2648  decode.d5.loss_cls: 0.2135  decode.d5.loss_mask: 0.2060  decode.d5.loss_dice: 0.2409  decode.d6.loss_cls: 0.1766  decode.d6.loss_mask: 0.2068  decode.d6.loss_dice: 0.2732  decode.d7.loss_cls: 0.1926  decode.d7.loss_mask: 0.2052  decode.d7.loss_dice: 0.2495  decode.d8.loss_cls: 0.2100  decode.d8.loss_mask: 0.2036  decode.d8.loss_dice: 0.2453
08/06 11:56:59 - mmengine - INFO - Iter(train) [ 70050/320000]  base_lr: 8.0063e-05 lr: 8.0063e-06  eta: 1 day, 10:15:56  time: 0.4974  data_time: 0.0113  memory: 5894  grad_norm: 207.1211  loss: 8.1552  decode.loss_cls: 0.2462  decode.loss_mask: 0.2559  decode.loss_dice: 0.2759  decode.d0.loss_cls: 0.9666  decode.d0.loss_mask: 0.2615  decode.d0.loss_dice: 0.2781  decode.d1.loss_cls: 0.1670  decode.d1.loss_mask: 0.2616  decode.d1.loss_dice: 0.2763  decode.d2.loss_cls: 0.2782  decode.d2.loss_mask: 0.2576  decode.d2.loss_dice: 0.2783  decode.d3.loss_cls: 0.1997  decode.d3.loss_mask: 0.2583  decode.d3.loss_dice: 0.2737  decode.d4.loss_cls: 0.2555  decode.d4.loss_mask: 0.2567  decode.d4.loss_dice: 0.2699  decode.d5.loss_cls: 0.1953  decode.d5.loss_mask: 0.2590  decode.d5.loss_dice: 0.2628  decode.d6.loss_cls: 0.1688  decode.d6.loss_mask: 0.2505  decode.d6.loss_dice: 0.2486  decode.d7.loss_cls: 0.2161  decode.d7.loss_mask: 0.2549  decode.d7.loss_dice: 0.2524  decode.d8.loss_cls: 0.1881  decode.d8.loss_mask: 0.2535  decode.d8.loss_dice: 0.2883
08/06 11:57:23 - mmengine - INFO - Iter(train) [ 70100/320000]  base_lr: 8.0049e-05 lr: 8.0049e-06  eta: 1 day, 10:15:31  time: 0.4973  data_time: 0.0113  memory: 5874  grad_norm: 261.1276  loss: 6.6858  decode.loss_cls: 0.0781  decode.loss_mask: 0.2264  decode.loss_dice: 0.2761  decode.d0.loss_cls: 0.8887  decode.d0.loss_mask: 0.2267  decode.d0.loss_dice: 0.2661  decode.d1.loss_cls: 0.0803  decode.d1.loss_mask: 0.2281  decode.d1.loss_dice: 0.2739  decode.d2.loss_cls: 0.0856  decode.d2.loss_mask: 0.2265  decode.d2.loss_dice: 0.2586  decode.d3.loss_cls: 0.1146  decode.d3.loss_mask: 0.2251  decode.d3.loss_dice: 0.2708  decode.d4.loss_cls: 0.1140  decode.d4.loss_mask: 0.2255  decode.d4.loss_dice: 0.2787  decode.d5.loss_cls: 0.0747  decode.d5.loss_mask: 0.2287  decode.d5.loss_dice: 0.2713  decode.d6.loss_cls: 0.0842  decode.d6.loss_mask: 0.2281  decode.d6.loss_dice: 0.2723  decode.d7.loss_cls: 0.0821  decode.d7.loss_mask: 0.2302  decode.d7.loss_dice: 0.2727  decode.d8.loss_cls: 0.0991  decode.d8.loss_mask: 0.2273  decode.d8.loss_dice: 0.2714
08/06 11:57:48 - mmengine - INFO - Iter(train) [ 70150/320000]  base_lr: 8.0035e-05 lr: 8.0035e-06  eta: 1 day, 10:15:07  time: 0.4967  data_time: 0.0115  memory: 5911  grad_norm: 80.2467  loss: 7.6344  decode.loss_cls: 0.1739  decode.loss_mask: 0.2446  decode.loss_dice: 0.2724  decode.d0.loss_cls: 1.0141  decode.d0.loss_mask: 0.2396  decode.d0.loss_dice: 0.2908  decode.d1.loss_cls: 0.1839  decode.d1.loss_mask: 0.2486  decode.d1.loss_dice: 0.2928  decode.d2.loss_cls: 0.1564  decode.d2.loss_mask: 0.2444  decode.d2.loss_dice: 0.2752  decode.d3.loss_cls: 0.1507  decode.d3.loss_mask: 0.2516  decode.d3.loss_dice: 0.2835  decode.d4.loss_cls: 0.1505  decode.d4.loss_mask: 0.2481  decode.d4.loss_dice: 0.2387  decode.d5.loss_cls: 0.1562  decode.d5.loss_mask: 0.2505  decode.d5.loss_dice: 0.2395  decode.d6.loss_cls: 0.1518  decode.d6.loss_mask: 0.2460  decode.d6.loss_dice: 0.2598  decode.d7.loss_cls: 0.1427  decode.d7.loss_mask: 0.2477  decode.d7.loss_dice: 0.2644  decode.d8.loss_cls: 0.1784  decode.d8.loss_mask: 0.2487  decode.d8.loss_dice: 0.2890
08/06 11:58:13 - mmengine - INFO - Iter(train) [ 70200/320000]  base_lr: 8.0020e-05 lr: 8.0020e-06  eta: 1 day, 10:14:44  time: 0.4960  data_time: 0.0112  memory: 5894  grad_norm: 62.5234  loss: 5.4738  decode.loss_cls: 0.0109  decode.loss_mask: 0.2157  decode.loss_dice: 0.2230  decode.d0.loss_cls: 0.8944  decode.d0.loss_mask: 0.2200  decode.d0.loss_dice: 0.2345  decode.d1.loss_cls: 0.0331  decode.d1.loss_mask: 0.2179  decode.d1.loss_dice: 0.2361  decode.d2.loss_cls: 0.0108  decode.d2.loss_mask: 0.2207  decode.d2.loss_dice: 0.2269  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.2173  decode.d3.loss_dice: 0.2298  decode.d4.loss_cls: 0.0136  decode.d4.loss_mask: 0.2173  decode.d4.loss_dice: 0.2261  decode.d5.loss_cls: 0.0122  decode.d5.loss_mask: 0.2186  decode.d5.loss_dice: 0.2245  decode.d6.loss_cls: 0.0127  decode.d6.loss_mask: 0.2143  decode.d6.loss_dice: 0.2195  decode.d7.loss_cls: 0.0110  decode.d7.loss_mask: 0.2181  decode.d7.loss_dice: 0.2307  decode.d8.loss_cls: 0.0105  decode.d8.loss_mask: 0.2184  decode.d8.loss_dice: 0.2267
08/06 11:58:38 - mmengine - INFO - Iter(train) [ 70250/320000]  base_lr: 8.0006e-05 lr: 8.0006e-06  eta: 1 day, 10:14:20  time: 0.4959  data_time: 0.0112  memory: 5911  grad_norm: 40.9488  loss: 5.6989  decode.loss_cls: 0.0429  decode.loss_mask: 0.2018  decode.loss_dice: 0.2575  decode.d0.loss_cls: 0.7979  decode.d0.loss_mask: 0.2008  decode.d0.loss_dice: 0.2551  decode.d1.loss_cls: 0.0384  decode.d1.loss_mask: 0.1991  decode.d1.loss_dice: 0.2333  decode.d2.loss_cls: 0.0550  decode.d2.loss_mask: 0.1993  decode.d2.loss_dice: 0.2461  decode.d3.loss_cls: 0.0378  decode.d3.loss_mask: 0.1983  decode.d3.loss_dice: 0.2459  decode.d4.loss_cls: 0.0574  decode.d4.loss_mask: 0.2004  decode.d4.loss_dice: 0.2500  decode.d5.loss_cls: 0.0417  decode.d5.loss_mask: 0.1966  decode.d5.loss_dice: 0.2383  decode.d6.loss_cls: 0.0730  decode.d6.loss_mask: 0.1983  decode.d6.loss_dice: 0.2532  decode.d7.loss_cls: 0.0500  decode.d7.loss_mask: 0.1980  decode.d7.loss_dice: 0.2506  decode.d8.loss_cls: 0.0375  decode.d8.loss_mask: 0.1970  decode.d8.loss_dice: 0.2478
08/06 11:59:03 - mmengine - INFO - Iter(train) [ 70300/320000]  base_lr: 7.9991e-05 lr: 7.9991e-06  eta: 1 day, 10:13:56  time: 0.4955  data_time: 0.0112  memory: 5894  grad_norm: 79.2389  loss: 7.2797  decode.loss_cls: 0.1275  decode.loss_mask: 0.2781  decode.loss_dice: 0.2464  decode.d0.loss_cls: 0.9675  decode.d0.loss_mask: 0.2884  decode.d0.loss_dice: 0.2696  decode.d1.loss_cls: 0.0862  decode.d1.loss_mask: 0.2799  decode.d1.loss_dice: 0.2658  decode.d2.loss_cls: 0.1044  decode.d2.loss_mask: 0.2796  decode.d2.loss_dice: 0.2549  decode.d3.loss_cls: 0.0911  decode.d3.loss_mask: 0.2778  decode.d3.loss_dice: 0.2485  decode.d4.loss_cls: 0.1053  decode.d4.loss_mask: 0.2787  decode.d4.loss_dice: 0.2566  decode.d5.loss_cls: 0.0912  decode.d5.loss_mask: 0.2741  decode.d5.loss_dice: 0.2622  decode.d6.loss_cls: 0.1449  decode.d6.loss_mask: 0.2747  decode.d6.loss_dice: 0.2505  decode.d7.loss_cls: 0.1221  decode.d7.loss_mask: 0.2741  decode.d7.loss_dice: 0.2446  decode.d8.loss_cls: 0.1144  decode.d8.loss_mask: 0.2735  decode.d8.loss_dice: 0.2473
08/06 11:59:28 - mmengine - INFO - Iter(train) [ 70350/320000]  base_lr: 7.9977e-05 lr: 7.9977e-06  eta: 1 day, 10:13:32  time: 0.4965  data_time: 0.0114  memory: 5894  grad_norm: 74.8069  loss: 6.6366  decode.loss_cls: 0.1155  decode.loss_mask: 0.2504  decode.loss_dice: 0.2271  decode.d0.loss_cls: 0.8479  decode.d0.loss_mask: 0.2483  decode.d0.loss_dice: 0.2366  decode.d1.loss_cls: 0.1453  decode.d1.loss_mask: 0.2481  decode.d1.loss_dice: 0.2350  decode.d2.loss_cls: 0.0865  decode.d2.loss_mask: 0.2500  decode.d2.loss_dice: 0.2384  decode.d3.loss_cls: 0.1125  decode.d3.loss_mask: 0.2459  decode.d3.loss_dice: 0.2249  decode.d4.loss_cls: 0.1069  decode.d4.loss_mask: 0.2444  decode.d4.loss_dice: 0.2238  decode.d5.loss_cls: 0.1093  decode.d5.loss_mask: 0.2455  decode.d5.loss_dice: 0.2404  decode.d6.loss_cls: 0.1274  decode.d6.loss_mask: 0.2468  decode.d6.loss_dice: 0.2233  decode.d7.loss_cls: 0.1145  decode.d7.loss_mask: 0.2478  decode.d7.loss_dice: 0.2163  decode.d8.loss_cls: 0.1090  decode.d8.loss_mask: 0.2461  decode.d8.loss_dice: 0.2226
08/06 11:59:53 - mmengine - INFO - Iter(train) [ 70400/320000]  base_lr: 7.9963e-05 lr: 7.9963e-06  eta: 1 day, 10:13:08  time: 0.4976  data_time: 0.0115  memory: 5894  grad_norm: 175.3912  loss: 6.3939  decode.loss_cls: 0.0793  decode.loss_mask: 0.2263  decode.loss_dice: 0.2587  decode.d0.loss_cls: 0.8017  decode.d0.loss_mask: 0.2423  decode.d0.loss_dice: 0.2762  decode.d1.loss_cls: 0.0956  decode.d1.loss_mask: 0.2299  decode.d1.loss_dice: 0.2613  decode.d2.loss_cls: 0.0705  decode.d2.loss_mask: 0.2245  decode.d2.loss_dice: 0.2424  decode.d3.loss_cls: 0.1306  decode.d3.loss_mask: 0.2254  decode.d3.loss_dice: 0.2488  decode.d4.loss_cls: 0.0839  decode.d4.loss_mask: 0.2256  decode.d4.loss_dice: 0.2575  decode.d5.loss_cls: 0.0713  decode.d5.loss_mask: 0.2257  decode.d5.loss_dice: 0.2418  decode.d6.loss_cls: 0.0721  decode.d6.loss_mask: 0.2258  decode.d6.loss_dice: 0.2585  decode.d7.loss_cls: 0.0680  decode.d7.loss_mask: 0.2281  decode.d7.loss_dice: 0.2596  decode.d8.loss_cls: 0.0734  decode.d8.loss_mask: 0.2270  decode.d8.loss_dice: 0.2620
08/06 12:00:18 - mmengine - INFO - Iter(train) [ 70450/320000]  base_lr: 7.9948e-05 lr: 7.9948e-06  eta: 1 day, 10:12:44  time: 0.4966  data_time: 0.0114  memory: 5894  grad_norm: 395.1240  loss: 8.8766  decode.loss_cls: 0.1924  decode.loss_mask: 0.2143  decode.loss_dice: 0.2800  decode.d0.loss_cls: 1.0515  decode.d0.loss_mask: 0.2217  decode.d0.loss_dice: 0.3476  decode.d1.loss_cls: 0.2976  decode.d1.loss_mask: 0.2180  decode.d1.loss_dice: 0.3615  decode.d2.loss_cls: 0.4559  decode.d2.loss_mask: 0.2163  decode.d2.loss_dice: 0.3298  decode.d3.loss_cls: 0.3124  decode.d3.loss_mask: 0.2133  decode.d3.loss_dice: 0.3187  decode.d4.loss_cls: 0.2973  decode.d4.loss_mask: 0.2159  decode.d4.loss_dice: 0.3584  decode.d5.loss_cls: 0.2446  decode.d5.loss_mask: 0.2153  decode.d5.loss_dice: 0.2956  decode.d6.loss_cls: 0.2002  decode.d6.loss_mask: 0.2152  decode.d6.loss_dice: 0.3220  decode.d7.loss_cls: 0.2258  decode.d7.loss_mask: 0.2140  decode.d7.loss_dice: 0.2621  decode.d8.loss_cls: 0.1986  decode.d8.loss_mask: 0.2182  decode.d8.loss_dice: 0.3622
08/06 12:00:42 - mmengine - INFO - Iter(train) [ 70500/320000]  base_lr: 7.9934e-05 lr: 7.9934e-06  eta: 1 day, 10:12:20  time: 0.4972  data_time: 0.0114  memory: 5913  grad_norm: 74.4393  loss: 6.5161  decode.loss_cls: 0.1206  decode.loss_mask: 0.2140  decode.loss_dice: 0.2398  decode.d0.loss_cls: 0.7790  decode.d0.loss_mask: 0.2143  decode.d0.loss_dice: 0.2558  decode.d1.loss_cls: 0.1274  decode.d1.loss_mask: 0.2141  decode.d1.loss_dice: 0.2500  decode.d2.loss_cls: 0.1193  decode.d2.loss_mask: 0.2147  decode.d2.loss_dice: 0.2455  decode.d3.loss_cls: 0.1663  decode.d3.loss_mask: 0.2125  decode.d3.loss_dice: 0.2394  decode.d4.loss_cls: 0.0964  decode.d4.loss_mask: 0.2117  decode.d4.loss_dice: 0.2445  decode.d5.loss_cls: 0.1020  decode.d5.loss_mask: 0.2144  decode.d5.loss_dice: 0.2447  decode.d6.loss_cls: 0.1264  decode.d6.loss_mask: 0.2160  decode.d6.loss_dice: 0.2543  decode.d7.loss_cls: 0.0900  decode.d7.loss_mask: 0.2137  decode.d7.loss_dice: 0.2511  decode.d8.loss_cls: 0.1447  decode.d8.loss_mask: 0.2148  decode.d8.loss_dice: 0.2786
08/06 12:01:07 - mmengine - INFO - Iter(train) [ 70550/320000]  base_lr: 7.9919e-05 lr: 7.9919e-06  eta: 1 day, 10:11:56  time: 0.4972  data_time: 0.0114  memory: 5911  grad_norm: 76.2087  loss: 6.2141  decode.loss_cls: 0.0371  decode.loss_mask: 0.2369  decode.loss_dice: 0.2669  decode.d0.loss_cls: 0.8357  decode.d0.loss_mask: 0.2398  decode.d0.loss_dice: 0.2646  decode.d1.loss_cls: 0.0447  decode.d1.loss_mask: 0.2403  decode.d1.loss_dice: 0.2791  decode.d2.loss_cls: 0.0285  decode.d2.loss_mask: 0.2359  decode.d2.loss_dice: 0.2681  decode.d3.loss_cls: 0.0243  decode.d3.loss_mask: 0.2389  decode.d3.loss_dice: 0.2732  decode.d4.loss_cls: 0.0230  decode.d4.loss_mask: 0.2413  decode.d4.loss_dice: 0.2701  decode.d5.loss_cls: 0.0200  decode.d5.loss_mask: 0.2412  decode.d5.loss_dice: 0.2639  decode.d6.loss_cls: 0.0424  decode.d6.loss_mask: 0.2385  decode.d6.loss_dice: 0.2682  decode.d7.loss_cls: 0.0403  decode.d7.loss_mask: 0.2405  decode.d7.loss_dice: 0.2718  decode.d8.loss_cls: 0.0333  decode.d8.loss_mask: 0.2393  decode.d8.loss_dice: 0.2664
08/06 12:01:32 - mmengine - INFO - Iter(train) [ 70600/320000]  base_lr: 7.9905e-05 lr: 7.9905e-06  eta: 1 day, 10:11:31  time: 0.4974  data_time: 0.0114  memory: 5894  grad_norm: 62.1646  loss: 6.9981  decode.loss_cls: 0.1278  decode.loss_mask: 0.2176  decode.loss_dice: 0.2739  decode.d0.loss_cls: 0.8192  decode.d0.loss_mask: 0.2190  decode.d0.loss_dice: 0.2939  decode.d1.loss_cls: 0.1306  decode.d1.loss_mask: 0.2176  decode.d1.loss_dice: 0.3099  decode.d2.loss_cls: 0.1244  decode.d2.loss_mask: 0.2191  decode.d2.loss_dice: 0.3081  decode.d3.loss_cls: 0.1172  decode.d3.loss_mask: 0.2169  decode.d3.loss_dice: 0.2888  decode.d4.loss_cls: 0.1227  decode.d4.loss_mask: 0.2151  decode.d4.loss_dice: 0.2896  decode.d5.loss_cls: 0.0956  decode.d5.loss_mask: 0.2151  decode.d5.loss_dice: 0.3130  decode.d6.loss_cls: 0.1152  decode.d6.loss_mask: 0.2172  decode.d6.loss_dice: 0.2779  decode.d7.loss_cls: 0.0960  decode.d7.loss_mask: 0.2166  decode.d7.loss_dice: 0.2967  decode.d8.loss_cls: 0.1297  decode.d8.loss_mask: 0.2159  decode.d8.loss_dice: 0.2981
08/06 12:01:57 - mmengine - INFO - Iter(train) [ 70650/320000]  base_lr: 7.9890e-05 lr: 7.9890e-06  eta: 1 day, 10:11:07  time: 0.4975  data_time: 0.0113  memory: 5896  grad_norm: 89.1064  loss: 5.3921  decode.loss_cls: 0.0220  decode.loss_mask: 0.2140  decode.loss_dice: 0.2133  decode.d0.loss_cls: 0.8065  decode.d0.loss_mask: 0.2199  decode.d0.loss_dice: 0.2244  decode.d1.loss_cls: 0.0554  decode.d1.loss_mask: 0.2186  decode.d1.loss_dice: 0.2157  decode.d2.loss_cls: 0.0360  decode.d2.loss_mask: 0.2151  decode.d2.loss_dice: 0.2194  decode.d3.loss_cls: 0.0340  decode.d3.loss_mask: 0.2156  decode.d3.loss_dice: 0.2180  decode.d4.loss_cls: 0.0226  decode.d4.loss_mask: 0.2166  decode.d4.loss_dice: 0.2204  decode.d5.loss_cls: 0.0173  decode.d5.loss_mask: 0.2165  decode.d5.loss_dice: 0.2202  decode.d6.loss_cls: 0.0113  decode.d6.loss_mask: 0.2131  decode.d6.loss_dice: 0.2204  decode.d7.loss_cls: 0.0152  decode.d7.loss_mask: 0.2160  decode.d7.loss_dice: 0.2200  decode.d8.loss_cls: 0.0196  decode.d8.loss_mask: 0.2168  decode.d8.loss_dice: 0.2182
08/06 12:02:22 - mmengine - INFO - Iter(train) [ 70700/320000]  base_lr: 7.9876e-05 lr: 7.9876e-06  eta: 1 day, 10:10:43  time: 0.4970  data_time: 0.0116  memory: 5891  grad_norm: 93.2116  loss: 5.2511  decode.loss_cls: 0.0142  decode.loss_mask: 0.2124  decode.loss_dice: 0.2089  decode.d0.loss_cls: 0.8974  decode.d0.loss_mask: 0.2057  decode.d0.loss_dice: 0.2051  decode.d1.loss_cls: 0.0349  decode.d1.loss_mask: 0.2172  decode.d1.loss_dice: 0.2040  decode.d2.loss_cls: 0.0270  decode.d2.loss_mask: 0.2149  decode.d2.loss_dice: 0.2061  decode.d3.loss_cls: 0.0177  decode.d3.loss_mask: 0.2113  decode.d3.loss_dice: 0.2078  decode.d4.loss_cls: 0.0166  decode.d4.loss_mask: 0.2119  decode.d4.loss_dice: 0.2079  decode.d5.loss_cls: 0.0155  decode.d5.loss_mask: 0.2173  decode.d5.loss_dice: 0.2063  decode.d6.loss_cls: 0.0143  decode.d6.loss_mask: 0.2111  decode.d6.loss_dice: 0.2064  decode.d7.loss_cls: 0.0173  decode.d7.loss_mask: 0.2074  decode.d7.loss_dice: 0.2004  decode.d8.loss_cls: 0.0155  decode.d8.loss_mask: 0.2133  decode.d8.loss_dice: 0.2050
08/06 12:02:47 - mmengine - INFO - Iter(train) [ 70750/320000]  base_lr: 7.9862e-05 lr: 7.9862e-06  eta: 1 day, 10:10:19  time: 0.4985  data_time: 0.0117  memory: 5895  grad_norm: 215.7480  loss: 5.8664  decode.loss_cls: 0.0366  decode.loss_mask: 0.2050  decode.loss_dice: 0.2440  decode.d0.loss_cls: 0.8793  decode.d0.loss_mask: 0.2104  decode.d0.loss_dice: 0.2424  decode.d1.loss_cls: 0.1037  decode.d1.loss_mask: 0.2085  decode.d1.loss_dice: 0.2438  decode.d2.loss_cls: 0.0841  decode.d2.loss_mask: 0.2088  decode.d2.loss_dice: 0.2473  decode.d3.loss_cls: 0.0468  decode.d3.loss_mask: 0.2061  decode.d3.loss_dice: 0.2471  decode.d4.loss_cls: 0.0535  decode.d4.loss_mask: 0.2082  decode.d4.loss_dice: 0.2466  decode.d5.loss_cls: 0.0395  decode.d5.loss_mask: 0.2075  decode.d5.loss_dice: 0.2437  decode.d6.loss_cls: 0.0355  decode.d6.loss_mask: 0.2064  decode.d6.loss_dice: 0.2377  decode.d7.loss_cls: 0.0321  decode.d7.loss_mask: 0.2063  decode.d7.loss_dice: 0.2448  decode.d8.loss_cls: 0.0446  decode.d8.loss_mask: 0.2058  decode.d8.loss_dice: 0.2403
08/06 12:03:12 - mmengine - INFO - Iter(train) [ 70800/320000]  base_lr: 7.9847e-05 lr: 7.9847e-06  eta: 1 day, 10:09:56  time: 0.4975  data_time: 0.0117  memory: 5911  grad_norm: 656.0649  loss: 9.7380  decode.loss_cls: 0.3248  decode.loss_mask: 0.2627  decode.loss_dice: 0.3117  decode.d0.loss_cls: 1.0440  decode.d0.loss_mask: 0.2946  decode.d0.loss_dice: 0.3497  decode.d1.loss_cls: 0.3040  decode.d1.loss_mask: 0.3367  decode.d1.loss_dice: 0.3070  decode.d2.loss_cls: 0.2111  decode.d2.loss_mask: 0.3395  decode.d2.loss_dice: 0.3245  decode.d3.loss_cls: 0.1783  decode.d3.loss_mask: 0.3297  decode.d3.loss_dice: 0.3050  decode.d4.loss_cls: 0.1863  decode.d4.loss_mask: 0.3411  decode.d4.loss_dice: 0.3391  decode.d5.loss_cls: 0.2322  decode.d5.loss_mask: 0.3421  decode.d5.loss_dice: 0.3413  decode.d6.loss_cls: 0.2372  decode.d6.loss_mask: 0.3762  decode.d6.loss_dice: 0.3344  decode.d7.loss_cls: 0.2385  decode.d7.loss_mask: 0.3283  decode.d7.loss_dice: 0.3048  decode.d8.loss_cls: 0.2541  decode.d8.loss_mask: 0.3270  decode.d8.loss_dice: 0.3319
08/06 12:03:37 - mmengine - INFO - Iter(train) [ 70850/320000]  base_lr: 7.9833e-05 lr: 7.9833e-06  eta: 1 day, 10:09:32  time: 0.4971  data_time: 0.0113  memory: 5895  grad_norm: 75.8996  loss: 6.5870  decode.loss_cls: 0.0448  decode.loss_mask: 0.2512  decode.loss_dice: 0.2780  decode.d0.loss_cls: 0.7591  decode.d0.loss_mask: 0.2533  decode.d0.loss_dice: 0.2733  decode.d1.loss_cls: 0.0787  decode.d1.loss_mask: 0.2517  decode.d1.loss_dice: 0.2992  decode.d2.loss_cls: 0.0853  decode.d2.loss_mask: 0.2511  decode.d2.loss_dice: 0.2698  decode.d3.loss_cls: 0.0745  decode.d3.loss_mask: 0.2546  decode.d3.loss_dice: 0.2449  decode.d4.loss_cls: 0.0657  decode.d4.loss_mask: 0.2501  decode.d4.loss_dice: 0.2636  decode.d5.loss_cls: 0.0645  decode.d5.loss_mask: 0.2488  decode.d5.loss_dice: 0.2734  decode.d6.loss_cls: 0.0687  decode.d6.loss_mask: 0.2524  decode.d6.loss_dice: 0.2945  decode.d7.loss_cls: 0.0665  decode.d7.loss_mask: 0.2503  decode.d7.loss_dice: 0.2536  decode.d8.loss_cls: 0.0553  decode.d8.loss_mask: 0.2492  decode.d8.loss_dice: 0.2609
08/06 12:04:02 - mmengine - INFO - Iter(train) [ 70900/320000]  base_lr: 7.9818e-05 lr: 7.9818e-06  eta: 1 day, 10:09:08  time: 0.4983  data_time: 0.0116  memory: 5895  grad_norm: 170.4339  loss: 6.6115  decode.loss_cls: 0.0806  decode.loss_mask: 0.2082  decode.loss_dice: 0.2838  decode.d0.loss_cls: 0.9443  decode.d0.loss_mask: 0.2148  decode.d0.loss_dice: 0.2553  decode.d1.loss_cls: 0.1068  decode.d1.loss_mask: 0.2092  decode.d1.loss_dice: 0.2838  decode.d2.loss_cls: 0.0769  decode.d2.loss_mask: 0.2118  decode.d2.loss_dice: 0.2805  decode.d3.loss_cls: 0.1335  decode.d3.loss_mask: 0.2124  decode.d3.loss_dice: 0.2944  decode.d4.loss_cls: 0.1226  decode.d4.loss_mask: 0.2080  decode.d4.loss_dice: 0.2678  decode.d5.loss_cls: 0.0762  decode.d5.loss_mask: 0.2098  decode.d5.loss_dice: 0.2690  decode.d6.loss_cls: 0.0638  decode.d6.loss_mask: 0.2071  decode.d6.loss_dice: 0.2737  decode.d7.loss_cls: 0.0830  decode.d7.loss_mask: 0.2106  decode.d7.loss_dice: 0.2770  decode.d8.loss_cls: 0.0799  decode.d8.loss_mask: 0.2092  decode.d8.loss_dice: 0.2576
08/06 12:04:27 - mmengine - INFO - Iter(train) [ 70950/320000]  base_lr: 7.9804e-05 lr: 7.9804e-06  eta: 1 day, 10:08:44  time: 0.4976  data_time: 0.0114  memory: 5894  grad_norm: 122.6144  loss: 8.0909  decode.loss_cls: 0.1469  decode.loss_mask: 0.2828  decode.loss_dice: 0.2513  decode.d0.loss_cls: 0.9618  decode.d0.loss_mask: 0.2862  decode.d0.loss_dice: 0.2647  decode.d1.loss_cls: 0.2363  decode.d1.loss_mask: 0.2886  decode.d1.loss_dice: 0.2724  decode.d2.loss_cls: 0.1766  decode.d2.loss_mask: 0.2819  decode.d2.loss_dice: 0.2701  decode.d3.loss_cls: 0.1816  decode.d3.loss_mask: 0.2796  decode.d3.loss_dice: 0.2839  decode.d4.loss_cls: 0.1540  decode.d4.loss_mask: 0.2862  decode.d4.loss_dice: 0.2842  decode.d5.loss_cls: 0.1453  decode.d5.loss_mask: 0.2817  decode.d5.loss_dice: 0.2767  decode.d6.loss_cls: 0.1624  decode.d6.loss_mask: 0.2838  decode.d6.loss_dice: 0.2858  decode.d7.loss_cls: 0.1675  decode.d7.loss_mask: 0.2832  decode.d7.loss_dice: 0.2618  decode.d8.loss_cls: 0.1774  decode.d8.loss_mask: 0.2815  decode.d8.loss_dice: 0.2951
08/06 12:04:51 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 12:04:51 - mmengine - INFO - Iter(train) [ 71000/320000]  base_lr: 7.9789e-05 lr: 7.9789e-06  eta: 1 day, 10:08:20  time: 0.4983  data_time: 0.0115  memory: 5913  grad_norm: 72.4194  loss: 6.8664  decode.loss_cls: 0.1039  decode.loss_mask: 0.2810  decode.loss_dice: 0.2493  decode.d0.loss_cls: 0.9726  decode.d0.loss_mask: 0.2275  decode.d0.loss_dice: 0.2334  decode.d1.loss_cls: 0.1576  decode.d1.loss_mask: 0.2358  decode.d1.loss_dice: 0.2270  decode.d2.loss_cls: 0.1517  decode.d2.loss_mask: 0.2304  decode.d2.loss_dice: 0.2216  decode.d3.loss_cls: 0.1323  decode.d3.loss_mask: 0.2517  decode.d3.loss_dice: 0.2392  decode.d4.loss_cls: 0.1465  decode.d4.loss_mask: 0.2361  decode.d4.loss_dice: 0.2164  decode.d5.loss_cls: 0.1428  decode.d5.loss_mask: 0.2348  decode.d5.loss_dice: 0.2314  decode.d6.loss_cls: 0.1048  decode.d6.loss_mask: 0.2362  decode.d6.loss_dice: 0.2271  decode.d7.loss_cls: 0.1260  decode.d7.loss_mask: 0.2322  decode.d7.loss_dice: 0.2162  decode.d8.loss_cls: 0.0977  decode.d8.loss_mask: 0.2437  decode.d8.loss_dice: 0.2596
08/06 12:05:16 - mmengine - INFO - Iter(train) [ 71050/320000]  base_lr: 7.9775e-05 lr: 7.9775e-06  eta: 1 day, 10:07:56  time: 0.4971  data_time: 0.0111  memory: 5895  grad_norm: 42.3337  loss: 6.0910  decode.loss_cls: 0.1188  decode.loss_mask: 0.2007  decode.loss_dice: 0.2159  decode.d0.loss_cls: 0.7567  decode.d0.loss_mask: 0.1997  decode.d0.loss_dice: 0.2173  decode.d1.loss_cls: 0.1251  decode.d1.loss_mask: 0.1954  decode.d1.loss_dice: 0.2148  decode.d2.loss_cls: 0.1412  decode.d2.loss_mask: 0.1998  decode.d2.loss_dice: 0.2244  decode.d3.loss_cls: 0.1306  decode.d3.loss_mask: 0.1968  decode.d3.loss_dice: 0.2102  decode.d4.loss_cls: 0.1315  decode.d4.loss_mask: 0.2011  decode.d4.loss_dice: 0.2152  decode.d5.loss_cls: 0.1373  decode.d5.loss_mask: 0.2001  decode.d5.loss_dice: 0.2141  decode.d6.loss_cls: 0.1417  decode.d6.loss_mask: 0.1972  decode.d6.loss_dice: 0.2131  decode.d7.loss_cls: 0.1390  decode.d7.loss_mask: 0.2001  decode.d7.loss_dice: 0.2187  decode.d8.loss_cls: 0.1208  decode.d8.loss_mask: 0.1986  decode.d8.loss_dice: 0.2151
08/06 12:05:41 - mmengine - INFO - Iter(train) [ 71100/320000]  base_lr: 7.9761e-05 lr: 7.9761e-06  eta: 1 day, 10:07:33  time: 0.4984  data_time: 0.0116  memory: 5928  grad_norm: 73.4406  loss: 6.3950  decode.loss_cls: 0.0586  decode.loss_mask: 0.2156  decode.loss_dice: 0.2649  decode.d0.loss_cls: 0.8063  decode.d0.loss_mask: 0.2183  decode.d0.loss_dice: 0.2644  decode.d1.loss_cls: 0.1023  decode.d1.loss_mask: 0.2150  decode.d1.loss_dice: 0.2531  decode.d2.loss_cls: 0.0992  decode.d2.loss_mask: 0.2144  decode.d2.loss_dice: 0.2517  decode.d3.loss_cls: 0.1321  decode.d3.loss_mask: 0.2141  decode.d3.loss_dice: 0.2597  decode.d4.loss_cls: 0.0933  decode.d4.loss_mask: 0.2169  decode.d4.loss_dice: 0.2615  decode.d5.loss_cls: 0.1298  decode.d5.loss_mask: 0.2156  decode.d5.loss_dice: 0.2517  decode.d6.loss_cls: 0.0982  decode.d6.loss_mask: 0.2150  decode.d6.loss_dice: 0.2494  decode.d7.loss_cls: 0.0959  decode.d7.loss_mask: 0.2132  decode.d7.loss_dice: 0.2487  decode.d8.loss_cls: 0.0701  decode.d8.loss_mask: 0.2144  decode.d8.loss_dice: 0.2517
08/06 12:06:06 - mmengine - INFO - Iter(train) [ 71150/320000]  base_lr: 7.9746e-05 lr: 7.9746e-06  eta: 1 day, 10:07:09  time: 0.4982  data_time: 0.0114  memory: 5928  grad_norm: 192.4207  loss: 7.7485  decode.loss_cls: 0.0978  decode.loss_mask: 0.3030  decode.loss_dice: 0.2579  decode.d0.loss_cls: 0.9050  decode.d0.loss_mask: 0.3320  decode.d0.loss_dice: 0.2548  decode.d1.loss_cls: 0.1088  decode.d1.loss_mask: 0.3306  decode.d1.loss_dice: 0.2849  decode.d2.loss_cls: 0.0560  decode.d2.loss_mask: 0.3312  decode.d2.loss_dice: 0.2997  decode.d3.loss_cls: 0.1500  decode.d3.loss_mask: 0.3274  decode.d3.loss_dice: 0.2554  decode.d4.loss_cls: 0.0798  decode.d4.loss_mask: 0.3276  decode.d4.loss_dice: 0.2838  decode.d5.loss_cls: 0.1208  decode.d5.loss_mask: 0.3085  decode.d5.loss_dice: 0.2601  decode.d6.loss_cls: 0.1356  decode.d6.loss_mask: 0.3100  decode.d6.loss_dice: 0.2664  decode.d7.loss_cls: 0.0761  decode.d7.loss_mask: 0.3191  decode.d7.loss_dice: 0.2817  decode.d8.loss_cls: 0.1089  decode.d8.loss_mask: 0.3200  decode.d8.loss_dice: 0.2556
08/06 12:06:31 - mmengine - INFO - Iter(train) [ 71200/320000]  base_lr: 7.9732e-05 lr: 7.9732e-06  eta: 1 day, 10:06:45  time: 0.4992  data_time: 0.0113  memory: 5911  grad_norm: 142.8271  loss: 9.2578  decode.loss_cls: 0.2234  decode.loss_mask: 0.2854  decode.loss_dice: 0.3292  decode.d0.loss_cls: 0.9974  decode.d0.loss_mask: 0.2594  decode.d0.loss_dice: 0.2958  decode.d1.loss_cls: 0.1564  decode.d1.loss_mask: 0.2726  decode.d1.loss_dice: 0.3223  decode.d2.loss_cls: 0.1723  decode.d2.loss_mask: 0.2685  decode.d2.loss_dice: 0.3221  decode.d3.loss_cls: 0.1264  decode.d3.loss_mask: 0.4613  decode.d3.loss_dice: 0.3374  decode.d4.loss_cls: 0.1108  decode.d4.loss_mask: 0.4736  decode.d4.loss_dice: 0.3581  decode.d5.loss_cls: 0.1559  decode.d5.loss_mask: 0.3634  decode.d5.loss_dice: 0.3632  decode.d6.loss_cls: 0.1593  decode.d6.loss_mask: 0.3759  decode.d6.loss_dice: 0.3585  decode.d7.loss_cls: 0.1229  decode.d7.loss_mask: 0.3694  decode.d7.loss_dice: 0.3586  decode.d8.loss_cls: 0.1348  decode.d8.loss_mask: 0.3759  decode.d8.loss_dice: 0.3477
08/06 12:06:56 - mmengine - INFO - Iter(train) [ 71250/320000]  base_lr: 7.9717e-05 lr: 7.9717e-06  eta: 1 day, 10:06:21  time: 0.4977  data_time: 0.0112  memory: 5891  grad_norm: 74.7729  loss: 6.7041  decode.loss_cls: 0.1084  decode.loss_mask: 0.2512  decode.loss_dice: 0.2549  decode.d0.loss_cls: 0.7906  decode.d0.loss_mask: 0.2376  decode.d0.loss_dice: 0.2510  decode.d1.loss_cls: 0.0892  decode.d1.loss_mask: 0.2530  decode.d1.loss_dice: 0.2564  decode.d2.loss_cls: 0.1128  decode.d2.loss_mask: 0.2509  decode.d2.loss_dice: 0.2700  decode.d3.loss_cls: 0.0919  decode.d3.loss_mask: 0.2420  decode.d3.loss_dice: 0.2490  decode.d4.loss_cls: 0.1317  decode.d4.loss_mask: 0.2518  decode.d4.loss_dice: 0.2475  decode.d5.loss_cls: 0.1132  decode.d5.loss_mask: 0.2534  decode.d5.loss_dice: 0.2510  decode.d6.loss_cls: 0.0864  decode.d6.loss_mask: 0.2511  decode.d6.loss_dice: 0.2485  decode.d7.loss_cls: 0.0827  decode.d7.loss_mask: 0.2535  decode.d7.loss_dice: 0.2527  decode.d8.loss_cls: 0.0802  decode.d8.loss_mask: 0.2522  decode.d8.loss_dice: 0.2393
08/06 12:07:21 - mmengine - INFO - Iter(train) [ 71300/320000]  base_lr: 7.9703e-05 lr: 7.9703e-06  eta: 1 day, 10:05:58  time: 0.5003  data_time: 0.0112  memory: 5911  grad_norm: 169.7467  loss: 8.1883  decode.loss_cls: 0.1197  decode.loss_mask: 0.3076  decode.loss_dice: 0.2977  decode.d0.loss_cls: 0.9106  decode.d0.loss_mask: 0.3072  decode.d0.loss_dice: 0.2975  decode.d1.loss_cls: 0.1678  decode.d1.loss_mask: 0.3057  decode.d1.loss_dice: 0.2957  decode.d2.loss_cls: 0.1153  decode.d2.loss_mask: 0.2993  decode.d2.loss_dice: 0.2718  decode.d3.loss_cls: 0.1201  decode.d3.loss_mask: 0.2991  decode.d3.loss_dice: 0.2920  decode.d4.loss_cls: 0.1945  decode.d4.loss_mask: 0.2999  decode.d4.loss_dice: 0.3017  decode.d5.loss_cls: 0.2158  decode.d5.loss_mask: 0.3027  decode.d5.loss_dice: 0.3003  decode.d6.loss_cls: 0.1219  decode.d6.loss_mask: 0.3030  decode.d6.loss_dice: 0.2840  decode.d7.loss_cls: 0.1354  decode.d7.loss_mask: 0.3076  decode.d7.loss_dice: 0.2941  decode.d8.loss_cls: 0.1398  decode.d8.loss_mask: 0.3013  decode.d8.loss_dice: 0.2792
08/06 12:07:46 - mmengine - INFO - Iter(train) [ 71350/320000]  base_lr: 7.9689e-05 lr: 7.9689e-06  eta: 1 day, 10:05:34  time: 0.4976  data_time: 0.0114  memory: 5894  grad_norm: 66.8196  loss: 6.6520  decode.loss_cls: 0.1131  decode.loss_mask: 0.1756  decode.loss_dice: 0.2833  decode.d0.loss_cls: 0.9408  decode.d0.loss_mask: 0.1769  decode.d0.loss_dice: 0.2807  decode.d1.loss_cls: 0.1889  decode.d1.loss_mask: 0.1773  decode.d1.loss_dice: 0.2856  decode.d2.loss_cls: 0.1251  decode.d2.loss_mask: 0.1810  decode.d2.loss_dice: 0.2990  decode.d3.loss_cls: 0.0812  decode.d3.loss_mask: 0.1810  decode.d3.loss_dice: 0.2972  decode.d4.loss_cls: 0.0765  decode.d4.loss_mask: 0.1786  decode.d4.loss_dice: 0.2848  decode.d5.loss_cls: 0.1010  decode.d5.loss_mask: 0.1792  decode.d5.loss_dice: 0.2820  decode.d6.loss_cls: 0.0949  decode.d6.loss_mask: 0.1740  decode.d6.loss_dice: 0.2812  decode.d7.loss_cls: 0.1129  decode.d7.loss_mask: 0.1762  decode.d7.loss_dice: 0.2988  decode.d8.loss_cls: 0.1299  decode.d8.loss_mask: 0.1762  decode.d8.loss_dice: 0.3190
08/06 12:08:11 - mmengine - INFO - Iter(train) [ 71400/320000]  base_lr: 7.9674e-05 lr: 7.9674e-06  eta: 1 day, 10:05:10  time: 0.4996  data_time: 0.0113  memory: 5874  grad_norm: 62.8585  loss: 5.7460  decode.loss_cls: 0.0325  decode.loss_mask: 0.2204  decode.loss_dice: 0.2526  decode.d0.loss_cls: 0.7239  decode.d0.loss_mask: 0.2195  decode.d0.loss_dice: 0.2512  decode.d1.loss_cls: 0.0464  decode.d1.loss_mask: 0.2202  decode.d1.loss_dice: 0.2624  decode.d2.loss_cls: 0.0151  decode.d2.loss_mask: 0.2195  decode.d2.loss_dice: 0.2687  decode.d3.loss_cls: 0.0155  decode.d3.loss_mask: 0.2204  decode.d3.loss_dice: 0.2596  decode.d4.loss_cls: 0.0153  decode.d4.loss_mask: 0.2224  decode.d4.loss_dice: 0.2689  decode.d5.loss_cls: 0.0158  decode.d5.loss_mask: 0.2198  decode.d5.loss_dice: 0.2510  decode.d6.loss_cls: 0.0243  decode.d6.loss_mask: 0.2195  decode.d6.loss_dice: 0.2670  decode.d7.loss_cls: 0.0357  decode.d7.loss_mask: 0.2201  decode.d7.loss_dice: 0.2689  decode.d8.loss_cls: 0.0226  decode.d8.loss_mask: 0.2157  decode.d8.loss_dice: 0.2512
08/06 12:08:36 - mmengine - INFO - Iter(train) [ 71450/320000]  base_lr: 7.9660e-05 lr: 7.9660e-06  eta: 1 day, 10:04:47  time: 0.5012  data_time: 0.0117  memory: 5913  grad_norm: 68.6930  loss: 6.9937  decode.loss_cls: 0.1465  decode.loss_mask: 0.2368  decode.loss_dice: 0.2371  decode.d0.loss_cls: 0.9392  decode.d0.loss_mask: 0.2435  decode.d0.loss_dice: 0.2316  decode.d1.loss_cls: 0.1042  decode.d1.loss_mask: 0.2381  decode.d1.loss_dice: 0.2451  decode.d2.loss_cls: 0.1288  decode.d2.loss_mask: 0.2408  decode.d2.loss_dice: 0.2435  decode.d3.loss_cls: 0.1085  decode.d3.loss_mask: 0.2379  decode.d3.loss_dice: 0.2521  decode.d4.loss_cls: 0.1338  decode.d4.loss_mask: 0.2393  decode.d4.loss_dice: 0.2369  decode.d5.loss_cls: 0.1308  decode.d5.loss_mask: 0.2412  decode.d5.loss_dice: 0.2613  decode.d6.loss_cls: 0.1321  decode.d6.loss_mask: 0.2391  decode.d6.loss_dice: 0.2722  decode.d7.loss_cls: 0.0845  decode.d7.loss_mask: 0.2417  decode.d7.loss_dice: 0.2608  decode.d8.loss_cls: 0.1627  decode.d8.loss_mask: 0.2403  decode.d8.loss_dice: 0.2831
08/06 12:09:01 - mmengine - INFO - Iter(train) [ 71500/320000]  base_lr: 7.9645e-05 lr: 7.9645e-06  eta: 1 day, 10:04:23  time: 0.4979  data_time: 0.0112  memory: 5891  grad_norm: 133.8592  loss: 7.5193  decode.loss_cls: 0.1394  decode.loss_mask: 0.2656  decode.loss_dice: 0.2440  decode.d0.loss_cls: 0.8915  decode.d0.loss_mask: 0.2797  decode.d0.loss_dice: 0.2680  decode.d1.loss_cls: 0.1073  decode.d1.loss_mask: 0.2801  decode.d1.loss_dice: 0.2614  decode.d2.loss_cls: 0.1371  decode.d2.loss_mask: 0.2716  decode.d2.loss_dice: 0.2608  decode.d3.loss_cls: 0.1342  decode.d3.loss_mask: 0.2718  decode.d3.loss_dice: 0.2929  decode.d4.loss_cls: 0.1515  decode.d4.loss_mask: 0.2684  decode.d4.loss_dice: 0.2681  decode.d5.loss_cls: 0.1475  decode.d5.loss_mask: 0.2689  decode.d5.loss_dice: 0.2547  decode.d6.loss_cls: 0.1895  decode.d6.loss_mask: 0.2698  decode.d6.loss_dice: 0.2501  decode.d7.loss_cls: 0.1163  decode.d7.loss_mask: 0.2700  decode.d7.loss_dice: 0.2465  decode.d8.loss_cls: 0.1613  decode.d8.loss_mask: 0.2733  decode.d8.loss_dice: 0.2779
08/06 12:09:26 - mmengine - INFO - Iter(train) [ 71550/320000]  base_lr: 7.9631e-05 lr: 7.9631e-06  eta: 1 day, 10:03:59  time: 0.4991  data_time: 0.0113  memory: 5911  grad_norm: 111.8978  loss: 6.5687  decode.loss_cls: 0.0573  decode.loss_mask: 0.2368  decode.loss_dice: 0.2725  decode.d0.loss_cls: 0.7810  decode.d0.loss_mask: 0.2433  decode.d0.loss_dice: 0.2876  decode.d1.loss_cls: 0.0885  decode.d1.loss_mask: 0.2396  decode.d1.loss_dice: 0.2842  decode.d2.loss_cls: 0.0643  decode.d2.loss_mask: 0.2423  decode.d2.loss_dice: 0.2777  decode.d3.loss_cls: 0.0615  decode.d3.loss_mask: 0.2388  decode.d3.loss_dice: 0.2780  decode.d4.loss_cls: 0.0920  decode.d4.loss_mask: 0.2404  decode.d4.loss_dice: 0.2836  decode.d5.loss_cls: 0.0259  decode.d5.loss_mask: 0.2389  decode.d5.loss_dice: 0.2730  decode.d6.loss_cls: 0.0610  decode.d6.loss_mask: 0.2365  decode.d6.loss_dice: 0.2776  decode.d7.loss_cls: 0.0694  decode.d7.loss_mask: 0.2415  decode.d7.loss_dice: 0.2838  decode.d8.loss_cls: 0.0702  decode.d8.loss_mask: 0.2368  decode.d8.loss_dice: 0.2848
08/06 12:09:51 - mmengine - INFO - Iter(train) [ 71600/320000]  base_lr: 7.9616e-05 lr: 7.9616e-06  eta: 1 day, 10:03:36  time: 0.5005  data_time: 0.0116  memory: 5911  grad_norm: 144.6711  loss: 5.8806  decode.loss_cls: 0.0831  decode.loss_mask: 0.1974  decode.loss_dice: 0.2375  decode.d0.loss_cls: 0.8745  decode.d0.loss_mask: 0.2006  decode.d0.loss_dice: 0.2316  decode.d1.loss_cls: 0.0602  decode.d1.loss_mask: 0.2068  decode.d1.loss_dice: 0.2448  decode.d2.loss_cls: 0.0474  decode.d2.loss_mask: 0.2013  decode.d2.loss_dice: 0.2363  decode.d3.loss_cls: 0.0742  decode.d3.loss_mask: 0.2027  decode.d3.loss_dice: 0.2383  decode.d4.loss_cls: 0.0597  decode.d4.loss_mask: 0.1980  decode.d4.loss_dice: 0.2311  decode.d5.loss_cls: 0.1020  decode.d5.loss_mask: 0.1978  decode.d5.loss_dice: 0.2332  decode.d6.loss_cls: 0.0739  decode.d6.loss_mask: 0.2010  decode.d6.loss_dice: 0.2329  decode.d7.loss_cls: 0.0738  decode.d7.loss_mask: 0.2010  decode.d7.loss_dice: 0.2305  decode.d8.loss_cls: 0.0795  decode.d8.loss_mask: 0.2004  decode.d8.loss_dice: 0.2292
08/06 12:10:16 - mmengine - INFO - Iter(train) [ 71650/320000]  base_lr: 7.9602e-05 lr: 7.9602e-06  eta: 1 day, 10:03:13  time: 0.5003  data_time: 0.0111  memory: 5930  grad_norm: 62.4773  loss: 7.0820  decode.loss_cls: 0.0778  decode.loss_mask: 0.2889  decode.loss_dice: 0.2798  decode.d0.loss_cls: 0.8396  decode.d0.loss_mask: 0.2942  decode.d0.loss_dice: 0.2846  decode.d1.loss_cls: 0.0514  decode.d1.loss_mask: 0.2896  decode.d1.loss_dice: 0.2912  decode.d2.loss_cls: 0.0474  decode.d2.loss_mask: 0.2863  decode.d2.loss_dice: 0.2900  decode.d3.loss_cls: 0.0516  decode.d3.loss_mask: 0.2857  decode.d3.loss_dice: 0.2805  decode.d4.loss_cls: 0.0677  decode.d4.loss_mask: 0.2929  decode.d4.loss_dice: 0.2883  decode.d5.loss_cls: 0.0606  decode.d5.loss_mask: 0.2853  decode.d5.loss_dice: 0.2676  decode.d6.loss_cls: 0.0473  decode.d6.loss_mask: 0.2891  decode.d6.loss_dice: 0.2786  decode.d7.loss_cls: 0.0631  decode.d7.loss_mask: 0.2837  decode.d7.loss_dice: 0.2803  decode.d8.loss_cls: 0.0627  decode.d8.loss_mask: 0.2893  decode.d8.loss_dice: 0.2870
08/06 12:10:41 - mmengine - INFO - Iter(train) [ 71700/320000]  base_lr: 7.9588e-05 lr: 7.9588e-06  eta: 1 day, 10:02:49  time: 0.4994  data_time: 0.0116  memory: 5909  grad_norm: 72.4237  loss: 6.8905  decode.loss_cls: 0.0300  decode.loss_mask: 0.2816  decode.loss_dice: 0.2933  decode.d0.loss_cls: 0.6993  decode.d0.loss_mask: 0.2899  decode.d0.loss_dice: 0.2867  decode.d1.loss_cls: 0.0880  decode.d1.loss_mask: 0.2831  decode.d1.loss_dice: 0.2961  decode.d2.loss_cls: 0.0622  decode.d2.loss_mask: 0.2760  decode.d2.loss_dice: 0.2874  decode.d3.loss_cls: 0.0299  decode.d3.loss_mask: 0.2841  decode.d3.loss_dice: 0.2860  decode.d4.loss_cls: 0.0264  decode.d4.loss_mask: 0.2849  decode.d4.loss_dice: 0.2977  decode.d5.loss_cls: 0.0871  decode.d5.loss_mask: 0.2788  decode.d5.loss_dice: 0.2551  decode.d6.loss_cls: 0.0813  decode.d6.loss_mask: 0.2771  decode.d6.loss_dice: 0.2775  decode.d7.loss_cls: 0.0646  decode.d7.loss_mask: 0.2784  decode.d7.loss_dice: 0.2809  decode.d8.loss_cls: 0.0580  decode.d8.loss_mask: 0.2786  decode.d8.loss_dice: 0.2902
08/06 12:11:06 - mmengine - INFO - Iter(train) [ 71750/320000]  base_lr: 7.9573e-05 lr: 7.9573e-06  eta: 1 day, 10:02:26  time: 0.5002  data_time: 0.0114  memory: 5928  grad_norm: 128.1977  loss: 7.0596  decode.loss_cls: 0.1710  decode.loss_mask: 0.2148  decode.loss_dice: 0.2694  decode.d0.loss_cls: 0.9437  decode.d0.loss_mask: 0.2108  decode.d0.loss_dice: 0.2587  decode.d1.loss_cls: 0.2012  decode.d1.loss_mask: 0.2149  decode.d1.loss_dice: 0.2476  decode.d2.loss_cls: 0.1529  decode.d2.loss_mask: 0.2164  decode.d2.loss_dice: 0.2688  decode.d3.loss_cls: 0.1604  decode.d3.loss_mask: 0.2121  decode.d3.loss_dice: 0.2652  decode.d4.loss_cls: 0.1612  decode.d4.loss_mask: 0.2134  decode.d4.loss_dice: 0.2442  decode.d5.loss_cls: 0.1439  decode.d5.loss_mask: 0.2129  decode.d5.loss_dice: 0.2456  decode.d6.loss_cls: 0.1540  decode.d6.loss_mask: 0.2125  decode.d6.loss_dice: 0.2488  decode.d7.loss_cls: 0.1442  decode.d7.loss_mask: 0.2131  decode.d7.loss_dice: 0.2466  decode.d8.loss_cls: 0.1457  decode.d8.loss_mask: 0.2141  decode.d8.loss_dice: 0.2515
08/06 12:11:31 - mmengine - INFO - Iter(train) [ 71800/320000]  base_lr: 7.9559e-05 lr: 7.9559e-06  eta: 1 day, 10:02:02  time: 0.4960  data_time: 0.0112  memory: 5911  grad_norm: 52.6093  loss: 6.9313  decode.loss_cls: 0.0678  decode.loss_mask: 0.2374  decode.loss_dice: 0.2929  decode.d0.loss_cls: 0.8532  decode.d0.loss_mask: 0.2406  decode.d0.loss_dice: 0.2984  decode.d1.loss_cls: 0.1026  decode.d1.loss_mask: 0.2378  decode.d1.loss_dice: 0.3000  decode.d2.loss_cls: 0.0970  decode.d2.loss_mask: 0.2371  decode.d2.loss_dice: 0.3040  decode.d3.loss_cls: 0.0877  decode.d3.loss_mask: 0.2373  decode.d3.loss_dice: 0.2961  decode.d4.loss_cls: 0.0838  decode.d4.loss_mask: 0.2343  decode.d4.loss_dice: 0.2802  decode.d5.loss_cls: 0.0856  decode.d5.loss_mask: 0.2377  decode.d5.loss_dice: 0.2879  decode.d6.loss_cls: 0.0665  decode.d6.loss_mask: 0.2354  decode.d6.loss_dice: 0.2714  decode.d7.loss_cls: 0.1049  decode.d7.loss_mask: 0.2350  decode.d7.loss_dice: 0.2880  decode.d8.loss_cls: 0.0842  decode.d8.loss_mask: 0.2401  decode.d8.loss_dice: 0.3065
08/06 12:11:56 - mmengine - INFO - Iter(train) [ 71850/320000]  base_lr: 7.9544e-05 lr: 7.9544e-06  eta: 1 day, 10:01:38  time: 0.4983  data_time: 0.0113  memory: 5874  grad_norm: 93.5518  loss: 6.2501  decode.loss_cls: 0.0507  decode.loss_mask: 0.2454  decode.loss_dice: 0.2593  decode.d0.loss_cls: 0.7593  decode.d0.loss_mask: 0.2730  decode.d0.loss_dice: 0.2886  decode.d1.loss_cls: 0.0527  decode.d1.loss_mask: 0.2511  decode.d1.loss_dice: 0.2692  decode.d2.loss_cls: 0.0179  decode.d2.loss_mask: 0.2429  decode.d2.loss_dice: 0.2661  decode.d3.loss_cls: 0.0583  decode.d3.loss_mask: 0.2472  decode.d3.loss_dice: 0.2461  decode.d4.loss_cls: 0.0245  decode.d4.loss_mask: 0.2457  decode.d4.loss_dice: 0.2631  decode.d5.loss_cls: 0.0572  decode.d5.loss_mask: 0.2460  decode.d5.loss_dice: 0.2487  decode.d6.loss_cls: 0.0495  decode.d6.loss_mask: 0.2456  decode.d6.loss_dice: 0.2516  decode.d7.loss_cls: 0.0594  decode.d7.loss_mask: 0.2449  decode.d7.loss_dice: 0.2564  decode.d8.loss_cls: 0.0265  decode.d8.loss_mask: 0.2445  decode.d8.loss_dice: 0.2585
08/06 12:12:21 - mmengine - INFO - Iter(train) [ 71900/320000]  base_lr: 7.9530e-05 lr: 7.9530e-06  eta: 1 day, 10:01:14  time: 0.4972  data_time: 0.0112  memory: 5874  grad_norm: 122.5136  loss: 5.9718  decode.loss_cls: 0.0207  decode.loss_mask: 0.2308  decode.loss_dice: 0.2499  decode.d0.loss_cls: 0.8268  decode.d0.loss_mask: 0.2166  decode.d0.loss_dice: 0.2420  decode.d1.loss_cls: 0.0720  decode.d1.loss_mask: 0.2149  decode.d1.loss_dice: 0.2463  decode.d2.loss_cls: 0.0428  decode.d2.loss_mask: 0.2364  decode.d2.loss_dice: 0.2512  decode.d3.loss_cls: 0.0631  decode.d3.loss_mask: 0.2295  decode.d3.loss_dice: 0.2412  decode.d4.loss_cls: 0.0548  decode.d4.loss_mask: 0.2264  decode.d4.loss_dice: 0.2483  decode.d5.loss_cls: 0.0556  decode.d5.loss_mask: 0.2294  decode.d5.loss_dice: 0.2492  decode.d6.loss_cls: 0.0414  decode.d6.loss_mask: 0.2281  decode.d6.loss_dice: 0.2423  decode.d7.loss_cls: 0.0304  decode.d7.loss_mask: 0.2319  decode.d7.loss_dice: 0.2433  decode.d8.loss_cls: 0.0262  decode.d8.loss_mask: 0.2297  decode.d8.loss_dice: 0.2506
08/06 12:12:46 - mmengine - INFO - Iter(train) [ 71950/320000]  base_lr: 7.9515e-05 lr: 7.9515e-06  eta: 1 day, 10:00:50  time: 0.4982  data_time: 0.0112  memory: 5928  grad_norm: 54.8434  loss: 5.5891  decode.loss_cls: 0.0022  decode.loss_mask: 0.2506  decode.loss_dice: 0.2277  decode.d0.loss_cls: 0.6597  decode.d0.loss_mask: 0.2513  decode.d0.loss_dice: 0.2250  decode.d1.loss_cls: 0.0483  decode.d1.loss_mask: 0.2532  decode.d1.loss_dice: 0.2361  decode.d2.loss_cls: 0.0048  decode.d2.loss_mask: 0.2514  decode.d2.loss_dice: 0.2341  decode.d3.loss_cls: 0.0117  decode.d3.loss_mask: 0.2548  decode.d3.loss_dice: 0.2346  decode.d4.loss_cls: 0.0069  decode.d4.loss_mask: 0.2538  decode.d4.loss_dice: 0.2310  decode.d5.loss_cls: 0.0043  decode.d5.loss_mask: 0.2555  decode.d5.loss_dice: 0.2336  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.2502  decode.d6.loss_dice: 0.2282  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.2489  decode.d7.loss_dice: 0.2318  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.2542  decode.d8.loss_dice: 0.2368
08/06 12:13:11 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 12:13:11 - mmengine - INFO - Iter(train) [ 72000/320000]  base_lr: 7.9501e-05 lr: 7.9501e-06  eta: 1 day, 10:00:26  time: 0.4959  data_time: 0.0110  memory: 5930  grad_norm: 85.8103  loss: 4.9766  decode.loss_cls: 0.0248  decode.loss_mask: 0.1931  decode.loss_dice: 0.2081  decode.d0.loss_cls: 0.7326  decode.d0.loss_mask: 0.1975  decode.d0.loss_dice: 0.2107  decode.d1.loss_cls: 0.0235  decode.d1.loss_mask: 0.1950  decode.d1.loss_dice: 0.2090  decode.d2.loss_cls: 0.0319  decode.d2.loss_mask: 0.1955  decode.d2.loss_dice: 0.2069  decode.d3.loss_cls: 0.0372  decode.d3.loss_mask: 0.1927  decode.d3.loss_dice: 0.2048  decode.d4.loss_cls: 0.0366  decode.d4.loss_mask: 0.1932  decode.d4.loss_dice: 0.2028  decode.d5.loss_cls: 0.0158  decode.d5.loss_mask: 0.1940  decode.d5.loss_dice: 0.2103  decode.d6.loss_cls: 0.0201  decode.d6.loss_mask: 0.1939  decode.d6.loss_dice: 0.2043  decode.d7.loss_cls: 0.0219  decode.d7.loss_mask: 0.1929  decode.d7.loss_dice: 0.2081  decode.d8.loss_cls: 0.0162  decode.d8.loss_mask: 0.1957  decode.d8.loss_dice: 0.2072
08/06 12:13:36 - mmengine - INFO - Iter(train) [ 72050/320000]  base_lr: 7.9487e-05 lr: 7.9487e-06  eta: 1 day, 10:00:02  time: 0.4972  data_time: 0.0110  memory: 5895  grad_norm: 95.9771  loss: 8.1484  decode.loss_cls: 0.1220  decode.loss_mask: 0.2313  decode.loss_dice: 0.3442  decode.d0.loss_cls: 1.0449  decode.d0.loss_mask: 0.2322  decode.d0.loss_dice: 0.3607  decode.d1.loss_cls: 0.1861  decode.d1.loss_mask: 0.2293  decode.d1.loss_dice: 0.3531  decode.d2.loss_cls: 0.1946  decode.d2.loss_mask: 0.2293  decode.d2.loss_dice: 0.3095  decode.d3.loss_cls: 0.1159  decode.d3.loss_mask: 0.2349  decode.d3.loss_dice: 0.3570  decode.d4.loss_cls: 0.1489  decode.d4.loss_mask: 0.2368  decode.d4.loss_dice: 0.3609  decode.d5.loss_cls: 0.0845  decode.d5.loss_mask: 0.2360  decode.d5.loss_dice: 0.3567  decode.d6.loss_cls: 0.1412  decode.d6.loss_mask: 0.2360  decode.d6.loss_dice: 0.3465  decode.d7.loss_cls: 0.1874  decode.d7.loss_mask: 0.2338  decode.d7.loss_dice: 0.3411  decode.d8.loss_cls: 0.1073  decode.d8.loss_mask: 0.2361  decode.d8.loss_dice: 0.3503
08/06 12:14:00 - mmengine - INFO - Iter(train) [ 72100/320000]  base_lr: 7.9472e-05 lr: 7.9472e-06  eta: 1 day, 9:59:38  time: 0.4958  data_time: 0.0111  memory: 5876  grad_norm: 66.2588  loss: 6.2212  decode.loss_cls: 0.0590  decode.loss_mask: 0.1995  decode.loss_dice: 0.2872  decode.d0.loss_cls: 0.8378  decode.d0.loss_mask: 0.2030  decode.d0.loss_dice: 0.2819  decode.d1.loss_cls: 0.1228  decode.d1.loss_mask: 0.2007  decode.d1.loss_dice: 0.2821  decode.d2.loss_cls: 0.0446  decode.d2.loss_mask: 0.2011  decode.d2.loss_dice: 0.2624  decode.d3.loss_cls: 0.0572  decode.d3.loss_mask: 0.2017  decode.d3.loss_dice: 0.2638  decode.d4.loss_cls: 0.0594  decode.d4.loss_mask: 0.2023  decode.d4.loss_dice: 0.2822  decode.d5.loss_cls: 0.0524  decode.d5.loss_mask: 0.1991  decode.d5.loss_dice: 0.2762  decode.d6.loss_cls: 0.0729  decode.d6.loss_mask: 0.2028  decode.d6.loss_dice: 0.2548  decode.d7.loss_cls: 0.0901  decode.d7.loss_mask: 0.2021  decode.d7.loss_dice: 0.2735  decode.d8.loss_cls: 0.0693  decode.d8.loss_mask: 0.2041  decode.d8.loss_dice: 0.2750
08/06 12:14:25 - mmengine - INFO - Iter(train) [ 72150/320000]  base_lr: 7.9458e-05 lr: 7.9458e-06  eta: 1 day, 9:59:14  time: 0.4977  data_time: 0.0113  memory: 5894  grad_norm: 140.5669  loss: 6.3835  decode.loss_cls: 0.1165  decode.loss_mask: 0.2226  decode.loss_dice: 0.2235  decode.d0.loss_cls: 0.9008  decode.d0.loss_mask: 0.2226  decode.d0.loss_dice: 0.2202  decode.d1.loss_cls: 0.1212  decode.d1.loss_mask: 0.2189  decode.d1.loss_dice: 0.2231  decode.d2.loss_cls: 0.1611  decode.d2.loss_mask: 0.2157  decode.d2.loss_dice: 0.2091  decode.d3.loss_cls: 0.0834  decode.d3.loss_mask: 0.2151  decode.d3.loss_dice: 0.2204  decode.d4.loss_cls: 0.1211  decode.d4.loss_mask: 0.2166  decode.d4.loss_dice: 0.2233  decode.d5.loss_cls: 0.1182  decode.d5.loss_mask: 0.2173  decode.d5.loss_dice: 0.2249  decode.d6.loss_cls: 0.1376  decode.d6.loss_mask: 0.2172  decode.d6.loss_dice: 0.2181  decode.d7.loss_cls: 0.1097  decode.d7.loss_mask: 0.2205  decode.d7.loss_dice: 0.2417  decode.d8.loss_cls: 0.0994  decode.d8.loss_mask: 0.2187  decode.d8.loss_dice: 0.2249
08/06 12:14:50 - mmengine - INFO - Iter(train) [ 72200/320000]  base_lr: 7.9443e-05 lr: 7.9443e-06  eta: 1 day, 9:58:50  time: 0.4992  data_time: 0.0115  memory: 5928  grad_norm: 265.4471  loss: 8.2344  decode.loss_cls: 0.1226  decode.loss_mask: 0.3402  decode.loss_dice: 0.2661  decode.d0.loss_cls: 1.0294  decode.d0.loss_mask: 0.3407  decode.d0.loss_dice: 0.2710  decode.d1.loss_cls: 0.1714  decode.d1.loss_mask: 0.3296  decode.d1.loss_dice: 0.2679  decode.d2.loss_cls: 0.1261  decode.d2.loss_mask: 0.3266  decode.d2.loss_dice: 0.2705  decode.d3.loss_cls: 0.1147  decode.d3.loss_mask: 0.3516  decode.d3.loss_dice: 0.2699  decode.d4.loss_cls: 0.1320  decode.d4.loss_mask: 0.3419  decode.d4.loss_dice: 0.2697  decode.d5.loss_cls: 0.0886  decode.d5.loss_mask: 0.3274  decode.d5.loss_dice: 0.2701  decode.d6.loss_cls: 0.1353  decode.d6.loss_mask: 0.3250  decode.d6.loss_dice: 0.2645  decode.d7.loss_cls: 0.1122  decode.d7.loss_mask: 0.3373  decode.d7.loss_dice: 0.2782  decode.d8.loss_cls: 0.1383  decode.d8.loss_mask: 0.3454  decode.d8.loss_dice: 0.2702
08/06 12:15:15 - mmengine - INFO - Iter(train) [ 72250/320000]  base_lr: 7.9429e-05 lr: 7.9429e-06  eta: 1 day, 9:58:26  time: 0.4966  data_time: 0.0114  memory: 5894  grad_norm: 220.5900  loss: 7.9892  decode.loss_cls: 0.1499  decode.loss_mask: 0.2696  decode.loss_dice: 0.2728  decode.d0.loss_cls: 0.9878  decode.d0.loss_mask: 0.2685  decode.d0.loss_dice: 0.2619  decode.d1.loss_cls: 0.2104  decode.d1.loss_mask: 0.2646  decode.d1.loss_dice: 0.2727  decode.d2.loss_cls: 0.1574  decode.d2.loss_mask: 0.2702  decode.d2.loss_dice: 0.2877  decode.d3.loss_cls: 0.1576  decode.d3.loss_mask: 0.2734  decode.d3.loss_dice: 0.2721  decode.d4.loss_cls: 0.2205  decode.d4.loss_mask: 0.2659  decode.d4.loss_dice: 0.2628  decode.d5.loss_cls: 0.1992  decode.d5.loss_mask: 0.2644  decode.d5.loss_dice: 0.2776  decode.d6.loss_cls: 0.1695  decode.d6.loss_mask: 0.2607  decode.d6.loss_dice: 0.2618  decode.d7.loss_cls: 0.1454  decode.d7.loss_mask: 0.2754  decode.d7.loss_dice: 0.2778  decode.d8.loss_cls: 0.1570  decode.d8.loss_mask: 0.2782  decode.d8.loss_dice: 0.2963
08/06 12:15:40 - mmengine - INFO - Iter(train) [ 72300/320000]  base_lr: 7.9414e-05 lr: 7.9414e-06  eta: 1 day, 9:58:02  time: 0.4997  data_time: 0.0115  memory: 5911  grad_norm: 48.4056  loss: 5.3999  decode.loss_cls: 0.0285  decode.loss_mask: 0.1932  decode.loss_dice: 0.2069  decode.d0.loss_cls: 0.9184  decode.d0.loss_mask: 0.2017  decode.d0.loss_dice: 0.2398  decode.d1.loss_cls: 0.0925  decode.d1.loss_mask: 0.1926  decode.d1.loss_dice: 0.2356  decode.d2.loss_cls: 0.0812  decode.d2.loss_mask: 0.1863  decode.d2.loss_dice: 0.1967  decode.d3.loss_cls: 0.0400  decode.d3.loss_mask: 0.1930  decode.d3.loss_dice: 0.2049  decode.d4.loss_cls: 0.0348  decode.d4.loss_mask: 0.1924  decode.d4.loss_dice: 0.2132  decode.d5.loss_cls: 0.0330  decode.d5.loss_mask: 0.1918  decode.d5.loss_dice: 0.2192  decode.d6.loss_cls: 0.0361  decode.d6.loss_mask: 0.1922  decode.d6.loss_dice: 0.2003  decode.d7.loss_cls: 0.0290  decode.d7.loss_mask: 0.1977  decode.d7.loss_dice: 0.2177  decode.d8.loss_cls: 0.0304  decode.d8.loss_mask: 0.1955  decode.d8.loss_dice: 0.2055
08/06 12:16:05 - mmengine - INFO - Iter(train) [ 72350/320000]  base_lr: 7.9400e-05 lr: 7.9400e-06  eta: 1 day, 9:57:38  time: 0.4974  data_time: 0.0112  memory: 5894  grad_norm: 97.3127  loss: 7.1049  decode.loss_cls: 0.0666  decode.loss_mask: 0.2539  decode.loss_dice: 0.2882  decode.d0.loss_cls: 0.9309  decode.d0.loss_mask: 0.2570  decode.d0.loss_dice: 0.2856  decode.d1.loss_cls: 0.1563  decode.d1.loss_mask: 0.2464  decode.d1.loss_dice: 0.2563  decode.d2.loss_cls: 0.1170  decode.d2.loss_mask: 0.2453  decode.d2.loss_dice: 0.2626  decode.d3.loss_cls: 0.1188  decode.d3.loss_mask: 0.2489  decode.d3.loss_dice: 0.2694  decode.d4.loss_cls: 0.1255  decode.d4.loss_mask: 0.2466  decode.d4.loss_dice: 0.2666  decode.d5.loss_cls: 0.1235  decode.d5.loss_mask: 0.2461  decode.d5.loss_dice: 0.2699  decode.d6.loss_cls: 0.0900  decode.d6.loss_mask: 0.2454  decode.d6.loss_dice: 0.2745  decode.d7.loss_cls: 0.0868  decode.d7.loss_mask: 0.2477  decode.d7.loss_dice: 0.2744  decode.d8.loss_cls: 0.0674  decode.d8.loss_mask: 0.2526  decode.d8.loss_dice: 0.2849
08/06 12:16:30 - mmengine - INFO - Iter(train) [ 72400/320000]  base_lr: 7.9386e-05 lr: 7.9386e-06  eta: 1 day, 9:57:14  time: 0.4993  data_time: 0.0113  memory: 5894  grad_norm: 114.1259  loss: 6.4660  decode.loss_cls: 0.0726  decode.loss_mask: 0.2066  decode.loss_dice: 0.2237  decode.d0.loss_cls: 0.8509  decode.d0.loss_mask: 0.2139  decode.d0.loss_dice: 0.2475  decode.d1.loss_cls: 0.1218  decode.d1.loss_mask: 0.2117  decode.d1.loss_dice: 0.2467  decode.d2.loss_cls: 0.1415  decode.d2.loss_mask: 0.2106  decode.d2.loss_dice: 0.2373  decode.d3.loss_cls: 0.1224  decode.d3.loss_mask: 0.2060  decode.d3.loss_dice: 0.2660  decode.d4.loss_cls: 0.1382  decode.d4.loss_mask: 0.2085  decode.d4.loss_dice: 0.2302  decode.d5.loss_cls: 0.1571  decode.d5.loss_mask: 0.2083  decode.d5.loss_dice: 0.2374  decode.d6.loss_cls: 0.1331  decode.d6.loss_mask: 0.2108  decode.d6.loss_dice: 0.2462  decode.d7.loss_cls: 0.1211  decode.d7.loss_mask: 0.2084  decode.d7.loss_dice: 0.2419  decode.d8.loss_cls: 0.0944  decode.d8.loss_mask: 0.2103  decode.d8.loss_dice: 0.2407
08/06 12:16:55 - mmengine - INFO - Iter(train) [ 72450/320000]  base_lr: 7.9371e-05 lr: 7.9371e-06  eta: 1 day, 9:56:51  time: 0.5011  data_time: 0.0114  memory: 5878  grad_norm: 102.3855  loss: 7.3396  decode.loss_cls: 0.0993  decode.loss_mask: 0.1967  decode.loss_dice: 0.2942  decode.d0.loss_cls: 1.0336  decode.d0.loss_mask: 0.1997  decode.d0.loss_dice: 0.2677  decode.d1.loss_cls: 0.1939  decode.d1.loss_mask: 0.1927  decode.d1.loss_dice: 0.2907  decode.d2.loss_cls: 0.1577  decode.d2.loss_mask: 0.1961  decode.d2.loss_dice: 0.2980  decode.d3.loss_cls: 0.2130  decode.d3.loss_mask: 0.1993  decode.d3.loss_dice: 0.2813  decode.d4.loss_cls: 0.1447  decode.d4.loss_mask: 0.1970  decode.d4.loss_dice: 0.3150  decode.d5.loss_cls: 0.1290  decode.d5.loss_mask: 0.1958  decode.d5.loss_dice: 0.2974  decode.d6.loss_cls: 0.1433  decode.d6.loss_mask: 0.2000  decode.d6.loss_dice: 0.3126  decode.d7.loss_cls: 0.1542  decode.d7.loss_mask: 0.1983  decode.d7.loss_dice: 0.3087  decode.d8.loss_cls: 0.1357  decode.d8.loss_mask: 0.1986  decode.d8.loss_dice: 0.2953
08/06 12:17:20 - mmengine - INFO - Iter(train) [ 72500/320000]  base_lr: 7.9357e-05 lr: 7.9357e-06  eta: 1 day, 9:56:27  time: 0.4972  data_time: 0.0110  memory: 5874  grad_norm: 150.7767  loss: 7.0025  decode.loss_cls: 0.0707  decode.loss_mask: 0.2423  decode.loss_dice: 0.3024  decode.d0.loss_cls: 0.9551  decode.d0.loss_mask: 0.2271  decode.d0.loss_dice: 0.2763  decode.d1.loss_cls: 0.0964  decode.d1.loss_mask: 0.2475  decode.d1.loss_dice: 0.2871  decode.d2.loss_cls: 0.0565  decode.d2.loss_mask: 0.2445  decode.d2.loss_dice: 0.3087  decode.d3.loss_cls: 0.0637  decode.d3.loss_mask: 0.2355  decode.d3.loss_dice: 0.3031  decode.d4.loss_cls: 0.0595  decode.d4.loss_mask: 0.2364  decode.d4.loss_dice: 0.3031  decode.d5.loss_cls: 0.0635  decode.d5.loss_mask: 0.2329  decode.d5.loss_dice: 0.2745  decode.d6.loss_cls: 0.1396  decode.d6.loss_mask: 0.2384  decode.d6.loss_dice: 0.2941  decode.d7.loss_cls: 0.1215  decode.d7.loss_mask: 0.2382  decode.d7.loss_dice: 0.2958  decode.d8.loss_cls: 0.0469  decode.d8.loss_mask: 0.2429  decode.d8.loss_dice: 0.2983
08/06 12:17:45 - mmengine - INFO - Iter(train) [ 72550/320000]  base_lr: 7.9342e-05 lr: 7.9342e-06  eta: 1 day, 9:56:03  time: 0.4987  data_time: 0.0114  memory: 5911  grad_norm: 65.6526  loss: 6.6330  decode.loss_cls: 0.1112  decode.loss_mask: 0.2112  decode.loss_dice: 0.2709  decode.d0.loss_cls: 0.8310  decode.d0.loss_mask: 0.2159  decode.d0.loss_dice: 0.2701  decode.d1.loss_cls: 0.1262  decode.d1.loss_mask: 0.2136  decode.d1.loss_dice: 0.2577  decode.d2.loss_cls: 0.1224  decode.d2.loss_mask: 0.2122  decode.d2.loss_dice: 0.2665  decode.d3.loss_cls: 0.1064  decode.d3.loss_mask: 0.2150  decode.d3.loss_dice: 0.2662  decode.d4.loss_cls: 0.1067  decode.d4.loss_mask: 0.2112  decode.d4.loss_dice: 0.2564  decode.d5.loss_cls: 0.1025  decode.d5.loss_mask: 0.2125  decode.d5.loss_dice: 0.2623  decode.d6.loss_cls: 0.1100  decode.d6.loss_mask: 0.2148  decode.d6.loss_dice: 0.2792  decode.d7.loss_cls: 0.1161  decode.d7.loss_mask: 0.2100  decode.d7.loss_dice: 0.2669  decode.d8.loss_cls: 0.1041  decode.d8.loss_mask: 0.2139  decode.d8.loss_dice: 0.2701
08/06 12:18:10 - mmengine - INFO - Iter(train) [ 72600/320000]  base_lr: 7.9328e-05 lr: 7.9328e-06  eta: 1 day, 9:55:39  time: 0.4977  data_time: 0.0114  memory: 5861  grad_norm: 119.4839  loss: 8.1452  decode.loss_cls: 0.1619  decode.loss_mask: 0.2741  decode.loss_dice: 0.3090  decode.d0.loss_cls: 0.8277  decode.d0.loss_mask: 0.2779  decode.d0.loss_dice: 0.3191  decode.d1.loss_cls: 0.1304  decode.d1.loss_mask: 0.2850  decode.d1.loss_dice: 0.3081  decode.d2.loss_cls: 0.1376  decode.d2.loss_mask: 0.2764  decode.d2.loss_dice: 0.3055  decode.d3.loss_cls: 0.1425  decode.d3.loss_mask: 0.2745  decode.d3.loss_dice: 0.3042  decode.d4.loss_cls: 0.1990  decode.d4.loss_mask: 0.2723  decode.d4.loss_dice: 0.3140  decode.d5.loss_cls: 0.1580  decode.d5.loss_mask: 0.2759  decode.d5.loss_dice: 0.3010  decode.d6.loss_cls: 0.1783  decode.d6.loss_mask: 0.2736  decode.d6.loss_dice: 0.3146  decode.d7.loss_cls: 0.1793  decode.d7.loss_mask: 0.2762  decode.d7.loss_dice: 0.3163  decode.d8.loss_cls: 0.1605  decode.d8.loss_mask: 0.2772  decode.d8.loss_dice: 0.3150
08/06 12:18:35 - mmengine - INFO - Iter(train) [ 72650/320000]  base_lr: 7.9313e-05 lr: 7.9313e-06  eta: 1 day, 9:55:15  time: 0.4975  data_time: 0.0115  memory: 5911  grad_norm: 178.4860  loss: 7.6107  decode.loss_cls: 0.1705  decode.loss_mask: 0.2502  decode.loss_dice: 0.2512  decode.d0.loss_cls: 0.8253  decode.d0.loss_mask: 0.2609  decode.d0.loss_dice: 0.2956  decode.d1.loss_cls: 0.2235  decode.d1.loss_mask: 0.2610  decode.d1.loss_dice: 0.2589  decode.d2.loss_cls: 0.1288  decode.d2.loss_mask: 0.2829  decode.d2.loss_dice: 0.2663  decode.d3.loss_cls: 0.2335  decode.d3.loss_mask: 0.2587  decode.d3.loss_dice: 0.2658  decode.d4.loss_cls: 0.1940  decode.d4.loss_mask: 0.2605  decode.d4.loss_dice: 0.2711  decode.d5.loss_cls: 0.1713  decode.d5.loss_mask: 0.2714  decode.d5.loss_dice: 0.2517  decode.d6.loss_cls: 0.1601  decode.d6.loss_mask: 0.2554  decode.d6.loss_dice: 0.2430  decode.d7.loss_cls: 0.0984  decode.d7.loss_mask: 0.2881  decode.d7.loss_dice: 0.2661  decode.d8.loss_cls: 0.1320  decode.d8.loss_mask: 0.2550  decode.d8.loss_dice: 0.2594
08/06 12:19:00 - mmengine - INFO - Iter(train) [ 72700/320000]  base_lr: 7.9299e-05 lr: 7.9299e-06  eta: 1 day, 9:54:51  time: 0.4986  data_time: 0.0117  memory: 5896  grad_norm: 168.4806  loss: 6.6434  decode.loss_cls: 0.0566  decode.loss_mask: 0.2344  decode.loss_dice: 0.2915  decode.d0.loss_cls: 0.9031  decode.d0.loss_mask: 0.2341  decode.d0.loss_dice: 0.2841  decode.d1.loss_cls: 0.0583  decode.d1.loss_mask: 0.2294  decode.d1.loss_dice: 0.2760  decode.d2.loss_cls: 0.0422  decode.d2.loss_mask: 0.2284  decode.d2.loss_dice: 0.2686  decode.d3.loss_cls: 0.0724  decode.d3.loss_mask: 0.2291  decode.d3.loss_dice: 0.2771  decode.d4.loss_cls: 0.1032  decode.d4.loss_mask: 0.2315  decode.d4.loss_dice: 0.2705  decode.d5.loss_cls: 0.0883  decode.d5.loss_mask: 0.2402  decode.d5.loss_dice: 0.2891  decode.d6.loss_cls: 0.0818  decode.d6.loss_mask: 0.2347  decode.d6.loss_dice: 0.2931  decode.d7.loss_cls: 0.0594  decode.d7.loss_mask: 0.2341  decode.d7.loss_dice: 0.2742  decode.d8.loss_cls: 0.0560  decode.d8.loss_mask: 0.2347  decode.d8.loss_dice: 0.2676
08/06 12:19:25 - mmengine - INFO - Iter(train) [ 72750/320000]  base_lr: 7.9285e-05 lr: 7.9285e-06  eta: 1 day, 9:54:28  time: 0.4979  data_time: 0.0113  memory: 5894  grad_norm: 108.3333  loss: 8.2009  decode.loss_cls: 0.1579  decode.loss_mask: 0.2756  decode.loss_dice: 0.3124  decode.d0.loss_cls: 0.8826  decode.d0.loss_mask: 0.2848  decode.d0.loss_dice: 0.3065  decode.d1.loss_cls: 0.1063  decode.d1.loss_mask: 0.2836  decode.d1.loss_dice: 0.3240  decode.d2.loss_cls: 0.0964  decode.d2.loss_mask: 0.2732  decode.d2.loss_dice: 0.3263  decode.d3.loss_cls: 0.1109  decode.d3.loss_mask: 0.2825  decode.d3.loss_dice: 0.3282  decode.d4.loss_cls: 0.1260  decode.d4.loss_mask: 0.3047  decode.d4.loss_dice: 0.3345  decode.d5.loss_cls: 0.1280  decode.d5.loss_mask: 0.3374  decode.d5.loss_dice: 0.3314  decode.d6.loss_cls: 0.1407  decode.d6.loss_mask: 0.2943  decode.d6.loss_dice: 0.3351  decode.d7.loss_cls: 0.1882  decode.d7.loss_mask: 0.2782  decode.d7.loss_dice: 0.3180  decode.d8.loss_cls: 0.1064  decode.d8.loss_mask: 0.2924  decode.d8.loss_dice: 0.3340
08/06 12:19:50 - mmengine - INFO - Iter(train) [ 72800/320000]  base_lr: 7.9270e-05 lr: 7.9270e-06  eta: 1 day, 9:54:04  time: 0.4987  data_time: 0.0114  memory: 5875  grad_norm: 88.9947  loss: 6.3768  decode.loss_cls: 0.1337  decode.loss_mask: 0.1853  decode.loss_dice: 0.2309  decode.d0.loss_cls: 0.9046  decode.d0.loss_mask: 0.1824  decode.d0.loss_dice: 0.2197  decode.d1.loss_cls: 0.1690  decode.d1.loss_mask: 0.1859  decode.d1.loss_dice: 0.2238  decode.d2.loss_cls: 0.1251  decode.d2.loss_mask: 0.1831  decode.d2.loss_dice: 0.2319  decode.d3.loss_cls: 0.1506  decode.d3.loss_mask: 0.1848  decode.d3.loss_dice: 0.2282  decode.d4.loss_cls: 0.1580  decode.d4.loss_mask: 0.1831  decode.d4.loss_dice: 0.2293  decode.d5.loss_cls: 0.1671  decode.d5.loss_mask: 0.1837  decode.d5.loss_dice: 0.2500  decode.d6.loss_cls: 0.1294  decode.d6.loss_mask: 0.1853  decode.d6.loss_dice: 0.2358  decode.d7.loss_cls: 0.1270  decode.d7.loss_mask: 0.1826  decode.d7.loss_dice: 0.2288  decode.d8.loss_cls: 0.1525  decode.d8.loss_mask: 0.1799  decode.d8.loss_dice: 0.2451
08/06 12:20:15 - mmengine - INFO - Iter(train) [ 72850/320000]  base_lr: 7.9256e-05 lr: 7.9256e-06  eta: 1 day, 9:53:40  time: 0.4986  data_time: 0.0115  memory: 5894  grad_norm: 253.9932  loss: 7.9665  decode.loss_cls: 0.2005  decode.loss_mask: 0.2795  decode.loss_dice: 0.2356  decode.d0.loss_cls: 0.8747  decode.d0.loss_mask: 0.2925  decode.d0.loss_dice: 0.2721  decode.d1.loss_cls: 0.2278  decode.d1.loss_mask: 0.2962  decode.d1.loss_dice: 0.2588  decode.d2.loss_cls: 0.1711  decode.d2.loss_mask: 0.2902  decode.d2.loss_dice: 0.2496  decode.d3.loss_cls: 0.1966  decode.d3.loss_mask: 0.2796  decode.d3.loss_dice: 0.2417  decode.d4.loss_cls: 0.1863  decode.d4.loss_mask: 0.2905  decode.d4.loss_dice: 0.2524  decode.d5.loss_cls: 0.1710  decode.d5.loss_mask: 0.2964  decode.d5.loss_dice: 0.2484  decode.d6.loss_cls: 0.1821  decode.d6.loss_mask: 0.2877  decode.d6.loss_dice: 0.2467  decode.d7.loss_cls: 0.1925  decode.d7.loss_mask: 0.2909  decode.d7.loss_dice: 0.2409  decode.d8.loss_cls: 0.1908  decode.d8.loss_mask: 0.2840  decode.d8.loss_dice: 0.2396
08/06 12:20:39 - mmengine - INFO - Iter(train) [ 72900/320000]  base_lr: 7.9241e-05 lr: 7.9241e-06  eta: 1 day, 9:53:16  time: 0.4991  data_time: 0.0113  memory: 5894  grad_norm: 41.5188  loss: 6.8156  decode.loss_cls: 0.0804  decode.loss_mask: 0.2616  decode.loss_dice: 0.2903  decode.d0.loss_cls: 0.8219  decode.d0.loss_mask: 0.2653  decode.d0.loss_dice: 0.2774  decode.d1.loss_cls: 0.0451  decode.d1.loss_mask: 0.2590  decode.d1.loss_dice: 0.3033  decode.d2.loss_cls: 0.0566  decode.d2.loss_mask: 0.2589  decode.d2.loss_dice: 0.2960  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 0.2554  decode.d3.loss_dice: 0.2694  decode.d4.loss_cls: 0.1097  decode.d4.loss_mask: 0.2634  decode.d4.loss_dice: 0.2790  decode.d5.loss_cls: 0.0775  decode.d5.loss_mask: 0.2618  decode.d5.loss_dice: 0.2594  decode.d6.loss_cls: 0.0626  decode.d6.loss_mask: 0.2629  decode.d6.loss_dice: 0.2563  decode.d7.loss_cls: 0.0862  decode.d7.loss_mask: 0.2566  decode.d7.loss_dice: 0.2728  decode.d8.loss_cls: 0.0500  decode.d8.loss_mask: 0.2560  decode.d8.loss_dice: 0.2580
08/06 12:21:04 - mmengine - INFO - Iter(train) [ 72950/320000]  base_lr: 7.9227e-05 lr: 7.9227e-06  eta: 1 day, 9:52:52  time: 0.4979  data_time: 0.0111  memory: 5911  grad_norm: 82.1688  loss: 6.3269  decode.loss_cls: 0.1171  decode.loss_mask: 0.2005  decode.loss_dice: 0.2502  decode.d0.loss_cls: 0.8238  decode.d0.loss_mask: 0.2096  decode.d0.loss_dice: 0.2699  decode.d1.loss_cls: 0.1285  decode.d1.loss_mask: 0.2067  decode.d1.loss_dice: 0.2577  decode.d2.loss_cls: 0.1370  decode.d2.loss_mask: 0.2043  decode.d2.loss_dice: 0.2385  decode.d3.loss_cls: 0.1012  decode.d3.loss_mask: 0.2020  decode.d3.loss_dice: 0.2489  decode.d4.loss_cls: 0.0972  decode.d4.loss_mask: 0.2031  decode.d4.loss_dice: 0.2358  decode.d5.loss_cls: 0.0990  decode.d5.loss_mask: 0.2054  decode.d5.loss_dice: 0.2467  decode.d6.loss_cls: 0.1044  decode.d6.loss_mask: 0.2018  decode.d6.loss_dice: 0.2586  decode.d7.loss_cls: 0.1021  decode.d7.loss_mask: 0.2008  decode.d7.loss_dice: 0.2450  decode.d8.loss_cls: 0.0846  decode.d8.loss_mask: 0.1989  decode.d8.loss_dice: 0.2477
08/06 12:21:29 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 12:21:29 - mmengine - INFO - Iter(train) [ 73000/320000]  base_lr: 7.9212e-05 lr: 7.9212e-06  eta: 1 day, 9:52:28  time: 0.4998  data_time: 0.0118  memory: 5878  grad_norm: 65.9972  loss: 6.2705  decode.loss_cls: 0.0779  decode.loss_mask: 0.2080  decode.loss_dice: 0.2492  decode.d0.loss_cls: 0.8793  decode.d0.loss_mask: 0.2080  decode.d0.loss_dice: 0.2443  decode.d1.loss_cls: 0.1022  decode.d1.loss_mask: 0.2081  decode.d1.loss_dice: 0.2533  decode.d2.loss_cls: 0.0955  decode.d2.loss_mask: 0.2074  decode.d2.loss_dice: 0.2521  decode.d3.loss_cls: 0.1045  decode.d3.loss_mask: 0.2087  decode.d3.loss_dice: 0.2495  decode.d4.loss_cls: 0.0867  decode.d4.loss_mask: 0.2069  decode.d4.loss_dice: 0.2518  decode.d5.loss_cls: 0.0764  decode.d5.loss_mask: 0.2091  decode.d5.loss_dice: 0.2464  decode.d6.loss_cls: 0.1020  decode.d6.loss_mask: 0.2063  decode.d6.loss_dice: 0.2470  decode.d7.loss_cls: 0.0778  decode.d7.loss_mask: 0.2085  decode.d7.loss_dice: 0.2529  decode.d8.loss_cls: 0.0971  decode.d8.loss_mask: 0.2086  decode.d8.loss_dice: 0.2449
08/06 12:21:54 - mmengine - INFO - Iter(train) [ 73050/320000]  base_lr: 7.9198e-05 lr: 7.9198e-06  eta: 1 day, 9:52:05  time: 0.4967  data_time: 0.0112  memory: 5891  grad_norm: 79.6208  loss: 7.3701  decode.loss_cls: 0.2060  decode.loss_mask: 0.2323  decode.loss_dice: 0.2861  decode.d0.loss_cls: 0.8324  decode.d0.loss_mask: 0.2351  decode.d0.loss_dice: 0.2602  decode.d1.loss_cls: 0.1941  decode.d1.loss_mask: 0.2298  decode.d1.loss_dice: 0.2436  decode.d2.loss_cls: 0.1676  decode.d2.loss_mask: 0.2290  decode.d2.loss_dice: 0.2991  decode.d3.loss_cls: 0.1496  decode.d3.loss_mask: 0.2302  decode.d3.loss_dice: 0.2697  decode.d4.loss_cls: 0.1225  decode.d4.loss_mask: 0.2332  decode.d4.loss_dice: 0.2416  decode.d5.loss_cls: 0.1781  decode.d5.loss_mask: 0.2282  decode.d5.loss_dice: 0.2692  decode.d6.loss_cls: 0.1445  decode.d6.loss_mask: 0.2323  decode.d6.loss_dice: 0.3179  decode.d7.loss_cls: 0.1350  decode.d7.loss_mask: 0.2323  decode.d7.loss_dice: 0.2934  decode.d8.loss_cls: 0.1701  decode.d8.loss_mask: 0.2339  decode.d8.loss_dice: 0.2736
08/06 12:22:19 - mmengine - INFO - Iter(train) [ 73100/320000]  base_lr: 7.9184e-05 lr: 7.9184e-06  eta: 1 day, 9:51:41  time: 0.4980  data_time: 0.0115  memory: 5894  grad_norm: 136.9895  loss: 9.5118  decode.loss_cls: 0.2305  decode.loss_mask: 0.3364  decode.loss_dice: 0.3566  decode.d0.loss_cls: 1.0548  decode.d0.loss_mask: 0.3399  decode.d0.loss_dice: 0.3374  decode.d1.loss_cls: 0.2001  decode.d1.loss_mask: 0.3303  decode.d1.loss_dice: 0.3264  decode.d2.loss_cls: 0.1914  decode.d2.loss_mask: 0.3323  decode.d2.loss_dice: 0.3236  decode.d3.loss_cls: 0.1343  decode.d3.loss_mask: 0.3331  decode.d3.loss_dice: 0.3373  decode.d4.loss_cls: 0.2185  decode.d4.loss_mask: 0.3413  decode.d4.loss_dice: 0.3170  decode.d5.loss_cls: 0.1789  decode.d5.loss_mask: 0.3393  decode.d5.loss_dice: 0.3431  decode.d6.loss_cls: 0.1702  decode.d6.loss_mask: 0.3339  decode.d6.loss_dice: 0.3249  decode.d7.loss_cls: 0.2453  decode.d7.loss_mask: 0.3334  decode.d7.loss_dice: 0.3322  decode.d8.loss_cls: 0.1899  decode.d8.loss_mask: 0.3331  decode.d8.loss_dice: 0.3466
08/06 12:22:44 - mmengine - INFO - Iter(train) [ 73150/320000]  base_lr: 7.9169e-05 lr: 7.9169e-06  eta: 1 day, 9:51:17  time: 0.4995  data_time: 0.0115  memory: 5894  grad_norm: 39.4448  loss: 6.0173  decode.loss_cls: 0.0648  decode.loss_mask: 0.2153  decode.loss_dice: 0.2491  decode.d0.loss_cls: 0.8781  decode.d0.loss_mask: 0.2127  decode.d0.loss_dice: 0.2595  decode.d1.loss_cls: 0.0558  decode.d1.loss_mask: 0.2116  decode.d1.loss_dice: 0.2471  decode.d2.loss_cls: 0.0697  decode.d2.loss_mask: 0.2126  decode.d2.loss_dice: 0.2665  decode.d3.loss_cls: 0.0313  decode.d3.loss_mask: 0.2132  decode.d3.loss_dice: 0.2557  decode.d4.loss_cls: 0.0515  decode.d4.loss_mask: 0.2104  decode.d4.loss_dice: 0.2493  decode.d5.loss_cls: 0.0328  decode.d5.loss_mask: 0.2100  decode.d5.loss_dice: 0.2494  decode.d6.loss_cls: 0.0720  decode.d6.loss_mask: 0.2135  decode.d6.loss_dice: 0.2647  decode.d7.loss_cls: 0.0301  decode.d7.loss_mask: 0.2115  decode.d7.loss_dice: 0.2558  decode.d8.loss_cls: 0.0624  decode.d8.loss_mask: 0.2132  decode.d8.loss_dice: 0.2478
08/06 12:23:09 - mmengine - INFO - Iter(train) [ 73200/320000]  base_lr: 7.9155e-05 lr: 7.9155e-06  eta: 1 day, 9:50:54  time: 0.4996  data_time: 0.0117  memory: 5895  grad_norm: 107.4347  loss: 6.7587  decode.loss_cls: 0.1279  decode.loss_mask: 0.2354  decode.loss_dice: 0.2719  decode.d0.loss_cls: 0.7869  decode.d0.loss_mask: 0.2434  decode.d0.loss_dice: 0.2906  decode.d1.loss_cls: 0.1058  decode.d1.loss_mask: 0.2358  decode.d1.loss_dice: 0.2583  decode.d2.loss_cls: 0.0673  decode.d2.loss_mask: 0.2353  decode.d2.loss_dice: 0.2293  decode.d3.loss_cls: 0.1005  decode.d3.loss_mask: 0.2359  decode.d3.loss_dice: 0.2808  decode.d4.loss_cls: 0.1156  decode.d4.loss_mask: 0.2368  decode.d4.loss_dice: 0.2308  decode.d5.loss_cls: 0.1057  decode.d5.loss_mask: 0.2353  decode.d5.loss_dice: 0.2643  decode.d6.loss_cls: 0.1273  decode.d6.loss_mask: 0.2363  decode.d6.loss_dice: 0.2591  decode.d7.loss_cls: 0.1182  decode.d7.loss_mask: 0.2360  decode.d7.loss_dice: 0.2786  decode.d8.loss_cls: 0.1112  decode.d8.loss_mask: 0.2388  decode.d8.loss_dice: 0.2597
08/06 12:23:34 - mmengine - INFO - Iter(train) [ 73250/320000]  base_lr: 7.9140e-05 lr: 7.9140e-06  eta: 1 day, 9:50:30  time: 0.4993  data_time: 0.0116  memory: 5911  grad_norm: 49.4487  loss: 6.6839  decode.loss_cls: 0.0472  decode.loss_mask: 0.2619  decode.loss_dice: 0.2476  decode.d0.loss_cls: 0.9576  decode.d0.loss_mask: 0.2588  decode.d0.loss_dice: 0.2511  decode.d1.loss_cls: 0.1036  decode.d1.loss_mask: 0.2565  decode.d1.loss_dice: 0.2416  decode.d2.loss_cls: 0.1088  decode.d2.loss_mask: 0.2676  decode.d2.loss_dice: 0.2454  decode.d3.loss_cls: 0.1008  decode.d3.loss_mask: 0.2569  decode.d3.loss_dice: 0.2612  decode.d4.loss_cls: 0.0489  decode.d4.loss_mask: 0.2617  decode.d4.loss_dice: 0.2478  decode.d5.loss_cls: 0.0745  decode.d5.loss_mask: 0.2602  decode.d5.loss_dice: 0.2404  decode.d6.loss_cls: 0.0343  decode.d6.loss_mask: 0.2606  decode.d6.loss_dice: 0.2527  decode.d7.loss_cls: 0.0400  decode.d7.loss_mask: 0.2619  decode.d7.loss_dice: 0.2535  decode.d8.loss_cls: 0.0720  decode.d8.loss_mask: 0.2632  decode.d8.loss_dice: 0.2455
08/06 12:23:59 - mmengine - INFO - Iter(train) [ 73300/320000]  base_lr: 7.9126e-05 lr: 7.9126e-06  eta: 1 day, 9:50:06  time: 0.4981  data_time: 0.0113  memory: 5911  grad_norm: 89.8805  loss: 6.8382  decode.loss_cls: 0.0759  decode.loss_mask: 0.2780  decode.loss_dice: 0.2781  decode.d0.loss_cls: 0.8442  decode.d0.loss_mask: 0.2810  decode.d0.loss_dice: 0.2748  decode.d1.loss_cls: 0.0500  decode.d1.loss_mask: 0.2799  decode.d1.loss_dice: 0.2791  decode.d2.loss_cls: 0.0598  decode.d2.loss_mask: 0.2781  decode.d2.loss_dice: 0.2929  decode.d3.loss_cls: 0.0259  decode.d3.loss_mask: 0.2764  decode.d3.loss_dice: 0.2792  decode.d4.loss_cls: 0.0268  decode.d4.loss_mask: 0.2808  decode.d4.loss_dice: 0.2749  decode.d5.loss_cls: 0.0248  decode.d5.loss_mask: 0.2783  decode.d5.loss_dice: 0.2806  decode.d6.loss_cls: 0.0617  decode.d6.loss_mask: 0.2783  decode.d6.loss_dice: 0.2682  decode.d7.loss_cls: 0.0310  decode.d7.loss_mask: 0.2764  decode.d7.loss_dice: 0.2681  decode.d8.loss_cls: 0.0860  decode.d8.loss_mask: 0.2758  decode.d8.loss_dice: 0.2731
08/06 12:24:24 - mmengine - INFO - Iter(train) [ 73350/320000]  base_lr: 7.9111e-05 lr: 7.9111e-06  eta: 1 day, 9:49:42  time: 0.4984  data_time: 0.0114  memory: 5911  grad_norm: 57.1261  loss: 7.9434  decode.loss_cls: 0.3239  decode.loss_mask: 0.1977  decode.loss_dice: 0.2935  decode.d0.loss_cls: 0.9858  decode.d0.loss_mask: 0.1836  decode.d0.loss_dice: 0.2283  decode.d1.loss_cls: 0.2391  decode.d1.loss_mask: 0.1956  decode.d1.loss_dice: 0.2516  decode.d2.loss_cls: 0.2562  decode.d2.loss_mask: 0.1930  decode.d2.loss_dice: 0.2285  decode.d3.loss_cls: 0.2907  decode.d3.loss_mask: 0.1917  decode.d3.loss_dice: 0.2096  decode.d4.loss_cls: 0.2647  decode.d4.loss_mask: 0.1951  decode.d4.loss_dice: 0.2400  decode.d5.loss_cls: 0.2757  decode.d5.loss_mask: 0.1993  decode.d5.loss_dice: 0.2550  decode.d6.loss_cls: 0.3071  decode.d6.loss_mask: 0.1924  decode.d6.loss_dice: 0.2694  decode.d7.loss_cls: 0.2570  decode.d7.loss_mask: 0.1940  decode.d7.loss_dice: 0.2794  decode.d8.loss_cls: 0.2810  decode.d8.loss_mask: 0.1895  decode.d8.loss_dice: 0.2751
08/06 12:24:49 - mmengine - INFO - Iter(train) [ 73400/320000]  base_lr: 7.9097e-05 lr: 7.9097e-06  eta: 1 day, 9:49:18  time: 0.4986  data_time: 0.0113  memory: 5895  grad_norm: 89.8538  loss: 6.8470  decode.loss_cls: 0.1345  decode.loss_mask: 0.2437  decode.loss_dice: 0.2527  decode.d0.loss_cls: 0.9524  decode.d0.loss_mask: 0.2416  decode.d0.loss_dice: 0.2367  decode.d1.loss_cls: 0.1069  decode.d1.loss_mask: 0.2411  decode.d1.loss_dice: 0.2410  decode.d2.loss_cls: 0.0645  decode.d2.loss_mask: 0.2412  decode.d2.loss_dice: 0.2591  decode.d3.loss_cls: 0.1163  decode.d3.loss_mask: 0.2405  decode.d3.loss_dice: 0.2301  decode.d4.loss_cls: 0.1207  decode.d4.loss_mask: 0.2416  decode.d4.loss_dice: 0.2351  decode.d5.loss_cls: 0.1269  decode.d5.loss_mask: 0.2446  decode.d5.loss_dice: 0.2546  decode.d6.loss_cls: 0.1537  decode.d6.loss_mask: 0.2413  decode.d6.loss_dice: 0.2381  decode.d7.loss_cls: 0.1311  decode.d7.loss_mask: 0.2425  decode.d7.loss_dice: 0.2423  decode.d8.loss_cls: 0.0902  decode.d8.loss_mask: 0.2430  decode.d8.loss_dice: 0.2389
08/06 12:25:14 - mmengine - INFO - Iter(train) [ 73450/320000]  base_lr: 7.9083e-05 lr: 7.9083e-06  eta: 1 day, 9:48:54  time: 0.4993  data_time: 0.0118  memory: 5894  grad_norm: 1200.8439  loss: 10.9626  decode.loss_cls: 0.1107  decode.loss_mask: 0.4723  decode.loss_dice: 0.3750  decode.d0.loss_cls: 1.0525  decode.d0.loss_mask: 0.5024  decode.d0.loss_dice: 0.3977  decode.d1.loss_cls: 0.3369  decode.d1.loss_mask: 0.3983  decode.d1.loss_dice: 0.3486  decode.d2.loss_cls: 0.2176  decode.d2.loss_mask: 0.4057  decode.d2.loss_dice: 0.3674  decode.d3.loss_cls: 0.1966  decode.d3.loss_mask: 0.3993  decode.d3.loss_dice: 0.3461  decode.d4.loss_cls: 0.2329  decode.d4.loss_mask: 0.3900  decode.d4.loss_dice: 0.3447  decode.d5.loss_cls: 0.1098  decode.d5.loss_mask: 0.4836  decode.d5.loss_dice: 0.3816  decode.d6.loss_cls: 0.1913  decode.d6.loss_mask: 0.4799  decode.d6.loss_dice: 0.4029  decode.d7.loss_cls: 0.1429  decode.d7.loss_mask: 0.4718  decode.d7.loss_dice: 0.3691  decode.d8.loss_cls: 0.2112  decode.d8.loss_mask: 0.4198  decode.d8.loss_dice: 0.4042
08/06 12:25:39 - mmengine - INFO - Iter(train) [ 73500/320000]  base_lr: 7.9068e-05 lr: 7.9068e-06  eta: 1 day, 9:48:30  time: 0.4987  data_time: 0.0115  memory: 5911  grad_norm: 80.2544  loss: 6.2892  decode.loss_cls: 0.0559  decode.loss_mask: 0.2369  decode.loss_dice: 0.2300  decode.d0.loss_cls: 0.8121  decode.d0.loss_mask: 0.2405  decode.d0.loss_dice: 0.2437  decode.d1.loss_cls: 0.1009  decode.d1.loss_mask: 0.2478  decode.d1.loss_dice: 0.2377  decode.d2.loss_cls: 0.0794  decode.d2.loss_mask: 0.2379  decode.d2.loss_dice: 0.2357  decode.d3.loss_cls: 0.0699  decode.d3.loss_mask: 0.2378  decode.d3.loss_dice: 0.2451  decode.d4.loss_cls: 0.0928  decode.d4.loss_mask: 0.2557  decode.d4.loss_dice: 0.2587  decode.d5.loss_cls: 0.1056  decode.d5.loss_mask: 0.2481  decode.d5.loss_dice: 0.2416  decode.d6.loss_cls: 0.0714  decode.d6.loss_mask: 0.2437  decode.d6.loss_dice: 0.2284  decode.d7.loss_cls: 0.0528  decode.d7.loss_mask: 0.2373  decode.d7.loss_dice: 0.2263  decode.d8.loss_cls: 0.0504  decode.d8.loss_mask: 0.2350  decode.d8.loss_dice: 0.2299
08/06 12:26:04 - mmengine - INFO - Iter(train) [ 73550/320000]  base_lr: 7.9054e-05 lr: 7.9054e-06  eta: 1 day, 9:48:06  time: 0.4982  data_time: 0.0112  memory: 5911  grad_norm: 44.3542  loss: 5.6821  decode.loss_cls: 0.0145  decode.loss_mask: 0.2544  decode.loss_dice: 0.2290  decode.d0.loss_cls: 0.7469  decode.d0.loss_mask: 0.2567  decode.d0.loss_dice: 0.2293  decode.d1.loss_cls: 0.0155  decode.d1.loss_mask: 0.2559  decode.d1.loss_dice: 0.2284  decode.d2.loss_cls: 0.0089  decode.d2.loss_mask: 0.2541  decode.d2.loss_dice: 0.2299  decode.d3.loss_cls: 0.0095  decode.d3.loss_mask: 0.2502  decode.d3.loss_dice: 0.2321  decode.d4.loss_cls: 0.0071  decode.d4.loss_mask: 0.2558  decode.d4.loss_dice: 0.2330  decode.d5.loss_cls: 0.0080  decode.d5.loss_mask: 0.2528  decode.d5.loss_dice: 0.2258  decode.d6.loss_cls: 0.0110  decode.d6.loss_mask: 0.2520  decode.d6.loss_dice: 0.2340  decode.d7.loss_cls: 0.0096  decode.d7.loss_mask: 0.2508  decode.d7.loss_dice: 0.2293  decode.d8.loss_cls: 0.0098  decode.d8.loss_mask: 0.2547  decode.d8.loss_dice: 0.2330
08/06 12:26:29 - mmengine - INFO - Iter(train) [ 73600/320000]  base_lr: 7.9039e-05 lr: 7.9039e-06  eta: 1 day, 9:47:42  time: 0.4993  data_time: 0.0116  memory: 5894  grad_norm: 82.8975  loss: 6.7907  decode.loss_cls: 0.1530  decode.loss_mask: 0.1910  decode.loss_dice: 0.2417  decode.d0.loss_cls: 0.8850  decode.d0.loss_mask: 0.1961  decode.d0.loss_dice: 0.2599  decode.d1.loss_cls: 0.1942  decode.d1.loss_mask: 0.1959  decode.d1.loss_dice: 0.2286  decode.d2.loss_cls: 0.2068  decode.d2.loss_mask: 0.1953  decode.d2.loss_dice: 0.2451  decode.d3.loss_cls: 0.1847  decode.d3.loss_mask: 0.1972  decode.d3.loss_dice: 0.2485  decode.d4.loss_cls: 0.1790  decode.d4.loss_mask: 0.1936  decode.d4.loss_dice: 0.2306  decode.d5.loss_cls: 0.1801  decode.d5.loss_mask: 0.1931  decode.d5.loss_dice: 0.2323  decode.d6.loss_cls: 0.1475  decode.d6.loss_mask: 0.1934  decode.d6.loss_dice: 0.2403  decode.d7.loss_cls: 0.1522  decode.d7.loss_mask: 0.1935  decode.d7.loss_dice: 0.2470  decode.d8.loss_cls: 0.1376  decode.d8.loss_mask: 0.1925  decode.d8.loss_dice: 0.2550
08/06 12:26:54 - mmengine - INFO - Iter(train) [ 73650/320000]  base_lr: 7.9025e-05 lr: 7.9025e-06  eta: 1 day, 9:47:19  time: 0.4979  data_time: 0.0115  memory: 5891  grad_norm: 90.4600  loss: 5.5110  decode.loss_cls: 0.0282  decode.loss_mask: 0.2141  decode.loss_dice: 0.2090  decode.d0.loss_cls: 0.7707  decode.d0.loss_mask: 0.2189  decode.d0.loss_dice: 0.2368  decode.d1.loss_cls: 0.0764  decode.d1.loss_mask: 0.2140  decode.d1.loss_dice: 0.2242  decode.d2.loss_cls: 0.0798  decode.d2.loss_mask: 0.2150  decode.d2.loss_dice: 0.2110  decode.d3.loss_cls: 0.0387  decode.d3.loss_mask: 0.2120  decode.d3.loss_dice: 0.2130  decode.d4.loss_cls: 0.0642  decode.d4.loss_mask: 0.2151  decode.d4.loss_dice: 0.2108  decode.d5.loss_cls: 0.0551  decode.d5.loss_mask: 0.2131  decode.d5.loss_dice: 0.2126  decode.d6.loss_cls: 0.0296  decode.d6.loss_mask: 0.2111  decode.d6.loss_dice: 0.2142  decode.d7.loss_cls: 0.0269  decode.d7.loss_mask: 0.2130  decode.d7.loss_dice: 0.2133  decode.d8.loss_cls: 0.0394  decode.d8.loss_mask: 0.2138  decode.d8.loss_dice: 0.2169
08/06 12:27:19 - mmengine - INFO - Iter(train) [ 73700/320000]  base_lr: 7.9010e-05 lr: 7.9010e-06  eta: 1 day, 9:46:55  time: 0.4995  data_time: 0.0115  memory: 5895  grad_norm: 62.7469  loss: 5.2337  decode.loss_cls: 0.0435  decode.loss_mask: 0.1849  decode.loss_dice: 0.2117  decode.d0.loss_cls: 0.8844  decode.d0.loss_mask: 0.1868  decode.d0.loss_dice: 0.2064  decode.d1.loss_cls: 0.1280  decode.d1.loss_mask: 0.1855  decode.d1.loss_dice: 0.2294  decode.d2.loss_cls: 0.0260  decode.d2.loss_mask: 0.1821  decode.d2.loss_dice: 0.2114  decode.d3.loss_cls: 0.0260  decode.d3.loss_mask: 0.1811  decode.d3.loss_dice: 0.2111  decode.d4.loss_cls: 0.0522  decode.d4.loss_mask: 0.1823  decode.d4.loss_dice: 0.2060  decode.d5.loss_cls: 0.0265  decode.d5.loss_mask: 0.1802  decode.d5.loss_dice: 0.2107  decode.d6.loss_cls: 0.0390  decode.d6.loss_mask: 0.1822  decode.d6.loss_dice: 0.2107  decode.d7.loss_cls: 0.0352  decode.d7.loss_mask: 0.1806  decode.d7.loss_dice: 0.2099  decode.d8.loss_cls: 0.0298  decode.d8.loss_mask: 0.1830  decode.d8.loss_dice: 0.2074
08/06 12:27:44 - mmengine - INFO - Iter(train) [ 73750/320000]  base_lr: 7.8996e-05 lr: 7.8996e-06  eta: 1 day, 9:46:31  time: 0.4976  data_time: 0.0115  memory: 5890  grad_norm: 341.3669  loss: 6.5945  decode.loss_cls: 0.0385  decode.loss_mask: 0.2530  decode.loss_dice: 0.2593  decode.d0.loss_cls: 0.9085  decode.d0.loss_mask: 0.2443  decode.d0.loss_dice: 0.2520  decode.d1.loss_cls: 0.1024  decode.d1.loss_mask: 0.2746  decode.d1.loss_dice: 0.2658  decode.d2.loss_cls: 0.0230  decode.d2.loss_mask: 0.2989  decode.d2.loss_dice: 0.2654  decode.d3.loss_cls: 0.0354  decode.d3.loss_mask: 0.2721  decode.d3.loss_dice: 0.2598  decode.d4.loss_cls: 0.0497  decode.d4.loss_mask: 0.2732  decode.d4.loss_dice: 0.2631  decode.d5.loss_cls: 0.0474  decode.d5.loss_mask: 0.2656  decode.d5.loss_dice: 0.2675  decode.d6.loss_cls: 0.0455  decode.d6.loss_mask: 0.2572  decode.d6.loss_dice: 0.2605  decode.d7.loss_cls: 0.0403  decode.d7.loss_mask: 0.2559  decode.d7.loss_dice: 0.2650  decode.d8.loss_cls: 0.0494  decode.d8.loss_mask: 0.2470  decode.d8.loss_dice: 0.2543
08/06 12:28:09 - mmengine - INFO - Iter(train) [ 73800/320000]  base_lr: 7.8982e-05 lr: 7.8982e-06  eta: 1 day, 9:46:07  time: 0.4983  data_time: 0.0115  memory: 5911  grad_norm: 147.4970  loss: 9.9805  decode.loss_cls: 0.2804  decode.loss_mask: 0.2816  decode.loss_dice: 0.3412  decode.d0.loss_cls: 1.0358  decode.d0.loss_mask: 0.2511  decode.d0.loss_dice: 0.3571  decode.d1.loss_cls: 0.3906  decode.d1.loss_mask: 0.2491  decode.d1.loss_dice: 0.3317  decode.d2.loss_cls: 0.2404  decode.d2.loss_mask: 0.2983  decode.d2.loss_dice: 0.3357  decode.d3.loss_cls: 0.2443  decode.d3.loss_mask: 0.2795  decode.d3.loss_dice: 0.3341  decode.d4.loss_cls: 0.2861  decode.d4.loss_mask: 0.2923  decode.d4.loss_dice: 0.3812  decode.d5.loss_cls: 0.2651  decode.d5.loss_mask: 0.3076  decode.d5.loss_dice: 0.3955  decode.d6.loss_cls: 0.3125  decode.d6.loss_mask: 0.2890  decode.d6.loss_dice: 0.3692  decode.d7.loss_cls: 0.2961  decode.d7.loss_mask: 0.2751  decode.d7.loss_dice: 0.3560  decode.d8.loss_cls: 0.2893  decode.d8.loss_mask: 0.2758  decode.d8.loss_dice: 0.3388
08/06 12:28:34 - mmengine - INFO - Iter(train) [ 73850/320000]  base_lr: 7.8967e-05 lr: 7.8967e-06  eta: 1 day, 9:45:43  time: 0.4990  data_time: 0.0115  memory: 5911  grad_norm: 116.0750  loss: 8.0090  decode.loss_cls: 0.2087  decode.loss_mask: 0.2399  decode.loss_dice: 0.3112  decode.d0.loss_cls: 0.9904  decode.d0.loss_mask: 0.2347  decode.d0.loss_dice: 0.2659  decode.d1.loss_cls: 0.1553  decode.d1.loss_mask: 0.2367  decode.d1.loss_dice: 0.2947  decode.d2.loss_cls: 0.1976  decode.d2.loss_mask: 0.2342  decode.d2.loss_dice: 0.2481  decode.d3.loss_cls: 0.1882  decode.d3.loss_mask: 0.2332  decode.d3.loss_dice: 0.2501  decode.d4.loss_cls: 0.2073  decode.d4.loss_mask: 0.2373  decode.d4.loss_dice: 0.2628  decode.d5.loss_cls: 0.1839  decode.d5.loss_mask: 0.2343  decode.d5.loss_dice: 0.2647  decode.d6.loss_cls: 0.2629  decode.d6.loss_mask: 0.2376  decode.d6.loss_dice: 0.2859  decode.d7.loss_cls: 0.2098  decode.d7.loss_mask: 0.2415  decode.d7.loss_dice: 0.3014  decode.d8.loss_cls: 0.2297  decode.d8.loss_mask: 0.2484  decode.d8.loss_dice: 0.3128
08/06 12:28:59 - mmengine - INFO - Iter(train) [ 73900/320000]  base_lr: 7.8953e-05 lr: 7.8953e-06  eta: 1 day, 9:45:19  time: 0.4986  data_time: 0.0114  memory: 5928  grad_norm: 57.2549  loss: 5.9360  decode.loss_cls: 0.0492  decode.loss_mask: 0.1837  decode.loss_dice: 0.2718  decode.d0.loss_cls: 0.7781  decode.d0.loss_mask: 0.1875  decode.d0.loss_dice: 0.2735  decode.d1.loss_cls: 0.0981  decode.d1.loss_mask: 0.1855  decode.d1.loss_dice: 0.2749  decode.d2.loss_cls: 0.0566  decode.d2.loss_mask: 0.1875  decode.d2.loss_dice: 0.2611  decode.d3.loss_cls: 0.0765  decode.d3.loss_mask: 0.1834  decode.d3.loss_dice: 0.2605  decode.d4.loss_cls: 0.0538  decode.d4.loss_mask: 0.1852  decode.d4.loss_dice: 0.2574  decode.d5.loss_cls: 0.0510  decode.d5.loss_mask: 0.1849  decode.d5.loss_dice: 0.2790  decode.d6.loss_cls: 0.0764  decode.d6.loss_mask: 0.1850  decode.d6.loss_dice: 0.2874  decode.d7.loss_cls: 0.0652  decode.d7.loss_mask: 0.1846  decode.d7.loss_dice: 0.2696  decode.d8.loss_cls: 0.0561  decode.d8.loss_mask: 0.1865  decode.d8.loss_dice: 0.2861
08/06 12:29:23 - mmengine - INFO - Iter(train) [ 73950/320000]  base_lr: 7.8938e-05 lr: 7.8938e-06  eta: 1 day, 9:44:56  time: 0.4979  data_time: 0.0116  memory: 5894  grad_norm: 48.2134  loss: 6.3341  decode.loss_cls: 0.0426  decode.loss_mask: 0.2205  decode.loss_dice: 0.2772  decode.d0.loss_cls: 0.8317  decode.d0.loss_mask: 0.2182  decode.d0.loss_dice: 0.2761  decode.d1.loss_cls: 0.0904  decode.d1.loss_mask: 0.2216  decode.d1.loss_dice: 0.2744  decode.d2.loss_cls: 0.0350  decode.d2.loss_mask: 0.2164  decode.d2.loss_dice: 0.2768  decode.d3.loss_cls: 0.0641  decode.d3.loss_mask: 0.2209  decode.d3.loss_dice: 0.2662  decode.d4.loss_cls: 0.0361  decode.d4.loss_mask: 0.2191  decode.d4.loss_dice: 0.2798  decode.d5.loss_cls: 0.0646  decode.d5.loss_mask: 0.2222  decode.d5.loss_dice: 0.2841  decode.d6.loss_cls: 0.0624  decode.d6.loss_mask: 0.2198  decode.d6.loss_dice: 0.2751  decode.d7.loss_cls: 0.0949  decode.d7.loss_mask: 0.2220  decode.d7.loss_dice: 0.2630  decode.d8.loss_cls: 0.0709  decode.d8.loss_mask: 0.2176  decode.d8.loss_dice: 0.2706
08/06 12:29:48 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 12:29:48 - mmengine - INFO - Iter(train) [ 74000/320000]  base_lr: 7.8924e-05 lr: 7.8924e-06  eta: 1 day, 9:44:32  time: 0.4976  data_time: 0.0114  memory: 5895  grad_norm: 68.8104  loss: 6.9483  decode.loss_cls: 0.1574  decode.loss_mask: 0.2689  decode.loss_dice: 0.2375  decode.d0.loss_cls: 0.8279  decode.d0.loss_mask: 0.2686  decode.d0.loss_dice: 0.2248  decode.d1.loss_cls: 0.1435  decode.d1.loss_mask: 0.2679  decode.d1.loss_dice: 0.2250  decode.d2.loss_cls: 0.1397  decode.d2.loss_mask: 0.2669  decode.d2.loss_dice: 0.2132  decode.d3.loss_cls: 0.1324  decode.d3.loss_mask: 0.2679  decode.d3.loss_dice: 0.2231  decode.d4.loss_cls: 0.1074  decode.d4.loss_mask: 0.2687  decode.d4.loss_dice: 0.2228  decode.d5.loss_cls: 0.1112  decode.d5.loss_mask: 0.2694  decode.d5.loss_dice: 0.2181  decode.d6.loss_cls: 0.1252  decode.d6.loss_mask: 0.2676  decode.d6.loss_dice: 0.2370  decode.d7.loss_cls: 0.1224  decode.d7.loss_mask: 0.2704  decode.d7.loss_dice: 0.2158  decode.d8.loss_cls: 0.1516  decode.d8.loss_mask: 0.2658  decode.d8.loss_dice: 0.2306
08/06 12:30:13 - mmengine - INFO - Iter(train) [ 74050/320000]  base_lr: 7.8909e-05 lr: 7.8909e-06  eta: 1 day, 9:44:08  time: 0.4976  data_time: 0.0113  memory: 5911  grad_norm: 58.3968  loss: 8.1781  decode.loss_cls: 0.1521  decode.loss_mask: 0.3165  decode.loss_dice: 0.3012  decode.d0.loss_cls: 0.9259  decode.d0.loss_mask: 0.3196  decode.d0.loss_dice: 0.2798  decode.d1.loss_cls: 0.1553  decode.d1.loss_mask: 0.3108  decode.d1.loss_dice: 0.2914  decode.d2.loss_cls: 0.1347  decode.d2.loss_mask: 0.3063  decode.d2.loss_dice: 0.2787  decode.d3.loss_cls: 0.1241  decode.d3.loss_mask: 0.3103  decode.d3.loss_dice: 0.2693  decode.d4.loss_cls: 0.1304  decode.d4.loss_mask: 0.3107  decode.d4.loss_dice: 0.2702  decode.d5.loss_cls: 0.1139  decode.d5.loss_mask: 0.3168  decode.d5.loss_dice: 0.2949  decode.d6.loss_cls: 0.1331  decode.d6.loss_mask: 0.3096  decode.d6.loss_dice: 0.3049  decode.d7.loss_cls: 0.1472  decode.d7.loss_mask: 0.3118  decode.d7.loss_dice: 0.2795  decode.d8.loss_cls: 0.1504  decode.d8.loss_mask: 0.3287  decode.d8.loss_dice: 0.2998
08/06 12:30:38 - mmengine - INFO - Iter(train) [ 74100/320000]  base_lr: 7.8895e-05 lr: 7.8895e-06  eta: 1 day, 9:43:44  time: 0.4982  data_time: 0.0114  memory: 5894  grad_norm: 66.0919  loss: 6.5773  decode.loss_cls: 0.0295  decode.loss_mask: 0.2639  decode.loss_dice: 0.2823  decode.d0.loss_cls: 0.7471  decode.d0.loss_mask: 0.2700  decode.d0.loss_dice: 0.2881  decode.d1.loss_cls: 0.0257  decode.d1.loss_mask: 0.2705  decode.d1.loss_dice: 0.2925  decode.d2.loss_cls: 0.0451  decode.d2.loss_mask: 0.2645  decode.d2.loss_dice: 0.2877  decode.d3.loss_cls: 0.0424  decode.d3.loss_mask: 0.2634  decode.d3.loss_dice: 0.2834  decode.d4.loss_cls: 0.0426  decode.d4.loss_mask: 0.2641  decode.d4.loss_dice: 0.2842  decode.d5.loss_cls: 0.0348  decode.d5.loss_mask: 0.2609  decode.d5.loss_dice: 0.2891  decode.d6.loss_cls: 0.0311  decode.d6.loss_mask: 0.2630  decode.d6.loss_dice: 0.2835  decode.d7.loss_cls: 0.0315  decode.d7.loss_mask: 0.2648  decode.d7.loss_dice: 0.2807  decode.d8.loss_cls: 0.0339  decode.d8.loss_mask: 0.2678  decode.d8.loss_dice: 0.2894
08/06 12:31:03 - mmengine - INFO - Iter(train) [ 74150/320000]  base_lr: 7.8880e-05 lr: 7.8880e-06  eta: 1 day, 9:43:20  time: 0.4974  data_time: 0.0113  memory: 5894  grad_norm: 110.9051  loss: 8.2976  decode.loss_cls: 0.1339  decode.loss_mask: 0.2968  decode.loss_dice: 0.3081  decode.d0.loss_cls: 0.9480  decode.d0.loss_mask: 0.2934  decode.d0.loss_dice: 0.3198  decode.d1.loss_cls: 0.1985  decode.d1.loss_mask: 0.2963  decode.d1.loss_dice: 0.3061  decode.d2.loss_cls: 0.1135  decode.d2.loss_mask: 0.2915  decode.d2.loss_dice: 0.3152  decode.d3.loss_cls: 0.1733  decode.d3.loss_mask: 0.2942  decode.d3.loss_dice: 0.2993  decode.d4.loss_cls: 0.2025  decode.d4.loss_mask: 0.2922  decode.d4.loss_dice: 0.2854  decode.d5.loss_cls: 0.1441  decode.d5.loss_mask: 0.2998  decode.d5.loss_dice: 0.2953  decode.d6.loss_cls: 0.1344  decode.d6.loss_mask: 0.2932  decode.d6.loss_dice: 0.2873  decode.d7.loss_cls: 0.1326  decode.d7.loss_mask: 0.2976  decode.d7.loss_dice: 0.3268  decode.d8.loss_cls: 0.1354  decode.d8.loss_mask: 0.2934  decode.d8.loss_dice: 0.2896
08/06 12:31:28 - mmengine - INFO - Iter(train) [ 74200/320000]  base_lr: 7.8866e-05 lr: 7.8866e-06  eta: 1 day, 9:42:56  time: 0.4979  data_time: 0.0114  memory: 5876  grad_norm: 129.9972  loss: 6.6736  decode.loss_cls: 0.0991  decode.loss_mask: 0.2191  decode.loss_dice: 0.2720  decode.d0.loss_cls: 0.8445  decode.d0.loss_mask: 0.2219  decode.d0.loss_dice: 0.2675  decode.d1.loss_cls: 0.1353  decode.d1.loss_mask: 0.2243  decode.d1.loss_dice: 0.2618  decode.d2.loss_cls: 0.0996  decode.d2.loss_mask: 0.2221  decode.d2.loss_dice: 0.2752  decode.d3.loss_cls: 0.1105  decode.d3.loss_mask: 0.2152  decode.d3.loss_dice: 0.2507  decode.d4.loss_cls: 0.1056  decode.d4.loss_mask: 0.2208  decode.d4.loss_dice: 0.2562  decode.d5.loss_cls: 0.1078  decode.d5.loss_mask: 0.2224  decode.d5.loss_dice: 0.2756  decode.d6.loss_cls: 0.1125  decode.d6.loss_mask: 0.2203  decode.d6.loss_dice: 0.2655  decode.d7.loss_cls: 0.1045  decode.d7.loss_mask: 0.2225  decode.d7.loss_dice: 0.2587  decode.d8.loss_cls: 0.0883  decode.d8.loss_mask: 0.2227  decode.d8.loss_dice: 0.2714
08/06 12:31:53 - mmengine - INFO - Iter(train) [ 74250/320000]  base_lr: 7.8852e-05 lr: 7.8852e-06  eta: 1 day, 9:42:32  time: 0.4976  data_time: 0.0116  memory: 5891  grad_norm: 154.6071  loss: 8.7596  decode.loss_cls: 0.2385  decode.loss_mask: 0.2596  decode.loss_dice: 0.3072  decode.d0.loss_cls: 0.9797  decode.d0.loss_mask: 0.2659  decode.d0.loss_dice: 0.3416  decode.d1.loss_cls: 0.2404  decode.d1.loss_mask: 0.2639  decode.d1.loss_dice: 0.2909  decode.d2.loss_cls: 0.2431  decode.d2.loss_mask: 0.2605  decode.d2.loss_dice: 0.3139  decode.d3.loss_cls: 0.2046  decode.d3.loss_mask: 0.2621  decode.d3.loss_dice: 0.3097  decode.d4.loss_cls: 0.2125  decode.d4.loss_mask: 0.2644  decode.d4.loss_dice: 0.3260  decode.d5.loss_cls: 0.2376  decode.d5.loss_mask: 0.2616  decode.d5.loss_dice: 0.3087  decode.d6.loss_cls: 0.2101  decode.d6.loss_mask: 0.2618  decode.d6.loss_dice: 0.3240  decode.d7.loss_cls: 0.2199  decode.d7.loss_mask: 0.2596  decode.d7.loss_dice: 0.3110  decode.d8.loss_cls: 0.2205  decode.d8.loss_mask: 0.2604  decode.d8.loss_dice: 0.3001
08/06 12:32:18 - mmengine - INFO - Iter(train) [ 74300/320000]  base_lr: 7.8837e-05 lr: 7.8837e-06  eta: 1 day, 9:42:08  time: 0.4975  data_time: 0.0113  memory: 5911  grad_norm: 70.3371  loss: 6.0517  decode.loss_cls: 0.0483  decode.loss_mask: 0.1728  decode.loss_dice: 0.2592  decode.d0.loss_cls: 0.7632  decode.d0.loss_mask: 0.1747  decode.d0.loss_dice: 0.2627  decode.d1.loss_cls: 0.0932  decode.d1.loss_mask: 0.1764  decode.d1.loss_dice: 0.2593  decode.d2.loss_cls: 0.1992  decode.d2.loss_mask: 0.1728  decode.d2.loss_dice: 0.2442  decode.d3.loss_cls: 0.0883  decode.d3.loss_mask: 0.1761  decode.d3.loss_dice: 0.2553  decode.d4.loss_cls: 0.1238  decode.d4.loss_mask: 0.1775  decode.d4.loss_dice: 0.3137  decode.d5.loss_cls: 0.1099  decode.d5.loss_mask: 0.1770  decode.d5.loss_dice: 0.2561  decode.d6.loss_cls: 0.0875  decode.d6.loss_mask: 0.1738  decode.d6.loss_dice: 0.2640  decode.d7.loss_cls: 0.0719  decode.d7.loss_mask: 0.1757  decode.d7.loss_dice: 0.2650  decode.d8.loss_cls: 0.0757  decode.d8.loss_mask: 0.1757  decode.d8.loss_dice: 0.2586
08/06 12:32:43 - mmengine - INFO - Iter(train) [ 74350/320000]  base_lr: 7.8823e-05 lr: 7.8823e-06  eta: 1 day, 9:41:44  time: 0.4979  data_time: 0.0116  memory: 5894  grad_norm: 179.2378  loss: 8.0830  decode.loss_cls: 0.1881  decode.loss_mask: 0.2494  decode.loss_dice: 0.3107  decode.d0.loss_cls: 0.9724  decode.d0.loss_mask: 0.2429  decode.d0.loss_dice: 0.2982  decode.d1.loss_cls: 0.1833  decode.d1.loss_mask: 0.2459  decode.d1.loss_dice: 0.2811  decode.d2.loss_cls: 0.2479  decode.d2.loss_mask: 0.2432  decode.d2.loss_dice: 0.2850  decode.d3.loss_cls: 0.1499  decode.d3.loss_mask: 0.2398  decode.d3.loss_dice: 0.2888  decode.d4.loss_cls: 0.2313  decode.d4.loss_mask: 0.2411  decode.d4.loss_dice: 0.3050  decode.d5.loss_cls: 0.2049  decode.d5.loss_mask: 0.2464  decode.d5.loss_dice: 0.3152  decode.d6.loss_cls: 0.1974  decode.d6.loss_mask: 0.2385  decode.d6.loss_dice: 0.2807  decode.d7.loss_cls: 0.1282  decode.d7.loss_mask: 0.2423  decode.d7.loss_dice: 0.3011  decode.d8.loss_cls: 0.1830  decode.d8.loss_mask: 0.2404  decode.d8.loss_dice: 0.3011
08/06 12:33:08 - mmengine - INFO - Iter(train) [ 74400/320000]  base_lr: 7.8808e-05 lr: 7.8808e-06  eta: 1 day, 9:41:20  time: 0.4981  data_time: 0.0117  memory: 5894  grad_norm: 202.2630  loss: 7.0047  decode.loss_cls: 0.0297  decode.loss_mask: 0.2861  decode.loss_dice: 0.2843  decode.d0.loss_cls: 0.9349  decode.d0.loss_mask: 0.2001  decode.d0.loss_dice: 0.2782  decode.d1.loss_cls: 0.1728  decode.d1.loss_mask: 0.2245  decode.d1.loss_dice: 0.2850  decode.d2.loss_cls: 0.1332  decode.d2.loss_mask: 0.2079  decode.d2.loss_dice: 0.2764  decode.d3.loss_cls: 0.1654  decode.d3.loss_mask: 0.2128  decode.d3.loss_dice: 0.2799  decode.d4.loss_cls: 0.0207  decode.d4.loss_mask: 0.3028  decode.d4.loss_dice: 0.2839  decode.d5.loss_cls: 0.0231  decode.d5.loss_mask: 0.3016  decode.d5.loss_dice: 0.2602  decode.d6.loss_cls: 0.0718  decode.d6.loss_mask: 0.3044  decode.d6.loss_dice: 0.2714  decode.d7.loss_cls: 0.0226  decode.d7.loss_mask: 0.3118  decode.d7.loss_dice: 0.2789  decode.d8.loss_cls: 0.0249  decode.d8.loss_mask: 0.2892  decode.d8.loss_dice: 0.2661
08/06 12:33:33 - mmengine - INFO - Iter(train) [ 74450/320000]  base_lr: 7.8794e-05 lr: 7.8794e-06  eta: 1 day, 9:40:56  time: 0.4973  data_time: 0.0115  memory: 5911  grad_norm: 150.0281  loss: 6.7979  decode.loss_cls: 0.1169  decode.loss_mask: 0.2339  decode.loss_dice: 0.2198  decode.d0.loss_cls: 0.8365  decode.d0.loss_mask: 0.2342  decode.d0.loss_dice: 0.2241  decode.d1.loss_cls: 0.1419  decode.d1.loss_mask: 0.2311  decode.d1.loss_dice: 0.2330  decode.d2.loss_cls: 0.1688  decode.d2.loss_mask: 0.2325  decode.d2.loss_dice: 0.2269  decode.d3.loss_cls: 0.1852  decode.d3.loss_mask: 0.2322  decode.d3.loss_dice: 0.2240  decode.d4.loss_cls: 0.1708  decode.d4.loss_mask: 0.2361  decode.d4.loss_dice: 0.2174  decode.d5.loss_cls: 0.1667  decode.d5.loss_mask: 0.2365  decode.d5.loss_dice: 0.2252  decode.d6.loss_cls: 0.1839  decode.d6.loss_mask: 0.2316  decode.d6.loss_dice: 0.2261  decode.d7.loss_cls: 0.1437  decode.d7.loss_mask: 0.2319  decode.d7.loss_dice: 0.2210  decode.d8.loss_cls: 0.1206  decode.d8.loss_mask: 0.2294  decode.d8.loss_dice: 0.2161
08/06 12:33:58 - mmengine - INFO - Iter(train) [ 74500/320000]  base_lr: 7.8779e-05 lr: 7.8779e-06  eta: 1 day, 9:40:32  time: 0.4985  data_time: 0.0115  memory: 5894  grad_norm: 150.1906  loss: 5.5351  decode.loss_cls: 0.0154  decode.loss_mask: 0.2153  decode.loss_dice: 0.2333  decode.d0.loss_cls: 0.8099  decode.d0.loss_mask: 0.2161  decode.d0.loss_dice: 0.2613  decode.d1.loss_cls: 0.0173  decode.d1.loss_mask: 0.2170  decode.d1.loss_dice: 0.2625  decode.d2.loss_cls: 0.0102  decode.d2.loss_mask: 0.2163  decode.d2.loss_dice: 0.2422  decode.d3.loss_cls: 0.0149  decode.d3.loss_mask: 0.2152  decode.d3.loss_dice: 0.2387  decode.d4.loss_cls: 0.0123  decode.d4.loss_mask: 0.2162  decode.d4.loss_dice: 0.2525  decode.d5.loss_cls: 0.0135  decode.d5.loss_mask: 0.2149  decode.d5.loss_dice: 0.2297  decode.d6.loss_cls: 0.0158  decode.d6.loss_mask: 0.2164  decode.d6.loss_dice: 0.2378  decode.d7.loss_cls: 0.0110  decode.d7.loss_mask: 0.2155  decode.d7.loss_dice: 0.2445  decode.d8.loss_cls: 0.0105  decode.d8.loss_mask: 0.2179  decode.d8.loss_dice: 0.2411
08/06 12:34:22 - mmengine - INFO - Iter(train) [ 74550/320000]  base_lr: 7.8765e-05 lr: 7.8765e-06  eta: 1 day, 9:40:08  time: 0.4967  data_time: 0.0114  memory: 5891  grad_norm: 70.2280  loss: 6.4492  decode.loss_cls: 0.0781  decode.loss_mask: 0.2553  decode.loss_dice: 0.2307  decode.d0.loss_cls: 0.8494  decode.d0.loss_mask: 0.2619  decode.d0.loss_dice: 0.2600  decode.d1.loss_cls: 0.0885  decode.d1.loss_mask: 0.2628  decode.d1.loss_dice: 0.2387  decode.d2.loss_cls: 0.0620  decode.d2.loss_mask: 0.2582  decode.d2.loss_dice: 0.2340  decode.d3.loss_cls: 0.0584  decode.d3.loss_mask: 0.2553  decode.d3.loss_dice: 0.2326  decode.d4.loss_cls: 0.0543  decode.d4.loss_mask: 0.2545  decode.d4.loss_dice: 0.2446  decode.d5.loss_cls: 0.0747  decode.d5.loss_mask: 0.2577  decode.d5.loss_dice: 0.2408  decode.d6.loss_cls: 0.0836  decode.d6.loss_mask: 0.2570  decode.d6.loss_dice: 0.2377  decode.d7.loss_cls: 0.0535  decode.d7.loss_mask: 0.2565  decode.d7.loss_dice: 0.2376  decode.d8.loss_cls: 0.0871  decode.d8.loss_mask: 0.2589  decode.d8.loss_dice: 0.2249
08/06 12:34:47 - mmengine - INFO - Iter(train) [ 74600/320000]  base_lr: 7.8751e-05 lr: 7.8751e-06  eta: 1 day, 9:39:44  time: 0.4977  data_time: 0.0114  memory: 5911  grad_norm: 74.8143  loss: 7.2085  decode.loss_cls: 0.2067  decode.loss_mask: 0.2134  decode.loss_dice: 0.2527  decode.d0.loss_cls: 0.9239  decode.d0.loss_mask: 0.2087  decode.d0.loss_dice: 0.2666  decode.d1.loss_cls: 0.1948  decode.d1.loss_mask: 0.2068  decode.d1.loss_dice: 0.2353  decode.d2.loss_cls: 0.1558  decode.d2.loss_mask: 0.2132  decode.d2.loss_dice: 0.2425  decode.d3.loss_cls: 0.0966  decode.d3.loss_mask: 0.2139  decode.d3.loss_dice: 0.2512  decode.d4.loss_cls: 0.1903  decode.d4.loss_mask: 0.2098  decode.d4.loss_dice: 0.2511  decode.d5.loss_cls: 0.1702  decode.d5.loss_mask: 0.2055  decode.d5.loss_dice: 0.2412  decode.d6.loss_cls: 0.1746  decode.d6.loss_mask: 0.2101  decode.d6.loss_dice: 0.2629  decode.d7.loss_cls: 0.1917  decode.d7.loss_mask: 0.2159  decode.d7.loss_dice: 0.2755  decode.d8.loss_cls: 0.2257  decode.d8.loss_mask: 0.2195  decode.d8.loss_dice: 0.2822
08/06 12:35:12 - mmengine - INFO - Iter(train) [ 74650/320000]  base_lr: 7.8736e-05 lr: 7.8736e-06  eta: 1 day, 9:39:19  time: 0.4971  data_time: 0.0115  memory: 5931  grad_norm: 54.1743  loss: 6.2909  decode.loss_cls: 0.0063  decode.loss_mask: 0.2743  decode.loss_dice: 0.2808  decode.d0.loss_cls: 0.7392  decode.d0.loss_mask: 0.2831  decode.d0.loss_dice: 0.2702  decode.d1.loss_cls: 0.0140  decode.d1.loss_mask: 0.2797  decode.d1.loss_dice: 0.2869  decode.d2.loss_cls: 0.0162  decode.d2.loss_mask: 0.2738  decode.d2.loss_dice: 0.2532  decode.d3.loss_cls: 0.0159  decode.d3.loss_mask: 0.2747  decode.d3.loss_dice: 0.2604  decode.d4.loss_cls: 0.0108  decode.d4.loss_mask: 0.2779  decode.d4.loss_dice: 0.2746  decode.d5.loss_cls: 0.0074  decode.d5.loss_mask: 0.2713  decode.d5.loss_dice: 0.2600  decode.d6.loss_cls: 0.0102  decode.d6.loss_mask: 0.2743  decode.d6.loss_dice: 0.2652  decode.d7.loss_cls: 0.0092  decode.d7.loss_mask: 0.2768  decode.d7.loss_dice: 0.2675  decode.d8.loss_cls: 0.0075  decode.d8.loss_mask: 0.2709  decode.d8.loss_dice: 0.2788
08/06 12:35:37 - mmengine - INFO - Iter(train) [ 74700/320000]  base_lr: 7.8722e-05 lr: 7.8722e-06  eta: 1 day, 9:38:55  time: 0.4976  data_time: 0.0114  memory: 5894  grad_norm: 124.9291  loss: 7.2681  decode.loss_cls: 0.2791  decode.loss_mask: 0.1964  decode.loss_dice: 0.2415  decode.d0.loss_cls: 0.8681  decode.d0.loss_mask: 0.1993  decode.d0.loss_dice: 0.2587  decode.d1.loss_cls: 0.1338  decode.d1.loss_mask: 0.2031  decode.d1.loss_dice: 0.2584  decode.d2.loss_cls: 0.1109  decode.d2.loss_mask: 0.2035  decode.d2.loss_dice: 0.2607  decode.d3.loss_cls: 0.1830  decode.d3.loss_mask: 0.1988  decode.d3.loss_dice: 0.2580  decode.d4.loss_cls: 0.2253  decode.d4.loss_mask: 0.2013  decode.d4.loss_dice: 0.2609  decode.d5.loss_cls: 0.1827  decode.d5.loss_mask: 0.1980  decode.d5.loss_dice: 0.2438  decode.d6.loss_cls: 0.2072  decode.d6.loss_mask: 0.1999  decode.d6.loss_dice: 0.2531  decode.d7.loss_cls: 0.2407  decode.d7.loss_mask: 0.1990  decode.d7.loss_dice: 0.2571  decode.d8.loss_cls: 0.2891  decode.d8.loss_mask: 0.1998  decode.d8.loss_dice: 0.2569
08/06 12:36:02 - mmengine - INFO - Iter(train) [ 74750/320000]  base_lr: 7.8707e-05 lr: 7.8707e-06  eta: 1 day, 9:38:31  time: 0.4962  data_time: 0.0115  memory: 5894  grad_norm: 76.2076  loss: 7.2332  decode.loss_cls: 0.0878  decode.loss_mask: 0.2890  decode.loss_dice: 0.2439  decode.d0.loss_cls: 0.6504  decode.d0.loss_mask: 0.2960  decode.d0.loss_dice: 0.2605  decode.d1.loss_cls: 0.1122  decode.d1.loss_mask: 0.2914  decode.d1.loss_dice: 0.2669  decode.d2.loss_cls: 0.1146  decode.d2.loss_mask: 0.2899  decode.d2.loss_dice: 0.2488  decode.d3.loss_cls: 0.1775  decode.d3.loss_mask: 0.2914  decode.d3.loss_dice: 0.2501  decode.d4.loss_cls: 0.1200  decode.d4.loss_mask: 0.2850  decode.d4.loss_dice: 0.2614  decode.d5.loss_cls: 0.1337  decode.d5.loss_mask: 0.2880  decode.d5.loss_dice: 0.2880  decode.d6.loss_cls: 0.0978  decode.d6.loss_mask: 0.2870  decode.d6.loss_dice: 0.2701  decode.d7.loss_cls: 0.1095  decode.d7.loss_mask: 0.2877  decode.d7.loss_dice: 0.2571  decode.d8.loss_cls: 0.1173  decode.d8.loss_mask: 0.2860  decode.d8.loss_dice: 0.2744
08/06 12:36:27 - mmengine - INFO - Iter(train) [ 74800/320000]  base_lr: 7.8693e-05 lr: 7.8693e-06  eta: 1 day, 9:38:07  time: 0.4966  data_time: 0.0114  memory: 5911  grad_norm: 99.2479  loss: 6.0663  decode.loss_cls: 0.1101  decode.loss_mask: 0.2307  decode.loss_dice: 0.2158  decode.d0.loss_cls: 0.8735  decode.d0.loss_mask: 0.2270  decode.d0.loss_dice: 0.2090  decode.d1.loss_cls: 0.0450  decode.d1.loss_mask: 0.2493  decode.d1.loss_dice: 0.2164  decode.d2.loss_cls: 0.0550  decode.d2.loss_mask: 0.2487  decode.d2.loss_dice: 0.2158  decode.d3.loss_cls: 0.0418  decode.d3.loss_mask: 0.2598  decode.d3.loss_dice: 0.2167  decode.d4.loss_cls: 0.0976  decode.d4.loss_mask: 0.2233  decode.d4.loss_dice: 0.2091  decode.d5.loss_cls: 0.0950  decode.d5.loss_mask: 0.2257  decode.d5.loss_dice: 0.2114  decode.d6.loss_cls: 0.0797  decode.d6.loss_mask: 0.2249  decode.d6.loss_dice: 0.2109  decode.d7.loss_cls: 0.0960  decode.d7.loss_mask: 0.2227  decode.d7.loss_dice: 0.2096  decode.d8.loss_cls: 0.1149  decode.d8.loss_mask: 0.2228  decode.d8.loss_dice: 0.2079
08/06 12:36:52 - mmengine - INFO - Iter(train) [ 74850/320000]  base_lr: 7.8678e-05 lr: 7.8678e-06  eta: 1 day, 9:37:43  time: 0.4974  data_time: 0.0114  memory: 5928  grad_norm: 147.9094  loss: 7.8274  decode.loss_cls: 0.1497  decode.loss_mask: 0.2391  decode.loss_dice: 0.2630  decode.d0.loss_cls: 1.0625  decode.d0.loss_mask: 0.2552  decode.d0.loss_dice: 0.2824  decode.d1.loss_cls: 0.2518  decode.d1.loss_mask: 0.2450  decode.d1.loss_dice: 0.2948  decode.d2.loss_cls: 0.2115  decode.d2.loss_mask: 0.2466  decode.d2.loss_dice: 0.2705  decode.d3.loss_cls: 0.1260  decode.d3.loss_mask: 0.2432  decode.d3.loss_dice: 0.2848  decode.d4.loss_cls: 0.1471  decode.d4.loss_mask: 0.2469  decode.d4.loss_dice: 0.2792  decode.d5.loss_cls: 0.1702  decode.d5.loss_mask: 0.2456  decode.d5.loss_dice: 0.2624  decode.d6.loss_cls: 0.1451  decode.d6.loss_mask: 0.2452  decode.d6.loss_dice: 0.2777  decode.d7.loss_cls: 0.1648  decode.d7.loss_mask: 0.2465  decode.d7.loss_dice: 0.2755  decode.d8.loss_cls: 0.1795  decode.d8.loss_mask: 0.2432  decode.d8.loss_dice: 0.2722
08/06 12:37:17 - mmengine - INFO - Iter(train) [ 74900/320000]  base_lr: 7.8664e-05 lr: 7.8664e-06  eta: 1 day, 9:37:19  time: 0.4973  data_time: 0.0115  memory: 5891  grad_norm: 135.6227  loss: 6.8516  decode.loss_cls: 0.1609  decode.loss_mask: 0.2231  decode.loss_dice: 0.2681  decode.d0.loss_cls: 0.8979  decode.d0.loss_mask: 0.2279  decode.d0.loss_dice: 0.2802  decode.d1.loss_cls: 0.0456  decode.d1.loss_mask: 0.2229  decode.d1.loss_dice: 0.2889  decode.d2.loss_cls: 0.0949  decode.d2.loss_mask: 0.2233  decode.d2.loss_dice: 0.2629  decode.d3.loss_cls: 0.0645  decode.d3.loss_mask: 0.2267  decode.d3.loss_dice: 0.3007  decode.d4.loss_cls: 0.1078  decode.d4.loss_mask: 0.2218  decode.d4.loss_dice: 0.2593  decode.d5.loss_cls: 0.1103  decode.d5.loss_mask: 0.2239  decode.d5.loss_dice: 0.2894  decode.d6.loss_cls: 0.1625  decode.d6.loss_mask: 0.2235  decode.d6.loss_dice: 0.2613  decode.d7.loss_cls: 0.0624  decode.d7.loss_mask: 0.2227  decode.d7.loss_dice: 0.2782  decode.d8.loss_cls: 0.1484  decode.d8.loss_mask: 0.2233  decode.d8.loss_dice: 0.2681
08/06 12:37:41 - mmengine - INFO - Iter(train) [ 74950/320000]  base_lr: 7.8649e-05 lr: 7.8649e-06  eta: 1 day, 9:36:55  time: 0.4986  data_time: 0.0114  memory: 5911  grad_norm: 46.0111  loss: 6.5553  decode.loss_cls: 0.0708  decode.loss_mask: 0.2369  decode.loss_dice: 0.2695  decode.d0.loss_cls: 0.9007  decode.d0.loss_mask: 0.2366  decode.d0.loss_dice: 0.2746  decode.d1.loss_cls: 0.1014  decode.d1.loss_mask: 0.2336  decode.d1.loss_dice: 0.2636  decode.d2.loss_cls: 0.0859  decode.d2.loss_mask: 0.2378  decode.d2.loss_dice: 0.2663  decode.d3.loss_cls: 0.0450  decode.d3.loss_mask: 0.2335  decode.d3.loss_dice: 0.2669  decode.d4.loss_cls: 0.0823  decode.d4.loss_mask: 0.2371  decode.d4.loss_dice: 0.2725  decode.d5.loss_cls: 0.0735  decode.d5.loss_mask: 0.2360  decode.d5.loss_dice: 0.2591  decode.d6.loss_cls: 0.0535  decode.d6.loss_mask: 0.2389  decode.d6.loss_dice: 0.2583  decode.d7.loss_cls: 0.0679  decode.d7.loss_mask: 0.2368  decode.d7.loss_dice: 0.2623  decode.d8.loss_cls: 0.0668  decode.d8.loss_mask: 0.2351  decode.d8.loss_dice: 0.2521
08/06 12:38:06 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 12:38:06 - mmengine - INFO - Iter(train) [ 75000/320000]  base_lr: 7.8635e-05 lr: 7.8635e-06  eta: 1 day, 9:36:31  time: 0.4966  data_time: 0.0114  memory: 5894  grad_norm: 43.0237  loss: 7.5873  decode.loss_cls: 0.1086  decode.loss_mask: 0.2260  decode.loss_dice: 0.2930  decode.d0.loss_cls: 0.9370  decode.d0.loss_mask: 0.2200  decode.d0.loss_dice: 0.2978  decode.d1.loss_cls: 0.1237  decode.d1.loss_mask: 0.2262  decode.d1.loss_dice: 0.3267  decode.d2.loss_cls: 0.0973  decode.d2.loss_mask: 0.2271  decode.d2.loss_dice: 0.3146  decode.d3.loss_cls: 0.1336  decode.d3.loss_mask: 0.2255  decode.d3.loss_dice: 0.3073  decode.d4.loss_cls: 0.1328  decode.d4.loss_mask: 0.2269  decode.d4.loss_dice: 0.3100  decode.d5.loss_cls: 0.1495  decode.d5.loss_mask: 0.2299  decode.d5.loss_dice: 0.3269  decode.d6.loss_cls: 0.2504  decode.d6.loss_mask: 0.2231  decode.d6.loss_dice: 0.3028  decode.d7.loss_cls: 0.2106  decode.d7.loss_mask: 0.2206  decode.d7.loss_dice: 0.2969  decode.d8.loss_cls: 0.0999  decode.d8.loss_mask: 0.2296  decode.d8.loss_dice: 0.3131
08/06 12:38:31 - mmengine - INFO - Iter(train) [ 75050/320000]  base_lr: 7.8621e-05 lr: 7.8621e-06  eta: 1 day, 9:36:07  time: 0.4974  data_time: 0.0116  memory: 5909  grad_norm: 52.7458  loss: 6.4464  decode.loss_cls: 0.1063  decode.loss_mask: 0.2154  decode.loss_dice: 0.2789  decode.d0.loss_cls: 0.7758  decode.d0.loss_mask: 0.2139  decode.d0.loss_dice: 0.2786  decode.d1.loss_cls: 0.0921  decode.d1.loss_mask: 0.2137  decode.d1.loss_dice: 0.2869  decode.d2.loss_cls: 0.0832  decode.d2.loss_mask: 0.2118  decode.d2.loss_dice: 0.2788  decode.d3.loss_cls: 0.0524  decode.d3.loss_mask: 0.2122  decode.d3.loss_dice: 0.2753  decode.d4.loss_cls: 0.0460  decode.d4.loss_mask: 0.2124  decode.d4.loss_dice: 0.2742  decode.d5.loss_cls: 0.0512  decode.d5.loss_mask: 0.2128  decode.d5.loss_dice: 0.2860  decode.d6.loss_cls: 0.0688  decode.d6.loss_mask: 0.2141  decode.d6.loss_dice: 0.2926  decode.d7.loss_cls: 0.1068  decode.d7.loss_mask: 0.2154  decode.d7.loss_dice: 0.2787  decode.d8.loss_cls: 0.1251  decode.d8.loss_mask: 0.2127  decode.d8.loss_dice: 0.2743
08/06 12:38:56 - mmengine - INFO - Iter(train) [ 75100/320000]  base_lr: 7.8606e-05 lr: 7.8606e-06  eta: 1 day, 9:35:43  time: 0.4969  data_time: 0.0115  memory: 5911  grad_norm: 161.5628  loss: 7.8830  decode.loss_cls: 0.2593  decode.loss_mask: 0.1940  decode.loss_dice: 0.2139  decode.d0.loss_cls: 0.9904  decode.d0.loss_mask: 0.1939  decode.d0.loss_dice: 0.2766  decode.d1.loss_cls: 0.2517  decode.d1.loss_mask: 0.1933  decode.d1.loss_dice: 0.2877  decode.d2.loss_cls: 0.2810  decode.d2.loss_mask: 0.1988  decode.d2.loss_dice: 0.3060  decode.d3.loss_cls: 0.2150  decode.d3.loss_mask: 0.1938  decode.d3.loss_dice: 0.2789  decode.d4.loss_cls: 0.2714  decode.d4.loss_mask: 0.1930  decode.d4.loss_dice: 0.2378  decode.d5.loss_cls: 0.2731  decode.d5.loss_mask: 0.1935  decode.d5.loss_dice: 0.2655  decode.d6.loss_cls: 0.2713  decode.d6.loss_mask: 0.1949  decode.d6.loss_dice: 0.2697  decode.d7.loss_cls: 0.2191  decode.d7.loss_mask: 0.1936  decode.d7.loss_dice: 0.2457  decode.d8.loss_cls: 0.2485  decode.d8.loss_mask: 0.1941  decode.d8.loss_dice: 0.2773
08/06 12:39:21 - mmengine - INFO - Iter(train) [ 75150/320000]  base_lr: 7.8592e-05 lr: 7.8592e-06  eta: 1 day, 9:35:19  time: 0.4973  data_time: 0.0115  memory: 5911  grad_norm: 98.6428  loss: 7.7739  decode.loss_cls: 0.1845  decode.loss_mask: 0.2822  decode.loss_dice: 0.2580  decode.d0.loss_cls: 1.0333  decode.d0.loss_mask: 0.2533  decode.d0.loss_dice: 0.2474  decode.d1.loss_cls: 0.1979  decode.d1.loss_mask: 0.2523  decode.d1.loss_dice: 0.2538  decode.d2.loss_cls: 0.1829  decode.d2.loss_mask: 0.2662  decode.d2.loss_dice: 0.2584  decode.d3.loss_cls: 0.1705  decode.d3.loss_mask: 0.2526  decode.d3.loss_dice: 0.2504  decode.d4.loss_cls: 0.1784  decode.d4.loss_mask: 0.2501  decode.d4.loss_dice: 0.2575  decode.d5.loss_cls: 0.1983  decode.d5.loss_mask: 0.2503  decode.d5.loss_dice: 0.2418  decode.d6.loss_cls: 0.1856  decode.d6.loss_mask: 0.2781  decode.d6.loss_dice: 0.2585  decode.d7.loss_cls: 0.1135  decode.d7.loss_mask: 0.2521  decode.d7.loss_dice: 0.2386  decode.d8.loss_cls: 0.1845  decode.d8.loss_mask: 0.2786  decode.d8.loss_dice: 0.2643
08/06 12:39:46 - mmengine - INFO - Iter(train) [ 75200/320000]  base_lr: 7.8577e-05 lr: 7.8577e-06  eta: 1 day, 9:34:55  time: 0.4974  data_time: 0.0115  memory: 5911  grad_norm: 76.9780  loss: 6.4064  decode.loss_cls: 0.1099  decode.loss_mask: 0.2021  decode.loss_dice: 0.2744  decode.d0.loss_cls: 0.8663  decode.d0.loss_mask: 0.2029  decode.d0.loss_dice: 0.2614  decode.d1.loss_cls: 0.0762  decode.d1.loss_mask: 0.2002  decode.d1.loss_dice: 0.2800  decode.d2.loss_cls: 0.1158  decode.d2.loss_mask: 0.2012  decode.d2.loss_dice: 0.2603  decode.d3.loss_cls: 0.1014  decode.d3.loss_mask: 0.2053  decode.d3.loss_dice: 0.2668  decode.d4.loss_cls: 0.0998  decode.d4.loss_mask: 0.2029  decode.d4.loss_dice: 0.2693  decode.d5.loss_cls: 0.0892  decode.d5.loss_mask: 0.2032  decode.d5.loss_dice: 0.2573  decode.d6.loss_cls: 0.1026  decode.d6.loss_mask: 0.2026  decode.d6.loss_dice: 0.2509  decode.d7.loss_cls: 0.0918  decode.d7.loss_mask: 0.2010  decode.d7.loss_dice: 0.2694  decode.d8.loss_cls: 0.0923  decode.d8.loss_mask: 0.2013  decode.d8.loss_dice: 0.2487
08/06 12:40:11 - mmengine - INFO - Iter(train) [ 75250/320000]  base_lr: 7.8563e-05 lr: 7.8563e-06  eta: 1 day, 9:34:30  time: 0.4974  data_time: 0.0116  memory: 5894  grad_norm: 137.8322  loss: 5.5571  decode.loss_cls: 0.0180  decode.loss_mask: 0.2055  decode.loss_dice: 0.2176  decode.d0.loss_cls: 0.8494  decode.d0.loss_mask: 0.2002  decode.d0.loss_dice: 0.2125  decode.d1.loss_cls: 0.0268  decode.d1.loss_mask: 0.2117  decode.d1.loss_dice: 0.2210  decode.d2.loss_cls: 0.0526  decode.d2.loss_mask: 0.2077  decode.d2.loss_dice: 0.2195  decode.d3.loss_cls: 0.0360  decode.d3.loss_mask: 0.2079  decode.d3.loss_dice: 0.2230  decode.d4.loss_cls: 0.0700  decode.d4.loss_mask: 0.2061  decode.d4.loss_dice: 0.2207  decode.d5.loss_cls: 0.0629  decode.d5.loss_mask: 0.2060  decode.d5.loss_dice: 0.2183  decode.d6.loss_cls: 0.0833  decode.d6.loss_mask: 0.2057  decode.d6.loss_dice: 0.2200  decode.d7.loss_cls: 0.0683  decode.d7.loss_mask: 0.2055  decode.d7.loss_dice: 0.2196  decode.d8.loss_cls: 0.0278  decode.d8.loss_mask: 0.2093  decode.d8.loss_dice: 0.2242
08/06 12:40:36 - mmengine - INFO - Iter(train) [ 75300/320000]  base_lr: 7.8548e-05 lr: 7.8548e-06  eta: 1 day, 9:34:06  time: 0.4978  data_time: 0.0116  memory: 5911  grad_norm: 147.6697  loss: 8.9886  decode.loss_cls: 0.2761  decode.loss_mask: 0.2516  decode.loss_dice: 0.3354  decode.d0.loss_cls: 1.0355  decode.d0.loss_mask: 0.2517  decode.d0.loss_dice: 0.2974  decode.d1.loss_cls: 0.2737  decode.d1.loss_mask: 0.2523  decode.d1.loss_dice: 0.3001  decode.d2.loss_cls: 0.2234  decode.d2.loss_mask: 0.2497  decode.d2.loss_dice: 0.3114  decode.d3.loss_cls: 0.2434  decode.d3.loss_mask: 0.2508  decode.d3.loss_dice: 0.3069  decode.d4.loss_cls: 0.2687  decode.d4.loss_mask: 0.2476  decode.d4.loss_dice: 0.2726  decode.d5.loss_cls: 0.2731  decode.d5.loss_mask: 0.2525  decode.d5.loss_dice: 0.3225  decode.d6.loss_cls: 0.2732  decode.d6.loss_mask: 0.2488  decode.d6.loss_dice: 0.3111  decode.d7.loss_cls: 0.2576  decode.d7.loss_mask: 0.2509  decode.d7.loss_dice: 0.3070  decode.d8.loss_cls: 0.2794  decode.d8.loss_mask: 0.2494  decode.d8.loss_dice: 0.3146
08/06 12:41:01 - mmengine - INFO - Iter(train) [ 75350/320000]  base_lr: 7.8534e-05 lr: 7.8534e-06  eta: 1 day, 9:33:42  time: 0.4963  data_time: 0.0112  memory: 5911  grad_norm: 157.1781  loss: 7.9140  decode.loss_cls: 0.1327  decode.loss_mask: 0.3109  decode.loss_dice: 0.2914  decode.d0.loss_cls: 0.9451  decode.d0.loss_mask: 0.3209  decode.d0.loss_dice: 0.2792  decode.d1.loss_cls: 0.0650  decode.d1.loss_mask: 0.3123  decode.d1.loss_dice: 0.2838  decode.d2.loss_cls: 0.0697  decode.d2.loss_mask: 0.3111  decode.d2.loss_dice: 0.2864  decode.d3.loss_cls: 0.0767  decode.d3.loss_mask: 0.3139  decode.d3.loss_dice: 0.2947  decode.d4.loss_cls: 0.1056  decode.d4.loss_mask: 0.3083  decode.d4.loss_dice: 0.3009  decode.d5.loss_cls: 0.1416  decode.d5.loss_mask: 0.3126  decode.d5.loss_dice: 0.2973  decode.d6.loss_cls: 0.1259  decode.d6.loss_mask: 0.3113  decode.d6.loss_dice: 0.2998  decode.d7.loss_cls: 0.1181  decode.d7.loss_mask: 0.3112  decode.d7.loss_dice: 0.2642  decode.d8.loss_cls: 0.1142  decode.d8.loss_mask: 0.3110  decode.d8.loss_dice: 0.2982
08/06 12:41:25 - mmengine - INFO - Iter(train) [ 75400/320000]  base_lr: 7.8519e-05 lr: 7.8519e-06  eta: 1 day, 9:33:18  time: 0.4974  data_time: 0.0113  memory: 5874  grad_norm: 116.8574  loss: 7.2362  decode.loss_cls: 0.1114  decode.loss_mask: 0.2259  decode.loss_dice: 0.2597  decode.d0.loss_cls: 1.1908  decode.d0.loss_mask: 0.2316  decode.d0.loss_dice: 0.2576  decode.d1.loss_cls: 0.1171  decode.d1.loss_mask: 0.2304  decode.d1.loss_dice: 0.2627  decode.d2.loss_cls: 0.1180  decode.d2.loss_mask: 0.2304  decode.d2.loss_dice: 0.2569  decode.d3.loss_cls: 0.1320  decode.d3.loss_mask: 0.2315  decode.d3.loss_dice: 0.2658  decode.d4.loss_cls: 0.1273  decode.d4.loss_mask: 0.2291  decode.d4.loss_dice: 0.2581  decode.d5.loss_cls: 0.1241  decode.d5.loss_mask: 0.2260  decode.d5.loss_dice: 0.2621  decode.d6.loss_cls: 0.1585  decode.d6.loss_mask: 0.2280  decode.d6.loss_dice: 0.2588  decode.d7.loss_cls: 0.1345  decode.d7.loss_mask: 0.2279  decode.d7.loss_dice: 0.2608  decode.d8.loss_cls: 0.1284  decode.d8.loss_mask: 0.2269  decode.d8.loss_dice: 0.2636
08/06 12:41:50 - mmengine - INFO - Iter(train) [ 75450/320000]  base_lr: 7.8505e-05 lr: 7.8505e-06  eta: 1 day, 9:32:54  time: 0.4976  data_time: 0.0116  memory: 5891  grad_norm: 100.9158  loss: 6.7763  decode.loss_cls: 0.0930  decode.loss_mask: 0.2168  decode.loss_dice: 0.2720  decode.d0.loss_cls: 0.9076  decode.d0.loss_mask: 0.2175  decode.d0.loss_dice: 0.2563  decode.d1.loss_cls: 0.1559  decode.d1.loss_mask: 0.2163  decode.d1.loss_dice: 0.2697  decode.d2.loss_cls: 0.1313  decode.d2.loss_mask: 0.2196  decode.d2.loss_dice: 0.2722  decode.d3.loss_cls: 0.1460  decode.d3.loss_mask: 0.2165  decode.d3.loss_dice: 0.2650  decode.d4.loss_cls: 0.1062  decode.d4.loss_mask: 0.2160  decode.d4.loss_dice: 0.2790  decode.d5.loss_cls: 0.1043  decode.d5.loss_mask: 0.2142  decode.d5.loss_dice: 0.2574  decode.d6.loss_cls: 0.1086  decode.d6.loss_mask: 0.2173  decode.d6.loss_dice: 0.2654  decode.d7.loss_cls: 0.1056  decode.d7.loss_mask: 0.2157  decode.d7.loss_dice: 0.2719  decode.d8.loss_cls: 0.0809  decode.d8.loss_mask: 0.2135  decode.d8.loss_dice: 0.2647
08/06 12:42:15 - mmengine - INFO - Iter(train) [ 75500/320000]  base_lr: 7.8491e-05 lr: 7.8491e-06  eta: 1 day, 9:32:30  time: 0.4976  data_time: 0.0113  memory: 5968  grad_norm: 125.0116  loss: 7.0569  decode.loss_cls: 0.1924  decode.loss_mask: 0.1912  decode.loss_dice: 0.2705  decode.d0.loss_cls: 0.9202  decode.d0.loss_mask: 0.1870  decode.d0.loss_dice: 0.2402  decode.d1.loss_cls: 0.2350  decode.d1.loss_mask: 0.1905  decode.d1.loss_dice: 0.2482  decode.d2.loss_cls: 0.1726  decode.d2.loss_mask: 0.1914  decode.d2.loss_dice: 0.2481  decode.d3.loss_cls: 0.1790  decode.d3.loss_mask: 0.1886  decode.d3.loss_dice: 0.2584  decode.d4.loss_cls: 0.1560  decode.d4.loss_mask: 0.1907  decode.d4.loss_dice: 0.2521  decode.d5.loss_cls: 0.1526  decode.d5.loss_mask: 0.1926  decode.d5.loss_dice: 0.2636  decode.d6.loss_cls: 0.1974  decode.d6.loss_mask: 0.1932  decode.d6.loss_dice: 0.2602  decode.d7.loss_cls: 0.1919  decode.d7.loss_mask: 0.1934  decode.d7.loss_dice: 0.2449  decode.d8.loss_cls: 0.2049  decode.d8.loss_mask: 0.1943  decode.d8.loss_dice: 0.2559
08/06 12:42:40 - mmengine - INFO - Iter(train) [ 75550/320000]  base_lr: 7.8476e-05 lr: 7.8476e-06  eta: 1 day, 9:32:05  time: 0.4968  data_time: 0.0114  memory: 5891  grad_norm: 127.9485  loss: 8.2068  decode.loss_cls: 0.2232  decode.loss_mask: 0.2354  decode.loss_dice: 0.2749  decode.d0.loss_cls: 1.0563  decode.d0.loss_mask: 0.2402  decode.d0.loss_dice: 0.2886  decode.d1.loss_cls: 0.2507  decode.d1.loss_mask: 0.2337  decode.d1.loss_dice: 0.3129  decode.d2.loss_cls: 0.2402  decode.d2.loss_mask: 0.2358  decode.d2.loss_dice: 0.2907  decode.d3.loss_cls: 0.1873  decode.d3.loss_mask: 0.2372  decode.d3.loss_dice: 0.3044  decode.d4.loss_cls: 0.1528  decode.d4.loss_mask: 0.2364  decode.d4.loss_dice: 0.3222  decode.d5.loss_cls: 0.1403  decode.d5.loss_mask: 0.2398  decode.d5.loss_dice: 0.2976  decode.d6.loss_cls: 0.2441  decode.d6.loss_mask: 0.2399  decode.d6.loss_dice: 0.2775  decode.d7.loss_cls: 0.1998  decode.d7.loss_mask: 0.2396  decode.d7.loss_dice: 0.3046  decode.d8.loss_cls: 0.1850  decode.d8.loss_mask: 0.2385  decode.d8.loss_dice: 0.2771
08/06 12:43:05 - mmengine - INFO - Iter(train) [ 75600/320000]  base_lr: 7.8462e-05 lr: 7.8462e-06  eta: 1 day, 9:31:42  time: 0.4973  data_time: 0.0113  memory: 5891  grad_norm: 88.1629  loss: 6.2354  decode.loss_cls: 0.0524  decode.loss_mask: 0.2363  decode.loss_dice: 0.2457  decode.d0.loss_cls: 0.8598  decode.d0.loss_mask: 0.2380  decode.d0.loss_dice: 0.2499  decode.d1.loss_cls: 0.0863  decode.d1.loss_mask: 0.2365  decode.d1.loss_dice: 0.2399  decode.d2.loss_cls: 0.0710  decode.d2.loss_mask: 0.2361  decode.d2.loss_dice: 0.2366  decode.d3.loss_cls: 0.0566  decode.d3.loss_mask: 0.2366  decode.d3.loss_dice: 0.2528  decode.d4.loss_cls: 0.0642  decode.d4.loss_mask: 0.2345  decode.d4.loss_dice: 0.2312  decode.d5.loss_cls: 0.0683  decode.d5.loss_mask: 0.2339  decode.d5.loss_dice: 0.2537  decode.d6.loss_cls: 0.0753  decode.d6.loss_mask: 0.2337  decode.d6.loss_dice: 0.2466  decode.d7.loss_cls: 0.0615  decode.d7.loss_mask: 0.2319  decode.d7.loss_dice: 0.2420  decode.d8.loss_cls: 0.0586  decode.d8.loss_mask: 0.2332  decode.d8.loss_dice: 0.2324
08/06 12:43:30 - mmengine - INFO - Iter(train) [ 75650/320000]  base_lr: 7.8447e-05 lr: 7.8447e-06  eta: 1 day, 9:31:17  time: 0.4974  data_time: 0.0114  memory: 5930  grad_norm: 168.8412  loss: 7.2209  decode.loss_cls: 0.0876  decode.loss_mask: 0.2860  decode.loss_dice: 0.2940  decode.d0.loss_cls: 0.8849  decode.d0.loss_mask: 0.2907  decode.d0.loss_dice: 0.2932  decode.d1.loss_cls: 0.0621  decode.d1.loss_mask: 0.2862  decode.d1.loss_dice: 0.2911  decode.d2.loss_cls: 0.0720  decode.d2.loss_mask: 0.2822  decode.d2.loss_dice: 0.2897  decode.d3.loss_cls: 0.0520  decode.d3.loss_mask: 0.2869  decode.d3.loss_dice: 0.2937  decode.d4.loss_cls: 0.0452  decode.d4.loss_mask: 0.2860  decode.d4.loss_dice: 0.2901  decode.d5.loss_cls: 0.0379  decode.d5.loss_mask: 0.2885  decode.d5.loss_dice: 0.2955  decode.d6.loss_cls: 0.0612  decode.d6.loss_mask: 0.2869  decode.d6.loss_dice: 0.2969  decode.d7.loss_cls: 0.0713  decode.d7.loss_mask: 0.2820  decode.d7.loss_dice: 0.2923  decode.d8.loss_cls: 0.0633  decode.d8.loss_mask: 0.2836  decode.d8.loss_dice: 0.2877
08/06 12:43:55 - mmengine - INFO - Iter(train) [ 75700/320000]  base_lr: 7.8433e-05 lr: 7.8433e-06  eta: 1 day, 9:30:53  time: 0.4978  data_time: 0.0115  memory: 5894  grad_norm: 105.6980  loss: 5.4034  decode.loss_cls: 0.0049  decode.loss_mask: 0.2363  decode.loss_dice: 0.2233  decode.d0.loss_cls: 0.7965  decode.d0.loss_mask: 0.2379  decode.d0.loss_dice: 0.2146  decode.d1.loss_cls: 0.0150  decode.d1.loss_mask: 0.2375  decode.d1.loss_dice: 0.2131  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.2364  decode.d2.loss_dice: 0.2177  decode.d3.loss_cls: 0.0075  decode.d3.loss_mask: 0.2355  decode.d3.loss_dice: 0.2182  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.2353  decode.d4.loss_dice: 0.2157  decode.d5.loss_cls: 0.0063  decode.d5.loss_mask: 0.2384  decode.d5.loss_dice: 0.2198  decode.d6.loss_cls: 0.0063  decode.d6.loss_mask: 0.2374  decode.d6.loss_dice: 0.2157  decode.d7.loss_cls: 0.0046  decode.d7.loss_mask: 0.2369  decode.d7.loss_dice: 0.2169  decode.d8.loss_cls: 0.0044  decode.d8.loss_mask: 0.2383  decode.d8.loss_dice: 0.2191
08/06 12:44:20 - mmengine - INFO - Iter(train) [ 75750/320000]  base_lr: 7.8418e-05 lr: 7.8418e-06  eta: 1 day, 9:30:29  time: 0.4973  data_time: 0.0112  memory: 5911  grad_norm: 148.2595  loss: 7.3220  decode.loss_cls: 0.1724  decode.loss_mask: 0.2212  decode.loss_dice: 0.2728  decode.d0.loss_cls: 0.8845  decode.d0.loss_mask: 0.2232  decode.d0.loss_dice: 0.2706  decode.d1.loss_cls: 0.2603  decode.d1.loss_mask: 0.2246  decode.d1.loss_dice: 0.2583  decode.d2.loss_cls: 0.1617  decode.d2.loss_mask: 0.2293  decode.d2.loss_dice: 0.2690  decode.d3.loss_cls: 0.1751  decode.d3.loss_mask: 0.2206  decode.d3.loss_dice: 0.2483  decode.d4.loss_cls: 0.2027  decode.d4.loss_mask: 0.2185  decode.d4.loss_dice: 0.2679  decode.d5.loss_cls: 0.1333  decode.d5.loss_mask: 0.2208  decode.d5.loss_dice: 0.2744  decode.d6.loss_cls: 0.1442  decode.d6.loss_mask: 0.2189  decode.d6.loss_dice: 0.2701  decode.d7.loss_cls: 0.1599  decode.d7.loss_mask: 0.2182  decode.d7.loss_dice: 0.2748  decode.d8.loss_cls: 0.1526  decode.d8.loss_mask: 0.2198  decode.d8.loss_dice: 0.2538
08/06 12:44:44 - mmengine - INFO - Iter(train) [ 75800/320000]  base_lr: 7.8404e-05 lr: 7.8404e-06  eta: 1 day, 9:30:05  time: 0.4974  data_time: 0.0112  memory: 5894  grad_norm: 65.5280  loss: 6.1988  decode.loss_cls: 0.0758  decode.loss_mask: 0.2219  decode.loss_dice: 0.2366  decode.d0.loss_cls: 0.8918  decode.d0.loss_mask: 0.2218  decode.d0.loss_dice: 0.2432  decode.d1.loss_cls: 0.0612  decode.d1.loss_mask: 0.2212  decode.d1.loss_dice: 0.2348  decode.d2.loss_cls: 0.0679  decode.d2.loss_mask: 0.2209  decode.d2.loss_dice: 0.2352  decode.d3.loss_cls: 0.0793  decode.d3.loss_mask: 0.2201  decode.d3.loss_dice: 0.2292  decode.d4.loss_cls: 0.0943  decode.d4.loss_mask: 0.2179  decode.d4.loss_dice: 0.2246  decode.d5.loss_cls: 0.0877  decode.d5.loss_mask: 0.2190  decode.d5.loss_dice: 0.2450  decode.d6.loss_cls: 0.1061  decode.d6.loss_mask: 0.2224  decode.d6.loss_dice: 0.2391  decode.d7.loss_cls: 0.0948  decode.d7.loss_mask: 0.2226  decode.d7.loss_dice: 0.2309  decode.d8.loss_cls: 0.0794  decode.d8.loss_mask: 0.2193  decode.d8.loss_dice: 0.2349
08/06 12:45:09 - mmengine - INFO - Iter(train) [ 75850/320000]  base_lr: 7.8389e-05 lr: 7.8389e-06  eta: 1 day, 9:29:41  time: 0.4962  data_time: 0.0113  memory: 5911  grad_norm: 63.2020  loss: 6.0664  decode.loss_cls: 0.0307  decode.loss_mask: 0.2532  decode.loss_dice: 0.2400  decode.d0.loss_cls: 0.8425  decode.d0.loss_mask: 0.2625  decode.d0.loss_dice: 0.2361  decode.d1.loss_cls: 0.0550  decode.d1.loss_mask: 0.2568  decode.d1.loss_dice: 0.2566  decode.d2.loss_cls: 0.0185  decode.d2.loss_mask: 0.2509  decode.d2.loss_dice: 0.2352  decode.d3.loss_cls: 0.0184  decode.d3.loss_mask: 0.2535  decode.d3.loss_dice: 0.2386  decode.d4.loss_cls: 0.0178  decode.d4.loss_mask: 0.2531  decode.d4.loss_dice: 0.2412  decode.d5.loss_cls: 0.0185  decode.d5.loss_mask: 0.2523  decode.d5.loss_dice: 0.2293  decode.d6.loss_cls: 0.0337  decode.d6.loss_mask: 0.2527  decode.d6.loss_dice: 0.2347  decode.d7.loss_cls: 0.0177  decode.d7.loss_mask: 0.2542  decode.d7.loss_dice: 0.2400  decode.d8.loss_cls: 0.0881  decode.d8.loss_mask: 0.2501  decode.d8.loss_dice: 0.2347
08/06 12:45:34 - mmengine - INFO - Iter(train) [ 75900/320000]  base_lr: 7.8375e-05 lr: 7.8375e-06  eta: 1 day, 9:29:17  time: 0.4975  data_time: 0.0116  memory: 5913  grad_norm: 91.7562  loss: 8.3234  decode.loss_cls: 0.0336  decode.loss_mask: 0.3282  decode.loss_dice: 0.3331  decode.d0.loss_cls: 0.8287  decode.d0.loss_mask: 0.3425  decode.d0.loss_dice: 0.3422  decode.d1.loss_cls: 0.1214  decode.d1.loss_mask: 0.3283  decode.d1.loss_dice: 0.3228  decode.d2.loss_cls: 0.1045  decode.d2.loss_mask: 0.3325  decode.d2.loss_dice: 0.3261  decode.d3.loss_cls: 0.0978  decode.d3.loss_mask: 0.3294  decode.d3.loss_dice: 0.3409  decode.d4.loss_cls: 0.1429  decode.d4.loss_mask: 0.3287  decode.d4.loss_dice: 0.3304  decode.d5.loss_cls: 0.1466  decode.d5.loss_mask: 0.3280  decode.d5.loss_dice: 0.3384  decode.d6.loss_cls: 0.0711  decode.d6.loss_mask: 0.3328  decode.d6.loss_dice: 0.3423  decode.d7.loss_cls: 0.0692  decode.d7.loss_mask: 0.3298  decode.d7.loss_dice: 0.3301  decode.d8.loss_cls: 0.0681  decode.d8.loss_mask: 0.3286  decode.d8.loss_dice: 0.3247
08/06 12:45:59 - mmengine - INFO - Iter(train) [ 75950/320000]  base_lr: 7.8360e-05 lr: 7.8360e-06  eta: 1 day, 9:28:53  time: 0.4968  data_time: 0.0114  memory: 5876  grad_norm: 146.1886  loss: 9.3333  decode.loss_cls: 0.1568  decode.loss_mask: 0.3464  decode.loss_dice: 0.3464  decode.d0.loss_cls: 0.9725  decode.d0.loss_mask: 0.3106  decode.d0.loss_dice: 0.3077  decode.d1.loss_cls: 0.2723  decode.d1.loss_mask: 0.2928  decode.d1.loss_dice: 0.2950  decode.d2.loss_cls: 0.2564  decode.d2.loss_mask: 0.2886  decode.d2.loss_dice: 0.2919  decode.d3.loss_cls: 0.3129  decode.d3.loss_mask: 0.2580  decode.d3.loss_dice: 0.2954  decode.d4.loss_cls: 0.2319  decode.d4.loss_mask: 0.2921  decode.d4.loss_dice: 0.3304  decode.d5.loss_cls: 0.1591  decode.d5.loss_mask: 0.3473  decode.d5.loss_dice: 0.3330  decode.d6.loss_cls: 0.2202  decode.d6.loss_mask: 0.3082  decode.d6.loss_dice: 0.3440  decode.d7.loss_cls: 0.2713  decode.d7.loss_mask: 0.3083  decode.d7.loss_dice: 0.3191  decode.d8.loss_cls: 0.1850  decode.d8.loss_mask: 0.3525  decode.d8.loss_dice: 0.3270
08/06 12:46:24 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 12:46:24 - mmengine - INFO - Iter(train) [ 76000/320000]  base_lr: 7.8346e-05 lr: 7.8346e-06  eta: 1 day, 9:28:29  time: 0.4975  data_time: 0.0113  memory: 5911  grad_norm: 247.3628  loss: 10.8413  decode.loss_cls: 0.3510  decode.loss_mask: 0.2705  decode.loss_dice: 0.4263  decode.d0.loss_cls: 1.0770  decode.d0.loss_mask: 0.2597  decode.d0.loss_dice: 0.3855  decode.d1.loss_cls: 0.4429  decode.d1.loss_mask: 0.2661  decode.d1.loss_dice: 0.3903  decode.d2.loss_cls: 0.2913  decode.d2.loss_mask: 0.2614  decode.d2.loss_dice: 0.4132  decode.d3.loss_cls: 0.2149  decode.d3.loss_mask: 0.2796  decode.d3.loss_dice: 0.4315  decode.d4.loss_cls: 0.3027  decode.d4.loss_mask: 0.2610  decode.d4.loss_dice: 0.4148  decode.d5.loss_cls: 0.4100  decode.d5.loss_mask: 0.2567  decode.d5.loss_dice: 0.3890  decode.d6.loss_cls: 0.3526  decode.d6.loss_mask: 0.2609  decode.d6.loss_dice: 0.4102  decode.d7.loss_cls: 0.2446  decode.d7.loss_mask: 0.2676  decode.d7.loss_dice: 0.4414  decode.d8.loss_cls: 0.3834  decode.d8.loss_mask: 0.2627  decode.d8.loss_dice: 0.4226
08/06 12:46:49 - mmengine - INFO - Iter(train) [ 76050/320000]  base_lr: 7.8332e-05 lr: 7.8332e-06  eta: 1 day, 9:28:05  time: 0.4968  data_time: 0.0115  memory: 5894  grad_norm: 124.1921  loss: 8.1882  decode.loss_cls: 0.1487  decode.loss_mask: 0.2701  decode.loss_dice: 0.3407  decode.d0.loss_cls: 0.8068  decode.d0.loss_mask: 0.2782  decode.d0.loss_dice: 0.3504  decode.d1.loss_cls: 0.1414  decode.d1.loss_mask: 0.2772  decode.d1.loss_dice: 0.3663  decode.d2.loss_cls: 0.1221  decode.d2.loss_mask: 0.2702  decode.d2.loss_dice: 0.3364  decode.d3.loss_cls: 0.1774  decode.d3.loss_mask: 0.2718  decode.d3.loss_dice: 0.3319  decode.d4.loss_cls: 0.1447  decode.d4.loss_mask: 0.2724  decode.d4.loss_dice: 0.3314  decode.d5.loss_cls: 0.1619  decode.d5.loss_mask: 0.2695  decode.d5.loss_dice: 0.3255  decode.d6.loss_cls: 0.1299  decode.d6.loss_mask: 0.2714  decode.d6.loss_dice: 0.3432  decode.d7.loss_cls: 0.1090  decode.d7.loss_mask: 0.2685  decode.d7.loss_dice: 0.3402  decode.d8.loss_cls: 0.0982  decode.d8.loss_mask: 0.2718  decode.d8.loss_dice: 0.3612
08/06 12:47:14 - mmengine - INFO - Iter(train) [ 76100/320000]  base_lr: 7.8317e-05 lr: 7.8317e-06  eta: 1 day, 9:27:41  time: 0.4977  data_time: 0.0115  memory: 5911  grad_norm: 113.7761  loss: 7.9935  decode.loss_cls: 0.0669  decode.loss_mask: 0.3232  decode.loss_dice: 0.3201  decode.d0.loss_cls: 0.7546  decode.d0.loss_mask: 0.3402  decode.d0.loss_dice: 0.3327  decode.d1.loss_cls: 0.1367  decode.d1.loss_mask: 0.3247  decode.d1.loss_dice: 0.3203  decode.d2.loss_cls: 0.1517  decode.d2.loss_mask: 0.3163  decode.d2.loss_dice: 0.3167  decode.d3.loss_cls: 0.1095  decode.d3.loss_mask: 0.3198  decode.d3.loss_dice: 0.3310  decode.d4.loss_cls: 0.0729  decode.d4.loss_mask: 0.3218  decode.d4.loss_dice: 0.3090  decode.d5.loss_cls: 0.0493  decode.d5.loss_mask: 0.3227  decode.d5.loss_dice: 0.3323  decode.d6.loss_cls: 0.0531  decode.d6.loss_mask: 0.3196  decode.d6.loss_dice: 0.3126  decode.d7.loss_cls: 0.0524  decode.d7.loss_mask: 0.3277  decode.d7.loss_dice: 0.3210  decode.d8.loss_cls: 0.1039  decode.d8.loss_mask: 0.3161  decode.d8.loss_dice: 0.3148
08/06 12:47:39 - mmengine - INFO - Iter(train) [ 76150/320000]  base_lr: 7.8303e-05 lr: 7.8303e-06  eta: 1 day, 9:27:17  time: 0.4987  data_time: 0.0114  memory: 5895  grad_norm: 88.4097  loss: 6.1495  decode.loss_cls: 0.0677  decode.loss_mask: 0.2283  decode.loss_dice: 0.2458  decode.d0.loss_cls: 0.7349  decode.d0.loss_mask: 0.2325  decode.d0.loss_dice: 0.2479  decode.d1.loss_cls: 0.0912  decode.d1.loss_mask: 0.2380  decode.d1.loss_dice: 0.2509  decode.d2.loss_cls: 0.0762  decode.d2.loss_mask: 0.2322  decode.d2.loss_dice: 0.2446  decode.d3.loss_cls: 0.0718  decode.d3.loss_mask: 0.2307  decode.d3.loss_dice: 0.2385  decode.d4.loss_cls: 0.0659  decode.d4.loss_mask: 0.2282  decode.d4.loss_dice: 0.2458  decode.d5.loss_cls: 0.0692  decode.d5.loss_mask: 0.2295  decode.d5.loss_dice: 0.2455  decode.d6.loss_cls: 0.0755  decode.d6.loss_mask: 0.2289  decode.d6.loss_dice: 0.2446  decode.d7.loss_cls: 0.0734  decode.d7.loss_mask: 0.2320  decode.d7.loss_dice: 0.2421  decode.d8.loss_cls: 0.0629  decode.d8.loss_mask: 0.2300  decode.d8.loss_dice: 0.2447
08/06 12:48:04 - mmengine - INFO - Iter(train) [ 76200/320000]  base_lr: 7.8288e-05 lr: 7.8288e-06  eta: 1 day, 9:26:53  time: 0.4988  data_time: 0.0115  memory: 5891  grad_norm: 105.7767  loss: 6.7942  decode.loss_cls: 0.1540  decode.loss_mask: 0.2276  decode.loss_dice: 0.2355  decode.d0.loss_cls: 0.9142  decode.d0.loss_mask: 0.2246  decode.d0.loss_dice: 0.2453  decode.d1.loss_cls: 0.1294  decode.d1.loss_mask: 0.2313  decode.d1.loss_dice: 0.2777  decode.d2.loss_cls: 0.1625  decode.d2.loss_mask: 0.2274  decode.d2.loss_dice: 0.2369  decode.d3.loss_cls: 0.1141  decode.d3.loss_mask: 0.2275  decode.d3.loss_dice: 0.2373  decode.d4.loss_cls: 0.1090  decode.d4.loss_mask: 0.2344  decode.d4.loss_dice: 0.2533  decode.d5.loss_cls: 0.1086  decode.d5.loss_mask: 0.2258  decode.d5.loss_dice: 0.2346  decode.d6.loss_cls: 0.1320  decode.d6.loss_mask: 0.2287  decode.d6.loss_dice: 0.2442  decode.d7.loss_cls: 0.1226  decode.d7.loss_mask: 0.2292  decode.d7.loss_dice: 0.2369  decode.d8.loss_cls: 0.1211  decode.d8.loss_mask: 0.2286  decode.d8.loss_dice: 0.2400
08/06 12:48:29 - mmengine - INFO - Iter(train) [ 76250/320000]  base_lr: 7.8274e-05 lr: 7.8274e-06  eta: 1 day, 9:26:29  time: 0.4969  data_time: 0.0112  memory: 5911  grad_norm: 74.7793  loss: 7.6857  decode.loss_cls: 0.1030  decode.loss_mask: 0.3009  decode.loss_dice: 0.2863  decode.d0.loss_cls: 1.0141  decode.d0.loss_mask: 0.2901  decode.d0.loss_dice: 0.2961  decode.d1.loss_cls: 0.1084  decode.d1.loss_mask: 0.3074  decode.d1.loss_dice: 0.2834  decode.d2.loss_cls: 0.0698  decode.d2.loss_mask: 0.3080  decode.d2.loss_dice: 0.2813  decode.d3.loss_cls: 0.0803  decode.d3.loss_mask: 0.2996  decode.d3.loss_dice: 0.2912  decode.d4.loss_cls: 0.0810  decode.d4.loss_mask: 0.2886  decode.d4.loss_dice: 0.2831  decode.d5.loss_cls: 0.0916  decode.d5.loss_mask: 0.2948  decode.d5.loss_dice: 0.2994  decode.d6.loss_cls: 0.1130  decode.d6.loss_mask: 0.2969  decode.d6.loss_dice: 0.2911  decode.d7.loss_cls: 0.0975  decode.d7.loss_mask: 0.3047  decode.d7.loss_dice: 0.2742  decode.d8.loss_cls: 0.0641  decode.d8.loss_mask: 0.2989  decode.d8.loss_dice: 0.2869
08/06 12:48:54 - mmengine - INFO - Iter(train) [ 76300/320000]  base_lr: 7.8259e-05 lr: 7.8259e-06  eta: 1 day, 9:26:04  time: 0.4975  data_time: 0.0113  memory: 5911  grad_norm: 66.3337  loss: 5.6370  decode.loss_cls: 0.0648  decode.loss_mask: 0.1909  decode.loss_dice: 0.2247  decode.d0.loss_cls: 0.8300  decode.d0.loss_mask: 0.1944  decode.d0.loss_dice: 0.2169  decode.d1.loss_cls: 0.0999  decode.d1.loss_mask: 0.1929  decode.d1.loss_dice: 0.2306  decode.d2.loss_cls: 0.0646  decode.d2.loss_mask: 0.1924  decode.d2.loss_dice: 0.2249  decode.d3.loss_cls: 0.0872  decode.d3.loss_mask: 0.1968  decode.d3.loss_dice: 0.2220  decode.d4.loss_cls: 0.0795  decode.d4.loss_mask: 0.1921  decode.d4.loss_dice: 0.2171  decode.d5.loss_cls: 0.0639  decode.d5.loss_mask: 0.1900  decode.d5.loss_dice: 0.2179  decode.d6.loss_cls: 0.0642  decode.d6.loss_mask: 0.1893  decode.d6.loss_dice: 0.2208  decode.d7.loss_cls: 0.0686  decode.d7.loss_mask: 0.1907  decode.d7.loss_dice: 0.2154  decode.d8.loss_cls: 0.0820  decode.d8.loss_mask: 0.1896  decode.d8.loss_dice: 0.2230
08/06 12:49:18 - mmengine - INFO - Iter(train) [ 76350/320000]  base_lr: 7.8245e-05 lr: 7.8245e-06  eta: 1 day, 9:25:40  time: 0.4967  data_time: 0.0115  memory: 5911  grad_norm: 130.4978  loss: 6.5131  decode.loss_cls: 0.0697  decode.loss_mask: 0.2262  decode.loss_dice: 0.2798  decode.d0.loss_cls: 0.8797  decode.d0.loss_mask: 0.2312  decode.d0.loss_dice: 0.2995  decode.d1.loss_cls: 0.0579  decode.d1.loss_mask: 0.2279  decode.d1.loss_dice: 0.2767  decode.d2.loss_cls: 0.0647  decode.d2.loss_mask: 0.2289  decode.d2.loss_dice: 0.2584  decode.d3.loss_cls: 0.0791  decode.d3.loss_mask: 0.2269  decode.d3.loss_dice: 0.2809  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.2270  decode.d4.loss_dice: 0.2682  decode.d5.loss_cls: 0.0654  decode.d5.loss_mask: 0.2267  decode.d5.loss_dice: 0.2713  decode.d6.loss_cls: 0.0727  decode.d6.loss_mask: 0.2267  decode.d6.loss_dice: 0.2618  decode.d7.loss_cls: 0.0420  decode.d7.loss_mask: 0.2277  decode.d7.loss_dice: 0.2999  decode.d8.loss_cls: 0.0560  decode.d8.loss_mask: 0.2265  decode.d8.loss_dice: 0.2943
08/06 12:49:43 - mmengine - INFO - Iter(train) [ 76400/320000]  base_lr: 7.8230e-05 lr: 7.8230e-06  eta: 1 day, 9:25:16  time: 0.4977  data_time: 0.0116  memory: 5911  grad_norm: 67.1522  loss: 8.8935  decode.loss_cls: 0.2088  decode.loss_mask: 0.3081  decode.loss_dice: 0.3186  decode.d0.loss_cls: 0.9140  decode.d0.loss_mask: 0.3487  decode.d0.loss_dice: 0.3115  decode.d1.loss_cls: 0.2061  decode.d1.loss_mask: 0.3146  decode.d1.loss_dice: 0.3120  decode.d2.loss_cls: 0.1984  decode.d2.loss_mask: 0.3018  decode.d2.loss_dice: 0.2960  decode.d3.loss_cls: 0.1768  decode.d3.loss_mask: 0.3062  decode.d3.loss_dice: 0.3045  decode.d4.loss_cls: 0.1167  decode.d4.loss_mask: 0.3891  decode.d4.loss_dice: 0.3125  decode.d5.loss_cls: 0.1149  decode.d5.loss_mask: 0.3889  decode.d5.loss_dice: 0.3167  decode.d6.loss_cls: 0.2000  decode.d6.loss_mask: 0.3106  decode.d6.loss_dice: 0.2877  decode.d7.loss_cls: 0.2188  decode.d7.loss_mask: 0.3059  decode.d7.loss_dice: 0.3004  decode.d8.loss_cls: 0.1957  decode.d8.loss_mask: 0.2969  decode.d8.loss_dice: 0.3126
08/06 12:50:08 - mmengine - INFO - Iter(train) [ 76450/320000]  base_lr: 7.8216e-05 lr: 7.8216e-06  eta: 1 day, 9:24:52  time: 0.4980  data_time: 0.0116  memory: 5928  grad_norm: 111.3495  loss: 6.5552  decode.loss_cls: 0.1375  decode.loss_mask: 0.2035  decode.loss_dice: 0.2526  decode.d0.loss_cls: 0.8416  decode.d0.loss_mask: 0.2047  decode.d0.loss_dice: 0.2187  decode.d1.loss_cls: 0.1348  decode.d1.loss_mask: 0.2023  decode.d1.loss_dice: 0.2451  decode.d2.loss_cls: 0.1385  decode.d2.loss_mask: 0.2013  decode.d2.loss_dice: 0.2281  decode.d3.loss_cls: 0.1303  decode.d3.loss_mask: 0.2013  decode.d3.loss_dice: 0.2401  decode.d4.loss_cls: 0.1465  decode.d4.loss_mask: 0.2007  decode.d4.loss_dice: 0.2505  decode.d5.loss_cls: 0.1674  decode.d5.loss_mask: 0.2039  decode.d5.loss_dice: 0.2519  decode.d6.loss_cls: 0.1314  decode.d6.loss_mask: 0.2026  decode.d6.loss_dice: 0.2486  decode.d7.loss_cls: 0.1218  decode.d7.loss_mask: 0.2040  decode.d7.loss_dice: 0.2591  decode.d8.loss_cls: 0.1378  decode.d8.loss_mask: 0.2016  decode.d8.loss_dice: 0.2470
08/06 12:50:33 - mmengine - INFO - Iter(train) [ 76500/320000]  base_lr: 7.8202e-05 lr: 7.8202e-06  eta: 1 day, 9:24:28  time: 0.4970  data_time: 0.0114  memory: 5894  grad_norm: 105.6567  loss: 6.2088  decode.loss_cls: 0.0554  decode.loss_mask: 0.2362  decode.loss_dice: 0.2465  decode.d0.loss_cls: 0.8666  decode.d0.loss_mask: 0.2390  decode.d0.loss_dice: 0.2640  decode.d1.loss_cls: 0.0634  decode.d1.loss_mask: 0.2372  decode.d1.loss_dice: 0.2587  decode.d2.loss_cls: 0.0951  decode.d2.loss_mask: 0.2323  decode.d2.loss_dice: 0.2261  decode.d3.loss_cls: 0.0617  decode.d3.loss_mask: 0.2371  decode.d3.loss_dice: 0.2292  decode.d4.loss_cls: 0.0742  decode.d4.loss_mask: 0.2339  decode.d4.loss_dice: 0.2445  decode.d5.loss_cls: 0.0628  decode.d5.loss_mask: 0.2319  decode.d5.loss_dice: 0.2436  decode.d6.loss_cls: 0.0659  decode.d6.loss_mask: 0.2341  decode.d6.loss_dice: 0.2374  decode.d7.loss_cls: 0.0516  decode.d7.loss_mask: 0.2348  decode.d7.loss_dice: 0.2239  decode.d8.loss_cls: 0.0479  decode.d8.loss_mask: 0.2324  decode.d8.loss_dice: 0.2415
08/06 12:50:58 - mmengine - INFO - Iter(train) [ 76550/320000]  base_lr: 7.8187e-05 lr: 7.8187e-06  eta: 1 day, 9:24:04  time: 0.4975  data_time: 0.0114  memory: 5967  grad_norm: 205.5864  loss: 8.4235  decode.loss_cls: 0.1997  decode.loss_mask: 0.2733  decode.loss_dice: 0.3400  decode.d0.loss_cls: 0.9254  decode.d0.loss_mask: 0.2827  decode.d0.loss_dice: 0.2983  decode.d1.loss_cls: 0.2480  decode.d1.loss_mask: 0.2694  decode.d1.loss_dice: 0.2992  decode.d2.loss_cls: 0.1750  decode.d2.loss_mask: 0.2726  decode.d2.loss_dice: 0.3147  decode.d3.loss_cls: 0.1013  decode.d3.loss_mask: 0.2726  decode.d3.loss_dice: 0.3129  decode.d4.loss_cls: 0.1454  decode.d4.loss_mask: 0.2725  decode.d4.loss_dice: 0.2800  decode.d5.loss_cls: 0.1177  decode.d5.loss_mask: 0.2758  decode.d5.loss_dice: 0.3220  decode.d6.loss_cls: 0.2823  decode.d6.loss_mask: 0.2707  decode.d6.loss_dice: 0.3395  decode.d7.loss_cls: 0.1807  decode.d7.loss_mask: 0.2734  decode.d7.loss_dice: 0.3329  decode.d8.loss_cls: 0.1493  decode.d8.loss_mask: 0.2771  decode.d8.loss_dice: 0.3192
08/06 12:51:23 - mmengine - INFO - Iter(train) [ 76600/320000]  base_lr: 7.8173e-05 lr: 7.8173e-06  eta: 1 day, 9:23:40  time: 0.4987  data_time: 0.0117  memory: 5928  grad_norm: 94.0229  loss: 8.0316  decode.loss_cls: 0.1874  decode.loss_mask: 0.2049  decode.loss_dice: 0.3024  decode.d0.loss_cls: 1.0376  decode.d0.loss_mask: 0.2245  decode.d0.loss_dice: 0.2935  decode.d1.loss_cls: 0.2566  decode.d1.loss_mask: 0.2132  decode.d1.loss_dice: 0.2896  decode.d2.loss_cls: 0.2460  decode.d2.loss_mask: 0.2080  decode.d2.loss_dice: 0.2806  decode.d3.loss_cls: 0.1479  decode.d3.loss_mask: 0.2214  decode.d3.loss_dice: 0.3061  decode.d4.loss_cls: 0.1992  decode.d4.loss_mask: 0.2238  decode.d4.loss_dice: 0.3038  decode.d5.loss_cls: 0.2668  decode.d5.loss_mask: 0.2142  decode.d5.loss_dice: 0.3010  decode.d6.loss_cls: 0.2225  decode.d6.loss_mask: 0.2080  decode.d6.loss_dice: 0.2825  decode.d7.loss_cls: 0.2067  decode.d7.loss_mask: 0.2054  decode.d7.loss_dice: 0.2799  decode.d8.loss_cls: 0.2104  decode.d8.loss_mask: 0.2081  decode.d8.loss_dice: 0.2796
08/06 12:51:48 - mmengine - INFO - Iter(train) [ 76650/320000]  base_lr: 7.8158e-05 lr: 7.8158e-06  eta: 1 day, 9:23:16  time: 0.4977  data_time: 0.0116  memory: 5891  grad_norm: 100.1855  loss: 7.6670  decode.loss_cls: 0.1261  decode.loss_mask: 0.2750  decode.loss_dice: 0.2869  decode.d0.loss_cls: 0.8461  decode.d0.loss_mask: 0.2555  decode.d0.loss_dice: 0.2752  decode.d1.loss_cls: 0.1821  decode.d1.loss_mask: 0.2606  decode.d1.loss_dice: 0.2772  decode.d2.loss_cls: 0.1724  decode.d2.loss_mask: 0.2530  decode.d2.loss_dice: 0.2542  decode.d3.loss_cls: 0.1777  decode.d3.loss_mask: 0.2541  decode.d3.loss_dice: 0.2767  decode.d4.loss_cls: 0.1837  decode.d4.loss_mask: 0.2538  decode.d4.loss_dice: 0.2565  decode.d5.loss_cls: 0.2207  decode.d5.loss_mask: 0.2567  decode.d5.loss_dice: 0.2628  decode.d6.loss_cls: 0.1761  decode.d6.loss_mask: 0.2566  decode.d6.loss_dice: 0.2563  decode.d7.loss_cls: 0.1497  decode.d7.loss_mask: 0.2688  decode.d7.loss_dice: 0.2778  decode.d8.loss_cls: 0.1318  decode.d8.loss_mask: 0.2682  decode.d8.loss_dice: 0.2747
08/06 12:52:13 - mmengine - INFO - Iter(train) [ 76700/320000]  base_lr: 7.8144e-05 lr: 7.8144e-06  eta: 1 day, 9:22:52  time: 0.4977  data_time: 0.0116  memory: 5894  grad_norm: 96.4874  loss: 7.2432  decode.loss_cls: 0.0945  decode.loss_mask: 0.2350  decode.loss_dice: 0.3218  decode.d0.loss_cls: 0.8083  decode.d0.loss_mask: 0.2318  decode.d0.loss_dice: 0.3386  decode.d1.loss_cls: 0.1019  decode.d1.loss_mask: 0.2343  decode.d1.loss_dice: 0.3014  decode.d2.loss_cls: 0.0933  decode.d2.loss_mask: 0.2357  decode.d2.loss_dice: 0.3146  decode.d3.loss_cls: 0.0861  decode.d3.loss_mask: 0.2247  decode.d3.loss_dice: 0.3077  decode.d4.loss_cls: 0.1151  decode.d4.loss_mask: 0.2283  decode.d4.loss_dice: 0.3261  decode.d5.loss_cls: 0.1059  decode.d5.loss_mask: 0.2320  decode.d5.loss_dice: 0.3217  decode.d6.loss_cls: 0.1351  decode.d6.loss_mask: 0.2339  decode.d6.loss_dice: 0.3063  decode.d7.loss_cls: 0.0953  decode.d7.loss_mask: 0.2366  decode.d7.loss_dice: 0.3127  decode.d8.loss_cls: 0.0994  decode.d8.loss_mask: 0.2453  decode.d8.loss_dice: 0.3196
08/06 12:52:38 - mmengine - INFO - Iter(train) [ 76750/320000]  base_lr: 7.8129e-05 lr: 7.8129e-06  eta: 1 day, 9:22:28  time: 0.4977  data_time: 0.0115  memory: 5909  grad_norm: 126.4798  loss: 5.7894  decode.loss_cls: 0.0107  decode.loss_mask: 0.2561  decode.loss_dice: 0.2312  decode.d0.loss_cls: 0.7758  decode.d0.loss_mask: 0.2571  decode.d0.loss_dice: 0.2319  decode.d1.loss_cls: 0.0343  decode.d1.loss_mask: 0.2555  decode.d1.loss_dice: 0.2279  decode.d2.loss_cls: 0.0342  decode.d2.loss_mask: 0.2559  decode.d2.loss_dice: 0.2300  decode.d3.loss_cls: 0.0109  decode.d3.loss_mask: 0.2554  decode.d3.loss_dice: 0.2274  decode.d4.loss_cls: 0.0102  decode.d4.loss_mask: 0.2543  decode.d4.loss_dice: 0.2302  decode.d5.loss_cls: 0.0115  decode.d5.loss_mask: 0.2535  decode.d5.loss_dice: 0.2288  decode.d6.loss_cls: 0.0141  decode.d6.loss_mask: 0.2555  decode.d6.loss_dice: 0.2288  decode.d7.loss_cls: 0.0126  decode.d7.loss_mask: 0.2566  decode.d7.loss_dice: 0.2309  decode.d8.loss_cls: 0.0181  decode.d8.loss_mask: 0.2576  decode.d8.loss_dice: 0.2323
08/06 12:53:03 - mmengine - INFO - Iter(train) [ 76800/320000]  base_lr: 7.8115e-05 lr: 7.8115e-06  eta: 1 day, 9:22:04  time: 0.4965  data_time: 0.0114  memory: 5930  grad_norm: 101.1290  loss: 6.7130  decode.loss_cls: 0.0721  decode.loss_mask: 0.2821  decode.loss_dice: 0.2401  decode.d0.loss_cls: 0.8791  decode.d0.loss_mask: 0.2656  decode.d0.loss_dice: 0.2275  decode.d1.loss_cls: 0.0737  decode.d1.loss_mask: 0.2637  decode.d1.loss_dice: 0.2407  decode.d2.loss_cls: 0.0623  decode.d2.loss_mask: 0.2611  decode.d2.loss_dice: 0.2381  decode.d3.loss_cls: 0.1018  decode.d3.loss_mask: 0.2578  decode.d3.loss_dice: 0.2343  decode.d4.loss_cls: 0.0882  decode.d4.loss_mask: 0.2700  decode.d4.loss_dice: 0.2584  decode.d5.loss_cls: 0.0837  decode.d5.loss_mask: 0.2637  decode.d5.loss_dice: 0.2436  decode.d6.loss_cls: 0.0777  decode.d6.loss_mask: 0.2649  decode.d6.loss_dice: 0.2510  decode.d7.loss_cls: 0.0867  decode.d7.loss_mask: 0.2614  decode.d7.loss_dice: 0.2472  decode.d8.loss_cls: 0.0932  decode.d8.loss_mask: 0.2806  decode.d8.loss_dice: 0.2427
08/06 12:53:27 - mmengine - INFO - Iter(train) [ 76850/320000]  base_lr: 7.8100e-05 lr: 7.8100e-06  eta: 1 day, 9:21:40  time: 0.4976  data_time: 0.0115  memory: 5891  grad_norm: 176.8999  loss: 7.9363  decode.loss_cls: 0.1541  decode.loss_mask: 0.2454  decode.loss_dice: 0.3208  decode.d0.loss_cls: 0.9220  decode.d0.loss_mask: 0.2530  decode.d0.loss_dice: 0.3279  decode.d1.loss_cls: 0.1453  decode.d1.loss_mask: 0.2495  decode.d1.loss_dice: 0.3265  decode.d2.loss_cls: 0.1914  decode.d2.loss_mask: 0.2477  decode.d2.loss_dice: 0.3501  decode.d3.loss_cls: 0.1189  decode.d3.loss_mask: 0.2524  decode.d3.loss_dice: 0.3510  decode.d4.loss_cls: 0.1312  decode.d4.loss_mask: 0.2479  decode.d4.loss_dice: 0.3403  decode.d5.loss_cls: 0.0998  decode.d5.loss_mask: 0.2516  decode.d5.loss_dice: 0.3426  decode.d6.loss_cls: 0.1244  decode.d6.loss_mask: 0.2483  decode.d6.loss_dice: 0.3373  decode.d7.loss_cls: 0.0978  decode.d7.loss_mask: 0.2508  decode.d7.loss_dice: 0.3369  decode.d8.loss_cls: 0.0929  decode.d8.loss_mask: 0.2480  decode.d8.loss_dice: 0.3303
08/06 12:53:52 - mmengine - INFO - Iter(train) [ 76900/320000]  base_lr: 7.8086e-05 lr: 7.8086e-06  eta: 1 day, 9:21:16  time: 0.4981  data_time: 0.0115  memory: 5894  grad_norm: 87.5546  loss: 6.6712  decode.loss_cls: 0.1633  decode.loss_mask: 0.2124  decode.loss_dice: 0.2593  decode.d0.loss_cls: 1.0624  decode.d0.loss_mask: 0.1957  decode.d0.loss_dice: 0.2454  decode.d1.loss_cls: 0.0618  decode.d1.loss_mask: 0.1966  decode.d1.loss_dice: 0.2424  decode.d2.loss_cls: 0.0771  decode.d2.loss_mask: 0.1942  decode.d2.loss_dice: 0.2458  decode.d3.loss_cls: 0.0546  decode.d3.loss_mask: 0.2066  decode.d3.loss_dice: 0.2567  decode.d4.loss_cls: 0.1438  decode.d4.loss_mask: 0.2006  decode.d4.loss_dice: 0.2537  decode.d5.loss_cls: 0.1287  decode.d5.loss_mask: 0.2123  decode.d5.loss_dice: 0.2491  decode.d6.loss_cls: 0.1700  decode.d6.loss_mask: 0.2120  decode.d6.loss_dice: 0.2531  decode.d7.loss_cls: 0.1199  decode.d7.loss_mask: 0.2061  decode.d7.loss_dice: 0.2524  decode.d8.loss_cls: 0.1493  decode.d8.loss_mask: 0.2039  decode.d8.loss_dice: 0.2421
08/06 12:54:17 - mmengine - INFO - Iter(train) [ 76950/320000]  base_lr: 7.8071e-05 lr: 7.8071e-06  eta: 1 day, 9:20:52  time: 0.4971  data_time: 0.0116  memory: 5928  grad_norm: 78.1405  loss: 6.1770  decode.loss_cls: 0.1038  decode.loss_mask: 0.2104  decode.loss_dice: 0.2131  decode.d0.loss_cls: 0.8833  decode.d0.loss_mask: 0.2174  decode.d0.loss_dice: 0.2173  decode.d1.loss_cls: 0.1202  decode.d1.loss_mask: 0.2161  decode.d1.loss_dice: 0.2059  decode.d2.loss_cls: 0.0983  decode.d2.loss_mask: 0.2118  decode.d2.loss_dice: 0.2120  decode.d3.loss_cls: 0.1447  decode.d3.loss_mask: 0.2107  decode.d3.loss_dice: 0.2099  decode.d4.loss_cls: 0.1291  decode.d4.loss_mask: 0.2113  decode.d4.loss_dice: 0.2112  decode.d5.loss_cls: 0.1434  decode.d5.loss_mask: 0.2088  decode.d5.loss_dice: 0.2121  decode.d6.loss_cls: 0.1043  decode.d6.loss_mask: 0.2115  decode.d6.loss_dice: 0.2112  decode.d7.loss_cls: 0.1115  decode.d7.loss_mask: 0.2094  decode.d7.loss_dice: 0.2098  decode.d8.loss_cls: 0.1047  decode.d8.loss_mask: 0.2116  decode.d8.loss_dice: 0.2125
08/06 12:54:42 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 12:54:42 - mmengine - INFO - Iter(train) [ 77000/320000]  base_lr: 7.8057e-05 lr: 7.8057e-06  eta: 1 day, 9:20:28  time: 0.4981  data_time: 0.0115  memory: 5911  grad_norm: 62.0827  loss: 6.4800  decode.loss_cls: 0.1298  decode.loss_mask: 0.2043  decode.loss_dice: 0.2429  decode.d0.loss_cls: 0.8196  decode.d0.loss_mask: 0.2098  decode.d0.loss_dice: 0.2545  decode.d1.loss_cls: 0.0919  decode.d1.loss_mask: 0.2066  decode.d1.loss_dice: 0.2374  decode.d2.loss_cls: 0.1671  decode.d2.loss_mask: 0.2075  decode.d2.loss_dice: 0.2553  decode.d3.loss_cls: 0.1132  decode.d3.loss_mask: 0.2090  decode.d3.loss_dice: 0.2470  decode.d4.loss_cls: 0.1112  decode.d4.loss_mask: 0.2084  decode.d4.loss_dice: 0.2591  decode.d5.loss_cls: 0.1286  decode.d5.loss_mask: 0.2083  decode.d5.loss_dice: 0.2529  decode.d6.loss_cls: 0.1207  decode.d6.loss_mask: 0.2080  decode.d6.loss_dice: 0.2430  decode.d7.loss_cls: 0.1160  decode.d7.loss_mask: 0.2076  decode.d7.loss_dice: 0.2535  decode.d8.loss_cls: 0.1084  decode.d8.loss_mask: 0.2069  decode.d8.loss_dice: 0.2517
08/06 12:55:07 - mmengine - INFO - Iter(train) [ 77050/320000]  base_lr: 7.8043e-05 lr: 7.8043e-06  eta: 1 day, 9:20:04  time: 0.4983  data_time: 0.0115  memory: 5891  grad_norm: 88.1590  loss: 6.4816  decode.loss_cls: 0.1364  decode.loss_mask: 0.2002  decode.loss_dice: 0.2324  decode.d0.loss_cls: 0.8049  decode.d0.loss_mask: 0.2034  decode.d0.loss_dice: 0.2425  decode.d1.loss_cls: 0.1470  decode.d1.loss_mask: 0.1991  decode.d1.loss_dice: 0.2514  decode.d2.loss_cls: 0.1339  decode.d2.loss_mask: 0.2033  decode.d2.loss_dice: 0.2544  decode.d3.loss_cls: 0.1625  decode.d3.loss_mask: 0.2018  decode.d3.loss_dice: 0.2147  decode.d4.loss_cls: 0.1556  decode.d4.loss_mask: 0.2018  decode.d4.loss_dice: 0.2334  decode.d5.loss_cls: 0.1289  decode.d5.loss_mask: 0.2005  decode.d5.loss_dice: 0.2443  decode.d6.loss_cls: 0.1314  decode.d6.loss_mask: 0.2023  decode.d6.loss_dice: 0.2354  decode.d7.loss_cls: 0.1419  decode.d7.loss_mask: 0.2008  decode.d7.loss_dice: 0.2442  decode.d8.loss_cls: 0.1394  decode.d8.loss_mask: 0.2014  decode.d8.loss_dice: 0.2326
08/06 12:55:32 - mmengine - INFO - Iter(train) [ 77100/320000]  base_lr: 7.8028e-05 lr: 7.8028e-06  eta: 1 day, 9:19:40  time: 0.4978  data_time: 0.0116  memory: 5859  grad_norm: 49.4349  loss: 6.3708  decode.loss_cls: 0.1629  decode.loss_mask: 0.2104  decode.loss_dice: 0.2097  decode.d0.loss_cls: 0.8574  decode.d0.loss_mask: 0.2143  decode.d0.loss_dice: 0.2272  decode.d1.loss_cls: 0.1712  decode.d1.loss_mask: 0.2077  decode.d1.loss_dice: 0.2177  decode.d2.loss_cls: 0.0925  decode.d2.loss_mask: 0.2102  decode.d2.loss_dice: 0.2108  decode.d3.loss_cls: 0.0771  decode.d3.loss_mask: 0.2096  decode.d3.loss_dice: 0.2385  decode.d4.loss_cls: 0.0708  decode.d4.loss_mask: 0.2123  decode.d4.loss_dice: 0.2275  decode.d5.loss_cls: 0.1147  decode.d5.loss_mask: 0.2122  decode.d5.loss_dice: 0.2356  decode.d6.loss_cls: 0.1432  decode.d6.loss_mask: 0.2099  decode.d6.loss_dice: 0.2378  decode.d7.loss_cls: 0.1585  decode.d7.loss_mask: 0.2099  decode.d7.loss_dice: 0.2345  decode.d8.loss_cls: 0.1207  decode.d8.loss_mask: 0.2185  decode.d8.loss_dice: 0.2476
08/06 12:55:57 - mmengine - INFO - Iter(train) [ 77150/320000]  base_lr: 7.8014e-05 lr: 7.8014e-06  eta: 1 day, 9:19:16  time: 0.4966  data_time: 0.0115  memory: 5874  grad_norm: 202.0724  loss: 7.8356  decode.loss_cls: 0.1578  decode.loss_mask: 0.2412  decode.loss_dice: 0.2703  decode.d0.loss_cls: 0.8335  decode.d0.loss_mask: 0.2637  decode.d0.loss_dice: 0.3017  decode.d1.loss_cls: 0.1983  decode.d1.loss_mask: 0.2580  decode.d1.loss_dice: 0.2996  decode.d2.loss_cls: 0.1845  decode.d2.loss_mask: 0.2544  decode.d2.loss_dice: 0.3076  decode.d3.loss_cls: 0.1631  decode.d3.loss_mask: 0.2493  decode.d3.loss_dice: 0.3017  decode.d4.loss_cls: 0.1321  decode.d4.loss_mask: 0.2499  decode.d4.loss_dice: 0.2931  decode.d5.loss_cls: 0.1911  decode.d5.loss_mask: 0.2491  decode.d5.loss_dice: 0.2755  decode.d6.loss_cls: 0.2209  decode.d6.loss_mask: 0.2478  decode.d6.loss_dice: 0.2856  decode.d7.loss_cls: 0.1942  decode.d7.loss_mask: 0.2404  decode.d7.loss_dice: 0.2727  decode.d8.loss_cls: 0.1866  decode.d8.loss_mask: 0.2414  decode.d8.loss_dice: 0.2708
08/06 12:56:22 - mmengine - INFO - Iter(train) [ 77200/320000]  base_lr: 7.7999e-05 lr: 7.7999e-06  eta: 1 day, 9:18:51  time: 0.4968  data_time: 0.0115  memory: 5875  grad_norm: 31.4465  loss: 5.0961  decode.loss_cls: 0.0055  decode.loss_mask: 0.2414  decode.loss_dice: 0.1955  decode.d0.loss_cls: 0.6756  decode.d0.loss_mask: 0.2446  decode.d0.loss_dice: 0.1867  decode.d1.loss_cls: 0.0061  decode.d1.loss_mask: 0.2369  decode.d1.loss_dice: 0.1932  decode.d2.loss_cls: 0.0072  decode.d2.loss_mask: 0.2394  decode.d2.loss_dice: 0.1940  decode.d3.loss_cls: 0.0043  decode.d3.loss_mask: 0.2398  decode.d3.loss_dice: 0.1923  decode.d4.loss_cls: 0.0053  decode.d4.loss_mask: 0.2457  decode.d4.loss_dice: 0.1955  decode.d5.loss_cls: 0.0074  decode.d5.loss_mask: 0.2428  decode.d5.loss_dice: 0.1958  decode.d6.loss_cls: 0.0061  decode.d6.loss_mask: 0.2441  decode.d6.loss_dice: 0.1969  decode.d7.loss_cls: 0.0081  decode.d7.loss_mask: 0.2424  decode.d7.loss_dice: 0.1981  decode.d8.loss_cls: 0.0062  decode.d8.loss_mask: 0.2406  decode.d8.loss_dice: 0.1983
08/06 12:56:47 - mmengine - INFO - Iter(train) [ 77250/320000]  base_lr: 7.7985e-05 lr: 7.7985e-06  eta: 1 day, 9:18:27  time: 0.4975  data_time: 0.0116  memory: 5911  grad_norm: 67.7954  loss: 8.0163  decode.loss_cls: 0.1188  decode.loss_mask: 0.2977  decode.loss_dice: 0.3080  decode.d0.loss_cls: 0.9346  decode.d0.loss_mask: 0.2995  decode.d0.loss_dice: 0.2848  decode.d1.loss_cls: 0.1651  decode.d1.loss_mask: 0.2953  decode.d1.loss_dice: 0.2855  decode.d2.loss_cls: 0.1262  decode.d2.loss_mask: 0.2987  decode.d2.loss_dice: 0.3036  decode.d3.loss_cls: 0.0954  decode.d3.loss_mask: 0.2985  decode.d3.loss_dice: 0.3039  decode.d4.loss_cls: 0.1343  decode.d4.loss_mask: 0.3010  decode.d4.loss_dice: 0.2944  decode.d5.loss_cls: 0.1364  decode.d5.loss_mask: 0.2988  decode.d5.loss_dice: 0.2998  decode.d6.loss_cls: 0.1320  decode.d6.loss_mask: 0.3028  decode.d6.loss_dice: 0.2979  decode.d7.loss_cls: 0.1086  decode.d7.loss_mask: 0.2943  decode.d7.loss_dice: 0.3006  decode.d8.loss_cls: 0.1027  decode.d8.loss_mask: 0.3003  decode.d8.loss_dice: 0.2968
08/06 12:57:12 - mmengine - INFO - Iter(train) [ 77300/320000]  base_lr: 7.7970e-05 lr: 7.7970e-06  eta: 1 day, 9:18:04  time: 0.4960  data_time: 0.0112  memory: 5911  grad_norm: 142.0922  loss: 5.5023  decode.loss_cls: 0.0324  decode.loss_mask: 0.2079  decode.loss_dice: 0.2290  decode.d0.loss_cls: 0.8329  decode.d0.loss_mask: 0.2192  decode.d0.loss_dice: 0.2472  decode.d1.loss_cls: 0.0183  decode.d1.loss_mask: 0.2075  decode.d1.loss_dice: 0.2401  decode.d2.loss_cls: 0.0250  decode.d2.loss_mask: 0.2070  decode.d2.loss_dice: 0.2309  decode.d3.loss_cls: 0.0240  decode.d3.loss_mask: 0.2100  decode.d3.loss_dice: 0.2326  decode.d4.loss_cls: 0.0248  decode.d4.loss_mask: 0.2079  decode.d4.loss_dice: 0.2346  decode.d5.loss_cls: 0.0233  decode.d5.loss_mask: 0.2074  decode.d5.loss_dice: 0.2370  decode.d6.loss_cls: 0.0264  decode.d6.loss_mask: 0.2076  decode.d6.loss_dice: 0.2291  decode.d7.loss_cls: 0.0251  decode.d7.loss_mask: 0.2067  decode.d7.loss_dice: 0.2334  decode.d8.loss_cls: 0.0350  decode.d8.loss_mask: 0.2060  decode.d8.loss_dice: 0.2337
08/06 12:57:37 - mmengine - INFO - Iter(train) [ 77350/320000]  base_lr: 7.7956e-05 lr: 7.7956e-06  eta: 1 day, 9:17:39  time: 0.4979  data_time: 0.0113  memory: 5875  grad_norm: 48.5646  loss: 5.3701  decode.loss_cls: 0.0104  decode.loss_mask: 0.2124  decode.loss_dice: 0.2430  decode.d0.loss_cls: 0.7247  decode.d0.loss_mask: 0.2150  decode.d0.loss_dice: 0.2299  decode.d1.loss_cls: 0.0164  decode.d1.loss_mask: 0.2141  decode.d1.loss_dice: 0.2385  decode.d2.loss_cls: 0.0177  decode.d2.loss_mask: 0.2123  decode.d2.loss_dice: 0.2367  decode.d3.loss_cls: 0.0138  decode.d3.loss_mask: 0.2137  decode.d3.loss_dice: 0.2404  decode.d4.loss_cls: 0.0132  decode.d4.loss_mask: 0.2131  decode.d4.loss_dice: 0.2389  decode.d5.loss_cls: 0.0149  decode.d5.loss_mask: 0.2134  decode.d5.loss_dice: 0.2391  decode.d6.loss_cls: 0.0130  decode.d6.loss_mask: 0.2129  decode.d6.loss_dice: 0.2400  decode.d7.loss_cls: 0.0126  decode.d7.loss_mask: 0.2118  decode.d7.loss_dice: 0.2377  decode.d8.loss_cls: 0.0119  decode.d8.loss_mask: 0.2133  decode.d8.loss_dice: 0.2454
08/06 12:58:02 - mmengine - INFO - Iter(train) [ 77400/320000]  base_lr: 7.7941e-05 lr: 7.7941e-06  eta: 1 day, 9:17:15  time: 0.4971  data_time: 0.0115  memory: 5911  grad_norm: 234.3669  loss: 6.8910  decode.loss_cls: 0.1158  decode.loss_mask: 0.1990  decode.loss_dice: 0.2500  decode.d0.loss_cls: 0.7911  decode.d0.loss_mask: 0.2045  decode.d0.loss_dice: 0.2757  decode.d1.loss_cls: 0.1926  decode.d1.loss_mask: 0.2002  decode.d1.loss_dice: 0.2720  decode.d2.loss_cls: 0.1702  decode.d2.loss_mask: 0.1993  decode.d2.loss_dice: 0.2824  decode.d3.loss_cls: 0.1803  decode.d3.loss_mask: 0.1975  decode.d3.loss_dice: 0.2833  decode.d4.loss_cls: 0.1455  decode.d4.loss_mask: 0.1988  decode.d4.loss_dice: 0.2689  decode.d5.loss_cls: 0.1544  decode.d5.loss_mask: 0.1999  decode.d5.loss_dice: 0.2663  decode.d6.loss_cls: 0.1390  decode.d6.loss_mask: 0.1980  decode.d6.loss_dice: 0.2533  decode.d7.loss_cls: 0.1508  decode.d7.loss_mask: 0.1986  decode.d7.loss_dice: 0.2683  decode.d8.loss_cls: 0.1730  decode.d8.loss_mask: 0.1965  decode.d8.loss_dice: 0.2659
08/06 12:58:26 - mmengine - INFO - Iter(train) [ 77450/320000]  base_lr: 7.7927e-05 lr: 7.7927e-06  eta: 1 day, 9:16:51  time: 0.4976  data_time: 0.0114  memory: 5909  grad_norm: 93.7132  loss: 6.9099  decode.loss_cls: 0.1359  decode.loss_mask: 0.2162  decode.loss_dice: 0.2320  decode.d0.loss_cls: 0.8412  decode.d0.loss_mask: 0.2182  decode.d0.loss_dice: 0.2491  decode.d1.loss_cls: 0.2166  decode.d1.loss_mask: 0.2174  decode.d1.loss_dice: 0.2326  decode.d2.loss_cls: 0.1728  decode.d2.loss_mask: 0.2167  decode.d2.loss_dice: 0.2533  decode.d3.loss_cls: 0.1656  decode.d3.loss_mask: 0.2147  decode.d3.loss_dice: 0.2447  decode.d4.loss_cls: 0.1904  decode.d4.loss_mask: 0.2187  decode.d4.loss_dice: 0.2463  decode.d5.loss_cls: 0.1280  decode.d5.loss_mask: 0.2184  decode.d5.loss_dice: 0.2585  decode.d6.loss_cls: 0.1620  decode.d6.loss_mask: 0.2170  decode.d6.loss_dice: 0.2487  decode.d7.loss_cls: 0.1455  decode.d7.loss_mask: 0.2182  decode.d7.loss_dice: 0.2345  decode.d8.loss_cls: 0.1384  decode.d8.loss_mask: 0.2164  decode.d8.loss_dice: 0.2419
08/06 12:58:51 - mmengine - INFO - Iter(train) [ 77500/320000]  base_lr: 7.7912e-05 lr: 7.7912e-06  eta: 1 day, 9:16:27  time: 0.4974  data_time: 0.0114  memory: 5878  grad_norm: 174.9591  loss: 6.3427  decode.loss_cls: 0.1485  decode.loss_mask: 0.1772  decode.loss_dice: 0.2428  decode.d0.loss_cls: 0.8802  decode.d0.loss_mask: 0.1807  decode.d0.loss_dice: 0.2368  decode.d1.loss_cls: 0.1324  decode.d1.loss_mask: 0.1797  decode.d1.loss_dice: 0.2389  decode.d2.loss_cls: 0.1142  decode.d2.loss_mask: 0.1790  decode.d2.loss_dice: 0.2388  decode.d3.loss_cls: 0.1541  decode.d3.loss_mask: 0.1787  decode.d3.loss_dice: 0.2404  decode.d4.loss_cls: 0.1305  decode.d4.loss_mask: 0.1794  decode.d4.loss_dice: 0.2177  decode.d5.loss_cls: 0.1688  decode.d5.loss_mask: 0.1781  decode.d5.loss_dice: 0.2463  decode.d6.loss_cls: 0.1344  decode.d6.loss_mask: 0.1780  decode.d6.loss_dice: 0.2537  decode.d7.loss_cls: 0.1513  decode.d7.loss_mask: 0.1785  decode.d7.loss_dice: 0.2326  decode.d8.loss_cls: 0.1704  decode.d8.loss_mask: 0.1777  decode.d8.loss_dice: 0.2227
08/06 12:59:16 - mmengine - INFO - Iter(train) [ 77550/320000]  base_lr: 7.7898e-05 lr: 7.7898e-06  eta: 1 day, 9:16:03  time: 0.4971  data_time: 0.0114  memory: 5931  grad_norm: 54.6703  loss: 6.1807  decode.loss_cls: 0.0497  decode.loss_mask: 0.2258  decode.loss_dice: 0.2656  decode.d0.loss_cls: 0.7936  decode.d0.loss_mask: 0.2247  decode.d0.loss_dice: 0.2676  decode.d1.loss_cls: 0.0357  decode.d1.loss_mask: 0.2305  decode.d1.loss_dice: 0.2574  decode.d2.loss_cls: 0.0398  decode.d2.loss_mask: 0.2326  decode.d2.loss_dice: 0.2617  decode.d3.loss_cls: 0.0457  decode.d3.loss_mask: 0.2289  decode.d3.loss_dice: 0.2621  decode.d4.loss_cls: 0.0601  decode.d4.loss_mask: 0.2285  decode.d4.loss_dice: 0.2551  decode.d5.loss_cls: 0.0568  decode.d5.loss_mask: 0.2283  decode.d5.loss_dice: 0.2560  decode.d6.loss_cls: 0.1090  decode.d6.loss_mask: 0.2287  decode.d6.loss_dice: 0.2509  decode.d7.loss_cls: 0.0519  decode.d7.loss_mask: 0.2278  decode.d7.loss_dice: 0.2580  decode.d8.loss_cls: 0.0487  decode.d8.loss_mask: 0.2268  decode.d8.loss_dice: 0.2728
08/06 12:59:41 - mmengine - INFO - Iter(train) [ 77600/320000]  base_lr: 7.7884e-05 lr: 7.7884e-06  eta: 1 day, 9:15:39  time: 0.4969  data_time: 0.0114  memory: 5875  grad_norm: 237.9966  loss: 7.5422  decode.loss_cls: 0.0866  decode.loss_mask: 0.2742  decode.loss_dice: 0.2759  decode.d0.loss_cls: 0.8729  decode.d0.loss_mask: 0.2800  decode.d0.loss_dice: 0.2806  decode.d1.loss_cls: 0.1541  decode.d1.loss_mask: 0.2812  decode.d1.loss_dice: 0.2858  decode.d2.loss_cls: 0.1180  decode.d2.loss_mask: 0.2793  decode.d2.loss_dice: 0.2844  decode.d3.loss_cls: 0.1317  decode.d3.loss_mask: 0.2817  decode.d3.loss_dice: 0.2842  decode.d4.loss_cls: 0.1311  decode.d4.loss_mask: 0.2777  decode.d4.loss_dice: 0.2862  decode.d5.loss_cls: 0.1386  decode.d5.loss_mask: 0.2747  decode.d5.loss_dice: 0.2769  decode.d6.loss_cls: 0.1225  decode.d6.loss_mask: 0.2783  decode.d6.loss_dice: 0.2742  decode.d7.loss_cls: 0.1187  decode.d7.loss_mask: 0.2774  decode.d7.loss_dice: 0.2748  decode.d8.loss_cls: 0.0857  decode.d8.loss_mask: 0.2772  decode.d8.loss_dice: 0.2777
08/06 13:00:06 - mmengine - INFO - Iter(train) [ 77650/320000]  base_lr: 7.7869e-05 lr: 7.7869e-06  eta: 1 day, 9:15:15  time: 0.4979  data_time: 0.0115  memory: 5911  grad_norm: 110.0918  loss: 6.5693  decode.loss_cls: 0.0686  decode.loss_mask: 0.2562  decode.loss_dice: 0.2532  decode.d0.loss_cls: 0.9478  decode.d0.loss_mask: 0.2596  decode.d0.loss_dice: 0.2442  decode.d1.loss_cls: 0.0250  decode.d1.loss_mask: 0.2566  decode.d1.loss_dice: 0.2584  decode.d2.loss_cls: 0.0353  decode.d2.loss_mask: 0.2608  decode.d2.loss_dice: 0.2544  decode.d3.loss_cls: 0.0709  decode.d3.loss_mask: 0.2581  decode.d3.loss_dice: 0.2562  decode.d4.loss_cls: 0.0535  decode.d4.loss_mask: 0.2591  decode.d4.loss_dice: 0.2574  decode.d5.loss_cls: 0.0602  decode.d5.loss_mask: 0.2570  decode.d5.loss_dice: 0.2535  decode.d6.loss_cls: 0.0734  decode.d6.loss_mask: 0.2561  decode.d6.loss_dice: 0.2531  decode.d7.loss_cls: 0.0501  decode.d7.loss_mask: 0.2574  decode.d7.loss_dice: 0.2537  decode.d8.loss_cls: 0.0738  decode.d8.loss_mask: 0.2560  decode.d8.loss_dice: 0.2499
08/06 13:00:31 - mmengine - INFO - Iter(train) [ 77700/320000]  base_lr: 7.7855e-05 lr: 7.7855e-06  eta: 1 day, 9:14:51  time: 0.4986  data_time: 0.0116  memory: 5894  grad_norm: 159.6899  loss: 8.4086  decode.loss_cls: 0.1769  decode.loss_mask: 0.2681  decode.loss_dice: 0.2897  decode.d0.loss_cls: 1.1133  decode.d0.loss_mask: 0.2751  decode.d0.loss_dice: 0.2762  decode.d1.loss_cls: 0.1947  decode.d1.loss_mask: 0.2714  decode.d1.loss_dice: 0.2724  decode.d2.loss_cls: 0.2094  decode.d2.loss_mask: 0.2651  decode.d2.loss_dice: 0.2554  decode.d3.loss_cls: 0.2058  decode.d3.loss_mask: 0.2693  decode.d3.loss_dice: 0.2809  decode.d4.loss_cls: 0.1378  decode.d4.loss_mask: 0.2904  decode.d4.loss_dice: 0.2692  decode.d5.loss_cls: 0.1932  decode.d5.loss_mask: 0.2963  decode.d5.loss_dice: 0.2892  decode.d6.loss_cls: 0.1875  decode.d6.loss_mask: 0.3018  decode.d6.loss_dice: 0.3168  decode.d7.loss_cls: 0.2031  decode.d7.loss_mask: 0.2756  decode.d7.loss_dice: 0.2845  decode.d8.loss_cls: 0.2192  decode.d8.loss_mask: 0.2656  decode.d8.loss_dice: 0.2547
08/06 13:00:56 - mmengine - INFO - Iter(train) [ 77750/320000]  base_lr: 7.7840e-05 lr: 7.7840e-06  eta: 1 day, 9:14:26  time: 0.4984  data_time: 0.0116  memory: 5891  grad_norm: 133.5614  loss: 8.6161  decode.loss_cls: 0.2209  decode.loss_mask: 0.2282  decode.loss_dice: 0.3174  decode.d0.loss_cls: 0.9968  decode.d0.loss_mask: 0.2309  decode.d0.loss_dice: 0.3765  decode.d1.loss_cls: 0.2528  decode.d1.loss_mask: 0.2327  decode.d1.loss_dice: 0.3369  decode.d2.loss_cls: 0.2824  decode.d2.loss_mask: 0.2334  decode.d2.loss_dice: 0.2963  decode.d3.loss_cls: 0.2402  decode.d3.loss_mask: 0.2296  decode.d3.loss_dice: 0.3040  decode.d4.loss_cls: 0.2456  decode.d4.loss_mask: 0.2277  decode.d4.loss_dice: 0.3211  decode.d5.loss_cls: 0.2422  decode.d5.loss_mask: 0.2328  decode.d5.loss_dice: 0.3352  decode.d6.loss_cls: 0.1885  decode.d6.loss_mask: 0.2293  decode.d6.loss_dice: 0.3101  decode.d7.loss_cls: 0.1802  decode.d7.loss_mask: 0.2307  decode.d7.loss_dice: 0.3101  decode.d8.loss_cls: 0.2432  decode.d8.loss_mask: 0.2318  decode.d8.loss_dice: 0.3085
08/06 13:01:21 - mmengine - INFO - Iter(train) [ 77800/320000]  base_lr: 7.7826e-05 lr: 7.7826e-06  eta: 1 day, 9:14:02  time: 0.4991  data_time: 0.0116  memory: 5894  grad_norm: 79.3499  loss: 6.9486  decode.loss_cls: 0.0899  decode.loss_mask: 0.2417  decode.loss_dice: 0.2539  decode.d0.loss_cls: 0.9925  decode.d0.loss_mask: 0.2483  decode.d0.loss_dice: 0.2650  decode.d1.loss_cls: 0.1819  decode.d1.loss_mask: 0.2422  decode.d1.loss_dice: 0.2544  decode.d2.loss_cls: 0.1872  decode.d2.loss_mask: 0.2446  decode.d2.loss_dice: 0.2414  decode.d3.loss_cls: 0.0842  decode.d3.loss_mask: 0.2446  decode.d3.loss_dice: 0.2615  decode.d4.loss_cls: 0.0685  decode.d4.loss_mask: 0.2416  decode.d4.loss_dice: 0.2569  decode.d5.loss_cls: 0.1205  decode.d5.loss_mask: 0.2434  decode.d5.loss_dice: 0.2472  decode.d6.loss_cls: 0.1004  decode.d6.loss_mask: 0.2457  decode.d6.loss_dice: 0.2551  decode.d7.loss_cls: 0.0774  decode.d7.loss_mask: 0.2443  decode.d7.loss_dice: 0.2501  decode.d8.loss_cls: 0.0760  decode.d8.loss_mask: 0.2386  decode.d8.loss_dice: 0.2496
08/06 13:01:46 - mmengine - INFO - Iter(train) [ 77850/320000]  base_lr: 7.7811e-05 lr: 7.7811e-06  eta: 1 day, 9:13:38  time: 0.4977  data_time: 0.0114  memory: 5911  grad_norm: 59.2545  loss: 6.1619  decode.loss_cls: 0.0496  decode.loss_mask: 0.2143  decode.loss_dice: 0.2557  decode.d0.loss_cls: 0.8803  decode.d0.loss_mask: 0.2221  decode.d0.loss_dice: 0.2634  decode.d1.loss_cls: 0.0700  decode.d1.loss_mask: 0.2180  decode.d1.loss_dice: 0.2465  decode.d2.loss_cls: 0.0986  decode.d2.loss_mask: 0.2188  decode.d2.loss_dice: 0.2571  decode.d3.loss_cls: 0.0602  decode.d3.loss_mask: 0.2193  decode.d3.loss_dice: 0.2514  decode.d4.loss_cls: 0.0595  decode.d4.loss_mask: 0.2171  decode.d4.loss_dice: 0.2710  decode.d5.loss_cls: 0.0569  decode.d5.loss_mask: 0.2146  decode.d5.loss_dice: 0.2638  decode.d6.loss_cls: 0.0350  decode.d6.loss_mask: 0.2182  decode.d6.loss_dice: 0.2406  decode.d7.loss_cls: 0.0518  decode.d7.loss_mask: 0.2176  decode.d7.loss_dice: 0.2596  decode.d8.loss_cls: 0.0541  decode.d8.loss_mask: 0.2160  decode.d8.loss_dice: 0.2609
08/06 13:02:11 - mmengine - INFO - Iter(train) [ 77900/320000]  base_lr: 7.7797e-05 lr: 7.7797e-06  eta: 1 day, 9:13:14  time: 0.4974  data_time: 0.0114  memory: 5894  grad_norm: 63.6476  loss: 6.3187  decode.loss_cls: 0.0760  decode.loss_mask: 0.2192  decode.loss_dice: 0.2382  decode.d0.loss_cls: 0.7934  decode.d0.loss_mask: 0.2275  decode.d0.loss_dice: 0.2511  decode.d1.loss_cls: 0.1665  decode.d1.loss_mask: 0.2306  decode.d1.loss_dice: 0.2341  decode.d2.loss_cls: 0.0755  decode.d2.loss_mask: 0.2255  decode.d2.loss_dice: 0.2452  decode.d3.loss_cls: 0.1703  decode.d3.loss_mask: 0.2228  decode.d3.loss_dice: 0.2326  decode.d4.loss_cls: 0.0896  decode.d4.loss_mask: 0.2237  decode.d4.loss_dice: 0.2419  decode.d5.loss_cls: 0.0849  decode.d5.loss_mask: 0.2171  decode.d5.loss_dice: 0.2356  decode.d6.loss_cls: 0.0653  decode.d6.loss_mask: 0.2241  decode.d6.loss_dice: 0.2399  decode.d7.loss_cls: 0.0878  decode.d7.loss_mask: 0.2235  decode.d7.loss_dice: 0.2335  decode.d8.loss_cls: 0.0804  decode.d8.loss_mask: 0.2211  decode.d8.loss_dice: 0.2420
08/06 13:02:35 - mmengine - INFO - Iter(train) [ 77950/320000]  base_lr: 7.7782e-05 lr: 7.7782e-06  eta: 1 day, 9:12:50  time: 0.4977  data_time: 0.0115  memory: 5928  grad_norm: 119.4613  loss: 7.5801  decode.loss_cls: 0.1679  decode.loss_mask: 0.2266  decode.loss_dice: 0.2677  decode.d0.loss_cls: 0.8801  decode.d0.loss_mask: 0.2290  decode.d0.loss_dice: 0.2696  decode.d1.loss_cls: 0.2708  decode.d1.loss_mask: 0.2285  decode.d1.loss_dice: 0.2729  decode.d2.loss_cls: 0.2488  decode.d2.loss_mask: 0.2262  decode.d2.loss_dice: 0.2405  decode.d3.loss_cls: 0.1887  decode.d3.loss_mask: 0.2225  decode.d3.loss_dice: 0.2543  decode.d4.loss_cls: 0.2209  decode.d4.loss_mask: 0.2247  decode.d4.loss_dice: 0.2676  decode.d5.loss_cls: 0.1820  decode.d5.loss_mask: 0.2240  decode.d5.loss_dice: 0.2483  decode.d6.loss_cls: 0.2183  decode.d6.loss_mask: 0.2250  decode.d6.loss_dice: 0.2503  decode.d7.loss_cls: 0.1757  decode.d7.loss_mask: 0.2249  decode.d7.loss_dice: 0.2450  decode.d8.loss_cls: 0.2046  decode.d8.loss_mask: 0.2252  decode.d8.loss_dice: 0.2497
08/06 13:03:00 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 13:03:00 - mmengine - INFO - Iter(train) [ 78000/320000]  base_lr: 7.7768e-05 lr: 7.7768e-06  eta: 1 day, 9:12:26  time: 0.4979  data_time: 0.0115  memory: 5913  grad_norm: 76.9668  loss: 4.9514  decode.loss_cls: 0.0288  decode.loss_mask: 0.1969  decode.loss_dice: 0.2059  decode.d0.loss_cls: 0.7038  decode.d0.loss_mask: 0.1994  decode.d0.loss_dice: 0.2103  decode.d1.loss_cls: 0.0112  decode.d1.loss_mask: 0.2012  decode.d1.loss_dice: 0.2129  decode.d2.loss_cls: 0.0157  decode.d2.loss_mask: 0.1984  decode.d2.loss_dice: 0.2061  decode.d3.loss_cls: 0.0214  decode.d3.loss_mask: 0.1984  decode.d3.loss_dice: 0.2001  decode.d4.loss_cls: 0.0166  decode.d4.loss_mask: 0.1975  decode.d4.loss_dice: 0.2019  decode.d5.loss_cls: 0.0166  decode.d5.loss_mask: 0.1962  decode.d5.loss_dice: 0.2027  decode.d6.loss_cls: 0.0492  decode.d6.loss_mask: 0.1974  decode.d6.loss_dice: 0.2014  decode.d7.loss_cls: 0.0293  decode.d7.loss_mask: 0.1985  decode.d7.loss_dice: 0.2058  decode.d8.loss_cls: 0.0274  decode.d8.loss_mask: 0.1986  decode.d8.loss_dice: 0.2018
08/06 13:03:25 - mmengine - INFO - Iter(train) [ 78050/320000]  base_lr: 7.7753e-05 lr: 7.7753e-06  eta: 1 day, 9:12:02  time: 0.4978  data_time: 0.0114  memory: 5928  grad_norm: 73.6981  loss: 6.5785  decode.loss_cls: 0.1245  decode.loss_mask: 0.2008  decode.loss_dice: 0.2450  decode.d0.loss_cls: 0.9396  decode.d0.loss_mask: 0.2066  decode.d0.loss_dice: 0.2526  decode.d1.loss_cls: 0.1458  decode.d1.loss_mask: 0.2011  decode.d1.loss_dice: 0.2563  decode.d2.loss_cls: 0.1290  decode.d2.loss_mask: 0.2028  decode.d2.loss_dice: 0.2574  decode.d3.loss_cls: 0.1294  decode.d3.loss_mask: 0.2022  decode.d3.loss_dice: 0.2473  decode.d4.loss_cls: 0.1172  decode.d4.loss_mask: 0.1998  decode.d4.loss_dice: 0.2495  decode.d5.loss_cls: 0.0987  decode.d5.loss_mask: 0.2015  decode.d5.loss_dice: 0.2484  decode.d6.loss_cls: 0.1200  decode.d6.loss_mask: 0.2010  decode.d6.loss_dice: 0.2477  decode.d7.loss_cls: 0.1221  decode.d7.loss_mask: 0.2034  decode.d7.loss_dice: 0.2601  decode.d8.loss_cls: 0.1206  decode.d8.loss_mask: 0.2033  decode.d8.loss_dice: 0.2445
08/06 13:03:50 - mmengine - INFO - Iter(train) [ 78100/320000]  base_lr: 7.7739e-05 lr: 7.7739e-06  eta: 1 day, 9:11:38  time: 0.4988  data_time: 0.0114  memory: 5909  grad_norm: 273.3952  loss: 7.2962  decode.loss_cls: 0.0783  decode.loss_mask: 0.2644  decode.loss_dice: 0.3052  decode.d0.loss_cls: 0.9263  decode.d0.loss_mask: 0.2574  decode.d0.loss_dice: 0.2757  decode.d1.loss_cls: 0.1061  decode.d1.loss_mask: 0.2429  decode.d1.loss_dice: 0.2789  decode.d2.loss_cls: 0.1067  decode.d2.loss_mask: 0.2398  decode.d2.loss_dice: 0.2723  decode.d3.loss_cls: 0.1151  decode.d3.loss_mask: 0.2465  decode.d3.loss_dice: 0.2747  decode.d4.loss_cls: 0.0872  decode.d4.loss_mask: 0.2472  decode.d4.loss_dice: 0.2876  decode.d5.loss_cls: 0.0805  decode.d5.loss_mask: 0.2510  decode.d5.loss_dice: 0.2797  decode.d6.loss_cls: 0.1370  decode.d6.loss_mask: 0.2633  decode.d6.loss_dice: 0.3035  decode.d7.loss_cls: 0.1129  decode.d7.loss_mask: 0.2577  decode.d7.loss_dice: 0.2916  decode.d8.loss_cls: 0.1382  decode.d8.loss_mask: 0.2657  decode.d8.loss_dice: 0.3026
08/06 13:04:15 - mmengine - INFO - Iter(train) [ 78150/320000]  base_lr: 7.7724e-05 lr: 7.7724e-06  eta: 1 day, 9:11:14  time: 0.4972  data_time: 0.0112  memory: 5911  grad_norm: 174.0970  loss: 6.3735  decode.loss_cls: 0.1304  decode.loss_mask: 0.2088  decode.loss_dice: 0.2304  decode.d0.loss_cls: 0.9216  decode.d0.loss_mask: 0.2119  decode.d0.loss_dice: 0.2415  decode.d1.loss_cls: 0.0887  decode.d1.loss_mask: 0.2138  decode.d1.loss_dice: 0.2391  decode.d2.loss_cls: 0.0887  decode.d2.loss_mask: 0.2093  decode.d2.loss_dice: 0.2337  decode.d3.loss_cls: 0.1246  decode.d3.loss_mask: 0.2093  decode.d3.loss_dice: 0.2372  decode.d4.loss_cls: 0.1089  decode.d4.loss_mask: 0.2123  decode.d4.loss_dice: 0.2322  decode.d5.loss_cls: 0.1031  decode.d5.loss_mask: 0.2110  decode.d5.loss_dice: 0.2372  decode.d6.loss_cls: 0.1020  decode.d6.loss_mask: 0.2115  decode.d6.loss_dice: 0.2391  decode.d7.loss_cls: 0.1152  decode.d7.loss_mask: 0.2137  decode.d7.loss_dice: 0.2409  decode.d8.loss_cls: 0.1138  decode.d8.loss_mask: 0.2098  decode.d8.loss_dice: 0.2337
08/06 13:04:40 - mmengine - INFO - Iter(train) [ 78200/320000]  base_lr: 7.7710e-05 lr: 7.7710e-06  eta: 1 day, 9:10:49  time: 0.4964  data_time: 0.0111  memory: 5894  grad_norm: 231.6076  loss: 7.4689  decode.loss_cls: 0.2105  decode.loss_mask: 0.2047  decode.loss_dice: 0.2638  decode.d0.loss_cls: 0.9773  decode.d0.loss_mask: 0.2067  decode.d0.loss_dice: 0.2625  decode.d1.loss_cls: 0.2287  decode.d1.loss_mask: 0.2091  decode.d1.loss_dice: 0.2633  decode.d2.loss_cls: 0.2385  decode.d2.loss_mask: 0.2134  decode.d2.loss_dice: 0.2644  decode.d3.loss_cls: 0.1922  decode.d3.loss_mask: 0.2129  decode.d3.loss_dice: 0.2629  decode.d4.loss_cls: 0.1580  decode.d4.loss_mask: 0.2156  decode.d4.loss_dice: 0.2991  decode.d5.loss_cls: 0.1737  decode.d5.loss_mask: 0.2140  decode.d5.loss_dice: 0.2754  decode.d6.loss_cls: 0.1308  decode.d6.loss_mask: 0.2163  decode.d6.loss_dice: 0.2719  decode.d7.loss_cls: 0.2074  decode.d7.loss_mask: 0.2060  decode.d7.loss_dice: 0.2632  decode.d8.loss_cls: 0.1375  decode.d8.loss_mask: 0.2090  decode.d8.loss_dice: 0.2799
08/06 13:05:05 - mmengine - INFO - Iter(train) [ 78250/320000]  base_lr: 7.7696e-05 lr: 7.7696e-06  eta: 1 day, 9:10:25  time: 0.4983  data_time: 0.0114  memory: 5894  grad_norm: 68.6183  loss: 6.3275  decode.loss_cls: 0.0865  decode.loss_mask: 0.2279  decode.loss_dice: 0.2374  decode.d0.loss_cls: 0.8063  decode.d0.loss_mask: 0.2352  decode.d0.loss_dice: 0.2613  decode.d1.loss_cls: 0.0877  decode.d1.loss_mask: 0.2327  decode.d1.loss_dice: 0.2545  decode.d2.loss_cls: 0.0918  decode.d2.loss_mask: 0.2311  decode.d2.loss_dice: 0.2479  decode.d3.loss_cls: 0.0862  decode.d3.loss_mask: 0.2285  decode.d3.loss_dice: 0.2371  decode.d4.loss_cls: 0.0911  decode.d4.loss_mask: 0.2302  decode.d4.loss_dice: 0.2550  decode.d5.loss_cls: 0.0828  decode.d5.loss_mask: 0.2314  decode.d5.loss_dice: 0.2593  decode.d6.loss_cls: 0.0581  decode.d6.loss_mask: 0.2306  decode.d6.loss_dice: 0.2526  decode.d7.loss_cls: 0.0590  decode.d7.loss_mask: 0.2296  decode.d7.loss_dice: 0.2418  decode.d8.loss_cls: 0.0735  decode.d8.loss_mask: 0.2301  decode.d8.loss_dice: 0.2505
08/06 13:05:30 - mmengine - INFO - Iter(train) [ 78300/320000]  base_lr: 7.7681e-05 lr: 7.7681e-06  eta: 1 day, 9:10:01  time: 0.4966  data_time: 0.0114  memory: 5876  grad_norm: 68.3633  loss: 5.9657  decode.loss_cls: 0.0357  decode.loss_mask: 0.2259  decode.loss_dice: 0.2651  decode.d0.loss_cls: 0.7648  decode.d0.loss_mask: 0.2294  decode.d0.loss_dice: 0.2546  decode.d1.loss_cls: 0.0295  decode.d1.loss_mask: 0.2299  decode.d1.loss_dice: 0.2555  decode.d2.loss_cls: 0.0794  decode.d2.loss_mask: 0.2267  decode.d2.loss_dice: 0.2256  decode.d3.loss_cls: 0.0738  decode.d3.loss_mask: 0.2252  decode.d3.loss_dice: 0.2552  decode.d4.loss_cls: 0.0223  decode.d4.loss_mask: 0.2263  decode.d4.loss_dice: 0.2516  decode.d5.loss_cls: 0.0298  decode.d5.loss_mask: 0.2261  decode.d5.loss_dice: 0.2512  decode.d6.loss_cls: 0.0283  decode.d6.loss_mask: 0.2269  decode.d6.loss_dice: 0.2602  decode.d7.loss_cls: 0.0301  decode.d7.loss_mask: 0.2239  decode.d7.loss_dice: 0.2490  decode.d8.loss_cls: 0.0779  decode.d8.loss_mask: 0.2270  decode.d8.loss_dice: 0.2584
08/06 13:05:55 - mmengine - INFO - Iter(train) [ 78350/320000]  base_lr: 7.7667e-05 lr: 7.7667e-06  eta: 1 day, 9:09:37  time: 0.4964  data_time: 0.0114  memory: 5878  grad_norm: 50.2026  loss: 6.4065  decode.loss_cls: 0.0585  decode.loss_mask: 0.2609  decode.loss_dice: 0.2475  decode.d0.loss_cls: 0.7731  decode.d0.loss_mask: 0.2626  decode.d0.loss_dice: 0.2456  decode.d1.loss_cls: 0.0578  decode.d1.loss_mask: 0.2671  decode.d1.loss_dice: 0.2495  decode.d2.loss_cls: 0.0571  decode.d2.loss_mask: 0.2627  decode.d2.loss_dice: 0.2446  decode.d3.loss_cls: 0.0594  decode.d3.loss_mask: 0.2600  decode.d3.loss_dice: 0.2478  decode.d4.loss_cls: 0.0526  decode.d4.loss_mask: 0.2578  decode.d4.loss_dice: 0.2522  decode.d5.loss_cls: 0.0675  decode.d5.loss_mask: 0.2587  decode.d5.loss_dice: 0.2548  decode.d6.loss_cls: 0.0669  decode.d6.loss_mask: 0.2593  decode.d6.loss_dice: 0.2400  decode.d7.loss_cls: 0.0557  decode.d7.loss_mask: 0.2623  decode.d7.loss_dice: 0.2473  decode.d8.loss_cls: 0.0622  decode.d8.loss_mask: 0.2646  decode.d8.loss_dice: 0.2504
08/06 13:06:19 - mmengine - INFO - Iter(train) [ 78400/320000]  base_lr: 7.7652e-05 lr: 7.7652e-06  eta: 1 day, 9:09:13  time: 0.4979  data_time: 0.0115  memory: 5894  grad_norm: 378.6067  loss: 7.6505  decode.loss_cls: 0.1641  decode.loss_mask: 0.2402  decode.loss_dice: 0.2727  decode.d0.loss_cls: 0.9331  decode.d0.loss_mask: 0.2563  decode.d0.loss_dice: 0.2819  decode.d1.loss_cls: 0.1202  decode.d1.loss_mask: 0.2378  decode.d1.loss_dice: 0.2733  decode.d2.loss_cls: 0.1828  decode.d2.loss_mask: 0.2407  decode.d2.loss_dice: 0.2774  decode.d3.loss_cls: 0.1385  decode.d3.loss_mask: 0.2457  decode.d3.loss_dice: 0.2728  decode.d4.loss_cls: 0.1667  decode.d4.loss_mask: 0.2452  decode.d4.loss_dice: 0.2732  decode.d5.loss_cls: 0.2029  decode.d5.loss_mask: 0.2402  decode.d5.loss_dice: 0.2733  decode.d6.loss_cls: 0.1758  decode.d6.loss_mask: 0.2371  decode.d6.loss_dice: 0.2708  decode.d7.loss_cls: 0.2203  decode.d7.loss_mask: 0.2452  decode.d7.loss_dice: 0.2715  decode.d8.loss_cls: 0.1736  decode.d8.loss_mask: 0.2425  decode.d8.loss_dice: 0.2749
08/06 13:06:44 - mmengine - INFO - Iter(train) [ 78450/320000]  base_lr: 7.7638e-05 lr: 7.7638e-06  eta: 1 day, 9:08:49  time: 0.4966  data_time: 0.0116  memory: 5911  grad_norm: 160.8996  loss: 6.2333  decode.loss_cls: 0.0852  decode.loss_mask: 0.2333  decode.loss_dice: 0.2433  decode.d0.loss_cls: 0.7714  decode.d0.loss_mask: 0.2366  decode.d0.loss_dice: 0.2526  decode.d1.loss_cls: 0.0807  decode.d1.loss_mask: 0.2312  decode.d1.loss_dice: 0.2317  decode.d2.loss_cls: 0.0733  decode.d2.loss_mask: 0.2329  decode.d2.loss_dice: 0.2433  decode.d3.loss_cls: 0.0895  decode.d3.loss_mask: 0.2322  decode.d3.loss_dice: 0.2523  decode.d4.loss_cls: 0.0775  decode.d4.loss_mask: 0.2279  decode.d4.loss_dice: 0.2336  decode.d5.loss_cls: 0.0720  decode.d5.loss_mask: 0.2301  decode.d5.loss_dice: 0.2417  decode.d6.loss_cls: 0.0749  decode.d6.loss_mask: 0.2270  decode.d6.loss_dice: 0.2318  decode.d7.loss_cls: 0.0956  decode.d7.loss_mask: 0.2274  decode.d7.loss_dice: 0.2496  decode.d8.loss_cls: 0.0878  decode.d8.loss_mask: 0.2296  decode.d8.loss_dice: 0.2374
08/06 13:07:09 - mmengine - INFO - Iter(train) [ 78500/320000]  base_lr: 7.7623e-05 lr: 7.7623e-06  eta: 1 day, 9:08:25  time: 0.4976  data_time: 0.0114  memory: 5890  grad_norm: 139.7674  loss: 8.0431  decode.loss_cls: 0.2189  decode.loss_mask: 0.1883  decode.loss_dice: 0.3298  decode.d0.loss_cls: 0.9977  decode.d0.loss_mask: 0.1867  decode.d0.loss_dice: 0.3032  decode.d1.loss_cls: 0.2601  decode.d1.loss_mask: 0.1873  decode.d1.loss_dice: 0.3149  decode.d2.loss_cls: 0.2334  decode.d2.loss_mask: 0.1791  decode.d2.loss_dice: 0.3086  decode.d3.loss_cls: 0.2232  decode.d3.loss_mask: 0.1906  decode.d3.loss_dice: 0.3118  decode.d4.loss_cls: 0.2341  decode.d4.loss_mask: 0.1845  decode.d4.loss_dice: 0.3344  decode.d5.loss_cls: 0.2417  decode.d5.loss_mask: 0.1848  decode.d5.loss_dice: 0.3204  decode.d6.loss_cls: 0.2074  decode.d6.loss_mask: 0.1881  decode.d6.loss_dice: 0.2998  decode.d7.loss_cls: 0.2113  decode.d7.loss_mask: 0.1874  decode.d7.loss_dice: 0.3225  decode.d8.loss_cls: 0.1888  decode.d8.loss_mask: 0.1904  decode.d8.loss_dice: 0.3138
08/06 13:07:34 - mmengine - INFO - Iter(train) [ 78550/320000]  base_lr: 7.7609e-05 lr: 7.7609e-06  eta: 1 day, 9:08:01  time: 0.4981  data_time: 0.0114  memory: 5968  grad_norm: 97.6720  loss: 6.2498  decode.loss_cls: 0.0765  decode.loss_mask: 0.2037  decode.loss_dice: 0.2709  decode.d0.loss_cls: 0.9398  decode.d0.loss_mask: 0.2040  decode.d0.loss_dice: 0.2662  decode.d1.loss_cls: 0.1110  decode.d1.loss_mask: 0.2031  decode.d1.loss_dice: 0.2557  decode.d2.loss_cls: 0.0688  decode.d2.loss_mask: 0.2026  decode.d2.loss_dice: 0.2603  decode.d3.loss_cls: 0.0749  decode.d3.loss_mask: 0.2025  decode.d3.loss_dice: 0.2561  decode.d4.loss_cls: 0.0601  decode.d4.loss_mask: 0.2027  decode.d4.loss_dice: 0.2656  decode.d5.loss_cls: 0.0652  decode.d5.loss_mask: 0.2018  decode.d5.loss_dice: 0.2603  decode.d6.loss_cls: 0.0350  decode.d6.loss_mask: 0.2040  decode.d6.loss_dice: 0.2784  decode.d7.loss_cls: 0.0642  decode.d7.loss_mask: 0.2049  decode.d7.loss_dice: 0.2789  decode.d8.loss_cls: 0.0649  decode.d8.loss_mask: 0.2010  decode.d8.loss_dice: 0.2667
08/06 13:07:59 - mmengine - INFO - Iter(train) [ 78600/320000]  base_lr: 7.7594e-05 lr: 7.7594e-06  eta: 1 day, 9:07:37  time: 0.4972  data_time: 0.0113  memory: 5891  grad_norm: 184.2980  loss: 6.9596  decode.loss_cls: 0.1173  decode.loss_mask: 0.2322  decode.loss_dice: 0.2757  decode.d0.loss_cls: 0.9943  decode.d0.loss_mask: 0.2396  decode.d0.loss_dice: 0.2578  decode.d1.loss_cls: 0.1045  decode.d1.loss_mask: 0.2383  decode.d1.loss_dice: 0.2733  decode.d2.loss_cls: 0.1078  decode.d2.loss_mask: 0.2358  decode.d2.loss_dice: 0.2745  decode.d3.loss_cls: 0.1044  decode.d3.loss_mask: 0.2299  decode.d3.loss_dice: 0.2649  decode.d4.loss_cls: 0.0750  decode.d4.loss_mask: 0.2330  decode.d4.loss_dice: 0.2653  decode.d5.loss_cls: 0.1089  decode.d5.loss_mask: 0.2350  decode.d5.loss_dice: 0.2649  decode.d6.loss_cls: 0.0894  decode.d6.loss_mask: 0.2317  decode.d6.loss_dice: 0.2677  decode.d7.loss_cls: 0.1094  decode.d7.loss_mask: 0.2471  decode.d7.loss_dice: 0.2784  decode.d8.loss_cls: 0.0871  decode.d8.loss_mask: 0.2387  decode.d8.loss_dice: 0.2778
08/06 13:08:24 - mmengine - INFO - Iter(train) [ 78650/320000]  base_lr: 7.7580e-05 lr: 7.7580e-06  eta: 1 day, 9:07:12  time: 0.4978  data_time: 0.0117  memory: 5911  grad_norm: 148.1237  loss: 7.4901  decode.loss_cls: 0.1699  decode.loss_mask: 0.2179  decode.loss_dice: 0.3024  decode.d0.loss_cls: 0.8208  decode.d0.loss_mask: 0.2015  decode.d0.loss_dice: 0.3169  decode.d1.loss_cls: 0.2195  decode.d1.loss_mask: 0.2197  decode.d1.loss_dice: 0.2606  decode.d2.loss_cls: 0.1704  decode.d2.loss_mask: 0.2274  decode.d2.loss_dice: 0.2717  decode.d3.loss_cls: 0.1879  decode.d3.loss_mask: 0.2149  decode.d3.loss_dice: 0.2832  decode.d4.loss_cls: 0.1790  decode.d4.loss_mask: 0.2119  decode.d4.loss_dice: 0.3042  decode.d5.loss_cls: 0.1863  decode.d5.loss_mask: 0.2165  decode.d5.loss_dice: 0.3062  decode.d6.loss_cls: 0.1184  decode.d6.loss_mask: 0.2121  decode.d6.loss_dice: 0.2936  decode.d7.loss_cls: 0.1934  decode.d7.loss_mask: 0.2173  decode.d7.loss_dice: 0.2811  decode.d8.loss_cls: 0.1857  decode.d8.loss_mask: 0.2173  decode.d8.loss_dice: 0.2821
08/06 13:08:49 - mmengine - INFO - Iter(train) [ 78700/320000]  base_lr: 7.7565e-05 lr: 7.7565e-06  eta: 1 day, 9:06:48  time: 0.4986  data_time: 0.0116  memory: 5932  grad_norm: 44.9918  loss: 7.0865  decode.loss_cls: 0.1714  decode.loss_mask: 0.1898  decode.loss_dice: 0.3091  decode.d0.loss_cls: 0.9237  decode.d0.loss_mask: 0.1922  decode.d0.loss_dice: 0.2895  decode.d1.loss_cls: 0.1548  decode.d1.loss_mask: 0.1949  decode.d1.loss_dice: 0.2948  decode.d2.loss_cls: 0.1277  decode.d2.loss_mask: 0.1908  decode.d2.loss_dice: 0.2775  decode.d3.loss_cls: 0.1312  decode.d3.loss_mask: 0.1924  decode.d3.loss_dice: 0.2846  decode.d4.loss_cls: 0.1501  decode.d4.loss_mask: 0.1919  decode.d4.loss_dice: 0.3041  decode.d5.loss_cls: 0.1289  decode.d5.loss_mask: 0.1899  decode.d5.loss_dice: 0.2764  decode.d6.loss_cls: 0.1394  decode.d6.loss_mask: 0.1909  decode.d6.loss_dice: 0.3094  decode.d7.loss_cls: 0.1764  decode.d7.loss_mask: 0.1917  decode.d7.loss_dice: 0.2767  decode.d8.loss_cls: 0.1497  decode.d8.loss_mask: 0.1900  decode.d8.loss_dice: 0.2967
08/06 13:09:14 - mmengine - INFO - Iter(train) [ 78750/320000]  base_lr: 7.7551e-05 lr: 7.7551e-06  eta: 1 day, 9:06:25  time: 0.4975  data_time: 0.0114  memory: 5911  grad_norm: 72.5759  loss: 5.7332  decode.loss_cls: 0.0071  decode.loss_mask: 0.2504  decode.loss_dice: 0.2340  decode.d0.loss_cls: 0.7813  decode.d0.loss_mask: 0.2568  decode.d0.loss_dice: 0.2281  decode.d1.loss_cls: 0.0089  decode.d1.loss_mask: 0.2506  decode.d1.loss_dice: 0.2299  decode.d2.loss_cls: 0.0087  decode.d2.loss_mask: 0.2500  decode.d2.loss_dice: 0.2311  decode.d3.loss_cls: 0.0111  decode.d3.loss_mask: 0.2476  decode.d3.loss_dice: 0.2300  decode.d4.loss_cls: 0.0101  decode.d4.loss_mask: 0.2502  decode.d4.loss_dice: 0.2316  decode.d5.loss_cls: 0.0102  decode.d5.loss_mask: 0.2509  decode.d5.loss_dice: 0.2337  decode.d6.loss_cls: 0.0083  decode.d6.loss_mask: 0.2496  decode.d6.loss_dice: 0.2338  decode.d7.loss_cls: 0.0071  decode.d7.loss_mask: 0.2497  decode.d7.loss_dice: 0.2319  decode.d8.loss_cls: 0.0664  decode.d8.loss_mask: 0.2496  decode.d8.loss_dice: 0.2246
08/06 13:09:39 - mmengine - INFO - Iter(train) [ 78800/320000]  base_lr: 7.7536e-05 lr: 7.7536e-06  eta: 1 day, 9:06:01  time: 0.4981  data_time: 0.0115  memory: 5891  grad_norm: 82.3884  loss: 6.2617  decode.loss_cls: 0.0746  decode.loss_mask: 0.2043  decode.loss_dice: 0.2514  decode.d0.loss_cls: 0.8241  decode.d0.loss_mask: 0.2065  decode.d0.loss_dice: 0.2795  decode.d1.loss_cls: 0.0986  decode.d1.loss_mask: 0.2090  decode.d1.loss_dice: 0.2525  decode.d2.loss_cls: 0.0963  decode.d2.loss_mask: 0.2063  decode.d2.loss_dice: 0.2459  decode.d3.loss_cls: 0.0898  decode.d3.loss_mask: 0.2098  decode.d3.loss_dice: 0.2603  decode.d4.loss_cls: 0.0569  decode.d4.loss_mask: 0.2066  decode.d4.loss_dice: 0.2603  decode.d5.loss_cls: 0.0817  decode.d5.loss_mask: 0.2071  decode.d5.loss_dice: 0.2592  decode.d6.loss_cls: 0.0787  decode.d6.loss_mask: 0.2054  decode.d6.loss_dice: 0.2616  decode.d7.loss_cls: 0.1129  decode.d7.loss_mask: 0.2085  decode.d7.loss_dice: 0.2673  decode.d8.loss_cls: 0.0861  decode.d8.loss_mask: 0.2053  decode.d8.loss_dice: 0.2551
08/06 13:10:04 - mmengine - INFO - Iter(train) [ 78850/320000]  base_lr: 7.7522e-05 lr: 7.7522e-06  eta: 1 day, 9:05:37  time: 0.4981  data_time: 0.0114  memory: 5911  grad_norm: 48.5436  loss: 4.8478  decode.loss_cls: 0.0522  decode.loss_mask: 0.1394  decode.loss_dice: 0.1844  decode.d0.loss_cls: 1.0020  decode.d0.loss_mask: 0.1406  decode.d0.loss_dice: 0.1837  decode.d1.loss_cls: 0.1104  decode.d1.loss_mask: 0.1393  decode.d1.loss_dice: 0.1775  decode.d2.loss_cls: 0.0513  decode.d2.loss_mask: 0.1397  decode.d2.loss_dice: 0.2111  decode.d3.loss_cls: 0.0850  decode.d3.loss_mask: 0.1422  decode.d3.loss_dice: 0.1764  decode.d4.loss_cls: 0.0845  decode.d4.loss_mask: 0.1402  decode.d4.loss_dice: 0.1931  decode.d5.loss_cls: 0.0599  decode.d5.loss_mask: 0.1419  decode.d5.loss_dice: 0.1763  decode.d6.loss_cls: 0.0457  decode.d6.loss_mask: 0.1405  decode.d6.loss_dice: 0.1796  decode.d7.loss_cls: 0.0553  decode.d7.loss_mask: 0.1398  decode.d7.loss_dice: 0.1786  decode.d8.loss_cls: 0.0411  decode.d8.loss_mask: 0.1410  decode.d8.loss_dice: 0.1949
08/06 13:10:29 - mmengine - INFO - Iter(train) [ 78900/320000]  base_lr: 7.7508e-05 lr: 7.7508e-06  eta: 1 day, 9:05:12  time: 0.4980  data_time: 0.0117  memory: 5911  grad_norm: 84.7856  loss: 5.9509  decode.loss_cls: 0.0900  decode.loss_mask: 0.1985  decode.loss_dice: 0.2149  decode.d0.loss_cls: 0.7873  decode.d0.loss_mask: 0.1951  decode.d0.loss_dice: 0.2442  decode.d1.loss_cls: 0.0860  decode.d1.loss_mask: 0.2027  decode.d1.loss_dice: 0.2238  decode.d2.loss_cls: 0.1086  decode.d2.loss_mask: 0.1941  decode.d2.loss_dice: 0.2161  decode.d3.loss_cls: 0.1224  decode.d3.loss_mask: 0.1945  decode.d3.loss_dice: 0.2422  decode.d4.loss_cls: 0.0894  decode.d4.loss_mask: 0.1914  decode.d4.loss_dice: 0.2137  decode.d5.loss_cls: 0.1241  decode.d5.loss_mask: 0.1958  decode.d5.loss_dice: 0.2232  decode.d6.loss_cls: 0.1128  decode.d6.loss_mask: 0.2018  decode.d6.loss_dice: 0.2287  decode.d7.loss_cls: 0.1172  decode.d7.loss_mask: 0.1977  decode.d7.loss_dice: 0.2197  decode.d8.loss_cls: 0.1083  decode.d8.loss_mask: 0.1964  decode.d8.loss_dice: 0.2104
08/06 13:10:54 - mmengine - INFO - Iter(train) [ 78950/320000]  base_lr: 7.7493e-05 lr: 7.7493e-06  eta: 1 day, 9:04:48  time: 0.4996  data_time: 0.0117  memory: 5913  grad_norm: 73.4708  loss: 6.5929  decode.loss_cls: 0.0603  decode.loss_mask: 0.2403  decode.loss_dice: 0.2888  decode.d0.loss_cls: 0.7282  decode.d0.loss_mask: 0.2442  decode.d0.loss_dice: 0.2875  decode.d1.loss_cls: 0.0236  decode.d1.loss_mask: 0.2406  decode.d1.loss_dice: 0.2880  decode.d2.loss_cls: 0.0638  decode.d2.loss_mask: 0.2420  decode.d2.loss_dice: 0.2937  decode.d3.loss_cls: 0.0538  decode.d3.loss_mask: 0.2417  decode.d3.loss_dice: 0.2924  decode.d4.loss_cls: 0.0928  decode.d4.loss_mask: 0.2428  decode.d4.loss_dice: 0.2912  decode.d5.loss_cls: 0.0505  decode.d5.loss_mask: 0.2423  decode.d5.loss_dice: 0.2941  decode.d6.loss_cls: 0.0689  decode.d6.loss_mask: 0.2437  decode.d6.loss_dice: 0.2921  decode.d7.loss_cls: 0.0619  decode.d7.loss_mask: 0.2428  decode.d7.loss_dice: 0.2919  decode.d8.loss_cls: 0.0574  decode.d8.loss_mask: 0.2414  decode.d8.loss_dice: 0.2902
08/06 13:11:19 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 13:11:19 - mmengine - INFO - Iter(train) [ 79000/320000]  base_lr: 7.7479e-05 lr: 7.7479e-06  eta: 1 day, 9:04:24  time: 0.4971  data_time: 0.0115  memory: 5895  grad_norm: 152.7576  loss: 6.7954  decode.loss_cls: 0.1630  decode.loss_mask: 0.2172  decode.loss_dice: 0.2263  decode.d0.loss_cls: 0.9308  decode.d0.loss_mask: 0.2164  decode.d0.loss_dice: 0.2294  decode.d1.loss_cls: 0.1745  decode.d1.loss_mask: 0.2182  decode.d1.loss_dice: 0.2413  decode.d2.loss_cls: 0.1443  decode.d2.loss_mask: 0.2139  decode.d2.loss_dice: 0.2232  decode.d3.loss_cls: 0.1098  decode.d3.loss_mask: 0.2175  decode.d3.loss_dice: 0.2215  decode.d4.loss_cls: 0.1538  decode.d4.loss_mask: 0.2174  decode.d4.loss_dice: 0.2358  decode.d5.loss_cls: 0.1417  decode.d5.loss_mask: 0.2169  decode.d5.loss_dice: 0.2323  decode.d6.loss_cls: 0.1434  decode.d6.loss_mask: 0.2157  decode.d6.loss_dice: 0.2180  decode.d7.loss_cls: 0.1912  decode.d7.loss_mask: 0.2173  decode.d7.loss_dice: 0.2222  decode.d8.loss_cls: 0.1961  decode.d8.loss_mask: 0.2166  decode.d8.loss_dice: 0.2300
08/06 13:11:43 - mmengine - INFO - Iter(train) [ 79050/320000]  base_lr: 7.7464e-05 lr: 7.7464e-06  eta: 1 day, 9:04:00  time: 0.4987  data_time: 0.0113  memory: 5909  grad_norm: 32.6745  loss: 4.8771  decode.loss_cls: 0.0086  decode.loss_mask: 0.1972  decode.loss_dice: 0.1967  decode.d0.loss_cls: 0.7600  decode.d0.loss_mask: 0.1992  decode.d0.loss_dice: 0.1995  decode.d1.loss_cls: 0.0237  decode.d1.loss_mask: 0.2001  decode.d1.loss_dice: 0.2072  decode.d2.loss_cls: 0.0127  decode.d2.loss_mask: 0.1959  decode.d2.loss_dice: 0.2022  decode.d3.loss_cls: 0.0095  decode.d3.loss_mask: 0.1989  decode.d3.loss_dice: 0.2015  decode.d4.loss_cls: 0.0082  decode.d4.loss_mask: 0.2008  decode.d4.loss_dice: 0.2029  decode.d5.loss_cls: 0.0093  decode.d5.loss_mask: 0.1990  decode.d5.loss_dice: 0.1987  decode.d6.loss_cls: 0.0092  decode.d6.loss_mask: 0.2001  decode.d6.loss_dice: 0.2056  decode.d7.loss_cls: 0.0100  decode.d7.loss_mask: 0.1981  decode.d7.loss_dice: 0.2044  decode.d8.loss_cls: 0.0102  decode.d8.loss_mask: 0.1980  decode.d8.loss_dice: 0.2095
08/06 13:12:08 - mmengine - INFO - Iter(train) [ 79100/320000]  base_lr: 7.7450e-05 lr: 7.7450e-06  eta: 1 day, 9:03:36  time: 0.4979  data_time: 0.0116  memory: 5894  grad_norm: 66.3376  loss: 6.2533  decode.loss_cls: 0.0094  decode.loss_mask: 0.2497  decode.loss_dice: 0.2850  decode.d0.loss_cls: 0.7324  decode.d0.loss_mask: 0.2501  decode.d0.loss_dice: 0.2946  decode.d1.loss_cls: 0.0816  decode.d1.loss_mask: 0.2497  decode.d1.loss_dice: 0.2791  decode.d2.loss_cls: 0.0096  decode.d2.loss_mask: 0.2504  decode.d2.loss_dice: 0.2943  decode.d3.loss_cls: 0.0079  decode.d3.loss_mask: 0.2516  decode.d3.loss_dice: 0.2861  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.2478  decode.d4.loss_dice: 0.2865  decode.d5.loss_cls: 0.0056  decode.d5.loss_mask: 0.2470  decode.d5.loss_dice: 0.2853  decode.d6.loss_cls: 0.0086  decode.d6.loss_mask: 0.2492  decode.d6.loss_dice: 0.2878  decode.d7.loss_cls: 0.0104  decode.d7.loss_mask: 0.2483  decode.d7.loss_dice: 0.2873  decode.d8.loss_cls: 0.0102  decode.d8.loss_mask: 0.2480  decode.d8.loss_dice: 0.2935
08/06 13:12:33 - mmengine - INFO - Iter(train) [ 79150/320000]  base_lr: 7.7435e-05 lr: 7.7435e-06  eta: 1 day, 9:03:12  time: 0.4975  data_time: 0.0114  memory: 5895  grad_norm: 83.8045  loss: 8.2033  decode.loss_cls: 0.2026  decode.loss_mask: 0.2238  decode.loss_dice: 0.2644  decode.d0.loss_cls: 0.9388  decode.d0.loss_mask: 0.2290  decode.d0.loss_dice: 0.3201  decode.d1.loss_cls: 0.2657  decode.d1.loss_mask: 0.2275  decode.d1.loss_dice: 0.2725  decode.d2.loss_cls: 0.3289  decode.d2.loss_mask: 0.2220  decode.d2.loss_dice: 0.2805  decode.d3.loss_cls: 0.2275  decode.d3.loss_mask: 0.2291  decode.d3.loss_dice: 0.2896  decode.d4.loss_cls: 0.2962  decode.d4.loss_mask: 0.2251  decode.d4.loss_dice: 0.2851  decode.d5.loss_cls: 0.2190  decode.d5.loss_mask: 0.2250  decode.d5.loss_dice: 0.3115  decode.d6.loss_cls: 0.2038  decode.d6.loss_mask: 0.2230  decode.d6.loss_dice: 0.2865  decode.d7.loss_cls: 0.2319  decode.d7.loss_mask: 0.2215  decode.d7.loss_dice: 0.2900  decode.d8.loss_cls: 0.1465  decode.d8.loss_mask: 0.2249  decode.d8.loss_dice: 0.2913
08/06 13:12:58 - mmengine - INFO - Iter(train) [ 79200/320000]  base_lr: 7.7421e-05 lr: 7.7421e-06  eta: 1 day, 9:02:48  time: 0.4983  data_time: 0.0116  memory: 5895  grad_norm: 58.8185  loss: 7.3713  decode.loss_cls: 0.0839  decode.loss_mask: 0.2292  decode.loss_dice: 0.2922  decode.d0.loss_cls: 0.9155  decode.d0.loss_mask: 0.1995  decode.d0.loss_dice: 0.2731  decode.d1.loss_cls: 0.1563  decode.d1.loss_mask: 0.2096  decode.d1.loss_dice: 0.3130  decode.d2.loss_cls: 0.1553  decode.d2.loss_mask: 0.2064  decode.d2.loss_dice: 0.2873  decode.d3.loss_cls: 0.1512  decode.d3.loss_mask: 0.2065  decode.d3.loss_dice: 0.2919  decode.d4.loss_cls: 0.2181  decode.d4.loss_mask: 0.1994  decode.d4.loss_dice: 0.2817  decode.d5.loss_cls: 0.1287  decode.d5.loss_mask: 0.2063  decode.d5.loss_dice: 0.2916  decode.d6.loss_cls: 0.2373  decode.d6.loss_mask: 0.2075  decode.d6.loss_dice: 0.2752  decode.d7.loss_cls: 0.1944  decode.d7.loss_mask: 0.2094  decode.d7.loss_dice: 0.2875  decode.d8.loss_cls: 0.1532  decode.d8.loss_mask: 0.2105  decode.d8.loss_dice: 0.2997
08/06 13:13:23 - mmengine - INFO - Iter(train) [ 79250/320000]  base_lr: 7.7406e-05 lr: 7.7406e-06  eta: 1 day, 9:02:24  time: 0.4989  data_time: 0.0116  memory: 5891  grad_norm: 95.9637  loss: 7.9879  decode.loss_cls: 0.1448  decode.loss_mask: 0.2412  decode.loss_dice: 0.3690  decode.d0.loss_cls: 0.9360  decode.d0.loss_mask: 0.2378  decode.d0.loss_dice: 0.3082  decode.d1.loss_cls: 0.1539  decode.d1.loss_mask: 0.2398  decode.d1.loss_dice: 0.3182  decode.d2.loss_cls: 0.1410  decode.d2.loss_mask: 0.2410  decode.d2.loss_dice: 0.3128  decode.d3.loss_cls: 0.1400  decode.d3.loss_mask: 0.2359  decode.d3.loss_dice: 0.3207  decode.d4.loss_cls: 0.1640  decode.d4.loss_mask: 0.2394  decode.d4.loss_dice: 0.3281  decode.d5.loss_cls: 0.1440  decode.d5.loss_mask: 0.2411  decode.d5.loss_dice: 0.3249  decode.d6.loss_cls: 0.1473  decode.d6.loss_mask: 0.2378  decode.d6.loss_dice: 0.3437  decode.d7.loss_cls: 0.1810  decode.d7.loss_mask: 0.2385  decode.d7.loss_dice: 0.3353  decode.d8.loss_cls: 0.1506  decode.d8.loss_mask: 0.2354  decode.d8.loss_dice: 0.3364
08/06 13:13:48 - mmengine - INFO - Iter(train) [ 79300/320000]  base_lr: 7.7392e-05 lr: 7.7392e-06  eta: 1 day, 9:02:00  time: 0.4976  data_time: 0.0114  memory: 5911  grad_norm: 71.7590  loss: 6.0886  decode.loss_cls: 0.0683  decode.loss_mask: 0.2457  decode.loss_dice: 0.2320  decode.d0.loss_cls: 0.7332  decode.d0.loss_mask: 0.2300  decode.d0.loss_dice: 0.2503  decode.d1.loss_cls: 0.0778  decode.d1.loss_mask: 0.2231  decode.d1.loss_dice: 0.2479  decode.d2.loss_cls: 0.0692  decode.d2.loss_mask: 0.2213  decode.d2.loss_dice: 0.2354  decode.d3.loss_cls: 0.0783  decode.d3.loss_mask: 0.2268  decode.d3.loss_dice: 0.2373  decode.d4.loss_cls: 0.0691  decode.d4.loss_mask: 0.2307  decode.d4.loss_dice: 0.2419  decode.d5.loss_cls: 0.0660  decode.d5.loss_mask: 0.2283  decode.d5.loss_dice: 0.2360  decode.d6.loss_cls: 0.0646  decode.d6.loss_mask: 0.2504  decode.d6.loss_dice: 0.2496  decode.d7.loss_cls: 0.0652  decode.d7.loss_mask: 0.2450  decode.d7.loss_dice: 0.2382  decode.d8.loss_cls: 0.0681  decode.d8.loss_mask: 0.2241  decode.d8.loss_dice: 0.2346
08/06 13:14:13 - mmengine - INFO - Iter(train) [ 79350/320000]  base_lr: 7.7377e-05 lr: 7.7377e-06  eta: 1 day, 9:01:36  time: 0.4974  data_time: 0.0117  memory: 5911  grad_norm: 121.8148  loss: 8.2028  decode.loss_cls: 0.1298  decode.loss_mask: 0.3078  decode.loss_dice: 0.3331  decode.d0.loss_cls: 0.7840  decode.d0.loss_mask: 0.3148  decode.d0.loss_dice: 0.3227  decode.d1.loss_cls: 0.1825  decode.d1.loss_mask: 0.3020  decode.d1.loss_dice: 0.3097  decode.d2.loss_cls: 0.1217  decode.d2.loss_mask: 0.3053  decode.d2.loss_dice: 0.3075  decode.d3.loss_cls: 0.1082  decode.d3.loss_mask: 0.3136  decode.d3.loss_dice: 0.3131  decode.d4.loss_cls: 0.1144  decode.d4.loss_mask: 0.3056  decode.d4.loss_dice: 0.3049  decode.d5.loss_cls: 0.1261  decode.d5.loss_mask: 0.3087  decode.d5.loss_dice: 0.3199  decode.d6.loss_cls: 0.1135  decode.d6.loss_mask: 0.3056  decode.d6.loss_dice: 0.3235  decode.d7.loss_cls: 0.1338  decode.d7.loss_mask: 0.3049  decode.d7.loss_dice: 0.3125  decode.d8.loss_cls: 0.1483  decode.d8.loss_mask: 0.3087  decode.d8.loss_dice: 0.3168
08/06 13:14:38 - mmengine - INFO - Iter(train) [ 79400/320000]  base_lr: 7.7363e-05 lr: 7.7363e-06  eta: 1 day, 9:01:12  time: 0.4981  data_time: 0.0113  memory: 5894  grad_norm: 65.1371  loss: 5.5185  decode.loss_cls: 0.0454  decode.loss_mask: 0.2096  decode.loss_dice: 0.2280  decode.d0.loss_cls: 0.8239  decode.d0.loss_mask: 0.2085  decode.d0.loss_dice: 0.2255  decode.d1.loss_cls: 0.0329  decode.d1.loss_mask: 0.2232  decode.d1.loss_dice: 0.2153  decode.d2.loss_cls: 0.0265  decode.d2.loss_mask: 0.2103  decode.d2.loss_dice: 0.2229  decode.d3.loss_cls: 0.0437  decode.d3.loss_mask: 0.2079  decode.d3.loss_dice: 0.2260  decode.d4.loss_cls: 0.0395  decode.d4.loss_mask: 0.2119  decode.d4.loss_dice: 0.2396  decode.d5.loss_cls: 0.0401  decode.d5.loss_mask: 0.2097  decode.d5.loss_dice: 0.2175  decode.d6.loss_cls: 0.0538  decode.d6.loss_mask: 0.2074  decode.d6.loss_dice: 0.2359  decode.d7.loss_cls: 0.0387  decode.d7.loss_mask: 0.2121  decode.d7.loss_dice: 0.2122  decode.d8.loss_cls: 0.0403  decode.d8.loss_mask: 0.2095  decode.d8.loss_dice: 0.2007
08/06 13:15:03 - mmengine - INFO - Iter(train) [ 79450/320000]  base_lr: 7.7348e-05 lr: 7.7348e-06  eta: 1 day, 9:00:48  time: 0.4974  data_time: 0.0116  memory: 5911  grad_norm: 254.1704  loss: 9.0110  decode.loss_cls: 0.1883  decode.loss_mask: 0.3558  decode.loss_dice: 0.3672  decode.d0.loss_cls: 0.7642  decode.d0.loss_mask: 0.3531  decode.d0.loss_dice: 0.3485  decode.d1.loss_cls: 0.1288  decode.d1.loss_mask: 0.3558  decode.d1.loss_dice: 0.3616  decode.d2.loss_cls: 0.1072  decode.d2.loss_mask: 0.3470  decode.d2.loss_dice: 0.3577  decode.d3.loss_cls: 0.1855  decode.d3.loss_mask: 0.3518  decode.d3.loss_dice: 0.3666  decode.d4.loss_cls: 0.1156  decode.d4.loss_mask: 0.3501  decode.d4.loss_dice: 0.3600  decode.d5.loss_cls: 0.1063  decode.d5.loss_mask: 0.3511  decode.d5.loss_dice: 0.3545  decode.d6.loss_cls: 0.1041  decode.d6.loss_mask: 0.3470  decode.d6.loss_dice: 0.3637  decode.d7.loss_cls: 0.0877  decode.d7.loss_mask: 0.3487  decode.d7.loss_dice: 0.3577  decode.d8.loss_cls: 0.1161  decode.d8.loss_mask: 0.3503  decode.d8.loss_dice: 0.3590
08/06 13:15:28 - mmengine - INFO - Iter(train) [ 79500/320000]  base_lr: 7.7334e-05 lr: 7.7334e-06  eta: 1 day, 9:00:23  time: 0.4981  data_time: 0.0114  memory: 5911  grad_norm: 105.6831  loss: 5.7129  decode.loss_cls: 0.0378  decode.loss_mask: 0.2488  decode.loss_dice: 0.2408  decode.d0.loss_cls: 0.7702  decode.d0.loss_mask: 0.2519  decode.d0.loss_dice: 0.2179  decode.d1.loss_cls: 0.0370  decode.d1.loss_mask: 0.2448  decode.d1.loss_dice: 0.2160  decode.d2.loss_cls: 0.0276  decode.d2.loss_mask: 0.2489  decode.d2.loss_dice: 0.2222  decode.d3.loss_cls: 0.0280  decode.d3.loss_mask: 0.2454  decode.d3.loss_dice: 0.2040  decode.d4.loss_cls: 0.0347  decode.d4.loss_mask: 0.2455  decode.d4.loss_dice: 0.2232  decode.d5.loss_cls: 0.0405  decode.d5.loss_mask: 0.2449  decode.d5.loss_dice: 0.2071  decode.d6.loss_cls: 0.0362  decode.d6.loss_mask: 0.2446  decode.d6.loss_dice: 0.2095  decode.d7.loss_cls: 0.0334  decode.d7.loss_mask: 0.2474  decode.d7.loss_dice: 0.2069  decode.d8.loss_cls: 0.0363  decode.d8.loss_mask: 0.2472  decode.d8.loss_dice: 0.2143
08/06 13:15:53 - mmengine - INFO - Iter(train) [ 79550/320000]  base_lr: 7.7319e-05 lr: 7.7319e-06  eta: 1 day, 8:59:59  time: 0.4985  data_time: 0.0113  memory: 5894  grad_norm: 43.8435  loss: 6.0328  decode.loss_cls: 0.0527  decode.loss_mask: 0.1850  decode.loss_dice: 0.2413  decode.d0.loss_cls: 0.8896  decode.d0.loss_mask: 0.1904  decode.d0.loss_dice: 0.2841  decode.d1.loss_cls: 0.1118  decode.d1.loss_mask: 0.1860  decode.d1.loss_dice: 0.2834  decode.d2.loss_cls: 0.0658  decode.d2.loss_mask: 0.1902  decode.d2.loss_dice: 0.2711  decode.d3.loss_cls: 0.0263  decode.d3.loss_mask: 0.1858  decode.d3.loss_dice: 0.2773  decode.d4.loss_cls: 0.0652  decode.d4.loss_mask: 0.1870  decode.d4.loss_dice: 0.2683  decode.d5.loss_cls: 0.0669  decode.d5.loss_mask: 0.1868  decode.d5.loss_dice: 0.2608  decode.d6.loss_cls: 0.0834  decode.d6.loss_mask: 0.1874  decode.d6.loss_dice: 0.2519  decode.d7.loss_cls: 0.0807  decode.d7.loss_mask: 0.1876  decode.d7.loss_dice: 0.2557  decode.d8.loss_cls: 0.0647  decode.d8.loss_mask: 0.1856  decode.d8.loss_dice: 0.2599
08/06 13:16:18 - mmengine - INFO - Iter(train) [ 79600/320000]  base_lr: 7.7305e-05 lr: 7.7305e-06  eta: 1 day, 8:59:35  time: 0.4961  data_time: 0.0115  memory: 5967  grad_norm: 87.3108  loss: 6.7845  decode.loss_cls: 0.0475  decode.loss_mask: 0.3104  decode.loss_dice: 0.2558  decode.d0.loss_cls: 0.7508  decode.d0.loss_mask: 0.2882  decode.d0.loss_dice: 0.2405  decode.d1.loss_cls: 0.0752  decode.d1.loss_mask: 0.2881  decode.d1.loss_dice: 0.2583  decode.d2.loss_cls: 0.0152  decode.d2.loss_mask: 0.3080  decode.d2.loss_dice: 0.2546  decode.d3.loss_cls: 0.0972  decode.d3.loss_mask: 0.2845  decode.d3.loss_dice: 0.2522  decode.d4.loss_cls: 0.0533  decode.d4.loss_mask: 0.3124  decode.d4.loss_dice: 0.2630  decode.d5.loss_cls: 0.0528  decode.d5.loss_mask: 0.3073  decode.d5.loss_dice: 0.2519  decode.d6.loss_cls: 0.0427  decode.d6.loss_mask: 0.3064  decode.d6.loss_dice: 0.2591  decode.d7.loss_cls: 0.0383  decode.d7.loss_mask: 0.3048  decode.d7.loss_dice: 0.2575  decode.d8.loss_cls: 0.0392  decode.d8.loss_mask: 0.3029  decode.d8.loss_dice: 0.2666
08/06 13:16:42 - mmengine - INFO - Iter(train) [ 79650/320000]  base_lr: 7.7290e-05 lr: 7.7290e-06  eta: 1 day, 8:59:11  time: 0.4979  data_time: 0.0118  memory: 5876  grad_norm: 80.5183  loss: 8.2968  decode.loss_cls: 0.1468  decode.loss_mask: 0.2810  decode.loss_dice: 0.2884  decode.d0.loss_cls: 0.9704  decode.d0.loss_mask: 0.2890  decode.d0.loss_dice: 0.2943  decode.d1.loss_cls: 0.2532  decode.d1.loss_mask: 0.2851  decode.d1.loss_dice: 0.2799  decode.d2.loss_cls: 0.1589  decode.d2.loss_mask: 0.2781  decode.d2.loss_dice: 0.2954  decode.d3.loss_cls: 0.1619  decode.d3.loss_mask: 0.2785  decode.d3.loss_dice: 0.2888  decode.d4.loss_cls: 0.2121  decode.d4.loss_mask: 0.2790  decode.d4.loss_dice: 0.2957  decode.d5.loss_cls: 0.1503  decode.d5.loss_mask: 0.2799  decode.d5.loss_dice: 0.2881  decode.d6.loss_cls: 0.2035  decode.d6.loss_mask: 0.2815  decode.d6.loss_dice: 0.2729  decode.d7.loss_cls: 0.1750  decode.d7.loss_mask: 0.2825  decode.d7.loss_dice: 0.2864  decode.d8.loss_cls: 0.1578  decode.d8.loss_mask: 0.2839  decode.d8.loss_dice: 0.2987
08/06 13:17:07 - mmengine - INFO - Iter(train) [ 79700/320000]  base_lr: 7.7276e-05 lr: 7.7276e-06  eta: 1 day, 8:58:47  time: 0.4971  data_time: 0.0113  memory: 5894  grad_norm: 100.1556  loss: 7.0201  decode.loss_cls: 0.1464  decode.loss_mask: 0.2285  decode.loss_dice: 0.2625  decode.d0.loss_cls: 0.9167  decode.d0.loss_mask: 0.2259  decode.d0.loss_dice: 0.2666  decode.d1.loss_cls: 0.1074  decode.d1.loss_mask: 0.2279  decode.d1.loss_dice: 0.2648  decode.d2.loss_cls: 0.1395  decode.d2.loss_mask: 0.2239  decode.d2.loss_dice: 0.2562  decode.d3.loss_cls: 0.1289  decode.d3.loss_mask: 0.2257  decode.d3.loss_dice: 0.2854  decode.d4.loss_cls: 0.0930  decode.d4.loss_mask: 0.2285  decode.d4.loss_dice: 0.2934  decode.d5.loss_cls: 0.0823  decode.d5.loss_mask: 0.2278  decode.d5.loss_dice: 0.2739  decode.d6.loss_cls: 0.0659  decode.d6.loss_mask: 0.2281  decode.d6.loss_dice: 0.2793  decode.d7.loss_cls: 0.1286  decode.d7.loss_mask: 0.2259  decode.d7.loss_dice: 0.2807  decode.d8.loss_cls: 0.2256  decode.d8.loss_mask: 0.2207  decode.d8.loss_dice: 0.2600
08/06 13:17:32 - mmengine - INFO - Iter(train) [ 79750/320000]  base_lr: 7.7262e-05 lr: 7.7262e-06  eta: 1 day, 8:58:23  time: 0.4974  data_time: 0.0115  memory: 5911  grad_norm: 120.7999  loss: 6.4714  decode.loss_cls: 0.0953  decode.loss_mask: 0.2432  decode.loss_dice: 0.2482  decode.d0.loss_cls: 0.8150  decode.d0.loss_mask: 0.2433  decode.d0.loss_dice: 0.2464  decode.d1.loss_cls: 0.1103  decode.d1.loss_mask: 0.2440  decode.d1.loss_dice: 0.2499  decode.d2.loss_cls: 0.0850  decode.d2.loss_mask: 0.2448  decode.d2.loss_dice: 0.2442  decode.d3.loss_cls: 0.0762  decode.d3.loss_mask: 0.2429  decode.d3.loss_dice: 0.2454  decode.d4.loss_cls: 0.0773  decode.d4.loss_mask: 0.2421  decode.d4.loss_dice: 0.2401  decode.d5.loss_cls: 0.0999  decode.d5.loss_mask: 0.2446  decode.d5.loss_dice: 0.2490  decode.d6.loss_cls: 0.0390  decode.d6.loss_mask: 0.2389  decode.d6.loss_dice: 0.2466  decode.d7.loss_cls: 0.0795  decode.d7.loss_mask: 0.2428  decode.d7.loss_dice: 0.2502  decode.d8.loss_cls: 0.0939  decode.d8.loss_mask: 0.2444  decode.d8.loss_dice: 0.2491
08/06 13:17:57 - mmengine - INFO - Iter(train) [ 79800/320000]  base_lr: 7.7247e-05 lr: 7.7247e-06  eta: 1 day, 8:57:59  time: 0.4980  data_time: 0.0116  memory: 5968  grad_norm: 99.9982  loss: 7.3572  decode.loss_cls: 0.0981  decode.loss_mask: 0.2150  decode.loss_dice: 0.3228  decode.d0.loss_cls: 0.9820  decode.d0.loss_mask: 0.2188  decode.d0.loss_dice: 0.3285  decode.d1.loss_cls: 0.1033  decode.d1.loss_mask: 0.2189  decode.d1.loss_dice: 0.3236  decode.d2.loss_cls: 0.0709  decode.d2.loss_mask: 0.2162  decode.d2.loss_dice: 0.3620  decode.d3.loss_cls: 0.0799  decode.d3.loss_mask: 0.2176  decode.d3.loss_dice: 0.3474  decode.d4.loss_cls: 0.1165  decode.d4.loss_mask: 0.2146  decode.d4.loss_dice: 0.3207  decode.d5.loss_cls: 0.1466  decode.d5.loss_mask: 0.2162  decode.d5.loss_dice: 0.3219  decode.d6.loss_cls: 0.1108  decode.d6.loss_mask: 0.2168  decode.d6.loss_dice: 0.3099  decode.d7.loss_cls: 0.1065  decode.d7.loss_mask: 0.2159  decode.d7.loss_dice: 0.3174  decode.d8.loss_cls: 0.0946  decode.d8.loss_mask: 0.2163  decode.d8.loss_dice: 0.3275
08/06 13:18:22 - mmengine - INFO - Iter(train) [ 79850/320000]  base_lr: 7.7233e-05 lr: 7.7233e-06  eta: 1 day, 8:57:35  time: 0.4985  data_time: 0.0115  memory: 5911  grad_norm: 53.7615  loss: 6.9970  decode.loss_cls: 0.0575  decode.loss_mask: 0.2792  decode.loss_dice: 0.2729  decode.d0.loss_cls: 0.9381  decode.d0.loss_mask: 0.2585  decode.d0.loss_dice: 0.2684  decode.d1.loss_cls: 0.0939  decode.d1.loss_mask: 0.2545  decode.d1.loss_dice: 0.2584  decode.d2.loss_cls: 0.0477  decode.d2.loss_mask: 0.2715  decode.d2.loss_dice: 0.2664  decode.d3.loss_cls: 0.1657  decode.d3.loss_mask: 0.2480  decode.d3.loss_dice: 0.2597  decode.d4.loss_cls: 0.0719  decode.d4.loss_mask: 0.2720  decode.d4.loss_dice: 0.2716  decode.d5.loss_cls: 0.1233  decode.d5.loss_mask: 0.2522  decode.d5.loss_dice: 0.2633  decode.d6.loss_cls: 0.0522  decode.d6.loss_mask: 0.2786  decode.d6.loss_dice: 0.2663  decode.d7.loss_cls: 0.0536  decode.d7.loss_mask: 0.2781  decode.d7.loss_dice: 0.2706  decode.d8.loss_cls: 0.0568  decode.d8.loss_mask: 0.2761  decode.d8.loss_dice: 0.2700
08/06 13:18:47 - mmengine - INFO - Iter(train) [ 79900/320000]  base_lr: 7.7218e-05 lr: 7.7218e-06  eta: 1 day, 8:57:11  time: 0.4978  data_time: 0.0114  memory: 5891  grad_norm: 79.9255  loss: 7.3503  decode.loss_cls: 0.1611  decode.loss_mask: 0.2015  decode.loss_dice: 0.2771  decode.d0.loss_cls: 0.9028  decode.d0.loss_mask: 0.2113  decode.d0.loss_dice: 0.2891  decode.d1.loss_cls: 0.2562  decode.d1.loss_mask: 0.2005  decode.d1.loss_dice: 0.2801  decode.d2.loss_cls: 0.1553  decode.d2.loss_mask: 0.2069  decode.d2.loss_dice: 0.2583  decode.d3.loss_cls: 0.1959  decode.d3.loss_mask: 0.2014  decode.d3.loss_dice: 0.2804  decode.d4.loss_cls: 0.1833  decode.d4.loss_mask: 0.2008  decode.d4.loss_dice: 0.2792  decode.d5.loss_cls: 0.1985  decode.d5.loss_mask: 0.2016  decode.d5.loss_dice: 0.2638  decode.d6.loss_cls: 0.1783  decode.d6.loss_mask: 0.2042  decode.d6.loss_dice: 0.2671  decode.d7.loss_cls: 0.1615  decode.d7.loss_mask: 0.2029  decode.d7.loss_dice: 0.2777  decode.d8.loss_cls: 0.1847  decode.d8.loss_mask: 0.2000  decode.d8.loss_dice: 0.2689
08/06 13:19:12 - mmengine - INFO - Iter(train) [ 79950/320000]  base_lr: 7.7204e-05 lr: 7.7204e-06  eta: 1 day, 8:56:47  time: 0.4981  data_time: 0.0115  memory: 5894  grad_norm: 80.7822  loss: 6.3052  decode.loss_cls: 0.0848  decode.loss_mask: 0.2117  decode.loss_dice: 0.2416  decode.d0.loss_cls: 0.8696  decode.d0.loss_mask: 0.2113  decode.d0.loss_dice: 0.2486  decode.d1.loss_cls: 0.0772  decode.d1.loss_mask: 0.2132  decode.d1.loss_dice: 0.2460  decode.d2.loss_cls: 0.0824  decode.d2.loss_mask: 0.2115  decode.d2.loss_dice: 0.2402  decode.d3.loss_cls: 0.1110  decode.d3.loss_mask: 0.2126  decode.d3.loss_dice: 0.2660  decode.d4.loss_cls: 0.0824  decode.d4.loss_mask: 0.2102  decode.d4.loss_dice: 0.2465  decode.d5.loss_cls: 0.0913  decode.d5.loss_mask: 0.2092  decode.d5.loss_dice: 0.2489  decode.d6.loss_cls: 0.0810  decode.d6.loss_mask: 0.2064  decode.d6.loss_dice: 0.2518  decode.d7.loss_cls: 0.1061  decode.d7.loss_mask: 0.2091  decode.d7.loss_dice: 0.2519  decode.d8.loss_cls: 0.1050  decode.d8.loss_mask: 0.2109  decode.d8.loss_dice: 0.2667
08/06 13:19:37 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 13:19:37 - mmengine - INFO - Iter(train) [ 80000/320000]  base_lr: 7.7189e-05 lr: 7.7189e-06  eta: 1 day, 8:56:23  time: 0.4987  data_time: 0.0116  memory: 5909  grad_norm: 71.5559  loss: 5.7664  decode.loss_cls: 0.1472  decode.loss_mask: 0.1903  decode.loss_dice: 0.2297  decode.d0.loss_cls: 0.8214  decode.d0.loss_mask: 0.1924  decode.d0.loss_dice: 0.2549  decode.d1.loss_cls: 0.1282  decode.d1.loss_mask: 0.1893  decode.d1.loss_dice: 0.2245  decode.d2.loss_cls: 0.0877  decode.d2.loss_mask: 0.1886  decode.d2.loss_dice: 0.2034  decode.d3.loss_cls: 0.0702  decode.d3.loss_mask: 0.1897  decode.d3.loss_dice: 0.2114  decode.d4.loss_cls: 0.0790  decode.d4.loss_mask: 0.1903  decode.d4.loss_dice: 0.2248  decode.d5.loss_cls: 0.0660  decode.d5.loss_mask: 0.1900  decode.d5.loss_dice: 0.2284  decode.d6.loss_cls: 0.0683  decode.d6.loss_mask: 0.1891  decode.d6.loss_dice: 0.2329  decode.d7.loss_cls: 0.0601  decode.d7.loss_mask: 0.1875  decode.d7.loss_dice: 0.2096  decode.d8.loss_cls: 0.0957  decode.d8.loss_mask: 0.1899  decode.d8.loss_dice: 0.2256
08/06 13:19:37 - mmengine - INFO - Saving checkpoint at 80000 iterations
08/06 13:19:47 - mmengine - INFO - Iter(val) [  50/1587]    eta: 0:04:02  time: 0.1556  data_time: 0.0041  memory: 2340  
08/06 13:19:55 - mmengine - INFO - Iter(val) [ 100/1587]    eta: 0:03:53  time: 0.1558  data_time: 0.0042  memory: 2340  
08/06 13:20:03 - mmengine - INFO - Iter(val) [ 150/1587]    eta: 0:03:45  time: 0.1566  data_time: 0.0043  memory: 2340  
08/06 13:20:11 - mmengine - INFO - Iter(val) [ 200/1587]    eta: 0:03:37  time: 0.1563  data_time: 0.0041  memory: 2340  
08/06 13:20:19 - mmengine - INFO - Iter(val) [ 250/1587]    eta: 0:03:29  time: 0.1569  data_time: 0.0043  memory: 2340  
08/06 13:20:27 - mmengine - INFO - Iter(val) [ 300/1587]    eta: 0:03:21  time: 0.1568  data_time: 0.0043  memory: 2340  
08/06 13:20:34 - mmengine - INFO - Iter(val) [ 350/1587]    eta: 0:03:13  time: 0.1571  data_time: 0.0043  memory: 2340  
08/06 13:20:42 - mmengine - INFO - Iter(val) [ 400/1587]    eta: 0:03:06  time: 0.1569  data_time: 0.0042  memory: 2340  
08/06 13:20:50 - mmengine - INFO - Iter(val) [ 450/1587]    eta: 0:02:58  time: 0.1568  data_time: 0.0043  memory: 2340  
08/06 13:20:58 - mmengine - INFO - Iter(val) [ 500/1587]    eta: 0:02:50  time: 0.1569  data_time: 0.0042  memory: 2340  
08/06 13:21:06 - mmengine - INFO - Iter(val) [ 550/1587]    eta: 0:02:42  time: 0.1570  data_time: 0.0042  memory: 2340  
08/06 13:21:14 - mmengine - INFO - Iter(val) [ 600/1587]    eta: 0:02:34  time: 0.1572  data_time: 0.0044  memory: 2340  
08/06 13:21:22 - mmengine - INFO - Iter(val) [ 650/1587]    eta: 0:02:26  time: 0.1570  data_time: 0.0043  memory: 2340  
08/06 13:21:29 - mmengine - INFO - Iter(val) [ 700/1587]    eta: 0:02:19  time: 0.1565  data_time: 0.0041  memory: 2340  
08/06 13:21:37 - mmengine - INFO - Iter(val) [ 750/1587]    eta: 0:02:11  time: 0.1569  data_time: 0.0043  memory: 2340  
08/06 13:21:45 - mmengine - INFO - Iter(val) [ 800/1587]    eta: 0:02:03  time: 0.1571  data_time: 0.0043  memory: 2340  
08/06 13:21:53 - mmengine - INFO - Iter(val) [ 850/1587]    eta: 0:01:55  time: 0.1571  data_time: 0.0042  memory: 2340  
08/06 13:22:01 - mmengine - INFO - Iter(val) [ 900/1587]    eta: 0:01:47  time: 0.1571  data_time: 0.0042  memory: 2340  
08/06 13:22:09 - mmengine - INFO - Iter(val) [ 950/1587]    eta: 0:01:39  time: 0.1571  data_time: 0.0043  memory: 2340  
08/06 13:22:17 - mmengine - INFO - Iter(val) [1000/1587]    eta: 0:01:32  time: 0.1570  data_time: 0.0043  memory: 2340  
08/06 13:22:24 - mmengine - INFO - Iter(val) [1050/1587]    eta: 0:01:24  time: 0.1571  data_time: 0.0043  memory: 2340  
08/06 13:22:31 - mmengine - INFO - Iter(val) [1100/1587]    eta: 0:01:15  time: 0.1197  data_time: 0.0036  memory: 2340  
08/06 13:22:37 - mmengine - INFO - Iter(val) [1150/1587]    eta: 0:01:07  time: 0.1197  data_time: 0.0037  memory: 1887  
08/06 13:22:43 - mmengine - INFO - Iter(val) [1200/1587]    eta: 0:00:59  time: 0.1196  data_time: 0.0036  memory: 1887  
08/06 13:22:49 - mmengine - INFO - Iter(val) [1250/1587]    eta: 0:00:50  time: 0.1197  data_time: 0.0037  memory: 1887  
08/06 13:22:55 - mmengine - INFO - Iter(val) [1300/1587]    eta: 0:00:43  time: 0.1196  data_time: 0.0036  memory: 1887  
08/06 13:23:01 - mmengine - INFO - Iter(val) [1350/1587]    eta: 0:00:35  time: 0.1197  data_time: 0.0037  memory: 1887  
08/06 13:23:07 - mmengine - INFO - Iter(val) [1400/1587]    eta: 0:00:27  time: 0.1196  data_time: 0.0036  memory: 1887  
08/06 13:23:13 - mmengine - INFO - Iter(val) [1450/1587]    eta: 0:00:20  time: 0.1196  data_time: 0.0036  memory: 1887  
08/06 13:23:19 - mmengine - INFO - Iter(val) [1500/1587]    eta: 0:00:12  time: 0.1197  data_time: 0.0036  memory: 1887  
08/06 13:23:25 - mmengine - INFO - Iter(val) [1550/1587]    eta: 0:00:05  time: 0.1197  data_time: 0.0037  memory: 1887  
08/06 13:23:29 - mmengine - INFO - per class results:
08/06 13:23:29 - mmengine - INFO - 
+------------------------------------+-------+-------+
|               Class                |  IoU  |  Acc  |
+------------------------------------+-------+-------+
|             background             | 99.03 | 99.53 |
|            Aloo Dry fry            | 95.42 | 97.32 |
|      Avakaya Muddha Papu Rice      | 95.68 | 97.59 |
|      Baby-Corn & Capsicum-Dry      | 93.36 |  96.5 |
|           Cabbage Pakodi           | 88.69 |  91.2 |
|            Cabbage fry             | 93.46 |  95.8 |
|       Capsicum Paneer Curry        | 91.58 | 95.92 |
|           Chakar-Pongal            | 78.14 | 81.81 |
|            Chole-Masala            | 93.95 | 97.92 |
|        Cluster Beans Curry         | 89.62 | 92.36 |
|          Cucumber-Raitha           | 76.02 | 79.74 |
|         Gobi Masala Curry          | 93.21 | 95.68 |
|        Gutti Vankaya Curry         | 93.27 | 96.83 |
|             Jeera Rice             | 94.71 | 96.91 |
|            Mixed Curry             | 94.07 | 96.82 |
|             Muskmelon              | 94.88 | 96.83 |
|               Rajma                | 91.43 | 98.13 |
|              Rasgulla              | 96.53 | 98.78 |
|               Sambar               | 93.49 | 97.22 |
|            Tomato Rasam            | 94.47 | 97.48 |
|         Vankaya-Ali-Karam          | 89.52 | 96.94 |
|            Veg-Biriyani            | 93.23 | 97.07 |
|             aloo-curry             | 95.09 | 97.54 |
|                curd                | 94.52 | 97.04 |
|                dal                 | 93.35 | 96.91 |
|           fresh-chutney            | 92.07 | 95.92 |
|            green-salad             | 93.72 | 96.61 |
|         Moong-Beans-Curry          | 94.75 | 96.85 |
|              khichdi               | 94.91 | 96.84 |
|             lemon-rice             | 94.89 | 97.04 |
|        live-roti-with-ghee         | 98.02 | 98.86 |
|    non-spicy-curry-bottle-gourd    |  94.5 | 97.49 |
|               papad                | 93.68 | 95.48 |
|             plain-rice             | 95.64 | 97.56 |
|             watermelon             | 95.64 |  97.9 |
|              Aloo-Fry              | 92.47 | 95.85 |
|               Banana               | 95.92 | 97.11 |
|             Mix-Fruit              | 95.93 | 98.07 |
| Non-Spicy-Baby-Corn & Capsicum-Dry | 88.87 | 93.93 |
|               Sweet                | 84.91 |  86.7 |
|            Tomato-Rice             | 96.14 | 97.54 |
|         fried-papad-rings          | 91.72 | 97.19 |
|               gravy                | 92.29 | 94.83 |
|           ivy-gourd-fry            | 95.32 | 97.57 |
|            mango-pickle            | 91.62 | 95.05 |
|             papad-chat             | 92.85 | 97.51 |
|            pepper-rasam            |  95.9 | 97.73 |
|             pineapple              | 94.68 | 97.24 |
|              corn-fry              | 89.12 | 92.26 |
|            paneer-curry            | 90.92 | 99.18 |
|               semiya               | 91.07 | 96.77 |
+------------------------------------+-------+-------+
08/06 13:23:29 - mmengine - INFO - Iter(val) [1587/1587]    aAcc: 99.1500  mIoU: 92.8300  mAcc: 95.9000  data_time: 0.0041  time: 0.1444
08/06 13:23:29 - mmengine - INFO - The previous best checkpoint /scratch/seg_benchmark/NEW/mask2former_swin_T_seed_320K/best_mIoU_iter_40000.pth is removed
08/06 13:23:31 - mmengine - INFO - The best checkpoint with 92.8300 mIoU at 80000 iter is saved to best_mIoU_iter_80000.pth.
08/06 13:24:02 - mmengine - INFO - Iter(train) [ 80050/320000]  base_lr: 7.7175e-05 lr: 7.7175e-06  eta: 1 day, 8:56:21  time: 0.4967  data_time: 0.0112  memory: 5894  grad_norm: 64.8044  loss: 5.1727  decode.loss_cls: 0.0450  decode.loss_mask: 0.1913  decode.loss_dice: 0.2218  decode.d0.loss_cls: 0.6623  decode.d0.loss_mask: 0.1914  decode.d0.loss_dice: 0.2340  decode.d1.loss_cls: 0.0226  decode.d1.loss_mask: 0.1899  decode.d1.loss_dice: 0.2240  decode.d2.loss_cls: 0.0213  decode.d2.loss_mask: 0.1928  decode.d2.loss_dice: 0.2100  decode.d3.loss_cls: 0.0330  decode.d3.loss_mask: 0.1901  decode.d3.loss_dice: 0.2194  decode.d4.loss_cls: 0.0453  decode.d4.loss_mask: 0.1908  decode.d4.loss_dice: 0.2159  decode.d5.loss_cls: 0.0710  decode.d5.loss_mask: 0.1904  decode.d5.loss_dice: 0.2257  decode.d6.loss_cls: 0.0503  decode.d6.loss_mask: 0.1903  decode.d6.loss_dice: 0.2346  decode.d7.loss_cls: 0.0440  decode.d7.loss_mask: 0.1889  decode.d7.loss_dice: 0.2142  decode.d8.loss_cls: 0.0587  decode.d8.loss_mask: 0.1871  decode.d8.loss_dice: 0.2170
08/06 13:24:27 - mmengine - INFO - Iter(train) [ 80100/320000]  base_lr: 7.7160e-05 lr: 7.7160e-06  eta: 1 day, 8:55:57  time: 0.4963  data_time: 0.0112  memory: 5874  grad_norm: 58.2181  loss: 5.8501  decode.loss_cls: 0.0075  decode.loss_mask: 0.2535  decode.loss_dice: 0.2384  decode.d0.loss_cls: 0.7433  decode.d0.loss_mask: 0.2634  decode.d0.loss_dice: 0.2344  decode.d1.loss_cls: 0.0249  decode.d1.loss_mask: 0.2549  decode.d1.loss_dice: 0.2339  decode.d2.loss_cls: 0.0733  decode.d2.loss_mask: 0.2554  decode.d2.loss_dice: 0.2365  decode.d3.loss_cls: 0.0167  decode.d3.loss_mask: 0.2560  decode.d3.loss_dice: 0.2394  decode.d4.loss_cls: 0.0163  decode.d4.loss_mask: 0.2537  decode.d4.loss_dice: 0.2374  decode.d5.loss_cls: 0.0100  decode.d5.loss_mask: 0.2556  decode.d5.loss_dice: 0.2419  decode.d6.loss_cls: 0.0080  decode.d6.loss_mask: 0.2540  decode.d6.loss_dice: 0.2469  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 0.2541  decode.d7.loss_dice: 0.2346  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.2551  decode.d8.loss_dice: 0.2378
08/06 13:24:51 - mmengine - INFO - Iter(train) [ 80150/320000]  base_lr: 7.7146e-05 lr: 7.7146e-06  eta: 1 day, 8:55:33  time: 0.4970  data_time: 0.0115  memory: 5891  grad_norm: 92.2163  loss: 8.2568  decode.loss_cls: 0.1504  decode.loss_mask: 0.2480  decode.loss_dice: 0.3095  decode.d0.loss_cls: 1.0902  decode.d0.loss_mask: 0.2587  decode.d0.loss_dice: 0.3071  decode.d1.loss_cls: 0.1891  decode.d1.loss_mask: 0.2520  decode.d1.loss_dice: 0.3020  decode.d2.loss_cls: 0.2283  decode.d2.loss_mask: 0.2405  decode.d2.loss_dice: 0.2939  decode.d3.loss_cls: 0.1494  decode.d3.loss_mask: 0.2473  decode.d3.loss_dice: 0.3225  decode.d4.loss_cls: 0.1637  decode.d4.loss_mask: 0.2417  decode.d4.loss_dice: 0.3119  decode.d5.loss_cls: 0.1863  decode.d5.loss_mask: 0.2448  decode.d5.loss_dice: 0.3066  decode.d6.loss_cls: 0.1621  decode.d6.loss_mask: 0.2499  decode.d6.loss_dice: 0.3015  decode.d7.loss_cls: 0.2165  decode.d7.loss_mask: 0.2458  decode.d7.loss_dice: 0.3013  decode.d8.loss_cls: 0.1852  decode.d8.loss_mask: 0.2495  decode.d8.loss_dice: 0.3014
08/06 13:25:16 - mmengine - INFO - Iter(train) [ 80200/320000]  base_lr: 7.7131e-05 lr: 7.7131e-06  eta: 1 day, 8:55:09  time: 0.4976  data_time: 0.0116  memory: 5878  grad_norm: 56.2698  loss: 7.2822  decode.loss_cls: 0.1388  decode.loss_mask: 0.2554  decode.loss_dice: 0.2392  decode.d0.loss_cls: 0.7950  decode.d0.loss_mask: 0.2638  decode.d0.loss_dice: 0.2664  decode.d1.loss_cls: 0.2049  decode.d1.loss_mask: 0.2541  decode.d1.loss_dice: 0.2596  decode.d2.loss_cls: 0.1594  decode.d2.loss_mask: 0.2534  decode.d2.loss_dice: 0.2404  decode.d3.loss_cls: 0.1256  decode.d3.loss_mask: 0.2620  decode.d3.loss_dice: 0.2741  decode.d4.loss_cls: 0.1133  decode.d4.loss_mask: 0.2596  decode.d4.loss_dice: 0.2714  decode.d5.loss_cls: 0.2202  decode.d5.loss_mask: 0.2530  decode.d5.loss_dice: 0.2292  decode.d6.loss_cls: 0.1731  decode.d6.loss_mask: 0.2501  decode.d6.loss_dice: 0.2228  decode.d7.loss_cls: 0.0943  decode.d7.loss_mask: 0.2631  decode.d7.loss_dice: 0.2647  decode.d8.loss_cls: 0.1791  decode.d8.loss_mask: 0.2562  decode.d8.loss_dice: 0.2399
08/06 13:25:41 - mmengine - INFO - Iter(train) [ 80250/320000]  base_lr: 7.7117e-05 lr: 7.7117e-06  eta: 1 day, 8:54:45  time: 0.4997  data_time: 0.0115  memory: 5891  grad_norm: 39.7031  loss: 5.2565  decode.loss_cls: 0.0110  decode.loss_mask: 0.1929  decode.loss_dice: 0.2306  decode.d0.loss_cls: 0.8306  decode.d0.loss_mask: 0.1942  decode.d0.loss_dice: 0.2299  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.1944  decode.d1.loss_dice: 0.2367  decode.d2.loss_cls: 0.0344  decode.d2.loss_mask: 0.1931  decode.d2.loss_dice: 0.2192  decode.d3.loss_cls: 0.0462  decode.d3.loss_mask: 0.1933  decode.d3.loss_dice: 0.2317  decode.d4.loss_cls: 0.0117  decode.d4.loss_mask: 0.1946  decode.d4.loss_dice: 0.2274  decode.d5.loss_cls: 0.0102  decode.d5.loss_mask: 0.1949  decode.d5.loss_dice: 0.2232  decode.d6.loss_cls: 0.0685  decode.d6.loss_mask: 0.1938  decode.d6.loss_dice: 0.2276  decode.d7.loss_cls: 0.0091  decode.d7.loss_mask: 0.1912  decode.d7.loss_dice: 0.2244  decode.d8.loss_cls: 0.0090  decode.d8.loss_mask: 0.1930  decode.d8.loss_dice: 0.2316
08/06 13:26:06 - mmengine - INFO - Iter(train) [ 80300/320000]  base_lr: 7.7102e-05 lr: 7.7102e-06  eta: 1 day, 8:54:21  time: 0.4978  data_time: 0.0116  memory: 5878  grad_norm: 35.3229  loss: 5.4267  decode.loss_cls: 0.0062  decode.loss_mask: 0.2273  decode.loss_dice: 0.2239  decode.d0.loss_cls: 0.8269  decode.d0.loss_mask: 0.2314  decode.d0.loss_dice: 0.2240  decode.d1.loss_cls: 0.0103  decode.d1.loss_mask: 0.2296  decode.d1.loss_dice: 0.2163  decode.d2.loss_cls: 0.0090  decode.d2.loss_mask: 0.2304  decode.d2.loss_dice: 0.2172  decode.d3.loss_cls: 0.0098  decode.d3.loss_mask: 0.2295  decode.d3.loss_dice: 0.2258  decode.d4.loss_cls: 0.0084  decode.d4.loss_mask: 0.2286  decode.d4.loss_dice: 0.2258  decode.d5.loss_cls: 0.0083  decode.d5.loss_mask: 0.2289  decode.d5.loss_dice: 0.2260  decode.d6.loss_cls: 0.0090  decode.d6.loss_mask: 0.2284  decode.d6.loss_dice: 0.2094  decode.d7.loss_cls: 0.0077  decode.d7.loss_mask: 0.2289  decode.d7.loss_dice: 0.2299  decode.d8.loss_cls: 0.0078  decode.d8.loss_mask: 0.2315  decode.d8.loss_dice: 0.2302
08/06 13:26:31 - mmengine - INFO - Iter(train) [ 80350/320000]  base_lr: 7.7088e-05 lr: 7.7088e-06  eta: 1 day, 8:53:57  time: 0.4979  data_time: 0.0117  memory: 5891  grad_norm: 107.7826  loss: 5.9051  decode.loss_cls: 0.0254  decode.loss_mask: 0.2578  decode.loss_dice: 0.2148  decode.d0.loss_cls: 0.7725  decode.d0.loss_mask: 0.2618  decode.d0.loss_dice: 0.2283  decode.d1.loss_cls: 0.0593  decode.d1.loss_mask: 0.2578  decode.d1.loss_dice: 0.2140  decode.d2.loss_cls: 0.0759  decode.d2.loss_mask: 0.2595  decode.d2.loss_dice: 0.2135  decode.d3.loss_cls: 0.0750  decode.d3.loss_mask: 0.2692  decode.d3.loss_dice: 0.2089  decode.d4.loss_cls: 0.0273  decode.d4.loss_mask: 0.2700  decode.d4.loss_dice: 0.2090  decode.d5.loss_cls: 0.0247  decode.d5.loss_mask: 0.2616  decode.d5.loss_dice: 0.2100  decode.d6.loss_cls: 0.0413  decode.d6.loss_mask: 0.2608  decode.d6.loss_dice: 0.2144  decode.d7.loss_cls: 0.0207  decode.d7.loss_mask: 0.2641  decode.d7.loss_dice: 0.2115  decode.d8.loss_cls: 0.0277  decode.d8.loss_mask: 0.2576  decode.d8.loss_dice: 0.2109
08/06 13:26:56 - mmengine - INFO - Iter(train) [ 80400/320000]  base_lr: 7.7073e-05 lr: 7.7073e-06  eta: 1 day, 8:53:33  time: 0.4976  data_time: 0.0115  memory: 5891  grad_norm: 107.0345  loss: 7.3845  decode.loss_cls: 0.1184  decode.loss_mask: 0.2560  decode.loss_dice: 0.2624  decode.d0.loss_cls: 0.9041  decode.d0.loss_mask: 0.2459  decode.d0.loss_dice: 0.2526  decode.d1.loss_cls: 0.1685  decode.d1.loss_mask: 0.2572  decode.d1.loss_dice: 0.2517  decode.d2.loss_cls: 0.1142  decode.d2.loss_mask: 0.2510  decode.d2.loss_dice: 0.2663  decode.d3.loss_cls: 0.1508  decode.d3.loss_mask: 0.2496  decode.d3.loss_dice: 0.2643  decode.d4.loss_cls: 0.1781  decode.d4.loss_mask: 0.2541  decode.d4.loss_dice: 0.2623  decode.d5.loss_cls: 0.1684  decode.d5.loss_mask: 0.2569  decode.d5.loss_dice: 0.2751  decode.d6.loss_cls: 0.1427  decode.d6.loss_mask: 0.2539  decode.d6.loss_dice: 0.2672  decode.d7.loss_cls: 0.1272  decode.d7.loss_mask: 0.2575  decode.d7.loss_dice: 0.2667  decode.d8.loss_cls: 0.1244  decode.d8.loss_mask: 0.2568  decode.d8.loss_dice: 0.2805
08/06 13:27:21 - mmengine - INFO - Iter(train) [ 80450/320000]  base_lr: 7.7059e-05 lr: 7.7059e-06  eta: 1 day, 8:53:08  time: 0.4978  data_time: 0.0115  memory: 5928  grad_norm: 47.5112  loss: 6.2352  decode.loss_cls: 0.0431  decode.loss_mask: 0.2388  decode.loss_dice: 0.2719  decode.d0.loss_cls: 0.7689  decode.d0.loss_mask: 0.2455  decode.d0.loss_dice: 0.2655  decode.d1.loss_cls: 0.0468  decode.d1.loss_mask: 0.2388  decode.d1.loss_dice: 0.2659  decode.d2.loss_cls: 0.0376  decode.d2.loss_mask: 0.2364  decode.d2.loss_dice: 0.2683  decode.d3.loss_cls: 0.0349  decode.d3.loss_mask: 0.2379  decode.d3.loss_dice: 0.2754  decode.d4.loss_cls: 0.0350  decode.d4.loss_mask: 0.2367  decode.d4.loss_dice: 0.2689  decode.d5.loss_cls: 0.0350  decode.d5.loss_mask: 0.2387  decode.d5.loss_dice: 0.2709  decode.d6.loss_cls: 0.0418  decode.d6.loss_mask: 0.2362  decode.d6.loss_dice: 0.2723  decode.d7.loss_cls: 0.0490  decode.d7.loss_mask: 0.2387  decode.d7.loss_dice: 0.2730  decode.d8.loss_cls: 0.0501  decode.d8.loss_mask: 0.2392  decode.d8.loss_dice: 0.2740
08/06 13:27:46 - mmengine - INFO - Iter(train) [ 80500/320000]  base_lr: 7.7044e-05 lr: 7.7044e-06  eta: 1 day, 8:52:44  time: 0.4990  data_time: 0.0117  memory: 5911  grad_norm: 78.1861  loss: 7.4187  decode.loss_cls: 0.0482  decode.loss_mask: 0.3425  decode.loss_dice: 0.2622  decode.d0.loss_cls: 0.8639  decode.d0.loss_mask: 0.3482  decode.d0.loss_dice: 0.2421  decode.d1.loss_cls: 0.0695  decode.d1.loss_mask: 0.3462  decode.d1.loss_dice: 0.2614  decode.d2.loss_cls: 0.0628  decode.d2.loss_mask: 0.3400  decode.d2.loss_dice: 0.2609  decode.d3.loss_cls: 0.0656  decode.d3.loss_mask: 0.3420  decode.d3.loss_dice: 0.2622  decode.d4.loss_cls: 0.0685  decode.d4.loss_mask: 0.3443  decode.d4.loss_dice: 0.2611  decode.d5.loss_cls: 0.0451  decode.d5.loss_mask: 0.3440  decode.d5.loss_dice: 0.2633  decode.d6.loss_cls: 0.0452  decode.d6.loss_mask: 0.3413  decode.d6.loss_dice: 0.2631  decode.d7.loss_cls: 0.0549  decode.d7.loss_mask: 0.3445  decode.d7.loss_dice: 0.2623  decode.d8.loss_cls: 0.0600  decode.d8.loss_mask: 0.3437  decode.d8.loss_dice: 0.2597
08/06 13:28:11 - mmengine - INFO - Iter(train) [ 80550/320000]  base_lr: 7.7030e-05 lr: 7.7030e-06  eta: 1 day, 8:52:20  time: 0.4979  data_time: 0.0113  memory: 5911  grad_norm: 117.4214  loss: 6.4385  decode.loss_cls: 0.0174  decode.loss_mask: 0.2616  decode.loss_dice: 0.2844  decode.d0.loss_cls: 0.8198  decode.d0.loss_mask: 0.2636  decode.d0.loss_dice: 0.2634  decode.d1.loss_cls: 0.0167  decode.d1.loss_mask: 0.2652  decode.d1.loss_dice: 0.2727  decode.d2.loss_cls: 0.0292  decode.d2.loss_mask: 0.2660  decode.d2.loss_dice: 0.2827  decode.d3.loss_cls: 0.0308  decode.d3.loss_mask: 0.2636  decode.d3.loss_dice: 0.2797  decode.d4.loss_cls: 0.0183  decode.d4.loss_mask: 0.2599  decode.d4.loss_dice: 0.2809  decode.d5.loss_cls: 0.0134  decode.d5.loss_mask: 0.2612  decode.d5.loss_dice: 0.2864  decode.d6.loss_cls: 0.0155  decode.d6.loss_mask: 0.2623  decode.d6.loss_dice: 0.2834  decode.d7.loss_cls: 0.0346  decode.d7.loss_mask: 0.2603  decode.d7.loss_dice: 0.2795  decode.d8.loss_cls: 0.0252  decode.d8.loss_mask: 0.2607  decode.d8.loss_dice: 0.2802
08/06 13:28:36 - mmengine - INFO - Iter(train) [ 80600/320000]  base_lr: 7.7015e-05 lr: 7.7015e-06  eta: 1 day, 8:51:56  time: 0.4976  data_time: 0.0116  memory: 5876  grad_norm: 66.0132  loss: 7.2911  decode.loss_cls: 0.0366  decode.loss_mask: 0.3088  decode.loss_dice: 0.3044  decode.d0.loss_cls: 0.7834  decode.d0.loss_mask: 0.3133  decode.d0.loss_dice: 0.2756  decode.d1.loss_cls: 0.0578  decode.d1.loss_mask: 0.3118  decode.d1.loss_dice: 0.3096  decode.d2.loss_cls: 0.0674  decode.d2.loss_mask: 0.3129  decode.d2.loss_dice: 0.2959  decode.d3.loss_cls: 0.0585  decode.d3.loss_mask: 0.3142  decode.d3.loss_dice: 0.2992  decode.d4.loss_cls: 0.0577  decode.d4.loss_mask: 0.3089  decode.d4.loss_dice: 0.2877  decode.d5.loss_cls: 0.0650  decode.d5.loss_mask: 0.3049  decode.d5.loss_dice: 0.2932  decode.d6.loss_cls: 0.0398  decode.d6.loss_mask: 0.3064  decode.d6.loss_dice: 0.2936  decode.d7.loss_cls: 0.0280  decode.d7.loss_mask: 0.3139  decode.d7.loss_dice: 0.3019  decode.d8.loss_cls: 0.0212  decode.d8.loss_mask: 0.3174  decode.d8.loss_dice: 0.3023
08/06 13:29:01 - mmengine - INFO - Iter(train) [ 80650/320000]  base_lr: 7.7001e-05 lr: 7.7001e-06  eta: 1 day, 8:51:32  time: 0.4975  data_time: 0.0114  memory: 5970  grad_norm: 105.6423  loss: 7.8929  decode.loss_cls: 0.1455  decode.loss_mask: 0.2742  decode.loss_dice: 0.2974  decode.d0.loss_cls: 0.9111  decode.d0.loss_mask: 0.2728  decode.d0.loss_dice: 0.2964  decode.d1.loss_cls: 0.1724  decode.d1.loss_mask: 0.2722  decode.d1.loss_dice: 0.3168  decode.d2.loss_cls: 0.1160  decode.d2.loss_mask: 0.2829  decode.d2.loss_dice: 0.2952  decode.d3.loss_cls: 0.0936  decode.d3.loss_mask: 0.2766  decode.d3.loss_dice: 0.3056  decode.d4.loss_cls: 0.1137  decode.d4.loss_mask: 0.2799  decode.d4.loss_dice: 0.3235  decode.d5.loss_cls: 0.1004  decode.d5.loss_mask: 0.2801  decode.d5.loss_dice: 0.3146  decode.d6.loss_cls: 0.1276  decode.d6.loss_mask: 0.2772  decode.d6.loss_dice: 0.3184  decode.d7.loss_cls: 0.1516  decode.d7.loss_mask: 0.2785  decode.d7.loss_dice: 0.3060  decode.d8.loss_cls: 0.0883  decode.d8.loss_mask: 0.2775  decode.d8.loss_dice: 0.3267
08/06 13:29:26 - mmengine - INFO - Iter(train) [ 80700/320000]  base_lr: 7.6987e-05 lr: 7.6987e-06  eta: 1 day, 8:51:08  time: 0.4976  data_time: 0.0115  memory: 5913  grad_norm: 64.1602  loss: 6.3943  decode.loss_cls: 0.0741  decode.loss_mask: 0.2479  decode.loss_dice: 0.2416  decode.d0.loss_cls: 0.8467  decode.d0.loss_mask: 0.2539  decode.d0.loss_dice: 0.2377  decode.d1.loss_cls: 0.0626  decode.d1.loss_mask: 0.2501  decode.d1.loss_dice: 0.2468  decode.d2.loss_cls: 0.0630  decode.d2.loss_mask: 0.2507  decode.d2.loss_dice: 0.2423  decode.d3.loss_cls: 0.0618  decode.d3.loss_mask: 0.2473  decode.d3.loss_dice: 0.2418  decode.d4.loss_cls: 0.0616  decode.d4.loss_mask: 0.2512  decode.d4.loss_dice: 0.2442  decode.d5.loss_cls: 0.0566  decode.d5.loss_mask: 0.2516  decode.d5.loss_dice: 0.2437  decode.d6.loss_cls: 0.0834  decode.d6.loss_mask: 0.2494  decode.d6.loss_dice: 0.2450  decode.d7.loss_cls: 0.0853  decode.d7.loss_mask: 0.2479  decode.d7.loss_dice: 0.2378  decode.d8.loss_cls: 0.0757  decode.d8.loss_mask: 0.2493  decode.d8.loss_dice: 0.2433
08/06 13:29:51 - mmengine - INFO - Iter(train) [ 80750/320000]  base_lr: 7.6972e-05 lr: 7.6972e-06  eta: 1 day, 8:50:44  time: 0.4985  data_time: 0.0113  memory: 5894  grad_norm: 81.7710  loss: 5.5754  decode.loss_cls: 0.0248  decode.loss_mask: 0.2015  decode.loss_dice: 0.2491  decode.d0.loss_cls: 0.8894  decode.d0.loss_mask: 0.1956  decode.d0.loss_dice: 0.2315  decode.d1.loss_cls: 0.0413  decode.d1.loss_mask: 0.1991  decode.d1.loss_dice: 0.2368  decode.d2.loss_cls: 0.0379  decode.d2.loss_mask: 0.1971  decode.d2.loss_dice: 0.2467  decode.d3.loss_cls: 0.0309  decode.d3.loss_mask: 0.1986  decode.d3.loss_dice: 0.2449  decode.d4.loss_cls: 0.0250  decode.d4.loss_mask: 0.1982  decode.d4.loss_dice: 0.2399  decode.d5.loss_cls: 0.0472  decode.d5.loss_mask: 0.1982  decode.d5.loss_dice: 0.2380  decode.d6.loss_cls: 0.0325  decode.d6.loss_mask: 0.1979  decode.d6.loss_dice: 0.2505  decode.d7.loss_cls: 0.0164  decode.d7.loss_mask: 0.2007  decode.d7.loss_dice: 0.2452  decode.d8.loss_cls: 0.0276  decode.d8.loss_mask: 0.1946  decode.d8.loss_dice: 0.2383
08/06 13:30:16 - mmengine - INFO - Iter(train) [ 80800/320000]  base_lr: 7.6958e-05 lr: 7.6958e-06  eta: 1 day, 8:50:20  time: 0.4983  data_time: 0.0115  memory: 5894  grad_norm: 423.3989  loss: 11.9114  decode.loss_cls: 0.4015  decode.loss_mask: 0.3608  decode.loss_dice: 0.3816  decode.d0.loss_cls: 1.0294  decode.d0.loss_mask: 0.2875  decode.d0.loss_dice: 0.3290  decode.d1.loss_cls: 0.3987  decode.d1.loss_mask: 0.2933  decode.d1.loss_dice: 0.3196  decode.d2.loss_cls: 0.3914  decode.d2.loss_mask: 0.2911  decode.d2.loss_dice: 0.3446  decode.d3.loss_cls: 0.3441  decode.d3.loss_mask: 0.4658  decode.d3.loss_dice: 0.3333  decode.d4.loss_cls: 0.3850  decode.d4.loss_mask: 0.5715  decode.d4.loss_dice: 0.3468  decode.d5.loss_cls: 0.3692  decode.d5.loss_mask: 0.4256  decode.d5.loss_dice: 0.3444  decode.d6.loss_cls: 0.3849  decode.d6.loss_mask: 0.5913  decode.d6.loss_dice: 0.3622  decode.d7.loss_cls: 0.3509  decode.d7.loss_mask: 0.2967  decode.d7.loss_dice: 0.3470  decode.d8.loss_cls: 0.3757  decode.d8.loss_mask: 0.4524  decode.d8.loss_dice: 0.3361
08/06 13:30:40 - mmengine - INFO - Iter(train) [ 80850/320000]  base_lr: 7.6943e-05 lr: 7.6943e-06  eta: 1 day, 8:49:56  time: 0.4982  data_time: 0.0115  memory: 5891  grad_norm: 234.0427  loss: 9.1228  decode.loss_cls: 0.2926  decode.loss_mask: 0.2115  decode.loss_dice: 0.3032  decode.d0.loss_cls: 1.0414  decode.d0.loss_mask: 0.2284  decode.d0.loss_dice: 0.3066  decode.d1.loss_cls: 0.3161  decode.d1.loss_mask: 0.2158  decode.d1.loss_dice: 0.2887  decode.d2.loss_cls: 0.3233  decode.d2.loss_mask: 0.2145  decode.d2.loss_dice: 0.2955  decode.d3.loss_cls: 0.3070  decode.d3.loss_mask: 0.2173  decode.d3.loss_dice: 0.3117  decode.d4.loss_cls: 0.3327  decode.d4.loss_mask: 0.2147  decode.d4.loss_dice: 0.2998  decode.d5.loss_cls: 0.3383  decode.d5.loss_mask: 0.2156  decode.d5.loss_dice: 0.2798  decode.d6.loss_cls: 0.3924  decode.d6.loss_mask: 0.2135  decode.d6.loss_dice: 0.2898  decode.d7.loss_cls: 0.3379  decode.d7.loss_mask: 0.2191  decode.d7.loss_dice: 0.3098  decode.d8.loss_cls: 0.3193  decode.d8.loss_mask: 0.2136  decode.d8.loss_dice: 0.2729
08/06 13:31:06 - mmengine - INFO - Iter(train) [ 80900/320000]  base_lr: 7.6929e-05 lr: 7.6929e-06  eta: 1 day, 8:49:32  time: 0.5145  data_time: 0.0114  memory: 5894  grad_norm: 147.5674  loss: 6.4898  decode.loss_cls: 0.0890  decode.loss_mask: 0.2094  decode.loss_dice: 0.2702  decode.d0.loss_cls: 0.8075  decode.d0.loss_mask: 0.2078  decode.d0.loss_dice: 0.2806  decode.d1.loss_cls: 0.2250  decode.d1.loss_mask: 0.2082  decode.d1.loss_dice: 0.2451  decode.d2.loss_cls: 0.0930  decode.d2.loss_mask: 0.2086  decode.d2.loss_dice: 0.2441  decode.d3.loss_cls: 0.0911  decode.d3.loss_mask: 0.2074  decode.d3.loss_dice: 0.2460  decode.d4.loss_cls: 0.1194  decode.d4.loss_mask: 0.2129  decode.d4.loss_dice: 0.2469  decode.d5.loss_cls: 0.1017  decode.d5.loss_mask: 0.2166  decode.d5.loss_dice: 0.2781  decode.d6.loss_cls: 0.0905  decode.d6.loss_mask: 0.2129  decode.d6.loss_dice: 0.2690  decode.d7.loss_cls: 0.0957  decode.d7.loss_mask: 0.2192  decode.d7.loss_dice: 0.2466  decode.d8.loss_cls: 0.0885  decode.d8.loss_mask: 0.2075  decode.d8.loss_dice: 0.2512
08/06 13:31:30 - mmengine - INFO - Iter(train) [ 80950/320000]  base_lr: 7.6914e-05 lr: 7.6914e-06  eta: 1 day, 8:49:08  time: 0.4979  data_time: 0.0116  memory: 5928  grad_norm: 65.7805  loss: 7.7461  decode.loss_cls: 0.1432  decode.loss_mask: 0.2686  decode.loss_dice: 0.2807  decode.d0.loss_cls: 0.8654  decode.d0.loss_mask: 0.2682  decode.d0.loss_dice: 0.2830  decode.d1.loss_cls: 0.1912  decode.d1.loss_mask: 0.2748  decode.d1.loss_dice: 0.2823  decode.d2.loss_cls: 0.2025  decode.d2.loss_mask: 0.2719  decode.d2.loss_dice: 0.2818  decode.d3.loss_cls: 0.1474  decode.d3.loss_mask: 0.2693  decode.d3.loss_dice: 0.2743  decode.d4.loss_cls: 0.1326  decode.d4.loss_mask: 0.2699  decode.d4.loss_dice: 0.2759  decode.d5.loss_cls: 0.1522  decode.d5.loss_mask: 0.2660  decode.d5.loss_dice: 0.2723  decode.d6.loss_cls: 0.1529  decode.d6.loss_mask: 0.2663  decode.d6.loss_dice: 0.2657  decode.d7.loss_cls: 0.1378  decode.d7.loss_mask: 0.2666  decode.d7.loss_dice: 0.2711  decode.d8.loss_cls: 0.1700  decode.d8.loss_mask: 0.2695  decode.d8.loss_dice: 0.2725
08/06 13:31:55 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 13:31:55 - mmengine - INFO - Iter(train) [ 81000/320000]  base_lr: 7.6900e-05 lr: 7.6900e-06  eta: 1 day, 8:48:44  time: 0.4977  data_time: 0.0114  memory: 5874  grad_norm: 111.4730  loss: 6.5173  decode.loss_cls: 0.0533  decode.loss_mask: 0.2473  decode.loss_dice: 0.2611  decode.d0.loss_cls: 0.8855  decode.d0.loss_mask: 0.2564  decode.d0.loss_dice: 0.2534  decode.d1.loss_cls: 0.1318  decode.d1.loss_mask: 0.2470  decode.d1.loss_dice: 0.2589  decode.d2.loss_cls: 0.0578  decode.d2.loss_mask: 0.2481  decode.d2.loss_dice: 0.2608  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 0.2507  decode.d3.loss_dice: 0.2564  decode.d4.loss_cls: 0.0382  decode.d4.loss_mask: 0.2480  decode.d4.loss_dice: 0.2636  decode.d5.loss_cls: 0.0310  decode.d5.loss_mask: 0.2510  decode.d5.loss_dice: 0.2639  decode.d6.loss_cls: 0.0342  decode.d6.loss_mask: 0.2502  decode.d6.loss_dice: 0.2616  decode.d7.loss_cls: 0.0532  decode.d7.loss_mask: 0.2484  decode.d7.loss_dice: 0.2703  decode.d8.loss_cls: 0.0598  decode.d8.loss_mask: 0.2477  decode.d8.loss_dice: 0.2647
08/06 13:32:20 - mmengine - INFO - Iter(train) [ 81050/320000]  base_lr: 7.6885e-05 lr: 7.6885e-06  eta: 1 day, 8:48:20  time: 0.4964  data_time: 0.0116  memory: 5876  grad_norm: 154.1128  loss: 7.3699  decode.loss_cls: 0.1186  decode.loss_mask: 0.2582  decode.loss_dice: 0.2916  decode.d0.loss_cls: 0.8255  decode.d0.loss_mask: 0.2548  decode.d0.loss_dice: 0.2753  decode.d1.loss_cls: 0.1559  decode.d1.loss_mask: 0.2610  decode.d1.loss_dice: 0.2904  decode.d2.loss_cls: 0.1128  decode.d2.loss_mask: 0.2550  decode.d2.loss_dice: 0.2759  decode.d3.loss_cls: 0.1539  decode.d3.loss_mask: 0.2551  decode.d3.loss_dice: 0.2836  decode.d4.loss_cls: 0.1412  decode.d4.loss_mask: 0.2565  decode.d4.loss_dice: 0.2596  decode.d5.loss_cls: 0.1200  decode.d5.loss_mask: 0.2534  decode.d5.loss_dice: 0.2841  decode.d6.loss_cls: 0.1299  decode.d6.loss_mask: 0.2529  decode.d6.loss_dice: 0.3082  decode.d7.loss_cls: 0.1131  decode.d7.loss_mask: 0.2562  decode.d7.loss_dice: 0.2716  decode.d8.loss_cls: 0.1277  decode.d8.loss_mask: 0.2560  decode.d8.loss_dice: 0.2718
08/06 13:32:45 - mmengine - INFO - Iter(train) [ 81100/320000]  base_lr: 7.6871e-05 lr: 7.6871e-06  eta: 1 day, 8:47:56  time: 0.4973  data_time: 0.0113  memory: 5876  grad_norm: 57.0317  loss: 6.3522  decode.loss_cls: 0.0499  decode.loss_mask: 0.2321  decode.loss_dice: 0.2755  decode.d0.loss_cls: 0.7968  decode.d0.loss_mask: 0.2317  decode.d0.loss_dice: 0.2554  decode.d1.loss_cls: 0.0533  decode.d1.loss_mask: 0.2375  decode.d1.loss_dice: 0.2736  decode.d2.loss_cls: 0.0499  decode.d2.loss_mask: 0.2308  decode.d2.loss_dice: 0.2686  decode.d3.loss_cls: 0.0780  decode.d3.loss_mask: 0.2323  decode.d3.loss_dice: 0.2609  decode.d4.loss_cls: 0.0609  decode.d4.loss_mask: 0.2279  decode.d4.loss_dice: 0.2534  decode.d5.loss_cls: 0.0502  decode.d5.loss_mask: 0.2312  decode.d5.loss_dice: 0.2749  decode.d6.loss_cls: 0.0591  decode.d6.loss_mask: 0.2335  decode.d6.loss_dice: 0.2861  decode.d7.loss_cls: 0.0696  decode.d7.loss_mask: 0.2293  decode.d7.loss_dice: 0.2845  decode.d8.loss_cls: 0.0541  decode.d8.loss_mask: 0.2278  decode.d8.loss_dice: 0.2832
08/06 13:33:10 - mmengine - INFO - Iter(train) [ 81150/320000]  base_lr: 7.6856e-05 lr: 7.6856e-06  eta: 1 day, 8:47:32  time: 0.4974  data_time: 0.0113  memory: 5891  grad_norm: 108.0427  loss: 5.6923  decode.loss_cls: 0.0590  decode.loss_mask: 0.1725  decode.loss_dice: 0.2437  decode.d0.loss_cls: 0.7981  decode.d0.loss_mask: 0.1735  decode.d0.loss_dice: 0.2615  decode.d1.loss_cls: 0.1272  decode.d1.loss_mask: 0.1757  decode.d1.loss_dice: 0.2505  decode.d2.loss_cls: 0.0905  decode.d2.loss_mask: 0.1683  decode.d2.loss_dice: 0.2567  decode.d3.loss_cls: 0.0593  decode.d3.loss_mask: 0.1711  decode.d3.loss_dice: 0.2431  decode.d4.loss_cls: 0.0761  decode.d4.loss_mask: 0.1692  decode.d4.loss_dice: 0.2365  decode.d5.loss_cls: 0.0857  decode.d5.loss_mask: 0.1682  decode.d5.loss_dice: 0.2437  decode.d6.loss_cls: 0.0672  decode.d6.loss_mask: 0.1695  decode.d6.loss_dice: 0.2361  decode.d7.loss_cls: 0.0783  decode.d7.loss_mask: 0.1709  decode.d7.loss_dice: 0.2608  decode.d8.loss_cls: 0.0576  decode.d8.loss_mask: 0.1696  decode.d8.loss_dice: 0.2522
08/06 13:33:35 - mmengine - INFO - Iter(train) [ 81200/320000]  base_lr: 7.6842e-05 lr: 7.6842e-06  eta: 1 day, 8:47:07  time: 0.4977  data_time: 0.0116  memory: 5891  grad_norm: 107.6671  loss: 5.9310  decode.loss_cls: 0.0511  decode.loss_mask: 0.1784  decode.loss_dice: 0.2809  decode.d0.loss_cls: 0.8888  decode.d0.loss_mask: 0.1812  decode.d0.loss_dice: 0.3035  decode.d1.loss_cls: 0.0262  decode.d1.loss_mask: 0.1839  decode.d1.loss_dice: 0.3022  decode.d2.loss_cls: 0.0455  decode.d2.loss_mask: 0.1759  decode.d2.loss_dice: 0.2874  decode.d3.loss_cls: 0.0361  decode.d3.loss_mask: 0.1791  decode.d3.loss_dice: 0.2816  decode.d4.loss_cls: 0.0328  decode.d4.loss_mask: 0.1786  decode.d4.loss_dice: 0.2844  decode.d5.loss_cls: 0.0305  decode.d5.loss_mask: 0.1784  decode.d5.loss_dice: 0.2956  decode.d6.loss_cls: 0.0520  decode.d6.loss_mask: 0.1800  decode.d6.loss_dice: 0.2882  decode.d7.loss_cls: 0.0332  decode.d7.loss_mask: 0.1797  decode.d7.loss_dice: 0.3040  decode.d8.loss_cls: 0.0352  decode.d8.loss_mask: 0.1784  decode.d8.loss_dice: 0.2782
08/06 13:34:00 - mmengine - INFO - Iter(train) [ 81250/320000]  base_lr: 7.6827e-05 lr: 7.6827e-06  eta: 1 day, 8:46:43  time: 0.4983  data_time: 0.0115  memory: 5928  grad_norm: 93.3067  loss: 5.6198  decode.loss_cls: 0.0124  decode.loss_mask: 0.2461  decode.loss_dice: 0.2210  decode.d0.loss_cls: 0.7006  decode.d0.loss_mask: 0.2497  decode.d0.loss_dice: 0.2194  decode.d1.loss_cls: 0.0545  decode.d1.loss_mask: 0.2476  decode.d1.loss_dice: 0.2271  decode.d2.loss_cls: 0.0219  decode.d2.loss_mask: 0.2440  decode.d2.loss_dice: 0.2289  decode.d3.loss_cls: 0.0119  decode.d3.loss_mask: 0.2471  decode.d3.loss_dice: 0.2250  decode.d4.loss_cls: 0.0272  decode.d4.loss_mask: 0.2467  decode.d4.loss_dice: 0.2253  decode.d5.loss_cls: 0.0265  decode.d5.loss_mask: 0.2452  decode.d5.loss_dice: 0.2227  decode.d6.loss_cls: 0.0223  decode.d6.loss_mask: 0.2454  decode.d6.loss_dice: 0.2262  decode.d7.loss_cls: 0.0201  decode.d7.loss_mask: 0.2447  decode.d7.loss_dice: 0.2287  decode.d8.loss_cls: 0.0163  decode.d8.loss_mask: 0.2436  decode.d8.loss_dice: 0.2217
08/06 13:34:25 - mmengine - INFO - Iter(train) [ 81300/320000]  base_lr: 7.6813e-05 lr: 7.6813e-06  eta: 1 day, 8:46:19  time: 0.4980  data_time: 0.0115  memory: 5930  grad_norm: 84.0392  loss: 8.4196  decode.loss_cls: 0.2918  decode.loss_mask: 0.1912  decode.loss_dice: 0.3219  decode.d0.loss_cls: 1.0138  decode.d0.loss_mask: 0.1880  decode.d0.loss_dice: 0.3337  decode.d1.loss_cls: 0.4193  decode.d1.loss_mask: 0.1880  decode.d1.loss_dice: 0.2788  decode.d2.loss_cls: 0.2689  decode.d2.loss_mask: 0.1905  decode.d2.loss_dice: 0.2798  decode.d3.loss_cls: 0.2864  decode.d3.loss_mask: 0.1898  decode.d3.loss_dice: 0.3034  decode.d4.loss_cls: 0.2892  decode.d4.loss_mask: 0.1906  decode.d4.loss_dice: 0.2773  decode.d5.loss_cls: 0.3002  decode.d5.loss_mask: 0.1891  decode.d5.loss_dice: 0.2907  decode.d6.loss_cls: 0.2258  decode.d6.loss_mask: 0.1887  decode.d6.loss_dice: 0.2732  decode.d7.loss_cls: 0.2586  decode.d7.loss_mask: 0.1883  decode.d7.loss_dice: 0.2761  decode.d8.loss_cls: 0.2590  decode.d8.loss_mask: 0.1901  decode.d8.loss_dice: 0.2777
08/06 13:34:50 - mmengine - INFO - Iter(train) [ 81350/320000]  base_lr: 7.6798e-05 lr: 7.6798e-06  eta: 1 day, 8:45:55  time: 0.4986  data_time: 0.0115  memory: 5930  grad_norm: 74.2824  loss: 7.9565  decode.loss_cls: 0.1369  decode.loss_mask: 0.2572  decode.loss_dice: 0.3243  decode.d0.loss_cls: 0.9283  decode.d0.loss_mask: 0.2659  decode.d0.loss_dice: 0.2999  decode.d1.loss_cls: 0.1937  decode.d1.loss_mask: 0.2604  decode.d1.loss_dice: 0.2892  decode.d2.loss_cls: 0.1548  decode.d2.loss_mask: 0.2610  decode.d2.loss_dice: 0.3099  decode.d3.loss_cls: 0.1265  decode.d3.loss_mask: 0.2608  decode.d3.loss_dice: 0.3006  decode.d4.loss_cls: 0.2187  decode.d4.loss_mask: 0.2592  decode.d4.loss_dice: 0.3007  decode.d5.loss_cls: 0.1206  decode.d5.loss_mask: 0.2603  decode.d5.loss_dice: 0.3106  decode.d6.loss_cls: 0.1396  decode.d6.loss_mask: 0.2599  decode.d6.loss_dice: 0.3120  decode.d7.loss_cls: 0.1261  decode.d7.loss_mask: 0.2588  decode.d7.loss_dice: 0.3248  decode.d8.loss_cls: 0.1462  decode.d8.loss_mask: 0.2589  decode.d8.loss_dice: 0.2908
08/06 13:35:15 - mmengine - INFO - Iter(train) [ 81400/320000]  base_lr: 7.6784e-05 lr: 7.6784e-06  eta: 1 day, 8:45:31  time: 0.4970  data_time: 0.0115  memory: 5891  grad_norm: 56.9093  loss: 6.8356  decode.loss_cls: 0.0178  decode.loss_mask: 0.2760  decode.loss_dice: 0.2951  decode.d0.loss_cls: 0.8590  decode.d0.loss_mask: 0.2784  decode.d0.loss_dice: 0.2543  decode.d1.loss_cls: 0.0429  decode.d1.loss_mask: 0.2751  decode.d1.loss_dice: 0.2823  decode.d2.loss_cls: 0.0097  decode.d2.loss_mask: 0.2775  decode.d2.loss_dice: 0.2979  decode.d3.loss_cls: 0.0203  decode.d3.loss_mask: 0.2739  decode.d3.loss_dice: 0.3021  decode.d4.loss_cls: 0.0184  decode.d4.loss_mask: 0.2737  decode.d4.loss_dice: 0.2804  decode.d5.loss_cls: 0.0885  decode.d5.loss_mask: 0.2752  decode.d5.loss_dice: 0.2966  decode.d6.loss_cls: 0.0522  decode.d6.loss_mask: 0.2756  decode.d6.loss_dice: 0.2993  decode.d7.loss_cls: 0.0319  decode.d7.loss_mask: 0.2746  decode.d7.loss_dice: 0.2948  decode.d8.loss_cls: 0.0336  decode.d8.loss_mask: 0.2761  decode.d8.loss_dice: 0.3024
08/06 13:35:40 - mmengine - INFO - Iter(train) [ 81450/320000]  base_lr: 7.6769e-05 lr: 7.6769e-06  eta: 1 day, 8:45:07  time: 0.4980  data_time: 0.0114  memory: 5911  grad_norm: 61.1769  loss: 5.2832  decode.loss_cls: 0.0436  decode.loss_mask: 0.1679  decode.loss_dice: 0.2492  decode.d0.loss_cls: 0.7722  decode.d0.loss_mask: 0.1689  decode.d0.loss_dice: 0.2491  decode.d1.loss_cls: 0.0527  decode.d1.loss_mask: 0.1689  decode.d1.loss_dice: 0.2453  decode.d2.loss_cls: 0.0478  decode.d2.loss_mask: 0.1668  decode.d2.loss_dice: 0.2405  decode.d3.loss_cls: 0.0320  decode.d3.loss_mask: 0.1693  decode.d3.loss_dice: 0.2448  decode.d4.loss_cls: 0.0353  decode.d4.loss_mask: 0.1688  decode.d4.loss_dice: 0.2418  decode.d5.loss_cls: 0.0375  decode.d5.loss_mask: 0.1669  decode.d5.loss_dice: 0.2290  decode.d6.loss_cls: 0.0751  decode.d6.loss_mask: 0.1691  decode.d6.loss_dice: 0.2405  decode.d7.loss_cls: 0.0357  decode.d7.loss_mask: 0.1677  decode.d7.loss_dice: 0.2447  decode.d8.loss_cls: 0.0348  decode.d8.loss_mask: 0.1670  decode.d8.loss_dice: 0.2504
08/06 13:36:05 - mmengine - INFO - Iter(train) [ 81500/320000]  base_lr: 7.6755e-05 lr: 7.6755e-06  eta: 1 day, 8:44:43  time: 0.5104  data_time: 0.0117  memory: 5894  grad_norm: 209.8424  loss: 9.3031  decode.loss_cls: 0.2157  decode.loss_mask: 0.3075  decode.loss_dice: 0.3230  decode.d0.loss_cls: 1.0931  decode.d0.loss_mask: 0.3027  decode.d0.loss_dice: 0.3336  decode.d1.loss_cls: 0.2580  decode.d1.loss_mask: 0.3044  decode.d1.loss_dice: 0.3153  decode.d2.loss_cls: 0.1919  decode.d2.loss_mask: 0.3011  decode.d2.loss_dice: 0.3246  decode.d3.loss_cls: 0.2012  decode.d3.loss_mask: 0.3036  decode.d3.loss_dice: 0.3158  decode.d4.loss_cls: 0.2274  decode.d4.loss_mask: 0.3032  decode.d4.loss_dice: 0.3303  decode.d5.loss_cls: 0.1919  decode.d5.loss_mask: 0.3045  decode.d5.loss_dice: 0.3327  decode.d6.loss_cls: 0.2037  decode.d6.loss_mask: 0.3020  decode.d6.loss_dice: 0.3241  decode.d7.loss_cls: 0.2132  decode.d7.loss_mask: 0.3065  decode.d7.loss_dice: 0.3350  decode.d8.loss_cls: 0.1989  decode.d8.loss_mask: 0.3072  decode.d8.loss_dice: 0.3307
08/06 13:36:30 - mmengine - INFO - Iter(train) [ 81550/320000]  base_lr: 7.6740e-05 lr: 7.6740e-06  eta: 1 day, 8:44:19  time: 0.4973  data_time: 0.0115  memory: 5895  grad_norm: 141.7219  loss: 6.4913  decode.loss_cls: 0.0160  decode.loss_mask: 0.2442  decode.loss_dice: 0.2789  decode.d0.loss_cls: 0.8352  decode.d0.loss_mask: 0.2482  decode.d0.loss_dice: 0.2832  decode.d1.loss_cls: 0.0837  decode.d1.loss_mask: 0.2439  decode.d1.loss_dice: 0.2834  decode.d2.loss_cls: 0.0848  decode.d2.loss_mask: 0.2454  decode.d2.loss_dice: 0.2776  decode.d3.loss_cls: 0.0397  decode.d3.loss_mask: 0.2433  decode.d3.loss_dice: 0.2869  decode.d4.loss_cls: 0.0596  decode.d4.loss_mask: 0.2466  decode.d4.loss_dice: 0.2841  decode.d5.loss_cls: 0.0380  decode.d5.loss_mask: 0.2461  decode.d5.loss_dice: 0.2808  decode.d6.loss_cls: 0.0291  decode.d6.loss_mask: 0.2433  decode.d6.loss_dice: 0.2776  decode.d7.loss_cls: 0.0279  decode.d7.loss_mask: 0.2429  decode.d7.loss_dice: 0.2777  decode.d8.loss_cls: 0.0211  decode.d8.loss_mask: 0.2456  decode.d8.loss_dice: 0.2764
08/06 13:36:54 - mmengine - INFO - Iter(train) [ 81600/320000]  base_lr: 7.6726e-05 lr: 7.6726e-06  eta: 1 day, 8:43:54  time: 0.4988  data_time: 0.0117  memory: 5891  grad_norm: 40.3196  loss: 6.1422  decode.loss_cls: 0.0700  decode.loss_mask: 0.2198  decode.loss_dice: 0.2149  decode.d0.loss_cls: 0.8850  decode.d0.loss_mask: 0.2211  decode.d0.loss_dice: 0.2088  decode.d1.loss_cls: 0.1776  decode.d1.loss_mask: 0.2175  decode.d1.loss_dice: 0.2145  decode.d2.loss_cls: 0.0918  decode.d2.loss_mask: 0.2192  decode.d2.loss_dice: 0.2205  decode.d3.loss_cls: 0.0858  decode.d3.loss_mask: 0.2208  decode.d3.loss_dice: 0.2144  decode.d4.loss_cls: 0.0753  decode.d4.loss_mask: 0.2164  decode.d4.loss_dice: 0.2121  decode.d5.loss_cls: 0.1069  decode.d5.loss_mask: 0.2179  decode.d5.loss_dice: 0.2128  decode.d6.loss_cls: 0.0973  decode.d6.loss_mask: 0.2186  decode.d6.loss_dice: 0.2157  decode.d7.loss_cls: 0.0933  decode.d7.loss_mask: 0.2188  decode.d7.loss_dice: 0.2198  decode.d8.loss_cls: 0.1187  decode.d8.loss_mask: 0.2193  decode.d8.loss_dice: 0.2175
08/06 13:37:19 - mmengine - INFO - Iter(train) [ 81650/320000]  base_lr: 7.6711e-05 lr: 7.6711e-06  eta: 1 day, 8:43:30  time: 0.4981  data_time: 0.0116  memory: 5894  grad_norm: 58.9931  loss: 6.9452  decode.loss_cls: 0.1271  decode.loss_mask: 0.2134  decode.loss_dice: 0.2752  decode.d0.loss_cls: 0.9183  decode.d0.loss_mask: 0.2114  decode.d0.loss_dice: 0.2643  decode.d1.loss_cls: 0.1317  decode.d1.loss_mask: 0.2125  decode.d1.loss_dice: 0.2595  decode.d2.loss_cls: 0.1481  decode.d2.loss_mask: 0.2100  decode.d2.loss_dice: 0.2808  decode.d3.loss_cls: 0.1455  decode.d3.loss_mask: 0.2098  decode.d3.loss_dice: 0.2643  decode.d4.loss_cls: 0.1161  decode.d4.loss_mask: 0.2117  decode.d4.loss_dice: 0.2858  decode.d5.loss_cls: 0.1463  decode.d5.loss_mask: 0.2086  decode.d5.loss_dice: 0.2717  decode.d6.loss_cls: 0.1115  decode.d6.loss_mask: 0.2134  decode.d6.loss_dice: 0.2567  decode.d7.loss_cls: 0.1554  decode.d7.loss_mask: 0.2122  decode.d7.loss_dice: 0.2850  decode.d8.loss_cls: 0.1241  decode.d8.loss_mask: 0.2164  decode.d8.loss_dice: 0.2585
08/06 13:37:44 - mmengine - INFO - Iter(train) [ 81700/320000]  base_lr: 7.6697e-05 lr: 7.6697e-06  eta: 1 day, 8:43:06  time: 0.4984  data_time: 0.0116  memory: 5909  grad_norm: 78.6418  loss: 5.7881  decode.loss_cls: 0.0568  decode.loss_mask: 0.1986  decode.loss_dice: 0.2290  decode.d0.loss_cls: 0.8396  decode.d0.loss_mask: 0.2020  decode.d0.loss_dice: 0.2240  decode.d1.loss_cls: 0.0962  decode.d1.loss_mask: 0.1978  decode.d1.loss_dice: 0.2259  decode.d2.loss_cls: 0.0866  decode.d2.loss_mask: 0.1953  decode.d2.loss_dice: 0.2357  decode.d3.loss_cls: 0.0665  decode.d3.loss_mask: 0.1952  decode.d3.loss_dice: 0.2269  decode.d4.loss_cls: 0.0651  decode.d4.loss_mask: 0.1955  decode.d4.loss_dice: 0.2107  decode.d5.loss_cls: 0.0697  decode.d5.loss_mask: 0.1968  decode.d5.loss_dice: 0.2371  decode.d6.loss_cls: 0.0697  decode.d6.loss_mask: 0.1970  decode.d6.loss_dice: 0.2256  decode.d7.loss_cls: 0.0842  decode.d7.loss_mask: 0.1980  decode.d7.loss_dice: 0.2391  decode.d8.loss_cls: 0.0946  decode.d8.loss_mask: 0.1976  decode.d8.loss_dice: 0.2313
08/06 13:38:09 - mmengine - INFO - Iter(train) [ 81750/320000]  base_lr: 7.6682e-05 lr: 7.6682e-06  eta: 1 day, 8:42:42  time: 0.4985  data_time: 0.0116  memory: 5895  grad_norm: 63.0294  loss: 5.9916  decode.loss_cls: 0.0509  decode.loss_mask: 0.1896  decode.loss_dice: 0.2757  decode.d0.loss_cls: 0.8070  decode.d0.loss_mask: 0.1909  decode.d0.loss_dice: 0.2780  decode.d1.loss_cls: 0.1149  decode.d1.loss_mask: 0.1906  decode.d1.loss_dice: 0.2758  decode.d2.loss_cls: 0.0905  decode.d2.loss_mask: 0.1908  decode.d2.loss_dice: 0.2592  decode.d3.loss_cls: 0.0645  decode.d3.loss_mask: 0.1899  decode.d3.loss_dice: 0.2667  decode.d4.loss_cls: 0.0555  decode.d4.loss_mask: 0.1895  decode.d4.loss_dice: 0.2582  decode.d5.loss_cls: 0.0568  decode.d5.loss_mask: 0.1885  decode.d5.loss_dice: 0.2648  decode.d6.loss_cls: 0.0571  decode.d6.loss_mask: 0.1899  decode.d6.loss_dice: 0.2723  decode.d7.loss_cls: 0.0479  decode.d7.loss_mask: 0.1896  decode.d7.loss_dice: 0.2831  decode.d8.loss_cls: 0.0567  decode.d8.loss_mask: 0.1896  decode.d8.loss_dice: 0.2571
08/06 13:38:34 - mmengine - INFO - Iter(train) [ 81800/320000]  base_lr: 7.6668e-05 lr: 7.6668e-06  eta: 1 day, 8:42:18  time: 0.4983  data_time: 0.0113  memory: 5930  grad_norm: 80.1642  loss: 6.0988  decode.loss_cls: 0.0943  decode.loss_mask: 0.2136  decode.loss_dice: 0.2190  decode.d0.loss_cls: 0.9336  decode.d0.loss_mask: 0.2127  decode.d0.loss_dice: 0.2185  decode.d1.loss_cls: 0.0856  decode.d1.loss_mask: 0.2151  decode.d1.loss_dice: 0.2266  decode.d2.loss_cls: 0.0811  decode.d2.loss_mask: 0.2143  decode.d2.loss_dice: 0.2221  decode.d3.loss_cls: 0.0957  decode.d3.loss_mask: 0.2159  decode.d3.loss_dice: 0.2247  decode.d4.loss_cls: 0.0813  decode.d4.loss_mask: 0.2158  decode.d4.loss_dice: 0.2229  decode.d5.loss_cls: 0.0688  decode.d5.loss_mask: 0.2155  decode.d5.loss_dice: 0.2249  decode.d6.loss_cls: 0.0788  decode.d6.loss_mask: 0.2245  decode.d6.loss_dice: 0.2283  decode.d7.loss_cls: 0.0918  decode.d7.loss_mask: 0.2177  decode.d7.loss_dice: 0.2257  decode.d8.loss_cls: 0.0936  decode.d8.loss_mask: 0.2142  decode.d8.loss_dice: 0.2224
08/06 13:38:59 - mmengine - INFO - Iter(train) [ 81850/320000]  base_lr: 7.6653e-05 lr: 7.6653e-06  eta: 1 day, 8:41:53  time: 0.4979  data_time: 0.0114  memory: 5925  grad_norm: 102.7391  loss: 9.5489  decode.loss_cls: 0.3054  decode.loss_mask: 0.2521  decode.loss_dice: 0.3254  decode.d0.loss_cls: 1.0944  decode.d0.loss_mask: 0.2761  decode.d0.loss_dice: 0.3246  decode.d1.loss_cls: 0.2749  decode.d1.loss_mask: 0.2773  decode.d1.loss_dice: 0.3285  decode.d2.loss_cls: 0.3110  decode.d2.loss_mask: 0.2509  decode.d2.loss_dice: 0.3308  decode.d3.loss_cls: 0.2414  decode.d3.loss_mask: 0.2764  decode.d3.loss_dice: 0.3257  decode.d4.loss_cls: 0.3516  decode.d4.loss_mask: 0.2534  decode.d4.loss_dice: 0.3402  decode.d5.loss_cls: 0.2288  decode.d5.loss_mask: 0.2689  decode.d5.loss_dice: 0.3293  decode.d6.loss_cls: 0.2748  decode.d6.loss_mask: 0.2507  decode.d6.loss_dice: 0.3142  decode.d7.loss_cls: 0.2478  decode.d7.loss_mask: 0.2754  decode.d7.loss_dice: 0.3318  decode.d8.loss_cls: 0.3111  decode.d8.loss_mask: 0.2552  decode.d8.loss_dice: 0.3211
08/06 13:39:24 - mmengine - INFO - Iter(train) [ 81900/320000]  base_lr: 7.6639e-05 lr: 7.6639e-06  eta: 1 day, 8:41:29  time: 0.4982  data_time: 0.0115  memory: 5932  grad_norm: 84.2848  loss: 6.3229  decode.loss_cls: 0.1094  decode.loss_mask: 0.1953  decode.loss_dice: 0.2623  decode.d0.loss_cls: 0.8284  decode.d0.loss_mask: 0.1971  decode.d0.loss_dice: 0.2818  decode.d1.loss_cls: 0.1063  decode.d1.loss_mask: 0.1967  decode.d1.loss_dice: 0.2662  decode.d2.loss_cls: 0.0945  decode.d2.loss_mask: 0.1927  decode.d2.loss_dice: 0.2609  decode.d3.loss_cls: 0.0858  decode.d3.loss_mask: 0.1927  decode.d3.loss_dice: 0.2667  decode.d4.loss_cls: 0.0988  decode.d4.loss_mask: 0.1959  decode.d4.loss_dice: 0.2677  decode.d5.loss_cls: 0.1016  decode.d5.loss_mask: 0.1933  decode.d5.loss_dice: 0.2477  decode.d6.loss_cls: 0.1072  decode.d6.loss_mask: 0.1920  decode.d6.loss_dice: 0.2553  decode.d7.loss_cls: 0.0944  decode.d7.loss_mask: 0.1934  decode.d7.loss_dice: 0.2679  decode.d8.loss_cls: 0.1193  decode.d8.loss_mask: 0.1925  decode.d8.loss_dice: 0.2592
08/06 13:39:49 - mmengine - INFO - Iter(train) [ 81950/320000]  base_lr: 7.6624e-05 lr: 7.6624e-06  eta: 1 day, 8:41:05  time: 0.4973  data_time: 0.0116  memory: 5894  grad_norm: 61.4210  loss: 5.6035  decode.loss_cls: 0.0848  decode.loss_mask: 0.1688  decode.loss_dice: 0.2248  decode.d0.loss_cls: 0.9232  decode.d0.loss_mask: 0.1676  decode.d0.loss_dice: 0.2146  decode.d1.loss_cls: 0.1380  decode.d1.loss_mask: 0.1681  decode.d1.loss_dice: 0.2145  decode.d2.loss_cls: 0.0951  decode.d2.loss_mask: 0.1689  decode.d2.loss_dice: 0.2167  decode.d3.loss_cls: 0.0734  decode.d3.loss_mask: 0.1677  decode.d3.loss_dice: 0.2052  decode.d4.loss_cls: 0.0811  decode.d4.loss_mask: 0.1699  decode.d4.loss_dice: 0.2145  decode.d5.loss_cls: 0.0770  decode.d5.loss_mask: 0.1696  decode.d5.loss_dice: 0.2333  decode.d6.loss_cls: 0.1012  decode.d6.loss_mask: 0.1688  decode.d6.loss_dice: 0.2199  decode.d7.loss_cls: 0.0599  decode.d7.loss_mask: 0.1695  decode.d7.loss_dice: 0.2199  decode.d8.loss_cls: 0.0808  decode.d8.loss_mask: 0.1694  decode.d8.loss_dice: 0.2372
08/06 13:40:14 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 13:40:14 - mmengine - INFO - Iter(train) [ 82000/320000]  base_lr: 7.6610e-05 lr: 7.6610e-06  eta: 1 day, 8:40:41  time: 0.4988  data_time: 0.0114  memory: 5909  grad_norm: 164.6519  loss: 6.0800  decode.loss_cls: 0.1362  decode.loss_mask: 0.1957  decode.loss_dice: 0.2504  decode.d0.loss_cls: 0.9270  decode.d0.loss_mask: 0.1964  decode.d0.loss_dice: 0.2456  decode.d1.loss_cls: 0.0615  decode.d1.loss_mask: 0.1968  decode.d1.loss_dice: 0.2603  decode.d2.loss_cls: 0.0483  decode.d2.loss_mask: 0.1964  decode.d2.loss_dice: 0.2575  decode.d3.loss_cls: 0.0326  decode.d3.loss_mask: 0.1973  decode.d3.loss_dice: 0.2706  decode.d4.loss_cls: 0.0366  decode.d4.loss_mask: 0.1954  decode.d4.loss_dice: 0.2511  decode.d5.loss_cls: 0.0583  decode.d5.loss_mask: 0.1955  decode.d5.loss_dice: 0.2491  decode.d6.loss_cls: 0.0997  decode.d6.loss_mask: 0.1956  decode.d6.loss_dice: 0.2460  decode.d7.loss_cls: 0.0982  decode.d7.loss_mask: 0.1940  decode.d7.loss_dice: 0.2480  decode.d8.loss_cls: 0.0987  decode.d8.loss_mask: 0.1951  decode.d8.loss_dice: 0.2461
08/06 13:40:39 - mmengine - INFO - Iter(train) [ 82050/320000]  base_lr: 7.6596e-05 lr: 7.6596e-06  eta: 1 day, 8:40:17  time: 0.4980  data_time: 0.0117  memory: 5895  grad_norm: 132.7829  loss: 7.4595  decode.loss_cls: 0.2123  decode.loss_mask: 0.2247  decode.loss_dice: 0.2926  decode.d0.loss_cls: 0.7929  decode.d0.loss_mask: 0.2239  decode.d0.loss_dice: 0.2935  decode.d1.loss_cls: 0.1809  decode.d1.loss_mask: 0.2255  decode.d1.loss_dice: 0.3018  decode.d2.loss_cls: 0.1686  decode.d2.loss_mask: 0.2224  decode.d2.loss_dice: 0.2912  decode.d3.loss_cls: 0.1633  decode.d3.loss_mask: 0.2231  decode.d3.loss_dice: 0.2981  decode.d4.loss_cls: 0.1308  decode.d4.loss_mask: 0.2230  decode.d4.loss_dice: 0.2967  decode.d5.loss_cls: 0.1480  decode.d5.loss_mask: 0.2230  decode.d5.loss_dice: 0.3051  decode.d6.loss_cls: 0.1504  decode.d6.loss_mask: 0.2239  decode.d6.loss_dice: 0.2948  decode.d7.loss_cls: 0.1428  decode.d7.loss_mask: 0.2233  decode.d7.loss_dice: 0.2944  decode.d8.loss_cls: 0.1662  decode.d8.loss_mask: 0.2254  decode.d8.loss_dice: 0.2972
08/06 13:41:04 - mmengine - INFO - Iter(train) [ 82100/320000]  base_lr: 7.6581e-05 lr: 7.6581e-06  eta: 1 day, 8:39:53  time: 0.4974  data_time: 0.0116  memory: 5876  grad_norm: 67.3482  loss: 5.4675  decode.loss_cls: 0.0582  decode.loss_mask: 0.2033  decode.loss_dice: 0.2201  decode.d0.loss_cls: 0.7739  decode.d0.loss_mask: 0.2054  decode.d0.loss_dice: 0.2167  decode.d1.loss_cls: 0.0926  decode.d1.loss_mask: 0.2023  decode.d1.loss_dice: 0.2193  decode.d2.loss_cls: 0.0793  decode.d2.loss_mask: 0.2026  decode.d2.loss_dice: 0.2265  decode.d3.loss_cls: 0.0486  decode.d3.loss_mask: 0.2014  decode.d3.loss_dice: 0.2139  decode.d4.loss_cls: 0.0352  decode.d4.loss_mask: 0.2030  decode.d4.loss_dice: 0.2210  decode.d5.loss_cls: 0.0261  decode.d5.loss_mask: 0.2009  decode.d5.loss_dice: 0.2238  decode.d6.loss_cls: 0.0239  decode.d6.loss_mask: 0.2047  decode.d6.loss_dice: 0.2321  decode.d7.loss_cls: 0.0284  decode.d7.loss_mask: 0.2012  decode.d7.loss_dice: 0.2171  decode.d8.loss_cls: 0.0669  decode.d8.loss_mask: 0.2003  decode.d8.loss_dice: 0.2190
08/06 13:41:29 - mmengine - INFO - Iter(train) [ 82150/320000]  base_lr: 7.6567e-05 lr: 7.6567e-06  eta: 1 day, 8:39:29  time: 0.4982  data_time: 0.0114  memory: 5909  grad_norm: 56.5623  loss: 6.0369  decode.loss_cls: 0.0510  decode.loss_mask: 0.2290  decode.loss_dice: 0.2236  decode.d0.loss_cls: 0.9322  decode.d0.loss_mask: 0.2330  decode.d0.loss_dice: 0.2352  decode.d1.loss_cls: 0.1276  decode.d1.loss_mask: 0.2316  decode.d1.loss_dice: 0.2232  decode.d2.loss_cls: 0.0573  decode.d2.loss_mask: 0.2303  decode.d2.loss_dice: 0.2286  decode.d3.loss_cls: 0.0613  decode.d3.loss_mask: 0.2309  decode.d3.loss_dice: 0.2248  decode.d4.loss_cls: 0.0516  decode.d4.loss_mask: 0.2314  decode.d4.loss_dice: 0.2244  decode.d5.loss_cls: 0.0477  decode.d5.loss_mask: 0.2295  decode.d5.loss_dice: 0.2182  decode.d6.loss_cls: 0.0622  decode.d6.loss_mask: 0.2284  decode.d6.loss_dice: 0.2161  decode.d7.loss_cls: 0.0531  decode.d7.loss_mask: 0.2326  decode.d7.loss_dice: 0.2215  decode.d8.loss_cls: 0.0522  decode.d8.loss_mask: 0.2300  decode.d8.loss_dice: 0.2183
08/06 13:41:54 - mmengine - INFO - Iter(train) [ 82200/320000]  base_lr: 7.6552e-05 lr: 7.6552e-06  eta: 1 day, 8:39:05  time: 0.4979  data_time: 0.0115  memory: 5913  grad_norm: 42.5713  loss: 5.5642  decode.loss_cls: 0.0670  decode.loss_mask: 0.1827  decode.loss_dice: 0.2297  decode.d0.loss_cls: 0.7933  decode.d0.loss_mask: 0.1830  decode.d0.loss_dice: 0.2400  decode.d1.loss_cls: 0.0882  decode.d1.loss_mask: 0.1841  decode.d1.loss_dice: 0.2312  decode.d2.loss_cls: 0.0740  decode.d2.loss_mask: 0.1822  decode.d2.loss_dice: 0.2293  decode.d3.loss_cls: 0.0798  decode.d3.loss_mask: 0.1839  decode.d3.loss_dice: 0.2364  decode.d4.loss_cls: 0.0713  decode.d4.loss_mask: 0.1828  decode.d4.loss_dice: 0.2425  decode.d5.loss_cls: 0.0702  decode.d5.loss_mask: 0.1831  decode.d5.loss_dice: 0.2312  decode.d6.loss_cls: 0.0533  decode.d6.loss_mask: 0.1839  decode.d6.loss_dice: 0.2440  decode.d7.loss_cls: 0.0292  decode.d7.loss_mask: 0.1843  decode.d7.loss_dice: 0.2462  decode.d8.loss_cls: 0.0223  decode.d8.loss_mask: 0.1840  decode.d8.loss_dice: 0.2513
08/06 13:42:18 - mmengine - INFO - Iter(train) [ 82250/320000]  base_lr: 7.6538e-05 lr: 7.6538e-06  eta: 1 day, 8:38:41  time: 0.4983  data_time: 0.0117  memory: 5891  grad_norm: 154.4615  loss: 7.8399  decode.loss_cls: 0.2158  decode.loss_mask: 0.2110  decode.loss_dice: 0.2956  decode.d0.loss_cls: 0.8924  decode.d0.loss_mask: 0.2176  decode.d0.loss_dice: 0.3189  decode.d1.loss_cls: 0.2004  decode.d1.loss_mask: 0.2093  decode.d1.loss_dice: 0.2829  decode.d2.loss_cls: 0.2701  decode.d2.loss_mask: 0.2101  decode.d2.loss_dice: 0.2866  decode.d3.loss_cls: 0.2291  decode.d3.loss_mask: 0.2078  decode.d3.loss_dice: 0.2771  decode.d4.loss_cls: 0.1881  decode.d4.loss_mask: 0.2128  decode.d4.loss_dice: 0.2926  decode.d5.loss_cls: 0.1640  decode.d5.loss_mask: 0.2105  decode.d5.loss_dice: 0.2759  decode.d6.loss_cls: 0.2123  decode.d6.loss_mask: 0.2073  decode.d6.loss_dice: 0.2796  decode.d7.loss_cls: 0.2242  decode.d7.loss_mask: 0.2089  decode.d7.loss_dice: 0.2691  decode.d8.loss_cls: 0.2521  decode.d8.loss_mask: 0.2101  decode.d8.loss_dice: 0.3075
08/06 13:42:43 - mmengine - INFO - Iter(train) [ 82300/320000]  base_lr: 7.6523e-05 lr: 7.6523e-06  eta: 1 day, 8:38:17  time: 0.5000  data_time: 0.0118  memory: 5932  grad_norm: 99.7576  loss: 7.2041  decode.loss_cls: 0.0760  decode.loss_mask: 0.2486  decode.loss_dice: 0.3038  decode.d0.loss_cls: 0.9135  decode.d0.loss_mask: 0.2448  decode.d0.loss_dice: 0.2944  decode.d1.loss_cls: 0.1083  decode.d1.loss_mask: 0.2480  decode.d1.loss_dice: 0.3037  decode.d2.loss_cls: 0.1032  decode.d2.loss_mask: 0.2445  decode.d2.loss_dice: 0.2966  decode.d3.loss_cls: 0.1037  decode.d3.loss_mask: 0.2438  decode.d3.loss_dice: 0.2921  decode.d4.loss_cls: 0.0797  decode.d4.loss_mask: 0.2480  decode.d4.loss_dice: 0.2999  decode.d5.loss_cls: 0.1218  decode.d5.loss_mask: 0.2463  decode.d5.loss_dice: 0.2879  decode.d6.loss_cls: 0.0984  decode.d6.loss_mask: 0.2421  decode.d6.loss_dice: 0.2975  decode.d7.loss_cls: 0.0821  decode.d7.loss_mask: 0.2464  decode.d7.loss_dice: 0.2935  decode.d8.loss_cls: 0.1085  decode.d8.loss_mask: 0.2491  decode.d8.loss_dice: 0.2777
08/06 13:43:09 - mmengine - INFO - Iter(train) [ 82350/320000]  base_lr: 7.6509e-05 lr: 7.6509e-06  eta: 1 day, 8:37:53  time: 0.4980  data_time: 0.0115  memory: 5928  grad_norm: 318.4014  loss: 7.7969  decode.loss_cls: 0.3167  decode.loss_mask: 0.1883  decode.loss_dice: 0.2845  decode.d0.loss_cls: 0.9468  decode.d0.loss_mask: 0.1991  decode.d0.loss_dice: 0.2566  decode.d1.loss_cls: 0.2750  decode.d1.loss_mask: 0.1929  decode.d1.loss_dice: 0.2565  decode.d2.loss_cls: 0.2529  decode.d2.loss_mask: 0.1989  decode.d2.loss_dice: 0.2854  decode.d3.loss_cls: 0.2620  decode.d3.loss_mask: 0.1878  decode.d3.loss_dice: 0.2578  decode.d4.loss_cls: 0.2507  decode.d4.loss_mask: 0.1875  decode.d4.loss_dice: 0.2435  decode.d5.loss_cls: 0.2342  decode.d5.loss_mask: 0.1871  decode.d5.loss_dice: 0.2298  decode.d6.loss_cls: 0.2484  decode.d6.loss_mask: 0.1889  decode.d6.loss_dice: 0.2621  decode.d7.loss_cls: 0.2866  decode.d7.loss_mask: 0.1883  decode.d7.loss_dice: 0.2412  decode.d8.loss_cls: 0.2585  decode.d8.loss_mask: 0.1905  decode.d8.loss_dice: 0.2381
08/06 13:43:33 - mmengine - INFO - Iter(train) [ 82400/320000]  base_lr: 7.6494e-05 lr: 7.6494e-06  eta: 1 day, 8:37:29  time: 0.4993  data_time: 0.0119  memory: 5909  grad_norm: 57.2358  loss: 5.9668  decode.loss_cls: 0.0698  decode.loss_mask: 0.2265  decode.loss_dice: 0.2443  decode.d0.loss_cls: 0.8450  decode.d0.loss_mask: 0.2323  decode.d0.loss_dice: 0.2398  decode.d1.loss_cls: 0.0290  decode.d1.loss_mask: 0.2304  decode.d1.loss_dice: 0.2327  decode.d2.loss_cls: 0.0706  decode.d2.loss_mask: 0.2284  decode.d2.loss_dice: 0.2303  decode.d3.loss_cls: 0.0369  decode.d3.loss_mask: 0.2303  decode.d3.loss_dice: 0.2501  decode.d4.loss_cls: 0.0316  decode.d4.loss_mask: 0.2293  decode.d4.loss_dice: 0.2225  decode.d5.loss_cls: 0.0540  decode.d5.loss_mask: 0.2279  decode.d5.loss_dice: 0.2484  decode.d6.loss_cls: 0.0744  decode.d6.loss_mask: 0.2287  decode.d6.loss_dice: 0.2237  decode.d7.loss_cls: 0.0510  decode.d7.loss_mask: 0.2263  decode.d7.loss_dice: 0.2257  decode.d8.loss_cls: 0.0675  decode.d8.loss_mask: 0.2279  decode.d8.loss_dice: 0.2315
08/06 13:43:58 - mmengine - INFO - Iter(train) [ 82450/320000]  base_lr: 7.6480e-05 lr: 7.6480e-06  eta: 1 day, 8:37:05  time: 0.4995  data_time: 0.0116  memory: 5891  grad_norm: 65.0063  loss: 6.0379  decode.loss_cls: 0.1997  decode.loss_mask: 0.1765  decode.loss_dice: 0.2159  decode.d0.loss_cls: 0.8175  decode.d0.loss_mask: 0.1781  decode.d0.loss_dice: 0.2057  decode.d1.loss_cls: 0.1304  decode.d1.loss_mask: 0.1777  decode.d1.loss_dice: 0.2232  decode.d2.loss_cls: 0.0756  decode.d2.loss_mask: 0.1742  decode.d2.loss_dice: 0.2228  decode.d3.loss_cls: 0.1405  decode.d3.loss_mask: 0.1719  decode.d3.loss_dice: 0.2267  decode.d4.loss_cls: 0.1167  decode.d4.loss_mask: 0.1763  decode.d4.loss_dice: 0.2206  decode.d5.loss_cls: 0.1486  decode.d5.loss_mask: 0.1734  decode.d5.loss_dice: 0.2198  decode.d6.loss_cls: 0.1562  decode.d6.loss_mask: 0.1737  decode.d6.loss_dice: 0.2170  decode.d7.loss_cls: 0.1363  decode.d7.loss_mask: 0.1760  decode.d7.loss_dice: 0.2177  decode.d8.loss_cls: 0.1730  decode.d8.loss_mask: 0.1751  decode.d8.loss_dice: 0.2210
08/06 13:44:23 - mmengine - INFO - Iter(train) [ 82500/320000]  base_lr: 7.6465e-05 lr: 7.6465e-06  eta: 1 day, 8:36:41  time: 0.4994  data_time: 0.0116  memory: 5928  grad_norm: 87.3745  loss: 5.9245  decode.loss_cls: 0.0541  decode.loss_mask: 0.2191  decode.loss_dice: 0.2474  decode.d0.loss_cls: 0.8334  decode.d0.loss_mask: 0.2091  decode.d0.loss_dice: 0.2300  decode.d1.loss_cls: 0.0487  decode.d1.loss_mask: 0.2165  decode.d1.loss_dice: 0.2344  decode.d2.loss_cls: 0.0596  decode.d2.loss_mask: 0.2217  decode.d2.loss_dice: 0.2479  decode.d3.loss_cls: 0.0760  decode.d3.loss_mask: 0.2199  decode.d3.loss_dice: 0.2325  decode.d4.loss_cls: 0.0629  decode.d4.loss_mask: 0.2208  decode.d4.loss_dice: 0.2290  decode.d5.loss_cls: 0.0611  decode.d5.loss_mask: 0.2201  decode.d5.loss_dice: 0.2278  decode.d6.loss_cls: 0.0843  decode.d6.loss_mask: 0.2118  decode.d6.loss_dice: 0.2306  decode.d7.loss_cls: 0.0357  decode.d7.loss_mask: 0.2204  decode.d7.loss_dice: 0.2503  decode.d8.loss_cls: 0.0524  decode.d8.loss_mask: 0.2201  decode.d8.loss_dice: 0.2467
08/06 13:44:48 - mmengine - INFO - Iter(train) [ 82550/320000]  base_lr: 7.6451e-05 lr: 7.6451e-06  eta: 1 day, 8:36:17  time: 0.4986  data_time: 0.0114  memory: 5894  grad_norm: 80.6216  loss: 5.9437  decode.loss_cls: 0.0357  decode.loss_mask: 0.1940  decode.loss_dice: 0.2571  decode.d0.loss_cls: 0.8853  decode.d0.loss_mask: 0.1957  decode.d0.loss_dice: 0.2527  decode.d1.loss_cls: 0.0599  decode.d1.loss_mask: 0.1938  decode.d1.loss_dice: 0.2612  decode.d2.loss_cls: 0.0616  decode.d2.loss_mask: 0.1933  decode.d2.loss_dice: 0.2575  decode.d3.loss_cls: 0.0716  decode.d3.loss_mask: 0.1944  decode.d3.loss_dice: 0.2664  decode.d4.loss_cls: 0.0383  decode.d4.loss_mask: 0.1932  decode.d4.loss_dice: 0.2740  decode.d5.loss_cls: 0.0684  decode.d5.loss_mask: 0.1896  decode.d5.loss_dice: 0.2567  decode.d6.loss_cls: 0.0882  decode.d6.loss_mask: 0.1930  decode.d6.loss_dice: 0.2577  decode.d7.loss_cls: 0.0439  decode.d7.loss_mask: 0.1937  decode.d7.loss_dice: 0.2521  decode.d8.loss_cls: 0.0850  decode.d8.loss_mask: 0.1930  decode.d8.loss_dice: 0.2367
08/06 13:45:13 - mmengine - INFO - Iter(train) [ 82600/320000]  base_lr: 7.6436e-05 lr: 7.6436e-06  eta: 1 day, 8:35:52  time: 0.4980  data_time: 0.0116  memory: 5878  grad_norm: 212.7627  loss: 7.1803  decode.loss_cls: 0.0550  decode.loss_mask: 0.2893  decode.loss_dice: 0.2794  decode.d0.loss_cls: 0.8115  decode.d0.loss_mask: 0.2953  decode.d0.loss_dice: 0.2891  decode.d1.loss_cls: 0.0872  decode.d1.loss_mask: 0.2893  decode.d1.loss_dice: 0.2888  decode.d2.loss_cls: 0.0761  decode.d2.loss_mask: 0.2880  decode.d2.loss_dice: 0.2839  decode.d3.loss_cls: 0.0706  decode.d3.loss_mask: 0.2856  decode.d3.loss_dice: 0.2816  decode.d4.loss_cls: 0.0740  decode.d4.loss_mask: 0.2892  decode.d4.loss_dice: 0.2869  decode.d5.loss_cls: 0.0871  decode.d5.loss_mask: 0.2883  decode.d5.loss_dice: 0.2868  decode.d6.loss_cls: 0.0656  decode.d6.loss_mask: 0.2908  decode.d6.loss_dice: 0.2811  decode.d7.loss_cls: 0.0501  decode.d7.loss_mask: 0.2870  decode.d7.loss_dice: 0.2834  decode.d8.loss_cls: 0.0668  decode.d8.loss_mask: 0.2900  decode.d8.loss_dice: 0.2823
08/06 13:45:38 - mmengine - INFO - Iter(train) [ 82650/320000]  base_lr: 7.6422e-05 lr: 7.6422e-06  eta: 1 day, 8:35:28  time: 0.4975  data_time: 0.0116  memory: 5891  grad_norm: 149.3189  loss: 6.4408  decode.loss_cls: 0.0636  decode.loss_mask: 0.2572  decode.loss_dice: 0.2398  decode.d0.loss_cls: 0.8842  decode.d0.loss_mask: 0.2643  decode.d0.loss_dice: 0.2459  decode.d1.loss_cls: 0.0773  decode.d1.loss_mask: 0.2612  decode.d1.loss_dice: 0.2442  decode.d2.loss_cls: 0.0981  decode.d2.loss_mask: 0.2564  decode.d2.loss_dice: 0.2502  decode.d3.loss_cls: 0.0520  decode.d3.loss_mask: 0.2577  decode.d3.loss_dice: 0.2477  decode.d4.loss_cls: 0.0476  decode.d4.loss_mask: 0.2550  decode.d4.loss_dice: 0.2383  decode.d5.loss_cls: 0.0433  decode.d5.loss_mask: 0.2671  decode.d5.loss_dice: 0.2481  decode.d6.loss_cls: 0.0411  decode.d6.loss_mask: 0.2637  decode.d6.loss_dice: 0.2409  decode.d7.loss_cls: 0.0505  decode.d7.loss_mask: 0.2572  decode.d7.loss_dice: 0.2393  decode.d8.loss_cls: 0.0554  decode.d8.loss_mask: 0.2557  decode.d8.loss_dice: 0.2374
08/06 13:46:03 - mmengine - INFO - Iter(train) [ 82700/320000]  base_lr: 7.6407e-05 lr: 7.6407e-06  eta: 1 day, 8:35:04  time: 0.4983  data_time: 0.0115  memory: 5894  grad_norm: 349.4244  loss: 7.3294  decode.loss_cls: 0.0960  decode.loss_mask: 0.2503  decode.loss_dice: 0.2656  decode.d0.loss_cls: 0.9286  decode.d0.loss_mask: 0.2445  decode.d0.loss_dice: 0.2593  decode.d1.loss_cls: 0.1242  decode.d1.loss_mask: 0.2432  decode.d1.loss_dice: 0.2652  decode.d2.loss_cls: 0.1069  decode.d2.loss_mask: 0.2537  decode.d2.loss_dice: 0.2643  decode.d3.loss_cls: 0.1205  decode.d3.loss_mask: 0.2444  decode.d3.loss_dice: 0.2906  decode.d4.loss_cls: 0.1280  decode.d4.loss_mask: 0.2957  decode.d4.loss_dice: 0.2681  decode.d5.loss_cls: 0.1254  decode.d5.loss_mask: 0.2793  decode.d5.loss_dice: 0.2745  decode.d6.loss_cls: 0.1478  decode.d6.loss_mask: 0.2571  decode.d6.loss_dice: 0.2564  decode.d7.loss_cls: 0.1240  decode.d7.loss_mask: 0.2578  decode.d7.loss_dice: 0.2639  decode.d8.loss_cls: 0.1850  decode.d8.loss_mask: 0.2456  decode.d8.loss_dice: 0.2634
08/06 13:46:28 - mmengine - INFO - Iter(train) [ 82750/320000]  base_lr: 7.6393e-05 lr: 7.6393e-06  eta: 1 day, 8:34:40  time: 0.5005  data_time: 0.0114  memory: 5913  grad_norm: 23.4958  loss: 4.8042  decode.loss_cls: 0.0040  decode.loss_mask: 0.1765  decode.loss_dice: 0.2173  decode.d0.loss_cls: 0.8193  decode.d0.loss_mask: 0.1797  decode.d0.loss_dice: 0.2164  decode.d1.loss_cls: 0.0082  decode.d1.loss_mask: 0.1763  decode.d1.loss_dice: 0.2131  decode.d2.loss_cls: 0.0074  decode.d2.loss_mask: 0.1769  decode.d2.loss_dice: 0.2168  decode.d3.loss_cls: 0.0059  decode.d3.loss_mask: 0.1796  decode.d3.loss_dice: 0.2155  decode.d4.loss_cls: 0.0041  decode.d4.loss_mask: 0.1750  decode.d4.loss_dice: 0.2186  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.1763  decode.d5.loss_dice: 0.2161  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.1761  decode.d6.loss_dice: 0.2180  decode.d7.loss_cls: 0.0043  decode.d7.loss_mask: 0.1756  decode.d7.loss_dice: 0.2158  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.1776  decode.d8.loss_dice: 0.2207
08/06 13:46:53 - mmengine - INFO - Iter(train) [ 82800/320000]  base_lr: 7.6378e-05 lr: 7.6378e-06  eta: 1 day, 8:34:16  time: 0.4974  data_time: 0.0116  memory: 5909  grad_norm: 85.9476  loss: 6.7713  decode.loss_cls: 0.0697  decode.loss_mask: 0.2945  decode.loss_dice: 0.2402  decode.d0.loss_cls: 0.7346  decode.d0.loss_mask: 0.3280  decode.d0.loss_dice: 0.2452  decode.d1.loss_cls: 0.0704  decode.d1.loss_mask: 0.2970  decode.d1.loss_dice: 0.2437  decode.d2.loss_cls: 0.0692  decode.d2.loss_mask: 0.2968  decode.d2.loss_dice: 0.2406  decode.d3.loss_cls: 0.0694  decode.d3.loss_mask: 0.3006  decode.d3.loss_dice: 0.2438  decode.d4.loss_cls: 0.0690  decode.d4.loss_mask: 0.2938  decode.d4.loss_dice: 0.2383  decode.d5.loss_cls: 0.0778  decode.d5.loss_mask: 0.2969  decode.d5.loss_dice: 0.2431  decode.d6.loss_cls: 0.0649  decode.d6.loss_mask: 0.2954  decode.d6.loss_dice: 0.2406  decode.d7.loss_cls: 0.0604  decode.d7.loss_mask: 0.2969  decode.d7.loss_dice: 0.2416  decode.d8.loss_cls: 0.0676  decode.d8.loss_mask: 0.2987  decode.d8.loss_dice: 0.2424
08/06 13:47:18 - mmengine - INFO - Iter(train) [ 82850/320000]  base_lr: 7.6364e-05 lr: 7.6364e-06  eta: 1 day, 8:33:52  time: 0.4991  data_time: 0.0117  memory: 5894  grad_norm: 48.7835  loss: 6.2873  decode.loss_cls: 0.0596  decode.loss_mask: 0.2219  decode.loss_dice: 0.2447  decode.d0.loss_cls: 0.9010  decode.d0.loss_mask: 0.2173  decode.d0.loss_dice: 0.2726  decode.d1.loss_cls: 0.0879  decode.d1.loss_mask: 0.2200  decode.d1.loss_dice: 0.2422  decode.d2.loss_cls: 0.0834  decode.d2.loss_mask: 0.2201  decode.d2.loss_dice: 0.2628  decode.d3.loss_cls: 0.0741  decode.d3.loss_mask: 0.2185  decode.d3.loss_dice: 0.2577  decode.d4.loss_cls: 0.0298  decode.d4.loss_mask: 0.2209  decode.d4.loss_dice: 0.2775  decode.d5.loss_cls: 0.0665  decode.d5.loss_mask: 0.2206  decode.d5.loss_dice: 0.2656  decode.d6.loss_cls: 0.0780  decode.d6.loss_mask: 0.2219  decode.d6.loss_dice: 0.2441  decode.d7.loss_cls: 0.0720  decode.d7.loss_mask: 0.2195  decode.d7.loss_dice: 0.2487  decode.d8.loss_cls: 0.0714  decode.d8.loss_mask: 0.2218  decode.d8.loss_dice: 0.2452
08/06 13:47:43 - mmengine - INFO - Iter(train) [ 82900/320000]  base_lr: 7.6349e-05 lr: 7.6349e-06  eta: 1 day, 8:33:28  time: 0.4981  data_time: 0.0115  memory: 5913  grad_norm: 58.2320  loss: 6.6393  decode.loss_cls: 0.1156  decode.loss_mask: 0.2020  decode.loss_dice: 0.2582  decode.d0.loss_cls: 0.8503  decode.d0.loss_mask: 0.2042  decode.d0.loss_dice: 0.2661  decode.d1.loss_cls: 0.1919  decode.d1.loss_mask: 0.1998  decode.d1.loss_dice: 0.2628  decode.d2.loss_cls: 0.1105  decode.d2.loss_mask: 0.2037  decode.d2.loss_dice: 0.2539  decode.d3.loss_cls: 0.1182  decode.d3.loss_mask: 0.2031  decode.d3.loss_dice: 0.2589  decode.d4.loss_cls: 0.1321  decode.d4.loss_mask: 0.2021  decode.d4.loss_dice: 0.2591  decode.d5.loss_cls: 0.1444  decode.d5.loss_mask: 0.2016  decode.d5.loss_dice: 0.2573  decode.d6.loss_cls: 0.0826  decode.d6.loss_mask: 0.2050  decode.d6.loss_dice: 0.2769  decode.d7.loss_cls: 0.1308  decode.d7.loss_mask: 0.2036  decode.d7.loss_dice: 0.2642  decode.d8.loss_cls: 0.1065  decode.d8.loss_mask: 0.2062  decode.d8.loss_dice: 0.2675
08/06 13:48:08 - mmengine - INFO - Iter(train) [ 82950/320000]  base_lr: 7.6335e-05 lr: 7.6335e-06  eta: 1 day, 8:33:04  time: 0.4983  data_time: 0.0114  memory: 5911  grad_norm: 53.1852  loss: 5.5206  decode.loss_cls: 0.0695  decode.loss_mask: 0.1719  decode.loss_dice: 0.2546  decode.d0.loss_cls: 0.7105  decode.d0.loss_mask: 0.1755  decode.d0.loss_dice: 0.2588  decode.d1.loss_cls: 0.0546  decode.d1.loss_mask: 0.1731  decode.d1.loss_dice: 0.2386  decode.d2.loss_cls: 0.0581  decode.d2.loss_mask: 0.1698  decode.d2.loss_dice: 0.2411  decode.d3.loss_cls: 0.1063  decode.d3.loss_mask: 0.1723  decode.d3.loss_dice: 0.2371  decode.d4.loss_cls: 0.0594  decode.d4.loss_mask: 0.1704  decode.d4.loss_dice: 0.2445  decode.d5.loss_cls: 0.1133  decode.d5.loss_mask: 0.1699  decode.d5.loss_dice: 0.2392  decode.d6.loss_cls: 0.0594  decode.d6.loss_mask: 0.1689  decode.d6.loss_dice: 0.2485  decode.d7.loss_cls: 0.0440  decode.d7.loss_mask: 0.1724  decode.d7.loss_dice: 0.2479  decode.d8.loss_cls: 0.0596  decode.d8.loss_mask: 0.1710  decode.d8.loss_dice: 0.2602
08/06 13:48:33 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 13:48:33 - mmengine - INFO - Iter(train) [ 83000/320000]  base_lr: 7.6320e-05 lr: 7.6320e-06  eta: 1 day, 8:32:40  time: 0.4995  data_time: 0.0115  memory: 5928  grad_norm: 53.3953  loss: 6.0215  decode.loss_cls: 0.0349  decode.loss_mask: 0.1974  decode.loss_dice: 0.2609  decode.d0.loss_cls: 0.7730  decode.d0.loss_mask: 0.1998  decode.d0.loss_dice: 0.2708  decode.d1.loss_cls: 0.1050  decode.d1.loss_mask: 0.1978  decode.d1.loss_dice: 0.2595  decode.d2.loss_cls: 0.0700  decode.d2.loss_mask: 0.1950  decode.d2.loss_dice: 0.2540  decode.d3.loss_cls: 0.0805  decode.d3.loss_mask: 0.1960  decode.d3.loss_dice: 0.2548  decode.d4.loss_cls: 0.0609  decode.d4.loss_mask: 0.1966  decode.d4.loss_dice: 0.2582  decode.d5.loss_cls: 0.1045  decode.d5.loss_mask: 0.1987  decode.d5.loss_dice: 0.2596  decode.d6.loss_cls: 0.0842  decode.d6.loss_mask: 0.1963  decode.d6.loss_dice: 0.2515  decode.d7.loss_cls: 0.0811  decode.d7.loss_mask: 0.1967  decode.d7.loss_dice: 0.2629  decode.d8.loss_cls: 0.0719  decode.d8.loss_mask: 0.1965  decode.d8.loss_dice: 0.2523
08/06 13:48:58 - mmengine - INFO - Iter(train) [ 83050/320000]  base_lr: 7.6306e-05 lr: 7.6306e-06  eta: 1 day, 8:32:16  time: 0.4979  data_time: 0.0116  memory: 5874  grad_norm: 191.5485  loss: 6.6823  decode.loss_cls: 0.0828  decode.loss_mask: 0.1998  decode.loss_dice: 0.2942  decode.d0.loss_cls: 0.7387  decode.d0.loss_mask: 0.2070  decode.d0.loss_dice: 0.3052  decode.d1.loss_cls: 0.0925  decode.d1.loss_mask: 0.1952  decode.d1.loss_dice: 0.3084  decode.d2.loss_cls: 0.0885  decode.d2.loss_mask: 0.1969  decode.d2.loss_dice: 0.3057  decode.d3.loss_cls: 0.0997  decode.d3.loss_mask: 0.1958  decode.d3.loss_dice: 0.3050  decode.d4.loss_cls: 0.2077  decode.d4.loss_mask: 0.1792  decode.d4.loss_dice: 0.3194  decode.d5.loss_cls: 0.0804  decode.d5.loss_mask: 0.1944  decode.d5.loss_dice: 0.3104  decode.d6.loss_cls: 0.0606  decode.d6.loss_mask: 0.1986  decode.d6.loss_dice: 0.3004  decode.d7.loss_cls: 0.0880  decode.d7.loss_mask: 0.2014  decode.d7.loss_dice: 0.3170  decode.d8.loss_cls: 0.1700  decode.d8.loss_mask: 0.1784  decode.d8.loss_dice: 0.2612
08/06 13:49:23 - mmengine - INFO - Iter(train) [ 83100/320000]  base_lr: 7.6291e-05 lr: 7.6291e-06  eta: 1 day, 8:31:52  time: 0.4985  data_time: 0.0118  memory: 5895  grad_norm: 92.8751  loss: 8.3532  decode.loss_cls: 0.1287  decode.loss_mask: 0.3104  decode.loss_dice: 0.2985  decode.d0.loss_cls: 0.9764  decode.d0.loss_mask: 0.3135  decode.d0.loss_dice: 0.3149  decode.d1.loss_cls: 0.1893  decode.d1.loss_mask: 0.3098  decode.d1.loss_dice: 0.3179  decode.d2.loss_cls: 0.1438  decode.d2.loss_mask: 0.3150  decode.d2.loss_dice: 0.3305  decode.d3.loss_cls: 0.1436  decode.d3.loss_mask: 0.3147  decode.d3.loss_dice: 0.3260  decode.d4.loss_cls: 0.1327  decode.d4.loss_mask: 0.3103  decode.d4.loss_dice: 0.3044  decode.d5.loss_cls: 0.0784  decode.d5.loss_mask: 0.3130  decode.d5.loss_dice: 0.2979  decode.d6.loss_cls: 0.0909  decode.d6.loss_mask: 0.3099  decode.d6.loss_dice: 0.3156  decode.d7.loss_cls: 0.1359  decode.d7.loss_mask: 0.3097  decode.d7.loss_dice: 0.3065  decode.d8.loss_cls: 0.0757  decode.d8.loss_mask: 0.3153  decode.d8.loss_dice: 0.3238
