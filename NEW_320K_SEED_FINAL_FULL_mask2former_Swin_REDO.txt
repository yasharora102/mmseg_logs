==========================================
SLURM_JOB_ID = 2470937
SLURM_NODELIST = gnode070
SLURM_JOB_GPUS = 0
==========================================
08/06 02:16:35 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.23 (main, Jun  5 2025, 13:40:20) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 268722126
    GPU 0: NVIDIA GeForce RTX 2080 Ti
    CUDA_HOME: /opt/cuda-12.1/
    NVCC: Cuda compilation tools, release 12.1, V12.1.66
    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
    PyTorch: 2.1.2
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 268722126
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

08/06 02:16:36 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=2, enable=False)
backbone_embed_multi = dict(decay_mult=0.0, lr_mult=0.1)
backbone_norm_multi = dict(decay_mult=0.0, lr_mult=0.1)
crop_size = (
    512,
    1024,
)
custom_keys = dict({
    'absolute_pos_embed':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone':
    dict(decay_mult=1.0, lr_mult=0.1),
    'backbone.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.patch_embed.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.2.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.3.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.4.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.5.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'level_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_feat':
    dict(decay_mult=0.0, lr_mult=1.0),
    'relative_position_bias_table':
    dict(decay_mult=0.0, lr_mult=0.1)
})
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        512,
        1024,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    test_cfg=dict(size_divisor=32),
    type='SegDataPreProcessor')
data_root = '/scratch/seg_benchmark/splits_flat/'
dataset_type = 'YourDataset_BIG'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False,
        interval=40000,
        save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'))
default_scope = 'mmseg'
depths = [
    2,
    2,
    6,
    2,
]
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
img_suffix = '.jpg'
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        attn_drop_rate=0.0,
        depths=[
            2,
            2,
            6,
            2,
        ],
        drop_path_rate=0.3,
        drop_rate=0.0,
        embed_dims=96,
        frozen_stages=-1,
        init_cfg=dict(
            checkpoint=
            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth',
            type='Pretrained'),
        mlp_ratio=4,
        num_heads=[
            3,
            6,
            12,
            24,
        ],
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        patch_norm=True,
        qk_scale=None,
        qkv_bias=True,
        type='SwinTransformer',
        window_size=7,
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            1024,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        test_cfg=dict(size_divisor=32),
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            96,
            192,
            384,
            768,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=51,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 51
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict({
            'absolute_pos_embed':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone':
            dict(decay_mult=1.0, lr_mult=0.1),
            'backbone.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.patch_embed.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.2.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.3.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.4.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.5.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'level_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_feat':
            dict(decay_mult=0.0, lr_mult=1.0),
            'relative_position_bias_table':
            dict(decay_mult=0.0, lr_mult=0.1)
        }),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=320000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth'
randomness = dict(seed=268722126)
resume = False
seg_map_suffix = '.png'
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/seg_benchmark/splits_flat/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    classwise=True, iou_metrics=[
        'mIoU',
    ], type='IoUNanAbsent')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2048,
        1024,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(
    max_iters=320000, type='IterBasedTrainLoop', val_interval=40000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        data_prefix=dict(img_path='train/images', seg_map_path='train/masks'),
        data_root='/scratch/seg_benchmark/splits_flat/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                max_size=4096,
                resize_type='ResizeShortestEdge',
                scales=[
                    512,
                    614,
                    716,
                    819,
                    921,
                    1024,
                    1126,
                    1228,
                    1331,
                    1433,
                    1536,
                    1638,
                    1740,
                    1843,
                    1945,
                    2048,
                ],
                type='RandomChoiceResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    512,
                    1024,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        max_size=4096,
        resize_type='ResizeShortestEdge',
        scales=[
            512,
            614,
            716,
            819,
            921,
            1024,
            1126,
            1228,
            1331,
            1433,
            1536,
            1638,
            1740,
            1843,
            1945,
            2048,
        ],
        type='RandomChoiceResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        1024,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/seg_benchmark/splits_flat/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '/scratch/seg_benchmark/NEW/mask2former_swin_T_seed_320K'

08/06 02:16:41 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
08/06 02:16:41 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:weight_decay=0.05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:decay_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr=1e-05
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr_mult=0.1
08/06 02:16:42 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
08/06 02:16:42 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
08/06 02:16:42 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth
08/06 02:16:47 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
08/06 02:16:47 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
08/06 02:16:47 - mmengine - INFO - Checkpoints will be saved to /scratch/seg_benchmark/NEW/mask2former_swin_T_seed_320K.
/home2/yasharora120/miniconda3/envs/mmseg/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400441250/work/aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
08/06 02:17:16 - mmengine - INFO - Iter(train) [    50/320000]  base_lr: 9.9986e-05 lr: 9.9986e-06  eta: 2 days, 2:50:59  time: 0.4845  data_time: 0.0105  memory: 8941  grad_norm: 242.2523  loss: 103.6889  decode.loss_cls: 4.0523  decode.loss_mask: 2.2177  decode.loss_dice: 4.1183  decode.d0.loss_cls: 7.9803  decode.d0.loss_mask: 2.0244  decode.d0.loss_dice: 3.7734  decode.d1.loss_cls: 3.6009  decode.d1.loss_mask: 2.1517  decode.d1.loss_dice: 3.8214  decode.d2.loss_cls: 3.4406  decode.d2.loss_mask: 2.0439  decode.d2.loss_dice: 3.8323  decode.d3.loss_cls: 3.4915  decode.d3.loss_mask: 2.1331  decode.d3.loss_dice: 3.8770  decode.d4.loss_cls: 3.6622  decode.d4.loss_mask: 2.3944  decode.d4.loss_dice: 3.8287  decode.d5.loss_cls: 3.8721  decode.d5.loss_mask: 2.2988  decode.d5.loss_dice: 3.9699  decode.d6.loss_cls: 3.9998  decode.d6.loss_mask: 2.2680  decode.d6.loss_dice: 4.0648  decode.d7.loss_cls: 4.0605  decode.d7.loss_mask: 2.2993  decode.d7.loss_dice: 4.1341  decode.d8.loss_cls: 4.0652  decode.d8.loss_mask: 2.2002  decode.d8.loss_dice: 4.0121
08/06 02:17:40 - mmengine - INFO - Iter(train) [   100/320000]  base_lr: 9.9972e-05 lr: 9.9972e-06  eta: 1 day, 22:55:14  time: 0.4846  data_time: 0.0105  memory: 5907  grad_norm: 263.2748  loss: 80.5524  decode.loss_cls: 3.3351  decode.loss_mask: 1.7080  decode.loss_dice: 3.3763  decode.d0.loss_cls: 8.0424  decode.d0.loss_mask: 1.4938  decode.d0.loss_dice: 3.0813  decode.d1.loss_cls: 2.9343  decode.d1.loss_mask: 1.5267  decode.d1.loss_dice: 2.9937  decode.d2.loss_cls: 2.6794  decode.d2.loss_mask: 1.5114  decode.d2.loss_dice: 2.9729  decode.d3.loss_cls: 2.7374  decode.d3.loss_mask: 1.5240  decode.d3.loss_dice: 2.9265  decode.d4.loss_cls: 2.7828  decode.d4.loss_mask: 1.5240  decode.d4.loss_dice: 2.9519  decode.d5.loss_cls: 2.7709  decode.d5.loss_mask: 1.5606  decode.d5.loss_dice: 3.0155  decode.d6.loss_cls: 2.8797  decode.d6.loss_mask: 1.5752  decode.d6.loss_dice: 3.0294  decode.d7.loss_cls: 2.9352  decode.d7.loss_mask: 1.5929  decode.d7.loss_dice: 3.1101  decode.d8.loss_cls: 3.1789  decode.d8.loss_mask: 1.5930  decode.d8.loss_dice: 3.2091
08/06 02:18:04 - mmengine - INFO - Iter(train) [   150/320000]  base_lr: 9.9958e-05 lr: 9.9958e-06  eta: 1 day, 21:42:52  time: 0.4859  data_time: 0.0107  memory: 5907  grad_norm: 287.5317  loss: 69.2580  decode.loss_cls: 3.5324  decode.loss_mask: 1.1880  decode.loss_dice: 2.1938  decode.d0.loss_cls: 7.9801  decode.d0.loss_mask: 1.1672  decode.d0.loss_dice: 2.3903  decode.d1.loss_cls: 2.9434  decode.d1.loss_mask: 1.1831  decode.d1.loss_dice: 2.1406  decode.d2.loss_cls: 2.9631  decode.d2.loss_mask: 1.1055  decode.d2.loss_dice: 2.0415  decode.d3.loss_cls: 3.1253  decode.d3.loss_mask: 1.1006  decode.d3.loss_dice: 2.0228  decode.d4.loss_cls: 3.1643  decode.d4.loss_mask: 1.1071  decode.d4.loss_dice: 1.9804  decode.d5.loss_cls: 3.1536  decode.d5.loss_mask: 1.1827  decode.d5.loss_dice: 2.0258  decode.d6.loss_cls: 3.1434  decode.d6.loss_mask: 1.2010  decode.d6.loss_dice: 1.9944  decode.d7.loss_cls: 3.2334  decode.d7.loss_mask: 1.2243  decode.d7.loss_dice: 2.0485  decode.d8.loss_cls: 3.2665  decode.d8.loss_mask: 1.2270  decode.d8.loss_dice: 2.2277
08/06 02:18:29 - mmengine - INFO - Iter(train) [   200/320000]  base_lr: 9.9944e-05 lr: 9.9944e-06  eta: 1 day, 21:05:07  time: 0.4875  data_time: 0.0103  memory: 5892  grad_norm: 317.0971  loss: 59.3301  decode.loss_cls: 2.9295  decode.loss_mask: 1.0901  decode.loss_dice: 1.5771  decode.d0.loss_cls: 7.8814  decode.d0.loss_mask: 1.0306  decode.d0.loss_dice: 1.9160  decode.d1.loss_cls: 2.6320  decode.d1.loss_mask: 1.0930  decode.d1.loss_dice: 1.6858  decode.d2.loss_cls: 2.6536  decode.d2.loss_mask: 1.0715  decode.d2.loss_dice: 1.5597  decode.d3.loss_cls: 2.6742  decode.d3.loss_mask: 1.0058  decode.d3.loss_dice: 1.5378  decode.d4.loss_cls: 2.7574  decode.d4.loss_mask: 1.0522  decode.d4.loss_dice: 1.5276  decode.d5.loss_cls: 2.8573  decode.d5.loss_mask: 1.0071  decode.d5.loss_dice: 1.4765  decode.d6.loss_cls: 2.8859  decode.d6.loss_mask: 0.9804  decode.d6.loss_dice: 1.4453  decode.d7.loss_cls: 2.8742  decode.d7.loss_mask: 1.1039  decode.d7.loss_dice: 1.5080  decode.d8.loss_cls: 2.9062  decode.d8.loss_mask: 1.0772  decode.d8.loss_dice: 1.5326
08/06 02:18:53 - mmengine - INFO - Iter(train) [   250/320000]  base_lr: 9.9930e-05 lr: 9.9930e-06  eta: 1 day, 20:42:55  time: 0.4876  data_time: 0.0101  memory: 5892  grad_norm: 277.7302  loss: 56.1562  decode.loss_cls: 3.0561  decode.loss_mask: 0.8821  decode.loss_dice: 1.3224  decode.d0.loss_cls: 7.7463  decode.d0.loss_mask: 0.8445  decode.d0.loss_dice: 1.8208  decode.d1.loss_cls: 2.9815  decode.d1.loss_mask: 0.7951  decode.d1.loss_dice: 1.4276  decode.d2.loss_cls: 2.9545  decode.d2.loss_mask: 0.7635  decode.d2.loss_dice: 1.2968  decode.d3.loss_cls: 2.9242  decode.d3.loss_mask: 0.7269  decode.d3.loss_dice: 1.2554  decode.d4.loss_cls: 2.9378  decode.d4.loss_mask: 0.7655  decode.d4.loss_dice: 1.2548  decode.d5.loss_cls: 2.9634  decode.d5.loss_mask: 0.7913  decode.d5.loss_dice: 1.2560  decode.d6.loss_cls: 3.0061  decode.d6.loss_mask: 0.7970  decode.d6.loss_dice: 1.2470  decode.d7.loss_cls: 3.0359  decode.d7.loss_mask: 0.8471  decode.d7.loss_dice: 1.2586  decode.d8.loss_cls: 3.0682  decode.d8.loss_mask: 0.8429  decode.d8.loss_dice: 1.2869
08/06 02:19:17 - mmengine - INFO - Iter(train) [   300/320000]  base_lr: 9.9916e-05 lr: 9.9916e-06  eta: 1 day, 20:28:22  time: 0.4881  data_time: 0.0104  memory: 5908  grad_norm: 415.7970  loss: 51.7523  decode.loss_cls: 2.6193  decode.loss_mask: 0.9733  decode.loss_dice: 1.1063  decode.d0.loss_cls: 7.5652  decode.d0.loss_mask: 0.9865  decode.d0.loss_dice: 1.5240  decode.d1.loss_cls: 2.5825  decode.d1.loss_mask: 0.9004  decode.d1.loss_dice: 1.1825  decode.d2.loss_cls: 2.5456  decode.d2.loss_mask: 0.9037  decode.d2.loss_dice: 1.0854  decode.d3.loss_cls: 2.5499  decode.d3.loss_mask: 0.9108  decode.d3.loss_dice: 1.0077  decode.d4.loss_cls: 2.5190  decode.d4.loss_mask: 0.9234  decode.d4.loss_dice: 1.0776  decode.d5.loss_cls: 2.5545  decode.d5.loss_mask: 0.9921  decode.d5.loss_dice: 1.0833  decode.d6.loss_cls: 2.5887  decode.d6.loss_mask: 1.0056  decode.d6.loss_dice: 1.1025  decode.d7.loss_cls: 2.6124  decode.d7.loss_mask: 1.0092  decode.d7.loss_dice: 1.1358  decode.d8.loss_cls: 2.6313  decode.d8.loss_mask: 0.9336  decode.d8.loss_dice: 1.1403
08/06 02:19:42 - mmengine - INFO - Iter(train) [   350/320000]  base_lr: 9.9902e-05 lr: 9.9902e-06  eta: 1 day, 20:18:01  time: 0.4874  data_time: 0.0099  memory: 5892  grad_norm: 271.0692  loss: 52.7456  decode.loss_cls: 2.8952  decode.loss_mask: 0.7999  decode.loss_dice: 1.1294  decode.d0.loss_cls: 7.3801  decode.d0.loss_mask: 0.8319  decode.d0.loss_dice: 1.6631  decode.d1.loss_cls: 2.8838  decode.d1.loss_mask: 0.8329  decode.d1.loss_dice: 1.2252  decode.d2.loss_cls: 2.7671  decode.d2.loss_mask: 0.7858  decode.d2.loss_dice: 1.1238  decode.d3.loss_cls: 2.7711  decode.d3.loss_mask: 0.7354  decode.d3.loss_dice: 1.0614  decode.d4.loss_cls: 2.8564  decode.d4.loss_mask: 0.7468  decode.d4.loss_dice: 1.0768  decode.d5.loss_cls: 2.9050  decode.d5.loss_mask: 0.7446  decode.d5.loss_dice: 1.0583  decode.d6.loss_cls: 2.9378  decode.d6.loss_mask: 0.7354  decode.d6.loss_dice: 1.0622  decode.d7.loss_cls: 2.9581  decode.d7.loss_mask: 0.7761  decode.d7.loss_dice: 1.0783  decode.d8.loss_cls: 2.9781  decode.d8.loss_mask: 0.8120  decode.d8.loss_dice: 1.1335
08/06 02:20:06 - mmengine - INFO - Iter(train) [   400/320000]  base_lr: 9.9888e-05 lr: 9.9888e-06  eta: 1 day, 20:10:52  time: 0.4893  data_time: 0.0103  memory: 5908  grad_norm: 391.0088  loss: 50.4978  decode.loss_cls: 2.7614  decode.loss_mask: 0.7868  decode.loss_dice: 1.1969  decode.d0.loss_cls: 7.2830  decode.d0.loss_mask: 0.8352  decode.d0.loss_dice: 1.4141  decode.d1.loss_cls: 2.7607  decode.d1.loss_mask: 0.7893  decode.d1.loss_dice: 1.1637  decode.d2.loss_cls: 2.6860  decode.d2.loss_mask: 0.7784  decode.d2.loss_dice: 1.0722  decode.d3.loss_cls: 2.6559  decode.d3.loss_mask: 0.7167  decode.d3.loss_dice: 0.9990  decode.d4.loss_cls: 2.6279  decode.d4.loss_mask: 0.7600  decode.d4.loss_dice: 1.0233  decode.d5.loss_cls: 2.6044  decode.d5.loss_mask: 0.8010  decode.d5.loss_dice: 1.0620  decode.d6.loss_cls: 2.6790  decode.d6.loss_mask: 0.7947  decode.d6.loss_dice: 1.0435  decode.d7.loss_cls: 2.6687  decode.d7.loss_mask: 0.8052  decode.d7.loss_dice: 1.0470  decode.d8.loss_cls: 2.7936  decode.d8.loss_mask: 0.8033  decode.d8.loss_dice: 1.0847
08/06 02:20:31 - mmengine - INFO - Iter(train) [   450/320000]  base_lr: 9.9874e-05 lr: 9.9874e-06  eta: 1 day, 20:06:53  time: 0.4873  data_time: 0.0105  memory: 5889  grad_norm: 413.5357  loss: 48.3874  decode.loss_cls: 2.6960  decode.loss_mask: 0.7250  decode.loss_dice: 0.9490  decode.d0.loss_cls: 7.1043  decode.d0.loss_mask: 0.7834  decode.d0.loss_dice: 1.3479  decode.d1.loss_cls: 2.7237  decode.d1.loss_mask: 0.8164  decode.d1.loss_dice: 1.0995  decode.d2.loss_cls: 2.5207  decode.d2.loss_mask: 0.7365  decode.d2.loss_dice: 0.9497  decode.d3.loss_cls: 2.5241  decode.d3.loss_mask: 0.6753  decode.d3.loss_dice: 0.9287  decode.d4.loss_cls: 2.5510  decode.d4.loss_mask: 0.7156  decode.d4.loss_dice: 0.9082  decode.d5.loss_cls: 2.5958  decode.d5.loss_mask: 0.7271  decode.d5.loss_dice: 0.9559  decode.d6.loss_cls: 2.6890  decode.d6.loss_mask: 0.7567  decode.d6.loss_dice: 0.9834  decode.d7.loss_cls: 2.7273  decode.d7.loss_mask: 0.7435  decode.d7.loss_dice: 0.9765  decode.d8.loss_cls: 2.7136  decode.d8.loss_mask: 0.7719  decode.d8.loss_dice: 0.9916
08/06 02:20:55 - mmengine - INFO - Iter(train) [   500/320000]  base_lr: 9.9860e-05 lr: 9.9860e-06  eta: 1 day, 20:01:33  time: 0.4871  data_time: 0.0106  memory: 5892  grad_norm: 405.6812  loss: 43.2560  decode.loss_cls: 2.3091  decode.loss_mask: 0.7682  decode.loss_dice: 0.9339  decode.d0.loss_cls: 6.8611  decode.d0.loss_mask: 0.7456  decode.d0.loss_dice: 1.1298  decode.d1.loss_cls: 2.4066  decode.d1.loss_mask: 0.7118  decode.d1.loss_dice: 0.8424  decode.d2.loss_cls: 2.2475  decode.d2.loss_mask: 0.6453  decode.d2.loss_dice: 0.7410  decode.d3.loss_cls: 2.2708  decode.d3.loss_mask: 0.6737  decode.d3.loss_dice: 0.7866  decode.d4.loss_cls: 2.2946  decode.d4.loss_mask: 0.7223  decode.d4.loss_dice: 0.7949  decode.d5.loss_cls: 2.3750  decode.d5.loss_mask: 0.6635  decode.d5.loss_dice: 0.7985  decode.d6.loss_cls: 2.3616  decode.d6.loss_mask: 0.6676  decode.d6.loss_dice: 0.7947  decode.d7.loss_cls: 2.3253  decode.d7.loss_mask: 0.7134  decode.d7.loss_dice: 0.8332  decode.d8.loss_cls: 2.3707  decode.d8.loss_mask: 0.6568  decode.d8.loss_dice: 0.8103
08/06 02:21:19 - mmengine - INFO - Iter(train) [   550/320000]  base_lr: 9.9846e-05 lr: 9.9846e-06  eta: 1 day, 19:57:14  time: 0.4876  data_time: 0.0102  memory: 5893  grad_norm: 366.8522  loss: 45.3491  decode.loss_cls: 2.7144  decode.loss_mask: 0.6506  decode.loss_dice: 0.7993  decode.d0.loss_cls: 6.7306  decode.d0.loss_mask: 0.6702  decode.d0.loss_dice: 1.0464  decode.d1.loss_cls: 2.7296  decode.d1.loss_mask: 0.7006  decode.d1.loss_dice: 0.7667  decode.d2.loss_cls: 2.6619  decode.d2.loss_mask: 0.5804  decode.d2.loss_dice: 0.7074  decode.d3.loss_cls: 2.7316  decode.d3.loss_mask: 0.5845  decode.d3.loss_dice: 0.6946  decode.d4.loss_cls: 2.6832  decode.d4.loss_mask: 0.6341  decode.d4.loss_dice: 0.7309  decode.d5.loss_cls: 2.6895  decode.d5.loss_mask: 0.6292  decode.d5.loss_dice: 0.7639  decode.d6.loss_cls: 2.6968  decode.d6.loss_mask: 0.6415  decode.d6.loss_dice: 0.7745  decode.d7.loss_cls: 2.6856  decode.d7.loss_mask: 0.6907  decode.d7.loss_dice: 0.7517  decode.d8.loss_cls: 2.7118  decode.d8.loss_mask: 0.6814  decode.d8.loss_dice: 0.8153
08/06 02:21:44 - mmengine - INFO - Iter(train) [   600/320000]  base_lr: 9.9832e-05 lr: 9.9832e-06  eta: 1 day, 19:53:36  time: 0.4872  data_time: 0.0104  memory: 5875  grad_norm: 237.0377  loss: 44.1159  decode.loss_cls: 2.6967  decode.loss_mask: 0.5861  decode.loss_dice: 0.6614  decode.d0.loss_cls: 6.5200  decode.d0.loss_mask: 0.7772  decode.d0.loss_dice: 1.1065  decode.d1.loss_cls: 2.6323  decode.d1.loss_mask: 0.6430  decode.d1.loss_dice: 0.7938  decode.d2.loss_cls: 2.5904  decode.d2.loss_mask: 0.5959  decode.d2.loss_dice: 0.6533  decode.d3.loss_cls: 2.5761  decode.d3.loss_mask: 0.6034  decode.d3.loss_dice: 0.6588  decode.d4.loss_cls: 2.6507  decode.d4.loss_mask: 0.6535  decode.d4.loss_dice: 0.7014  decode.d5.loss_cls: 2.7266  decode.d5.loss_mask: 0.6100  decode.d5.loss_dice: 0.6959  decode.d6.loss_cls: 2.6966  decode.d6.loss_mask: 0.6382  decode.d6.loss_dice: 0.6860  decode.d7.loss_cls: 2.7061  decode.d7.loss_mask: 0.6680  decode.d7.loss_dice: 0.6512  decode.d8.loss_cls: 2.6690  decode.d8.loss_mask: 0.6029  decode.d8.loss_dice: 0.6647
08/06 02:22:08 - mmengine - INFO - Iter(train) [   650/320000]  base_lr: 9.9817e-05 lr: 9.9817e-06  eta: 1 day, 19:50:31  time: 0.4885  data_time: 0.0105  memory: 5908  grad_norm: 225.0499  loss: 41.8999  decode.loss_cls: 2.4333  decode.loss_mask: 0.5828  decode.loss_dice: 0.7398  decode.d0.loss_cls: 6.5042  decode.d0.loss_mask: 0.6534  decode.d0.loss_dice: 1.1760  decode.d1.loss_cls: 2.6164  decode.d1.loss_mask: 0.4899  decode.d1.loss_dice: 0.7665  decode.d2.loss_cls: 2.5133  decode.d2.loss_mask: 0.4754  decode.d2.loss_dice: 0.7050  decode.d3.loss_cls: 2.4627  decode.d3.loss_mask: 0.4654  decode.d3.loss_dice: 0.6817  decode.d4.loss_cls: 2.4429  decode.d4.loss_mask: 0.5098  decode.d4.loss_dice: 0.7220  decode.d5.loss_cls: 2.4748  decode.d5.loss_mask: 0.5109  decode.d5.loss_dice: 0.6988  decode.d6.loss_cls: 2.4530  decode.d6.loss_mask: 0.5329  decode.d6.loss_dice: 0.7287  decode.d7.loss_cls: 2.4236  decode.d7.loss_mask: 0.5581  decode.d7.loss_dice: 0.7437  decode.d8.loss_cls: 2.4718  decode.d8.loss_mask: 0.6202  decode.d8.loss_dice: 0.7429
08/06 02:22:33 - mmengine - INFO - Iter(train) [   700/320000]  base_lr: 9.9803e-05 lr: 9.9803e-06  eta: 1 day, 19:48:01  time: 0.4886  data_time: 0.0104  memory: 5907  grad_norm: 246.2066  loss: 40.5143  decode.loss_cls: 2.2118  decode.loss_mask: 0.7581  decode.loss_dice: 0.7355  decode.d0.loss_cls: 6.5318  decode.d0.loss_mask: 0.7995  decode.d0.loss_dice: 0.9523  decode.d1.loss_cls: 2.2892  decode.d1.loss_mask: 0.6227  decode.d1.loss_dice: 0.6959  decode.d2.loss_cls: 2.0789  decode.d2.loss_mask: 0.7650  decode.d2.loss_dice: 0.6731  decode.d3.loss_cls: 2.1108  decode.d3.loss_mask: 0.7327  decode.d3.loss_dice: 0.6691  decode.d4.loss_cls: 2.1576  decode.d4.loss_mask: 0.6899  decode.d4.loss_dice: 0.6590  decode.d5.loss_cls: 2.2307  decode.d5.loss_mask: 0.6961  decode.d5.loss_dice: 0.6568  decode.d6.loss_cls: 2.2441  decode.d6.loss_mask: 0.7329  decode.d6.loss_dice: 0.6511  decode.d7.loss_cls: 2.1973  decode.d7.loss_mask: 0.7236  decode.d7.loss_dice: 0.6609  decode.d8.loss_cls: 2.1612  decode.d8.loss_mask: 0.7316  decode.d8.loss_dice: 0.6950
08/06 02:22:57 - mmengine - INFO - Iter(train) [   750/320000]  base_lr: 9.9789e-05 lr: 9.9789e-06  eta: 1 day, 19:45:54  time: 0.4894  data_time: 0.0104  memory: 5895  grad_norm: 250.1668  loss: 41.0588  decode.loss_cls: 2.4525  decode.loss_mask: 0.6010  decode.loss_dice: 0.6120  decode.d0.loss_cls: 6.2685  decode.d0.loss_mask: 0.6328  decode.d0.loss_dice: 0.8467  decode.d1.loss_cls: 2.5536  decode.d1.loss_mask: 0.5916  decode.d1.loss_dice: 0.6310  decode.d2.loss_cls: 2.5195  decode.d2.loss_mask: 0.5316  decode.d2.loss_dice: 0.5851  decode.d3.loss_cls: 2.5335  decode.d3.loss_mask: 0.5666  decode.d3.loss_dice: 0.5969  decode.d4.loss_cls: 2.6251  decode.d4.loss_mask: 0.5648  decode.d4.loss_dice: 0.5929  decode.d5.loss_cls: 2.5817  decode.d5.loss_mask: 0.5711  decode.d5.loss_dice: 0.5879  decode.d6.loss_cls: 2.5282  decode.d6.loss_mask: 0.5596  decode.d6.loss_dice: 0.5925  decode.d7.loss_cls: 2.5164  decode.d7.loss_mask: 0.5502  decode.d7.loss_dice: 0.6035  decode.d8.loss_cls: 2.5000  decode.d8.loss_mask: 0.5525  decode.d8.loss_dice: 0.6096
08/06 02:23:22 - mmengine - INFO - Iter(train) [   800/320000]  base_lr: 9.9775e-05 lr: 9.9775e-06  eta: 1 day, 19:43:59  time: 0.4893  data_time: 0.0104  memory: 5908  grad_norm: 216.4431  loss: 39.7185  decode.loss_cls: 2.4368  decode.loss_mask: 0.5482  decode.loss_dice: 0.5996  decode.d0.loss_cls: 6.1644  decode.d0.loss_mask: 0.6357  decode.d0.loss_dice: 0.8880  decode.d1.loss_cls: 2.4653  decode.d1.loss_mask: 0.5779  decode.d1.loss_dice: 0.6441  decode.d2.loss_cls: 2.1859  decode.d2.loss_mask: 0.5707  decode.d2.loss_dice: 0.5971  decode.d3.loss_cls: 2.3101  decode.d3.loss_mask: 0.5514  decode.d3.loss_dice: 0.5804  decode.d4.loss_cls: 2.4249  decode.d4.loss_mask: 0.5560  decode.d4.loss_dice: 0.5890  decode.d5.loss_cls: 2.4791  decode.d5.loss_mask: 0.5126  decode.d5.loss_dice: 0.5886  decode.d6.loss_cls: 2.4992  decode.d6.loss_mask: 0.5241  decode.d6.loss_dice: 0.6234  decode.d7.loss_cls: 2.4811  decode.d7.loss_mask: 0.5257  decode.d7.loss_dice: 0.5869  decode.d8.loss_cls: 2.4357  decode.d8.loss_mask: 0.5265  decode.d8.loss_dice: 0.6102
08/06 02:23:46 - mmengine - INFO - Iter(train) [   850/320000]  base_lr: 9.9761e-05 lr: 9.9761e-06  eta: 1 day, 19:42:07  time: 0.4883  data_time: 0.0103  memory: 5909  grad_norm: 178.9452  loss: 35.1361  decode.loss_cls: 2.0882  decode.loss_mask: 0.4973  decode.loss_dice: 0.5670  decode.d0.loss_cls: 5.9629  decode.d0.loss_mask: 0.5475  decode.d0.loss_dice: 0.8060  decode.d1.loss_cls: 2.0754  decode.d1.loss_mask: 0.5062  decode.d1.loss_dice: 0.5814  decode.d2.loss_cls: 2.0090  decode.d2.loss_mask: 0.4662  decode.d2.loss_dice: 0.5288  decode.d3.loss_cls: 2.0253  decode.d3.loss_mask: 0.4905  decode.d3.loss_dice: 0.5693  decode.d4.loss_cls: 2.1057  decode.d4.loss_mask: 0.4980  decode.d4.loss_dice: 0.5411  decode.d5.loss_cls: 2.0585  decode.d5.loss_mask: 0.4785  decode.d5.loss_dice: 0.5219  decode.d6.loss_cls: 2.0163  decode.d6.loss_mask: 0.5081  decode.d6.loss_dice: 0.5494  decode.d7.loss_cls: 2.0655  decode.d7.loss_mask: 0.4932  decode.d7.loss_dice: 0.5426  decode.d8.loss_cls: 2.0374  decode.d8.loss_mask: 0.4736  decode.d8.loss_dice: 0.5256
08/06 02:24:11 - mmengine - INFO - Iter(train) [   900/320000]  base_lr: 9.9747e-05 lr: 9.9747e-06  eta: 1 day, 19:40:24  time: 0.4883  data_time: 0.0101  memory: 5891  grad_norm: 290.3508  loss: 40.0526  decode.loss_cls: 2.3126  decode.loss_mask: 0.5406  decode.loss_dice: 0.6469  decode.d0.loss_cls: 5.8304  decode.d0.loss_mask: 0.6185  decode.d0.loss_dice: 0.9084  decode.d1.loss_cls: 2.3746  decode.d1.loss_mask: 0.5187  decode.d1.loss_dice: 0.6029  decode.d2.loss_cls: 2.2112  decode.d2.loss_mask: 0.5216  decode.d2.loss_dice: 0.6475  decode.d3.loss_cls: 2.2524  decode.d3.loss_mask: 0.5964  decode.d3.loss_dice: 0.6316  decode.d4.loss_cls: 2.3242  decode.d4.loss_mask: 0.6047  decode.d4.loss_dice: 0.7278  decode.d5.loss_cls: 2.3711  decode.d5.loss_mask: 0.7201  decode.d5.loss_dice: 0.7421  decode.d6.loss_cls: 2.3822  decode.d6.loss_mask: 0.6769  decode.d6.loss_dice: 0.6997  decode.d7.loss_cls: 2.3786  decode.d7.loss_mask: 0.7055  decode.d7.loss_dice: 0.7707  decode.d8.loss_cls: 2.3114  decode.d8.loss_mask: 0.6922  decode.d8.loss_dice: 0.7311
08/06 02:24:35 - mmengine - INFO - Iter(train) [   950/320000]  base_lr: 9.9733e-05 lr: 9.9733e-06  eta: 1 day, 19:38:53  time: 0.4891  data_time: 0.0101  memory: 5892  grad_norm: 225.7848  loss: 38.6572  decode.loss_cls: 2.3905  decode.loss_mask: 0.4106  decode.loss_dice: 0.6143  decode.d0.loss_cls: 5.8775  decode.d0.loss_mask: 0.6128  decode.d0.loss_dice: 0.9543  decode.d1.loss_cls: 2.5394  decode.d1.loss_mask: 0.4147  decode.d1.loss_dice: 0.5682  decode.d2.loss_cls: 2.3573  decode.d2.loss_mask: 0.4588  decode.d2.loss_dice: 0.5590  decode.d3.loss_cls: 2.3555  decode.d3.loss_mask: 0.4476  decode.d3.loss_dice: 0.5877  decode.d4.loss_cls: 2.4236  decode.d4.loss_mask: 0.4397  decode.d4.loss_dice: 0.5684  decode.d5.loss_cls: 2.4321  decode.d5.loss_mask: 0.4594  decode.d5.loss_dice: 0.5907  decode.d6.loss_cls: 2.4162  decode.d6.loss_mask: 0.4266  decode.d6.loss_dice: 0.5958  decode.d7.loss_cls: 2.4809  decode.d7.loss_mask: 0.4738  decode.d7.loss_dice: 0.6490  decode.d8.loss_cls: 2.4861  decode.d8.loss_mask: 0.4517  decode.d8.loss_dice: 0.6153
08/06 02:24:59 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 02:24:59 - mmengine - INFO - Iter(train) [  1000/320000]  base_lr: 9.9719e-05 lr: 9.9719e-06  eta: 1 day, 19:37:23  time: 0.4890  data_time: 0.0105  memory: 5890  grad_norm: 323.4423  loss: 37.2938  decode.loss_cls: 1.9170  decode.loss_mask: 0.6888  decode.loss_dice: 0.6362  decode.d0.loss_cls: 5.6201  decode.d0.loss_mask: 0.8457  decode.d0.loss_dice: 0.9220  decode.d1.loss_cls: 2.1510  decode.d1.loss_mask: 0.6559  decode.d1.loss_dice: 0.6229  decode.d2.loss_cls: 1.8686  decode.d2.loss_mask: 0.7229  decode.d2.loss_dice: 0.6692  decode.d3.loss_cls: 1.9031  decode.d3.loss_mask: 0.7775  decode.d3.loss_dice: 0.6735  decode.d4.loss_cls: 2.0227  decode.d4.loss_mask: 0.6927  decode.d4.loss_dice: 0.6312  decode.d5.loss_cls: 2.0129  decode.d5.loss_mask: 0.6558  decode.d5.loss_dice: 0.6160  decode.d6.loss_cls: 2.0173  decode.d6.loss_mask: 0.6956  decode.d6.loss_dice: 0.6094  decode.d7.loss_cls: 2.0414  decode.d7.loss_mask: 0.7115  decode.d7.loss_dice: 0.6006  decode.d8.loss_cls: 1.9676  decode.d8.loss_mask: 0.7370  decode.d8.loss_dice: 0.6077
08/06 02:25:24 - mmengine - INFO - Iter(train) [  1050/320000]  base_lr: 9.9705e-05 lr: 9.9705e-06  eta: 1 day, 19:36:35  time: 0.4891  data_time: 0.0102  memory: 5874  grad_norm: 272.6884  loss: 41.3524  decode.loss_cls: 2.7107  decode.loss_mask: 0.4627  decode.loss_dice: 0.6077  decode.d0.loss_cls: 5.7560  decode.d0.loss_mask: 0.6544  decode.d0.loss_dice: 1.0534  decode.d1.loss_cls: 2.7219  decode.d1.loss_mask: 0.5185  decode.d1.loss_dice: 0.6792  decode.d2.loss_cls: 2.5514  decode.d2.loss_mask: 0.5190  decode.d2.loss_dice: 0.6183  decode.d3.loss_cls: 2.5494  decode.d3.loss_mask: 0.5231  decode.d3.loss_dice: 0.6311  decode.d4.loss_cls: 2.6876  decode.d4.loss_mask: 0.4980  decode.d4.loss_dice: 0.6137  decode.d5.loss_cls: 2.6125  decode.d5.loss_mask: 0.5025  decode.d5.loss_dice: 0.6077  decode.d6.loss_cls: 2.5930  decode.d6.loss_mask: 0.4933  decode.d6.loss_dice: 0.6292  decode.d7.loss_cls: 2.6067  decode.d7.loss_mask: 0.4879  decode.d7.loss_dice: 0.6501  decode.d8.loss_cls: 2.7193  decode.d8.loss_mask: 0.4844  decode.d8.loss_dice: 0.6099
08/06 02:25:48 - mmengine - INFO - Iter(train) [  1100/320000]  base_lr: 9.9691e-05 lr: 9.9691e-06  eta: 1 day, 19:35:18  time: 0.4883  data_time: 0.0102  memory: 5908  grad_norm: 306.6093  loss: 38.1815  decode.loss_cls: 2.3481  decode.loss_mask: 0.4435  decode.loss_dice: 0.5717  decode.d0.loss_cls: 5.5498  decode.d0.loss_mask: 0.5501  decode.d0.loss_dice: 0.8780  decode.d1.loss_cls: 2.5615  decode.d1.loss_mask: 0.4331  decode.d1.loss_dice: 0.5669  decode.d2.loss_cls: 2.4082  decode.d2.loss_mask: 0.4572  decode.d2.loss_dice: 0.5382  decode.d3.loss_cls: 2.3405  decode.d3.loss_mask: 0.4768  decode.d3.loss_dice: 0.5807  decode.d4.loss_cls: 2.4356  decode.d4.loss_mask: 0.4936  decode.d4.loss_dice: 0.5863  decode.d5.loss_cls: 2.3803  decode.d5.loss_mask: 0.4723  decode.d5.loss_dice: 0.5737  decode.d6.loss_cls: 2.3873  decode.d6.loss_mask: 0.5382  decode.d6.loss_dice: 0.6587  decode.d7.loss_cls: 2.3386  decode.d7.loss_mask: 0.5305  decode.d7.loss_dice: 0.6419  decode.d8.loss_cls: 2.3583  decode.d8.loss_mask: 0.4797  decode.d8.loss_dice: 0.6020
08/06 02:26:13 - mmengine - INFO - Iter(train) [  1150/320000]  base_lr: 9.9677e-05 lr: 9.9677e-06  eta: 1 day, 19:34:04  time: 0.4883  data_time: 0.0104  memory: 5907  grad_norm: 216.6767  loss: 37.3376  decode.loss_cls: 2.3325  decode.loss_mask: 0.3992  decode.loss_dice: 0.6009  decode.d0.loss_cls: 5.3871  decode.d0.loss_mask: 0.5239  decode.d0.loss_dice: 0.8676  decode.d1.loss_cls: 2.5343  decode.d1.loss_mask: 0.4277  decode.d1.loss_dice: 0.5757  decode.d2.loss_cls: 2.3913  decode.d2.loss_mask: 0.3960  decode.d2.loss_dice: 0.5393  decode.d3.loss_cls: 2.3891  decode.d3.loss_mask: 0.4336  decode.d3.loss_dice: 0.5522  decode.d4.loss_cls: 2.3830  decode.d4.loss_mask: 0.4034  decode.d4.loss_dice: 0.5614  decode.d5.loss_cls: 2.3911  decode.d5.loss_mask: 0.4144  decode.d5.loss_dice: 0.5619  decode.d6.loss_cls: 2.3767  decode.d6.loss_mask: 0.4492  decode.d6.loss_dice: 0.6316  decode.d7.loss_cls: 2.3715  decode.d7.loss_mask: 0.4450  decode.d7.loss_dice: 0.6551  decode.d8.loss_cls: 2.3067  decode.d8.loss_mask: 0.4344  decode.d8.loss_dice: 0.6020
08/06 02:26:37 - mmengine - INFO - Iter(train) [  1200/320000]  base_lr: 9.9663e-05 lr: 9.9663e-06  eta: 1 day, 19:32:51  time: 0.4879  data_time: 0.0102  memory: 5980  grad_norm: 231.7685  loss: 37.5549  decode.loss_cls: 2.4574  decode.loss_mask: 0.5408  decode.loss_dice: 0.7007  decode.d0.loss_cls: 5.3364  decode.d0.loss_mask: 0.5818  decode.d0.loss_dice: 0.9579  decode.d1.loss_cls: 2.4401  decode.d1.loss_mask: 0.4106  decode.d1.loss_dice: 0.5789  decode.d2.loss_cls: 2.3416  decode.d2.loss_mask: 0.4120  decode.d2.loss_dice: 0.5679  decode.d3.loss_cls: 2.3085  decode.d3.loss_mask: 0.4351  decode.d3.loss_dice: 0.5722  decode.d4.loss_cls: 2.4113  decode.d4.loss_mask: 0.4275  decode.d4.loss_dice: 0.5703  decode.d5.loss_cls: 2.3162  decode.d5.loss_mask: 0.4471  decode.d5.loss_dice: 0.5776  decode.d6.loss_cls: 2.2839  decode.d6.loss_mask: 0.4009  decode.d6.loss_dice: 0.5581  decode.d7.loss_cls: 2.3500  decode.d7.loss_mask: 0.4277  decode.d7.loss_dice: 0.5632  decode.d8.loss_cls: 2.5113  decode.d8.loss_mask: 0.4616  decode.d8.loss_dice: 0.6061
08/06 02:27:02 - mmengine - INFO - Iter(train) [  1250/320000]  base_lr: 9.9649e-05 lr: 9.9649e-06  eta: 1 day, 19:31:46  time: 0.4875  data_time: 0.0103  memory: 5891  grad_norm: 219.3307  loss: 35.5375  decode.loss_cls: 2.2446  decode.loss_mask: 0.4356  decode.loss_dice: 0.5635  decode.d0.loss_cls: 5.2028  decode.d0.loss_mask: 0.5896  decode.d0.loss_dice: 0.8628  decode.d1.loss_cls: 2.3940  decode.d1.loss_mask: 0.4472  decode.d1.loss_dice: 0.6171  decode.d2.loss_cls: 2.1394  decode.d2.loss_mask: 0.4687  decode.d2.loss_dice: 0.5552  decode.d3.loss_cls: 2.1200  decode.d3.loss_mask: 0.4782  decode.d3.loss_dice: 0.5553  decode.d4.loss_cls: 2.1976  decode.d4.loss_mask: 0.4502  decode.d4.loss_dice: 0.5408  decode.d5.loss_cls: 2.1662  decode.d5.loss_mask: 0.4693  decode.d5.loss_dice: 0.5393  decode.d6.loss_cls: 2.1708  decode.d6.loss_mask: 0.4440  decode.d6.loss_dice: 0.5236  decode.d7.loss_cls: 2.1587  decode.d7.loss_mask: 0.4589  decode.d7.loss_dice: 0.5467  decode.d8.loss_cls: 2.2054  decode.d8.loss_mask: 0.4317  decode.d8.loss_dice: 0.5602
08/06 02:27:26 - mmengine - INFO - Iter(train) [  1300/320000]  base_lr: 9.9635e-05 lr: 9.9635e-06  eta: 1 day, 19:30:38  time: 0.4881  data_time: 0.0105  memory: 5927  grad_norm: 238.6654  loss: 34.9284  decode.loss_cls: 2.2400  decode.loss_mask: 0.4741  decode.loss_dice: 0.5122  decode.d0.loss_cls: 5.1740  decode.d0.loss_mask: 0.5114  decode.d0.loss_dice: 0.7005  decode.d1.loss_cls: 2.3539  decode.d1.loss_mask: 0.4926  decode.d1.loss_dice: 0.5186  decode.d2.loss_cls: 2.0601  decode.d2.loss_mask: 0.4990  decode.d2.loss_dice: 0.4913  decode.d3.loss_cls: 2.1455  decode.d3.loss_mask: 0.4960  decode.d3.loss_dice: 0.5121  decode.d4.loss_cls: 2.2083  decode.d4.loss_mask: 0.4684  decode.d4.loss_dice: 0.5127  decode.d5.loss_cls: 2.1405  decode.d5.loss_mask: 0.4847  decode.d5.loss_dice: 0.5207  decode.d6.loss_cls: 2.2065  decode.d6.loss_mask: 0.4989  decode.d6.loss_dice: 0.4781  decode.d7.loss_cls: 2.1928  decode.d7.loss_mask: 0.4701  decode.d7.loss_dice: 0.5020  decode.d8.loss_cls: 2.1213  decode.d8.loss_mask: 0.4683  decode.d8.loss_dice: 0.4737
08/06 02:27:50 - mmengine - INFO - Iter(train) [  1350/320000]  base_lr: 9.9621e-05 lr: 9.9621e-06  eta: 1 day, 19:29:37  time: 0.4882  data_time: 0.0102  memory: 5966  grad_norm: 409.6792  loss: 36.0220  decode.loss_cls: 2.0659  decode.loss_mask: 0.5092  decode.loss_dice: 0.6153  decode.d0.loss_cls: 4.9405  decode.d0.loss_mask: 0.6814  decode.d0.loss_dice: 0.8842  decode.d1.loss_cls: 2.4116  decode.d1.loss_mask: 0.4967  decode.d1.loss_dice: 0.5814  decode.d2.loss_cls: 2.1820  decode.d2.loss_mask: 0.5042  decode.d2.loss_dice: 0.5679  decode.d3.loss_cls: 2.1828  decode.d3.loss_mask: 0.4983  decode.d3.loss_dice: 0.5681  decode.d4.loss_cls: 2.3041  decode.d4.loss_mask: 0.4956  decode.d4.loss_dice: 0.5541  decode.d5.loss_cls: 2.1768  decode.d5.loss_mask: 0.4662  decode.d5.loss_dice: 0.5956  decode.d6.loss_cls: 2.1384  decode.d6.loss_mask: 0.4736  decode.d6.loss_dice: 0.5733  decode.d7.loss_cls: 2.1744  decode.d7.loss_mask: 0.5269  decode.d7.loss_dice: 0.5758  decode.d8.loss_cls: 2.1745  decode.d8.loss_mask: 0.5231  decode.d8.loss_dice: 0.5798
08/06 02:28:15 - mmengine - INFO - Iter(train) [  1400/320000]  base_lr: 9.9606e-05 lr: 9.9606e-06  eta: 1 day, 19:28:37  time: 0.4887  data_time: 0.0104  memory: 5892  grad_norm: 234.3405  loss: 37.8902  decode.loss_cls: 2.2184  decode.loss_mask: 0.5769  decode.loss_dice: 0.6531  decode.d0.loss_cls: 4.9474  decode.d0.loss_mask: 0.6836  decode.d0.loss_dice: 0.8161  decode.d1.loss_cls: 2.4569  decode.d1.loss_mask: 0.5633  decode.d1.loss_dice: 0.6125  decode.d2.loss_cls: 2.2679  decode.d2.loss_mask: 0.5400  decode.d2.loss_dice: 0.6175  decode.d3.loss_cls: 2.2476  decode.d3.loss_mask: 0.5895  decode.d3.loss_dice: 0.6436  decode.d4.loss_cls: 2.3062  decode.d4.loss_mask: 0.5762  decode.d4.loss_dice: 0.6504  decode.d5.loss_cls: 2.2901  decode.d5.loss_mask: 0.6066  decode.d5.loss_dice: 0.6228  decode.d6.loss_cls: 2.2644  decode.d6.loss_mask: 0.5767  decode.d6.loss_dice: 0.6190  decode.d7.loss_cls: 2.1780  decode.d7.loss_mask: 0.6002  decode.d7.loss_dice: 0.6429  decode.d8.loss_cls: 2.3034  decode.d8.loss_mask: 0.5711  decode.d8.loss_dice: 0.6479
08/06 02:28:39 - mmengine - INFO - Iter(train) [  1450/320000]  base_lr: 9.9592e-05 lr: 9.9592e-06  eta: 1 day, 19:27:43  time: 0.4878  data_time: 0.0101  memory: 5889  grad_norm: 364.3848  loss: 35.3351  decode.loss_cls: 2.1390  decode.loss_mask: 0.4808  decode.loss_dice: 0.6592  decode.d0.loss_cls: 4.7774  decode.d0.loss_mask: 0.6368  decode.d0.loss_dice: 0.9108  decode.d1.loss_cls: 2.2816  decode.d1.loss_mask: 0.4604  decode.d1.loss_dice: 0.6569  decode.d2.loss_cls: 2.0573  decode.d2.loss_mask: 0.4695  decode.d2.loss_dice: 0.5868  decode.d3.loss_cls: 2.0535  decode.d3.loss_mask: 0.4683  decode.d3.loss_dice: 0.5703  decode.d4.loss_cls: 2.1217  decode.d4.loss_mask: 0.4651  decode.d4.loss_dice: 0.6019  decode.d5.loss_cls: 2.0467  decode.d5.loss_mask: 0.4840  decode.d5.loss_dice: 0.6244  decode.d6.loss_cls: 2.0876  decode.d6.loss_mask: 0.4915  decode.d6.loss_dice: 0.6541  decode.d7.loss_cls: 2.1680  decode.d7.loss_mask: 0.4863  decode.d7.loss_dice: 0.6302  decode.d8.loss_cls: 2.1400  decode.d8.loss_mask: 0.5255  decode.d8.loss_dice: 0.5996
08/06 02:29:04 - mmengine - INFO - Iter(train) [  1500/320000]  base_lr: 9.9578e-05 lr: 9.9578e-06  eta: 1 day, 19:26:51  time: 0.4884  data_time: 0.0102  memory: 5895  grad_norm: 195.6342  loss: 31.9688  decode.loss_cls: 1.7743  decode.loss_mask: 0.5449  decode.loss_dice: 0.5877  decode.d0.loss_cls: 4.5485  decode.d0.loss_mask: 0.5042  decode.d0.loss_dice: 0.8218  decode.d1.loss_cls: 1.9831  decode.d1.loss_mask: 0.4367  decode.d1.loss_dice: 0.6290  decode.d2.loss_cls: 1.7671  decode.d2.loss_mask: 0.4445  decode.d2.loss_dice: 0.5894  decode.d3.loss_cls: 1.7953  decode.d3.loss_mask: 0.4236  decode.d3.loss_dice: 0.5437  decode.d4.loss_cls: 1.8815  decode.d4.loss_mask: 0.4187  decode.d4.loss_dice: 0.5764  decode.d5.loss_cls: 1.8100  decode.d5.loss_mask: 0.5345  decode.d5.loss_dice: 0.6223  decode.d6.loss_cls: 1.7723  decode.d6.loss_mask: 0.4836  decode.d6.loss_dice: 0.5948  decode.d7.loss_cls: 1.7340  decode.d7.loss_mask: 0.4943  decode.d7.loss_dice: 0.6373  decode.d8.loss_cls: 1.7803  decode.d8.loss_mask: 0.5965  decode.d8.loss_dice: 0.6387
08/06 02:29:28 - mmengine - INFO - Iter(train) [  1550/320000]  base_lr: 9.9564e-05 lr: 9.9564e-06  eta: 1 day, 19:26:01  time: 0.4883  data_time: 0.0103  memory: 5926  grad_norm: 277.7840  loss: 32.1384  decode.loss_cls: 1.8624  decode.loss_mask: 0.5858  decode.loss_dice: 0.5642  decode.d0.loss_cls: 4.3630  decode.d0.loss_mask: 0.6712  decode.d0.loss_dice: 0.8097  decode.d1.loss_cls: 1.9125  decode.d1.loss_mask: 0.5902  decode.d1.loss_dice: 0.5669  decode.d2.loss_cls: 1.6998  decode.d2.loss_mask: 0.5715  decode.d2.loss_dice: 0.5356  decode.d3.loss_cls: 1.7208  decode.d3.loss_mask: 0.5429  decode.d3.loss_dice: 0.5237  decode.d4.loss_cls: 1.7915  decode.d4.loss_mask: 0.5815  decode.d4.loss_dice: 0.5759  decode.d5.loss_cls: 1.7513  decode.d5.loss_mask: 0.5827  decode.d5.loss_dice: 0.5314  decode.d6.loss_cls: 1.7584  decode.d6.loss_mask: 0.5839  decode.d6.loss_dice: 0.5581  decode.d7.loss_cls: 1.7475  decode.d7.loss_mask: 0.5830  decode.d7.loss_dice: 0.5386  decode.d8.loss_cls: 1.8758  decode.d8.loss_mask: 0.5931  decode.d8.loss_dice: 0.5658
08/06 02:29:53 - mmengine - INFO - Iter(train) [  1600/320000]  base_lr: 9.9550e-05 lr: 9.9550e-06  eta: 1 day, 19:25:36  time: 0.4891  data_time: 0.0105  memory: 5907  grad_norm: 225.1636  loss: 34.6685  decode.loss_cls: 2.0561  decode.loss_mask: 0.4609  decode.loss_dice: 0.5105  decode.d0.loss_cls: 4.5571  decode.d0.loss_mask: 0.6143  decode.d0.loss_dice: 0.7780  decode.d1.loss_cls: 2.3845  decode.d1.loss_mask: 0.4998  decode.d1.loss_dice: 0.5833  decode.d2.loss_cls: 2.1547  decode.d2.loss_mask: 0.4509  decode.d2.loss_dice: 0.5405  decode.d3.loss_cls: 2.1318  decode.d3.loss_mask: 0.4744  decode.d3.loss_dice: 0.5371  decode.d4.loss_cls: 2.1268  decode.d4.loss_mask: 0.4698  decode.d4.loss_dice: 0.5520  decode.d5.loss_cls: 2.1362  decode.d5.loss_mask: 0.5014  decode.d5.loss_dice: 0.5591  decode.d6.loss_cls: 2.0976  decode.d6.loss_mask: 0.5300  decode.d6.loss_dice: 0.5639  decode.d7.loss_cls: 2.1121  decode.d7.loss_mask: 0.4960  decode.d7.loss_dice: 0.5664  decode.d8.loss_cls: 2.2333  decode.d8.loss_mask: 0.4698  decode.d8.loss_dice: 0.5202
08/06 02:30:17 - mmengine - INFO - Iter(train) [  1650/320000]  base_lr: 9.9536e-05 lr: 9.9536e-06  eta: 1 day, 19:24:45  time: 0.4892  data_time: 0.0104  memory: 5907  grad_norm: 293.9070  loss: 35.2359  decode.loss_cls: 1.9432  decode.loss_mask: 0.6408  decode.loss_dice: 0.7154  decode.d0.loss_cls: 4.2475  decode.d0.loss_mask: 0.7785  decode.d0.loss_dice: 0.9739  decode.d1.loss_cls: 2.1085  decode.d1.loss_mask: 0.5817  decode.d1.loss_dice: 0.6301  decode.d2.loss_cls: 1.8672  decode.d2.loss_mask: 0.6251  decode.d2.loss_dice: 0.6396  decode.d3.loss_cls: 1.9264  decode.d3.loss_mask: 0.5432  decode.d3.loss_dice: 0.6275  decode.d4.loss_cls: 1.9608  decode.d4.loss_mask: 0.6152  decode.d4.loss_dice: 0.6798  decode.d5.loss_cls: 1.9589  decode.d5.loss_mask: 0.5875  decode.d5.loss_dice: 0.6794  decode.d6.loss_cls: 1.9657  decode.d6.loss_mask: 0.6298  decode.d6.loss_dice: 0.7323  decode.d7.loss_cls: 1.9283  decode.d7.loss_mask: 0.6733  decode.d7.loss_dice: 0.7398  decode.d8.loss_cls: 2.0081  decode.d8.loss_mask: 0.5758  decode.d8.loss_dice: 0.6528
08/06 02:30:42 - mmengine - INFO - Iter(train) [  1700/320000]  base_lr: 9.9522e-05 lr: 9.9522e-06  eta: 1 day, 19:23:54  time: 0.4887  data_time: 0.0104  memory: 5907  grad_norm: 204.0917  loss: 31.5047  decode.loss_cls: 1.9031  decode.loss_mask: 0.4374  decode.loss_dice: 0.5052  decode.d0.loss_cls: 4.1401  decode.d0.loss_mask: 0.4620  decode.d0.loss_dice: 0.7610  decode.d1.loss_cls: 2.1498  decode.d1.loss_mask: 0.4127  decode.d1.loss_dice: 0.5560  decode.d2.loss_cls: 1.9075  decode.d2.loss_mask: 0.4062  decode.d2.loss_dice: 0.5265  decode.d3.loss_cls: 1.8882  decode.d3.loss_mask: 0.4123  decode.d3.loss_dice: 0.5200  decode.d4.loss_cls: 1.8834  decode.d4.loss_mask: 0.4209  decode.d4.loss_dice: 0.5242  decode.d5.loss_cls: 2.0425  decode.d5.loss_mask: 0.4179  decode.d5.loss_dice: 0.5327  decode.d6.loss_cls: 1.8735  decode.d6.loss_mask: 0.4460  decode.d6.loss_dice: 0.5376  decode.d7.loss_cls: 1.9596  decode.d7.loss_mask: 0.4630  decode.d7.loss_dice: 0.5364  decode.d8.loss_cls: 2.0004  decode.d8.loss_mask: 0.3728  decode.d8.loss_dice: 0.5058
08/06 02:31:06 - mmengine - INFO - Iter(train) [  1750/320000]  base_lr: 9.9508e-05 lr: 9.9508e-06  eta: 1 day, 19:23:07  time: 0.4885  data_time: 0.0104  memory: 5892  grad_norm: 258.3203  loss: 35.7033  decode.loss_cls: 2.1718  decode.loss_mask: 0.4824  decode.loss_dice: 0.6444  decode.d0.loss_cls: 4.1619  decode.d0.loss_mask: 0.5542  decode.d0.loss_dice: 0.8636  decode.d1.loss_cls: 2.3092  decode.d1.loss_mask: 0.4845  decode.d1.loss_dice: 0.6827  decode.d2.loss_cls: 2.2645  decode.d2.loss_mask: 0.5015  decode.d2.loss_dice: 0.6543  decode.d3.loss_cls: 2.1797  decode.d3.loss_mask: 0.4728  decode.d3.loss_dice: 0.6400  decode.d4.loss_cls: 2.1933  decode.d4.loss_mask: 0.4759  decode.d4.loss_dice: 0.6838  decode.d5.loss_cls: 2.1354  decode.d5.loss_mask: 0.4849  decode.d5.loss_dice: 0.6379  decode.d6.loss_cls: 2.0715  decode.d6.loss_mask: 0.5131  decode.d6.loss_dice: 0.6637  decode.d7.loss_cls: 2.1984  decode.d7.loss_mask: 0.5058  decode.d7.loss_dice: 0.7012  decode.d8.loss_cls: 2.2853  decode.d8.loss_mask: 0.4767  decode.d8.loss_dice: 0.6087
08/06 02:31:30 - mmengine - INFO - Iter(train) [  1800/320000]  base_lr: 9.9494e-05 lr: 9.9494e-06  eta: 1 day, 19:22:20  time: 0.4884  data_time: 0.0103  memory: 5907  grad_norm: 196.6094  loss: 31.8284  decode.loss_cls: 1.9827  decode.loss_mask: 0.4696  decode.loss_dice: 0.5454  decode.d0.loss_cls: 4.0943  decode.d0.loss_mask: 0.4858  decode.d0.loss_dice: 0.7593  decode.d1.loss_cls: 2.3427  decode.d1.loss_mask: 0.3435  decode.d1.loss_dice: 0.4617  decode.d2.loss_cls: 2.0776  decode.d2.loss_mask: 0.3662  decode.d2.loss_dice: 0.4904  decode.d3.loss_cls: 1.9627  decode.d3.loss_mask: 0.3464  decode.d3.loss_dice: 0.4953  decode.d4.loss_cls: 2.0722  decode.d4.loss_mask: 0.3791  decode.d4.loss_dice: 0.5177  decode.d5.loss_cls: 2.0450  decode.d5.loss_mask: 0.3666  decode.d5.loss_dice: 0.5284  decode.d6.loss_cls: 1.9036  decode.d6.loss_mask: 0.4148  decode.d6.loss_dice: 0.5148  decode.d7.loss_cls: 1.9699  decode.d7.loss_mask: 0.3840  decode.d7.loss_dice: 0.4742  decode.d8.loss_cls: 2.0735  decode.d8.loss_mask: 0.4413  decode.d8.loss_dice: 0.5196
08/06 02:31:55 - mmengine - INFO - Iter(train) [  1850/320000]  base_lr: 9.9480e-05 lr: 9.9480e-06  eta: 1 day, 19:21:34  time: 0.4882  data_time: 0.0103  memory: 5875  grad_norm: 383.2812  loss: 32.6122  decode.loss_cls: 1.9275  decode.loss_mask: 0.6434  decode.loss_dice: 0.6052  decode.d0.loss_cls: 3.8585  decode.d0.loss_mask: 0.6448  decode.d0.loss_dice: 0.7486  decode.d1.loss_cls: 2.1763  decode.d1.loss_mask: 0.4825  decode.d1.loss_dice: 0.5228  decode.d2.loss_cls: 1.8755  decode.d2.loss_mask: 0.4200  decode.d2.loss_dice: 0.4910  decode.d3.loss_cls: 1.8755  decode.d3.loss_mask: 0.4264  decode.d3.loss_dice: 0.4831  decode.d4.loss_cls: 1.9410  decode.d4.loss_mask: 0.5031  decode.d4.loss_dice: 0.5297  decode.d5.loss_cls: 2.0489  decode.d5.loss_mask: 0.4777  decode.d5.loss_dice: 0.5283  decode.d6.loss_cls: 1.9904  decode.d6.loss_mask: 0.5933  decode.d6.loss_dice: 0.5881  decode.d7.loss_cls: 2.0582  decode.d7.loss_mask: 0.5152  decode.d7.loss_dice: 0.5530  decode.d8.loss_cls: 1.9754  decode.d8.loss_mask: 0.5957  decode.d8.loss_dice: 0.5330
08/06 02:32:19 - mmengine - INFO - Iter(train) [  1900/320000]  base_lr: 9.9466e-05 lr: 9.9466e-06  eta: 1 day, 19:21:25  time: 0.4884  data_time: 0.0105  memory: 5908  grad_norm: 222.3356  loss: 29.1156  decode.loss_cls: 1.7059  decode.loss_mask: 0.4492  decode.loss_dice: 0.5036  decode.d0.loss_cls: 3.6272  decode.d0.loss_mask: 0.6203  decode.d0.loss_dice: 0.7278  decode.d1.loss_cls: 1.7503  decode.d1.loss_mask: 0.5475  decode.d1.loss_dice: 0.5723  decode.d2.loss_cls: 1.7843  decode.d2.loss_mask: 0.4567  decode.d2.loss_dice: 0.4934  decode.d3.loss_cls: 1.6486  decode.d3.loss_mask: 0.4890  decode.d3.loss_dice: 0.5120  decode.d4.loss_cls: 1.7317  decode.d4.loss_mask: 0.4681  decode.d4.loss_dice: 0.4785  decode.d5.loss_cls: 1.7203  decode.d5.loss_mask: 0.4714  decode.d5.loss_dice: 0.4661  decode.d6.loss_cls: 1.6394  decode.d6.loss_mask: 0.4715  decode.d6.loss_dice: 0.5012  decode.d7.loss_cls: 1.6498  decode.d7.loss_mask: 0.4245  decode.d7.loss_dice: 0.4932  decode.d8.loss_cls: 1.7599  decode.d8.loss_mask: 0.4601  decode.d8.loss_dice: 0.4918
08/06 02:32:44 - mmengine - INFO - Iter(train) [  1950/320000]  base_lr: 9.9452e-05 lr: 9.9452e-06  eta: 1 day, 19:20:43  time: 0.4886  data_time: 0.0102  memory: 5895  grad_norm: 225.3153  loss: 32.5571  decode.loss_cls: 2.1256  decode.loss_mask: 0.3976  decode.loss_dice: 0.4872  decode.d0.loss_cls: 3.7132  decode.d0.loss_mask: 0.6171  decode.d0.loss_dice: 0.7891  decode.d1.loss_cls: 2.3185  decode.d1.loss_mask: 0.4352  decode.d1.loss_dice: 0.4896  decode.d2.loss_cls: 2.0644  decode.d2.loss_mask: 0.4050  decode.d2.loss_dice: 0.4671  decode.d3.loss_cls: 1.9817  decode.d3.loss_mask: 0.4217  decode.d3.loss_dice: 0.4774  decode.d4.loss_cls: 2.0368  decode.d4.loss_mask: 0.4983  decode.d4.loss_dice: 0.5410  decode.d5.loss_cls: 2.1682  decode.d5.loss_mask: 0.4441  decode.d5.loss_dice: 0.4966  decode.d6.loss_cls: 2.1436  decode.d6.loss_mask: 0.4260  decode.d6.loss_dice: 0.5198  decode.d7.loss_cls: 2.1098  decode.d7.loss_mask: 0.4286  decode.d7.loss_dice: 0.4992  decode.d8.loss_cls: 2.1362  decode.d8.loss_mask: 0.4228  decode.d8.loss_dice: 0.4956
08/06 02:33:08 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 02:33:08 - mmengine - INFO - Iter(train) [  2000/320000]  base_lr: 9.9438e-05 lr: 9.9438e-06  eta: 1 day, 19:19:59  time: 0.4885  data_time: 0.0102  memory: 5875  grad_norm: 249.8662  loss: 30.3562  decode.loss_cls: 2.1089  decode.loss_mask: 0.3669  decode.loss_dice: 0.4466  decode.d0.loss_cls: 3.5803  decode.d0.loss_mask: 0.4750  decode.d0.loss_dice: 0.6847  decode.d1.loss_cls: 2.0799  decode.d1.loss_mask: 0.3797  decode.d1.loss_dice: 0.4508  decode.d2.loss_cls: 1.9297  decode.d2.loss_mask: 0.3773  decode.d2.loss_dice: 0.4346  decode.d3.loss_cls: 1.9426  decode.d3.loss_mask: 0.3697  decode.d3.loss_dice: 0.4333  decode.d4.loss_cls: 2.0038  decode.d4.loss_mask: 0.4072  decode.d4.loss_dice: 0.4629  decode.d5.loss_cls: 1.9893  decode.d5.loss_mask: 0.3655  decode.d5.loss_dice: 0.4485  decode.d6.loss_cls: 2.0431  decode.d6.loss_mask: 0.3649  decode.d6.loss_dice: 0.4791  decode.d7.loss_cls: 2.0351  decode.d7.loss_mask: 0.3686  decode.d7.loss_dice: 0.4822  decode.d8.loss_cls: 2.0292  decode.d8.loss_mask: 0.3511  decode.d8.loss_dice: 0.4655
08/06 02:33:33 - mmengine - INFO - Iter(train) [  2050/320000]  base_lr: 9.9424e-05 lr: 9.9424e-06  eta: 1 day, 19:19:19  time: 0.4895  data_time: 0.0105  memory: 5908  grad_norm: 344.1642  loss: 28.0715  decode.loss_cls: 1.6682  decode.loss_mask: 0.4827  decode.loss_dice: 0.4657  decode.d0.loss_cls: 3.3062  decode.d0.loss_mask: 0.5719  decode.d0.loss_dice: 0.7362  decode.d1.loss_cls: 1.7834  decode.d1.loss_mask: 0.4933  decode.d1.loss_dice: 0.5070  decode.d2.loss_cls: 1.5930  decode.d2.loss_mask: 0.5165  decode.d2.loss_dice: 0.4768  decode.d3.loss_cls: 1.6333  decode.d3.loss_mask: 0.4674  decode.d3.loss_dice: 0.4938  decode.d4.loss_cls: 1.6054  decode.d4.loss_mask: 0.5239  decode.d4.loss_dice: 0.4896  decode.d5.loss_cls: 1.6494  decode.d5.loss_mask: 0.4626  decode.d5.loss_dice: 0.4677  decode.d6.loss_cls: 1.6140  decode.d6.loss_mask: 0.4494  decode.d6.loss_dice: 0.4175  decode.d7.loss_cls: 1.6478  decode.d7.loss_mask: 0.4417  decode.d7.loss_dice: 0.4245  decode.d8.loss_cls: 1.7273  decode.d8.loss_mask: 0.4853  decode.d8.loss_dice: 0.4700
08/06 02:33:57 - mmengine - INFO - Iter(train) [  2100/320000]  base_lr: 9.9409e-05 lr: 9.9409e-06  eta: 1 day, 19:18:43  time: 0.4891  data_time: 0.0104  memory: 5893  grad_norm: 398.7367  loss: 29.1872  decode.loss_cls: 1.6470  decode.loss_mask: 0.4558  decode.loss_dice: 0.4808  decode.d0.loss_cls: 3.2392  decode.d0.loss_mask: 0.6024  decode.d0.loss_dice: 0.6220  decode.d1.loss_cls: 1.8726  decode.d1.loss_mask: 0.5659  decode.d1.loss_dice: 0.5191  decode.d2.loss_cls: 1.6794  decode.d2.loss_mask: 0.5142  decode.d2.loss_dice: 0.4824  decode.d3.loss_cls: 1.6914  decode.d3.loss_mask: 0.5400  decode.d3.loss_dice: 0.5123  decode.d4.loss_cls: 1.7784  decode.d4.loss_mask: 0.4996  decode.d4.loss_dice: 0.4689  decode.d5.loss_cls: 1.7341  decode.d5.loss_mask: 0.5061  decode.d5.loss_dice: 0.5065  decode.d6.loss_cls: 1.6693  decode.d6.loss_mask: 0.5476  decode.d6.loss_dice: 0.5215  decode.d7.loss_cls: 1.7767  decode.d7.loss_mask: 0.5425  decode.d7.loss_dice: 0.5205  decode.d8.loss_cls: 1.6674  decode.d8.loss_mask: 0.5067  decode.d8.loss_dice: 0.5170
08/06 02:34:22 - mmengine - INFO - Iter(train) [  2150/320000]  base_lr: 9.9395e-05 lr: 9.9395e-06  eta: 1 day, 19:18:05  time: 0.4893  data_time: 0.0105  memory: 5966  grad_norm: 186.3238  loss: 28.1499  decode.loss_cls: 1.6328  decode.loss_mask: 0.4422  decode.loss_dice: 0.4947  decode.d0.loss_cls: 3.1457  decode.d0.loss_mask: 0.5589  decode.d0.loss_dice: 0.6711  decode.d1.loss_cls: 1.7770  decode.d1.loss_mask: 0.4406  decode.d1.loss_dice: 0.5123  decode.d2.loss_cls: 1.6500  decode.d2.loss_mask: 0.4743  decode.d2.loss_dice: 0.4853  decode.d3.loss_cls: 1.6006  decode.d3.loss_mask: 0.4528  decode.d3.loss_dice: 0.4963  decode.d4.loss_cls: 1.6039  decode.d4.loss_mask: 0.4702  decode.d4.loss_dice: 0.5310  decode.d5.loss_cls: 1.7158  decode.d5.loss_mask: 0.4204  decode.d5.loss_dice: 0.4930  decode.d6.loss_cls: 1.7331  decode.d6.loss_mask: 0.4399  decode.d6.loss_dice: 0.4929  decode.d7.loss_cls: 1.6685  decode.d7.loss_mask: 0.4744  decode.d7.loss_dice: 0.5130  decode.d8.loss_cls: 1.7466  decode.d8.loss_mask: 0.5029  decode.d8.loss_dice: 0.5096
08/06 02:34:46 - mmengine - INFO - Iter(train) [  2200/320000]  base_lr: 9.9381e-05 lr: 9.9381e-06  eta: 1 day, 19:17:31  time: 0.4896  data_time: 0.0104  memory: 5926  grad_norm: 204.1623  loss: 33.2008  decode.loss_cls: 2.0349  decode.loss_mask: 0.4823  decode.loss_dice: 0.5788  decode.d0.loss_cls: 3.3705  decode.d0.loss_mask: 0.5263  decode.d0.loss_dice: 0.7822  decode.d1.loss_cls: 2.2752  decode.d1.loss_mask: 0.4679  decode.d1.loss_dice: 0.5749  decode.d2.loss_cls: 2.0728  decode.d2.loss_mask: 0.4868  decode.d2.loss_dice: 0.5728  decode.d3.loss_cls: 2.0758  decode.d3.loss_mask: 0.4901  decode.d3.loss_dice: 0.5505  decode.d4.loss_cls: 2.0727  decode.d4.loss_mask: 0.5303  decode.d4.loss_dice: 0.6824  decode.d5.loss_cls: 2.1544  decode.d5.loss_mask: 0.4860  decode.d5.loss_dice: 0.5479  decode.d6.loss_cls: 2.0172  decode.d6.loss_mask: 0.4847  decode.d6.loss_dice: 0.5688  decode.d7.loss_cls: 2.1362  decode.d7.loss_mask: 0.4516  decode.d7.loss_dice: 0.5860  decode.d8.loss_cls: 2.0816  decode.d8.loss_mask: 0.4765  decode.d8.loss_dice: 0.5828
08/06 02:35:10 - mmengine - INFO - Iter(train) [  2250/320000]  base_lr: 9.9367e-05 lr: 9.9367e-06  eta: 1 day, 19:16:55  time: 0.4889  data_time: 0.0103  memory: 5907  grad_norm: 142.3921  loss: 26.2986  decode.loss_cls: 1.8108  decode.loss_mask: 0.3021  decode.loss_dice: 0.3800  decode.d0.loss_cls: 3.0044  decode.d0.loss_mask: 0.3510  decode.d0.loss_dice: 0.5197  decode.d1.loss_cls: 2.0005  decode.d1.loss_mask: 0.3047  decode.d1.loss_dice: 0.3878  decode.d2.loss_cls: 1.7248  decode.d2.loss_mask: 0.3051  decode.d2.loss_dice: 0.3764  decode.d3.loss_cls: 1.7339  decode.d3.loss_mask: 0.2921  decode.d3.loss_dice: 0.3773  decode.d4.loss_cls: 1.7100  decode.d4.loss_mask: 0.2977  decode.d4.loss_dice: 0.3743  decode.d5.loss_cls: 1.7910  decode.d5.loss_mask: 0.2973  decode.d5.loss_dice: 0.3721  decode.d6.loss_cls: 1.7737  decode.d6.loss_mask: 0.3075  decode.d6.loss_dice: 0.3896  decode.d7.loss_cls: 1.8367  decode.d7.loss_mask: 0.3018  decode.d7.loss_dice: 0.3921  decode.d8.loss_cls: 1.8550  decode.d8.loss_mask: 0.3285  decode.d8.loss_dice: 0.4007
08/06 02:35:35 - mmengine - INFO - Iter(train) [  2300/320000]  base_lr: 9.9353e-05 lr: 9.9353e-06  eta: 1 day, 19:16:17  time: 0.4878  data_time: 0.0102  memory: 5891  grad_norm: 153.0852  loss: 24.7043  decode.loss_cls: 1.5622  decode.loss_mask: 0.3023  decode.loss_dice: 0.4719  decode.d0.loss_cls: 2.8006  decode.d0.loss_mask: 0.3233  decode.d0.loss_dice: 0.5753  decode.d1.loss_cls: 1.6343  decode.d1.loss_mask: 0.3130  decode.d1.loss_dice: 0.4601  decode.d2.loss_cls: 1.5222  decode.d2.loss_mask: 0.3139  decode.d2.loss_dice: 0.4612  decode.d3.loss_cls: 1.5115  decode.d3.loss_mask: 0.3140  decode.d3.loss_dice: 0.4593  decode.d4.loss_cls: 1.5798  decode.d4.loss_mask: 0.2967  decode.d4.loss_dice: 0.4561  decode.d5.loss_cls: 1.6008  decode.d5.loss_mask: 0.2999  decode.d5.loss_dice: 0.4387  decode.d6.loss_cls: 1.5849  decode.d6.loss_mask: 0.3129  decode.d6.loss_dice: 0.4774  decode.d7.loss_cls: 1.5695  decode.d7.loss_mask: 0.3070  decode.d7.loss_dice: 0.4427  decode.d8.loss_cls: 1.5413  decode.d8.loss_mask: 0.3043  decode.d8.loss_dice: 0.4673
08/06 02:35:59 - mmengine - INFO - Iter(train) [  2350/320000]  base_lr: 9.9339e-05 lr: 9.9339e-06  eta: 1 day, 19:15:42  time: 0.4890  data_time: 0.0104  memory: 5966  grad_norm: 152.5126  loss: 25.7805  decode.loss_cls: 1.6825  decode.loss_mask: 0.3206  decode.loss_dice: 0.3610  decode.d0.loss_cls: 2.8596  decode.d0.loss_mask: 0.3930  decode.d0.loss_dice: 0.5111  decode.d1.loss_cls: 2.0085  decode.d1.loss_mask: 0.3287  decode.d1.loss_dice: 0.3719  decode.d2.loss_cls: 1.6679  decode.d2.loss_mask: 0.3302  decode.d2.loss_dice: 0.3553  decode.d3.loss_cls: 1.6844  decode.d3.loss_mask: 0.3241  decode.d3.loss_dice: 0.3607  decode.d4.loss_cls: 1.7159  decode.d4.loss_mask: 0.3271  decode.d4.loss_dice: 0.3773  decode.d5.loss_cls: 1.7857  decode.d5.loss_mask: 0.3348  decode.d5.loss_dice: 0.3639  decode.d6.loss_cls: 1.7198  decode.d6.loss_mask: 0.3437  decode.d6.loss_dice: 0.3849  decode.d7.loss_cls: 1.6592  decode.d7.loss_mask: 0.4116  decode.d7.loss_dice: 0.4007  decode.d8.loss_cls: 1.7012  decode.d8.loss_mask: 0.3284  decode.d8.loss_dice: 0.3665
08/06 02:36:24 - mmengine - INFO - Iter(train) [  2400/320000]  base_lr: 9.9325e-05 lr: 9.9325e-06  eta: 1 day, 19:15:06  time: 0.4891  data_time: 0.0101  memory: 5927  grad_norm: 151.8682  loss: 24.9119  decode.loss_cls: 1.6839  decode.loss_mask: 0.3583  decode.loss_dice: 0.3535  decode.d0.loss_cls: 2.6927  decode.d0.loss_mask: 0.3765  decode.d0.loss_dice: 0.4790  decode.d1.loss_cls: 1.8486  decode.d1.loss_mask: 0.3607  decode.d1.loss_dice: 0.3241  decode.d2.loss_cls: 1.6249  decode.d2.loss_mask: 0.3449  decode.d2.loss_dice: 0.3241  decode.d3.loss_cls: 1.5808  decode.d3.loss_mask: 0.3652  decode.d3.loss_dice: 0.3520  decode.d4.loss_cls: 1.6008  decode.d4.loss_mask: 0.3812  decode.d4.loss_dice: 0.3598  decode.d5.loss_cls: 1.7331  decode.d5.loss_mask: 0.3676  decode.d5.loss_dice: 0.3457  decode.d6.loss_cls: 1.6084  decode.d6.loss_mask: 0.3630  decode.d6.loss_dice: 0.3421  decode.d7.loss_cls: 1.6275  decode.d7.loss_mask: 0.3669  decode.d7.loss_dice: 0.3359  decode.d8.loss_cls: 1.6574  decode.d8.loss_mask: 0.3804  decode.d8.loss_dice: 0.3730
08/06 02:36:48 - mmengine - INFO - Iter(train) [  2450/320000]  base_lr: 9.9311e-05 lr: 9.9311e-06  eta: 1 day, 19:14:32  time: 0.4894  data_time: 0.0103  memory: 5892  grad_norm: 204.1460  loss: 29.6087  decode.loss_cls: 1.8941  decode.loss_mask: 0.3754  decode.loss_dice: 0.5854  decode.d0.loss_cls: 2.8222  decode.d0.loss_mask: 0.4569  decode.d0.loss_dice: 0.7347  decode.d1.loss_cls: 2.0123  decode.d1.loss_mask: 0.3880  decode.d1.loss_dice: 0.6229  decode.d2.loss_cls: 1.8519  decode.d2.loss_mask: 0.3632  decode.d2.loss_dice: 0.5897  decode.d3.loss_cls: 1.7968  decode.d3.loss_mask: 0.3622  decode.d3.loss_dice: 0.5436  decode.d4.loss_cls: 1.9163  decode.d4.loss_mask: 0.3637  decode.d4.loss_dice: 0.5720  decode.d5.loss_cls: 1.8833  decode.d5.loss_mask: 0.3462  decode.d5.loss_dice: 0.5713  decode.d6.loss_cls: 1.8849  decode.d6.loss_mask: 0.3738  decode.d6.loss_dice: 0.5813  decode.d7.loss_cls: 1.8434  decode.d7.loss_mask: 0.3911  decode.d7.loss_dice: 0.5749  decode.d8.loss_cls: 1.8556  decode.d8.loss_mask: 0.4324  decode.d8.loss_dice: 0.6194
08/06 02:37:13 - mmengine - INFO - Iter(train) [  2500/320000]  base_lr: 9.9297e-05 lr: 9.9297e-06  eta: 1 day, 19:14:14  time: 0.4882  data_time: 0.0102  memory: 5908  grad_norm: 191.6516  loss: 24.8897  decode.loss_cls: 1.6500  decode.loss_mask: 0.3660  decode.loss_dice: 0.3511  decode.d0.loss_cls: 2.7112  decode.d0.loss_mask: 0.4084  decode.d0.loss_dice: 0.4600  decode.d1.loss_cls: 1.8302  decode.d1.loss_mask: 0.3739  decode.d1.loss_dice: 0.3470  decode.d2.loss_cls: 1.6212  decode.d2.loss_mask: 0.3741  decode.d2.loss_dice: 0.3578  decode.d3.loss_cls: 1.6711  decode.d3.loss_mask: 0.3626  decode.d3.loss_dice: 0.3246  decode.d4.loss_cls: 1.6100  decode.d4.loss_mask: 0.3600  decode.d4.loss_dice: 0.3263  decode.d5.loss_cls: 1.6386  decode.d5.loss_mask: 0.3673  decode.d5.loss_dice: 0.3591  decode.d6.loss_cls: 1.6316  decode.d6.loss_mask: 0.3585  decode.d6.loss_dice: 0.3308  decode.d7.loss_cls: 1.6094  decode.d7.loss_mask: 0.3638  decode.d7.loss_dice: 0.3392  decode.d8.loss_cls: 1.6556  decode.d8.loss_mask: 0.3817  decode.d8.loss_dice: 0.3488
08/06 02:37:37 - mmengine - INFO - Iter(train) [  2550/320000]  base_lr: 9.9283e-05 lr: 9.9283e-06  eta: 1 day, 19:13:41  time: 0.4893  data_time: 0.0102  memory: 5891  grad_norm: 225.9841  loss: 26.9047  decode.loss_cls: 1.6731  decode.loss_mask: 0.3666  decode.loss_dice: 0.6003  decode.d0.loss_cls: 2.6492  decode.d0.loss_mask: 0.3460  decode.d0.loss_dice: 0.6880  decode.d1.loss_cls: 1.7945  decode.d1.loss_mask: 0.3435  decode.d1.loss_dice: 0.5836  decode.d2.loss_cls: 1.5380  decode.d2.loss_mask: 0.4108  decode.d2.loss_dice: 0.5616  decode.d3.loss_cls: 1.6316  decode.d3.loss_mask: 0.2936  decode.d3.loss_dice: 0.5378  decode.d4.loss_cls: 1.6491  decode.d4.loss_mask: 0.3187  decode.d4.loss_dice: 0.5575  decode.d5.loss_cls: 1.6994  decode.d5.loss_mask: 0.3427  decode.d5.loss_dice: 0.5954  decode.d6.loss_cls: 1.6722  decode.d6.loss_mask: 0.3327  decode.d6.loss_dice: 0.5565  decode.d7.loss_cls: 1.6879  decode.d7.loss_mask: 0.3393  decode.d7.loss_dice: 0.5635  decode.d8.loss_cls: 1.6530  decode.d8.loss_mask: 0.3465  decode.d8.loss_dice: 0.5723
08/06 02:38:02 - mmengine - INFO - Iter(train) [  2600/320000]  base_lr: 9.9269e-05 lr: 9.9269e-06  eta: 1 day, 19:13:10  time: 0.4895  data_time: 0.0102  memory: 5889  grad_norm: 267.8817  loss: 26.4292  decode.loss_cls: 1.6759  decode.loss_mask: 0.3712  decode.loss_dice: 0.4036  decode.d0.loss_cls: 2.7359  decode.d0.loss_mask: 0.4247  decode.d0.loss_dice: 0.5803  decode.d1.loss_cls: 2.1315  decode.d1.loss_mask: 0.3539  decode.d1.loss_dice: 0.4088  decode.d2.loss_cls: 1.7795  decode.d2.loss_mask: 0.3531  decode.d2.loss_dice: 0.4130  decode.d3.loss_cls: 1.7432  decode.d3.loss_mask: 0.3179  decode.d3.loss_dice: 0.3661  decode.d4.loss_cls: 1.7680  decode.d4.loss_mask: 0.3584  decode.d4.loss_dice: 0.3917  decode.d5.loss_cls: 1.7298  decode.d5.loss_mask: 0.3088  decode.d5.loss_dice: 0.3642  decode.d6.loss_cls: 1.7094  decode.d6.loss_mask: 0.3399  decode.d6.loss_dice: 0.3773  decode.d7.loss_cls: 1.7581  decode.d7.loss_mask: 0.3469  decode.d7.loss_dice: 0.3909  decode.d8.loss_cls: 1.7832  decode.d8.loss_mask: 0.3401  decode.d8.loss_dice: 0.4040
08/06 02:38:26 - mmengine - INFO - Iter(train) [  2650/320000]  base_lr: 9.9255e-05 lr: 9.9255e-06  eta: 1 day, 19:12:39  time: 0.4892  data_time: 0.0104  memory: 5907  grad_norm: 315.4468  loss: 26.9368  decode.loss_cls: 1.7116  decode.loss_mask: 0.4258  decode.loss_dice: 0.4693  decode.d0.loss_cls: 2.6809  decode.d0.loss_mask: 0.5490  decode.d0.loss_dice: 0.6185  decode.d1.loss_cls: 1.9337  decode.d1.loss_mask: 0.4138  decode.d1.loss_dice: 0.4560  decode.d2.loss_cls: 1.6801  decode.d2.loss_mask: 0.3903  decode.d2.loss_dice: 0.4097  decode.d3.loss_cls: 1.7547  decode.d3.loss_mask: 0.4545  decode.d3.loss_dice: 0.4339  decode.d4.loss_cls: 1.7224  decode.d4.loss_mask: 0.4015  decode.d4.loss_dice: 0.4205  decode.d5.loss_cls: 1.7593  decode.d5.loss_mask: 0.3969  decode.d5.loss_dice: 0.4249  decode.d6.loss_cls: 1.6570  decode.d6.loss_mask: 0.4000  decode.d6.loss_dice: 0.4264  decode.d7.loss_cls: 1.6240  decode.d7.loss_mask: 0.4143  decode.d7.loss_dice: 0.4272  decode.d8.loss_cls: 1.6949  decode.d8.loss_mask: 0.3764  decode.d8.loss_dice: 0.4093
08/06 02:38:51 - mmengine - INFO - Iter(train) [  2700/320000]  base_lr: 9.9241e-05 lr: 9.9241e-06  eta: 1 day, 19:12:08  time: 0.4883  data_time: 0.0103  memory: 5927  grad_norm: 182.4733  loss: 23.1331  decode.loss_cls: 1.4439  decode.loss_mask: 0.3372  decode.loss_dice: 0.3620  decode.d0.loss_cls: 2.4910  decode.d0.loss_mask: 0.3861  decode.d0.loss_dice: 0.4583  decode.d1.loss_cls: 1.8324  decode.d1.loss_mask: 0.3421  decode.d1.loss_dice: 0.3421  decode.d2.loss_cls: 1.4164  decode.d2.loss_mask: 0.3620  decode.d2.loss_dice: 0.3560  decode.d3.loss_cls: 1.4531  decode.d3.loss_mask: 0.3419  decode.d3.loss_dice: 0.3370  decode.d4.loss_cls: 1.5277  decode.d4.loss_mask: 0.3340  decode.d4.loss_dice: 0.3484  decode.d5.loss_cls: 1.4382  decode.d5.loss_mask: 0.4044  decode.d5.loss_dice: 0.3910  decode.d6.loss_cls: 1.4341  decode.d6.loss_mask: 0.3284  decode.d6.loss_dice: 0.3496  decode.d7.loss_cls: 1.4686  decode.d7.loss_mask: 0.3369  decode.d7.loss_dice: 0.3478  decode.d8.loss_cls: 1.4556  decode.d8.loss_mask: 0.3410  decode.d8.loss_dice: 0.3661
08/06 02:39:15 - mmengine - INFO - Iter(train) [  2750/320000]  base_lr: 9.9227e-05 lr: 9.9227e-06  eta: 1 day, 19:11:38  time: 0.4884  data_time: 0.0105  memory: 5874  grad_norm: 205.6069  loss: 24.9245  decode.loss_cls: 1.3566  decode.loss_mask: 0.5317  decode.loss_dice: 0.5813  decode.d0.loss_cls: 2.3453  decode.d0.loss_mask: 0.4807  decode.d0.loss_dice: 0.5775  decode.d1.loss_cls: 1.6104  decode.d1.loss_mask: 0.3943  decode.d1.loss_dice: 0.4448  decode.d2.loss_cls: 1.3684  decode.d2.loss_mask: 0.4104  decode.d2.loss_dice: 0.4683  decode.d3.loss_cls: 1.3803  decode.d3.loss_mask: 0.4010  decode.d3.loss_dice: 0.4651  decode.d4.loss_cls: 1.4665  decode.d4.loss_mask: 0.4239  decode.d4.loss_dice: 0.5050  decode.d5.loss_cls: 1.3664  decode.d5.loss_mask: 0.4953  decode.d5.loss_dice: 0.5327  decode.d6.loss_cls: 1.3474  decode.d6.loss_mask: 0.5388  decode.d6.loss_dice: 0.5712  decode.d7.loss_cls: 1.4392  decode.d7.loss_mask: 0.4750  decode.d7.loss_dice: 0.5219  decode.d8.loss_cls: 1.3257  decode.d8.loss_mask: 0.5051  decode.d8.loss_dice: 0.5942
08/06 02:39:39 - mmengine - INFO - Iter(train) [  2800/320000]  base_lr: 9.9212e-05 lr: 9.9212e-06  eta: 1 day, 19:11:07  time: 0.4888  data_time: 0.0104  memory: 5890  grad_norm: 224.1415  loss: 24.8726  decode.loss_cls: 1.4115  decode.loss_mask: 0.3711  decode.loss_dice: 0.4606  decode.d0.loss_cls: 2.3020  decode.d0.loss_mask: 0.4164  decode.d0.loss_dice: 0.6206  decode.d1.loss_cls: 1.6876  decode.d1.loss_mask: 0.3929  decode.d1.loss_dice: 0.5164  decode.d2.loss_cls: 1.4811  decode.d2.loss_mask: 0.3810  decode.d2.loss_dice: 0.4869  decode.d3.loss_cls: 1.4861  decode.d3.loss_mask: 0.3865  decode.d3.loss_dice: 0.4884  decode.d4.loss_cls: 1.5641  decode.d4.loss_mask: 0.3977  decode.d4.loss_dice: 0.4953  decode.d5.loss_cls: 1.4526  decode.d5.loss_mask: 0.3819  decode.d5.loss_dice: 0.4895  decode.d6.loss_cls: 1.4583  decode.d6.loss_mask: 0.4105  decode.d6.loss_dice: 0.5010  decode.d7.loss_cls: 1.6014  decode.d7.loss_mask: 0.3752  decode.d7.loss_dice: 0.4690  decode.d8.loss_cls: 1.5258  decode.d8.loss_mask: 0.3780  decode.d8.loss_dice: 0.4832
08/06 02:40:04 - mmengine - INFO - Iter(train) [  2850/320000]  base_lr: 9.9198e-05 lr: 9.9198e-06  eta: 1 day, 19:10:36  time: 0.4889  data_time: 0.0104  memory: 5891  grad_norm: 169.8307  loss: 25.0739  decode.loss_cls: 1.6178  decode.loss_mask: 0.3268  decode.loss_dice: 0.4455  decode.d0.loss_cls: 2.4776  decode.d0.loss_mask: 0.3897  decode.d0.loss_dice: 0.6760  decode.d1.loss_cls: 1.7318  decode.d1.loss_mask: 0.3212  decode.d1.loss_dice: 0.4714  decode.d2.loss_cls: 1.6191  decode.d2.loss_mask: 0.3169  decode.d2.loss_dice: 0.4483  decode.d3.loss_cls: 1.5881  decode.d3.loss_mask: 0.3201  decode.d3.loss_dice: 0.4268  decode.d4.loss_cls: 1.5930  decode.d4.loss_mask: 0.3210  decode.d4.loss_dice: 0.4525  decode.d5.loss_cls: 1.5568  decode.d5.loss_mask: 0.3141  decode.d5.loss_dice: 0.4633  decode.d6.loss_cls: 1.5853  decode.d6.loss_mask: 0.3287  decode.d6.loss_dice: 0.4513  decode.d7.loss_cls: 1.5301  decode.d7.loss_mask: 0.3415  decode.d7.loss_dice: 0.4517  decode.d8.loss_cls: 1.6351  decode.d8.loss_mask: 0.3842  decode.d8.loss_dice: 0.4880
08/06 02:40:28 - mmengine - INFO - Iter(train) [  2900/320000]  base_lr: 9.9184e-05 lr: 9.9184e-06  eta: 1 day, 19:10:07  time: 0.4882  data_time: 0.0105  memory: 5895  grad_norm: 284.8814  loss: 24.3241  decode.loss_cls: 1.3630  decode.loss_mask: 0.5006  decode.loss_dice: 0.4655  decode.d0.loss_cls: 2.3132  decode.d0.loss_mask: 0.4862  decode.d0.loss_dice: 0.5678  decode.d1.loss_cls: 1.6250  decode.d1.loss_mask: 0.5244  decode.d1.loss_dice: 0.4454  decode.d2.loss_cls: 1.3825  decode.d2.loss_mask: 0.4340  decode.d2.loss_dice: 0.4236  decode.d3.loss_cls: 1.3853  decode.d3.loss_mask: 0.4591  decode.d3.loss_dice: 0.4381  decode.d4.loss_cls: 1.4034  decode.d4.loss_mask: 0.4367  decode.d4.loss_dice: 0.4121  decode.d5.loss_cls: 1.3584  decode.d5.loss_mask: 0.4836  decode.d5.loss_dice: 0.4415  decode.d6.loss_cls: 1.3748  decode.d6.loss_mask: 0.4966  decode.d6.loss_dice: 0.4496  decode.d7.loss_cls: 1.3957  decode.d7.loss_mask: 0.4687  decode.d7.loss_dice: 0.4686  decode.d8.loss_cls: 1.3365  decode.d8.loss_mask: 0.5035  decode.d8.loss_dice: 0.4807
08/06 02:40:53 - mmengine - INFO - Iter(train) [  2950/320000]  base_lr: 9.9170e-05 lr: 9.9170e-06  eta: 1 day, 19:09:37  time: 0.4883  data_time: 0.0103  memory: 5908  grad_norm: 220.6300  loss: 23.1652  decode.loss_cls: 1.3440  decode.loss_mask: 0.4137  decode.loss_dice: 0.4278  decode.d0.loss_cls: 2.2879  decode.d0.loss_mask: 0.4081  decode.d0.loss_dice: 0.5833  decode.d1.loss_cls: 1.8299  decode.d1.loss_mask: 0.3356  decode.d1.loss_dice: 0.3718  decode.d2.loss_cls: 1.5195  decode.d2.loss_mask: 0.3036  decode.d2.loss_dice: 0.3587  decode.d3.loss_cls: 1.4843  decode.d3.loss_mask: 0.2892  decode.d3.loss_dice: 0.3694  decode.d4.loss_cls: 1.5354  decode.d4.loss_mask: 0.3228  decode.d4.loss_dice: 0.3782  decode.d5.loss_cls: 1.4137  decode.d5.loss_mask: 0.3044  decode.d5.loss_dice: 0.4060  decode.d6.loss_cls: 1.4357  decode.d6.loss_mask: 0.3309  decode.d6.loss_dice: 0.4296  decode.d7.loss_cls: 1.4161  decode.d7.loss_mask: 0.3153  decode.d7.loss_dice: 0.3833  decode.d8.loss_cls: 1.4419  decode.d8.loss_mask: 0.2997  decode.d8.loss_dice: 0.4255
08/06 02:41:17 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 02:41:17 - mmengine - INFO - Iter(train) [  3000/320000]  base_lr: 9.9156e-05 lr: 9.9156e-06  eta: 1 day, 19:09:16  time: 0.4884  data_time: 0.0101  memory: 5927  grad_norm: 1145.6733  loss: 26.2397  decode.loss_cls: 1.6354  decode.loss_mask: 0.4074  decode.loss_dice: 0.4477  decode.d0.loss_cls: 2.4744  decode.d0.loss_mask: 0.3977  decode.d0.loss_dice: 0.5203  decode.d1.loss_cls: 2.1715  decode.d1.loss_mask: 0.3315  decode.d1.loss_dice: 0.4078  decode.d2.loss_cls: 1.7137  decode.d2.loss_mask: 0.3164  decode.d2.loss_dice: 0.3749  decode.d3.loss_cls: 1.7596  decode.d3.loss_mask: 0.3459  decode.d3.loss_dice: 0.4226  decode.d4.loss_cls: 1.8366  decode.d4.loss_mask: 0.3469  decode.d4.loss_dice: 0.4015  decode.d5.loss_cls: 1.8536  decode.d5.loss_mask: 0.3305  decode.d5.loss_dice: 0.3833  decode.d6.loss_cls: 1.6504  decode.d6.loss_mask: 0.4025  decode.d6.loss_dice: 0.4092  decode.d7.loss_cls: 1.5690  decode.d7.loss_mask: 0.3817  decode.d7.loss_dice: 0.4583  decode.d8.loss_cls: 1.6672  decode.d8.loss_mask: 0.3727  decode.d8.loss_dice: 0.4493
08/06 02:41:42 - mmengine - INFO - Iter(train) [  3050/320000]  base_lr: 9.9142e-05 lr: 9.9142e-06  eta: 1 day, 19:08:44  time: 0.4894  data_time: 0.0104  memory: 5908  grad_norm: 159.0805  loss: 23.2984  decode.loss_cls: 1.4833  decode.loss_mask: 0.3198  decode.loss_dice: 0.3734  decode.d0.loss_cls: 2.4017  decode.d0.loss_mask: 0.3754  decode.d0.loss_dice: 0.5273  decode.d1.loss_cls: 1.8526  decode.d1.loss_mask: 0.3185  decode.d1.loss_dice: 0.3683  decode.d2.loss_cls: 1.5241  decode.d2.loss_mask: 0.3244  decode.d2.loss_dice: 0.3604  decode.d3.loss_cls: 1.5364  decode.d3.loss_mask: 0.2911  decode.d3.loss_dice: 0.3558  decode.d4.loss_cls: 1.5917  decode.d4.loss_mask: 0.3110  decode.d4.loss_dice: 0.3467  decode.d5.loss_cls: 1.5328  decode.d5.loss_mask: 0.3433  decode.d5.loss_dice: 0.3981  decode.d6.loss_cls: 1.4884  decode.d6.loss_mask: 0.2998  decode.d6.loss_dice: 0.3549  decode.d7.loss_cls: 1.4926  decode.d7.loss_mask: 0.3000  decode.d7.loss_dice: 0.3426  decode.d8.loss_cls: 1.4636  decode.d8.loss_mask: 0.2844  decode.d8.loss_dice: 0.3359
08/06 02:42:06 - mmengine - INFO - Iter(train) [  3100/320000]  base_lr: 9.9128e-05 lr: 9.9128e-06  eta: 1 day, 19:08:15  time: 0.4898  data_time: 0.0105  memory: 5890  grad_norm: 218.3266  loss: 23.2232  decode.loss_cls: 1.3029  decode.loss_mask: 0.4024  decode.loss_dice: 0.4316  decode.d0.loss_cls: 2.1680  decode.d0.loss_mask: 0.4297  decode.d0.loss_dice: 0.5438  decode.d1.loss_cls: 1.5117  decode.d1.loss_mask: 0.4608  decode.d1.loss_dice: 0.4558  decode.d2.loss_cls: 1.3194  decode.d2.loss_mask: 0.4262  decode.d2.loss_dice: 0.4488  decode.d3.loss_cls: 1.3444  decode.d3.loss_mask: 0.4154  decode.d3.loss_dice: 0.4464  decode.d4.loss_cls: 1.3803  decode.d4.loss_mask: 0.4236  decode.d4.loss_dice: 0.4840  decode.d5.loss_cls: 1.4205  decode.d5.loss_mask: 0.4056  decode.d5.loss_dice: 0.4670  decode.d6.loss_cls: 1.2756  decode.d6.loss_mask: 0.4024  decode.d6.loss_dice: 0.4558  decode.d7.loss_cls: 1.4403  decode.d7.loss_mask: 0.4029  decode.d7.loss_dice: 0.4364  decode.d8.loss_cls: 1.2792  decode.d8.loss_mask: 0.4085  decode.d8.loss_dice: 0.4336
08/06 02:42:31 - mmengine - INFO - Iter(train) [  3150/320000]  base_lr: 9.9114e-05 lr: 9.9114e-06  eta: 1 day, 19:07:43  time: 0.4879  data_time: 0.0102  memory: 5908  grad_norm: 351.0129  loss: 22.9536  decode.loss_cls: 1.3238  decode.loss_mask: 0.3745  decode.loss_dice: 0.4759  decode.d0.loss_cls: 2.0588  decode.d0.loss_mask: 0.3896  decode.d0.loss_dice: 0.5356  decode.d1.loss_cls: 1.5211  decode.d1.loss_mask: 0.3749  decode.d1.loss_dice: 0.4956  decode.d2.loss_cls: 1.2581  decode.d2.loss_mask: 0.3652  decode.d2.loss_dice: 0.4531  decode.d3.loss_cls: 1.2995  decode.d3.loss_mask: 0.3701  decode.d3.loss_dice: 0.4559  decode.d4.loss_cls: 1.3459  decode.d4.loss_mask: 0.3911  decode.d4.loss_dice: 0.4779  decode.d5.loss_cls: 1.3280  decode.d5.loss_mask: 0.3702  decode.d5.loss_dice: 0.4607  decode.d6.loss_cls: 1.2660  decode.d6.loss_mask: 0.3927  decode.d6.loss_dice: 0.5193  decode.d7.loss_cls: 1.3178  decode.d7.loss_mask: 0.3868  decode.d7.loss_dice: 0.6096  decode.d8.loss_cls: 1.3591  decode.d8.loss_mask: 0.3970  decode.d8.loss_dice: 0.5799
08/06 02:42:34 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 02:42:55 - mmengine - INFO - Iter(train) [  3200/320000]  base_lr: 9.9100e-05 lr: 9.9100e-06  eta: 1 day, 19:07:12  time: 0.4891  data_time: 0.0104  memory: 5890  grad_norm: 181.7991  loss: 25.7094  decode.loss_cls: 1.6149  decode.loss_mask: 0.4206  decode.loss_dice: 0.4325  decode.d0.loss_cls: 2.3439  decode.d0.loss_mask: 0.4386  decode.d0.loss_dice: 0.5393  decode.d1.loss_cls: 1.8374  decode.d1.loss_mask: 0.4291  decode.d1.loss_dice: 0.4912  decode.d2.loss_cls: 1.5371  decode.d2.loss_mask: 0.4296  decode.d2.loss_dice: 0.4651  decode.d3.loss_cls: 1.5923  decode.d3.loss_mask: 0.4165  decode.d3.loss_dice: 0.4781  decode.d4.loss_cls: 1.5525  decode.d4.loss_mask: 0.3975  decode.d4.loss_dice: 0.4390  decode.d5.loss_cls: 1.5752  decode.d5.loss_mask: 0.4154  decode.d5.loss_dice: 0.4685  decode.d6.loss_cls: 1.5030  decode.d6.loss_mask: 0.4595  decode.d6.loss_dice: 0.4909  decode.d7.loss_cls: 1.6275  decode.d7.loss_mask: 0.4010  decode.d7.loss_dice: 0.4567  decode.d8.loss_cls: 1.6237  decode.d8.loss_mask: 0.4131  decode.d8.loss_dice: 0.4198
08/06 02:43:20 - mmengine - INFO - Iter(train) [  3250/320000]  base_lr: 9.9086e-05 lr: 9.9086e-06  eta: 1 day, 19:06:41  time: 0.4892  data_time: 0.0102  memory: 5891  grad_norm: 255.8084  loss: 25.7576  decode.loss_cls: 1.5670  decode.loss_mask: 0.4531  decode.loss_dice: 0.4794  decode.d0.loss_cls: 2.3416  decode.d0.loss_mask: 0.4634  decode.d0.loss_dice: 0.5956  decode.d1.loss_cls: 1.8547  decode.d1.loss_mask: 0.4115  decode.d1.loss_dice: 0.4176  decode.d2.loss_cls: 1.5743  decode.d2.loss_mask: 0.3876  decode.d2.loss_dice: 0.3983  decode.d3.loss_cls: 1.5482  decode.d3.loss_mask: 0.4145  decode.d3.loss_dice: 0.4516  decode.d4.loss_cls: 1.6325  decode.d4.loss_mask: 0.3769  decode.d4.loss_dice: 0.4137  decode.d5.loss_cls: 1.5455  decode.d5.loss_mask: 0.3995  decode.d5.loss_dice: 0.4893  decode.d6.loss_cls: 1.6517  decode.d6.loss_mask: 0.3986  decode.d6.loss_dice: 0.4587  decode.d7.loss_cls: 1.6172  decode.d7.loss_mask: 0.4406  decode.d7.loss_dice: 0.4553  decode.d8.loss_cls: 1.6768  decode.d8.loss_mask: 0.3828  decode.d8.loss_dice: 0.4602
08/06 02:43:44 - mmengine - INFO - Iter(train) [  3300/320000]  base_lr: 9.9072e-05 lr: 9.9072e-06  eta: 1 day, 19:06:30  time: 0.4887  data_time: 0.0104  memory: 5910  grad_norm: 282.3649  loss: 23.1232  decode.loss_cls: 1.3298  decode.loss_mask: 0.3780  decode.loss_dice: 0.4058  decode.d0.loss_cls: 2.1830  decode.d0.loss_mask: 0.4322  decode.d0.loss_dice: 0.6332  decode.d1.loss_cls: 1.7653  decode.d1.loss_mask: 0.4174  decode.d1.loss_dice: 0.4633  decode.d2.loss_cls: 1.3564  decode.d2.loss_mask: 0.4305  decode.d2.loss_dice: 0.4214  decode.d3.loss_cls: 1.3386  decode.d3.loss_mask: 0.4014  decode.d3.loss_dice: 0.3510  decode.d4.loss_cls: 1.3947  decode.d4.loss_mask: 0.3886  decode.d4.loss_dice: 0.3911  decode.d5.loss_cls: 1.3916  decode.d5.loss_mask: 0.3769  decode.d5.loss_dice: 0.3741  decode.d6.loss_cls: 1.3784  decode.d6.loss_mask: 0.3724  decode.d6.loss_dice: 0.3844  decode.d7.loss_cls: 1.3320  decode.d7.loss_mask: 0.3841  decode.d7.loss_dice: 0.4064  decode.d8.loss_cls: 1.4080  decode.d8.loss_mask: 0.4076  decode.d8.loss_dice: 0.4256
08/06 02:44:09 - mmengine - INFO - Iter(train) [  3350/320000]  base_lr: 9.9058e-05 lr: 9.9058e-06  eta: 1 day, 19:06:01  time: 0.4888  data_time: 0.0106  memory: 5964  grad_norm: 344.4395  loss: 23.7475  decode.loss_cls: 1.3452  decode.loss_mask: 0.3946  decode.loss_dice: 0.4006  decode.d0.loss_cls: 2.0759  decode.d0.loss_mask: 0.4882  decode.d0.loss_dice: 0.6126  decode.d1.loss_cls: 1.7139  decode.d1.loss_mask: 0.4273  decode.d1.loss_dice: 0.4884  decode.d2.loss_cls: 1.4516  decode.d2.loss_mask: 0.4114  decode.d2.loss_dice: 0.4544  decode.d3.loss_cls: 1.4170  decode.d3.loss_mask: 0.4082  decode.d3.loss_dice: 0.4548  decode.d4.loss_cls: 1.4159  decode.d4.loss_mask: 0.4043  decode.d4.loss_dice: 0.4296  decode.d5.loss_cls: 1.3531  decode.d5.loss_mask: 0.4320  decode.d5.loss_dice: 0.4620  decode.d6.loss_cls: 1.3393  decode.d6.loss_mask: 0.4138  decode.d6.loss_dice: 0.4398  decode.d7.loss_cls: 1.3371  decode.d7.loss_mask: 0.4258  decode.d7.loss_dice: 0.4521  decode.d8.loss_cls: 1.4481  decode.d8.loss_mask: 0.3927  decode.d8.loss_dice: 0.4579
08/06 02:44:33 - mmengine - INFO - Iter(train) [  3400/320000]  base_lr: 9.9044e-05 lr: 9.9044e-06  eta: 1 day, 19:05:30  time: 0.4883  data_time: 0.0104  memory: 5892  grad_norm: 132.0581  loss: 20.1197  decode.loss_cls: 1.1540  decode.loss_mask: 0.3379  decode.loss_dice: 0.4425  decode.d0.loss_cls: 1.9767  decode.d0.loss_mask: 0.3420  decode.d0.loss_dice: 0.4561  decode.d1.loss_cls: 1.4251  decode.d1.loss_mask: 0.3514  decode.d1.loss_dice: 0.3798  decode.d2.loss_cls: 1.1883  decode.d2.loss_mask: 0.3492  decode.d2.loss_dice: 0.3651  decode.d3.loss_cls: 1.1775  decode.d3.loss_mask: 0.3740  decode.d3.loss_dice: 0.3670  decode.d4.loss_cls: 1.2638  decode.d4.loss_mask: 0.3330  decode.d4.loss_dice: 0.3934  decode.d5.loss_cls: 1.1957  decode.d5.loss_mask: 0.3192  decode.d5.loss_dice: 0.3633  decode.d6.loss_cls: 1.0936  decode.d6.loss_mask: 0.3279  decode.d6.loss_dice: 0.3625  decode.d7.loss_cls: 1.1832  decode.d7.loss_mask: 0.3287  decode.d7.loss_dice: 0.3542  decode.d8.loss_cls: 1.2078  decode.d8.loss_mask: 0.3237  decode.d8.loss_dice: 0.3832
08/06 02:44:58 - mmengine - INFO - Iter(train) [  3450/320000]  base_lr: 9.9029e-05 lr: 9.9029e-06  eta: 1 day, 19:05:00  time: 0.4894  data_time: 0.0104  memory: 5889  grad_norm: 279.4266  loss: 19.2227  decode.loss_cls: 1.0905  decode.loss_mask: 0.3140  decode.loss_dice: 0.3731  decode.d0.loss_cls: 2.0046  decode.d0.loss_mask: 0.3628  decode.d0.loss_dice: 0.5189  decode.d1.loss_cls: 1.4435  decode.d1.loss_mask: 0.3170  decode.d1.loss_dice: 0.3802  decode.d2.loss_cls: 1.1207  decode.d2.loss_mask: 0.3290  decode.d2.loss_dice: 0.3894  decode.d3.loss_cls: 1.0746  decode.d3.loss_mask: 0.3180  decode.d3.loss_dice: 0.3582  decode.d4.loss_cls: 0.9924  decode.d4.loss_mask: 0.3284  decode.d4.loss_dice: 0.4036  decode.d5.loss_cls: 1.0571  decode.d5.loss_mask: 0.3293  decode.d5.loss_dice: 0.3668  decode.d6.loss_cls: 1.0578  decode.d6.loss_mask: 0.3378  decode.d6.loss_dice: 0.3521  decode.d7.loss_cls: 1.0674  decode.d7.loss_mask: 0.3480  decode.d7.loss_dice: 0.3787  decode.d8.loss_cls: 1.0776  decode.d8.loss_mask: 0.3419  decode.d8.loss_dice: 0.3895
08/06 02:45:22 - mmengine - INFO - Iter(train) [  3500/320000]  base_lr: 9.9015e-05 lr: 9.9015e-06  eta: 1 day, 19:04:31  time: 0.4891  data_time: 0.0102  memory: 5966  grad_norm: 165.3104  loss: 21.4818  decode.loss_cls: 1.2454  decode.loss_mask: 0.3148  decode.loss_dice: 0.3705  decode.d0.loss_cls: 2.1193  decode.d0.loss_mask: 0.3617  decode.d0.loss_dice: 0.4722  decode.d1.loss_cls: 1.5773  decode.d1.loss_mask: 0.3045  decode.d1.loss_dice: 0.3481  decode.d2.loss_cls: 1.4195  decode.d2.loss_mask: 0.3055  decode.d2.loss_dice: 0.3647  decode.d3.loss_cls: 1.2987  decode.d3.loss_mask: 0.3051  decode.d3.loss_dice: 0.3675  decode.d4.loss_cls: 1.4490  decode.d4.loss_mask: 0.3162  decode.d4.loss_dice: 0.3462  decode.d5.loss_cls: 1.3985  decode.d5.loss_mask: 0.3035  decode.d5.loss_dice: 0.3577  decode.d6.loss_cls: 1.3869  decode.d6.loss_mask: 0.2829  decode.d6.loss_dice: 0.3442  decode.d7.loss_cls: 1.3883  decode.d7.loss_mask: 0.3198  decode.d7.loss_dice: 0.3822  decode.d8.loss_cls: 1.2869  decode.d8.loss_mask: 0.3533  decode.d8.loss_dice: 0.3910
08/06 02:45:46 - mmengine - INFO - Iter(train) [  3550/320000]  base_lr: 9.9001e-05 lr: 9.9001e-06  eta: 1 day, 19:04:02  time: 0.4891  data_time: 0.0104  memory: 5926  grad_norm: 174.9728  loss: 22.7476  decode.loss_cls: 1.3326  decode.loss_mask: 0.3328  decode.loss_dice: 0.4869  decode.d0.loss_cls: 2.0725  decode.d0.loss_mask: 0.3851  decode.d0.loss_dice: 0.5877  decode.d1.loss_cls: 1.6762  decode.d1.loss_mask: 0.3070  decode.d1.loss_dice: 0.4770  decode.d2.loss_cls: 1.3816  decode.d2.loss_mask: 0.3348  decode.d2.loss_dice: 0.4731  decode.d3.loss_cls: 1.4020  decode.d3.loss_mask: 0.3189  decode.d3.loss_dice: 0.4849  decode.d4.loss_cls: 1.3760  decode.d4.loss_mask: 0.3207  decode.d4.loss_dice: 0.4748  decode.d5.loss_cls: 1.3466  decode.d5.loss_mask: 0.3161  decode.d5.loss_dice: 0.4916  decode.d6.loss_cls: 1.3487  decode.d6.loss_mask: 0.3059  decode.d6.loss_dice: 0.4621  decode.d7.loss_cls: 1.3508  decode.d7.loss_mask: 0.3242  decode.d7.loss_dice: 0.4840  decode.d8.loss_cls: 1.3190  decode.d8.loss_mask: 0.3150  decode.d8.loss_dice: 0.4590
08/06 02:46:11 - mmengine - INFO - Iter(train) [  3600/320000]  base_lr: 9.8987e-05 lr: 9.8987e-06  eta: 1 day, 19:03:31  time: 0.4889  data_time: 0.0104  memory: 5859  grad_norm: 212.5244  loss: 21.9153  decode.loss_cls: 1.2540  decode.loss_mask: 0.4010  decode.loss_dice: 0.4563  decode.d0.loss_cls: 2.0218  decode.d0.loss_mask: 0.4288  decode.d0.loss_dice: 0.4985  decode.d1.loss_cls: 1.5923  decode.d1.loss_mask: 0.4011  decode.d1.loss_dice: 0.4027  decode.d2.loss_cls: 1.3005  decode.d2.loss_mask: 0.3763  decode.d2.loss_dice: 0.3966  decode.d3.loss_cls: 1.2730  decode.d3.loss_mask: 0.3797  decode.d3.loss_dice: 0.3725  decode.d4.loss_cls: 1.2583  decode.d4.loss_mask: 0.3878  decode.d4.loss_dice: 0.4112  decode.d5.loss_cls: 1.2530  decode.d5.loss_mask: 0.3891  decode.d5.loss_dice: 0.4121  decode.d6.loss_cls: 1.2914  decode.d6.loss_mask: 0.3874  decode.d6.loss_dice: 0.3977  decode.d7.loss_cls: 1.3281  decode.d7.loss_mask: 0.4099  decode.d7.loss_dice: 0.3925  decode.d8.loss_cls: 1.2262  decode.d8.loss_mask: 0.4130  decode.d8.loss_dice: 0.4026
08/06 02:46:35 - mmengine - INFO - Iter(train) [  3650/320000]  base_lr: 9.8973e-05 lr: 9.8973e-06  eta: 1 day, 19:03:02  time: 0.4899  data_time: 0.0104  memory: 5926  grad_norm: 177.9080  loss: 22.5298  decode.loss_cls: 1.3364  decode.loss_mask: 0.3362  decode.loss_dice: 0.4238  decode.d0.loss_cls: 2.0390  decode.d0.loss_mask: 0.3706  decode.d0.loss_dice: 0.5510  decode.d1.loss_cls: 1.7035  decode.d1.loss_mask: 0.3730  decode.d1.loss_dice: 0.4126  decode.d2.loss_cls: 1.3892  decode.d2.loss_mask: 0.3225  decode.d2.loss_dice: 0.4507  decode.d3.loss_cls: 1.4410  decode.d3.loss_mask: 0.3078  decode.d3.loss_dice: 0.4139  decode.d4.loss_cls: 1.4338  decode.d4.loss_mask: 0.3450  decode.d4.loss_dice: 0.3949  decode.d5.loss_cls: 1.4217  decode.d5.loss_mask: 0.3266  decode.d5.loss_dice: 0.4178  decode.d6.loss_cls: 1.3381  decode.d6.loss_mask: 0.3244  decode.d6.loss_dice: 0.4146  decode.d7.loss_cls: 1.4184  decode.d7.loss_mask: 0.3265  decode.d7.loss_dice: 0.4242  decode.d8.loss_cls: 1.3073  decode.d8.loss_mask: 0.3398  decode.d8.loss_dice: 0.4254
08/06 02:47:00 - mmengine - INFO - Iter(train) [  3700/320000]  base_lr: 9.8959e-05 lr: 9.8959e-06  eta: 1 day, 19:02:32  time: 0.4895  data_time: 0.0105  memory: 5892  grad_norm: 211.6209  loss: 23.9056  decode.loss_cls: 1.4134  decode.loss_mask: 0.3614  decode.loss_dice: 0.4126  decode.d0.loss_cls: 2.4066  decode.d0.loss_mask: 0.4565  decode.d0.loss_dice: 0.5694  decode.d1.loss_cls: 1.8833  decode.d1.loss_mask: 0.3357  decode.d1.loss_dice: 0.3435  decode.d2.loss_cls: 1.5252  decode.d2.loss_mask: 0.3391  decode.d2.loss_dice: 0.3768  decode.d3.loss_cls: 1.5265  decode.d3.loss_mask: 0.3531  decode.d3.loss_dice: 0.3424  decode.d4.loss_cls: 1.5506  decode.d4.loss_mask: 0.3232  decode.d4.loss_dice: 0.3868  decode.d5.loss_cls: 1.5338  decode.d5.loss_mask: 0.3325  decode.d5.loss_dice: 0.4007  decode.d6.loss_cls: 1.5161  decode.d6.loss_mask: 0.3240  decode.d6.loss_dice: 0.3762  decode.d7.loss_cls: 1.5012  decode.d7.loss_mask: 0.3325  decode.d7.loss_dice: 0.3817  decode.d8.loss_cls: 1.5802  decode.d8.loss_mask: 0.3466  decode.d8.loss_dice: 0.3742
08/06 02:47:24 - mmengine - INFO - Iter(train) [  3750/320000]  base_lr: 9.8945e-05 lr: 9.8945e-06  eta: 1 day, 19:02:03  time: 0.4893  data_time: 0.0104  memory: 5892  grad_norm: 187.6879  loss: 20.6509  decode.loss_cls: 1.1435  decode.loss_mask: 0.3638  decode.loss_dice: 0.3951  decode.d0.loss_cls: 2.0339  decode.d0.loss_mask: 0.3193  decode.d0.loss_dice: 0.4691  decode.d1.loss_cls: 1.5729  decode.d1.loss_mask: 0.3214  decode.d1.loss_dice: 0.4054  decode.d2.loss_cls: 1.2448  decode.d2.loss_mask: 0.3157  decode.d2.loss_dice: 0.3979  decode.d3.loss_cls: 1.1497  decode.d3.loss_mask: 0.3332  decode.d3.loss_dice: 0.3940  decode.d4.loss_cls: 1.2016  decode.d4.loss_mask: 0.3318  decode.d4.loss_dice: 0.4009  decode.d5.loss_cls: 1.2356  decode.d5.loss_mask: 0.3383  decode.d5.loss_dice: 0.3978  decode.d6.loss_cls: 1.1985  decode.d6.loss_mask: 0.3419  decode.d6.loss_dice: 0.3946  decode.d7.loss_cls: 1.2297  decode.d7.loss_mask: 0.3348  decode.d7.loss_dice: 0.3842  decode.d8.loss_cls: 1.2478  decode.d8.loss_mask: 0.3471  decode.d8.loss_dice: 0.4068
08/06 02:47:49 - mmengine - INFO - Iter(train) [  3800/320000]  base_lr: 9.8931e-05 lr: 9.8931e-06  eta: 1 day, 19:01:33  time: 0.4882  data_time: 0.0102  memory: 5926  grad_norm: 273.6805  loss: 21.8865  decode.loss_cls: 1.1884  decode.loss_mask: 0.3679  decode.loss_dice: 0.5250  decode.d0.loss_cls: 2.0408  decode.d0.loss_mask: 0.4546  decode.d0.loss_dice: 0.6149  decode.d1.loss_cls: 1.5985  decode.d1.loss_mask: 0.4323  decode.d1.loss_dice: 0.5305  decode.d2.loss_cls: 1.1800  decode.d2.loss_mask: 0.3763  decode.d2.loss_dice: 0.5062  decode.d3.loss_cls: 1.1517  decode.d3.loss_mask: 0.3838  decode.d3.loss_dice: 0.4686  decode.d4.loss_cls: 1.2857  decode.d4.loss_mask: 0.3547  decode.d4.loss_dice: 0.4838  decode.d5.loss_cls: 1.2056  decode.d5.loss_mask: 0.3292  decode.d5.loss_dice: 0.4878  decode.d6.loss_cls: 1.0971  decode.d6.loss_mask: 0.3240  decode.d6.loss_dice: 0.4527  decode.d7.loss_cls: 1.1842  decode.d7.loss_mask: 0.3544  decode.d7.loss_dice: 0.4839  decode.d8.loss_cls: 1.1962  decode.d8.loss_mask: 0.3595  decode.d8.loss_dice: 0.4681
08/06 02:48:13 - mmengine - INFO - Iter(train) [  3850/320000]  base_lr: 9.8917e-05 lr: 9.8917e-06  eta: 1 day, 19:01:04  time: 0.4884  data_time: 0.0104  memory: 5907  grad_norm: 348.8780  loss: 23.0967  decode.loss_cls: 1.2293  decode.loss_mask: 0.5221  decode.loss_dice: 0.4757  decode.d0.loss_cls: 2.1028  decode.d0.loss_mask: 0.4957  decode.d0.loss_dice: 0.5012  decode.d1.loss_cls: 1.5974  decode.d1.loss_mask: 0.4578  decode.d1.loss_dice: 0.4607  decode.d2.loss_cls: 1.2418  decode.d2.loss_mask: 0.4588  decode.d2.loss_dice: 0.4429  decode.d3.loss_cls: 1.2253  decode.d3.loss_mask: 0.4927  decode.d3.loss_dice: 0.4392  decode.d4.loss_cls: 1.1748  decode.d4.loss_mask: 0.4822  decode.d4.loss_dice: 0.4487  decode.d5.loss_cls: 1.3404  decode.d5.loss_mask: 0.5078  decode.d5.loss_dice: 0.4174  decode.d6.loss_cls: 1.3069  decode.d6.loss_mask: 0.4757  decode.d6.loss_dice: 0.4048  decode.d7.loss_cls: 1.3475  decode.d7.loss_mask: 0.4720  decode.d7.loss_dice: 0.4302  decode.d8.loss_cls: 1.2303  decode.d8.loss_mask: 0.4661  decode.d8.loss_dice: 0.4486
08/06 02:48:38 - mmengine - INFO - Iter(train) [  3900/320000]  base_lr: 9.8903e-05 lr: 9.8903e-06  eta: 1 day, 19:00:45  time: 0.4886  data_time: 0.0104  memory: 5892  grad_norm: 167.2469  loss: 21.0490  decode.loss_cls: 1.1490  decode.loss_mask: 0.3875  decode.loss_dice: 0.5028  decode.d0.loss_cls: 1.8980  decode.d0.loss_mask: 0.3710  decode.d0.loss_dice: 0.5574  decode.d1.loss_cls: 1.4530  decode.d1.loss_mask: 0.3400  decode.d1.loss_dice: 0.4446  decode.d2.loss_cls: 1.1399  decode.d2.loss_mask: 0.3380  decode.d2.loss_dice: 0.4633  decode.d3.loss_cls: 1.1074  decode.d3.loss_mask: 0.3433  decode.d3.loss_dice: 0.4774  decode.d4.loss_cls: 1.1430  decode.d4.loss_mask: 0.3380  decode.d4.loss_dice: 0.4668  decode.d5.loss_cls: 1.1347  decode.d5.loss_mask: 0.3528  decode.d5.loss_dice: 0.4694  decode.d6.loss_cls: 1.2014  decode.d6.loss_mask: 0.3383  decode.d6.loss_dice: 0.4840  decode.d7.loss_cls: 1.2742  decode.d7.loss_mask: 0.3486  decode.d7.loss_dice: 0.4757  decode.d8.loss_cls: 1.1753  decode.d8.loss_mask: 0.3642  decode.d8.loss_dice: 0.5099
08/06 02:49:02 - mmengine - INFO - Iter(train) [  3950/320000]  base_lr: 9.8889e-05 lr: 9.8889e-06  eta: 1 day, 19:00:17  time: 0.4884  data_time: 0.0103  memory: 5892  grad_norm: 183.9543  loss: 20.8069  decode.loss_cls: 1.1854  decode.loss_mask: 0.3228  decode.loss_dice: 0.4176  decode.d0.loss_cls: 2.0883  decode.d0.loss_mask: 0.3590  decode.d0.loss_dice: 0.4975  decode.d1.loss_cls: 1.6328  decode.d1.loss_mask: 0.3343  decode.d1.loss_dice: 0.4536  decode.d2.loss_cls: 1.1820  decode.d2.loss_mask: 0.3162  decode.d2.loss_dice: 0.4087  decode.d3.loss_cls: 1.1665  decode.d3.loss_mask: 0.3169  decode.d3.loss_dice: 0.3890  decode.d4.loss_cls: 1.3273  decode.d4.loss_mask: 0.3244  decode.d4.loss_dice: 0.4101  decode.d5.loss_cls: 1.1980  decode.d5.loss_mask: 0.3278  decode.d5.loss_dice: 0.4146  decode.d6.loss_cls: 1.1495  decode.d6.loss_mask: 0.3406  decode.d6.loss_dice: 0.4232  decode.d7.loss_cls: 1.2115  decode.d7.loss_mask: 0.3185  decode.d7.loss_dice: 0.4140  decode.d8.loss_cls: 1.1384  decode.d8.loss_mask: 0.3301  decode.d8.loss_dice: 0.4083
08/06 02:49:26 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 02:49:26 - mmengine - INFO - Iter(train) [  4000/320000]  base_lr: 9.8875e-05 lr: 9.8875e-06  eta: 1 day, 18:59:48  time: 0.4886  data_time: 0.0103  memory: 5890  grad_norm: 254.1363  loss: 17.2962  decode.loss_cls: 0.8638  decode.loss_mask: 0.3656  decode.loss_dice: 0.3921  decode.d0.loss_cls: 1.7523  decode.d0.loss_mask: 0.3991  decode.d0.loss_dice: 0.4776  decode.d1.loss_cls: 1.1429  decode.d1.loss_mask: 0.3635  decode.d1.loss_dice: 0.4454  decode.d2.loss_cls: 0.8195  decode.d2.loss_mask: 0.3643  decode.d2.loss_dice: 0.4101  decode.d3.loss_cls: 0.8156  decode.d3.loss_mask: 0.3569  decode.d3.loss_dice: 0.4001  decode.d4.loss_cls: 0.8014  decode.d4.loss_mask: 0.3749  decode.d4.loss_dice: 0.4022  decode.d5.loss_cls: 0.8619  decode.d5.loss_mask: 0.3612  decode.d5.loss_dice: 0.3977  decode.d6.loss_cls: 0.7971  decode.d6.loss_mask: 0.3638  decode.d6.loss_dice: 0.4006  decode.d7.loss_cls: 0.7773  decode.d7.loss_mask: 0.3612  decode.d7.loss_dice: 0.4050  decode.d8.loss_cls: 0.8818  decode.d8.loss_mask: 0.3534  decode.d8.loss_dice: 0.3879
08/06 02:49:51 - mmengine - INFO - Iter(train) [  4050/320000]  base_lr: 9.8860e-05 lr: 9.8860e-06  eta: 1 day, 18:59:21  time: 0.4890  data_time: 0.0102  memory: 5890  grad_norm: 182.5730  loss: 21.7382  decode.loss_cls: 1.4039  decode.loss_mask: 0.2578  decode.loss_dice: 0.4254  decode.d0.loss_cls: 2.3054  decode.d0.loss_mask: 0.2931  decode.d0.loss_dice: 0.5088  decode.d1.loss_cls: 1.7507  decode.d1.loss_mask: 0.2587  decode.d1.loss_dice: 0.4192  decode.d2.loss_cls: 1.4147  decode.d2.loss_mask: 0.2410  decode.d2.loss_dice: 0.3900  decode.d3.loss_cls: 1.3119  decode.d3.loss_mask: 0.2438  decode.d3.loss_dice: 0.3730  decode.d4.loss_cls: 1.4439  decode.d4.loss_mask: 0.2391  decode.d4.loss_dice: 0.4052  decode.d5.loss_cls: 1.4338  decode.d5.loss_mask: 0.2326  decode.d5.loss_dice: 0.4080  decode.d6.loss_cls: 1.3453  decode.d6.loss_mask: 0.2356  decode.d6.loss_dice: 0.3944  decode.d7.loss_cls: 1.2949  decode.d7.loss_mask: 0.2348  decode.d7.loss_dice: 0.3934  decode.d8.loss_cls: 1.4285  decode.d8.loss_mask: 0.2525  decode.d8.loss_dice: 0.3984
08/06 02:50:15 - mmengine - INFO - Iter(train) [  4100/320000]  base_lr: 9.8846e-05 lr: 9.8846e-06  eta: 1 day, 18:58:53  time: 0.4885  data_time: 0.0104  memory: 5877  grad_norm: 223.1309  loss: 19.0051  decode.loss_cls: 1.0934  decode.loss_mask: 0.2815  decode.loss_dice: 0.3986  decode.d0.loss_cls: 1.8341  decode.d0.loss_mask: 0.2994  decode.d0.loss_dice: 0.4965  decode.d1.loss_cls: 1.3150  decode.d1.loss_mask: 0.2867  decode.d1.loss_dice: 0.3742  decode.d2.loss_cls: 1.1869  decode.d2.loss_mask: 0.2775  decode.d2.loss_dice: 0.3764  decode.d3.loss_cls: 1.1131  decode.d3.loss_mask: 0.2758  decode.d3.loss_dice: 0.3431  decode.d4.loss_cls: 1.1507  decode.d4.loss_mask: 0.3012  decode.d4.loss_dice: 0.3719  decode.d5.loss_cls: 1.1297  decode.d5.loss_mask: 0.2939  decode.d5.loss_dice: 0.4054  decode.d6.loss_cls: 1.1523  decode.d6.loss_mask: 0.2766  decode.d6.loss_dice: 0.3564  decode.d7.loss_cls: 1.1456  decode.d7.loss_mask: 0.2861  decode.d7.loss_dice: 0.3930  decode.d8.loss_cls: 1.1475  decode.d8.loss_mask: 0.2815  decode.d8.loss_dice: 0.3611
08/06 02:50:40 - mmengine - INFO - Iter(train) [  4150/320000]  base_lr: 9.8832e-05 lr: 9.8832e-06  eta: 1 day, 18:58:27  time: 0.4898  data_time: 0.0102  memory: 5907  grad_norm: 254.7690  loss: 23.2949  decode.loss_cls: 1.1320  decode.loss_mask: 0.4580  decode.loss_dice: 0.5081  decode.d0.loss_cls: 2.1164  decode.d0.loss_mask: 0.5190  decode.d0.loss_dice: 0.6150  decode.d1.loss_cls: 1.4900  decode.d1.loss_mask: 0.4918  decode.d1.loss_dice: 0.5717  decode.d2.loss_cls: 1.2780  decode.d2.loss_mask: 0.4701  decode.d2.loss_dice: 0.5133  decode.d3.loss_cls: 1.1990  decode.d3.loss_mask: 0.4702  decode.d3.loss_dice: 0.5176  decode.d4.loss_cls: 1.1826  decode.d4.loss_mask: 0.4941  decode.d4.loss_dice: 0.5253  decode.d5.loss_cls: 1.1829  decode.d5.loss_mask: 0.5544  decode.d5.loss_dice: 0.5571  decode.d6.loss_cls: 1.1690  decode.d6.loss_mask: 0.4770  decode.d6.loss_dice: 0.5290  decode.d7.loss_cls: 1.1641  decode.d7.loss_mask: 0.4852  decode.d7.loss_dice: 0.5431  decode.d8.loss_cls: 1.1191  decode.d8.loss_mask: 0.4671  decode.d8.loss_dice: 0.4945
08/06 02:51:04 - mmengine - INFO - Iter(train) [  4200/320000]  base_lr: 9.8818e-05 lr: 9.8818e-06  eta: 1 day, 18:58:03  time: 0.4901  data_time: 0.0100  memory: 5908  grad_norm: 212.7129  loss: 17.3343  decode.loss_cls: 0.9642  decode.loss_mask: 0.2706  decode.loss_dice: 0.3651  decode.d0.loss_cls: 1.8688  decode.d0.loss_mask: 0.2628  decode.d0.loss_dice: 0.3483  decode.d1.loss_cls: 1.2089  decode.d1.loss_mask: 0.2947  decode.d1.loss_dice: 0.4069  decode.d2.loss_cls: 0.9150  decode.d2.loss_mask: 0.2858  decode.d2.loss_dice: 0.4144  decode.d3.loss_cls: 0.8531  decode.d3.loss_mask: 0.3317  decode.d3.loss_dice: 0.4161  decode.d4.loss_cls: 0.8912  decode.d4.loss_mask: 0.3080  decode.d4.loss_dice: 0.3922  decode.d5.loss_cls: 0.8923  decode.d5.loss_mask: 0.2945  decode.d5.loss_dice: 0.4058  decode.d6.loss_cls: 0.8617  decode.d6.loss_mask: 0.3187  decode.d6.loss_dice: 0.4487  decode.d7.loss_cls: 0.9104  decode.d7.loss_mask: 0.3372  decode.d7.loss_dice: 0.4751  decode.d8.loss_cls: 0.8950  decode.d8.loss_mask: 0.2914  decode.d8.loss_dice: 0.4055
08/06 02:51:29 - mmengine - INFO - Iter(train) [  4250/320000]  base_lr: 9.8804e-05 lr: 9.8804e-06  eta: 1 day, 18:57:38  time: 0.4893  data_time: 0.0101  memory: 5890  grad_norm: 156.1043  loss: 15.7030  decode.loss_cls: 0.7808  decode.loss_mask: 0.3097  decode.loss_dice: 0.3637  decode.d0.loss_cls: 1.6995  decode.d0.loss_mask: 0.3255  decode.d0.loss_dice: 0.4296  decode.d1.loss_cls: 0.9951  decode.d1.loss_mask: 0.3104  decode.d1.loss_dice: 0.3895  decode.d2.loss_cls: 0.7619  decode.d2.loss_mask: 0.3024  decode.d2.loss_dice: 0.3798  decode.d3.loss_cls: 0.7482  decode.d3.loss_mask: 0.2973  decode.d3.loss_dice: 0.3634  decode.d4.loss_cls: 0.7176  decode.d4.loss_mask: 0.3113  decode.d4.loss_dice: 0.3749  decode.d5.loss_cls: 0.7595  decode.d5.loss_mask: 0.3024  decode.d5.loss_dice: 0.3728  decode.d6.loss_cls: 0.7762  decode.d6.loss_mask: 0.2991  decode.d6.loss_dice: 0.3792  decode.d7.loss_cls: 0.7533  decode.d7.loss_mask: 0.3068  decode.d7.loss_dice: 0.3551  decode.d8.loss_cls: 0.8550  decode.d8.loss_mask: 0.3118  decode.d8.loss_dice: 0.3713
08/06 02:51:53 - mmengine - INFO - Iter(train) [  4300/320000]  base_lr: 9.8790e-05 lr: 9.8790e-06  eta: 1 day, 18:57:13  time: 0.4899  data_time: 0.0101  memory: 5907  grad_norm: 150.5903  loss: 18.8288  decode.loss_cls: 1.1572  decode.loss_mask: 0.2700  decode.loss_dice: 0.3579  decode.d0.loss_cls: 2.0551  decode.d0.loss_mask: 0.2774  decode.d0.loss_dice: 0.3912  decode.d1.loss_cls: 1.5064  decode.d1.loss_mask: 0.2471  decode.d1.loss_dice: 0.3140  decode.d2.loss_cls: 1.1274  decode.d2.loss_mask: 0.2489  decode.d2.loss_dice: 0.3336  decode.d3.loss_cls: 1.1672  decode.d3.loss_mask: 0.2570  decode.d3.loss_dice: 0.3596  decode.d4.loss_cls: 1.1897  decode.d4.loss_mask: 0.2752  decode.d4.loss_dice: 0.3738  decode.d5.loss_cls: 1.1991  decode.d5.loss_mask: 0.2571  decode.d5.loss_dice: 0.3387  decode.d6.loss_cls: 1.0831  decode.d6.loss_mask: 0.2490  decode.d6.loss_dice: 0.3314  decode.d7.loss_cls: 1.0909  decode.d7.loss_mask: 0.2499  decode.d7.loss_dice: 0.3233  decode.d8.loss_cls: 1.2116  decode.d8.loss_mask: 0.2527  decode.d8.loss_dice: 0.3335
08/06 02:52:18 - mmengine - INFO - Iter(train) [  4350/320000]  base_lr: 9.8776e-05 lr: 9.8776e-06  eta: 1 day, 18:56:50  time: 0.4901  data_time: 0.0102  memory: 5908  grad_norm: 220.3416  loss: 18.3608  decode.loss_cls: 0.8806  decode.loss_mask: 0.3748  decode.loss_dice: 0.3817  decode.d0.loss_cls: 1.9430  decode.d0.loss_mask: 0.3974  decode.d0.loss_dice: 0.4729  decode.d1.loss_cls: 1.4616  decode.d1.loss_mask: 0.3560  decode.d1.loss_dice: 0.3988  decode.d2.loss_cls: 1.0640  decode.d2.loss_mask: 0.3574  decode.d2.loss_dice: 0.3556  decode.d3.loss_cls: 0.9464  decode.d3.loss_mask: 0.3411  decode.d3.loss_dice: 0.3446  decode.d4.loss_cls: 0.9097  decode.d4.loss_mask: 0.3548  decode.d4.loss_dice: 0.3625  decode.d5.loss_cls: 0.9255  decode.d5.loss_mask: 0.3658  decode.d5.loss_dice: 0.3849  decode.d6.loss_cls: 0.9074  decode.d6.loss_mask: 0.3425  decode.d6.loss_dice: 0.3533  decode.d7.loss_cls: 0.9097  decode.d7.loss_mask: 0.3512  decode.d7.loss_dice: 0.3729  decode.d8.loss_cls: 0.9656  decode.d8.loss_mask: 0.3921  decode.d8.loss_dice: 0.3869
08/06 02:52:42 - mmengine - INFO - Iter(train) [  4400/320000]  base_lr: 9.8762e-05 lr: 9.8762e-06  eta: 1 day, 18:56:25  time: 0.4900  data_time: 0.0102  memory: 5908  grad_norm: 169.6911  loss: 16.4724  decode.loss_cls: 0.8404  decode.loss_mask: 0.2862  decode.loss_dice: 0.3538  decode.d0.loss_cls: 1.6466  decode.d0.loss_mask: 0.3013  decode.d0.loss_dice: 0.4388  decode.d1.loss_cls: 1.1369  decode.d1.loss_mask: 0.2851  decode.d1.loss_dice: 0.3787  decode.d2.loss_cls: 0.8540  decode.d2.loss_mask: 0.2808  decode.d2.loss_dice: 0.3374  decode.d3.loss_cls: 0.8814  decode.d3.loss_mask: 0.2816  decode.d3.loss_dice: 0.3506  decode.d4.loss_cls: 0.9334  decode.d4.loss_mask: 0.2829  decode.d4.loss_dice: 0.3401  decode.d5.loss_cls: 0.9614  decode.d5.loss_mask: 0.2993  decode.d5.loss_dice: 0.3765  decode.d6.loss_cls: 0.9599  decode.d6.loss_mask: 0.2975  decode.d6.loss_dice: 0.3338  decode.d7.loss_cls: 0.8987  decode.d7.loss_mask: 0.2882  decode.d7.loss_dice: 0.3474  decode.d8.loss_cls: 0.8393  decode.d8.loss_mask: 0.2855  decode.d8.loss_dice: 0.3750
08/06 02:53:07 - mmengine - INFO - Iter(train) [  4450/320000]  base_lr: 9.8748e-05 lr: 9.8748e-06  eta: 1 day, 18:56:07  time: 0.4895  data_time: 0.0101  memory: 5889  grad_norm: 264.8366  loss: 19.6069  decode.loss_cls: 1.1587  decode.loss_mask: 0.2922  decode.loss_dice: 0.3767  decode.d0.loss_cls: 1.9906  decode.d0.loss_mask: 0.3247  decode.d0.loss_dice: 0.4929  decode.d1.loss_cls: 1.2976  decode.d1.loss_mask: 0.3222  decode.d1.loss_dice: 0.4063  decode.d2.loss_cls: 1.1529  decode.d2.loss_mask: 0.3018  decode.d2.loss_dice: 0.3939  decode.d3.loss_cls: 1.1270  decode.d3.loss_mask: 0.2954  decode.d3.loss_dice: 0.4185  decode.d4.loss_cls: 1.2086  decode.d4.loss_mask: 0.2891  decode.d4.loss_dice: 0.4131  decode.d5.loss_cls: 1.1472  decode.d5.loss_mask: 0.3005  decode.d5.loss_dice: 0.4459  decode.d6.loss_cls: 1.0164  decode.d6.loss_mask: 0.3320  decode.d6.loss_dice: 0.4371  decode.d7.loss_cls: 1.0282  decode.d7.loss_mask: 0.3161  decode.d7.loss_dice: 0.4306  decode.d8.loss_cls: 1.1917  decode.d8.loss_mask: 0.2968  decode.d8.loss_dice: 0.4023
08/06 02:53:31 - mmengine - INFO - Iter(train) [  4500/320000]  base_lr: 9.8734e-05 lr: 9.8734e-06  eta: 1 day, 18:55:42  time: 0.4899  data_time: 0.0103  memory: 5891  grad_norm: 260.1581  loss: 18.8040  decode.loss_cls: 0.7978  decode.loss_mask: 0.5880  decode.loss_dice: 0.4195  decode.d0.loss_cls: 1.8369  decode.d0.loss_mask: 0.4980  decode.d0.loss_dice: 0.4473  decode.d1.loss_cls: 1.1467  decode.d1.loss_mask: 0.4600  decode.d1.loss_dice: 0.4219  decode.d2.loss_cls: 0.8010  decode.d2.loss_mask: 0.4646  decode.d2.loss_dice: 0.4261  decode.d3.loss_cls: 0.8671  decode.d3.loss_mask: 0.5005  decode.d3.loss_dice: 0.4237  decode.d4.loss_cls: 0.8487  decode.d4.loss_mask: 0.5106  decode.d4.loss_dice: 0.4299  decode.d5.loss_cls: 0.7593  decode.d5.loss_mask: 0.5195  decode.d5.loss_dice: 0.4452  decode.d6.loss_cls: 0.7581  decode.d6.loss_mask: 0.5526  decode.d6.loss_dice: 0.4353  decode.d7.loss_cls: 0.7857  decode.d7.loss_mask: 0.4845  decode.d7.loss_dice: 0.4433  decode.d8.loss_cls: 0.7884  decode.d8.loss_mask: 0.5069  decode.d8.loss_dice: 0.4369
08/06 02:53:56 - mmengine - INFO - Iter(train) [  4550/320000]  base_lr: 9.8720e-05 lr: 9.8720e-06  eta: 1 day, 18:55:17  time: 0.4901  data_time: 0.0101  memory: 5907  grad_norm: 161.2364  loss: 19.4357  decode.loss_cls: 1.1594  decode.loss_mask: 0.3591  decode.loss_dice: 0.3784  decode.d0.loss_cls: 2.0561  decode.d0.loss_mask: 0.3783  decode.d0.loss_dice: 0.4497  decode.d1.loss_cls: 1.3985  decode.d1.loss_mask: 0.3764  decode.d1.loss_dice: 0.3948  decode.d2.loss_cls: 1.0680  decode.d2.loss_mask: 0.3637  decode.d2.loss_dice: 0.3767  decode.d3.loss_cls: 0.9428  decode.d3.loss_mask: 0.3654  decode.d3.loss_dice: 0.3750  decode.d4.loss_cls: 0.9910  decode.d4.loss_mask: 0.3601  decode.d4.loss_dice: 0.3817  decode.d5.loss_cls: 0.9597  decode.d5.loss_mask: 0.3775  decode.d5.loss_dice: 0.3938  decode.d6.loss_cls: 0.9676  decode.d6.loss_mask: 0.3860  decode.d6.loss_dice: 0.3977  decode.d7.loss_cls: 1.0714  decode.d7.loss_mask: 0.3979  decode.d7.loss_dice: 0.4050  decode.d8.loss_cls: 1.1205  decode.d8.loss_mask: 0.3883  decode.d8.loss_dice: 0.3954
08/06 02:54:20 - mmengine - INFO - Iter(train) [  4600/320000]  base_lr: 9.8706e-05 lr: 9.8706e-06  eta: 1 day, 18:54:53  time: 0.4908  data_time: 0.0102  memory: 5877  grad_norm: 177.0326  loss: 17.6579  decode.loss_cls: 0.9346  decode.loss_mask: 0.2935  decode.loss_dice: 0.3408  decode.d0.loss_cls: 2.0105  decode.d0.loss_mask: 0.3445  decode.d0.loss_dice: 0.4644  decode.d1.loss_cls: 1.2639  decode.d1.loss_mask: 0.2804  decode.d1.loss_dice: 0.3704  decode.d2.loss_cls: 0.9914  decode.d2.loss_mask: 0.2828  decode.d2.loss_dice: 0.3320  decode.d3.loss_cls: 0.9758  decode.d3.loss_mask: 0.2682  decode.d3.loss_dice: 0.3276  decode.d4.loss_cls: 0.9673  decode.d4.loss_mask: 0.2872  decode.d4.loss_dice: 0.3384  decode.d5.loss_cls: 1.0163  decode.d5.loss_mask: 0.2921  decode.d5.loss_dice: 0.3442  decode.d6.loss_cls: 1.0108  decode.d6.loss_mask: 0.2917  decode.d6.loss_dice: 0.3442  decode.d7.loss_cls: 1.0166  decode.d7.loss_mask: 0.3021  decode.d7.loss_dice: 0.3545  decode.d8.loss_cls: 0.9668  decode.d8.loss_mask: 0.2973  decode.d8.loss_dice: 0.3474
08/06 02:54:45 - mmengine - INFO - Iter(train) [  4650/320000]  base_lr: 9.8692e-05 lr: 9.8692e-06  eta: 1 day, 18:54:28  time: 0.4897  data_time: 0.0103  memory: 5907  grad_norm: 254.0864  loss: 17.7275  decode.loss_cls: 0.8828  decode.loss_mask: 0.3431  decode.loss_dice: 0.3731  decode.d0.loss_cls: 1.8403  decode.d0.loss_mask: 0.3768  decode.d0.loss_dice: 0.4558  decode.d1.loss_cls: 1.2082  decode.d1.loss_mask: 0.3585  decode.d1.loss_dice: 0.4144  decode.d2.loss_cls: 0.8753  decode.d2.loss_mask: 0.3657  decode.d2.loss_dice: 0.4137  decode.d3.loss_cls: 0.8423  decode.d3.loss_mask: 0.3908  decode.d3.loss_dice: 0.4038  decode.d4.loss_cls: 0.8821  decode.d4.loss_mask: 0.3601  decode.d4.loss_dice: 0.4114  decode.d5.loss_cls: 0.8514  decode.d5.loss_mask: 0.3354  decode.d5.loss_dice: 0.3849  decode.d6.loss_cls: 0.8528  decode.d6.loss_mask: 0.3678  decode.d6.loss_dice: 0.4096  decode.d7.loss_cls: 0.8648  decode.d7.loss_mask: 0.3870  decode.d7.loss_dice: 0.3896  decode.d8.loss_cls: 0.9020  decode.d8.loss_mask: 0.3819  decode.d8.loss_dice: 0.4021
08/06 02:55:09 - mmengine - INFO - Iter(train) [  4700/320000]  base_lr: 9.8677e-05 lr: 9.8677e-06  eta: 1 day, 18:54:05  time: 0.4900  data_time: 0.0102  memory: 5908  grad_norm: 196.4633  loss: 18.6348  decode.loss_cls: 0.9906  decode.loss_mask: 0.3206  decode.loss_dice: 0.3585  decode.d0.loss_cls: 1.8901  decode.d0.loss_mask: 0.3433  decode.d0.loss_dice: 0.4469  decode.d1.loss_cls: 1.4390  decode.d1.loss_mask: 0.3376  decode.d1.loss_dice: 0.3863  decode.d2.loss_cls: 1.0733  decode.d2.loss_mask: 0.3273  decode.d2.loss_dice: 0.3698  decode.d3.loss_cls: 1.0044  decode.d3.loss_mask: 0.3310  decode.d3.loss_dice: 0.3515  decode.d4.loss_cls: 0.9895  decode.d4.loss_mask: 0.3196  decode.d4.loss_dice: 0.3664  decode.d5.loss_cls: 0.9905  decode.d5.loss_mask: 0.3540  decode.d5.loss_dice: 0.3879  decode.d6.loss_cls: 1.0955  decode.d6.loss_mask: 0.3213  decode.d6.loss_dice: 0.3603  decode.d7.loss_cls: 1.0674  decode.d7.loss_mask: 0.3238  decode.d7.loss_dice: 0.3598  decode.d8.loss_cls: 1.0496  decode.d8.loss_mask: 0.3200  decode.d8.loss_dice: 0.3590
08/06 02:55:34 - mmengine - INFO - Iter(train) [  4750/320000]  base_lr: 9.8663e-05 lr: 9.8663e-06  eta: 1 day, 18:53:51  time: 0.4890  data_time: 0.0103  memory: 5907  grad_norm: 253.7505  loss: 16.8476  decode.loss_cls: 0.7306  decode.loss_mask: 0.4112  decode.loss_dice: 0.4056  decode.d0.loss_cls: 1.5090  decode.d0.loss_mask: 0.4583  decode.d0.loss_dice: 0.4453  decode.d1.loss_cls: 0.9684  decode.d1.loss_mask: 0.4327  decode.d1.loss_dice: 0.3660  decode.d2.loss_cls: 0.7965  decode.d2.loss_mask: 0.4000  decode.d2.loss_dice: 0.3515  decode.d3.loss_cls: 0.8094  decode.d3.loss_mask: 0.4369  decode.d3.loss_dice: 0.3882  decode.d4.loss_cls: 0.7754  decode.d4.loss_mask: 0.4204  decode.d4.loss_dice: 0.3920  decode.d5.loss_cls: 0.8354  decode.d5.loss_mask: 0.4268  decode.d5.loss_dice: 0.3952  decode.d6.loss_cls: 0.8003  decode.d6.loss_mask: 0.4088  decode.d6.loss_dice: 0.3914  decode.d7.loss_cls: 0.7398  decode.d7.loss_mask: 0.4043  decode.d7.loss_dice: 0.3696  decode.d8.loss_cls: 0.7805  decode.d8.loss_mask: 0.4134  decode.d8.loss_dice: 0.3848
08/06 02:55:59 - mmengine - INFO - Iter(train) [  4800/320000]  base_lr: 9.8649e-05 lr: 9.8649e-06  eta: 1 day, 18:53:27  time: 0.4902  data_time: 0.0102  memory: 5891  grad_norm: 226.2338  loss: 17.7687  decode.loss_cls: 0.9927  decode.loss_mask: 0.2863  decode.loss_dice: 0.3615  decode.d0.loss_cls: 1.9284  decode.d0.loss_mask: 0.3095  decode.d0.loss_dice: 0.4119  decode.d1.loss_cls: 1.1912  decode.d1.loss_mask: 0.2915  decode.d1.loss_dice: 0.3787  decode.d2.loss_cls: 0.8962  decode.d2.loss_mask: 0.2996  decode.d2.loss_dice: 0.3795  decode.d3.loss_cls: 0.9247  decode.d3.loss_mask: 0.3112  decode.d3.loss_dice: 0.3916  decode.d4.loss_cls: 1.0137  decode.d4.loss_mask: 0.3122  decode.d4.loss_dice: 0.3668  decode.d5.loss_cls: 1.0043  decode.d5.loss_mask: 0.2993  decode.d5.loss_dice: 0.3809  decode.d6.loss_cls: 0.9340  decode.d6.loss_mask: 0.3039  decode.d6.loss_dice: 0.3948  decode.d7.loss_cls: 1.0210  decode.d7.loss_mask: 0.2896  decode.d7.loss_dice: 0.3857  decode.d8.loss_cls: 1.0486  decode.d8.loss_mask: 0.2889  decode.d8.loss_dice: 0.3705
08/06 02:56:23 - mmengine - INFO - Iter(train) [  4850/320000]  base_lr: 9.8635e-05 lr: 9.8635e-06  eta: 1 day, 18:53:04  time: 0.4903  data_time: 0.0100  memory: 5909  grad_norm: 196.6021  loss: 15.1370  decode.loss_cls: 0.7429  decode.loss_mask: 0.3320  decode.loss_dice: 0.3529  decode.d0.loss_cls: 1.5905  decode.d0.loss_mask: 0.3213  decode.d0.loss_dice: 0.3766  decode.d1.loss_cls: 0.9279  decode.d1.loss_mask: 0.3341  decode.d1.loss_dice: 0.3696  decode.d2.loss_cls: 0.7215  decode.d2.loss_mask: 0.3255  decode.d2.loss_dice: 0.3641  decode.d3.loss_cls: 0.7488  decode.d3.loss_mask: 0.3207  decode.d3.loss_dice: 0.3395  decode.d4.loss_cls: 0.7735  decode.d4.loss_mask: 0.3203  decode.d4.loss_dice: 0.3509  decode.d5.loss_cls: 0.7349  decode.d5.loss_mask: 0.3221  decode.d5.loss_dice: 0.3588  decode.d6.loss_cls: 0.6400  decode.d6.loss_mask: 0.3292  decode.d6.loss_dice: 0.3542  decode.d7.loss_cls: 0.6687  decode.d7.loss_mask: 0.3372  decode.d7.loss_dice: 0.3749  decode.d8.loss_cls: 0.7244  decode.d8.loss_mask: 0.3320  decode.d8.loss_dice: 0.3476
08/06 02:56:48 - mmengine - INFO - Iter(train) [  4900/320000]  base_lr: 9.8621e-05 lr: 9.8621e-06  eta: 1 day, 18:52:39  time: 0.4904  data_time: 0.0104  memory: 5875  grad_norm: 307.1407  loss: 17.1016  decode.loss_cls: 0.7750  decode.loss_mask: 0.4007  decode.loss_dice: 0.4596  decode.d0.loss_cls: 1.5783  decode.d0.loss_mask: 0.4710  decode.d0.loss_dice: 0.5764  decode.d1.loss_cls: 0.9552  decode.d1.loss_mask: 0.3932  decode.d1.loss_dice: 0.4566  decode.d2.loss_cls: 0.6916  decode.d2.loss_mask: 0.4089  decode.d2.loss_dice: 0.4265  decode.d3.loss_cls: 0.7111  decode.d3.loss_mask: 0.3948  decode.d3.loss_dice: 0.4528  decode.d4.loss_cls: 0.7789  decode.d4.loss_mask: 0.4127  decode.d4.loss_dice: 0.4423  decode.d5.loss_cls: 0.6972  decode.d5.loss_mask: 0.3939  decode.d5.loss_dice: 0.4432  decode.d6.loss_cls: 0.7258  decode.d6.loss_mask: 0.4051  decode.d6.loss_dice: 0.4648  decode.d7.loss_cls: 0.6837  decode.d7.loss_mask: 0.4229  decode.d7.loss_dice: 0.4541  decode.d8.loss_cls: 0.7659  decode.d8.loss_mask: 0.4107  decode.d8.loss_dice: 0.4489
08/06 02:57:12 - mmengine - INFO - Iter(train) [  4950/320000]  base_lr: 9.8607e-05 lr: 9.8607e-06  eta: 1 day, 18:52:15  time: 0.4897  data_time: 0.0104  memory: 5891  grad_norm: 326.6244  loss: 17.1715  decode.loss_cls: 0.7719  decode.loss_mask: 0.3385  decode.loss_dice: 0.4282  decode.d0.loss_cls: 1.6233  decode.d0.loss_mask: 0.3635  decode.d0.loss_dice: 0.4852  decode.d1.loss_cls: 1.0472  decode.d1.loss_mask: 0.4036  decode.d1.loss_dice: 0.5093  decode.d2.loss_cls: 0.8178  decode.d2.loss_mask: 0.3993  decode.d2.loss_dice: 0.4602  decode.d3.loss_cls: 0.7118  decode.d3.loss_mask: 0.3515  decode.d3.loss_dice: 0.4277  decode.d4.loss_cls: 0.8067  decode.d4.loss_mask: 0.3913  decode.d4.loss_dice: 0.4519  decode.d5.loss_cls: 0.8324  decode.d5.loss_mask: 0.3739  decode.d5.loss_dice: 0.4263  decode.d6.loss_cls: 0.7145  decode.d6.loss_mask: 0.3761  decode.d6.loss_dice: 0.4270  decode.d7.loss_cls: 0.8642  decode.d7.loss_mask: 0.3634  decode.d7.loss_dice: 0.4011  decode.d8.loss_cls: 0.8689  decode.d8.loss_mask: 0.3426  decode.d8.loss_dice: 0.3921
08/06 02:57:37 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 02:57:37 - mmengine - INFO - Iter(train) [  5000/320000]  base_lr: 9.8593e-05 lr: 9.8593e-06  eta: 1 day, 18:51:52  time: 0.4905  data_time: 0.0101  memory: 5891  grad_norm: 274.2921  loss: 19.7972  decode.loss_cls: 1.0292  decode.loss_mask: 0.4419  decode.loss_dice: 0.4520  decode.d0.loss_cls: 1.9349  decode.d0.loss_mask: 0.4150  decode.d0.loss_dice: 0.4773  decode.d1.loss_cls: 1.4807  decode.d1.loss_mask: 0.3555  decode.d1.loss_dice: 0.4000  decode.d2.loss_cls: 1.0878  decode.d2.loss_mask: 0.3471  decode.d2.loss_dice: 0.3531  decode.d3.loss_cls: 1.0730  decode.d3.loss_mask: 0.3474  decode.d3.loss_dice: 0.3705  decode.d4.loss_cls: 1.0701  decode.d4.loss_mask: 0.3477  decode.d4.loss_dice: 0.3814  decode.d5.loss_cls: 1.1139  decode.d5.loss_mask: 0.3609  decode.d5.loss_dice: 0.3858  decode.d6.loss_cls: 1.1093  decode.d6.loss_mask: 0.3537  decode.d6.loss_dice: 0.3769  decode.d7.loss_cls: 1.0700  decode.d7.loss_mask: 0.3736  decode.d7.loss_dice: 0.3844  decode.d8.loss_cls: 1.0166  decode.d8.loss_mask: 0.4489  decode.d8.loss_dice: 0.4388
08/06 02:58:01 - mmengine - INFO - Iter(train) [  5050/320000]  base_lr: 9.8579e-05 lr: 9.8579e-06  eta: 1 day, 18:51:27  time: 0.4894  data_time: 0.0102  memory: 5907  grad_norm: 193.7817  loss: 16.4934  decode.loss_cls: 0.7940  decode.loss_mask: 0.3377  decode.loss_dice: 0.3485  decode.d0.loss_cls: 1.7725  decode.d0.loss_mask: 0.3935  decode.d0.loss_dice: 0.4330  decode.d1.loss_cls: 1.0360  decode.d1.loss_mask: 0.3273  decode.d1.loss_dice: 0.3316  decode.d2.loss_cls: 0.8173  decode.d2.loss_mask: 0.3143  decode.d2.loss_dice: 0.3272  decode.d3.loss_cls: 0.8315  decode.d3.loss_mask: 0.3416  decode.d3.loss_dice: 0.3882  decode.d4.loss_cls: 0.8199  decode.d4.loss_mask: 0.3527  decode.d4.loss_dice: 0.3596  decode.d5.loss_cls: 0.8954  decode.d5.loss_mask: 0.3332  decode.d5.loss_dice: 0.3191  decode.d6.loss_cls: 0.8435  decode.d6.loss_mask: 0.3343  decode.d6.loss_dice: 0.3324  decode.d7.loss_cls: 0.9021  decode.d7.loss_mask: 0.3148  decode.d7.loss_dice: 0.3218  decode.d8.loss_cls: 0.8761  decode.d8.loss_mask: 0.3373  decode.d8.loss_dice: 0.3569
08/06 02:58:26 - mmengine - INFO - Iter(train) [  5100/320000]  base_lr: 9.8565e-05 lr: 9.8565e-06  eta: 1 day, 18:51:03  time: 0.4895  data_time: 0.0099  memory: 5889  grad_norm: 166.0307  loss: 17.7460  decode.loss_cls: 1.0422  decode.loss_mask: 0.2417  decode.loss_dice: 0.3306  decode.d0.loss_cls: 1.8940  decode.d0.loss_mask: 0.2715  decode.d0.loss_dice: 0.4244  decode.d1.loss_cls: 1.2471  decode.d1.loss_mask: 0.2669  decode.d1.loss_dice: 0.3803  decode.d2.loss_cls: 1.0762  decode.d2.loss_mask: 0.2521  decode.d2.loss_dice: 0.3703  decode.d3.loss_cls: 1.0668  decode.d3.loss_mask: 0.2379  decode.d3.loss_dice: 0.3396  decode.d4.loss_cls: 1.1532  decode.d4.loss_mask: 0.2364  decode.d4.loss_dice: 0.3159  decode.d5.loss_cls: 1.0961  decode.d5.loss_mask: 0.2477  decode.d5.loss_dice: 0.3305  decode.d6.loss_cls: 1.0769  decode.d6.loss_mask: 0.2408  decode.d6.loss_dice: 0.3434  decode.d7.loss_cls: 1.0675  decode.d7.loss_mask: 0.2402  decode.d7.loss_dice: 0.3395  decode.d8.loss_cls: 1.0663  decode.d8.loss_mask: 0.2357  decode.d8.loss_dice: 0.3142
08/06 02:58:50 - mmengine - INFO - Iter(train) [  5150/320000]  base_lr: 9.8551e-05 lr: 9.8551e-06  eta: 1 day, 18:50:40  time: 0.4901  data_time: 0.0101  memory: 5927  grad_norm: 139.0070  loss: 13.8380  decode.loss_cls: 0.7384  decode.loss_mask: 0.2640  decode.loss_dice: 0.2847  decode.d0.loss_cls: 1.7080  decode.d0.loss_mask: 0.2824  decode.d0.loss_dice: 0.3507  decode.d1.loss_cls: 1.0311  decode.d1.loss_mask: 0.2558  decode.d1.loss_dice: 0.3008  decode.d2.loss_cls: 0.7723  decode.d2.loss_mask: 0.2461  decode.d2.loss_dice: 0.2787  decode.d3.loss_cls: 0.6465  decode.d3.loss_mask: 0.2559  decode.d3.loss_dice: 0.2884  decode.d4.loss_cls: 0.6657  decode.d4.loss_mask: 0.2405  decode.d4.loss_dice: 0.2891  decode.d5.loss_cls: 0.6533  decode.d5.loss_mask: 0.2545  decode.d5.loss_dice: 0.2958  decode.d6.loss_cls: 0.6744  decode.d6.loss_mask: 0.2666  decode.d6.loss_dice: 0.2895  decode.d7.loss_cls: 0.7586  decode.d7.loss_mask: 0.2442  decode.d7.loss_dice: 0.2877  decode.d8.loss_cls: 0.6571  decode.d8.loss_mask: 0.2534  decode.d8.loss_dice: 0.3038
08/06 02:59:15 - mmengine - INFO - Iter(train) [  5200/320000]  base_lr: 9.8537e-05 lr: 9.8537e-06  eta: 1 day, 18:50:16  time: 0.4901  data_time: 0.0103  memory: 5907  grad_norm: 194.0533  loss: 15.0843  decode.loss_cls: 0.8378  decode.loss_mask: 0.2749  decode.loss_dice: 0.3367  decode.d0.loss_cls: 1.6839  decode.d0.loss_mask: 0.2973  decode.d0.loss_dice: 0.4509  decode.d1.loss_cls: 0.9490  decode.d1.loss_mask: 0.2903  decode.d1.loss_dice: 0.3572  decode.d2.loss_cls: 0.7403  decode.d2.loss_mask: 0.3016  decode.d2.loss_dice: 0.3420  decode.d3.loss_cls: 0.7240  decode.d3.loss_mask: 0.2899  decode.d3.loss_dice: 0.3349  decode.d4.loss_cls: 0.7207  decode.d4.loss_mask: 0.2809  decode.d4.loss_dice: 0.3414  decode.d5.loss_cls: 0.7287  decode.d5.loss_mask: 0.2825  decode.d5.loss_dice: 0.3550  decode.d6.loss_cls: 0.7964  decode.d6.loss_mask: 0.2774  decode.d6.loss_dice: 0.3335  decode.d7.loss_cls: 0.7521  decode.d7.loss_mask: 0.2775  decode.d7.loss_dice: 0.3517  decode.d8.loss_cls: 0.7006  decode.d8.loss_mask: 0.2898  decode.d8.loss_dice: 0.3857
08/06 02:59:39 - mmengine - INFO - Iter(train) [  5250/320000]  base_lr: 9.8522e-05 lr: 9.8522e-06  eta: 1 day, 18:49:51  time: 0.4892  data_time: 0.0102  memory: 5908  grad_norm: 261.8311  loss: 17.6156  decode.loss_cls: 0.8570  decode.loss_mask: 0.3295  decode.loss_dice: 0.3913  decode.d0.loss_cls: 1.9231  decode.d0.loss_mask: 0.3745  decode.d0.loss_dice: 0.4784  decode.d1.loss_cls: 1.2413  decode.d1.loss_mask: 0.3196  decode.d1.loss_dice: 0.3834  decode.d2.loss_cls: 0.9964  decode.d2.loss_mask: 0.3138  decode.d2.loss_dice: 0.3471  decode.d3.loss_cls: 0.9335  decode.d3.loss_mask: 0.3174  decode.d3.loss_dice: 0.3327  decode.d4.loss_cls: 0.9300  decode.d4.loss_mask: 0.3170  decode.d4.loss_dice: 0.3745  decode.d5.loss_cls: 0.9072  decode.d5.loss_mask: 0.3436  decode.d5.loss_dice: 0.4069  decode.d6.loss_cls: 0.9113  decode.d6.loss_mask: 0.3169  decode.d6.loss_dice: 0.4008  decode.d7.loss_cls: 0.8869  decode.d7.loss_mask: 0.3069  decode.d7.loss_dice: 0.3785  decode.d8.loss_cls: 0.8912  decode.d8.loss_mask: 0.3234  decode.d8.loss_dice: 0.3814
08/06 03:00:04 - mmengine - INFO - Iter(train) [  5300/320000]  base_lr: 9.8508e-05 lr: 9.8508e-06  eta: 1 day, 18:49:26  time: 0.4903  data_time: 0.0102  memory: 5874  grad_norm: 211.3751  loss: 15.8853  decode.loss_cls: 0.6287  decode.loss_mask: 0.4323  decode.loss_dice: 0.3928  decode.d0.loss_cls: 1.5822  decode.d0.loss_mask: 0.3985  decode.d0.loss_dice: 0.4276  decode.d1.loss_cls: 0.9375  decode.d1.loss_mask: 0.4111  decode.d1.loss_dice: 0.4053  decode.d2.loss_cls: 0.6565  decode.d2.loss_mask: 0.4064  decode.d2.loss_dice: 0.3567  decode.d3.loss_cls: 0.6387  decode.d3.loss_mask: 0.4029  decode.d3.loss_dice: 0.3716  decode.d4.loss_cls: 0.7169  decode.d4.loss_mask: 0.3810  decode.d4.loss_dice: 0.3675  decode.d5.loss_cls: 0.6824  decode.d5.loss_mask: 0.4072  decode.d5.loss_dice: 0.3964  decode.d6.loss_cls: 0.6652  decode.d6.loss_mask: 0.4034  decode.d6.loss_dice: 0.3869  decode.d7.loss_cls: 0.6809  decode.d7.loss_mask: 0.4085  decode.d7.loss_dice: 0.4001  decode.d8.loss_cls: 0.7363  decode.d8.loss_mask: 0.4169  decode.d8.loss_dice: 0.3871
08/06 03:00:28 - mmengine - INFO - Iter(train) [  5350/320000]  base_lr: 9.8494e-05 lr: 9.8494e-06  eta: 1 day, 18:49:07  time: 0.4891  data_time: 0.0101  memory: 5908  grad_norm: 831.6546  loss: 16.6242  decode.loss_cls: 0.6387  decode.loss_mask: 0.4097  decode.loss_dice: 0.3987  decode.d0.loss_cls: 1.6730  decode.d0.loss_mask: 0.4678  decode.d0.loss_dice: 0.5102  decode.d1.loss_cls: 0.9870  decode.d1.loss_mask: 0.4569  decode.d1.loss_dice: 0.4182  decode.d2.loss_cls: 0.7093  decode.d2.loss_mask: 0.4355  decode.d2.loss_dice: 0.3787  decode.d3.loss_cls: 0.6750  decode.d3.loss_mask: 0.4205  decode.d3.loss_dice: 0.3918  decode.d4.loss_cls: 0.6977  decode.d4.loss_mask: 0.4279  decode.d4.loss_dice: 0.3810  decode.d5.loss_cls: 0.7239  decode.d5.loss_mask: 0.4249  decode.d5.loss_dice: 0.4039  decode.d6.loss_cls: 0.7177  decode.d6.loss_mask: 0.4285  decode.d6.loss_dice: 0.4215  decode.d7.loss_cls: 0.6680  decode.d7.loss_mask: 0.4330  decode.d7.loss_dice: 0.4132  decode.d8.loss_cls: 0.6692  decode.d8.loss_mask: 0.4380  decode.d8.loss_dice: 0.4047
08/06 03:00:53 - mmengine - INFO - Iter(train) [  5400/320000]  base_lr: 9.8480e-05 lr: 9.8480e-06  eta: 1 day, 18:48:41  time: 0.4891  data_time: 0.0102  memory: 5891  grad_norm: 199.0452  loss: 16.2163  decode.loss_cls: 0.7880  decode.loss_mask: 0.3268  decode.loss_dice: 0.4001  decode.d0.loss_cls: 1.5944  decode.d0.loss_mask: 0.3428  decode.d0.loss_dice: 0.4748  decode.d1.loss_cls: 0.8933  decode.d1.loss_mask: 0.3216  decode.d1.loss_dice: 0.4271  decode.d2.loss_cls: 0.7352  decode.d2.loss_mask: 0.3132  decode.d2.loss_dice: 0.4145  decode.d3.loss_cls: 0.7513  decode.d3.loss_mask: 0.3235  decode.d3.loss_dice: 0.4297  decode.d4.loss_cls: 0.8313  decode.d4.loss_mask: 0.3170  decode.d4.loss_dice: 0.4164  decode.d5.loss_cls: 0.8508  decode.d5.loss_mask: 0.3257  decode.d5.loss_dice: 0.4069  decode.d6.loss_cls: 0.8111  decode.d6.loss_mask: 0.3215  decode.d6.loss_dice: 0.4096  decode.d7.loss_cls: 0.7978  decode.d7.loss_mask: 0.3226  decode.d7.loss_dice: 0.4113  decode.d8.loss_cls: 0.7308  decode.d8.loss_mask: 0.3263  decode.d8.loss_dice: 0.4009
08/06 03:01:17 - mmengine - INFO - Iter(train) [  5450/320000]  base_lr: 9.8466e-05 lr: 9.8466e-06  eta: 1 day, 18:48:17  time: 0.4901  data_time: 0.0102  memory: 5907  grad_norm: 210.0767  loss: 18.2156  decode.loss_cls: 0.9257  decode.loss_mask: 0.3364  decode.loss_dice: 0.4838  decode.d0.loss_cls: 1.7927  decode.d0.loss_mask: 0.4024  decode.d0.loss_dice: 0.5612  decode.d1.loss_cls: 1.0023  decode.d1.loss_mask: 0.3598  decode.d1.loss_dice: 0.4947  decode.d2.loss_cls: 0.8909  decode.d2.loss_mask: 0.3433  decode.d2.loss_dice: 0.4385  decode.d3.loss_cls: 0.8563  decode.d3.loss_mask: 0.3175  decode.d3.loss_dice: 0.4421  decode.d4.loss_cls: 0.8447  decode.d4.loss_mask: 0.3182  decode.d4.loss_dice: 0.4710  decode.d5.loss_cls: 0.9490  decode.d5.loss_mask: 0.3349  decode.d5.loss_dice: 0.5166  decode.d6.loss_cls: 0.8588  decode.d6.loss_mask: 0.3567  decode.d6.loss_dice: 0.5043  decode.d7.loss_cls: 0.8519  decode.d7.loss_mask: 0.3549  decode.d7.loss_dice: 0.5131  decode.d8.loss_cls: 0.8826  decode.d8.loss_mask: 0.3150  decode.d8.loss_dice: 0.4959
08/06 03:01:42 - mmengine - INFO - Iter(train) [  5500/320000]  base_lr: 9.8452e-05 lr: 9.8452e-06  eta: 1 day, 18:47:53  time: 0.4891  data_time: 0.0102  memory: 5890  grad_norm: 298.7262  loss: 18.7464  decode.loss_cls: 0.8030  decode.loss_mask: 0.4337  decode.loss_dice: 0.5259  decode.d0.loss_cls: 1.6683  decode.d0.loss_mask: 0.4878  decode.d0.loss_dice: 0.5979  decode.d1.loss_cls: 1.0246  decode.d1.loss_mask: 0.3955  decode.d1.loss_dice: 0.5066  decode.d2.loss_cls: 0.9434  decode.d2.loss_mask: 0.3855  decode.d2.loss_dice: 0.4704  decode.d3.loss_cls: 0.8419  decode.d3.loss_mask: 0.4018  decode.d3.loss_dice: 0.4825  decode.d4.loss_cls: 0.7971  decode.d4.loss_mask: 0.4406  decode.d4.loss_dice: 0.4969  decode.d5.loss_cls: 0.8199  decode.d5.loss_mask: 0.4287  decode.d5.loss_dice: 0.4941  decode.d6.loss_cls: 0.7942  decode.d6.loss_mask: 0.4579  decode.d6.loss_dice: 0.5177  decode.d7.loss_cls: 0.8538  decode.d7.loss_mask: 0.4040  decode.d7.loss_dice: 0.5188  decode.d8.loss_cls: 0.8565  decode.d8.loss_mask: 0.4244  decode.d8.loss_dice: 0.4730
08/06 03:02:06 - mmengine - INFO - Iter(train) [  5550/320000]  base_lr: 9.8438e-05 lr: 9.8438e-06  eta: 1 day, 18:47:30  time: 0.4901  data_time: 0.0102  memory: 5908  grad_norm: 210.1048  loss: 18.2314  decode.loss_cls: 1.0057  decode.loss_mask: 0.3358  decode.loss_dice: 0.4247  decode.d0.loss_cls: 1.9339  decode.d0.loss_mask: 0.3966  decode.d0.loss_dice: 0.5592  decode.d1.loss_cls: 1.2571  decode.d1.loss_mask: 0.3271  decode.d1.loss_dice: 0.3943  decode.d2.loss_cls: 0.8280  decode.d2.loss_mask: 0.3619  decode.d2.loss_dice: 0.4365  decode.d3.loss_cls: 0.8481  decode.d3.loss_mask: 0.3546  decode.d3.loss_dice: 0.4562  decode.d4.loss_cls: 0.9098  decode.d4.loss_mask: 0.3445  decode.d4.loss_dice: 0.4263  decode.d5.loss_cls: 0.8948  decode.d5.loss_mask: 0.3387  decode.d5.loss_dice: 0.4108  decode.d6.loss_cls: 0.8710  decode.d6.loss_mask: 0.3441  decode.d6.loss_dice: 0.4342  decode.d7.loss_cls: 0.8572  decode.d7.loss_mask: 0.3507  decode.d7.loss_dice: 0.4255  decode.d8.loss_cls: 0.9432  decode.d8.loss_mask: 0.3432  decode.d8.loss_dice: 0.4175
08/06 03:02:31 - mmengine - INFO - Iter(train) [  5600/320000]  base_lr: 9.8424e-05 lr: 9.8424e-06  eta: 1 day, 18:47:06  time: 0.4909  data_time: 0.0103  memory: 5891  grad_norm: 157.8341  loss: 14.4390  decode.loss_cls: 0.5659  decode.loss_mask: 0.3003  decode.loss_dice: 0.3560  decode.d0.loss_cls: 1.4966  decode.d0.loss_mask: 0.3507  decode.d0.loss_dice: 0.4495  decode.d1.loss_cls: 0.9147  decode.d1.loss_mask: 0.3217  decode.d1.loss_dice: 0.4048  decode.d2.loss_cls: 0.7046  decode.d2.loss_mask: 0.3140  decode.d2.loss_dice: 0.3896  decode.d3.loss_cls: 0.6879  decode.d3.loss_mask: 0.3179  decode.d3.loss_dice: 0.3826  decode.d4.loss_cls: 0.6727  decode.d4.loss_mask: 0.3070  decode.d4.loss_dice: 0.3862  decode.d5.loss_cls: 0.7010  decode.d5.loss_mask: 0.3040  decode.d5.loss_dice: 0.3638  decode.d6.loss_cls: 0.5702  decode.d6.loss_mask: 0.2997  decode.d6.loss_dice: 0.3546  decode.d7.loss_cls: 0.5923  decode.d7.loss_mask: 0.3008  decode.d7.loss_dice: 0.3812  decode.d8.loss_cls: 0.6165  decode.d8.loss_mask: 0.2972  decode.d8.loss_dice: 0.3351
08/06 03:02:55 - mmengine - INFO - Iter(train) [  5650/320000]  base_lr: 9.8410e-05 lr: 9.8410e-06  eta: 1 day, 18:46:42  time: 0.4903  data_time: 0.0103  memory: 5907  grad_norm: 257.4526  loss: 17.1195  decode.loss_cls: 0.8301  decode.loss_mask: 0.3599  decode.loss_dice: 0.4066  decode.d0.loss_cls: 1.7303  decode.d0.loss_mask: 0.4214  decode.d0.loss_dice: 0.5112  decode.d1.loss_cls: 1.1109  decode.d1.loss_mask: 0.3479  decode.d1.loss_dice: 0.4190  decode.d2.loss_cls: 0.9453  decode.d2.loss_mask: 0.3108  decode.d2.loss_dice: 0.3698  decode.d3.loss_cls: 0.8636  decode.d3.loss_mask: 0.3193  decode.d3.loss_dice: 0.3795  decode.d4.loss_cls: 0.8110  decode.d4.loss_mask: 0.3777  decode.d4.loss_dice: 0.3928  decode.d5.loss_cls: 0.8214  decode.d5.loss_mask: 0.4009  decode.d5.loss_dice: 0.4216  decode.d6.loss_cls: 0.7685  decode.d6.loss_mask: 0.3396  decode.d6.loss_dice: 0.4047  decode.d7.loss_cls: 0.8057  decode.d7.loss_mask: 0.3300  decode.d7.loss_dice: 0.4316  decode.d8.loss_cls: 0.8046  decode.d8.loss_mask: 0.3171  decode.d8.loss_dice: 0.3667
08/06 03:03:20 - mmengine - INFO - Iter(train) [  5700/320000]  base_lr: 9.8396e-05 lr: 9.8396e-06  eta: 1 day, 18:46:16  time: 0.4892  data_time: 0.0102  memory: 5907  grad_norm: 180.5857  loss: 16.5158  decode.loss_cls: 0.7868  decode.loss_mask: 0.3025  decode.loss_dice: 0.4559  decode.d0.loss_cls: 1.7733  decode.d0.loss_mask: 0.3620  decode.d0.loss_dice: 0.4667  decode.d1.loss_cls: 1.0731  decode.d1.loss_mask: 0.2751  decode.d1.loss_dice: 0.3917  decode.d2.loss_cls: 0.8681  decode.d2.loss_mask: 0.2732  decode.d2.loss_dice: 0.3655  decode.d3.loss_cls: 0.8823  decode.d3.loss_mask: 0.2896  decode.d3.loss_dice: 0.3735  decode.d4.loss_cls: 0.8449  decode.d4.loss_mask: 0.3083  decode.d4.loss_dice: 0.3992  decode.d5.loss_cls: 0.8509  decode.d5.loss_mask: 0.2739  decode.d5.loss_dice: 0.3871  decode.d6.loss_cls: 0.7802  decode.d6.loss_mask: 0.2769  decode.d6.loss_dice: 0.3802  decode.d7.loss_cls: 0.8109  decode.d7.loss_mask: 0.3167  decode.d7.loss_dice: 0.4340  decode.d8.loss_cls: 0.7629  decode.d8.loss_mask: 0.3024  decode.d8.loss_dice: 0.4480
08/06 03:03:44 - mmengine - INFO - Iter(train) [  5750/320000]  base_lr: 9.8382e-05 lr: 9.8382e-06  eta: 1 day, 18:45:50  time: 0.4882  data_time: 0.0103  memory: 5892  grad_norm: 173.3674  loss: 12.7926  decode.loss_cls: 0.4393  decode.loss_mask: 0.4478  decode.loss_dice: 0.3445  decode.d0.loss_cls: 1.3416  decode.d0.loss_mask: 0.3699  decode.d0.loss_dice: 0.3355  decode.d1.loss_cls: 0.6732  decode.d1.loss_mask: 0.3445  decode.d1.loss_dice: 0.2957  decode.d2.loss_cls: 0.4691  decode.d2.loss_mask: 0.3321  decode.d2.loss_dice: 0.2953  decode.d3.loss_cls: 0.4465  decode.d3.loss_mask: 0.3329  decode.d3.loss_dice: 0.3048  decode.d4.loss_cls: 0.5002  decode.d4.loss_mask: 0.3683  decode.d4.loss_dice: 0.2983  decode.d5.loss_cls: 0.4494  decode.d5.loss_mask: 0.3662  decode.d5.loss_dice: 0.3220  decode.d6.loss_cls: 0.4918  decode.d6.loss_mask: 0.4026  decode.d6.loss_dice: 0.3354  decode.d7.loss_cls: 0.5268  decode.d7.loss_mask: 0.4076  decode.d7.loss_dice: 0.3257  decode.d8.loss_cls: 0.4634  decode.d8.loss_mask: 0.4392  decode.d8.loss_dice: 0.3234
08/06 03:04:09 - mmengine - INFO - Iter(train) [  5800/320000]  base_lr: 9.8368e-05 lr: 9.8368e-06  eta: 1 day, 18:45:25  time: 0.4904  data_time: 0.0104  memory: 5910  grad_norm: 189.3755  loss: 15.7713  decode.loss_cls: 0.6470  decode.loss_mask: 0.4283  decode.loss_dice: 0.4310  decode.d0.loss_cls: 1.5535  decode.d0.loss_mask: 0.4654  decode.d0.loss_dice: 0.5123  decode.d1.loss_cls: 0.8091  decode.d1.loss_mask: 0.3831  decode.d1.loss_dice: 0.4334  decode.d2.loss_cls: 0.6000  decode.d2.loss_mask: 0.3809  decode.d2.loss_dice: 0.4401  decode.d3.loss_cls: 0.5861  decode.d3.loss_mask: 0.4009  decode.d3.loss_dice: 0.4247  decode.d4.loss_cls: 0.6347  decode.d4.loss_mask: 0.3996  decode.d4.loss_dice: 0.4208  decode.d5.loss_cls: 0.6236  decode.d5.loss_mask: 0.3917  decode.d5.loss_dice: 0.4072  decode.d6.loss_cls: 0.5825  decode.d6.loss_mask: 0.4108  decode.d6.loss_dice: 0.4278  decode.d7.loss_cls: 0.6218  decode.d7.loss_mask: 0.4128  decode.d7.loss_dice: 0.4213  decode.d8.loss_cls: 0.6731  decode.d8.loss_mask: 0.4253  decode.d8.loss_dice: 0.4227
08/06 03:04:33 - mmengine - INFO - Iter(train) [  5850/320000]  base_lr: 9.8353e-05 lr: 9.8353e-06  eta: 1 day, 18:45:04  time: 0.4903  data_time: 0.0100  memory: 5892  grad_norm: 188.8806  loss: 18.6416  decode.loss_cls: 1.0059  decode.loss_mask: 0.3041  decode.loss_dice: 0.4488  decode.d0.loss_cls: 1.7776  decode.d0.loss_mask: 0.3525  decode.d0.loss_dice: 0.5196  decode.d1.loss_cls: 1.2048  decode.d1.loss_mask: 0.2904  decode.d1.loss_dice: 0.4244  decode.d2.loss_cls: 1.0625  decode.d2.loss_mask: 0.3010  decode.d2.loss_dice: 0.4579  decode.d3.loss_cls: 0.8878  decode.d3.loss_mask: 0.3182  decode.d3.loss_dice: 0.4551  decode.d4.loss_cls: 1.0509  decode.d4.loss_mask: 0.3119  decode.d4.loss_dice: 0.4435  decode.d5.loss_cls: 1.0851  decode.d5.loss_mask: 0.2954  decode.d5.loss_dice: 0.4162  decode.d6.loss_cls: 1.0041  decode.d6.loss_mask: 0.2870  decode.d6.loss_dice: 0.4215  decode.d7.loss_cls: 1.0246  decode.d7.loss_mask: 0.3056  decode.d7.loss_dice: 0.4352  decode.d8.loss_cls: 0.9959  decode.d8.loss_mask: 0.3110  decode.d8.loss_dice: 0.4430
08/06 03:04:58 - mmengine - INFO - Iter(train) [  5900/320000]  base_lr: 9.8339e-05 lr: 9.8339e-06  eta: 1 day, 18:44:39  time: 0.4899  data_time: 0.0102  memory: 5908  grad_norm: 145.2628  loss: 13.7920  decode.loss_cls: 0.5581  decode.loss_mask: 0.3455  decode.loss_dice: 0.3188  decode.d0.loss_cls: 1.5155  decode.d0.loss_mask: 0.3343  decode.d0.loss_dice: 0.3626  decode.d1.loss_cls: 0.7299  decode.d1.loss_mask: 0.3443  decode.d1.loss_dice: 0.3421  decode.d2.loss_cls: 0.5483  decode.d2.loss_mask: 0.3532  decode.d2.loss_dice: 0.3355  decode.d3.loss_cls: 0.6182  decode.d3.loss_mask: 0.3384  decode.d3.loss_dice: 0.3106  decode.d4.loss_cls: 0.6734  decode.d4.loss_mask: 0.3375  decode.d4.loss_dice: 0.3113  decode.d5.loss_cls: 0.6258  decode.d5.loss_mask: 0.3420  decode.d5.loss_dice: 0.3351  decode.d6.loss_cls: 0.6111  decode.d6.loss_mask: 0.3389  decode.d6.loss_dice: 0.3183  decode.d7.loss_cls: 0.6193  decode.d7.loss_mask: 0.3473  decode.d7.loss_dice: 0.3186  decode.d8.loss_cls: 0.5813  decode.d8.loss_mask: 0.3485  decode.d8.loss_dice: 0.3280
08/06 03:05:22 - mmengine - INFO - Iter(train) [  5950/320000]  base_lr: 9.8325e-05 lr: 9.8325e-06  eta: 1 day, 18:44:15  time: 0.4903  data_time: 0.0102  memory: 5891  grad_norm: 105.4127  loss: 13.4848  decode.loss_cls: 0.5984  decode.loss_mask: 0.2712  decode.loss_dice: 0.3095  decode.d0.loss_cls: 1.7220  decode.d0.loss_mask: 0.2767  decode.d0.loss_dice: 0.3708  decode.d1.loss_cls: 0.8406  decode.d1.loss_mask: 0.2797  decode.d1.loss_dice: 0.3297  decode.d2.loss_cls: 0.6219  decode.d2.loss_mask: 0.2805  decode.d2.loss_dice: 0.3046  decode.d3.loss_cls: 0.5956  decode.d3.loss_mask: 0.2814  decode.d3.loss_dice: 0.3068  decode.d4.loss_cls: 0.7105  decode.d4.loss_mask: 0.2915  decode.d4.loss_dice: 0.3206  decode.d5.loss_cls: 0.6734  decode.d5.loss_mask: 0.2766  decode.d5.loss_dice: 0.3072  decode.d6.loss_cls: 0.5856  decode.d6.loss_mask: 0.2739  decode.d6.loss_dice: 0.3048  decode.d7.loss_cls: 0.5671  decode.d7.loss_mask: 0.2728  decode.d7.loss_dice: 0.3175  decode.d8.loss_cls: 0.5946  decode.d8.loss_mask: 0.2749  decode.d8.loss_dice: 0.3244
08/06 03:05:47 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250806_021634
08/06 03:05:47 - mmengine - INFO - Iter(train) [  6000/320000]  base_lr: 9.8311e-05 lr: 9.8311e-06  eta: 1 day, 18:43:50  time: 0.4902  data_time: 0.0101  memory: 5907  grad_norm: 199.8696  loss: 13.9089  decode.loss_cls: 0.6440  decode.loss_mask: 0.2651  decode.loss_dice: 0.3461  decode.d0.loss_cls: 1.6699  decode.d0.loss_mask: 0.2765  decode.d0.loss_dice: 0.3665  decode.d1.loss_cls: 0.8030  decode.d1.loss_mask: 0.2790  decode.d1.loss_dice: 0.3211  decode.d2.loss_cls: 0.6414  decode.d2.loss_mask: 0.2630  decode.d2.loss_dice: 0.3108  decode.d3.loss_cls: 0.6822  decode.d3.loss_mask: 0.2656  decode.d3.loss_dice: 0.3292  decode.d4.loss_cls: 0.6390  decode.d4.loss_mask: 0.2745  decode.d4.loss_dice: 0.3104  decode.d5.loss_cls: 0.6549  decode.d5.loss_mask: 0.2801  decode.d5.loss_dice: 0.3231  decode.d6.loss_cls: 0.6883  decode.d6.loss_mask: 0.2752  decode.d6.loss_dice: 0.3451  decode.d7.loss_cls: 0.7369  decode.d7.loss_mask: 0.2869  decode.d7.loss_dice: 0.3538  decode.d8.loss_cls: 0.6381  decode.d8.loss_mask: 0.2821  decode.d8.loss_dice: 0.3570
08/06 03:06:11 - mmengine - INFO - Iter(train) [  6050/320000]  base_lr: 9.8297e-05 lr: 9.8297e-06  eta: 1 day, 18:43:25  time: 0.4898  data_time: 0.0101  memory: 5891  grad_norm: 186.5623  loss: 15.0276  decode.loss_cls: 0.6410  decode.loss_mask: 0.3333  decode.loss_dice: 0.4006  decode.d0.loss_cls: 1.4675  decode.d0.loss_mask: 0.3163  decode.d0.loss_dice: 0.3755  decode.d1.loss_cls: 0.8791  decode.d1.loss_mask: 0.3636  decode.d1.loss_dice: 0.3542  decode.d2.loss_cls: 0.6871  decode.d2.loss_mask: 0.3062  decode.d2.loss_dice: 0.3447  decode.d3.loss_cls: 0.6423  decode.d3.loss_mask: 0.2832  decode.d3.loss_dice: 0.3237  decode.d4.loss_cls: 0.5971  decode.d4.loss_mask: 0.3979  decode.d4.loss_dice: 0.3639  decode.d5.loss_cls: 0.5608  decode.d5.loss_mask: 0.4759  decode.d5.loss_dice: 0.3501  decode.d6.loss_cls: 0.6498  decode.d6.loss_mask: 0.4599  decode.d6.loss_dice: 0.3618  decode.d7.loss_cls: 0.6786  decode.d7.loss_mask: 0.4476  decode.d7.loss_dice: 0.3649  decode.d8.loss_cls: 0.7300  decode.d8.loss_mask: 0.5035  decode.d8.loss_dice: 0.3676
08/06 03:06:36 - mmengine - INFO - Iter(train) [  6100/320000]  base_lr: 9.8283e-05 lr: 9.8283e-06  eta: 1 day, 18:43:01  time: 0.4912  data_time: 0.0105  memory: 5877  grad_norm: 199.2255  loss: 15.9399  decode.loss_cls: 0.7783  decode.loss_mask: 0.3336  decode.loss_dice: 0.4412  decode.d0.loss_cls: 1.4695  decode.d0.loss_mask: 0.3526  decode.d0.loss_dice: 0.5320  decode.d1.loss_cls: 0.9179  decode.d1.loss_mask: 0.3547  decode.d1.loss_dice: 0.4589  decode.d2.loss_cls: 0.7635  decode.d2.loss_mask: 0.3379  decode.d2.loss_dice: 0.4396  decode.d3.loss_cls: 0.5995  decode.d3.loss_mask: 0.3643  decode.d3.loss_dice: 0.4792  decode.d4.loss_cls: 0.6660  decode.d4.loss_mask: 0.3416  decode.d4.loss_dice: 0.4536  decode.d5.loss_cls: 0.6626  decode.d5.loss_mask: 0.3363  decode.d5.loss_dice: 0.4470  decode.d6.loss_cls: 0.6685  decode.d6.loss_mask: 0.3502  decode.d6.loss_dice: 0.4805  decode.d7.loss_cls: 0.6670  decode.d7.loss_mask: 0.3365  decode.d7.loss_dice: 0.4455  decode.d8.loss_cls: 0.7046  decode.d8.loss_mask: 0.3388  decode.d8.loss_dice: 0.4183
08/06 03:07:00 - mmengine - INFO - Iter(train) [  6150/320000]  base_lr: 9.8269e-05 lr: 9.8269e-06  eta: 1 day, 18:42:44  time: 0.4902  data_time: 0.0103  memory: 5875  grad_norm: 282.5012  loss: 17.7189  decode.loss_cls: 0.8671  decode.loss_mask: 0.4482  decode.loss_dice: 0.4279  decode.d0.loss_cls: 1.7270  decode.d0.loss_mask: 0.4065  decode.d0.loss_dice: 0.4482  decode.d1.loss_cls: 0.9266  decode.d1.loss_mask: 0.5120  decode.d1.loss_dice: 0.4668  decode.d2.loss_cls: 0.8369  decode.d2.loss_mask: 0.4125  decode.d2.loss_dice: 0.4098  decode.d3.loss_cls: 0.8677  decode.d3.loss_mask: 0.3781  decode.d3.loss_dice: 0.4214  decode.d4.loss_cls: 0.8144  decode.d4.loss_mask: 0.4008  decode.d4.loss_dice: 0.4026  decode.d5.loss_cls: 0.8063  decode.d5.loss_mask: 0.4050  decode.d5.loss_dice: 0.4179  decode.d6.loss_cls: 0.7710  decode.d6.loss_mask: 0.3767  decode.d6.loss_dice: 0.4121  decode.d7.loss_cls: 0.7916  decode.d7.loss_mask: 0.3556  decode.d7.loss_dice: 0.4354  decode.d8.loss_cls: 0.8923  decode.d8.loss_mask: 0.4430  decode.d8.loss_dice: 0.4375
08/06 03:07:25 - mmengine - INFO - Iter(train) [  6200/320000]  base_lr: 9.8255e-05 lr: 9.8255e-06  eta: 1 day, 18:42:19  time: 0.4896  data_time: 0.0101  memory: 5892  grad_norm: 388.7559  loss: 16.6966  decode.loss_cls: 0.7743  decode.loss_mask: 0.3787  decode.loss_dice: 0.4700  decode.d0.loss_cls: 1.7441  decode.d0.loss_mask: 0.3647  decode.d0.loss_dice: 0.4352  decode.d1.loss_cls: 0.9345  decode.d1.loss_mask: 0.3721  decode.d1.loss_dice: 0.4076  decode.d2.loss_cls: 0.8272  decode.d2.loss_mask: 0.3497  decode.d2.loss_dice: 0.3737  decode.d3.loss_cls: 0.7147  decode.d3.loss_mask: 0.3523  decode.d3.loss_dice: 0.3812  decode.d4.loss_cls: 0.7572  decode.d4.loss_mask: 0.3808  decode.d4.loss_dice: 0.4194  decode.d5.loss_cls: 0.6917  decode.d5.loss_mask: 0.3634  decode.d5.loss_dice: 0.4224  decode.d6.loss_cls: 0.6635  decode.d6.loss_mask: 0.3758  decode.d6.loss_dice: 0.4474  decode.d7.loss_cls: 0.6881  decode.d7.loss_mask: 0.4449  decode.d7.loss_dice: 0.5092  decode.d8.loss_cls: 0.8115  decode.d8.loss_mask: 0.3813  decode.d8.loss_dice: 0.4600
08/06 03:07:49 - mmengine - INFO - Iter(train) [  6250/320000]  base_lr: 9.8241e-05 lr: 9.8241e-06  eta: 1 day, 18:41:55  time: 0.4909  data_time: 0.0103  memory: 5910  grad_norm: 137.4566  loss: 12.2888  decode.loss_cls: 0.5049  decode.loss_mask: 0.2598  decode.loss_dice: 0.2887  decode.d0.loss_cls: 1.5997  decode.d0.loss_mask: 0.2555  decode.d0.loss_dice: 0.3172  decode.d1.loss_cls: 0.7625  decode.d1.loss_mask: 0.2650  decode.d1.loss_dice: 0.2992  decode.d2.loss_cls: 0.5778  decode.d2.loss_mask: 0.2562  decode.d2.loss_dice: 0.2969  decode.d3.loss_cls: 0.5459  decode.d3.loss_mask: 0.2611  decode.d3.loss_dice: 0.3134  decode.d4.loss_cls: 0.5780  decode.d4.loss_mask: 0.2622  decode.d4.loss_dice: 0.3111  decode.d5.loss_cls: 0.5051  decode.d5.loss_mask: 0.2612  decode.d5.loss_dice: 0.2947  decode.d6.loss_cls: 0.5025  decode.d6.loss_mask: 0.2566  decode.d6.loss_dice: 0.2877  decode.d7.loss_cls: 0.5470  decode.d7.loss_mask: 0.2587  decode.d7.loss_dice: 0.2880  decode.d8.loss_cls: 0.5608  decode.d8.loss_mask: 0.2614  decode.d8.loss_dice: 0.3100
08/06 03:08:14 - mmengine - INFO - Iter(train) [  6300/320000]  base_lr: 9.8227e-05 lr: 9.8227e-06  eta: 1 day, 18:41:30  time: 0.4903  data_time: 0.0104  memory: 5892  grad_norm: 179.3900  loss: 15.6589  decode.loss_cls: 0.7488  decode.loss_mask: 0.3541  decode.loss_dice: 0.3873  decode.d0.loss_cls: 1.7329  decode.d0.loss_mask: 0.3304  decode.d0.loss_dice: 0.4475  decode.d1.loss_cls: 0.7593  decode.d1.loss_mask: 0.3315  decode.d1.loss_dice: 0.4480  decode.d2.loss_cls: 0.6530  decode.d2.loss_mask: 0.3534  decode.d2.loss_dice: 0.3900  decode.d3.loss_cls: 0.6142  decode.d3.loss_mask: 0.3571  decode.d3.loss_dice: 0.3940  decode.d4.loss_cls: 0.6618  decode.d4.loss_mask: 0.3655  decode.d4.loss_dice: 0.3932  decode.d5.loss_cls: 0.7121  decode.d5.loss_mask: 0.3499  decode.d5.loss_dice: 0.4060  decode.d6.loss_cls: 0.7204  decode.d6.loss_mask: 0.3465  decode.d6.loss_dice: 0.3909  decode.d7.loss_cls: 0.7087  decode.d7.loss_mask: 0.3626  decode.d7.loss_dice: 0.4159  decode.d8.loss_cls: 0.7729  decode.d8.loss_mask: 0.3565  decode.d8.loss_dice: 0.3943
08/06 03:08:38 - mmengine - INFO - Iter(train) [  6350/320000]  base_lr: 9.8213e-05 lr: 9.8213e-06  eta: 1 day, 18:41:06  time: 0.4894  data_time: 0.0103  memory: 5891  grad_norm: 288.1376  loss: 16.2071  decode.loss_cls: 0.6674  decode.loss_mask: 0.3692  decode.loss_dice: 0.3937  decode.d0.loss_cls: 1.7198  decode.d0.loss_mask: 0.4088  decode.d0.loss_dice: 0.4342  decode.d1.loss_cls: 0.9692  decode.d1.loss_mask: 0.3684  decode.d1.loss_dice: 0.3964  decode.d2.loss_cls: 0.6372  decode.d2.loss_mask: 0.4292  decode.d2.loss_dice: 0.3995  decode.d3.loss_cls: 0.6463  decode.d3.loss_mask: 0.4298  decode.d3.loss_dice: 0.3660  decode.d4.loss_cls: 0.6924  decode.d4.loss_mask: 0.3849  decode.d4.loss_dice: 0.3826  decode.d5.loss_cls: 0.8077  decode.d5.loss_mask: 0.3724  decode.d5.loss_dice: 0.4084  decode.d6.loss_cls: 0.7253  decode.d6.loss_mask: 0.4044  decode.d6.loss_dice: 0.4080  decode.d7.loss_cls: 0.7231  decode.d7.loss_mask: 0.3720  decode.d7.loss_dice: 0.3877  decode.d8.loss_cls: 0.7011  decode.d8.loss_mask: 0.3986  decode.d8.loss_dice: 0.4034
08/06 03:09:03 - mmengine - INFO - Iter(train) [  6400/320000]  base_lr: 9.8198e-05 lr: 9.8198e-06  eta: 1 day, 18:40:42  time: 0.4895  data_time: 0.0102  memory: 5910  grad_norm: 156.0204  loss: 12.6339  decode.loss_cls: 0.5462  decode.loss_mask: 0.3070  decode.loss_dice: 0.3724  decode.d0.loss_cls: 1.3163  decode.d0.loss_mask: 0.3280  decode.d0.loss_dice: 0.4268  decode.d1.loss_cls: 0.6734  decode.d1.loss_mask: 0.3022  decode.d1.loss_dice: 0.3498  decode.d2.loss_cls: 0.4651  decode.d2.loss_mask: 0.2836  decode.d2.loss_dice: 0.3480  decode.d3.loss_cls: 0.4862  decode.d3.loss_mask: 0.3067  decode.d3.loss_dice: 0.3853  decode.d4.loss_cls: 0.5324  decode.d4.loss_mask: 0.2967  decode.d4.loss_dice: 0.3617  decode.d5.loss_cls: 0.5174  decode.d5.loss_mask: 0.2959  decode.d5.loss_dice: 0.3614  decode.d6.loss_cls: 0.4658  decode.d6.loss_mask: 0.2872  decode.d6.loss_dice: 0.3533  decode.d7.loss_cls: 0.4504  decode.d7.loss_mask: 0.2914  decode.d7.loss_dice: 0.3580  decode.d8.loss_cls: 0.4717  decode.d8.loss_mask: 0.2982  decode.d8.loss_dice: 0.3952
08/06 03:09:27 - mmengine - INFO - Iter(train) [  6450/320000]  base_lr: 9.8184e-05 lr: 9.8184e-06  eta: 1 day, 18:40:17  time: 0.4900  data_time: 0.0103  memory: 5907  grad_norm: 145.8460  loss: 13.9070  decode.loss_cls: 0.5601  decode.loss_mask: 0.3442  decode.loss_dice: 0.3345  decode.d0.loss_cls: 1.4002  decode.d0.loss_mask: 0.3498  decode.d0.loss_dice: 0.4109  decode.d1.loss_cls: 0.6789  decode.d1.loss_mask: 0.3658  decode.d1.loss_dice: 0.3626  decode.d2.loss_cls: 0.5708  decode.d2.loss_mask: 0.3739  decode.d2.loss_dice: 0.3415  decode.d3.loss_cls: 0.5753  decode.d3.loss_mask: 0.3526  decode.d3.loss_dice: 0.3339  decode.d4.loss_cls: 0.5790  decode.d4.loss_mask: 0.3666  decode.d4.loss_dice: 0.3777  decode.d5.loss_cls: 0.6398  decode.d5.loss_mask: 0.3570  decode.d5.loss_dice: 0.3491  decode.d6.loss_cls: 0.5806  decode.d6.loss_mask: 0.3511  decode.d6.loss_dice: 0.3445  decode.d7.loss_cls: 0.6157  decode.d7.loss_mask: 0.3398  decode.d7.loss_dice: 0.3303  decode.d8.loss_cls: 0.6544  decode.d8.loss_mask: 0.3366  decode.d8.loss_dice: 0.3299
08/06 03:09:52 - mmengine - INFO - Iter(train) [  6500/320000]  base_lr: 9.8170e-05 lr: 9.8170e-06  eta: 1 day, 18:39:53  time: 0.4907  data_time: 0.0101  memory: 5875  grad_norm: 236.0399  loss: 14.9793  decode.loss_cls: 0.6538  decode.loss_mask: 0.2958  decode.loss_dice: 0.3697  decode.d0.loss_cls: 1.6756  decode.d0.loss_mask: 0.2902  decode.d0.loss_dice: 0.4497  decode.d1.loss_cls: 0.9813  decode.d1.loss_mask: 0.2850  decode.d1.loss_dice: 0.4061  decode.d2.loss_cls: 0.8139  decode.d2.loss_mask: 0.3263  decode.d2.loss_dice: 0.4038  decode.d3.loss_cls: 0.7140  decode.d3.loss_mask: 0.3063  decode.d3.loss_dice: 0.3564  decode.d4.loss_cls: 0.6990  decode.d4.loss_mask: 0.2927  decode.d4.loss_dice: 0.3734  decode.d5.loss_cls: 0.6027  decode.d5.loss_mask: 0.3094  decode.d5.loss_dice: 0.3807  decode.d6.loss_cls: 0.6408  decode.d6.loss_mask: 0.3014  decode.d6.loss_dice: 0.3528  decode.d7.loss_cls: 0.6782  decode.d7.loss_mask: 0.2830  decode.d7.loss_dice: 0.3659  decode.d8.loss_cls: 0.6839  decode.d8.loss_mask: 0.3139  decode.d8.loss_dice: 0.3738
