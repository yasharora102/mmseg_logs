==========================================
SLURM_JOB_ID = 2468785
SLURM_NODELIST = gnode070
SLURM_JOB_GPUS = 0
==========================================
07/31 17:32:27 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.23 (main, Jun  5 2025, 13:40:20) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 268722126
    GPU 0: NVIDIA GeForce RTX 2080 Ti
    CUDA_HOME: /opt/cuda-12.1/
    NVCC: Cuda compilation tools, release 12.1, V12.1.66
    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
    PyTorch: 2.1.2
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 268722126
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

07/31 17:32:27 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=16, enable=False)
backbone_embed_multi = dict(decay_mult=0.0, lr_mult=0.1)
backbone_norm_multi = dict(decay_mult=0.0, lr_mult=0.1)
crop_size = (
    512,
    1024,
)
custom_keys = dict({
    'absolute_pos_embed':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone':
    dict(decay_mult=1.0, lr_mult=0.1),
    'backbone.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.patch_embed.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.2.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.3.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.4.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.5.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'level_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_feat':
    dict(decay_mult=0.0, lr_mult=1.0),
    'relative_position_bias_table':
    dict(decay_mult=0.0, lr_mult=0.1)
})
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        512,
        1024,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    test_cfg=dict(size_divisor=32),
    type='SegDataPreProcessor')
data_root = '/scratch/seg_benchmark/seg_full_redone_FINAL/'
dataset_type = 'YourDataset_BIG'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False, interval=5000, save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'))
default_scope = 'mmseg'
depths = [
    2,
    2,
    6,
    2,
]
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
img_suffix = '.jpg'
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        attn_drop_rate=0.0,
        depths=[
            2,
            2,
            6,
            2,
        ],
        drop_path_rate=0.3,
        drop_rate=0.0,
        embed_dims=96,
        frozen_stages=-1,
        init_cfg=dict(
            checkpoint=
            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth',
            type='Pretrained'),
        mlp_ratio=4,
        num_heads=[
            3,
            6,
            12,
            24,
        ],
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        patch_norm=True,
        qk_scale=None,
        qkv_bias=True,
        type='SwinTransformer',
        window_size=7,
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            1024,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        test_cfg=dict(size_divisor=32),
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            96,
            192,
            384,
            768,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=57,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 57
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict({
            'absolute_pos_embed':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone':
            dict(decay_mult=1.0, lr_mult=0.1),
            'backbone.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.patch_embed.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.2.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.3.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.4.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.5.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'level_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_feat':
            dict(decay_mult=0.0, lr_mult=1.0),
            'relative_position_bias_table':
            dict(decay_mult=0.0, lr_mult=0.1)
        }),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=80000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth'
randomness = dict(seed=268722126)
resume = False
seg_map_suffix = '.png'
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/seg_benchmark/seg_full_redone_FINAL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    classwise=True, iou_metrics=[
        'mIoU',
    ], type='IoUNanAbsent')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2048,
        1024,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(
    max_iters=80000, type='IterBasedTrainLoop', val_interval=80000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        data_prefix=dict(img_path='train/images', seg_map_path='train/masks'),
        data_root='/scratch/seg_benchmark/seg_full_redone_FINAL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                max_size=4096,
                resize_type='ResizeShortestEdge',
                scales=[
                    512,
                    614,
                    716,
                    819,
                    921,
                    1024,
                    1126,
                    1228,
                    1331,
                    1433,
                    1536,
                    1638,
                    1740,
                    1843,
                    1945,
                    2048,
                ],
                type='RandomChoiceResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    512,
                    1024,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        max_size=4096,
        resize_type='ResizeShortestEdge',
        scales=[
            512,
            614,
            716,
            819,
            921,
            1024,
            1126,
            1228,
            1331,
            1433,
            1536,
            1638,
            1740,
            1843,
            1945,
            2048,
        ],
        type='RandomChoiceResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        1024,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/seg_benchmark/seg_full_redone_FINAL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '/scratch/seg_benchmark/FINAL_seg_full_redone_redo/mask2former_swin_T_seed'

07/31 17:32:33 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
07/31 17:32:33 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:weight_decay=0.05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:decay_mult=1.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr=1e-05
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr_mult=0.1
07/31 17:32:34 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:decay_mult=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
07/31 17:32:34 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
07/31 17:32:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
07/31 17:32:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
07/31 17:32:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
07/31 17:32:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
07/31 17:32:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
07/31 17:32:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
07/31 17:32:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
07/31 17:32:35 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
07/31 17:32:35 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
07/31 17:32:35 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
07/31 17:32:35 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
07/31 17:32:35 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
07/31 17:32:35 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
07/31 17:32:35 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
07/31 17:32:35 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
07/31 17:32:35 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
07/31 17:32:35 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
07/31 17:32:35 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
07/31 17:32:35 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
07/31 17:32:35 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
07/31 17:32:35 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth
07/31 17:32:40 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
07/31 17:32:40 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
07/31 17:32:40 - mmengine - INFO - Checkpoints will be saved to /scratch/seg_benchmark/FINAL_seg_full_redone_redo/mask2former_swin_T_seed.
/home2/yasharora120/miniconda3/envs/mmseg/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400441250/work/aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
07/31 17:33:06 - mmengine - INFO - Iter(train) [   50/80000]  base_lr: 9.9945e-05 lr: 9.9945e-06  eta: 11:33:22  time: 0.4779  data_time: 0.0091  memory: 8941  grad_norm: 158.7529  loss: 103.5878  decode.loss_cls: 4.1269  decode.loss_mask: 2.3342  decode.loss_dice: 4.2844  decode.d0.loss_cls: 8.3327  decode.d0.loss_mask: 2.0047  decode.d0.loss_dice: 3.7635  decode.d1.loss_cls: 3.6634  decode.d1.loss_mask: 2.0226  decode.d1.loss_dice: 3.7663  decode.d2.loss_cls: 3.4959  decode.d2.loss_mask: 1.9676  decode.d2.loss_dice: 3.7496  decode.d3.loss_cls: 3.6017  decode.d3.loss_mask: 2.0541  decode.d3.loss_dice: 3.7522  decode.d4.loss_cls: 3.5722  decode.d4.loss_mask: 2.0224  decode.d4.loss_dice: 3.8309  decode.d5.loss_cls: 3.8127  decode.d5.loss_mask: 2.0562  decode.d5.loss_dice: 3.8829  decode.d6.loss_cls: 3.9971  decode.d6.loss_mask: 2.1437  decode.d6.loss_dice: 4.0060  decode.d7.loss_cls: 4.1027  decode.d7.loss_mask: 2.2193  decode.d7.loss_dice: 4.2701  decode.d8.loss_cls: 4.1231  decode.d8.loss_mask: 2.3437  decode.d8.loss_dice: 4.2850
07/31 17:33:30 - mmengine - INFO - Iter(train) [  100/80000]  base_lr: 9.9889e-05 lr: 9.9889e-06  eta: 11:08:18  time: 0.4802  data_time: 0.0091  memory: 5896  grad_norm: 277.1544  loss: 80.4237  decode.loss_cls: 3.1855  decode.loss_mask: 1.5062  decode.loss_dice: 3.2208  decode.d0.loss_cls: 8.2557  decode.d0.loss_mask: 1.4160  decode.d0.loss_dice: 3.1209  decode.d1.loss_cls: 3.0015  decode.d1.loss_mask: 1.4497  decode.d1.loss_dice: 3.0448  decode.d2.loss_cls: 2.8571  decode.d2.loss_mask: 1.4377  decode.d2.loss_dice: 2.9948  decode.d3.loss_cls: 2.8118  decode.d3.loss_mask: 1.4759  decode.d3.loss_dice: 2.9892  decode.d4.loss_cls: 2.9525  decode.d4.loss_mask: 1.4609  decode.d4.loss_dice: 2.9875  decode.d5.loss_cls: 2.9548  decode.d5.loss_mask: 1.4358  decode.d5.loss_dice: 3.0111  decode.d6.loss_cls: 2.9992  decode.d6.loss_mask: 1.4972  decode.d6.loss_dice: 2.9755  decode.d7.loss_cls: 3.0005  decode.d7.loss_mask: 1.5422  decode.d7.loss_dice: 3.1005  decode.d8.loss_cls: 3.0807  decode.d8.loss_mask: 1.5556  decode.d8.loss_dice: 3.1020
07/31 17:33:54 - mmengine - INFO - Iter(train) [  150/80000]  base_lr: 9.9832e-05 lr: 9.9832e-06  eta: 10:58:23  time: 0.4805  data_time: 0.0088  memory: 5918  grad_norm: 511.9701  loss: 72.6258  decode.loss_cls: 2.8867  decode.loss_mask: 1.3695  decode.loss_dice: 2.6255  decode.d0.loss_cls: 8.2202  decode.d0.loss_mask: 1.2465  decode.d0.loss_dice: 2.6595  decode.d1.loss_cls: 2.8272  decode.d1.loss_mask: 1.3664  decode.d1.loss_dice: 2.5196  decode.d2.loss_cls: 2.7376  decode.d2.loss_mask: 1.3708  decode.d2.loss_dice: 2.4857  decode.d3.loss_cls: 2.6845  decode.d3.loss_mask: 1.3622  decode.d3.loss_dice: 2.5274  decode.d4.loss_cls: 2.7186  decode.d4.loss_mask: 1.4083  decode.d4.loss_dice: 2.5477  decode.d5.loss_cls: 2.7627  decode.d5.loss_mask: 1.3520  decode.d5.loss_dice: 2.5855  decode.d6.loss_cls: 2.7659  decode.d6.loss_mask: 1.4096  decode.d6.loss_dice: 2.6223  decode.d7.loss_cls: 2.6902  decode.d7.loss_mask: 1.4080  decode.d7.loss_dice: 2.6300  decode.d8.loss_cls: 2.8537  decode.d8.loss_mask: 1.3981  decode.d8.loss_dice: 2.5838
07/31 17:34:18 - mmengine - INFO - Iter(train) [  200/80000]  base_lr: 9.9776e-05 lr: 9.9776e-06  eta: 10:53:26  time: 0.4807  data_time: 0.0087  memory: 5916  grad_norm: 276.6380  loss: 59.4730  decode.loss_cls: 2.6709  decode.loss_mask: 1.1412  decode.loss_dice: 1.8064  decode.d0.loss_cls: 7.9887  decode.d0.loss_mask: 1.0561  decode.d0.loss_dice: 2.0599  decode.d1.loss_cls: 2.5044  decode.d1.loss_mask: 1.0015  decode.d1.loss_dice: 1.7444  decode.d2.loss_cls: 2.5458  decode.d2.loss_mask: 1.0309  decode.d2.loss_dice: 1.7190  decode.d3.loss_cls: 2.7009  decode.d3.loss_mask: 1.0261  decode.d3.loss_dice: 1.7049  decode.d4.loss_cls: 2.6482  decode.d4.loss_mask: 1.0251  decode.d4.loss_dice: 1.6632  decode.d5.loss_cls: 2.6664  decode.d5.loss_mask: 1.0546  decode.d5.loss_dice: 1.6393  decode.d6.loss_cls: 2.6141  decode.d6.loss_mask: 1.0355  decode.d6.loss_dice: 1.7288  decode.d7.loss_cls: 2.5672  decode.d7.loss_mask: 1.0388  decode.d7.loss_dice: 1.6874  decode.d8.loss_cls: 2.5839  decode.d8.loss_mask: 1.0640  decode.d8.loss_dice: 1.7555
07/31 17:34:42 - mmengine - INFO - Iter(train) [  250/80000]  base_lr: 9.9720e-05 lr: 9.9720e-06  eta: 10:50:43  time: 0.4816  data_time: 0.0090  memory: 5934  grad_norm: 550.6789  loss: 50.1886  decode.loss_cls: 2.1100  decode.loss_mask: 1.0088  decode.loss_dice: 1.3830  decode.d0.loss_cls: 7.8753  decode.d0.loss_mask: 0.9476  decode.d0.loss_dice: 1.6596  decode.d1.loss_cls: 2.0458  decode.d1.loss_mask: 1.0193  decode.d1.loss_dice: 1.4963  decode.d2.loss_cls: 1.9354  decode.d2.loss_mask: 1.0087  decode.d2.loss_dice: 1.3855  decode.d3.loss_cls: 2.0538  decode.d3.loss_mask: 0.9678  decode.d3.loss_dice: 1.3407  decode.d4.loss_cls: 2.0736  decode.d4.loss_mask: 0.9748  decode.d4.loss_dice: 1.3159  decode.d5.loss_cls: 2.1208  decode.d5.loss_mask: 0.9503  decode.d5.loss_dice: 1.3012  decode.d6.loss_cls: 2.0891  decode.d6.loss_mask: 0.9264  decode.d6.loss_dice: 1.3578  decode.d7.loss_cls: 2.0709  decode.d7.loss_mask: 0.9663  decode.d7.loss_dice: 1.3023  decode.d8.loss_cls: 2.0730  decode.d8.loss_mask: 1.0324  decode.d8.loss_dice: 1.3962
07/31 17:35:07 - mmengine - INFO - Iter(train) [  300/80000]  base_lr: 9.9664e-05 lr: 9.9664e-06  eta: 10:48:50  time: 0.4827  data_time: 0.0089  memory: 5898  grad_norm: 459.9475  loss: 51.2082  decode.loss_cls: 2.3403  decode.loss_mask: 0.9492  decode.loss_dice: 1.2169  decode.d0.loss_cls: 7.7098  decode.d0.loss_mask: 0.9663  decode.d0.loss_dice: 1.6008  decode.d1.loss_cls: 2.3631  decode.d1.loss_mask: 1.0747  decode.d1.loss_dice: 1.3597  decode.d2.loss_cls: 2.2403  decode.d2.loss_mask: 1.0291  decode.d2.loss_dice: 1.2282  decode.d3.loss_cls: 2.3001  decode.d3.loss_mask: 1.0281  decode.d3.loss_dice: 1.2097  decode.d4.loss_cls: 2.2970  decode.d4.loss_mask: 0.9939  decode.d4.loss_dice: 1.1997  decode.d5.loss_cls: 2.4173  decode.d5.loss_mask: 0.9139  decode.d5.loss_dice: 1.1967  decode.d6.loss_cls: 2.3831  decode.d6.loss_mask: 0.9180  decode.d6.loss_dice: 1.1739  decode.d7.loss_cls: 2.3517  decode.d7.loss_mask: 0.9239  decode.d7.loss_dice: 1.2029  decode.d8.loss_cls: 2.3645  decode.d8.loss_mask: 1.0102  decode.d8.loss_dice: 1.2451
07/31 17:35:31 - mmengine - INFO - Iter(train) [  350/80000]  base_lr: 9.9607e-05 lr: 9.9607e-06  eta: 10:47:21  time: 0.4833  data_time: 0.0089  memory: 5897  grad_norm: 493.4419  loss: 53.1020  decode.loss_cls: 2.4691  decode.loss_mask: 1.0397  decode.loss_dice: 1.4210  decode.d0.loss_cls: 7.5808  decode.d0.loss_mask: 1.0235  decode.d0.loss_dice: 1.7384  decode.d1.loss_cls: 2.4843  decode.d1.loss_mask: 0.9794  decode.d1.loss_dice: 1.3778  decode.d2.loss_cls: 2.4309  decode.d2.loss_mask: 0.9975  decode.d2.loss_dice: 1.3217  decode.d3.loss_cls: 2.4112  decode.d3.loss_mask: 0.9644  decode.d3.loss_dice: 1.2565  decode.d4.loss_cls: 2.5233  decode.d4.loss_mask: 0.9285  decode.d4.loss_dice: 1.2653  decode.d5.loss_cls: 2.5276  decode.d5.loss_mask: 0.9274  decode.d5.loss_dice: 1.2814  decode.d6.loss_cls: 2.4645  decode.d6.loss_mask: 0.9124  decode.d6.loss_dice: 1.2724  decode.d7.loss_cls: 2.4278  decode.d7.loss_mask: 0.9465  decode.d7.loss_dice: 1.2945  decode.d8.loss_cls: 2.4624  decode.d8.loss_mask: 0.9906  decode.d8.loss_dice: 1.3810
07/31 17:35:55 - mmengine - INFO - Iter(train) [  400/80000]  base_lr: 9.9551e-05 lr: 9.9551e-06  eta: 10:46:13  time: 0.4837  data_time: 0.0091  memory: 5916  grad_norm: 307.5559  loss: 46.6676  decode.loss_cls: 2.4555  decode.loss_mask: 0.7543  decode.loss_dice: 0.9781  decode.d0.loss_cls: 7.4073  decode.d0.loss_mask: 0.7822  decode.d0.loss_dice: 1.2993  decode.d1.loss_cls: 2.4052  decode.d1.loss_mask: 0.8552  decode.d1.loss_dice: 1.0925  decode.d2.loss_cls: 2.2712  decode.d2.loss_mask: 0.8291  decode.d2.loss_dice: 1.0148  decode.d3.loss_cls: 2.2901  decode.d3.loss_mask: 0.8025  decode.d3.loss_dice: 1.0035  decode.d4.loss_cls: 2.3199  decode.d4.loss_mask: 0.7581  decode.d4.loss_dice: 0.9910  decode.d5.loss_cls: 2.3358  decode.d5.loss_mask: 0.7187  decode.d5.loss_dice: 0.9397  decode.d6.loss_cls: 2.4511  decode.d6.loss_mask: 0.7102  decode.d6.loss_dice: 0.9322  decode.d7.loss_cls: 2.4714  decode.d7.loss_mask: 0.7170  decode.d7.loss_dice: 0.9752  decode.d8.loss_cls: 2.4467  decode.d8.loss_mask: 0.7151  decode.d8.loss_dice: 0.9448
07/31 17:36:19 - mmengine - INFO - Iter(train) [  450/80000]  base_lr: 9.9495e-05 lr: 9.9495e-06  eta: 10:45:16  time: 0.4844  data_time: 0.0089  memory: 5933  grad_norm: 324.2250  loss: 45.5983  decode.loss_cls: 2.5034  decode.loss_mask: 0.6473  decode.loss_dice: 0.9240  decode.d0.loss_cls: 7.3075  decode.d0.loss_mask: 0.7743  decode.d0.loss_dice: 1.3036  decode.d1.loss_cls: 2.4168  decode.d1.loss_mask: 0.6817  decode.d1.loss_dice: 0.9795  decode.d2.loss_cls: 2.3639  decode.d2.loss_mask: 0.6779  decode.d2.loss_dice: 0.8946  decode.d3.loss_cls: 2.3233  decode.d3.loss_mask: 0.6923  decode.d3.loss_dice: 0.9040  decode.d4.loss_cls: 2.4437  decode.d4.loss_mask: 0.6438  decode.d4.loss_dice: 0.8296  decode.d5.loss_cls: 2.4782  decode.d5.loss_mask: 0.6893  decode.d5.loss_dice: 0.8862  decode.d6.loss_cls: 2.4603  decode.d6.loss_mask: 0.7087  decode.d6.loss_dice: 0.9486  decode.d7.loss_cls: 2.4472  decode.d7.loss_mask: 0.6834  decode.d7.loss_dice: 0.8878  decode.d8.loss_cls: 2.5074  decode.d8.loss_mask: 0.6496  decode.d8.loss_dice: 0.9404
07/31 17:36:43 - mmengine - INFO - Iter(train) [  500/80000]  base_lr: 9.9438e-05 lr: 9.9438e-06  eta: 10:44:37  time: 0.4841  data_time: 0.0091  memory: 5918  grad_norm: 376.1060  loss: 45.9950  decode.loss_cls: 2.6506  decode.loss_mask: 0.7146  decode.loss_dice: 0.8541  decode.d0.loss_cls: 7.1922  decode.d0.loss_mask: 0.7308  decode.d0.loss_dice: 1.1517  decode.d1.loss_cls: 2.3736  decode.d1.loss_mask: 0.6652  decode.d1.loss_dice: 0.9075  decode.d2.loss_cls: 2.3385  decode.d2.loss_mask: 0.6730  decode.d2.loss_dice: 0.9036  decode.d3.loss_cls: 2.3948  decode.d3.loss_mask: 0.6759  decode.d3.loss_dice: 0.9016  decode.d4.loss_cls: 2.4484  decode.d4.loss_mask: 0.6823  decode.d4.loss_dice: 0.9185  decode.d5.loss_cls: 2.5000  decode.d5.loss_mask: 0.7539  decode.d5.loss_dice: 0.9408  decode.d6.loss_cls: 2.5154  decode.d6.loss_mask: 0.7401  decode.d6.loss_dice: 0.9253  decode.d7.loss_cls: 2.6073  decode.d7.loss_mask: 0.7368  decode.d7.loss_dice: 0.8478  decode.d8.loss_cls: 2.6338  decode.d8.loss_mask: 0.7185  decode.d8.loss_dice: 0.8983
07/31 17:37:07 - mmengine - INFO - Iter(train) [  550/80000]  base_lr: 9.9382e-05 lr: 9.9382e-06  eta: 10:43:53  time: 0.4838  data_time: 0.0091  memory: 5881  grad_norm: 260.6026  loss: 39.9233  decode.loss_cls: 2.1522  decode.loss_mask: 0.6424  decode.loss_dice: 0.7513  decode.d0.loss_cls: 6.9537  decode.d0.loss_mask: 0.6222  decode.d0.loss_dice: 0.9926  decode.d1.loss_cls: 2.2718  decode.d1.loss_mask: 0.5382  decode.d1.loss_dice: 0.7363  decode.d2.loss_cls: 2.2481  decode.d2.loss_mask: 0.5582  decode.d2.loss_dice: 0.6694  decode.d3.loss_cls: 2.0836  decode.d3.loss_mask: 0.5857  decode.d3.loss_dice: 0.6961  decode.d4.loss_cls: 2.0798  decode.d4.loss_mask: 0.5915  decode.d4.loss_dice: 0.7564  decode.d5.loss_cls: 2.2409  decode.d5.loss_mask: 0.5817  decode.d5.loss_dice: 0.7140  decode.d6.loss_cls: 2.1323  decode.d6.loss_mask: 0.6167  decode.d6.loss_dice: 0.7148  decode.d7.loss_cls: 2.1770  decode.d7.loss_mask: 0.6241  decode.d7.loss_dice: 0.7167  decode.d8.loss_cls: 2.1688  decode.d8.loss_mask: 0.5904  decode.d8.loss_dice: 0.7165
07/31 17:37:32 - mmengine - INFO - Iter(train) [  600/80000]  base_lr: 9.9326e-05 lr: 9.9326e-06  eta: 10:43:09  time: 0.4830  data_time: 0.0091  memory: 5916  grad_norm: 596.4969  loss: 42.5622  decode.loss_cls: 2.2673  decode.loss_mask: 0.6622  decode.loss_dice: 0.9255  decode.d0.loss_cls: 6.9001  decode.d0.loss_mask: 0.7399  decode.d0.loss_dice: 1.1776  decode.d1.loss_cls: 2.2724  decode.d1.loss_mask: 0.7138  decode.d1.loss_dice: 0.9120  decode.d2.loss_cls: 2.2638  decode.d2.loss_mask: 0.6136  decode.d2.loss_dice: 0.8438  decode.d3.loss_cls: 2.2518  decode.d3.loss_mask: 0.5780  decode.d3.loss_dice: 0.8231  decode.d4.loss_cls: 2.2263  decode.d4.loss_mask: 0.6097  decode.d4.loss_dice: 0.8574  decode.d5.loss_cls: 2.2949  decode.d5.loss_mask: 0.6084  decode.d5.loss_dice: 0.8380  decode.d6.loss_cls: 2.2289  decode.d6.loss_mask: 0.6256  decode.d6.loss_dice: 0.8422  decode.d7.loss_cls: 2.3646  decode.d7.loss_mask: 0.5891  decode.d7.loss_dice: 0.8191  decode.d8.loss_cls: 2.3092  decode.d8.loss_mask: 0.5629  decode.d8.loss_dice: 0.8411
07/31 17:37:56 - mmengine - INFO - Iter(train) [  650/80000]  base_lr: 9.9270e-05 lr: 9.9270e-06  eta: 10:42:26  time: 0.4835  data_time: 0.0090  memory: 5897  grad_norm: 369.2722  loss: 35.9431  decode.loss_cls: 2.1237  decode.loss_mask: 0.4550  decode.loss_dice: 0.5771  decode.d0.loss_cls: 6.6830  decode.d0.loss_mask: 0.4975  decode.d0.loss_dice: 0.8298  decode.d1.loss_cls: 1.9364  decode.d1.loss_mask: 0.4997  decode.d1.loss_dice: 0.6639  decode.d2.loss_cls: 1.8976  decode.d2.loss_mask: 0.4609  decode.d2.loss_dice: 0.5937  decode.d3.loss_cls: 1.9106  decode.d3.loss_mask: 0.4582  decode.d3.loss_dice: 0.6207  decode.d4.loss_cls: 2.0245  decode.d4.loss_mask: 0.4860  decode.d4.loss_dice: 0.6736  decode.d5.loss_cls: 2.0472  decode.d5.loss_mask: 0.4732  decode.d5.loss_dice: 0.6055  decode.d6.loss_cls: 2.0705  decode.d6.loss_mask: 0.4855  decode.d6.loss_dice: 0.6400  decode.d7.loss_cls: 2.0788  decode.d7.loss_mask: 0.4729  decode.d7.loss_dice: 0.5610  decode.d8.loss_cls: 2.1045  decode.d8.loss_mask: 0.4546  decode.d8.loss_dice: 0.5572
07/31 17:38:20 - mmengine - INFO - Iter(train) [  700/80000]  base_lr: 9.9213e-05 lr: 9.9213e-06  eta: 10:42:00  time: 0.4840  data_time: 0.0090  memory: 5881  grad_norm: 325.4732  loss: 41.1365  decode.loss_cls: 2.3672  decode.loss_mask: 0.6137  decode.loss_dice: 0.7133  decode.d0.loss_cls: 6.5334  decode.d0.loss_mask: 0.6828  decode.d0.loss_dice: 1.0120  decode.d1.loss_cls: 2.2723  decode.d1.loss_mask: 0.5638  decode.d1.loss_dice: 0.7229  decode.d2.loss_cls: 2.3827  decode.d2.loss_mask: 0.5685  decode.d2.loss_dice: 0.7461  decode.d3.loss_cls: 2.4791  decode.d3.loss_mask: 0.5072  decode.d3.loss_dice: 0.6666  decode.d4.loss_cls: 2.5103  decode.d4.loss_mask: 0.5301  decode.d4.loss_dice: 0.6687  decode.d5.loss_cls: 2.4885  decode.d5.loss_mask: 0.5308  decode.d5.loss_dice: 0.6520  decode.d6.loss_cls: 2.3836  decode.d6.loss_mask: 0.5409  decode.d6.loss_dice: 0.6665  decode.d7.loss_cls: 2.4274  decode.d7.loss_mask: 0.5786  decode.d7.loss_dice: 0.7021  decode.d8.loss_cls: 2.3847  decode.d8.loss_mask: 0.5681  decode.d8.loss_dice: 0.6726
07/31 17:38:44 - mmengine - INFO - Iter(train) [  750/80000]  base_lr: 9.9157e-05 lr: 9.9157e-06  eta: 10:41:25  time: 0.4835  data_time: 0.0091  memory: 5932  grad_norm: 264.2737  loss: 38.7029  decode.loss_cls: 2.2217  decode.loss_mask: 0.4755  decode.loss_dice: 0.6106  decode.d0.loss_cls: 6.4990  decode.d0.loss_mask: 0.6624  decode.d0.loss_dice: 1.0279  decode.d1.loss_cls: 2.4405  decode.d1.loss_mask: 0.4775  decode.d1.loss_dice: 0.6537  decode.d2.loss_cls: 2.3610  decode.d2.loss_mask: 0.4542  decode.d2.loss_dice: 0.5891  decode.d3.loss_cls: 2.3176  decode.d3.loss_mask: 0.4692  decode.d3.loss_dice: 0.5801  decode.d4.loss_cls: 2.2808  decode.d4.loss_mask: 0.4647  decode.d4.loss_dice: 0.6107  decode.d5.loss_cls: 2.2920  decode.d5.loss_mask: 0.4703  decode.d5.loss_dice: 0.5986  decode.d6.loss_cls: 2.3124  decode.d6.loss_mask: 0.4597  decode.d6.loss_dice: 0.6014  decode.d7.loss_cls: 2.3065  decode.d7.loss_mask: 0.4878  decode.d7.loss_dice: 0.6051  decode.d8.loss_cls: 2.2385  decode.d8.loss_mask: 0.4876  decode.d8.loss_dice: 0.6466
07/31 17:39:08 - mmengine - INFO - Iter(train) [  800/80000]  base_lr: 9.9101e-05 lr: 9.9101e-06  eta: 10:40:52  time: 0.4833  data_time: 0.0090  memory: 5916  grad_norm: 260.6501  loss: 36.5981  decode.loss_cls: 2.1010  decode.loss_mask: 0.4527  decode.loss_dice: 0.6202  decode.d0.loss_cls: 6.3306  decode.d0.loss_mask: 0.4993  decode.d0.loss_dice: 0.9153  decode.d1.loss_cls: 2.2177  decode.d1.loss_mask: 0.4451  decode.d1.loss_dice: 0.6635  decode.d2.loss_cls: 2.1672  decode.d2.loss_mask: 0.4323  decode.d2.loss_dice: 0.6312  decode.d3.loss_cls: 2.1540  decode.d3.loss_mask: 0.4205  decode.d3.loss_dice: 0.6143  decode.d4.loss_cls: 2.1292  decode.d4.loss_mask: 0.4469  decode.d4.loss_dice: 0.6540  decode.d5.loss_cls: 2.1318  decode.d5.loss_mask: 0.4696  decode.d5.loss_dice: 0.6486  decode.d6.loss_cls: 2.0905  decode.d6.loss_mask: 0.4529  decode.d6.loss_dice: 0.6053  decode.d7.loss_cls: 2.1233  decode.d7.loss_mask: 0.4478  decode.d7.loss_dice: 0.5961  decode.d8.loss_cls: 2.1187  decode.d8.loss_mask: 0.4108  decode.d8.loss_dice: 0.6077
07/31 17:39:33 - mmengine - INFO - Iter(train) [  850/80000]  base_lr: 9.9044e-05 lr: 9.9044e-06  eta: 10:40:21  time: 0.4848  data_time: 0.0091  memory: 5933  grad_norm: 372.1219  loss: 36.8140  decode.loss_cls: 1.9999  decode.loss_mask: 0.5597  decode.loss_dice: 0.6891  decode.d0.loss_cls: 6.1669  decode.d0.loss_mask: 0.6636  decode.d0.loss_dice: 0.9966  decode.d1.loss_cls: 2.0508  decode.d1.loss_mask: 0.5569  decode.d1.loss_dice: 0.7400  decode.d2.loss_cls: 1.9572  decode.d2.loss_mask: 0.5613  decode.d2.loss_dice: 0.7190  decode.d3.loss_cls: 1.9870  decode.d3.loss_mask: 0.4972  decode.d3.loss_dice: 0.6944  decode.d4.loss_cls: 1.9937  decode.d4.loss_mask: 0.4853  decode.d4.loss_dice: 0.6665  decode.d5.loss_cls: 2.0059  decode.d5.loss_mask: 0.4668  decode.d5.loss_dice: 0.6425  decode.d6.loss_cls: 2.0343  decode.d6.loss_mask: 0.4841  decode.d6.loss_dice: 0.6544  decode.d7.loss_cls: 2.0899  decode.d7.loss_mask: 0.4816  decode.d7.loss_dice: 0.6887  decode.d8.loss_cls: 2.0018  decode.d8.loss_mask: 0.5706  decode.d8.loss_dice: 0.7080
07/31 17:39:57 - mmengine - INFO - Iter(train) [  900/80000]  base_lr: 9.8988e-05 lr: 9.8988e-06  eta: 10:39:46  time: 0.4835  data_time: 0.0091  memory: 5916  grad_norm: 468.6632  loss: 36.4481  decode.loss_cls: 1.9359  decode.loss_mask: 0.5656  decode.loss_dice: 0.6629  decode.d0.loss_cls: 6.0056  decode.d0.loss_mask: 0.6194  decode.d0.loss_dice: 0.9002  decode.d1.loss_cls: 2.1917  decode.d1.loss_mask: 0.4912  decode.d1.loss_dice: 0.6338  decode.d2.loss_cls: 2.0365  decode.d2.loss_mask: 0.5086  decode.d2.loss_dice: 0.6346  decode.d3.loss_cls: 2.0926  decode.d3.loss_mask: 0.5270  decode.d3.loss_dice: 0.6188  decode.d4.loss_cls: 2.0484  decode.d4.loss_mask: 0.5186  decode.d4.loss_dice: 0.6428  decode.d5.loss_cls: 1.9968  decode.d5.loss_mask: 0.5363  decode.d5.loss_dice: 0.6650  decode.d6.loss_cls: 1.9579  decode.d6.loss_mask: 0.5453  decode.d6.loss_dice: 0.6311  decode.d7.loss_cls: 2.1243  decode.d7.loss_mask: 0.4991  decode.d7.loss_dice: 0.6291  decode.d8.loss_cls: 2.0381  decode.d8.loss_mask: 0.5454  decode.d8.loss_dice: 0.6455
07/31 17:40:21 - mmengine - INFO - Iter(train) [  950/80000]  base_lr: 9.8932e-05 lr: 9.8932e-06  eta: 10:39:14  time: 0.4831  data_time: 0.0090  memory: 5896  grad_norm: 297.3131  loss: 31.8781  decode.loss_cls: 1.7603  decode.loss_mask: 0.4647  decode.loss_dice: 0.4885  decode.d0.loss_cls: 5.9116  decode.d0.loss_mask: 0.5365  decode.d0.loss_dice: 0.7767  decode.d1.loss_cls: 1.9359  decode.d1.loss_mask: 0.5314  decode.d1.loss_dice: 0.6031  decode.d2.loss_cls: 1.7687  decode.d2.loss_mask: 0.4502  decode.d2.loss_dice: 0.5341  decode.d3.loss_cls: 1.7125  decode.d3.loss_mask: 0.4500  decode.d3.loss_dice: 0.5066  decode.d4.loss_cls: 1.7201  decode.d4.loss_mask: 0.4633  decode.d4.loss_dice: 0.5066  decode.d5.loss_cls: 1.7129  decode.d5.loss_mask: 0.4696  decode.d5.loss_dice: 0.5303  decode.d6.loss_cls: 1.7578  decode.d6.loss_mask: 0.4855  decode.d6.loss_dice: 0.5208  decode.d7.loss_cls: 1.7212  decode.d7.loss_mask: 0.4371  decode.d7.loss_dice: 0.4973  decode.d8.loss_cls: 1.6963  decode.d8.loss_mask: 0.4351  decode.d8.loss_dice: 0.4934
07/31 17:40:45 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250731_173226
07/31 17:40:45 - mmengine - INFO - Iter(train) [ 1000/80000]  base_lr: 9.8875e-05 lr: 9.8875e-06  eta: 10:38:44  time: 0.4841  data_time: 0.0091  memory: 5919  grad_norm: 217.9801  loss: 30.3479  decode.loss_cls: 1.7080  decode.loss_mask: 0.4753  decode.loss_dice: 0.4525  decode.d0.loss_cls: 5.6386  decode.d0.loss_mask: 0.5242  decode.d0.loss_dice: 0.6556  decode.d1.loss_cls: 1.7753  decode.d1.loss_mask: 0.4538  decode.d1.loss_dice: 0.4839  decode.d2.loss_cls: 1.6655  decode.d2.loss_mask: 0.4126  decode.d2.loss_dice: 0.4523  decode.d3.loss_cls: 1.6990  decode.d3.loss_mask: 0.4370  decode.d3.loss_dice: 0.4653  decode.d4.loss_cls: 1.7643  decode.d4.loss_mask: 0.4187  decode.d4.loss_dice: 0.4534  decode.d5.loss_cls: 1.7267  decode.d5.loss_mask: 0.4327  decode.d5.loss_dice: 0.4355  decode.d6.loss_cls: 1.7416  decode.d6.loss_mask: 0.4119  decode.d6.loss_dice: 0.4334  decode.d7.loss_cls: 1.7424  decode.d7.loss_mask: 0.4607  decode.d7.loss_dice: 0.4464  decode.d8.loss_cls: 1.6684  decode.d8.loss_mask: 0.4591  decode.d8.loss_dice: 0.4539
07/31 17:41:09 - mmengine - INFO - Iter(train) [ 1050/80000]  base_lr: 9.8819e-05 lr: 9.8819e-06  eta: 10:38:13  time: 0.4838  data_time: 0.0090  memory: 5918  grad_norm: 399.7067  loss: 35.5368  decode.loss_cls: 2.1597  decode.loss_mask: 0.4268  decode.loss_dice: 0.5009  decode.d0.loss_cls: 5.6536  decode.d0.loss_mask: 0.5230  decode.d0.loss_dice: 0.7504  decode.d1.loss_cls: 2.1373  decode.d1.loss_mask: 0.4675  decode.d1.loss_dice: 0.5294  decode.d2.loss_cls: 2.0971  decode.d2.loss_mask: 0.4722  decode.d2.loss_dice: 0.5013  decode.d3.loss_cls: 2.0776  decode.d3.loss_mask: 0.5043  decode.d3.loss_dice: 0.5135  decode.d4.loss_cls: 2.2015  decode.d4.loss_mask: 0.4884  decode.d4.loss_dice: 0.5226  decode.d5.loss_cls: 2.2084  decode.d5.loss_mask: 0.5144  decode.d5.loss_dice: 0.5659  decode.d6.loss_cls: 2.2131  decode.d6.loss_mask: 0.4746  decode.d6.loss_dice: 0.5331  decode.d7.loss_cls: 2.2525  decode.d7.loss_mask: 0.4924  decode.d7.loss_dice: 0.5706  decode.d8.loss_cls: 2.1826  decode.d8.loss_mask: 0.4960  decode.d8.loss_dice: 0.5060
07/31 17:41:34 - mmengine - INFO - Iter(train) [ 1100/80000]  base_lr: 9.8763e-05 lr: 9.8763e-06  eta: 10:37:44  time: 0.4835  data_time: 0.0090  memory: 5932  grad_norm: 492.5117  loss: 36.2622  decode.loss_cls: 1.9781  decode.loss_mask: 0.5433  decode.loss_dice: 0.6715  decode.d0.loss_cls: 5.6467  decode.d0.loss_mask: 0.5850  decode.d0.loss_dice: 0.9506  decode.d1.loss_cls: 2.1561  decode.d1.loss_mask: 0.5521  decode.d1.loss_dice: 0.6592  decode.d2.loss_cls: 2.0324  decode.d2.loss_mask: 0.5413  decode.d2.loss_dice: 0.6693  decode.d3.loss_cls: 2.0739  decode.d3.loss_mask: 0.5328  decode.d3.loss_dice: 0.6139  decode.d4.loss_cls: 1.9780  decode.d4.loss_mask: 0.5199  decode.d4.loss_dice: 0.6296  decode.d5.loss_cls: 1.9332  decode.d5.loss_mask: 0.5442  decode.d5.loss_dice: 0.6528  decode.d6.loss_cls: 1.9162  decode.d6.loss_mask: 0.5788  decode.d6.loss_dice: 0.7266  decode.d7.loss_cls: 2.0215  decode.d7.loss_mask: 0.5614  decode.d7.loss_dice: 0.7140  decode.d8.loss_cls: 2.0203  decode.d8.loss_mask: 0.5647  decode.d8.loss_dice: 0.6947
07/31 17:41:58 - mmengine - INFO - Iter(train) [ 1150/80000]  base_lr: 9.8706e-05 lr: 9.8706e-06  eta: 10:37:14  time: 0.4836  data_time: 0.0091  memory: 5899  grad_norm: 506.3927  loss: 34.2641  decode.loss_cls: 1.7756  decode.loss_mask: 0.5139  decode.loss_dice: 0.6668  decode.d0.loss_cls: 5.4431  decode.d0.loss_mask: 0.6221  decode.d0.loss_dice: 0.8872  decode.d1.loss_cls: 1.9489  decode.d1.loss_mask: 0.4995  decode.d1.loss_dice: 0.6938  decode.d2.loss_cls: 1.8225  decode.d2.loss_mask: 0.5028  decode.d2.loss_dice: 0.6476  decode.d3.loss_cls: 1.8107  decode.d3.loss_mask: 0.4801  decode.d3.loss_dice: 0.7150  decode.d4.loss_cls: 1.8622  decode.d4.loss_mask: 0.5233  decode.d4.loss_dice: 0.7241  decode.d5.loss_cls: 1.8414  decode.d5.loss_mask: 0.5053  decode.d5.loss_dice: 0.6992  decode.d6.loss_cls: 1.8526  decode.d6.loss_mask: 0.5418  decode.d6.loss_dice: 0.7011  decode.d7.loss_cls: 1.8588  decode.d7.loss_mask: 0.5426  decode.d7.loss_dice: 0.6389  decode.d8.loss_cls: 1.7963  decode.d8.loss_mask: 0.5105  decode.d8.loss_dice: 0.6362
07/31 17:42:22 - mmengine - INFO - Iter(train) [ 1200/80000]  base_lr: 9.8650e-05 lr: 9.8650e-06  eta: 10:36:52  time: 0.4834  data_time: 0.0090  memory: 5973  grad_norm: 173.6164  loss: 30.3939  decode.loss_cls: 1.7870  decode.loss_mask: 0.4443  decode.loss_dice: 0.4307  decode.d0.loss_cls: 5.2815  decode.d0.loss_mask: 0.5075  decode.d0.loss_dice: 0.6248  decode.d1.loss_cls: 1.8628  decode.d1.loss_mask: 0.4571  decode.d1.loss_dice: 0.4564  decode.d2.loss_cls: 1.7577  decode.d2.loss_mask: 0.4454  decode.d2.loss_dice: 0.4294  decode.d3.loss_cls: 1.7597  decode.d3.loss_mask: 0.4413  decode.d3.loss_dice: 0.4039  decode.d4.loss_cls: 1.8143  decode.d4.loss_mask: 0.4439  decode.d4.loss_dice: 0.4221  decode.d5.loss_cls: 1.7933  decode.d5.loss_mask: 0.4321  decode.d5.loss_dice: 0.4188  decode.d6.loss_cls: 1.7988  decode.d6.loss_mask: 0.4251  decode.d6.loss_dice: 0.4015  decode.d7.loss_cls: 1.8309  decode.d7.loss_mask: 0.4436  decode.d7.loss_dice: 0.4370  decode.d8.loss_cls: 1.7377  decode.d8.loss_mask: 0.4467  decode.d8.loss_dice: 0.4586
07/31 17:42:46 - mmengine - INFO - Iter(train) [ 1250/80000]  base_lr: 9.8594e-05 lr: 9.8594e-06  eta: 10:36:22  time: 0.4834  data_time: 0.0090  memory: 5918  grad_norm: 195.8054  loss: 30.2232  decode.loss_cls: 1.8021  decode.loss_mask: 0.4448  decode.loss_dice: 0.4494  decode.d0.loss_cls: 5.1129  decode.d0.loss_mask: 0.5670  decode.d0.loss_dice: 0.6448  decode.d1.loss_cls: 1.8510  decode.d1.loss_mask: 0.4411  decode.d1.loss_dice: 0.4599  decode.d2.loss_cls: 1.7631  decode.d2.loss_mask: 0.4279  decode.d2.loss_dice: 0.4356  decode.d3.loss_cls: 1.7301  decode.d3.loss_mask: 0.4305  decode.d3.loss_dice: 0.4448  decode.d4.loss_cls: 1.7603  decode.d4.loss_mask: 0.4320  decode.d4.loss_dice: 0.4234  decode.d5.loss_cls: 1.7209  decode.d5.loss_mask: 0.4571  decode.d5.loss_dice: 0.4641  decode.d6.loss_cls: 1.7539  decode.d6.loss_mask: 0.4224  decode.d6.loss_dice: 0.4274  decode.d7.loss_cls: 1.8348  decode.d7.loss_mask: 0.4374  decode.d7.loss_dice: 0.4478  decode.d8.loss_cls: 1.7603  decode.d8.loss_mask: 0.4380  decode.d8.loss_dice: 0.4384
07/31 17:43:10 - mmengine - INFO - Iter(train) [ 1300/80000]  base_lr: 9.8537e-05 lr: 9.8537e-06  eta: 10:35:53  time: 0.4837  data_time: 0.0090  memory: 5931  grad_norm: 291.2046  loss: 35.2690  decode.loss_cls: 2.1090  decode.loss_mask: 0.5758  decode.loss_dice: 0.5708  decode.d0.loss_cls: 5.0799  decode.d0.loss_mask: 0.5954  decode.d0.loss_dice: 0.7974  decode.d1.loss_cls: 2.2772  decode.d1.loss_mask: 0.5614  decode.d1.loss_dice: 0.5575  decode.d2.loss_cls: 2.0902  decode.d2.loss_mask: 0.5366  decode.d2.loss_dice: 0.5316  decode.d3.loss_cls: 2.1261  decode.d3.loss_mask: 0.5234  decode.d3.loss_dice: 0.5123  decode.d4.loss_cls: 2.0626  decode.d4.loss_mask: 0.5067  decode.d4.loss_dice: 0.5606  decode.d5.loss_cls: 2.0776  decode.d5.loss_mask: 0.5044  decode.d5.loss_dice: 0.5526  decode.d6.loss_cls: 2.0882  decode.d6.loss_mask: 0.5144  decode.d6.loss_dice: 0.5445  decode.d7.loss_cls: 2.1562  decode.d7.loss_mask: 0.5270  decode.d7.loss_dice: 0.5500  decode.d8.loss_cls: 2.0975  decode.d8.loss_mask: 0.5493  decode.d8.loss_dice: 0.5328
07/31 17:43:34 - mmengine - INFO - Iter(train) [ 1350/80000]  base_lr: 9.8481e-05 lr: 9.8481e-06  eta: 10:35:24  time: 0.4831  data_time: 0.0091  memory: 5934  grad_norm: 347.9737  loss: 30.4539  decode.loss_cls: 1.6797  decode.loss_mask: 0.5259  decode.loss_dice: 0.5204  decode.d0.loss_cls: 4.8810  decode.d0.loss_mask: 0.5456  decode.d0.loss_dice: 0.6648  decode.d1.loss_cls: 1.7047  decode.d1.loss_mask: 0.5270  decode.d1.loss_dice: 0.4959  decode.d2.loss_cls: 1.6642  decode.d2.loss_mask: 0.5293  decode.d2.loss_dice: 0.5009  decode.d3.loss_cls: 1.6713  decode.d3.loss_mask: 0.5229  decode.d3.loss_dice: 0.4996  decode.d4.loss_cls: 1.7446  decode.d4.loss_mask: 0.4829  decode.d4.loss_dice: 0.4698  decode.d5.loss_cls: 1.7243  decode.d5.loss_mask: 0.4987  decode.d5.loss_dice: 0.5186  decode.d6.loss_cls: 1.7174  decode.d6.loss_mask: 0.4706  decode.d6.loss_dice: 0.4434  decode.d7.loss_cls: 1.7724  decode.d7.loss_mask: 0.4872  decode.d7.loss_dice: 0.4330  decode.d8.loss_cls: 1.7916  decode.d8.loss_mask: 0.4929  decode.d8.loss_dice: 0.4734
07/31 17:43:59 - mmengine - INFO - Iter(train) [ 1400/80000]  base_lr: 9.8425e-05 lr: 9.8425e-06  eta: 10:34:56  time: 0.4833  data_time: 0.0091  memory: 5933  grad_norm: 385.7527  loss: 32.2082  decode.loss_cls: 1.8715  decode.loss_mask: 0.4600  decode.loss_dice: 0.5893  decode.d0.loss_cls: 4.7992  decode.d0.loss_mask: 0.5921  decode.d0.loss_dice: 0.7379  decode.d1.loss_cls: 1.9179  decode.d1.loss_mask: 0.4824  decode.d1.loss_dice: 0.5724  decode.d2.loss_cls: 1.8330  decode.d2.loss_mask: 0.4407  decode.d2.loss_dice: 0.5275  decode.d3.loss_cls: 1.8491  decode.d3.loss_mask: 0.4637  decode.d3.loss_dice: 0.5156  decode.d4.loss_cls: 1.8879  decode.d4.loss_mask: 0.4671  decode.d4.loss_dice: 0.5489  decode.d5.loss_cls: 1.8465  decode.d5.loss_mask: 0.4341  decode.d5.loss_dice: 0.5430  decode.d6.loss_cls: 1.8367  decode.d6.loss_mask: 0.4774  decode.d6.loss_dice: 0.5656  decode.d7.loss_cls: 1.9411  decode.d7.loss_mask: 0.4954  decode.d7.loss_dice: 0.5841  decode.d8.loss_cls: 1.8606  decode.d8.loss_mask: 0.4743  decode.d8.loss_dice: 0.5934
07/31 17:44:23 - mmengine - INFO - Iter(train) [ 1450/80000]  base_lr: 9.8368e-05 lr: 9.8368e-06  eta: 10:34:31  time: 0.4843  data_time: 0.0091  memory: 5934  grad_norm: 269.9019  loss: 32.4274  decode.loss_cls: 2.0469  decode.loss_mask: 0.4419  decode.loss_dice: 0.4532  decode.d0.loss_cls: 4.6998  decode.d0.loss_mask: 0.6411  decode.d0.loss_dice: 0.7522  decode.d1.loss_cls: 2.0918  decode.d1.loss_mask: 0.4515  decode.d1.loss_dice: 0.4853  decode.d2.loss_cls: 1.9568  decode.d2.loss_mask: 0.4484  decode.d2.loss_dice: 0.4486  decode.d3.loss_cls: 1.9698  decode.d3.loss_mask: 0.4488  decode.d3.loss_dice: 0.4290  decode.d4.loss_cls: 2.0162  decode.d4.loss_mask: 0.4389  decode.d4.loss_dice: 0.4431  decode.d5.loss_cls: 2.0877  decode.d5.loss_mask: 0.4406  decode.d5.loss_dice: 0.4269  decode.d6.loss_cls: 2.1237  decode.d6.loss_mask: 0.4415  decode.d6.loss_dice: 0.4395  decode.d7.loss_cls: 2.0309  decode.d7.loss_mask: 0.4253  decode.d7.loss_dice: 0.4275  decode.d8.loss_cls: 2.0164  decode.d8.loss_mask: 0.4513  decode.d8.loss_dice: 0.4527
07/31 17:44:47 - mmengine - INFO - Iter(train) [ 1500/80000]  base_lr: 9.8312e-05 lr: 9.8312e-06  eta: 10:34:13  time: 0.4840  data_time: 0.0091  memory: 5898  grad_norm: 190.6756  loss: 28.2374  decode.loss_cls: 1.6831  decode.loss_mask: 0.4234  decode.loss_dice: 0.4973  decode.d0.loss_cls: 4.3275  decode.d0.loss_mask: 0.4756  decode.d0.loss_dice: 0.6300  decode.d1.loss_cls: 1.8011  decode.d1.loss_mask: 0.4083  decode.d1.loss_dice: 0.4530  decode.d2.loss_cls: 1.6067  decode.d2.loss_mask: 0.3815  decode.d2.loss_dice: 0.4190  decode.d3.loss_cls: 1.6508  decode.d3.loss_mask: 0.4084  decode.d3.loss_dice: 0.4432  decode.d4.loss_cls: 1.7107  decode.d4.loss_mask: 0.3914  decode.d4.loss_dice: 0.4247  decode.d5.loss_cls: 1.6580  decode.d5.loss_mask: 0.3928  decode.d5.loss_dice: 0.4372  decode.d6.loss_cls: 1.6734  decode.d6.loss_mask: 0.3928  decode.d6.loss_dice: 0.4171  decode.d7.loss_cls: 1.6938  decode.d7.loss_mask: 0.4049  decode.d7.loss_dice: 0.4110  decode.d8.loss_cls: 1.7230  decode.d8.loss_mask: 0.4259  decode.d8.loss_dice: 0.4723
07/31 17:45:11 - mmengine - INFO - Iter(train) [ 1550/80000]  base_lr: 9.8256e-05 lr: 9.8256e-06  eta: 10:33:46  time: 0.4835  data_time: 0.0091  memory: 5916  grad_norm: 245.4576  loss: 30.4391  decode.loss_cls: 1.7858  decode.loss_mask: 0.4126  decode.loss_dice: 0.5451  decode.d0.loss_cls: 4.3742  decode.d0.loss_mask: 0.5498  decode.d0.loss_dice: 0.8289  decode.d1.loss_cls: 1.8799  decode.d1.loss_mask: 0.4180  decode.d1.loss_dice: 0.5451  decode.d2.loss_cls: 1.7551  decode.d2.loss_mask: 0.4145  decode.d2.loss_dice: 0.5254  decode.d3.loss_cls: 1.8664  decode.d3.loss_mask: 0.4337  decode.d3.loss_dice: 0.5298  decode.d4.loss_cls: 1.8115  decode.d4.loss_mask: 0.4048  decode.d4.loss_dice: 0.5394  decode.d5.loss_cls: 1.8003  decode.d5.loss_mask: 0.3864  decode.d5.loss_dice: 0.5147  decode.d6.loss_cls: 1.7358  decode.d6.loss_mask: 0.4314  decode.d6.loss_dice: 0.5536  decode.d7.loss_cls: 1.7016  decode.d7.loss_mask: 0.4154  decode.d7.loss_dice: 0.5392  decode.d8.loss_cls: 1.7854  decode.d8.loss_mask: 0.4047  decode.d8.loss_dice: 0.5504
07/31 17:45:36 - mmengine - INFO - Iter(train) [ 1600/80000]  base_lr: 9.8199e-05 lr: 9.8199e-06  eta: 10:33:19  time: 0.4838  data_time: 0.0091  memory: 5879  grad_norm: 278.5769  loss: 26.6883  decode.loss_cls: 1.4825  decode.loss_mask: 0.3860  decode.loss_dice: 0.5245  decode.d0.loss_cls: 4.1856  decode.d0.loss_mask: 0.3391  decode.d0.loss_dice: 0.6093  decode.d1.loss_cls: 1.8229  decode.d1.loss_mask: 0.2970  decode.d1.loss_dice: 0.4471  decode.d2.loss_cls: 1.6113  decode.d2.loss_mask: 0.3035  decode.d2.loss_dice: 0.4464  decode.d3.loss_cls: 1.5530  decode.d3.loss_mask: 0.2944  decode.d3.loss_dice: 0.4456  decode.d4.loss_cls: 1.5990  decode.d4.loss_mask: 0.2858  decode.d4.loss_dice: 0.4551  decode.d5.loss_cls: 1.6056  decode.d5.loss_mask: 0.3002  decode.d5.loss_dice: 0.4499  decode.d6.loss_cls: 1.5631  decode.d6.loss_mask: 0.3193  decode.d6.loss_dice: 0.4915  decode.d7.loss_cls: 1.5560  decode.d7.loss_mask: 0.3859  decode.d7.loss_dice: 0.4835  decode.d8.loss_cls: 1.5443  decode.d8.loss_mask: 0.3853  decode.d8.loss_dice: 0.5159
07/31 17:46:00 - mmengine - INFO - Iter(train) [ 1650/80000]  base_lr: 9.8143e-05 lr: 9.8143e-06  eta: 10:32:51  time: 0.4831  data_time: 0.0090  memory: 5931  grad_norm: 256.8770  loss: 30.5376  decode.loss_cls: 1.9111  decode.loss_mask: 0.3345  decode.loss_dice: 0.4938  decode.d0.loss_cls: 4.2385  decode.d0.loss_mask: 0.4708  decode.d0.loss_dice: 0.7099  decode.d1.loss_cls: 2.0096  decode.d1.loss_mask: 0.3552  decode.d1.loss_dice: 0.5582  decode.d2.loss_cls: 1.8793  decode.d2.loss_mask: 0.3294  decode.d2.loss_dice: 0.4939  decode.d3.loss_cls: 1.9166  decode.d3.loss_mask: 0.3253  decode.d3.loss_dice: 0.4919  decode.d4.loss_cls: 1.8464  decode.d4.loss_mask: 0.3650  decode.d4.loss_dice: 0.4911  decode.d5.loss_cls: 1.9472  decode.d5.loss_mask: 0.3589  decode.d5.loss_dice: 0.5287  decode.d6.loss_cls: 1.9243  decode.d6.loss_mask: 0.3415  decode.d6.loss_dice: 0.5250  decode.d7.loss_cls: 1.9852  decode.d7.loss_mask: 0.3576  decode.d7.loss_dice: 0.5214  decode.d8.loss_cls: 1.9720  decode.d8.loss_mask: 0.3376  decode.d8.loss_dice: 0.5181
07/31 17:46:24 - mmengine - INFO - Iter(train) [ 1700/80000]  base_lr: 9.8087e-05 lr: 9.8087e-06  eta: 10:32:24  time: 0.4827  data_time: 0.0090  memory: 5897  grad_norm: 341.7373  loss: 25.2935  decode.loss_cls: 1.2749  decode.loss_mask: 0.4661  decode.loss_dice: 0.4217  decode.d0.loss_cls: 3.9217  decode.d0.loss_mask: 0.4870  decode.d0.loss_dice: 0.5895  decode.d1.loss_cls: 1.6074  decode.d1.loss_mask: 0.4851  decode.d1.loss_dice: 0.4149  decode.d2.loss_cls: 1.3134  decode.d2.loss_mask: 0.4355  decode.d2.loss_dice: 0.4070  decode.d3.loss_cls: 1.3320  decode.d3.loss_mask: 0.4543  decode.d3.loss_dice: 0.3882  decode.d4.loss_cls: 1.3274  decode.d4.loss_mask: 0.4686  decode.d4.loss_dice: 0.4389  decode.d5.loss_cls: 1.3727  decode.d5.loss_mask: 0.4563  decode.d5.loss_dice: 0.4108  decode.d6.loss_cls: 1.3941  decode.d6.loss_mask: 0.4554  decode.d6.loss_dice: 0.3936  decode.d7.loss_cls: 1.4014  decode.d7.loss_mask: 0.4709  decode.d7.loss_dice: 0.4307  decode.d8.loss_cls: 1.3867  decode.d8.loss_mask: 0.4661  decode.d8.loss_dice: 0.4213
07/31 17:46:48 - mmengine - INFO - Iter(train) [ 1750/80000]  base_lr: 9.8030e-05 lr: 9.8030e-06  eta: 10:31:57  time: 0.4837  data_time: 0.0090  memory: 5916  grad_norm: 186.3273  loss: 25.6760  decode.loss_cls: 1.4465  decode.loss_mask: 0.3201  decode.loss_dice: 0.4436  decode.d0.loss_cls: 3.8480  decode.d0.loss_mask: 0.3448  decode.d0.loss_dice: 0.6184  decode.d1.loss_cls: 1.7420  decode.d1.loss_mask: 0.3121  decode.d1.loss_dice: 0.4663  decode.d2.loss_cls: 1.5945  decode.d2.loss_mask: 0.3186  decode.d2.loss_dice: 0.4660  decode.d3.loss_cls: 1.4935  decode.d3.loss_mask: 0.3159  decode.d3.loss_dice: 0.4613  decode.d4.loss_cls: 1.4884  decode.d4.loss_mask: 0.3461  decode.d4.loss_dice: 0.4800  decode.d5.loss_cls: 1.5214  decode.d5.loss_mask: 0.3171  decode.d5.loss_dice: 0.4765  decode.d6.loss_cls: 1.4263  decode.d6.loss_mask: 0.3205  decode.d6.loss_dice: 0.4767  decode.d7.loss_cls: 1.5695  decode.d7.loss_mask: 0.3183  decode.d7.loss_dice: 0.4592  decode.d8.loss_cls: 1.4949  decode.d8.loss_mask: 0.3277  decode.d8.loss_dice: 0.4616
07/31 17:47:12 - mmengine - INFO - Iter(train) [ 1800/80000]  base_lr: 9.7974e-05 lr: 9.7974e-06  eta: 10:31:30  time: 0.4835  data_time: 0.0091  memory: 5895  grad_norm: 254.3883  loss: 24.2012  decode.loss_cls: 1.3072  decode.loss_mask: 0.3822  decode.loss_dice: 0.4066  decode.d0.loss_cls: 3.6340  decode.d0.loss_mask: 0.5190  decode.d0.loss_dice: 0.6239  decode.d1.loss_cls: 1.4626  decode.d1.loss_mask: 0.4178  decode.d1.loss_dice: 0.4394  decode.d2.loss_cls: 1.4450  decode.d2.loss_mask: 0.3764  decode.d2.loss_dice: 0.4617  decode.d3.loss_cls: 1.3899  decode.d3.loss_mask: 0.3752  decode.d3.loss_dice: 0.4430  decode.d4.loss_cls: 1.3560  decode.d4.loss_mask: 0.3827  decode.d4.loss_dice: 0.4163  decode.d5.loss_cls: 1.3451  decode.d5.loss_mask: 0.4140  decode.d5.loss_dice: 0.4094  decode.d6.loss_cls: 1.2888  decode.d6.loss_mask: 0.3637  decode.d6.loss_dice: 0.4010  decode.d7.loss_cls: 1.3056  decode.d7.loss_mask: 0.3846  decode.d7.loss_dice: 0.4013  decode.d8.loss_cls: 1.2508  decode.d8.loss_mask: 0.3991  decode.d8.loss_dice: 0.3987
07/31 17:47:36 - mmengine - INFO - Iter(train) [ 1850/80000]  base_lr: 9.7917e-05 lr: 9.7917e-06  eta: 10:31:04  time: 0.4831  data_time: 0.0089  memory: 5898  grad_norm: 176.6964  loss: 22.9268  decode.loss_cls: 1.1859  decode.loss_mask: 0.3610  decode.loss_dice: 0.4383  decode.d0.loss_cls: 3.5044  decode.d0.loss_mask: 0.4307  decode.d0.loss_dice: 0.5842  decode.d1.loss_cls: 1.4319  decode.d1.loss_mask: 0.4084  decode.d1.loss_dice: 0.4361  decode.d2.loss_cls: 1.2225  decode.d2.loss_mask: 0.3953  decode.d2.loss_dice: 0.4811  decode.d3.loss_cls: 1.1712  decode.d3.loss_mask: 0.3886  decode.d3.loss_dice: 0.4363  decode.d4.loss_cls: 1.2171  decode.d4.loss_mask: 0.3848  decode.d4.loss_dice: 0.4155  decode.d5.loss_cls: 1.2028  decode.d5.loss_mask: 0.3895  decode.d5.loss_dice: 0.4229  decode.d6.loss_cls: 1.1642  decode.d6.loss_mask: 0.3701  decode.d6.loss_dice: 0.4552  decode.d7.loss_cls: 1.1783  decode.d7.loss_mask: 0.3992  decode.d7.loss_dice: 0.4491  decode.d8.loss_cls: 1.1925  decode.d8.loss_mask: 0.3735  decode.d8.loss_dice: 0.4359
07/31 17:48:01 - mmengine - INFO - Iter(train) [ 1900/80000]  base_lr: 9.7861e-05 lr: 9.7861e-06  eta: 10:30:37  time: 0.4834  data_time: 0.0091  memory: 5896  grad_norm: 158.1643  loss: 23.8212  decode.loss_cls: 1.2811  decode.loss_mask: 0.4120  decode.loss_dice: 0.3763  decode.d0.loss_cls: 3.4825  decode.d0.loss_mask: 0.4692  decode.d0.loss_dice: 0.5636  decode.d1.loss_cls: 1.5941  decode.d1.loss_mask: 0.4319  decode.d1.loss_dice: 0.3888  decode.d2.loss_cls: 1.3569  decode.d2.loss_mask: 0.4190  decode.d2.loss_dice: 0.3850  decode.d3.loss_cls: 1.3160  decode.d3.loss_mask: 0.4196  decode.d3.loss_dice: 0.3915  decode.d4.loss_cls: 1.2976  decode.d4.loss_mask: 0.4157  decode.d4.loss_dice: 0.3908  decode.d5.loss_cls: 1.3062  decode.d5.loss_mask: 0.4060  decode.d5.loss_dice: 0.3854  decode.d6.loss_cls: 1.2929  decode.d6.loss_mask: 0.4224  decode.d6.loss_dice: 0.4021  decode.d7.loss_cls: 1.3653  decode.d7.loss_mask: 0.4059  decode.d7.loss_dice: 0.4031  decode.d8.loss_cls: 1.2566  decode.d8.loss_mask: 0.4138  decode.d8.loss_dice: 0.3698
07/31 17:48:25 - mmengine - INFO - Iter(train) [ 1950/80000]  base_lr: 9.7805e-05 lr: 9.7805e-06  eta: 10:30:12  time: 0.4848  data_time: 0.0092  memory: 5896  grad_norm: 179.9824  loss: 24.3712  decode.loss_cls: 1.4031  decode.loss_mask: 0.3416  decode.loss_dice: 0.4105  decode.d0.loss_cls: 3.4449  decode.d0.loss_mask: 0.5233  decode.d0.loss_dice: 0.6162  decode.d1.loss_cls: 1.5485  decode.d1.loss_mask: 0.3657  decode.d1.loss_dice: 0.4423  decode.d2.loss_cls: 1.4135  decode.d2.loss_mask: 0.3325  decode.d2.loss_dice: 0.3738  decode.d3.loss_cls: 1.4464  decode.d3.loss_mask: 0.3323  decode.d3.loss_dice: 0.4079  decode.d4.loss_cls: 1.4384  decode.d4.loss_mask: 0.3679  decode.d4.loss_dice: 0.4093  decode.d5.loss_cls: 1.4154  decode.d5.loss_mask: 0.3530  decode.d5.loss_dice: 0.4163  decode.d6.loss_cls: 1.4488  decode.d6.loss_mask: 0.3376  decode.d6.loss_dice: 0.3910  decode.d7.loss_cls: 1.4936  decode.d7.loss_mask: 0.3378  decode.d7.loss_dice: 0.3856  decode.d8.loss_cls: 1.4422  decode.d8.loss_mask: 0.3323  decode.d8.loss_dice: 0.3996
07/31 17:48:49 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250731_173226
07/31 17:48:49 - mmengine - INFO - Iter(train) [ 2000/80000]  base_lr: 9.7748e-05 lr: 9.7748e-06  eta: 10:29:47  time: 0.4830  data_time: 0.0090  memory: 5920  grad_norm: 242.1237  loss: 22.4708  decode.loss_cls: 1.1176  decode.loss_mask: 0.4257  decode.loss_dice: 0.4447  decode.d0.loss_cls: 3.1799  decode.d0.loss_mask: 0.4985  decode.d0.loss_dice: 0.5739  decode.d1.loss_cls: 1.4787  decode.d1.loss_mask: 0.4195  decode.d1.loss_dice: 0.3895  decode.d2.loss_cls: 1.2570  decode.d2.loss_mask: 0.4157  decode.d2.loss_dice: 0.4167  decode.d3.loss_cls: 1.1773  decode.d3.loss_mask: 0.4155  decode.d3.loss_dice: 0.3948  decode.d4.loss_cls: 1.1784  decode.d4.loss_mask: 0.4139  decode.d4.loss_dice: 0.4271  decode.d5.loss_cls: 1.0925  decode.d5.loss_mask: 0.4109  decode.d5.loss_dice: 0.4217  decode.d6.loss_cls: 1.1560  decode.d6.loss_mask: 0.4109  decode.d6.loss_dice: 0.4110  decode.d7.loss_cls: 1.1180  decode.d7.loss_mask: 0.3965  decode.d7.loss_dice: 0.4293  decode.d8.loss_cls: 1.1377  decode.d8.loss_mask: 0.4100  decode.d8.loss_dice: 0.4520
07/31 17:49:13 - mmengine - INFO - Iter(train) [ 2050/80000]  base_lr: 9.7692e-05 lr: 9.7692e-06  eta: 10:29:23  time: 0.4840  data_time: 0.0091  memory: 5897  grad_norm: 228.6532  loss: 24.9954  decode.loss_cls: 1.3363  decode.loss_mask: 0.3562  decode.loss_dice: 0.4505  decode.d0.loss_cls: 3.1313  decode.d0.loss_mask: 0.4418  decode.d0.loss_dice: 0.6862  decode.d1.loss_cls: 1.5968  decode.d1.loss_mask: 0.3607  decode.d1.loss_dice: 0.4809  decode.d2.loss_cls: 1.4533  decode.d2.loss_mask: 0.3497  decode.d2.loss_dice: 0.4406  decode.d3.loss_cls: 1.5071  decode.d3.loss_mask: 0.3465  decode.d3.loss_dice: 0.4443  decode.d4.loss_cls: 1.5147  decode.d4.loss_mask: 0.3807  decode.d4.loss_dice: 0.4823  decode.d5.loss_cls: 1.4791  decode.d5.loss_mask: 0.3705  decode.d5.loss_dice: 0.4670  decode.d6.loss_cls: 1.4957  decode.d6.loss_mask: 0.4000  decode.d6.loss_dice: 0.5036  decode.d7.loss_cls: 1.5239  decode.d7.loss_mask: 0.3573  decode.d7.loss_dice: 0.4710  decode.d8.loss_cls: 1.3687  decode.d8.loss_mask: 0.3523  decode.d8.loss_dice: 0.4463
07/31 17:49:37 - mmengine - INFO - Iter(train) [ 2100/80000]  base_lr: 9.7635e-05 lr: 9.7635e-06  eta: 10:29:00  time: 0.4835  data_time: 0.0091  memory: 5920  grad_norm: 220.4660  loss: 21.6862  decode.loss_cls: 1.1501  decode.loss_mask: 0.3676  decode.loss_dice: 0.3782  decode.d0.loss_cls: 3.1037  decode.d0.loss_mask: 0.3820  decode.d0.loss_dice: 0.5548  decode.d1.loss_cls: 1.3484  decode.d1.loss_mask: 0.3900  decode.d1.loss_dice: 0.3996  decode.d2.loss_cls: 1.1476  decode.d2.loss_mask: 0.3792  decode.d2.loss_dice: 0.4145  decode.d3.loss_cls: 1.1370  decode.d3.loss_mask: 0.3885  decode.d3.loss_dice: 0.4002  decode.d4.loss_cls: 1.1663  decode.d4.loss_mask: 0.3879  decode.d4.loss_dice: 0.4164  decode.d5.loss_cls: 1.1781  decode.d5.loss_mask: 0.3832  decode.d5.loss_dice: 0.3850  decode.d6.loss_cls: 1.1656  decode.d6.loss_mask: 0.3955  decode.d6.loss_dice: 0.3773  decode.d7.loss_cls: 1.1465  decode.d7.loss_mask: 0.3948  decode.d7.loss_dice: 0.3758  decode.d8.loss_cls: 1.2073  decode.d8.loss_mask: 0.3754  decode.d8.loss_dice: 0.3897
07/31 17:50:02 - mmengine - INFO - Iter(train) [ 2150/80000]  base_lr: 9.7579e-05 lr: 9.7579e-06  eta: 10:28:34  time: 0.4837  data_time: 0.0090  memory: 5916  grad_norm: 308.0614  loss: 23.6197  decode.loss_cls: 1.2756  decode.loss_mask: 0.4131  decode.loss_dice: 0.5007  decode.d0.loss_cls: 3.0300  decode.d0.loss_mask: 0.4037  decode.d0.loss_dice: 0.6704  decode.d1.loss_cls: 1.5522  decode.d1.loss_mask: 0.3595  decode.d1.loss_dice: 0.4408  decode.d2.loss_cls: 1.3233  decode.d2.loss_mask: 0.3349  decode.d2.loss_dice: 0.4573  decode.d3.loss_cls: 1.3335  decode.d3.loss_mask: 0.3263  decode.d3.loss_dice: 0.4614  decode.d4.loss_cls: 1.3489  decode.d4.loss_mask: 0.3992  decode.d4.loss_dice: 0.5116  decode.d5.loss_cls: 1.2571  decode.d5.loss_mask: 0.3808  decode.d5.loss_dice: 0.4736  decode.d6.loss_cls: 1.2710  decode.d6.loss_mask: 0.3576  decode.d6.loss_dice: 0.4734  decode.d7.loss_cls: 1.3010  decode.d7.loss_mask: 0.3940  decode.d7.loss_dice: 0.4696  decode.d8.loss_cls: 1.2256  decode.d8.loss_mask: 0.3895  decode.d8.loss_dice: 0.4841
07/31 17:50:26 - mmengine - INFO - Iter(train) [ 2200/80000]  base_lr: 9.7523e-05 lr: 9.7523e-06  eta: 10:28:08  time: 0.4841  data_time: 0.0090  memory: 5897  grad_norm: 250.0754  loss: 22.2972  decode.loss_cls: 1.1826  decode.loss_mask: 0.3134  decode.loss_dice: 0.4828  decode.d0.loss_cls: 2.8452  decode.d0.loss_mask: 0.3582  decode.d0.loss_dice: 0.5940  decode.d1.loss_cls: 1.4569  decode.d1.loss_mask: 0.3212  decode.d1.loss_dice: 0.4739  decode.d2.loss_cls: 1.2870  decode.d2.loss_mask: 0.3188  decode.d2.loss_dice: 0.4290  decode.d3.loss_cls: 1.2879  decode.d3.loss_mask: 0.3263  decode.d3.loss_dice: 0.4264  decode.d4.loss_cls: 1.3609  decode.d4.loss_mask: 0.3122  decode.d4.loss_dice: 0.4248  decode.d5.loss_cls: 1.2364  decode.d5.loss_mask: 0.3275  decode.d5.loss_dice: 0.4410  decode.d6.loss_cls: 1.2259  decode.d6.loss_mask: 0.3332  decode.d6.loss_dice: 0.4559  decode.d7.loss_cls: 1.3008  decode.d7.loss_mask: 0.3300  decode.d7.loss_dice: 0.4451  decode.d8.loss_cls: 1.2063  decode.d8.loss_mask: 0.3226  decode.d8.loss_dice: 0.4709
07/31 17:50:50 - mmengine - INFO - Iter(train) [ 2250/80000]  base_lr: 9.7466e-05 lr: 9.7466e-06  eta: 10:27:43  time: 0.4838  data_time: 0.0089  memory: 5896  grad_norm: 255.9415  loss: 23.0505  decode.loss_cls: 1.3031  decode.loss_mask: 0.3140  decode.loss_dice: 0.3984  decode.d0.loss_cls: 2.9821  decode.d0.loss_mask: 0.4142  decode.d0.loss_dice: 0.6534  decode.d1.loss_cls: 1.6587  decode.d1.loss_mask: 0.3221  decode.d1.loss_dice: 0.4470  decode.d2.loss_cls: 1.4105  decode.d2.loss_mask: 0.3173  decode.d2.loss_dice: 0.4010  decode.d3.loss_cls: 1.3992  decode.d3.loss_mask: 0.3013  decode.d3.loss_dice: 0.3627  decode.d4.loss_cls: 1.3496  decode.d4.loss_mask: 0.3139  decode.d4.loss_dice: 0.3936  decode.d5.loss_cls: 1.3865  decode.d5.loss_mask: 0.3151  decode.d5.loss_dice: 0.4159  decode.d6.loss_cls: 1.3704  decode.d6.loss_mask: 0.3427  decode.d6.loss_dice: 0.4075  decode.d7.loss_cls: 1.3677  decode.d7.loss_mask: 0.3084  decode.d7.loss_dice: 0.3977  decode.d8.loss_cls: 1.3129  decode.d8.loss_mask: 0.3068  decode.d8.loss_dice: 0.3767
07/31 17:51:14 - mmengine - INFO - Iter(train) [ 2300/80000]  base_lr: 9.7410e-05 lr: 9.7410e-06  eta: 10:27:17  time: 0.4835  data_time: 0.0091  memory: 5896  grad_norm: 185.2902  loss: 22.7305  decode.loss_cls: 1.2888  decode.loss_mask: 0.3088  decode.loss_dice: 0.4473  decode.d0.loss_cls: 2.9151  decode.d0.loss_mask: 0.3652  decode.d0.loss_dice: 0.5607  decode.d1.loss_cls: 1.5546  decode.d1.loss_mask: 0.3279  decode.d1.loss_dice: 0.4701  decode.d2.loss_cls: 1.3858  decode.d2.loss_mask: 0.3021  decode.d2.loss_dice: 0.4420  decode.d3.loss_cls: 1.2951  decode.d3.loss_mask: 0.2971  decode.d3.loss_dice: 0.4303  decode.d4.loss_cls: 1.2613  decode.d4.loss_mask: 0.3036  decode.d4.loss_dice: 0.4610  decode.d5.loss_cls: 1.2807  decode.d5.loss_mask: 0.2986  decode.d5.loss_dice: 0.4483  decode.d6.loss_cls: 1.2963  decode.d6.loss_mask: 0.3057  decode.d6.loss_dice: 0.4540  decode.d7.loss_cls: 1.3856  decode.d7.loss_mask: 0.3110  decode.d7.loss_dice: 0.4650  decode.d8.loss_cls: 1.3052  decode.d8.loss_mask: 0.3068  decode.d8.loss_dice: 0.4567
07/31 17:51:38 - mmengine - INFO - Iter(train) [ 2350/80000]  base_lr: 9.7353e-05 lr: 9.7353e-06  eta: 10:26:51  time: 0.4839  data_time: 0.0091  memory: 5899  grad_norm: 162.2422  loss: 19.3412  decode.loss_cls: 0.9897  decode.loss_mask: 0.3307  decode.loss_dice: 0.3816  decode.d0.loss_cls: 2.6111  decode.d0.loss_mask: 0.3506  decode.d0.loss_dice: 0.5037  decode.d1.loss_cls: 1.2392  decode.d1.loss_mask: 0.3296  decode.d1.loss_dice: 0.3831  decode.d2.loss_cls: 1.0786  decode.d2.loss_mask: 0.3180  decode.d2.loss_dice: 0.3502  decode.d3.loss_cls: 1.0634  decode.d3.loss_mask: 0.3122  decode.d3.loss_dice: 0.3433  decode.d4.loss_cls: 1.1003  decode.d4.loss_mask: 0.3102  decode.d4.loss_dice: 0.3385  decode.d5.loss_cls: 1.1110  decode.d5.loss_mask: 0.3161  decode.d5.loss_dice: 0.3463  decode.d6.loss_cls: 1.0538  decode.d6.loss_mask: 0.3150  decode.d6.loss_dice: 0.3428  decode.d7.loss_cls: 1.1042  decode.d7.loss_mask: 0.3259  decode.d7.loss_dice: 0.3710  decode.d8.loss_cls: 1.0224  decode.d8.loss_mask: 0.3254  decode.d8.loss_dice: 0.3732
07/31 17:52:03 - mmengine - INFO - Iter(train) [ 2400/80000]  base_lr: 9.7297e-05 lr: 9.7297e-06  eta: 10:26:26  time: 0.4828  data_time: 0.0091  memory: 5934  grad_norm: 190.4994  loss: 18.3934  decode.loss_cls: 0.7014  decode.loss_mask: 0.4982  decode.loss_dice: 0.4282  decode.d0.loss_cls: 2.3429  decode.d0.loss_mask: 0.5613  decode.d0.loss_dice: 0.5086  decode.d1.loss_cls: 0.9257  decode.d1.loss_mask: 0.5021  decode.d1.loss_dice: 0.4632  decode.d2.loss_cls: 0.7662  decode.d2.loss_mask: 0.4889  decode.d2.loss_dice: 0.4201  decode.d3.loss_cls: 0.7213  decode.d3.loss_mask: 0.4857  decode.d3.loss_dice: 0.4019  decode.d4.loss_cls: 0.7176  decode.d4.loss_mask: 0.4894  decode.d4.loss_dice: 0.4270  decode.d5.loss_cls: 0.6645  decode.d5.loss_mask: 0.5080  decode.d5.loss_dice: 0.4349  decode.d6.loss_cls: 0.6999  decode.d6.loss_mask: 0.5035  decode.d6.loss_dice: 0.4390  decode.d7.loss_cls: 0.7349  decode.d7.loss_mask: 0.4981  decode.d7.loss_dice: 0.4046  decode.d8.loss_cls: 0.7271  decode.d8.loss_mask: 0.4962  decode.d8.loss_dice: 0.4331
07/31 17:52:27 - mmengine - INFO - Iter(train) [ 2450/80000]  base_lr: 9.7241e-05 lr: 9.7241e-06  eta: 10:26:01  time: 0.4832  data_time: 0.0090  memory: 5896  grad_norm: 392.1188  loss: 22.4025  decode.loss_cls: 1.0888  decode.loss_mask: 0.4818  decode.loss_dice: 0.4940  decode.d0.loss_cls: 2.5841  decode.d0.loss_mask: 0.4280  decode.d0.loss_dice: 0.5093  decode.d1.loss_cls: 1.3551  decode.d1.loss_mask: 0.4110  decode.d1.loss_dice: 0.4522  decode.d2.loss_cls: 1.2575  decode.d2.loss_mask: 0.4031  decode.d2.loss_dice: 0.4205  decode.d3.loss_cls: 1.2838  decode.d3.loss_mask: 0.3960  decode.d3.loss_dice: 0.4367  decode.d4.loss_cls: 1.2673  decode.d4.loss_mask: 0.3940  decode.d4.loss_dice: 0.4264  decode.d5.loss_cls: 1.1939  decode.d5.loss_mask: 0.5342  decode.d5.loss_dice: 0.4968  decode.d6.loss_cls: 1.1343  decode.d6.loss_mask: 0.4323  decode.d6.loss_dice: 0.4773  decode.d7.loss_cls: 1.1661  decode.d7.loss_mask: 0.4102  decode.d7.loss_dice: 0.4635  decode.d8.loss_cls: 1.0829  decode.d8.loss_mask: 0.4770  decode.d8.loss_dice: 0.4445
07/31 17:52:51 - mmengine - INFO - Iter(train) [ 2500/80000]  base_lr: 9.7184e-05 lr: 9.7184e-06  eta: 10:25:36  time: 0.4838  data_time: 0.0090  memory: 5916  grad_norm: 351.2246  loss: 24.7314  decode.loss_cls: 1.3557  decode.loss_mask: 0.4153  decode.loss_dice: 0.5119  decode.d0.loss_cls: 2.6325  decode.d0.loss_mask: 0.4731  decode.d0.loss_dice: 0.6903  decode.d1.loss_cls: 1.7169  decode.d1.loss_mask: 0.4374  decode.d1.loss_dice: 0.5250  decode.d2.loss_cls: 1.3474  decode.d2.loss_mask: 0.4386  decode.d2.loss_dice: 0.5278  decode.d3.loss_cls: 1.3034  decode.d3.loss_mask: 0.4546  decode.d3.loss_dice: 0.5137  decode.d4.loss_cls: 1.2797  decode.d4.loss_mask: 0.4215  decode.d4.loss_dice: 0.5332  decode.d5.loss_cls: 1.2747  decode.d5.loss_mask: 0.4407  decode.d5.loss_dice: 0.5363  decode.d6.loss_cls: 1.3018  decode.d6.loss_mask: 0.4338  decode.d6.loss_dice: 0.5187  decode.d7.loss_cls: 1.4007  decode.d7.loss_mask: 0.4266  decode.d7.loss_dice: 0.5070  decode.d8.loss_cls: 1.4014  decode.d8.loss_mask: 0.4028  decode.d8.loss_dice: 0.5087
07/31 17:53:15 - mmengine - INFO - Iter(train) [ 2550/80000]  base_lr: 9.7128e-05 lr: 9.7128e-06  eta: 10:25:11  time: 0.4845  data_time: 0.0089  memory: 5916  grad_norm: 214.8016  loss: 22.7987  decode.loss_cls: 1.1746  decode.loss_mask: 0.3089  decode.loss_dice: 0.5256  decode.d0.loss_cls: 2.5670  decode.d0.loss_mask: 0.3719  decode.d0.loss_dice: 0.7625  decode.d1.loss_cls: 1.4866  decode.d1.loss_mask: 0.3439  decode.d1.loss_dice: 0.5815  decode.d2.loss_cls: 1.2988  decode.d2.loss_mask: 0.3560  decode.d2.loss_dice: 0.5606  decode.d3.loss_cls: 1.1443  decode.d3.loss_mask: 0.3481  decode.d3.loss_dice: 0.5527  decode.d4.loss_cls: 1.2273  decode.d4.loss_mask: 0.3449  decode.d4.loss_dice: 0.5391  decode.d5.loss_cls: 1.2434  decode.d5.loss_mask: 0.3210  decode.d5.loss_dice: 0.5160  decode.d6.loss_cls: 1.2079  decode.d6.loss_mask: 0.3259  decode.d6.loss_dice: 0.5182  decode.d7.loss_cls: 1.2228  decode.d7.loss_mask: 0.3241  decode.d7.loss_dice: 0.5452  decode.d8.loss_cls: 1.2249  decode.d8.loss_mask: 0.3208  decode.d8.loss_dice: 0.5340
07/31 17:53:39 - mmengine - INFO - Iter(train) [ 2600/80000]  base_lr: 9.7071e-05 lr: 9.7071e-06  eta: 10:24:48  time: 0.4847  data_time: 0.0090  memory: 5916  grad_norm: 256.0621  loss: 21.1130  decode.loss_cls: 1.1747  decode.loss_mask: 0.3634  decode.loss_dice: 0.3868  decode.d0.loss_cls: 2.5433  decode.d0.loss_mask: 0.4924  decode.d0.loss_dice: 0.5243  decode.d1.loss_cls: 1.3403  decode.d1.loss_mask: 0.3655  decode.d1.loss_dice: 0.4124  decode.d2.loss_cls: 1.1671  decode.d2.loss_mask: 0.3704  decode.d2.loss_dice: 0.4031  decode.d3.loss_cls: 1.1365  decode.d3.loss_mask: 0.3848  decode.d3.loss_dice: 0.4231  decode.d4.loss_cls: 1.1454  decode.d4.loss_mask: 0.3954  decode.d4.loss_dice: 0.4087  decode.d5.loss_cls: 1.1620  decode.d5.loss_mask: 0.4045  decode.d5.loss_dice: 0.4096  decode.d6.loss_cls: 1.1290  decode.d6.loss_mask: 0.3665  decode.d6.loss_dice: 0.3813  decode.d7.loss_cls: 1.1678  decode.d7.loss_mask: 0.3707  decode.d7.loss_dice: 0.3703  decode.d8.loss_cls: 1.1639  decode.d8.loss_mask: 0.3591  decode.d8.loss_dice: 0.3904
07/31 17:54:04 - mmengine - INFO - Iter(train) [ 2650/80000]  base_lr: 9.7015e-05 lr: 9.7015e-06  eta: 10:24:25  time: 0.4840  data_time: 0.0089  memory: 5920  grad_norm: 299.0542  loss: 19.0351  decode.loss_cls: 0.9455  decode.loss_mask: 0.4473  decode.loss_dice: 0.4115  decode.d0.loss_cls: 2.3187  decode.d0.loss_mask: 0.3767  decode.d0.loss_dice: 0.4584  decode.d1.loss_cls: 1.2191  decode.d1.loss_mask: 0.3751  decode.d1.loss_dice: 0.3890  decode.d2.loss_cls: 0.9884  decode.d2.loss_mask: 0.3630  decode.d2.loss_dice: 0.3703  decode.d3.loss_cls: 0.9175  decode.d3.loss_mask: 0.3696  decode.d3.loss_dice: 0.3317  decode.d4.loss_cls: 0.9589  decode.d4.loss_mask: 0.3703  decode.d4.loss_dice: 0.3596  decode.d5.loss_cls: 0.9070  decode.d5.loss_mask: 0.3841  decode.d5.loss_dice: 0.3805  decode.d6.loss_cls: 0.9404  decode.d6.loss_mask: 0.4285  decode.d6.loss_dice: 0.4077  decode.d7.loss_cls: 0.9875  decode.d7.loss_mask: 0.3960  decode.d7.loss_dice: 0.3998  decode.d8.loss_cls: 1.0171  decode.d8.loss_mask: 0.4085  decode.d8.loss_dice: 0.4071
07/31 17:54:28 - mmengine - INFO - Iter(train) [ 2700/80000]  base_lr: 9.6958e-05 lr: 9.6958e-06  eta: 10:24:01  time: 0.4877  data_time: 0.0093  memory: 5896  grad_norm: 237.2114  loss: 20.8755  decode.loss_cls: 1.1252  decode.loss_mask: 0.3541  decode.loss_dice: 0.4759  decode.d0.loss_cls: 2.3156  decode.d0.loss_mask: 0.3727  decode.d0.loss_dice: 0.5616  decode.d1.loss_cls: 1.4137  decode.d1.loss_mask: 0.3736  decode.d1.loss_dice: 0.4909  decode.d2.loss_cls: 1.1075  decode.d2.loss_mask: 0.3595  decode.d2.loss_dice: 0.4371  decode.d3.loss_cls: 1.1365  decode.d3.loss_mask: 0.3613  decode.d3.loss_dice: 0.4360  decode.d4.loss_cls: 1.2065  decode.d4.loss_mask: 0.3506  decode.d4.loss_dice: 0.4502  decode.d5.loss_cls: 1.1138  decode.d5.loss_mask: 0.3402  decode.d5.loss_dice: 0.4561  decode.d6.loss_cls: 1.0019  decode.d6.loss_mask: 0.3642  decode.d6.loss_dice: 0.4748  decode.d7.loss_cls: 1.0474  decode.d7.loss_mask: 0.3551  decode.d7.loss_dice: 0.4906  decode.d8.loss_cls: 1.0388  decode.d8.loss_mask: 0.3534  decode.d8.loss_dice: 0.5106
07/31 17:54:52 - mmengine - INFO - Iter(train) [ 2750/80000]  base_lr: 9.6902e-05 lr: 9.6902e-06  eta: 10:23:36  time: 0.4841  data_time: 0.0089  memory: 5919  grad_norm: 237.5447  loss: 22.2609  decode.loss_cls: 1.2577  decode.loss_mask: 0.3332  decode.loss_dice: 0.4304  decode.d0.loss_cls: 2.5655  decode.d0.loss_mask: 0.3889  decode.d0.loss_dice: 0.5490  decode.d1.loss_cls: 1.5484  decode.d1.loss_mask: 0.3357  decode.d1.loss_dice: 0.4193  decode.d2.loss_cls: 1.3944  decode.d2.loss_mask: 0.3181  decode.d2.loss_dice: 0.4194  decode.d3.loss_cls: 1.3725  decode.d3.loss_mask: 0.3206  decode.d3.loss_dice: 0.4251  decode.d4.loss_cls: 1.3849  decode.d4.loss_mask: 0.3108  decode.d4.loss_dice: 0.3682  decode.d5.loss_cls: 1.3155  decode.d5.loss_mask: 0.3330  decode.d5.loss_dice: 0.3883  decode.d6.loss_cls: 1.2785  decode.d6.loss_mask: 0.3277  decode.d6.loss_dice: 0.3982  decode.d7.loss_cls: 1.3177  decode.d7.loss_mask: 0.3273  decode.d7.loss_dice: 0.4298  decode.d8.loss_cls: 1.2227  decode.d8.loss_mask: 0.3347  decode.d8.loss_dice: 0.4456
07/31 17:55:16 - mmengine - INFO - Iter(train) [ 2800/80000]  base_lr: 9.6846e-05 lr: 9.6846e-06  eta: 10:23:11  time: 0.4849  data_time: 0.0090  memory: 5879  grad_norm: 202.0339  loss: 18.5769  decode.loss_cls: 1.0532  decode.loss_mask: 0.3197  decode.loss_dice: 0.3331  decode.d0.loss_cls: 2.3304  decode.d0.loss_mask: 0.3551  decode.d0.loss_dice: 0.5151  decode.d1.loss_cls: 1.3488  decode.d1.loss_mask: 0.3164  decode.d1.loss_dice: 0.3375  decode.d2.loss_cls: 1.0789  decode.d2.loss_mask: 0.3310  decode.d2.loss_dice: 0.3149  decode.d3.loss_cls: 1.0252  decode.d3.loss_mask: 0.2848  decode.d3.loss_dice: 0.3129  decode.d4.loss_cls: 0.9538  decode.d4.loss_mask: 0.3221  decode.d4.loss_dice: 0.3270  decode.d5.loss_cls: 1.0004  decode.d5.loss_mask: 0.3252  decode.d5.loss_dice: 0.3415  decode.d6.loss_cls: 1.0386  decode.d6.loss_mask: 0.3100  decode.d6.loss_dice: 0.3106  decode.d7.loss_cls: 1.0383  decode.d7.loss_mask: 0.3416  decode.d7.loss_dice: 0.3474  decode.d8.loss_cls: 1.0051  decode.d8.loss_mask: 0.3198  decode.d8.loss_dice: 0.3383
07/31 17:55:40 - mmengine - INFO - Iter(train) [ 2850/80000]  base_lr: 9.6789e-05 lr: 9.6789e-06  eta: 10:22:47  time: 0.4831  data_time: 0.0090  memory: 5918  grad_norm: 207.3795  loss: 18.0257  decode.loss_cls: 0.8982  decode.loss_mask: 0.3699  decode.loss_dice: 0.3104  decode.d0.loss_cls: 2.1331  decode.d0.loss_mask: 0.4163  decode.d0.loss_dice: 0.4344  decode.d1.loss_cls: 1.1785  decode.d1.loss_mask: 0.3799  decode.d1.loss_dice: 0.3099  decode.d2.loss_cls: 0.9613  decode.d2.loss_mask: 0.3823  decode.d2.loss_dice: 0.3202  decode.d3.loss_cls: 0.9969  decode.d3.loss_mask: 0.3742  decode.d3.loss_dice: 0.3285  decode.d4.loss_cls: 0.9548  decode.d4.loss_mask: 0.3792  decode.d4.loss_dice: 0.3246  decode.d5.loss_cls: 0.9333  decode.d5.loss_mask: 0.3767  decode.d5.loss_dice: 0.3202  decode.d6.loss_cls: 0.9584  decode.d6.loss_mask: 0.3621  decode.d6.loss_dice: 0.3074  decode.d7.loss_cls: 1.0009  decode.d7.loss_mask: 0.3719  decode.d7.loss_dice: 0.3287  decode.d8.loss_cls: 0.9029  decode.d8.loss_mask: 0.3720  decode.d8.loss_dice: 0.3386
07/31 17:56:05 - mmengine - INFO - Iter(train) [ 2900/80000]  base_lr: 9.6733e-05 lr: 9.6733e-06  eta: 10:22:21  time: 0.4828  data_time: 0.0089  memory: 5897  grad_norm: 223.8244  loss: 20.3984  decode.loss_cls: 1.0193  decode.loss_mask: 0.3589  decode.loss_dice: 0.5247  decode.d0.loss_cls: 1.9295  decode.d0.loss_mask: 0.4250  decode.d0.loss_dice: 0.6319  decode.d1.loss_cls: 1.1847  decode.d1.loss_mask: 0.3628  decode.d1.loss_dice: 0.5080  decode.d2.loss_cls: 1.0825  decode.d2.loss_mask: 0.3546  decode.d2.loss_dice: 0.5274  decode.d3.loss_cls: 1.0057  decode.d3.loss_mask: 0.3506  decode.d3.loss_dice: 0.5118  decode.d4.loss_cls: 1.1075  decode.d4.loss_mask: 0.3493  decode.d4.loss_dice: 0.5010  decode.d5.loss_cls: 0.9820  decode.d5.loss_mask: 0.3444  decode.d5.loss_dice: 0.5444  decode.d6.loss_cls: 1.0350  decode.d6.loss_mask: 0.3669  decode.d6.loss_dice: 0.5439  decode.d7.loss_cls: 1.0197  decode.d7.loss_mask: 0.3881  decode.d7.loss_dice: 0.5086  decode.d8.loss_cls: 1.0310  decode.d8.loss_mask: 0.3896  decode.d8.loss_dice: 0.5097
07/31 17:56:29 - mmengine - INFO - Iter(train) [ 2950/80000]  base_lr: 9.6676e-05 lr: 9.6676e-06  eta: 10:22:01  time: 0.4837  data_time: 0.0089  memory: 5933  grad_norm: 215.5096  loss: 18.4252  decode.loss_cls: 0.8412  decode.loss_mask: 0.3369  decode.loss_dice: 0.4579  decode.d0.loss_cls: 2.0743  decode.d0.loss_mask: 0.3231  decode.d0.loss_dice: 0.5125  decode.d1.loss_cls: 1.1544  decode.d1.loss_mask: 0.3217  decode.d1.loss_dice: 0.4421  decode.d2.loss_cls: 0.9851  decode.d2.loss_mask: 0.3236  decode.d2.loss_dice: 0.4030  decode.d3.loss_cls: 1.0027  decode.d3.loss_mask: 0.3205  decode.d3.loss_dice: 0.3984  decode.d4.loss_cls: 0.9799  decode.d4.loss_mask: 0.3271  decode.d4.loss_dice: 0.4203  decode.d5.loss_cls: 0.9468  decode.d5.loss_mask: 0.3193  decode.d5.loss_dice: 0.4017  decode.d6.loss_cls: 0.9329  decode.d6.loss_mask: 0.3246  decode.d6.loss_dice: 0.4448  decode.d7.loss_cls: 0.9465  decode.d7.loss_mask: 0.3291  decode.d7.loss_dice: 0.4454  decode.d8.loss_cls: 0.9111  decode.d8.loss_mask: 0.3375  decode.d8.loss_dice: 0.4610
07/31 17:56:53 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250731_173226
07/31 17:56:53 - mmengine - INFO - Iter(train) [ 3000/80000]  base_lr: 9.6620e-05 lr: 9.6620e-06  eta: 10:21:36  time: 0.4837  data_time: 0.0090  memory: 5897  grad_norm: 347.1123  loss: 19.8160  decode.loss_cls: 0.9243  decode.loss_mask: 0.4346  decode.loss_dice: 0.4225  decode.d0.loss_cls: 2.0167  decode.d0.loss_mask: 0.4478  decode.d0.loss_dice: 0.5563  decode.d1.loss_cls: 1.1715  decode.d1.loss_mask: 0.4435  decode.d1.loss_dice: 0.4304  decode.d2.loss_cls: 1.0527  decode.d2.loss_mask: 0.4289  decode.d2.loss_dice: 0.4290  decode.d3.loss_cls: 0.9492  decode.d3.loss_mask: 0.4340  decode.d3.loss_dice: 0.4153  decode.d4.loss_cls: 1.0348  decode.d4.loss_mask: 0.4287  decode.d4.loss_dice: 0.4255  decode.d5.loss_cls: 0.9963  decode.d5.loss_mask: 0.4459  decode.d5.loss_dice: 0.4303  decode.d6.loss_cls: 0.9429  decode.d6.loss_mask: 0.4414  decode.d6.loss_dice: 0.4067  decode.d7.loss_cls: 1.0149  decode.d7.loss_mask: 0.4215  decode.d7.loss_dice: 0.4085  decode.d8.loss_cls: 1.0036  decode.d8.loss_mask: 0.4380  decode.d8.loss_dice: 0.4204
07/31 17:57:17 - mmengine - INFO - Iter(train) [ 3050/80000]  base_lr: 9.6563e-05 lr: 9.6563e-06  eta: 10:21:11  time: 0.4833  data_time: 0.0089  memory: 5883  grad_norm: 177.0338  loss: 17.9797  decode.loss_cls: 0.8297  decode.loss_mask: 0.3685  decode.loss_dice: 0.4036  decode.d0.loss_cls: 1.9485  decode.d0.loss_mask: 0.3879  decode.d0.loss_dice: 0.4937  decode.d1.loss_cls: 1.1788  decode.d1.loss_mask: 0.4296  decode.d1.loss_dice: 0.4155  decode.d2.loss_cls: 0.8601  decode.d2.loss_mask: 0.3910  decode.d2.loss_dice: 0.4228  decode.d3.loss_cls: 0.8525  decode.d3.loss_mask: 0.3776  decode.d3.loss_dice: 0.3654  decode.d4.loss_cls: 0.9147  decode.d4.loss_mask: 0.3820  decode.d4.loss_dice: 0.3940  decode.d5.loss_cls: 0.8929  decode.d5.loss_mask: 0.3778  decode.d5.loss_dice: 0.3915  decode.d6.loss_cls: 0.9296  decode.d6.loss_mask: 0.3753  decode.d6.loss_dice: 0.3939  decode.d7.loss_cls: 0.8724  decode.d7.loss_mask: 0.3792  decode.d7.loss_dice: 0.3947  decode.d8.loss_cls: 0.7930  decode.d8.loss_mask: 0.3751  decode.d8.loss_dice: 0.3885
07/31 17:57:42 - mmengine - INFO - Iter(train) [ 3100/80000]  base_lr: 9.6507e-05 lr: 9.6507e-06  eta: 10:20:46  time: 0.4842  data_time: 0.0090  memory: 5896  grad_norm: 292.8744  loss: 20.2550  decode.loss_cls: 1.0763  decode.loss_mask: 0.4244  decode.loss_dice: 0.4764  decode.d0.loss_cls: 2.2195  decode.d0.loss_mask: 0.3759  decode.d0.loss_dice: 0.5383  decode.d1.loss_cls: 1.2714  decode.d1.loss_mask: 0.3322  decode.d1.loss_dice: 0.4310  decode.d2.loss_cls: 1.0177  decode.d2.loss_mask: 0.3313  decode.d2.loss_dice: 0.4469  decode.d3.loss_cls: 1.0493  decode.d3.loss_mask: 0.3285  decode.d3.loss_dice: 0.4320  decode.d4.loss_cls: 1.0990  decode.d4.loss_mask: 0.3095  decode.d4.loss_dice: 0.4020  decode.d5.loss_cls: 1.0827  decode.d5.loss_mask: 0.3126  decode.d5.loss_dice: 0.4206  decode.d6.loss_cls: 1.1102  decode.d6.loss_mask: 0.3513  decode.d6.loss_dice: 0.4493  decode.d7.loss_cls: 1.1427  decode.d7.loss_mask: 0.3975  decode.d7.loss_dice: 0.4555  decode.d8.loss_cls: 1.1045  decode.d8.loss_mask: 0.3877  decode.d8.loss_dice: 0.4788
07/31 17:58:06 - mmengine - INFO - Iter(train) [ 3150/80000]  base_lr: 9.6450e-05 lr: 9.6450e-06  eta: 10:20:21  time: 0.4842  data_time: 0.0091  memory: 5919  grad_norm: 215.0530  loss: 15.9728  decode.loss_cls: 0.7356  decode.loss_mask: 0.3807  decode.loss_dice: 0.3387  decode.d0.loss_cls: 1.8062  decode.d0.loss_mask: 0.3929  decode.d0.loss_dice: 0.4141  decode.d1.loss_cls: 1.0023  decode.d1.loss_mask: 0.4179  decode.d1.loss_dice: 0.3765  decode.d2.loss_cls: 0.7312  decode.d2.loss_mask: 0.3981  decode.d2.loss_dice: 0.3423  decode.d3.loss_cls: 0.7566  decode.d3.loss_mask: 0.3957  decode.d3.loss_dice: 0.3382  decode.d4.loss_cls: 0.6796  decode.d4.loss_mask: 0.3865  decode.d4.loss_dice: 0.3361  decode.d5.loss_cls: 0.6598  decode.d5.loss_mask: 0.3866  decode.d5.loss_dice: 0.3467  decode.d6.loss_cls: 0.6856  decode.d6.loss_mask: 0.3800  decode.d6.loss_dice: 0.3459  decode.d7.loss_cls: 0.6862  decode.d7.loss_mask: 0.4044  decode.d7.loss_dice: 0.3782  decode.d8.loss_cls: 0.7077  decode.d8.loss_mask: 0.3972  decode.d8.loss_dice: 0.3651
07/31 17:58:30 - mmengine - INFO - Iter(train) [ 3200/80000]  base_lr: 9.6394e-05 lr: 9.6394e-06  eta: 10:19:57  time: 0.4833  data_time: 0.0091  memory: 5918  grad_norm: 276.8138  loss: 16.8700  decode.loss_cls: 0.8145  decode.loss_mask: 0.3641  decode.loss_dice: 0.3174  decode.d0.loss_cls: 1.9360  decode.d0.loss_mask: 0.4738  decode.d0.loss_dice: 0.3908  decode.d1.loss_cls: 1.0188  decode.d1.loss_mask: 0.4122  decode.d1.loss_dice: 0.3361  decode.d2.loss_cls: 0.8567  decode.d2.loss_mask: 0.3982  decode.d2.loss_dice: 0.3071  decode.d3.loss_cls: 0.8304  decode.d3.loss_mask: 0.3677  decode.d3.loss_dice: 0.2920  decode.d4.loss_cls: 0.8704  decode.d4.loss_mask: 0.3720  decode.d4.loss_dice: 0.3163  decode.d5.loss_cls: 0.8457  decode.d5.loss_mask: 0.3687  decode.d5.loss_dice: 0.3177  decode.d6.loss_cls: 0.8577  decode.d6.loss_mask: 0.3740  decode.d6.loss_dice: 0.3366  decode.d7.loss_cls: 0.8473  decode.d7.loss_mask: 0.3732  decode.d7.loss_dice: 0.3037  decode.d8.loss_cls: 0.8732  decode.d8.loss_mask: 0.3822  decode.d8.loss_dice: 0.3155
07/31 17:58:54 - mmengine - INFO - Iter(train) [ 3250/80000]  base_lr: 9.6337e-05 lr: 9.6337e-06  eta: 10:19:32  time: 0.4824  data_time: 0.0090  memory: 5916  grad_norm: 208.6661  loss: 14.5827  decode.loss_cls: 0.5599  decode.loss_mask: 0.3845  decode.loss_dice: 0.4003  decode.d0.loss_cls: 1.6538  decode.d0.loss_mask: 0.4278  decode.d0.loss_dice: 0.4601  decode.d1.loss_cls: 0.7616  decode.d1.loss_mask: 0.3707  decode.d1.loss_dice: 0.3740  decode.d2.loss_cls: 0.6352  decode.d2.loss_mask: 0.3766  decode.d2.loss_dice: 0.3771  decode.d3.loss_cls: 0.5611  decode.d3.loss_mask: 0.3788  decode.d3.loss_dice: 0.3768  decode.d4.loss_cls: 0.5405  decode.d4.loss_mask: 0.3580  decode.d4.loss_dice: 0.3495  decode.d5.loss_cls: 0.5298  decode.d5.loss_mask: 0.3604  decode.d5.loss_dice: 0.3520  decode.d6.loss_cls: 0.5441  decode.d6.loss_mask: 0.3707  decode.d6.loss_dice: 0.3666  decode.d7.loss_cls: 0.5860  decode.d7.loss_mask: 0.3704  decode.d7.loss_dice: 0.3632  decode.d8.loss_cls: 0.6124  decode.d8.loss_mask: 0.3940  decode.d8.loss_dice: 0.3869
07/31 17:59:18 - mmengine - INFO - Iter(train) [ 3300/80000]  base_lr: 9.6281e-05 lr: 9.6281e-06  eta: 10:19:07  time: 0.4844  data_time: 0.0090  memory: 5936  grad_norm: 185.6992  loss: 17.2184  decode.loss_cls: 0.7968  decode.loss_mask: 0.2735  decode.loss_dice: 0.5051  decode.d0.loss_cls: 2.0333  decode.d0.loss_mask: 0.3266  decode.d0.loss_dice: 0.5670  decode.d1.loss_cls: 1.0590  decode.d1.loss_mask: 0.2841  decode.d1.loss_dice: 0.4827  decode.d2.loss_cls: 0.8257  decode.d2.loss_mask: 0.2920  decode.d2.loss_dice: 0.4479  decode.d3.loss_cls: 0.7824  decode.d3.loss_mask: 0.2897  decode.d3.loss_dice: 0.4573  decode.d4.loss_cls: 0.7289  decode.d4.loss_mask: 0.2908  decode.d4.loss_dice: 0.4705  decode.d5.loss_cls: 0.7871  decode.d5.loss_mask: 0.2822  decode.d5.loss_dice: 0.4759  decode.d6.loss_cls: 0.8307  decode.d6.loss_mask: 0.2857  decode.d6.loss_dice: 0.5001  decode.d7.loss_cls: 0.8004  decode.d7.loss_mask: 0.2811  decode.d7.loss_dice: 0.4975  decode.d8.loss_cls: 0.7804  decode.d8.loss_mask: 0.2861  decode.d8.loss_dice: 0.4977
07/31 17:59:43 - mmengine - INFO - Iter(train) [ 3350/80000]  base_lr: 9.6224e-05 lr: 9.6224e-06  eta: 10:18:42  time: 0.4835  data_time: 0.0090  memory: 5973  grad_norm: 226.1125  loss: 18.4185  decode.loss_cls: 0.9782  decode.loss_mask: 0.2923  decode.loss_dice: 0.3742  decode.d0.loss_cls: 2.1115  decode.d0.loss_mask: 0.3508  decode.d0.loss_dice: 0.4833  decode.d1.loss_cls: 1.1751  decode.d1.loss_mask: 0.3112  decode.d1.loss_dice: 0.3930  decode.d2.loss_cls: 1.0683  decode.d2.loss_mask: 0.3084  decode.d2.loss_dice: 0.3859  decode.d3.loss_cls: 0.9856  decode.d3.loss_mask: 0.3269  decode.d3.loss_dice: 0.4177  decode.d4.loss_cls: 0.9715  decode.d4.loss_mask: 0.3122  decode.d4.loss_dice: 0.4122  decode.d5.loss_cls: 0.9647  decode.d5.loss_mask: 0.3187  decode.d5.loss_dice: 0.4037  decode.d6.loss_cls: 1.0047  decode.d6.loss_mask: 0.2905  decode.d6.loss_dice: 0.3826  decode.d7.loss_cls: 0.9539  decode.d7.loss_mask: 0.2949  decode.d7.loss_dice: 0.3700  decode.d8.loss_cls: 1.0131  decode.d8.loss_mask: 0.3378  decode.d8.loss_dice: 0.4259
07/31 18:00:07 - mmengine - INFO - Iter(train) [ 3400/80000]  base_lr: 9.6168e-05 lr: 9.6168e-06  eta: 10:18:18  time: 0.4846  data_time: 0.0090  memory: 5916  grad_norm: 138.3524  loss: 16.0526  decode.loss_cls: 0.7364  decode.loss_mask: 0.3214  decode.loss_dice: 0.3979  decode.d0.loss_cls: 1.7817  decode.d0.loss_mask: 0.3714  decode.d0.loss_dice: 0.5102  decode.d1.loss_cls: 1.0541  decode.d1.loss_mask: 0.3398  decode.d1.loss_dice: 0.4276  decode.d2.loss_cls: 0.8025  decode.d2.loss_mask: 0.3103  decode.d2.loss_dice: 0.4018  decode.d3.loss_cls: 0.7142  decode.d3.loss_mask: 0.3068  decode.d3.loss_dice: 0.3763  decode.d4.loss_cls: 0.7532  decode.d4.loss_mask: 0.3141  decode.d4.loss_dice: 0.3940  decode.d5.loss_cls: 0.7257  decode.d5.loss_mask: 0.3207  decode.d5.loss_dice: 0.3865  decode.d6.loss_cls: 0.6923  decode.d6.loss_mask: 0.3106  decode.d6.loss_dice: 0.3925  decode.d7.loss_cls: 0.7170  decode.d7.loss_mask: 0.3347  decode.d7.loss_dice: 0.4112  decode.d8.loss_cls: 0.7096  decode.d8.loss_mask: 0.3442  decode.d8.loss_dice: 0.3936
07/31 18:00:31 - mmengine - INFO - Iter(train) [ 3450/80000]  base_lr: 9.6111e-05 lr: 9.6111e-06  eta: 10:17:53  time: 0.4841  data_time: 0.0091  memory: 5897  grad_norm: 313.6021  loss: 17.6930  decode.loss_cls: 0.8260  decode.loss_mask: 0.3427  decode.loss_dice: 0.4487  decode.d0.loss_cls: 1.8187  decode.d0.loss_mask: 0.3371  decode.d0.loss_dice: 0.4874  decode.d1.loss_cls: 1.1711  decode.d1.loss_mask: 0.2908  decode.d1.loss_dice: 0.4072  decode.d2.loss_cls: 0.9268  decode.d2.loss_mask: 0.3229  decode.d2.loss_dice: 0.4372  decode.d3.loss_cls: 0.9566  decode.d3.loss_mask: 0.3161  decode.d3.loss_dice: 0.4403  decode.d4.loss_cls: 0.8016  decode.d4.loss_mask: 0.3396  decode.d4.loss_dice: 0.4506  decode.d5.loss_cls: 0.8646  decode.d5.loss_mask: 0.3328  decode.d5.loss_dice: 0.4218  decode.d6.loss_cls: 0.8909  decode.d6.loss_mask: 0.3440  decode.d6.loss_dice: 0.4253  decode.d7.loss_cls: 0.9064  decode.d7.loss_mask: 0.3675  decode.d7.loss_dice: 0.4477  decode.d8.loss_cls: 0.8028  decode.d8.loss_mask: 0.3403  decode.d8.loss_dice: 0.4275
07/31 18:00:55 - mmengine - INFO - Iter(train) [ 3500/80000]  base_lr: 9.6055e-05 lr: 9.6055e-06  eta: 10:17:29  time: 0.4870  data_time: 0.0092  memory: 5918  grad_norm: 159.4036  loss: 19.8222  decode.loss_cls: 1.0542  decode.loss_mask: 0.3633  decode.loss_dice: 0.4066  decode.d0.loss_cls: 2.1745  decode.d0.loss_mask: 0.3695  decode.d0.loss_dice: 0.4887  decode.d1.loss_cls: 1.3970  decode.d1.loss_mask: 0.3769  decode.d1.loss_dice: 0.4638  decode.d2.loss_cls: 1.1538  decode.d2.loss_mask: 0.3535  decode.d2.loss_dice: 0.4320  decode.d3.loss_cls: 0.9993  decode.d3.loss_mask: 0.3538  decode.d3.loss_dice: 0.4217  decode.d4.loss_cls: 1.0510  decode.d4.loss_mask: 0.3623  decode.d4.loss_dice: 0.4243  decode.d5.loss_cls: 1.0151  decode.d5.loss_mask: 0.3574  decode.d5.loss_dice: 0.4479  decode.d6.loss_cls: 1.0519  decode.d6.loss_mask: 0.3477  decode.d6.loss_dice: 0.4130  decode.d7.loss_cls: 0.9699  decode.d7.loss_mask: 0.3664  decode.d7.loss_dice: 0.4338  decode.d8.loss_cls: 0.9754  decode.d8.loss_mask: 0.3610  decode.d8.loss_dice: 0.4366
07/31 18:01:19 - mmengine - INFO - Iter(train) [ 3550/80000]  base_lr: 9.5998e-05 lr: 9.5998e-06  eta: 10:17:07  time: 0.4840  data_time: 0.0090  memory: 5937  grad_norm: 283.4699  loss: 17.1221  decode.loss_cls: 0.9271  decode.loss_mask: 0.3022  decode.loss_dice: 0.3515  decode.d0.loss_cls: 2.0118  decode.d0.loss_mask: 0.3477  decode.d0.loss_dice: 0.5341  decode.d1.loss_cls: 1.2358  decode.d1.loss_mask: 0.2949  decode.d1.loss_dice: 0.3962  decode.d2.loss_cls: 0.9311  decode.d2.loss_mask: 0.2878  decode.d2.loss_dice: 0.3331  decode.d3.loss_cls: 0.9880  decode.d3.loss_mask: 0.2796  decode.d3.loss_dice: 0.3355  decode.d4.loss_cls: 0.9170  decode.d4.loss_mask: 0.2772  decode.d4.loss_dice: 0.3436  decode.d5.loss_cls: 0.8624  decode.d5.loss_mask: 0.2810  decode.d5.loss_dice: 0.3395  decode.d6.loss_cls: 0.8565  decode.d6.loss_mask: 0.3041  decode.d6.loss_dice: 0.3771  decode.d7.loss_cls: 0.8138  decode.d7.loss_mask: 0.3061  decode.d7.loss_dice: 0.3567  decode.d8.loss_cls: 0.9089  decode.d8.loss_mask: 0.2856  decode.d8.loss_dice: 0.3364
07/31 18:01:44 - mmengine - INFO - Iter(train) [ 3600/80000]  base_lr: 9.5942e-05 lr: 9.5942e-06  eta: 10:16:42  time: 0.4835  data_time: 0.0090  memory: 5933  grad_norm: 272.6083  loss: 16.2835  decode.loss_cls: 0.7071  decode.loss_mask: 0.3591  decode.loss_dice: 0.3685  decode.d0.loss_cls: 1.8713  decode.d0.loss_mask: 0.4301  decode.d0.loss_dice: 0.4798  decode.d1.loss_cls: 1.0496  decode.d1.loss_mask: 0.3646  decode.d1.loss_dice: 0.4091  decode.d2.loss_cls: 0.7703  decode.d2.loss_mask: 0.4002  decode.d2.loss_dice: 0.4100  decode.d3.loss_cls: 0.7370  decode.d3.loss_mask: 0.3730  decode.d3.loss_dice: 0.4009  decode.d4.loss_cls: 0.7300  decode.d4.loss_mask: 0.3684  decode.d4.loss_dice: 0.4004  decode.d5.loss_cls: 0.6604  decode.d5.loss_mask: 0.3644  decode.d5.loss_dice: 0.3937  decode.d6.loss_cls: 0.6729  decode.d6.loss_mask: 0.3700  decode.d6.loss_dice: 0.4063  decode.d7.loss_cls: 0.6841  decode.d7.loss_mask: 0.3592  decode.d7.loss_dice: 0.3563  decode.d8.loss_cls: 0.6520  decode.d8.loss_mask: 0.3579  decode.d8.loss_dice: 0.3769
07/31 18:02:08 - mmengine - INFO - Iter(train) [ 3650/80000]  base_lr: 9.5885e-05 lr: 9.5885e-06  eta: 10:16:18  time: 0.4846  data_time: 0.0090  memory: 5918  grad_norm: 287.1694  loss: 19.2449  decode.loss_cls: 0.9291  decode.loss_mask: 0.3299  decode.loss_dice: 0.4646  decode.d0.loss_cls: 1.9679  decode.d0.loss_mask: 0.4124  decode.d0.loss_dice: 0.5300  decode.d1.loss_cls: 1.3533  decode.d1.loss_mask: 0.3307  decode.d1.loss_dice: 0.4288  decode.d2.loss_cls: 0.9996  decode.d2.loss_mask: 0.3555  decode.d2.loss_dice: 0.4368  decode.d3.loss_cls: 1.0313  decode.d3.loss_mask: 0.3275  decode.d3.loss_dice: 0.4396  decode.d4.loss_cls: 1.0462  decode.d4.loss_mask: 0.3358  decode.d4.loss_dice: 0.4535  decode.d5.loss_cls: 1.0029  decode.d5.loss_mask: 0.3364  decode.d5.loss_dice: 0.4601  decode.d6.loss_cls: 1.0186  decode.d6.loss_mask: 0.3360  decode.d6.loss_dice: 0.4618  decode.d7.loss_cls: 0.9456  decode.d7.loss_mask: 0.3414  decode.d7.loss_dice: 0.4435  decode.d8.loss_cls: 0.9305  decode.d8.loss_mask: 0.3385  decode.d8.loss_dice: 0.4572
07/31 18:02:20 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250731_173226
07/31 18:02:32 - mmengine - INFO - Iter(train) [ 3700/80000]  base_lr: 9.5829e-05 lr: 9.5829e-06  eta: 10:15:53  time: 0.4836  data_time: 0.0091  memory: 5896  grad_norm: 142.0055  loss: 13.3034  decode.loss_cls: 0.5209  decode.loss_mask: 0.2788  decode.loss_dice: 0.3334  decode.d0.loss_cls: 1.6690  decode.d0.loss_mask: 0.3033  decode.d0.loss_dice: 0.4247  decode.d1.loss_cls: 0.7749  decode.d1.loss_mask: 0.2779  decode.d1.loss_dice: 0.2975  decode.d2.loss_cls: 0.7156  decode.d2.loss_mask: 0.2783  decode.d2.loss_dice: 0.3075  decode.d3.loss_cls: 0.5945  decode.d3.loss_mask: 0.2804  decode.d3.loss_dice: 0.3033  decode.d4.loss_cls: 0.5887  decode.d4.loss_mask: 0.2745  decode.d4.loss_dice: 0.2953  decode.d5.loss_cls: 0.6499  decode.d5.loss_mask: 0.2653  decode.d5.loss_dice: 0.3057  decode.d6.loss_cls: 0.6507  decode.d6.loss_mask: 0.2670  decode.d6.loss_dice: 0.2934  decode.d7.loss_cls: 0.6026  decode.d7.loss_mask: 0.2687  decode.d7.loss_dice: 0.2993  decode.d8.loss_cls: 0.5876  decode.d8.loss_mask: 0.2679  decode.d8.loss_dice: 0.3269
07/31 18:02:56 - mmengine - INFO - Iter(train) [ 3750/80000]  base_lr: 9.5772e-05 lr: 9.5772e-06  eta: 10:15:28  time: 0.4832  data_time: 0.0089  memory: 5918  grad_norm: 238.1387  loss: 14.6782  decode.loss_cls: 0.6663  decode.loss_mask: 0.2620  decode.loss_dice: 0.3442  decode.d0.loss_cls: 1.8895  decode.d0.loss_mask: 0.3053  decode.d0.loss_dice: 0.4678  decode.d1.loss_cls: 0.9837  decode.d1.loss_mask: 0.2745  decode.d1.loss_dice: 0.3857  decode.d2.loss_cls: 0.7687  decode.d2.loss_mask: 0.2721  decode.d2.loss_dice: 0.3601  decode.d3.loss_cls: 0.6315  decode.d3.loss_mask: 0.2610  decode.d3.loss_dice: 0.3444  decode.d4.loss_cls: 0.6692  decode.d4.loss_mask: 0.2516  decode.d4.loss_dice: 0.3119  decode.d5.loss_cls: 0.6810  decode.d5.loss_mask: 0.2609  decode.d5.loss_dice: 0.3182  decode.d6.loss_cls: 0.7139  decode.d6.loss_mask: 0.2550  decode.d6.loss_dice: 0.3108  decode.d7.loss_cls: 0.7903  decode.d7.loss_mask: 0.2560  decode.d7.loss_dice: 0.3291  decode.d8.loss_cls: 0.7116  decode.d8.loss_mask: 0.2547  decode.d8.loss_dice: 0.3472
07/31 18:03:20 - mmengine - INFO - Iter(train) [ 3800/80000]  base_lr: 9.5716e-05 lr: 9.5716e-06  eta: 10:15:02  time: 0.4832  data_time: 0.0092  memory: 5916  grad_norm: 301.3076  loss: 18.6849  decode.loss_cls: 0.7693  decode.loss_mask: 0.5332  decode.loss_dice: 0.5055  decode.d0.loss_cls: 1.7091  decode.d0.loss_mask: 0.5029  decode.d0.loss_dice: 0.5843  decode.d1.loss_cls: 0.8688  decode.d1.loss_mask: 0.4714  decode.d1.loss_dice: 0.4823  decode.d2.loss_cls: 0.7595  decode.d2.loss_mask: 0.4738  decode.d2.loss_dice: 0.4752  decode.d3.loss_cls: 0.7324  decode.d3.loss_mask: 0.4939  decode.d3.loss_dice: 0.4859  decode.d4.loss_cls: 0.7689  decode.d4.loss_mask: 0.4973  decode.d4.loss_dice: 0.4761  decode.d5.loss_cls: 0.7773  decode.d5.loss_mask: 0.5090  decode.d5.loss_dice: 0.4969  decode.d6.loss_cls: 0.7355  decode.d6.loss_mask: 0.4789  decode.d6.loss_dice: 0.4880  decode.d7.loss_cls: 0.7979  decode.d7.loss_mask: 0.5209  decode.d7.loss_dice: 0.5072  decode.d8.loss_cls: 0.7779  decode.d8.loss_mask: 0.5161  decode.d8.loss_dice: 0.4896
07/31 18:03:45 - mmengine - INFO - Iter(train) [ 3850/80000]  base_lr: 9.5659e-05 lr: 9.5659e-06  eta: 10:14:37  time: 0.4842  data_time: 0.0089  memory: 5916  grad_norm: 183.6469  loss: 13.6626  decode.loss_cls: 0.6825  decode.loss_mask: 0.2606  decode.loss_dice: 0.3038  decode.d0.loss_cls: 1.7185  decode.d0.loss_mask: 0.2807  decode.d0.loss_dice: 0.4049  decode.d1.loss_cls: 0.8047  decode.d1.loss_mask: 0.2918  decode.d1.loss_dice: 0.3000  decode.d2.loss_cls: 0.6542  decode.d2.loss_mask: 0.2657  decode.d2.loss_dice: 0.3184  decode.d3.loss_cls: 0.6716  decode.d3.loss_mask: 0.2696  decode.d3.loss_dice: 0.3256  decode.d4.loss_cls: 0.6050  decode.d4.loss_mask: 0.2906  decode.d4.loss_dice: 0.3323  decode.d5.loss_cls: 0.6271  decode.d5.loss_mask: 0.2698  decode.d5.loss_dice: 0.3227  decode.d6.loss_cls: 0.6287  decode.d6.loss_mask: 0.2758  decode.d6.loss_dice: 0.3269  decode.d7.loss_cls: 0.6040  decode.d7.loss_mask: 0.2753  decode.d7.loss_dice: 0.3231  decode.d8.loss_cls: 0.6442  decode.d8.loss_mask: 0.2725  decode.d8.loss_dice: 0.3119
07/31 18:04:09 - mmengine - INFO - Iter(train) [ 3900/80000]  base_lr: 9.5603e-05 lr: 9.5603e-06  eta: 10:14:12  time: 0.4835  data_time: 0.0090  memory: 5895  grad_norm: 235.8682  loss: 16.1309  decode.loss_cls: 0.6117  decode.loss_mask: 0.3701  decode.loss_dice: 0.4274  decode.d0.loss_cls: 1.6441  decode.d0.loss_mask: 0.3820  decode.d0.loss_dice: 0.5007  decode.d1.loss_cls: 0.8409  decode.d1.loss_mask: 0.3833  decode.d1.loss_dice: 0.4596  decode.d2.loss_cls: 0.6966  decode.d2.loss_mask: 0.3757  decode.d2.loss_dice: 0.4522  decode.d3.loss_cls: 0.6839  decode.d3.loss_mask: 0.3744  decode.d3.loss_dice: 0.4581  decode.d4.loss_cls: 0.6903  decode.d4.loss_mask: 0.3785  decode.d4.loss_dice: 0.4508  decode.d5.loss_cls: 0.6865  decode.d5.loss_mask: 0.3753  decode.d5.loss_dice: 0.4694  decode.d6.loss_cls: 0.6833  decode.d6.loss_mask: 0.3689  decode.d6.loss_dice: 0.4601  decode.d7.loss_cls: 0.6637  decode.d7.loss_mask: 0.3657  decode.d7.loss_dice: 0.4324  decode.d8.loss_cls: 0.6360  decode.d8.loss_mask: 0.3688  decode.d8.loss_dice: 0.4405
07/31 18:04:33 - mmengine - INFO - Iter(train) [ 3950/80000]  base_lr: 9.5546e-05 lr: 9.5546e-06  eta: 10:13:47  time: 0.4844  data_time: 0.0092  memory: 5936  grad_norm: 239.7465  loss: 15.7967  decode.loss_cls: 0.6305  decode.loss_mask: 0.3763  decode.loss_dice: 0.3655  decode.d0.loss_cls: 1.7556  decode.d0.loss_mask: 0.3610  decode.d0.loss_dice: 0.4091  decode.d1.loss_cls: 0.8405  decode.d1.loss_mask: 0.3953  decode.d1.loss_dice: 0.4043  decode.d2.loss_cls: 0.7899  decode.d2.loss_mask: 0.3901  decode.d2.loss_dice: 0.3751  decode.d3.loss_cls: 0.7158  decode.d3.loss_mask: 0.3846  decode.d3.loss_dice: 0.3878  decode.d4.loss_cls: 0.7297  decode.d4.loss_mask: 0.3805  decode.d4.loss_dice: 0.3653  decode.d5.loss_cls: 0.7095  decode.d5.loss_mask: 0.3662  decode.d5.loss_dice: 0.3646  decode.d6.loss_cls: 0.6890  decode.d6.loss_mask: 0.3666  decode.d6.loss_dice: 0.3691  decode.d7.loss_cls: 0.7097  decode.d7.loss_mask: 0.3812  decode.d7.loss_dice: 0.3881  decode.d8.loss_cls: 0.6264  decode.d8.loss_mask: 0.3880  decode.d8.loss_dice: 0.3813
07/31 18:04:57 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250731_173226
07/31 18:04:57 - mmengine - INFO - Iter(train) [ 4000/80000]  base_lr: 9.5490e-05 lr: 9.5490e-06  eta: 10:13:23  time: 0.4879  data_time: 0.0094  memory: 5986  grad_norm: 178.7002  loss: 14.6415  decode.loss_cls: 0.6730  decode.loss_mask: 0.3213  decode.loss_dice: 0.4290  decode.d0.loss_cls: 1.4700  decode.d0.loss_mask: 0.3466  decode.d0.loss_dice: 0.5810  decode.d1.loss_cls: 0.6654  decode.d1.loss_mask: 0.3376  decode.d1.loss_dice: 0.3833  decode.d2.loss_cls: 0.5833  decode.d2.loss_mask: 0.3304  decode.d2.loss_dice: 0.4090  decode.d3.loss_cls: 0.5286  decode.d3.loss_mask: 0.3281  decode.d3.loss_dice: 0.4175  decode.d4.loss_cls: 0.5635  decode.d4.loss_mask: 0.3282  decode.d4.loss_dice: 0.4016  decode.d5.loss_cls: 0.6332  decode.d5.loss_mask: 0.3270  decode.d5.loss_dice: 0.4143  decode.d6.loss_cls: 0.6349  decode.d6.loss_mask: 0.3260  decode.d6.loss_dice: 0.3934  decode.d7.loss_cls: 0.6943  decode.d7.loss_mask: 0.3276  decode.d7.loss_dice: 0.4181  decode.d8.loss_cls: 0.6761  decode.d8.loss_mask: 0.3110  decode.d8.loss_dice: 0.3883
07/31 18:05:21 - mmengine - INFO - Iter(train) [ 4050/80000]  base_lr: 9.5433e-05 lr: 9.5433e-06  eta: 10:13:01  time: 0.4840  data_time: 0.0090  memory: 5898  grad_norm: 182.2274  loss: 15.7789  decode.loss_cls: 0.6304  decode.loss_mask: 0.4061  decode.loss_dice: 0.3753  decode.d0.loss_cls: 1.5953  decode.d0.loss_mask: 0.4050  decode.d0.loss_dice: 0.4241  decode.d1.loss_cls: 0.9921  decode.d1.loss_mask: 0.3863  decode.d1.loss_dice: 0.3524  decode.d2.loss_cls: 0.7889  decode.d2.loss_mask: 0.3929  decode.d2.loss_dice: 0.3529  decode.d3.loss_cls: 0.6916  decode.d3.loss_mask: 0.3804  decode.d3.loss_dice: 0.3539  decode.d4.loss_cls: 0.7427  decode.d4.loss_mask: 0.3768  decode.d4.loss_dice: 0.3603  decode.d5.loss_cls: 0.7030  decode.d5.loss_mask: 0.3836  decode.d5.loss_dice: 0.3570  decode.d6.loss_cls: 0.7188  decode.d6.loss_mask: 0.3962  decode.d6.loss_dice: 0.3560  decode.d7.loss_cls: 0.7056  decode.d7.loss_mask: 0.3821  decode.d7.loss_dice: 0.3634  decode.d8.loss_cls: 0.6622  decode.d8.loss_mask: 0.3871  decode.d8.loss_dice: 0.3564
07/31 18:05:46 - mmengine - INFO - Iter(train) [ 4100/80000]  base_lr: 9.5377e-05 lr: 9.5377e-06  eta: 10:12:37  time: 0.4851  data_time: 0.0092  memory: 5971  grad_norm: 201.0632  loss: 15.9532  decode.loss_cls: 0.7079  decode.loss_mask: 0.3278  decode.loss_dice: 0.4110  decode.d0.loss_cls: 1.7126  decode.d0.loss_mask: 0.4010  decode.d0.loss_dice: 0.5413  decode.d1.loss_cls: 0.8938  decode.d1.loss_mask: 0.3364  decode.d1.loss_dice: 0.4120  decode.d2.loss_cls: 0.6608  decode.d2.loss_mask: 0.3527  decode.d2.loss_dice: 0.4196  decode.d3.loss_cls: 0.5732  decode.d3.loss_mask: 0.3663  decode.d3.loss_dice: 0.4478  decode.d4.loss_cls: 0.5987  decode.d4.loss_mask: 0.3658  decode.d4.loss_dice: 0.4438  decode.d5.loss_cls: 0.6711  decode.d5.loss_mask: 0.3635  decode.d5.loss_dice: 0.4732  decode.d6.loss_cls: 0.7016  decode.d6.loss_mask: 0.3631  decode.d6.loss_dice: 0.4521  decode.d7.loss_cls: 0.6823  decode.d7.loss_mask: 0.3565  decode.d7.loss_dice: 0.4403  decode.d8.loss_cls: 0.6731  decode.d8.loss_mask: 0.3503  decode.d8.loss_dice: 0.4536
07/31 18:06:10 - mmengine - INFO - Iter(train) [ 4150/80000]  base_lr: 9.5320e-05 lr: 9.5320e-06  eta: 10:12:13  time: 0.4836  data_time: 0.0092  memory: 5895  grad_norm: 465.9977  loss: 14.5294  decode.loss_cls: 0.4312  decode.loss_mask: 0.4669  decode.loss_dice: 0.4047  decode.d0.loss_cls: 1.3939  decode.d0.loss_mask: 0.4812  decode.d0.loss_dice: 0.4500  decode.d1.loss_cls: 0.5623  decode.d1.loss_mask: 0.4913  decode.d1.loss_dice: 0.3985  decode.d2.loss_cls: 0.4304  decode.d2.loss_mask: 0.4503  decode.d2.loss_dice: 0.4101  decode.d3.loss_cls: 0.5163  decode.d3.loss_mask: 0.4673  decode.d3.loss_dice: 0.3737  decode.d4.loss_cls: 0.4646  decode.d4.loss_mask: 0.4827  decode.d4.loss_dice: 0.4102  decode.d5.loss_cls: 0.4164  decode.d5.loss_mask: 0.4748  decode.d5.loss_dice: 0.4096  decode.d6.loss_cls: 0.4899  decode.d6.loss_mask: 0.4727  decode.d6.loss_dice: 0.4225  decode.d7.loss_cls: 0.5114  decode.d7.loss_mask: 0.4802  decode.d7.loss_dice: 0.4206  decode.d8.loss_cls: 0.4295  decode.d8.loss_mask: 0.4873  decode.d8.loss_dice: 0.4291
07/31 18:06:34 - mmengine - INFO - Iter(train) [ 4200/80000]  base_lr: 9.5263e-05 lr: 9.5263e-06  eta: 10:11:49  time: 0.4840  data_time: 0.0089  memory: 5934  grad_norm: 178.2150  loss: 15.0740  decode.loss_cls: 0.7376  decode.loss_mask: 0.2410  decode.loss_dice: 0.3436  decode.d0.loss_cls: 1.9758  decode.d0.loss_mask: 0.2987  decode.d0.loss_dice: 0.4792  decode.d1.loss_cls: 0.9599  decode.d1.loss_mask: 0.2758  decode.d1.loss_dice: 0.4107  decode.d2.loss_cls: 0.7221  decode.d2.loss_mask: 0.2487  decode.d2.loss_dice: 0.3490  decode.d3.loss_cls: 0.7296  decode.d3.loss_mask: 0.2670  decode.d3.loss_dice: 0.3624  decode.d4.loss_cls: 0.7174  decode.d4.loss_mask: 0.2456  decode.d4.loss_dice: 0.3363  decode.d5.loss_cls: 0.7468  decode.d5.loss_mask: 0.2390  decode.d5.loss_dice: 0.3285  decode.d6.loss_cls: 0.7210  decode.d6.loss_mask: 0.2632  decode.d6.loss_dice: 0.3458  decode.d7.loss_cls: 0.7242  decode.d7.loss_mask: 0.2467  decode.d7.loss_dice: 0.3529  decode.d8.loss_cls: 0.7875  decode.d8.loss_mask: 0.2650  decode.d8.loss_dice: 0.3531
07/31 18:06:58 - mmengine - INFO - Iter(train) [ 4250/80000]  base_lr: 9.5207e-05 lr: 9.5207e-06  eta: 10:11:24  time: 0.4838  data_time: 0.0091  memory: 5898  grad_norm: 217.5961  loss: 15.3591  decode.loss_cls: 0.5919  decode.loss_mask: 0.3832  decode.loss_dice: 0.4215  decode.d0.loss_cls: 1.4930  decode.d0.loss_mask: 0.4813  decode.d0.loss_dice: 0.4957  decode.d1.loss_cls: 0.8363  decode.d1.loss_mask: 0.3615  decode.d1.loss_dice: 0.4310  decode.d2.loss_cls: 0.6902  decode.d2.loss_mask: 0.3571  decode.d2.loss_dice: 0.4166  decode.d3.loss_cls: 0.5970  decode.d3.loss_mask: 0.3858  decode.d3.loss_dice: 0.4110  decode.d4.loss_cls: 0.6441  decode.d4.loss_mask: 0.4070  decode.d4.loss_dice: 0.4281  decode.d5.loss_cls: 0.5488  decode.d5.loss_mask: 0.4073  decode.d5.loss_dice: 0.4278  decode.d6.loss_cls: 0.6259  decode.d6.loss_mask: 0.3895  decode.d6.loss_dice: 0.4102  decode.d7.loss_cls: 0.4851  decode.d7.loss_mask: 0.4216  decode.d7.loss_dice: 0.4223  decode.d8.loss_cls: 0.5556  decode.d8.loss_mask: 0.4050  decode.d8.loss_dice: 0.4279
07/31 18:07:22 - mmengine - INFO - Iter(train) [ 4300/80000]  base_lr: 9.5150e-05 lr: 9.5150e-06  eta: 10:10:59  time: 0.4838  data_time: 0.0088  memory: 5918  grad_norm: 279.4336  loss: 15.4063  decode.loss_cls: 0.5494  decode.loss_mask: 0.3725  decode.loss_dice: 0.4256  decode.d0.loss_cls: 1.7321  decode.d0.loss_mask: 0.3984  decode.d0.loss_dice: 0.5089  decode.d1.loss_cls: 0.9000  decode.d1.loss_mask: 0.3864  decode.d1.loss_dice: 0.4318  decode.d2.loss_cls: 0.6447  decode.d2.loss_mask: 0.3720  decode.d2.loss_dice: 0.4432  decode.d3.loss_cls: 0.5650  decode.d3.loss_mask: 0.3762  decode.d3.loss_dice: 0.4366  decode.d4.loss_cls: 0.6356  decode.d4.loss_mask: 0.3586  decode.d4.loss_dice: 0.4086  decode.d5.loss_cls: 0.6307  decode.d5.loss_mask: 0.3567  decode.d5.loss_dice: 0.4132  decode.d6.loss_cls: 0.6281  decode.d6.loss_mask: 0.3575  decode.d6.loss_dice: 0.4091  decode.d7.loss_cls: 0.5834  decode.d7.loss_mask: 0.3634  decode.d7.loss_dice: 0.3998  decode.d8.loss_cls: 0.5466  decode.d8.loss_mask: 0.3540  decode.d8.loss_dice: 0.4181
07/31 18:07:47 - mmengine - INFO - Iter(train) [ 4350/80000]  base_lr: 9.5094e-05 lr: 9.5094e-06  eta: 10:10:38  time: 0.4844  data_time: 0.0091  memory: 5897  grad_norm: 148.0965  loss: 11.8704  decode.loss_cls: 0.3895  decode.loss_mask: 0.2955  decode.loss_dice: 0.3543  decode.d0.loss_cls: 1.5124  decode.d0.loss_mask: 0.3003  decode.d0.loss_dice: 0.4110  decode.d1.loss_cls: 0.6382  decode.d1.loss_mask: 0.2879  decode.d1.loss_dice: 0.3544  decode.d2.loss_cls: 0.4238  decode.d2.loss_mask: 0.2793  decode.d2.loss_dice: 0.3378  decode.d3.loss_cls: 0.3770  decode.d3.loss_mask: 0.2836  decode.d3.loss_dice: 0.3411  decode.d4.loss_cls: 0.4050  decode.d4.loss_mask: 0.2891  decode.d4.loss_dice: 0.3494  decode.d5.loss_cls: 0.3943  decode.d5.loss_mask: 0.2864  decode.d5.loss_dice: 0.3502  decode.d6.loss_cls: 0.4224  decode.d6.loss_mask: 0.2925  decode.d6.loss_dice: 0.3472  decode.d7.loss_cls: 0.4794  decode.d7.loss_mask: 0.2758  decode.d7.loss_dice: 0.3376  decode.d8.loss_cls: 0.4108  decode.d8.loss_mask: 0.2998  decode.d8.loss_dice: 0.3445
07/31 18:08:11 - mmengine - INFO - Iter(train) [ 4400/80000]  base_lr: 9.5037e-05 lr: 9.5037e-06  eta: 10:10:13  time: 0.4844  data_time: 0.0090  memory: 5933  grad_norm: 192.6431  loss: 17.5164  decode.loss_cls: 0.7803  decode.loss_mask: 0.3755  decode.loss_dice: 0.3628  decode.d0.loss_cls: 1.8584  decode.d0.loss_mask: 0.4508  decode.d0.loss_dice: 0.5257  decode.d1.loss_cls: 1.0667  decode.d1.loss_mask: 0.4039  decode.d1.loss_dice: 0.4337  decode.d2.loss_cls: 0.8472  decode.d2.loss_mask: 0.4274  decode.d2.loss_dice: 0.3914  decode.d3.loss_cls: 0.7902  decode.d3.loss_mask: 0.3927  decode.d3.loss_dice: 0.3942  decode.d4.loss_cls: 0.7811  decode.d4.loss_mask: 0.3999  decode.d4.loss_dice: 0.3978  decode.d5.loss_cls: 0.7517  decode.d5.loss_mask: 0.4120  decode.d5.loss_dice: 0.4261  decode.d6.loss_cls: 0.7653  decode.d6.loss_mask: 0.4279  decode.d6.loss_dice: 0.3950  decode.d7.loss_cls: 0.8382  decode.d7.loss_mask: 0.4381  decode.d7.loss_dice: 0.3921  decode.d8.loss_cls: 0.7867  decode.d8.loss_mask: 0.3971  decode.d8.loss_dice: 0.4065
07/31 18:08:35 - mmengine - INFO - Iter(train) [ 4450/80000]  base_lr: 9.4981e-05 lr: 9.4981e-06  eta: 10:09:50  time: 0.4834  data_time: 0.0090  memory: 5934  grad_norm: 225.0769  loss: 13.6650  decode.loss_cls: 0.5250  decode.loss_mask: 0.3437  decode.loss_dice: 0.4295  decode.d0.loss_cls: 1.4237  decode.d0.loss_mask: 0.3458  decode.d0.loss_dice: 0.4089  decode.d1.loss_cls: 0.8110  decode.d1.loss_mask: 0.3171  decode.d1.loss_dice: 0.3699  decode.d2.loss_cls: 0.5180  decode.d2.loss_mask: 0.3327  decode.d2.loss_dice: 0.3822  decode.d3.loss_cls: 0.5653  decode.d3.loss_mask: 0.3349  decode.d3.loss_dice: 0.3618  decode.d4.loss_cls: 0.5837  decode.d4.loss_mask: 0.3306  decode.d4.loss_dice: 0.3656  decode.d5.loss_cls: 0.5155  decode.d5.loss_mask: 0.3265  decode.d5.loss_dice: 0.3653  decode.d6.loss_cls: 0.5101  decode.d6.loss_mask: 0.3320  decode.d6.loss_dice: 0.3816  decode.d7.loss_cls: 0.5381  decode.d7.loss_mask: 0.3368  decode.d7.loss_dice: 0.3554  decode.d8.loss_cls: 0.5022  decode.d8.loss_mask: 0.3526  decode.d8.loss_dice: 0.3995
07/31 18:08:59 - mmengine - INFO - Iter(train) [ 4500/80000]  base_lr: 9.4924e-05 lr: 9.4924e-06  eta: 10:09:25  time: 0.4829  data_time: 0.0088  memory: 5931  grad_norm: 305.4689  loss: 13.7330  decode.loss_cls: 0.5820  decode.loss_mask: 0.3113  decode.loss_dice: 0.3322  decode.d0.loss_cls: 1.5800  decode.d0.loss_mask: 0.3599  decode.d0.loss_dice: 0.4519  decode.d1.loss_cls: 0.6974  decode.d1.loss_mask: 0.3247  decode.d1.loss_dice: 0.3487  decode.d2.loss_cls: 0.6377  decode.d2.loss_mask: 0.3196  decode.d2.loss_dice: 0.3393  decode.d3.loss_cls: 0.5852  decode.d3.loss_mask: 0.3273  decode.d3.loss_dice: 0.3482  decode.d4.loss_cls: 0.6092  decode.d4.loss_mask: 0.3254  decode.d4.loss_dice: 0.3432  decode.d5.loss_cls: 0.6123  decode.d5.loss_mask: 0.3156  decode.d5.loss_dice: 0.3195  decode.d6.loss_cls: 0.6037  decode.d6.loss_mask: 0.3237  decode.d6.loss_dice: 0.3428  decode.d7.loss_cls: 0.5730  decode.d7.loss_mask: 0.3173  decode.d7.loss_dice: 0.3087  decode.d8.loss_cls: 0.5495  decode.d8.loss_mask: 0.3090  decode.d8.loss_dice: 0.3348
07/31 18:09:24 - mmengine - INFO - Iter(train) [ 4550/80000]  base_lr: 9.4867e-05 lr: 9.4867e-06  eta: 10:09:00  time: 0.4836  data_time: 0.0088  memory: 5918  grad_norm: 147.4431  loss: 14.5841  decode.loss_cls: 0.6150  decode.loss_mask: 0.3105  decode.loss_dice: 0.3710  decode.d0.loss_cls: 1.5740  decode.d0.loss_mask: 0.3418  decode.d0.loss_dice: 0.4300  decode.d1.loss_cls: 0.7963  decode.d1.loss_mask: 0.3273  decode.d1.loss_dice: 0.4222  decode.d2.loss_cls: 0.7030  decode.d2.loss_mask: 0.3189  decode.d2.loss_dice: 0.3704  decode.d3.loss_cls: 0.5905  decode.d3.loss_mask: 0.3111  decode.d3.loss_dice: 0.3873  decode.d4.loss_cls: 0.6603  decode.d4.loss_mask: 0.3145  decode.d4.loss_dice: 0.3922  decode.d5.loss_cls: 0.6587  decode.d5.loss_mask: 0.3246  decode.d5.loss_dice: 0.3906  decode.d6.loss_cls: 0.6252  decode.d6.loss_mask: 0.3155  decode.d6.loss_dice: 0.3585  decode.d7.loss_cls: 0.6787  decode.d7.loss_mask: 0.3119  decode.d7.loss_dice: 0.3700  decode.d8.loss_cls: 0.6442  decode.d8.loss_mask: 0.3067  decode.d8.loss_dice: 0.3633
07/31 18:09:48 - mmengine - INFO - Iter(train) [ 4600/80000]  base_lr: 9.4811e-05 lr: 9.4811e-06  eta: 10:08:34  time: 0.4827  data_time: 0.0090  memory: 5895  grad_norm: 291.8931  loss: 17.1313  decode.loss_cls: 0.6998  decode.loss_mask: 0.4237  decode.loss_dice: 0.4208  decode.d0.loss_cls: 1.7175  decode.d0.loss_mask: 0.4659  decode.d0.loss_dice: 0.5273  decode.d1.loss_cls: 0.9960  decode.d1.loss_mask: 0.4318  decode.d1.loss_dice: 0.4591  decode.d2.loss_cls: 0.7548  decode.d2.loss_mask: 0.4339  decode.d2.loss_dice: 0.4618  decode.d3.loss_cls: 0.6850  decode.d3.loss_mask: 0.4462  decode.d3.loss_dice: 0.4510  decode.d4.loss_cls: 0.6942  decode.d4.loss_mask: 0.4446  decode.d4.loss_dice: 0.4547  decode.d5.loss_cls: 0.6781  decode.d5.loss_mask: 0.4303  decode.d5.loss_dice: 0.4593  decode.d6.loss_cls: 0.6452  decode.d6.loss_mask: 0.4143  decode.d6.loss_dice: 0.4372  decode.d7.loss_cls: 0.7219  decode.d7.loss_mask: 0.4320  decode.d7.loss_dice: 0.4448  decode.d8.loss_cls: 0.6695  decode.d8.loss_mask: 0.4039  decode.d8.loss_dice: 0.4269
07/31 18:10:12 - mmengine - INFO - Iter(train) [ 4650/80000]  base_lr: 9.4754e-05 lr: 9.4754e-06  eta: 10:08:10  time: 0.4851  data_time: 0.0092  memory: 5896  grad_norm: 566.2065  loss: 19.9722  decode.loss_cls: 0.9215  decode.loss_mask: 0.4169  decode.loss_dice: 0.5806  decode.d0.loss_cls: 1.8314  decode.d0.loss_mask: 0.4595  decode.d0.loss_dice: 0.6419  decode.d1.loss_cls: 1.1247  decode.d1.loss_mask: 0.4192  decode.d1.loss_dice: 0.5176  decode.d2.loss_cls: 0.8943  decode.d2.loss_mask: 0.4220  decode.d2.loss_dice: 0.5376  decode.d3.loss_cls: 0.8435  decode.d3.loss_mask: 0.4148  decode.d3.loss_dice: 0.5286  decode.d4.loss_cls: 0.8457  decode.d4.loss_mask: 0.4481  decode.d4.loss_dice: 0.5263  decode.d5.loss_cls: 0.8939  decode.d5.loss_mask: 0.4396  decode.d5.loss_dice: 0.5559  decode.d6.loss_cls: 0.9370  decode.d6.loss_mask: 0.4165  decode.d6.loss_dice: 0.5611  decode.d7.loss_cls: 0.9283  decode.d7.loss_mask: 0.4211  decode.d7.loss_dice: 0.5689  decode.d8.loss_cls: 0.8659  decode.d8.loss_mask: 0.4242  decode.d8.loss_dice: 0.5857
07/31 18:10:36 - mmengine - INFO - Iter(train) [ 4700/80000]  base_lr: 9.4698e-05 lr: 9.4698e-06  eta: 10:07:46  time: 0.4844  data_time: 0.0090  memory: 5918  grad_norm: 321.1601  loss: 15.0981  decode.loss_cls: 0.7819  decode.loss_mask: 0.3016  decode.loss_dice: 0.3795  decode.d0.loss_cls: 1.4918  decode.d0.loss_mask: 0.3803  decode.d0.loss_dice: 0.5079  decode.d1.loss_cls: 0.8360  decode.d1.loss_mask: 0.3272  decode.d1.loss_dice: 0.4099  decode.d2.loss_cls: 0.6735  decode.d2.loss_mask: 0.3497  decode.d2.loss_dice: 0.4027  decode.d3.loss_cls: 0.5956  decode.d3.loss_mask: 0.3515  decode.d3.loss_dice: 0.4101  decode.d4.loss_cls: 0.6205  decode.d4.loss_mask: 0.3493  decode.d4.loss_dice: 0.4063  decode.d5.loss_cls: 0.6384  decode.d5.loss_mask: 0.3543  decode.d5.loss_dice: 0.3810  decode.d6.loss_cls: 0.6786  decode.d6.loss_mask: 0.3068  decode.d6.loss_dice: 0.3777  decode.d7.loss_cls: 0.6469  decode.d7.loss_mask: 0.3173  decode.d7.loss_dice: 0.3858  decode.d8.loss_cls: 0.7355  decode.d8.loss_mask: 0.3188  decode.d8.loss_dice: 0.3813
07/31 18:11:00 - mmengine - INFO - Iter(train) [ 4750/80000]  base_lr: 9.4641e-05 lr: 9.4641e-06  eta: 10:07:22  time: 0.4836  data_time: 0.0091  memory: 5897  grad_norm: 160.4776  loss: 14.6271  decode.loss_cls: 0.5686  decode.loss_mask: 0.2823  decode.loss_dice: 0.4059  decode.d0.loss_cls: 1.6720  decode.d0.loss_mask: 0.3451  decode.d0.loss_dice: 0.5401  decode.d1.loss_cls: 0.7511  decode.d1.loss_mask: 0.2829  decode.d1.loss_dice: 0.3785  decode.d2.loss_cls: 0.6596  decode.d2.loss_mask: 0.2815  decode.d2.loss_dice: 0.4127  decode.d3.loss_cls: 0.6862  decode.d3.loss_mask: 0.2759  decode.d3.loss_dice: 0.3798  decode.d4.loss_cls: 0.7006  decode.d4.loss_mask: 0.2729  decode.d4.loss_dice: 0.4016  decode.d5.loss_cls: 0.5812  decode.d5.loss_mask: 0.2903  decode.d5.loss_dice: 0.4118  decode.d6.loss_cls: 0.5992  decode.d6.loss_mask: 0.2916  decode.d6.loss_dice: 0.3976  decode.d7.loss_cls: 0.7169  decode.d7.loss_mask: 0.2885  decode.d7.loss_dice: 0.3940  decode.d8.loss_cls: 0.6589  decode.d8.loss_mask: 0.2940  decode.d8.loss_dice: 0.4057
07/31 18:11:25 - mmengine - INFO - Iter(train) [ 4800/80000]  base_lr: 9.4584e-05 lr: 9.4584e-06  eta: 10:06:57  time: 0.4831  data_time: 0.0092  memory: 5973  grad_norm: 315.5473  loss: 13.8408  decode.loss_cls: 0.5000  decode.loss_mask: 0.4097  decode.loss_dice: 0.4083  decode.d0.loss_cls: 1.2917  decode.d0.loss_mask: 0.4319  decode.d0.loss_dice: 0.4570  decode.d1.loss_cls: 0.6922  decode.d1.loss_mask: 0.4063  decode.d1.loss_dice: 0.4070  decode.d2.loss_cls: 0.4499  decode.d2.loss_mask: 0.4087  decode.d2.loss_dice: 0.4256  decode.d3.loss_cls: 0.3829  decode.d3.loss_mask: 0.4120  decode.d3.loss_dice: 0.4105  decode.d4.loss_cls: 0.4184  decode.d4.loss_mask: 0.4076  decode.d4.loss_dice: 0.4172  decode.d5.loss_cls: 0.4123  decode.d5.loss_mask: 0.4055  decode.d5.loss_dice: 0.3966  decode.d6.loss_cls: 0.4298  decode.d6.loss_mask: 0.3913  decode.d6.loss_dice: 0.4298  decode.d7.loss_cls: 0.5248  decode.d7.loss_mask: 0.3909  decode.d7.loss_dice: 0.4060  decode.d8.loss_cls: 0.4972  decode.d8.loss_mask: 0.4129  decode.d8.loss_dice: 0.4069
07/31 18:11:49 - mmengine - INFO - Iter(train) [ 4850/80000]  base_lr: 9.4528e-05 lr: 9.4528e-06  eta: 10:06:32  time: 0.4825  data_time: 0.0090  memory: 5937  grad_norm: 182.1099  loss: 14.6122  decode.loss_cls: 0.6286  decode.loss_mask: 0.3737  decode.loss_dice: 0.4205  decode.d0.loss_cls: 1.4209  decode.d0.loss_mask: 0.3923  decode.d0.loss_dice: 0.4887  decode.d1.loss_cls: 0.7011  decode.d1.loss_mask: 0.3790  decode.d1.loss_dice: 0.4121  decode.d2.loss_cls: 0.6436  decode.d2.loss_mask: 0.3573  decode.d2.loss_dice: 0.4068  decode.d3.loss_cls: 0.5275  decode.d3.loss_mask: 0.3543  decode.d3.loss_dice: 0.3780  decode.d4.loss_cls: 0.6237  decode.d4.loss_mask: 0.3414  decode.d4.loss_dice: 0.3810  decode.d5.loss_cls: 0.6892  decode.d5.loss_mask: 0.3421  decode.d5.loss_dice: 0.3764  decode.d6.loss_cls: 0.5320  decode.d6.loss_mask: 0.3558  decode.d6.loss_dice: 0.4027  decode.d7.loss_cls: 0.5837  decode.d7.loss_mask: 0.3786  decode.d7.loss_dice: 0.3960  decode.d8.loss_cls: 0.5221  decode.d8.loss_mask: 0.3860  decode.d8.loss_dice: 0.4170
07/31 18:12:13 - mmengine - INFO - Iter(train) [ 4900/80000]  base_lr: 9.4471e-05 lr: 9.4471e-06  eta: 10:06:07  time: 0.4825  data_time: 0.0091  memory: 5934  grad_norm: 402.8112  loss: 17.6622  decode.loss_cls: 0.7519  decode.loss_mask: 0.4621  decode.loss_dice: 0.4566  decode.d0.loss_cls: 1.6503  decode.d0.loss_mask: 0.4849  decode.d0.loss_dice: 0.5685  decode.d1.loss_cls: 0.7935  decode.d1.loss_mask: 0.5117  decode.d1.loss_dice: 0.5453  decode.d2.loss_cls: 0.7394  decode.d2.loss_mask: 0.4787  decode.d2.loss_dice: 0.4986  decode.d3.loss_cls: 0.7868  decode.d3.loss_mask: 0.4057  decode.d3.loss_dice: 0.4568  decode.d4.loss_cls: 0.8416  decode.d4.loss_mask: 0.4235  decode.d4.loss_dice: 0.4830  decode.d5.loss_cls: 0.6483  decode.d5.loss_mask: 0.4352  decode.d5.loss_dice: 0.4770  decode.d6.loss_cls: 0.6497  decode.d6.loss_mask: 0.4069  decode.d6.loss_dice: 0.4781  decode.d7.loss_cls: 0.6579  decode.d7.loss_mask: 0.4432  decode.d7.loss_dice: 0.4800  decode.d8.loss_cls: 0.7407  decode.d8.loss_mask: 0.4470  decode.d8.loss_dice: 0.4589
07/31 18:12:37 - mmengine - INFO - Iter(train) [ 4950/80000]  base_lr: 9.4415e-05 lr: 9.4415e-06  eta: 10:05:43  time: 0.4830  data_time: 0.0090  memory: 5971  grad_norm: 224.2112  loss: 12.8100  decode.loss_cls: 0.4146  decode.loss_mask: 0.3294  decode.loss_dice: 0.4093  decode.d0.loss_cls: 1.3018  decode.d0.loss_mask: 0.3262  decode.d0.loss_dice: 0.4197  decode.d1.loss_cls: 0.4810  decode.d1.loss_mask: 0.3379  decode.d1.loss_dice: 0.4135  decode.d2.loss_cls: 0.4675  decode.d2.loss_mask: 0.3247  decode.d2.loss_dice: 0.4070  decode.d3.loss_cls: 0.3875  decode.d3.loss_mask: 0.3296  decode.d3.loss_dice: 0.3960  decode.d4.loss_cls: 0.4432  decode.d4.loss_mask: 0.3390  decode.d4.loss_dice: 0.4074  decode.d5.loss_cls: 0.3782  decode.d5.loss_mask: 0.3418  decode.d5.loss_dice: 0.4079  decode.d6.loss_cls: 0.4569  decode.d6.loss_mask: 0.3645  decode.d6.loss_dice: 0.4417  decode.d7.loss_cls: 0.4823  decode.d7.loss_mask: 0.3543  decode.d7.loss_dice: 0.4427  decode.d8.loss_cls: 0.4699  decode.d8.loss_mask: 0.3248  decode.d8.loss_dice: 0.4095
07/31 18:13:01 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250731_173226
07/31 18:13:01 - mmengine - INFO - Iter(train) [ 5000/80000]  base_lr: 9.4358e-05 lr: 9.4358e-06  eta: 10:05:18  time: 0.4827  data_time: 0.0091  memory: 5918  grad_norm: 177.3670  loss: 14.1480  decode.loss_cls: 0.4759  decode.loss_mask: 0.3475  decode.loss_dice: 0.4209  decode.d0.loss_cls: 1.3204  decode.d0.loss_mask: 0.3798  decode.d0.loss_dice: 0.4534  decode.d1.loss_cls: 0.6170  decode.d1.loss_mask: 0.3806  decode.d1.loss_dice: 0.4710  decode.d2.loss_cls: 0.5885  decode.d2.loss_mask: 0.3649  decode.d2.loss_dice: 0.4457  decode.d3.loss_cls: 0.4898  decode.d3.loss_mask: 0.3577  decode.d3.loss_dice: 0.4402  decode.d4.loss_cls: 0.4805  decode.d4.loss_mask: 0.3704  decode.d4.loss_dice: 0.4503  decode.d5.loss_cls: 0.5851  decode.d5.loss_mask: 0.3605  decode.d5.loss_dice: 0.4439  decode.d6.loss_cls: 0.5244  decode.d6.loss_mask: 0.3520  decode.d6.loss_dice: 0.4304  decode.d7.loss_cls: 0.5198  decode.d7.loss_mask: 0.3542  decode.d7.loss_dice: 0.4210  decode.d8.loss_cls: 0.5222  decode.d8.loss_mask: 0.3490  decode.d8.loss_dice: 0.4309
07/31 18:13:01 - mmengine - INFO - Saving checkpoint at 5000 iterations
07/31 18:13:28 - mmengine - INFO - Iter(train) [ 5050/80000]  base_lr: 9.4301e-05 lr: 9.4301e-06  eta: 10:05:25  time: 0.4824  data_time: 0.0090  memory: 5920  grad_norm: 138.8256  loss: 12.1864  decode.loss_cls: 0.5026  decode.loss_mask: 0.2733  decode.loss_dice: 0.2808  decode.d0.loss_cls: 1.4443  decode.d0.loss_mask: 0.3130  decode.d0.loss_dice: 0.3718  decode.d1.loss_cls: 0.6340  decode.d1.loss_mask: 0.2696  decode.d1.loss_dice: 0.2938  decode.d2.loss_cls: 0.4963  decode.d2.loss_mask: 0.2863  decode.d2.loss_dice: 0.2907  decode.d3.loss_cls: 0.5407  decode.d3.loss_mask: 0.2811  decode.d3.loss_dice: 0.2818  decode.d4.loss_cls: 0.5343  decode.d4.loss_mask: 0.2801  decode.d4.loss_dice: 0.2868  decode.d5.loss_cls: 0.4729  decode.d5.loss_mask: 0.3282  decode.d5.loss_dice: 0.2967  decode.d6.loss_cls: 0.5682  decode.d6.loss_mask: 0.2845  decode.d6.loss_dice: 0.3012  decode.d7.loss_cls: 0.5646  decode.d7.loss_mask: 0.2751  decode.d7.loss_dice: 0.2887  decode.d8.loss_cls: 0.5683  decode.d8.loss_mask: 0.2807  decode.d8.loss_dice: 0.2961
07/31 18:13:52 - mmengine - INFO - Iter(train) [ 5100/80000]  base_lr: 9.4245e-05 lr: 9.4245e-06  eta: 10:04:59  time: 0.4830  data_time: 0.0089  memory: 5897  grad_norm: 195.9160  loss: 13.2869  decode.loss_cls: 0.4593  decode.loss_mask: 0.4332  decode.loss_dice: 0.3809  decode.d0.loss_cls: 1.5341  decode.d0.loss_mask: 0.4593  decode.d0.loss_dice: 0.4789  decode.d1.loss_cls: 0.7067  decode.d1.loss_mask: 0.3233  decode.d1.loss_dice: 0.3695  decode.d2.loss_cls: 0.5537  decode.d2.loss_mask: 0.3079  decode.d2.loss_dice: 0.3436  decode.d3.loss_cls: 0.4266  decode.d3.loss_mask: 0.3557  decode.d3.loss_dice: 0.3505  decode.d4.loss_cls: 0.4768  decode.d4.loss_mask: 0.3556  decode.d4.loss_dice: 0.3304  decode.d5.loss_cls: 0.4176  decode.d5.loss_mask: 0.3606  decode.d5.loss_dice: 0.3182  decode.d6.loss_cls: 0.4588  decode.d6.loss_mask: 0.3732  decode.d6.loss_dice: 0.3390  decode.d7.loss_cls: 0.4382  decode.d7.loss_mask: 0.3740  decode.d7.loss_dice: 0.3273  decode.d8.loss_cls: 0.4633  decode.d8.loss_mask: 0.3948  decode.d8.loss_dice: 0.3759
07/31 18:14:16 - mmengine - INFO - Iter(train) [ 5150/80000]  base_lr: 9.4188e-05 lr: 9.4188e-06  eta: 10:04:33  time: 0.4831  data_time: 0.0091  memory: 5916  grad_norm: 257.5896  loss: 16.3897  decode.loss_cls: 0.5825  decode.loss_mask: 0.4249  decode.loss_dice: 0.4717  decode.d0.loss_cls: 1.4248  decode.d0.loss_mask: 0.5248  decode.d0.loss_dice: 0.5196  decode.d1.loss_cls: 0.6381  decode.d1.loss_mask: 0.4455  decode.d1.loss_dice: 0.4805  decode.d2.loss_cls: 0.5975  decode.d2.loss_mask: 0.4393  decode.d2.loss_dice: 0.4631  decode.d3.loss_cls: 0.6420  decode.d3.loss_mask: 0.4525  decode.d3.loss_dice: 0.4724  decode.d4.loss_cls: 0.7715  decode.d4.loss_mask: 0.4189  decode.d4.loss_dice: 0.4432  decode.d5.loss_cls: 0.6344  decode.d5.loss_mask: 0.4585  decode.d5.loss_dice: 0.5246  decode.d6.loss_cls: 0.6298  decode.d6.loss_mask: 0.4359  decode.d6.loss_dice: 0.4749  decode.d7.loss_cls: 0.6098  decode.d7.loss_mask: 0.4492  decode.d7.loss_dice: 0.4522  decode.d8.loss_cls: 0.5976  decode.d8.loss_mask: 0.4344  decode.d8.loss_dice: 0.4754
07/31 18:14:40 - mmengine - INFO - Iter(train) [ 5200/80000]  base_lr: 9.4132e-05 lr: 9.4132e-06  eta: 10:04:08  time: 0.4836  data_time: 0.0091  memory: 5896  grad_norm: 171.9682  loss: 11.2152  decode.loss_cls: 0.3871  decode.loss_mask: 0.2808  decode.loss_dice: 0.3409  decode.d0.loss_cls: 1.1786  decode.d0.loss_mask: 0.3105  decode.d0.loss_dice: 0.3929  decode.d1.loss_cls: 0.4872  decode.d1.loss_mask: 0.2967  decode.d1.loss_dice: 0.3423  decode.d2.loss_cls: 0.4793  decode.d2.loss_mask: 0.2964  decode.d2.loss_dice: 0.3428  decode.d3.loss_cls: 0.4223  decode.d3.loss_mask: 0.2903  decode.d3.loss_dice: 0.3163  decode.d4.loss_cls: 0.4181  decode.d4.loss_mask: 0.2871  decode.d4.loss_dice: 0.3479  decode.d5.loss_cls: 0.3953  decode.d5.loss_mask: 0.2860  decode.d5.loss_dice: 0.3302  decode.d6.loss_cls: 0.3894  decode.d6.loss_mask: 0.2836  decode.d6.loss_dice: 0.3133  decode.d7.loss_cls: 0.3995  decode.d7.loss_mask: 0.2841  decode.d7.loss_dice: 0.3168  decode.d8.loss_cls: 0.3827  decode.d8.loss_mask: 0.2871  decode.d8.loss_dice: 0.3299
07/31 18:15:04 - mmengine - INFO - Iter(train) [ 5250/80000]  base_lr: 9.4075e-05 lr: 9.4075e-06  eta: 10:03:44  time: 0.4838  data_time: 0.0093  memory: 5934  grad_norm: 212.8959  loss: 13.7595  decode.loss_cls: 0.4535  decode.loss_mask: 0.3328  decode.loss_dice: 0.4461  decode.d0.loss_cls: 1.3629  decode.d0.loss_mask: 0.3411  decode.d0.loss_dice: 0.5134  decode.d1.loss_cls: 0.6109  decode.d1.loss_mask: 0.3349  decode.d1.loss_dice: 0.4213  decode.d2.loss_cls: 0.5015  decode.d2.loss_mask: 0.3355  decode.d2.loss_dice: 0.4462  decode.d3.loss_cls: 0.5336  decode.d3.loss_mask: 0.3316  decode.d3.loss_dice: 0.4445  decode.d4.loss_cls: 0.5467  decode.d4.loss_mask: 0.3349  decode.d4.loss_dice: 0.4420  decode.d5.loss_cls: 0.5026  decode.d5.loss_mask: 0.3383  decode.d5.loss_dice: 0.4331  decode.d6.loss_cls: 0.4874  decode.d6.loss_mask: 0.3396  decode.d6.loss_dice: 0.4344  decode.d7.loss_cls: 0.4971  decode.d7.loss_mask: 0.3291  decode.d7.loss_dice: 0.4315  decode.d8.loss_cls: 0.4596  decode.d8.loss_mask: 0.3332  decode.d8.loss_dice: 0.4402
07/31 18:15:28 - mmengine - INFO - Iter(train) [ 5300/80000]  base_lr: 9.4018e-05 lr: 9.4018e-06  eta: 10:03:19  time: 0.4834  data_time: 0.0092  memory: 5916  grad_norm: 225.2221  loss: 12.6979  decode.loss_cls: 0.5259  decode.loss_mask: 0.3281  decode.loss_dice: 0.3900  decode.d0.loss_cls: 1.4922  decode.d0.loss_mask: 0.3146  decode.d0.loss_dice: 0.3660  decode.d1.loss_cls: 0.5729  decode.d1.loss_mask: 0.3140  decode.d1.loss_dice: 0.3642  decode.d2.loss_cls: 0.4919  decode.d2.loss_mask: 0.3094  decode.d2.loss_dice: 0.3474  decode.d3.loss_cls: 0.5053  decode.d3.loss_mask: 0.2997  decode.d3.loss_dice: 0.3452  decode.d4.loss_cls: 0.4901  decode.d4.loss_mask: 0.3009  decode.d4.loss_dice: 0.3456  decode.d5.loss_cls: 0.5161  decode.d5.loss_mask: 0.3066  decode.d5.loss_dice: 0.3961  decode.d6.loss_cls: 0.4469  decode.d6.loss_mask: 0.3040  decode.d6.loss_dice: 0.3480  decode.d7.loss_cls: 0.4870  decode.d7.loss_mask: 0.3058  decode.d7.loss_dice: 0.3394  decode.d8.loss_cls: 0.4663  decode.d8.loss_mask: 0.3169  decode.d8.loss_dice: 0.3615
07/31 18:15:53 - mmengine - INFO - Iter(train) [ 5350/80000]  base_lr: 9.3962e-05 lr: 9.3962e-06  eta: 10:02:57  time: 0.4839  data_time: 0.0090  memory: 5971  grad_norm: 284.6873  loss: 15.0930  decode.loss_cls: 0.6558  decode.loss_mask: 0.3388  decode.loss_dice: 0.4312  decode.d0.loss_cls: 1.4319  decode.d0.loss_mask: 0.4091  decode.d0.loss_dice: 0.5649  decode.d1.loss_cls: 0.8465  decode.d1.loss_mask: 0.3289  decode.d1.loss_dice: 0.4057  decode.d2.loss_cls: 0.7133  decode.d2.loss_mask: 0.3039  decode.d2.loss_dice: 0.3689  decode.d3.loss_cls: 0.6480  decode.d3.loss_mask: 0.3067  decode.d3.loss_dice: 0.3869  decode.d4.loss_cls: 0.6855  decode.d4.loss_mask: 0.3044  decode.d4.loss_dice: 0.3732  decode.d5.loss_cls: 0.6709  decode.d5.loss_mask: 0.3187  decode.d5.loss_dice: 0.4046  decode.d6.loss_cls: 0.6080  decode.d6.loss_mask: 0.3376  decode.d6.loss_dice: 0.4042  decode.d7.loss_cls: 0.6601  decode.d7.loss_mask: 0.3389  decode.d7.loss_dice: 0.4288  decode.d8.loss_cls: 0.6289  decode.d8.loss_mask: 0.3423  decode.d8.loss_dice: 0.4466
07/31 18:16:17 - mmengine - INFO - Iter(train) [ 5400/80000]  base_lr: 9.3905e-05 lr: 9.3905e-06  eta: 10:02:32  time: 0.4836  data_time: 0.0091  memory: 5918  grad_norm: 182.1050  loss: 13.3749  decode.loss_cls: 0.4936  decode.loss_mask: 0.3208  decode.loss_dice: 0.3777  decode.d0.loss_cls: 1.3574  decode.d0.loss_mask: 0.3268  decode.d0.loss_dice: 0.4880  decode.d1.loss_cls: 0.6636  decode.d1.loss_mask: 0.2892  decode.d1.loss_dice: 0.3762  decode.d2.loss_cls: 0.5577  decode.d2.loss_mask: 0.2962  decode.d2.loss_dice: 0.4315  decode.d3.loss_cls: 0.5467  decode.d3.loss_mask: 0.2905  decode.d3.loss_dice: 0.4454  decode.d4.loss_cls: 0.6160  decode.d4.loss_mask: 0.2757  decode.d4.loss_dice: 0.4048  decode.d5.loss_cls: 0.5559  decode.d5.loss_mask: 0.2797  decode.d5.loss_dice: 0.3871  decode.d6.loss_cls: 0.5132  decode.d6.loss_mask: 0.3035  decode.d6.loss_dice: 0.3800  decode.d7.loss_cls: 0.5572  decode.d7.loss_mask: 0.2807  decode.d7.loss_dice: 0.3607  decode.d8.loss_cls: 0.5124  decode.d8.loss_mask: 0.3133  decode.d8.loss_dice: 0.3732
07/31 18:16:41 - mmengine - INFO - Iter(train) [ 5450/80000]  base_lr: 9.3848e-05 lr: 9.3848e-06  eta: 10:02:07  time: 0.4845  data_time: 0.0092  memory: 5916  grad_norm: 171.2248  loss: 11.0790  decode.loss_cls: 0.3222  decode.loss_mask: 0.2948  decode.loss_dice: 0.3472  decode.d0.loss_cls: 1.3940  decode.d0.loss_mask: 0.3190  decode.d0.loss_dice: 0.4363  decode.d1.loss_cls: 0.5037  decode.d1.loss_mask: 0.2961  decode.d1.loss_dice: 0.3724  decode.d2.loss_cls: 0.3251  decode.d2.loss_mask: 0.2978  decode.d2.loss_dice: 0.3731  decode.d3.loss_cls: 0.3147  decode.d3.loss_mask: 0.2868  decode.d3.loss_dice: 0.3370  decode.d4.loss_cls: 0.3214  decode.d4.loss_mask: 0.2976  decode.d4.loss_dice: 0.3638  decode.d5.loss_cls: 0.3093  decode.d5.loss_mask: 0.2995  decode.d5.loss_dice: 0.3739  decode.d6.loss_cls: 0.3263  decode.d6.loss_mask: 0.2869  decode.d6.loss_dice: 0.3527  decode.d7.loss_cls: 0.3243  decode.d7.loss_mask: 0.2901  decode.d7.loss_dice: 0.3636  decode.d8.loss_cls: 0.2981  decode.d8.loss_mask: 0.2904  decode.d8.loss_dice: 0.3610
07/31 18:17:05 - mmengine - INFO - Iter(train) [ 5500/80000]  base_lr: 9.3792e-05 lr: 9.3792e-06  eta: 10:01:43  time: 0.4844  data_time: 0.0092  memory: 5899  grad_norm: 146.1515  loss: 11.4154  decode.loss_cls: 0.4532  decode.loss_mask: 0.2720  decode.loss_dice: 0.2854  decode.d0.loss_cls: 1.4569  decode.d0.loss_mask: 0.2995  decode.d0.loss_dice: 0.3532  decode.d1.loss_cls: 0.6457  decode.d1.loss_mask: 0.2783  decode.d1.loss_dice: 0.3123  decode.d2.loss_cls: 0.5066  decode.d2.loss_mask: 0.2849  decode.d2.loss_dice: 0.3071  decode.d3.loss_cls: 0.4248  decode.d3.loss_mask: 0.2796  decode.d3.loss_dice: 0.2928  decode.d4.loss_cls: 0.4185  decode.d4.loss_mask: 0.2734  decode.d4.loss_dice: 0.2891  decode.d5.loss_cls: 0.3793  decode.d5.loss_mask: 0.2780  decode.d5.loss_dice: 0.2982  decode.d6.loss_cls: 0.4153  decode.d6.loss_mask: 0.2745  decode.d6.loss_dice: 0.2863  decode.d7.loss_cls: 0.4510  decode.d7.loss_mask: 0.2817  decode.d7.loss_dice: 0.2922  decode.d8.loss_cls: 0.4462  decode.d8.loss_mask: 0.2771  decode.d8.loss_dice: 0.3024
07/31 18:17:30 - mmengine - INFO - Iter(train) [ 5550/80000]  base_lr: 9.3735e-05 lr: 9.3735e-06  eta: 10:01:18  time: 0.4849  data_time: 0.0094  memory: 5916  grad_norm: 222.1305  loss: 11.7226  decode.loss_cls: 0.3148  decode.loss_mask: 0.3113  decode.loss_dice: 0.3411  decode.d0.loss_cls: 1.4941  decode.d0.loss_mask: 0.3821  decode.d0.loss_dice: 0.3855  decode.d1.loss_cls: 0.4812  decode.d1.loss_mask: 0.3276  decode.d1.loss_dice: 0.3355  decode.d2.loss_cls: 0.4082  decode.d2.loss_mask: 0.3289  decode.d2.loss_dice: 0.3553  decode.d3.loss_cls: 0.4315  decode.d3.loss_mask: 0.3117  decode.d3.loss_dice: 0.3415  decode.d4.loss_cls: 0.4131  decode.d4.loss_mask: 0.3116  decode.d4.loss_dice: 0.3328  decode.d5.loss_cls: 0.4150  decode.d5.loss_mask: 0.3148  decode.d5.loss_dice: 0.3258  decode.d6.loss_cls: 0.4413  decode.d6.loss_mask: 0.3093  decode.d6.loss_dice: 0.3290  decode.d7.loss_cls: 0.3630  decode.d7.loss_mask: 0.3092  decode.d7.loss_dice: 0.3263  decode.d8.loss_cls: 0.3251  decode.d8.loss_mask: 0.3115  decode.d8.loss_dice: 0.3449
07/31 18:17:54 - mmengine - INFO - Iter(train) [ 5600/80000]  base_lr: 9.3678e-05 lr: 9.3678e-06  eta: 10:00:54  time: 0.4850  data_time: 0.0090  memory: 5933  grad_norm: 140.2060  loss: 10.3040  decode.loss_cls: 0.2993  decode.loss_mask: 0.3462  decode.loss_dice: 0.2563  decode.d0.loss_cls: 1.4481  decode.d0.loss_mask: 0.3888  decode.d0.loss_dice: 0.3220  decode.d1.loss_cls: 0.4021  decode.d1.loss_mask: 0.3495  decode.d1.loss_dice: 0.2628  decode.d2.loss_cls: 0.2653  decode.d2.loss_mask: 0.3637  decode.d2.loss_dice: 0.2723  decode.d3.loss_cls: 0.2642  decode.d3.loss_mask: 0.3730  decode.d3.loss_dice: 0.2704  decode.d4.loss_cls: 0.2893  decode.d4.loss_mask: 0.3525  decode.d4.loss_dice: 0.2593  decode.d5.loss_cls: 0.2589  decode.d5.loss_mask: 0.3531  decode.d5.loss_dice: 0.2694  decode.d6.loss_cls: 0.2487  decode.d6.loss_mask: 0.3554  decode.d6.loss_dice: 0.2648  decode.d7.loss_cls: 0.2718  decode.d7.loss_mask: 0.3457  decode.d7.loss_dice: 0.2613  decode.d8.loss_cls: 0.2636  decode.d8.loss_mask: 0.3606  decode.d8.loss_dice: 0.2654
07/31 18:18:18 - mmengine - INFO - Iter(train) [ 5650/80000]  base_lr: 9.3622e-05 lr: 9.3622e-06  eta: 10:00:30  time: 0.4840  data_time: 0.0090  memory: 5931  grad_norm: 201.4865  loss: 12.5226  decode.loss_cls: 0.4800  decode.loss_mask: 0.3600  decode.loss_dice: 0.3492  decode.d0.loss_cls: 1.3524  decode.d0.loss_mask: 0.3191  decode.d0.loss_dice: 0.3568  decode.d1.loss_cls: 0.5285  decode.d1.loss_mask: 0.3278  decode.d1.loss_dice: 0.3391  decode.d2.loss_cls: 0.5232  decode.d2.loss_mask: 0.3240  decode.d2.loss_dice: 0.3427  decode.d3.loss_cls: 0.4133  decode.d3.loss_mask: 0.3311  decode.d3.loss_dice: 0.3654  decode.d4.loss_cls: 0.4413  decode.d4.loss_mask: 0.3267  decode.d4.loss_dice: 0.3634  decode.d5.loss_cls: 0.4806  decode.d5.loss_mask: 0.3256  decode.d5.loss_dice: 0.3670  decode.d6.loss_cls: 0.4374  decode.d6.loss_mask: 0.3248  decode.d6.loss_dice: 0.3758  decode.d7.loss_cls: 0.4102  decode.d7.loss_mask: 0.3594  decode.d7.loss_dice: 0.3932  decode.d8.loss_cls: 0.4808  decode.d8.loss_mask: 0.3599  decode.d8.loss_dice: 0.3642
07/31 18:18:42 - mmengine - INFO - Iter(train) [ 5700/80000]  base_lr: 9.3565e-05 lr: 9.3565e-06  eta: 10:00:05  time: 0.4840  data_time: 0.0089  memory: 5934  grad_norm: 252.4498  loss: 13.4189  decode.loss_cls: 0.3408  decode.loss_mask: 0.4134  decode.loss_dice: 0.4248  decode.d0.loss_cls: 1.5083  decode.d0.loss_mask: 0.4519  decode.d0.loss_dice: 0.5070  decode.d1.loss_cls: 0.6145  decode.d1.loss_mask: 0.3835  decode.d1.loss_dice: 0.4249  decode.d2.loss_cls: 0.3389  decode.d2.loss_mask: 0.4074  decode.d2.loss_dice: 0.4308  decode.d3.loss_cls: 0.4514  decode.d3.loss_mask: 0.3735  decode.d3.loss_dice: 0.3889  decode.d4.loss_cls: 0.4548  decode.d4.loss_mask: 0.3710  decode.d4.loss_dice: 0.3930  decode.d5.loss_cls: 0.3942  decode.d5.loss_mask: 0.3959  decode.d5.loss_dice: 0.4212  decode.d6.loss_cls: 0.3659  decode.d6.loss_mask: 0.3907  decode.d6.loss_dice: 0.4084  decode.d7.loss_cls: 0.3646  decode.d7.loss_mask: 0.3924  decode.d7.loss_dice: 0.4055  decode.d8.loss_cls: 0.3527  decode.d8.loss_mask: 0.4075  decode.d8.loss_dice: 0.4412
07/31 18:19:07 - mmengine - INFO - Iter(train) [ 5750/80000]  base_lr: 9.3508e-05 lr: 9.3508e-06  eta: 9:59:41  time: 0.4841  data_time: 0.0091  memory: 5932  grad_norm: 330.3917  loss: 15.4220  decode.loss_cls: 0.5353  decode.loss_mask: 0.4785  decode.loss_dice: 0.4308  decode.d0.loss_cls: 1.3442  decode.d0.loss_mask: 0.4007  decode.d0.loss_dice: 0.4746  decode.d1.loss_cls: 0.6549  decode.d1.loss_mask: 0.3929  decode.d1.loss_dice: 0.4351  decode.d2.loss_cls: 0.6254  decode.d2.loss_mask: 0.4306  decode.d2.loss_dice: 0.4144  decode.d3.loss_cls: 0.6922  decode.d3.loss_mask: 0.4043  decode.d3.loss_dice: 0.3976  decode.d4.loss_cls: 0.6500  decode.d4.loss_mask: 0.4074  decode.d4.loss_dice: 0.4327  decode.d5.loss_cls: 0.5481  decode.d5.loss_mask: 0.4041  decode.d5.loss_dice: 0.4364  decode.d6.loss_cls: 0.5793  decode.d6.loss_mask: 0.4090  decode.d6.loss_dice: 0.4336  decode.d7.loss_cls: 0.6436  decode.d7.loss_mask: 0.4468  decode.d7.loss_dice: 0.4507  decode.d8.loss_cls: 0.6067  decode.d8.loss_mask: 0.4333  decode.d8.loss_dice: 0.4289
07/31 18:19:31 - mmengine - INFO - Iter(train) [ 5800/80000]  base_lr: 9.3452e-05 lr: 9.3452e-06  eta: 9:59:17  time: 0.4856  data_time: 0.0090  memory: 5897  grad_norm: 186.8557  loss: 11.4771  decode.loss_cls: 0.3841  decode.loss_mask: 0.2507  decode.loss_dice: 0.3084  decode.d0.loss_cls: 1.5963  decode.d0.loss_mask: 0.2456  decode.d0.loss_dice: 0.3913  decode.d1.loss_cls: 0.6132  decode.d1.loss_mask: 0.2491  decode.d1.loss_dice: 0.3420  decode.d2.loss_cls: 0.5181  decode.d2.loss_mask: 0.2325  decode.d2.loss_dice: 0.3162  decode.d3.loss_cls: 0.4584  decode.d3.loss_mask: 0.2383  decode.d3.loss_dice: 0.3077  decode.d4.loss_cls: 0.4690  decode.d4.loss_mask: 0.2589  decode.d4.loss_dice: 0.3207  decode.d5.loss_cls: 0.4637  decode.d5.loss_mask: 0.2391  decode.d5.loss_dice: 0.3069  decode.d6.loss_cls: 0.4208  decode.d6.loss_mask: 0.2673  decode.d6.loss_dice: 0.3173  decode.d7.loss_cls: 0.4230  decode.d7.loss_mask: 0.2594  decode.d7.loss_dice: 0.3107  decode.d8.loss_cls: 0.4084  decode.d8.loss_mask: 0.2555  decode.d8.loss_dice: 0.3046
07/31 18:19:55 - mmengine - INFO - Iter(train) [ 5850/80000]  base_lr: 9.3395e-05 lr: 9.3395e-06  eta: 9:58:53  time: 0.4850  data_time: 0.0090  memory: 5896  grad_norm: 224.5785  loss: 12.7885  decode.loss_cls: 0.5171  decode.loss_mask: 0.3047  decode.loss_dice: 0.3495  decode.d0.loss_cls: 1.4228  decode.d0.loss_mask: 0.2983  decode.d0.loss_dice: 0.3811  decode.d1.loss_cls: 0.5162  decode.d1.loss_mask: 0.3093  decode.d1.loss_dice: 0.3972  decode.d2.loss_cls: 0.4266  decode.d2.loss_mask: 0.3050  decode.d2.loss_dice: 0.3692  decode.d3.loss_cls: 0.4103  decode.d3.loss_mask: 0.3106  decode.d3.loss_dice: 0.3495  decode.d4.loss_cls: 0.4294  decode.d4.loss_mask: 0.3262  decode.d4.loss_dice: 0.3719  decode.d5.loss_cls: 0.4447  decode.d5.loss_mask: 0.4035  decode.d5.loss_dice: 0.3967  decode.d6.loss_cls: 0.4429  decode.d6.loss_mask: 0.4261  decode.d6.loss_dice: 0.3946  decode.d7.loss_cls: 0.4749  decode.d7.loss_mask: 0.3789  decode.d7.loss_dice: 0.3869  decode.d8.loss_cls: 0.4662  decode.d8.loss_mask: 0.3879  decode.d8.loss_dice: 0.3902
07/31 18:20:19 - mmengine - INFO - Iter(train) [ 5900/80000]  base_lr: 9.3338e-05 lr: 9.3338e-06  eta: 9:58:28  time: 0.4843  data_time: 0.0092  memory: 5933  grad_norm: 241.5615  loss: 10.8059  decode.loss_cls: 0.3246  decode.loss_mask: 0.2900  decode.loss_dice: 0.3090  decode.d0.loss_cls: 1.3861  decode.d0.loss_mask: 0.3039  decode.d0.loss_dice: 0.3160  decode.d1.loss_cls: 0.4703  decode.d1.loss_mask: 0.3034  decode.d1.loss_dice: 0.3222  decode.d2.loss_cls: 0.3966  decode.d2.loss_mask: 0.2707  decode.d2.loss_dice: 0.3136  decode.d3.loss_cls: 0.3664  decode.d3.loss_mask: 0.2812  decode.d3.loss_dice: 0.2932  decode.d4.loss_cls: 0.4021  decode.d4.loss_mask: 0.2871  decode.d4.loss_dice: 0.3125  decode.d5.loss_cls: 0.3956  decode.d5.loss_mask: 0.2752  decode.d5.loss_dice: 0.2987  decode.d6.loss_cls: 0.3947  decode.d6.loss_mask: 0.2735  decode.d6.loss_dice: 0.3123  decode.d7.loss_cls: 0.3915  decode.d7.loss_mask: 0.2778  decode.d7.loss_dice: 0.3053  decode.d8.loss_cls: 0.3423  decode.d8.loss_mask: 0.2779  decode.d8.loss_dice: 0.3124
07/31 18:20:44 - mmengine - INFO - Iter(train) [ 5950/80000]  base_lr: 9.3282e-05 lr: 9.3282e-06  eta: 9:58:05  time: 0.4832  data_time: 0.0090  memory: 5918  grad_norm: 171.2419  loss: 14.5352  decode.loss_cls: 0.6170  decode.loss_mask: 0.3264  decode.loss_dice: 0.4185  decode.d0.loss_cls: 1.4993  decode.d0.loss_mask: 0.3159  decode.d0.loss_dice: 0.4875  decode.d1.loss_cls: 0.7199  decode.d1.loss_mask: 0.3085  decode.d1.loss_dice: 0.4253  decode.d2.loss_cls: 0.7081  decode.d2.loss_mask: 0.3176  decode.d2.loss_dice: 0.4130  decode.d3.loss_cls: 0.5552  decode.d3.loss_mask: 0.3243  decode.d3.loss_dice: 0.4303  decode.d4.loss_cls: 0.5819  decode.d4.loss_mask: 0.3201  decode.d4.loss_dice: 0.4301  decode.d5.loss_cls: 0.5780  decode.d5.loss_mask: 0.3206  decode.d5.loss_dice: 0.4064  decode.d6.loss_cls: 0.5988  decode.d6.loss_mask: 0.3120  decode.d6.loss_dice: 0.4123  decode.d7.loss_cls: 0.6232  decode.d7.loss_mask: 0.3213  decode.d7.loss_dice: 0.3870  decode.d8.loss_cls: 0.6172  decode.d8.loss_mask: 0.3312  decode.d8.loss_dice: 0.4283
07/31 18:21:08 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250731_173226
07/31 18:21:08 - mmengine - INFO - Iter(train) [ 6000/80000]  base_lr: 9.3225e-05 lr: 9.3225e-06  eta: 9:57:40  time: 0.4833  data_time: 0.0090  memory: 5916  grad_norm: 303.4971  loss: 14.2410  decode.loss_cls: 0.4231  decode.loss_mask: 0.5334  decode.loss_dice: 0.4388  decode.d0.loss_cls: 1.4757  decode.d0.loss_mask: 0.5068  decode.d0.loss_dice: 0.4414  decode.d1.loss_cls: 0.6257  decode.d1.loss_mask: 0.4846  decode.d1.loss_dice: 0.4136  decode.d2.loss_cls: 0.3500  decode.d2.loss_mask: 0.4828  decode.d2.loss_dice: 0.4011  decode.d3.loss_cls: 0.3629  decode.d3.loss_mask: 0.4754  decode.d3.loss_dice: 0.4102  decode.d4.loss_cls: 0.4045  decode.d4.loss_mask: 0.4834  decode.d4.loss_dice: 0.4062  decode.d5.loss_cls: 0.3793  decode.d5.loss_mask: 0.4830  decode.d5.loss_dice: 0.3971  decode.d6.loss_cls: 0.3460  decode.d6.loss_mask: 0.4874  decode.d6.loss_dice: 0.4023  decode.d7.loss_cls: 0.3871  decode.d7.loss_mask: 0.4844  decode.d7.loss_dice: 0.3977  decode.d8.loss_cls: 0.4373  decode.d8.loss_mask: 0.5132  decode.d8.loss_dice: 0.4066
07/31 18:21:32 - mmengine - INFO - Iter(train) [ 6050/80000]  base_lr: 9.3168e-05 lr: 9.3168e-06  eta: 9:57:16  time: 0.4852  data_time: 0.0089  memory: 5918  grad_norm: 227.9516  loss: 11.7153  decode.loss_cls: 0.4886  decode.loss_mask: 0.2870  decode.loss_dice: 0.3548  decode.d0.loss_cls: 1.2379  decode.d0.loss_mask: 0.2994  decode.d0.loss_dice: 0.3899  decode.d1.loss_cls: 0.5410  decode.d1.loss_mask: 0.2902  decode.d1.loss_dice: 0.3614  decode.d2.loss_cls: 0.4279  decode.d2.loss_mask: 0.3034  decode.d2.loss_dice: 0.3692  decode.d3.loss_cls: 0.3892  decode.d3.loss_mask: 0.3033  decode.d3.loss_dice: 0.3460  decode.d4.loss_cls: 0.4685  decode.d4.loss_mask: 0.2936  decode.d4.loss_dice: 0.3535  decode.d5.loss_cls: 0.4780  decode.d5.loss_mask: 0.2936  decode.d5.loss_dice: 0.3412  decode.d6.loss_cls: 0.4320  decode.d6.loss_mask: 0.2908  decode.d6.loss_dice: 0.3421  decode.d7.loss_cls: 0.3846  decode.d7.loss_mask: 0.2861  decode.d7.loss_dice: 0.3286  decode.d8.loss_cls: 0.4435  decode.d8.loss_mask: 0.2770  decode.d8.loss_dice: 0.3128
07/31 18:21:56 - mmengine - INFO - Iter(train) [ 6100/80000]  base_lr: 9.3112e-05 lr: 9.3112e-06  eta: 9:56:51  time: 0.4829  data_time: 0.0090  memory: 5882  grad_norm: 237.3151  loss: 12.2687  decode.loss_cls: 0.3344  decode.loss_mask: 0.3744  decode.loss_dice: 0.3849  decode.d0.loss_cls: 1.2484  decode.d0.loss_mask: 0.4039  decode.d0.loss_dice: 0.4988  decode.d1.loss_cls: 0.5406  decode.d1.loss_mask: 0.3735  decode.d1.loss_dice: 0.4066  decode.d2.loss_cls: 0.3998  decode.d2.loss_mask: 0.3515  decode.d2.loss_dice: 0.3852  decode.d3.loss_cls: 0.3393  decode.d3.loss_mask: 0.3655  decode.d3.loss_dice: 0.3662  decode.d4.loss_cls: 0.3374  decode.d4.loss_mask: 0.3637  decode.d4.loss_dice: 0.3671  decode.d5.loss_cls: 0.3600  decode.d5.loss_mask: 0.3648  decode.d5.loss_dice: 0.3757  decode.d6.loss_cls: 0.3286  decode.d6.loss_mask: 0.3797  decode.d6.loss_dice: 0.3839  decode.d7.loss_cls: 0.3682  decode.d7.loss_mask: 0.3810  decode.d7.loss_dice: 0.3758  decode.d8.loss_cls: 0.3210  decode.d8.loss_mask: 0.3925  decode.d8.loss_dice: 0.3961
07/31 18:22:20 - mmengine - INFO - Iter(train) [ 6150/80000]  base_lr: 9.3055e-05 lr: 9.3055e-06  eta: 9:56:27  time: 0.4846  data_time: 0.0092  memory: 5933  grad_norm: 170.0276  loss: 13.1014  decode.loss_cls: 0.4354  decode.loss_mask: 0.3801  decode.loss_dice: 0.4270  decode.d0.loss_cls: 1.4139  decode.d0.loss_mask: 0.3835  decode.d0.loss_dice: 0.4727  decode.d1.loss_cls: 0.4885  decode.d1.loss_mask: 0.3832  decode.d1.loss_dice: 0.4407  decode.d2.loss_cls: 0.3583  decode.d2.loss_mask: 0.3886  decode.d2.loss_dice: 0.4062  decode.d3.loss_cls: 0.3678  decode.d3.loss_mask: 0.3820  decode.d3.loss_dice: 0.4106  decode.d4.loss_cls: 0.3727  decode.d4.loss_mask: 0.3816  decode.d4.loss_dice: 0.4247  decode.d5.loss_cls: 0.3979  decode.d5.loss_mask: 0.3870  decode.d5.loss_dice: 0.4131  decode.d6.loss_cls: 0.4242  decode.d6.loss_mask: 0.3825  decode.d6.loss_dice: 0.4134  decode.d7.loss_cls: 0.3923  decode.d7.loss_mask: 0.3847  decode.d7.loss_dice: 0.4105  decode.d8.loss_cls: 0.3982  decode.d8.loss_mask: 0.3706  decode.d8.loss_dice: 0.4095
07/31 18:22:45 - mmengine - INFO - Iter(train) [ 6200/80000]  base_lr: 9.2998e-05 lr: 9.2998e-06  eta: 9:56:02  time: 0.4853  data_time: 0.0092  memory: 5931  grad_norm: 293.5608  loss: 11.3238  decode.loss_cls: 0.3971  decode.loss_mask: 0.3012  decode.loss_dice: 0.3013  decode.d0.loss_cls: 1.4350  decode.d0.loss_mask: 0.3014  decode.d0.loss_dice: 0.3531  decode.d1.loss_cls: 0.5298  decode.d1.loss_mask: 0.3071  decode.d1.loss_dice: 0.3156  decode.d2.loss_cls: 0.4434  decode.d2.loss_mask: 0.3138  decode.d2.loss_dice: 0.3192  decode.d3.loss_cls: 0.4414  decode.d3.loss_mask: 0.3070  decode.d3.loss_dice: 0.3043  decode.d4.loss_cls: 0.3747  decode.d4.loss_mask: 0.3180  decode.d4.loss_dice: 0.3462  decode.d5.loss_cls: 0.3951  decode.d5.loss_mask: 0.3154  decode.d5.loss_dice: 0.3027  decode.d6.loss_cls: 0.3888  decode.d6.loss_mask: 0.3040  decode.d6.loss_dice: 0.2898  decode.d7.loss_cls: 0.3414  decode.d7.loss_mask: 0.2992  decode.d7.loss_dice: 0.2925  decode.d8.loss_cls: 0.3936  decode.d8.loss_mask: 0.2968  decode.d8.loss_dice: 0.2950
07/31 18:23:09 - mmengine - INFO - Iter(train) [ 6250/80000]  base_lr: 9.2942e-05 lr: 9.2942e-06  eta: 9:55:38  time: 0.4835  data_time: 0.0091  memory: 5916  grad_norm: 251.5796  loss: 12.6332  decode.loss_cls: 0.4883  decode.loss_mask: 0.3042  decode.loss_dice: 0.3725  decode.d0.loss_cls: 1.3532  decode.d0.loss_mask: 0.3377  decode.d0.loss_dice: 0.4419  decode.d1.loss_cls: 0.5594  decode.d1.loss_mask: 0.3034  decode.d1.loss_dice: 0.3736  decode.d2.loss_cls: 0.5382  decode.d2.loss_mask: 0.3208  decode.d2.loss_dice: 0.3723  decode.d3.loss_cls: 0.4876  decode.d3.loss_mask: 0.2657  decode.d3.loss_dice: 0.3267  decode.d4.loss_cls: 0.5238  decode.d4.loss_mask: 0.3063  decode.d4.loss_dice: 0.3405  decode.d5.loss_cls: 0.5179  decode.d5.loss_mask: 0.2863  decode.d5.loss_dice: 0.3447  decode.d6.loss_cls: 0.5613  decode.d6.loss_mask: 0.2837  decode.d6.loss_dice: 0.3428  decode.d7.loss_cls: 0.5089  decode.d7.loss_mask: 0.3078  decode.d7.loss_dice: 0.3379  decode.d8.loss_cls: 0.4369  decode.d8.loss_mask: 0.3147  decode.d8.loss_dice: 0.3741
07/31 18:23:33 - mmengine - INFO - Iter(train) [ 6300/80000]  base_lr: 9.2885e-05 lr: 9.2885e-06  eta: 9:55:13  time: 0.4841  data_time: 0.0092  memory: 5916  grad_norm: 159.3817  loss: 12.1597  decode.loss_cls: 0.4367  decode.loss_mask: 0.2767  decode.loss_dice: 0.3653  decode.d0.loss_cls: 1.3676  decode.d0.loss_mask: 0.3035  decode.d0.loss_dice: 0.4508  decode.d1.loss_cls: 0.5188  decode.d1.loss_mask: 0.2994  decode.d1.loss_dice: 0.3897  decode.d2.loss_cls: 0.4855  decode.d2.loss_mask: 0.2943  decode.d2.loss_dice: 0.3659  decode.d3.loss_cls: 0.4147  decode.d3.loss_mask: 0.2910  decode.d3.loss_dice: 0.3787  decode.d4.loss_cls: 0.4636  decode.d4.loss_mask: 0.2912  decode.d4.loss_dice: 0.3584  decode.d5.loss_cls: 0.5465  decode.d5.loss_mask: 0.2850  decode.d5.loss_dice: 0.3802  decode.d6.loss_cls: 0.4491  decode.d6.loss_mask: 0.2856  decode.d6.loss_dice: 0.3488  decode.d7.loss_cls: 0.4548  decode.d7.loss_mask: 0.2731  decode.d7.loss_dice: 0.3564  decode.d8.loss_cls: 0.4199  decode.d8.loss_mask: 0.2698  decode.d8.loss_dice: 0.3387
07/31 18:23:57 - mmengine - INFO - Iter(train) [ 6350/80000]  base_lr: 9.2828e-05 lr: 9.2828e-06  eta: 9:54:49  time: 0.4904  data_time: 0.0095  memory: 5986  grad_norm: 373.3992  loss: 12.6982  decode.loss_cls: 0.4924  decode.loss_mask: 0.3020  decode.loss_dice: 0.3838  decode.d0.loss_cls: 1.4217  decode.d0.loss_mask: 0.3302  decode.d0.loss_dice: 0.4471  decode.d1.loss_cls: 0.6793  decode.d1.loss_mask: 0.3207  decode.d1.loss_dice: 0.3794  decode.d2.loss_cls: 0.4899  decode.d2.loss_mask: 0.3192  decode.d2.loss_dice: 0.3748  decode.d3.loss_cls: 0.4621  decode.d3.loss_mask: 0.3119  decode.d3.loss_dice: 0.3898  decode.d4.loss_cls: 0.4694  decode.d4.loss_mask: 0.3125  decode.d4.loss_dice: 0.3868  decode.d5.loss_cls: 0.4695  decode.d5.loss_mask: 0.2999  decode.d5.loss_dice: 0.3699  decode.d6.loss_cls: 0.3996  decode.d6.loss_mask: 0.3027  decode.d6.loss_dice: 0.3678  decode.d7.loss_cls: 0.3995  decode.d7.loss_mask: 0.3012  decode.d7.loss_dice: 0.3702  decode.d8.loss_cls: 0.4533  decode.d8.loss_mask: 0.3039  decode.d8.loss_dice: 0.3876
07/31 18:24:21 - mmengine - INFO - Iter(train) [ 6400/80000]  base_lr: 9.2771e-05 lr: 9.2771e-06  eta: 9:54:25  time: 0.4840  data_time: 0.0092  memory: 5918  grad_norm: 197.6943  loss: 12.2170  decode.loss_cls: 0.4543  decode.loss_mask: 0.2719  decode.loss_dice: 0.3143  decode.d0.loss_cls: 1.3580  decode.d0.loss_mask: 0.3061  decode.d0.loss_dice: 0.4011  decode.d1.loss_cls: 0.5907  decode.d1.loss_mask: 0.2818  decode.d1.loss_dice: 0.3056  decode.d2.loss_cls: 0.5481  decode.d2.loss_mask: 0.2822  decode.d2.loss_dice: 0.3279  decode.d3.loss_cls: 0.5212  decode.d3.loss_mask: 0.2721  decode.d3.loss_dice: 0.3133  decode.d4.loss_cls: 0.5574  decode.d4.loss_mask: 0.2813  decode.d4.loss_dice: 0.3372  decode.d5.loss_cls: 0.5385  decode.d5.loss_mask: 0.2686  decode.d5.loss_dice: 0.3041  decode.d6.loss_cls: 0.5799  decode.d6.loss_mask: 0.2793  decode.d6.loss_dice: 0.3078  decode.d7.loss_cls: 0.5134  decode.d7.loss_mask: 0.2665  decode.d7.loss_dice: 0.3004  decode.d8.loss_cls: 0.5455  decode.d8.loss_mask: 0.2691  decode.d8.loss_dice: 0.3194
07/31 18:24:46 - mmengine - INFO - Iter(train) [ 6450/80000]  base_lr: 9.2715e-05 lr: 9.2715e-06  eta: 9:54:01  time: 0.4837  data_time: 0.0091  memory: 5916  grad_norm: 320.3922  loss: 15.0061  decode.loss_cls: 0.4925  decode.loss_mask: 0.3988  decode.loss_dice: 0.4692  decode.d0.loss_cls: 1.3131  decode.d0.loss_mask: 0.3924  decode.d0.loss_dice: 0.5391  decode.d1.loss_cls: 0.7704  decode.d1.loss_mask: 0.3667  decode.d1.loss_dice: 0.4587  decode.d2.loss_cls: 0.6337  decode.d2.loss_mask: 0.3579  decode.d2.loss_dice: 0.4281  decode.d3.loss_cls: 0.5488  decode.d3.loss_mask: 0.3653  decode.d3.loss_dice: 0.4338  decode.d4.loss_cls: 0.4962  decode.d4.loss_mask: 0.3684  decode.d4.loss_dice: 0.4541  decode.d5.loss_cls: 0.6115  decode.d5.loss_mask: 0.3891  decode.d5.loss_dice: 0.4390  decode.d6.loss_cls: 0.5674  decode.d6.loss_mask: 0.4144  decode.d6.loss_dice: 0.4576  decode.d7.loss_cls: 0.5326  decode.d7.loss_mask: 0.4083  decode.d7.loss_dice: 0.4611  decode.d8.loss_cls: 0.5829  decode.d8.loss_mask: 0.4153  decode.d8.loss_dice: 0.4399
07/31 18:25:10 - mmengine - INFO - Iter(train) [ 6500/80000]  base_lr: 9.2658e-05 lr: 9.2658e-06  eta: 9:53:36  time: 0.4843  data_time: 0.0090  memory: 5985  grad_norm: 232.5165  loss: 13.2570  decode.loss_cls: 0.4603  decode.loss_mask: 0.3401  decode.loss_dice: 0.4107  decode.d0.loss_cls: 1.4078  decode.d0.loss_mask: 0.3556  decode.d0.loss_dice: 0.4461  decode.d1.loss_cls: 0.6372  decode.d1.loss_mask: 0.3348  decode.d1.loss_dice: 0.3979  decode.d2.loss_cls: 0.4702  decode.d2.loss_mask: 0.3382  decode.d2.loss_dice: 0.4048  decode.d3.loss_cls: 0.5007  decode.d3.loss_mask: 0.3205  decode.d3.loss_dice: 0.3899  decode.d4.loss_cls: 0.4813  decode.d4.loss_mask: 0.3275  decode.d4.loss_dice: 0.3781  decode.d5.loss_cls: 0.4947  decode.d5.loss_mask: 0.3437  decode.d5.loss_dice: 0.3906  decode.d6.loss_cls: 0.4988  decode.d6.loss_mask: 0.3550  decode.d6.loss_dice: 0.3909  decode.d7.loss_cls: 0.4429  decode.d7.loss_mask: 0.3444  decode.d7.loss_dice: 0.3888  decode.d8.loss_cls: 0.4618  decode.d8.loss_mask: 0.3493  decode.d8.loss_dice: 0.3946
07/31 18:25:34 - mmengine - INFO - Iter(train) [ 6550/80000]  base_lr: 9.2601e-05 lr: 9.2601e-06  eta: 9:53:12  time: 0.4840  data_time: 0.0092  memory: 5919  grad_norm: 217.3850  loss: 10.8396  decode.loss_cls: 0.3398  decode.loss_mask: 0.2798  decode.loss_dice: 0.3002  decode.d0.loss_cls: 1.3549  decode.d0.loss_mask: 0.3282  decode.d0.loss_dice: 0.3761  decode.d1.loss_cls: 0.5057  decode.d1.loss_mask: 0.2881  decode.d1.loss_dice: 0.3143  decode.d2.loss_cls: 0.3986  decode.d2.loss_mask: 0.2792  decode.d2.loss_dice: 0.3089  decode.d3.loss_cls: 0.4021  decode.d3.loss_mask: 0.2773  decode.d3.loss_dice: 0.2988  decode.d4.loss_cls: 0.4092  decode.d4.loss_mask: 0.2655  decode.d4.loss_dice: 0.3007  decode.d5.loss_cls: 0.3765  decode.d5.loss_mask: 0.2694  decode.d5.loss_dice: 0.2982  decode.d6.loss_cls: 0.3309  decode.d6.loss_mask: 0.2890  decode.d6.loss_dice: 0.3263  decode.d7.loss_cls: 0.3900  decode.d7.loss_mask: 0.2664  decode.d7.loss_dice: 0.3045  decode.d8.loss_cls: 0.3581  decode.d8.loss_mask: 0.2935  decode.d8.loss_dice: 0.3094
07/31 18:25:58 - mmengine - INFO - Iter(train) [ 6600/80000]  base_lr: 9.2544e-05 lr: 9.2544e-06  eta: 9:52:47  time: 0.4838  data_time: 0.0091  memory: 5971  grad_norm: 187.1709  loss: 12.2427  decode.loss_cls: 0.3870  decode.loss_mask: 0.3123  decode.loss_dice: 0.3408  decode.d0.loss_cls: 1.3219  decode.d0.loss_mask: 0.3167  decode.d0.loss_dice: 0.4240  decode.d1.loss_cls: 0.5363  decode.d1.loss_mask: 0.3298  decode.d1.loss_dice: 0.4030  decode.d2.loss_cls: 0.4871  decode.d2.loss_mask: 0.3196  decode.d2.loss_dice: 0.3912  decode.d3.loss_cls: 0.4039  decode.d3.loss_mask: 0.3140  decode.d3.loss_dice: 0.4002  decode.d4.loss_cls: 0.4205  decode.d4.loss_mask: 0.3153  decode.d4.loss_dice: 0.3819  decode.d5.loss_cls: 0.4323  decode.d5.loss_mask: 0.3191  decode.d5.loss_dice: 0.3586  decode.d6.loss_cls: 0.4145  decode.d6.loss_mask: 0.3147  decode.d6.loss_dice: 0.3579  decode.d7.loss_cls: 0.4536  decode.d7.loss_mask: 0.3156  decode.d7.loss_dice: 0.3687  decode.d8.loss_cls: 0.4188  decode.d8.loss_mask: 0.3159  decode.d8.loss_dice: 0.3674
07/31 18:26:23 - mmengine - INFO - Iter(train) [ 6650/80000]  base_lr: 9.2488e-05 lr: 9.2488e-06  eta: 9:52:23  time: 0.4838  data_time: 0.0092  memory: 5881  grad_norm: 96.2940  loss: 10.1395  decode.loss_cls: 0.2662  decode.loss_mask: 0.2971  decode.loss_dice: 0.3104  decode.d0.loss_cls: 1.1058  decode.d0.loss_mask: 0.3074  decode.d0.loss_dice: 0.3494  decode.d1.loss_cls: 0.4946  decode.d1.loss_mask: 0.3099  decode.d1.loss_dice: 0.3221  decode.d2.loss_cls: 0.3630  decode.d2.loss_mask: 0.3013  decode.d2.loss_dice: 0.3125  decode.d3.loss_cls: 0.2637  decode.d3.loss_mask: 0.3047  decode.d3.loss_dice: 0.3490  decode.d4.loss_cls: 0.3022  decode.d4.loss_mask: 0.2986  decode.d4.loss_dice: 0.3300  decode.d5.loss_cls: 0.2620  decode.d5.loss_mask: 0.2987  decode.d5.loss_dice: 0.3437  decode.d6.loss_cls: 0.2533  decode.d6.loss_mask: 0.2969  decode.d6.loss_dice: 0.3283  decode.d7.loss_cls: 0.2845  decode.d7.loss_mask: 0.2961  decode.d7.loss_dice: 0.3188  decode.d8.loss_cls: 0.2585  decode.d8.loss_mask: 0.2957  decode.d8.loss_dice: 0.3151
07/31 18:26:47 - mmengine - INFO - Iter(train) [ 6700/80000]  base_lr: 9.2431e-05 lr: 9.2431e-06  eta: 9:51:58  time: 0.4839  data_time: 0.0091  memory: 5918  grad_norm: 144.9100  loss: 8.8823  decode.loss_cls: 0.1880  decode.loss_mask: 0.2957  decode.loss_dice: 0.2817  decode.d0.loss_cls: 1.2984  decode.d0.loss_mask: 0.3176  decode.d0.loss_dice: 0.3280  decode.d1.loss_cls: 0.2497  decode.d1.loss_mask: 0.3016  decode.d1.loss_dice: 0.2966  decode.d2.loss_cls: 0.2337  decode.d2.loss_mask: 0.2932  decode.d2.loss_dice: 0.2760  decode.d3.loss_cls: 0.2027  decode.d3.loss_mask: 0.2881  decode.d3.loss_dice: 0.2733  decode.d4.loss_cls: 0.1934  decode.d4.loss_mask: 0.2920  decode.d4.loss_dice: 0.2730  decode.d5.loss_cls: 0.1880  decode.d5.loss_mask: 0.2956  decode.d5.loss_dice: 0.2848  decode.d6.loss_cls: 0.1656  decode.d6.loss_mask: 0.2878  decode.d6.loss_dice: 0.2737  decode.d7.loss_cls: 0.1756  decode.d7.loss_mask: 0.2910  decode.d7.loss_dice: 0.2717  decode.d8.loss_cls: 0.1945  decode.d8.loss_mask: 0.2920  decode.d8.loss_dice: 0.2794
07/31 18:27:11 - mmengine - INFO - Iter(train) [ 6750/80000]  base_lr: 9.2374e-05 lr: 9.2374e-06  eta: 9:51:36  time: 0.4840  data_time: 0.0093  memory: 5971  grad_norm: 171.5670  loss: 11.5168  decode.loss_cls: 0.3916  decode.loss_mask: 0.3106  decode.loss_dice: 0.3793  decode.d0.loss_cls: 1.1283  decode.d0.loss_mask: 0.3098  decode.d0.loss_dice: 0.4110  decode.d1.loss_cls: 0.4792  decode.d1.loss_mask: 0.3127  decode.d1.loss_dice: 0.3711  decode.d2.loss_cls: 0.4044  decode.d2.loss_mask: 0.3226  decode.d2.loss_dice: 0.3937  decode.d3.loss_cls: 0.3465  decode.d3.loss_mask: 0.3243  decode.d3.loss_dice: 0.3748  decode.d4.loss_cls: 0.3276  decode.d4.loss_mask: 0.3165  decode.d4.loss_dice: 0.4079  decode.d5.loss_cls: 0.3034  decode.d5.loss_mask: 0.3171  decode.d5.loss_dice: 0.3721  decode.d6.loss_cls: 0.3295  decode.d6.loss_mask: 0.3109  decode.d6.loss_dice: 0.3761  decode.d7.loss_cls: 0.3644  decode.d7.loss_mask: 0.3192  decode.d7.loss_dice: 0.3777  decode.d8.loss_cls: 0.4394  decode.d8.loss_mask: 0.3221  decode.d8.loss_dice: 0.3729
07/31 18:27:35 - mmengine - INFO - Iter(train) [ 6800/80000]  base_lr: 9.2317e-05 lr: 9.2317e-06  eta: 9:51:11  time: 0.4844  data_time: 0.0091  memory: 5918  grad_norm: 132.5794  loss: 11.7021  decode.loss_cls: 0.3459  decode.loss_mask: 0.3221  decode.loss_dice: 0.3551  decode.d0.loss_cls: 1.4067  decode.d0.loss_mask: 0.2824  decode.d0.loss_dice: 0.3498  decode.d1.loss_cls: 0.4957  decode.d1.loss_mask: 0.3141  decode.d1.loss_dice: 0.3328  decode.d2.loss_cls: 0.4381  decode.d2.loss_mask: 0.3030  decode.d2.loss_dice: 0.3386  decode.d3.loss_cls: 0.4169  decode.d3.loss_mask: 0.3115  decode.d3.loss_dice: 0.3435  decode.d4.loss_cls: 0.4003  decode.d4.loss_mask: 0.3141  decode.d4.loss_dice: 0.3455  decode.d5.loss_cls: 0.4236  decode.d5.loss_mask: 0.3049  decode.d5.loss_dice: 0.3409  decode.d6.loss_cls: 0.4470  decode.d6.loss_mask: 0.3113  decode.d6.loss_dice: 0.3513  decode.d7.loss_cls: 0.4288  decode.d7.loss_mask: 0.2903  decode.d7.loss_dice: 0.3389  decode.d8.loss_cls: 0.4205  decode.d8.loss_mask: 0.2967  decode.d8.loss_dice: 0.3316
07/31 18:28:00 - mmengine - INFO - Iter(train) [ 6850/80000]  base_lr: 9.2261e-05 lr: 9.2261e-06  eta: 9:50:47  time: 0.4850  data_time: 0.0093  memory: 5916  grad_norm: 142.3306  loss: 10.5799  decode.loss_cls: 0.2911  decode.loss_mask: 0.2524  decode.loss_dice: 0.3500  decode.d0.loss_cls: 1.3052  decode.d0.loss_mask: 0.2956  decode.d0.loss_dice: 0.4027  decode.d1.loss_cls: 0.4190  decode.d1.loss_mask: 0.2612  decode.d1.loss_dice: 0.3433  decode.d2.loss_cls: 0.3067  decode.d2.loss_mask: 0.2531  decode.d2.loss_dice: 0.3430  decode.d3.loss_cls: 0.3196  decode.d3.loss_mask: 0.2810  decode.d3.loss_dice: 0.3592  decode.d4.loss_cls: 0.3416  decode.d4.loss_mask: 0.3025  decode.d4.loss_dice: 0.3477  decode.d5.loss_cls: 0.3705  decode.d5.loss_mask: 0.2680  decode.d5.loss_dice: 0.3446  decode.d6.loss_cls: 0.3570  decode.d6.loss_mask: 0.2583  decode.d6.loss_dice: 0.3382  decode.d7.loss_cls: 0.3680  decode.d7.loss_mask: 0.2527  decode.d7.loss_dice: 0.3300  decode.d8.loss_cls: 0.2931  decode.d8.loss_mask: 0.2587  decode.d8.loss_dice: 0.3658
07/31 18:28:24 - mmengine - INFO - Iter(train) [ 6900/80000]  base_lr: 9.2204e-05 lr: 9.2204e-06  eta: 9:50:22  time: 0.4836  data_time: 0.0091  memory: 5898  grad_norm: 245.2688  loss: 10.8385  decode.loss_cls: 0.2516  decode.loss_mask: 0.3431  decode.loss_dice: 0.3457  decode.d0.loss_cls: 1.1035  decode.d0.loss_mask: 0.3635  decode.d0.loss_dice: 0.3916  decode.d1.loss_cls: 0.3903  decode.d1.loss_mask: 0.3629  decode.d1.loss_dice: 0.3853  decode.d2.loss_cls: 0.3895  decode.d2.loss_mask: 0.3380  decode.d2.loss_dice: 0.3614  decode.d3.loss_cls: 0.2675  decode.d3.loss_mask: 0.3356  decode.d3.loss_dice: 0.3448  decode.d4.loss_cls: 0.2847  decode.d4.loss_mask: 0.3418  decode.d4.loss_dice: 0.3433  decode.d5.loss_cls: 0.2660  decode.d5.loss_mask: 0.3402  decode.d5.loss_dice: 0.3343  decode.d6.loss_cls: 0.3024  decode.d6.loss_mask: 0.3483  decode.d6.loss_dice: 0.3382  decode.d7.loss_cls: 0.3088  decode.d7.loss_mask: 0.3420  decode.d7.loss_dice: 0.3384  decode.d8.loss_cls: 0.2649  decode.d8.loss_mask: 0.3509  decode.d8.loss_dice: 0.3601
07/31 18:28:48 - mmengine - INFO - Iter(train) [ 6950/80000]  base_lr: 9.2147e-05 lr: 9.2147e-06  eta: 9:49:57  time: 0.4829  data_time: 0.0091  memory: 5918  grad_norm: 264.4473  loss: 15.1626  decode.loss_cls: 0.4140  decode.loss_mask: 0.4602  decode.loss_dice: 0.5000  decode.d0.loss_cls: 1.4436  decode.d0.loss_mask: 0.4917  decode.d0.loss_dice: 0.5430  decode.d1.loss_cls: 0.6493  decode.d1.loss_mask: 0.4465  decode.d1.loss_dice: 0.5040  decode.d2.loss_cls: 0.5534  decode.d2.loss_mask: 0.4363  decode.d2.loss_dice: 0.4794  decode.d3.loss_cls: 0.5743  decode.d3.loss_mask: 0.4478  decode.d3.loss_dice: 0.4697  decode.d4.loss_cls: 0.4905  decode.d4.loss_mask: 0.4441  decode.d4.loss_dice: 0.4480  decode.d5.loss_cls: 0.4575  decode.d5.loss_mask: 0.4636  decode.d5.loss_dice: 0.4319  decode.d6.loss_cls: 0.4341  decode.d6.loss_mask: 0.4556  decode.d6.loss_dice: 0.4365  decode.d7.loss_cls: 0.3859  decode.d7.loss_mask: 0.4558  decode.d7.loss_dice: 0.4718  decode.d8.loss_cls: 0.4339  decode.d8.loss_mask: 0.4492  decode.d8.loss_dice: 0.4908
07/31 18:29:12 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250731_173226
07/31 18:29:12 - mmengine - INFO - Iter(train) [ 7000/80000]  base_lr: 9.2090e-05 lr: 9.2090e-06  eta: 9:49:33  time: 0.4834  data_time: 0.0093  memory: 5896  grad_norm: 212.3563  loss: 13.1680  decode.loss_cls: 0.4868  decode.loss_mask: 0.4259  decode.loss_dice: 0.3928  decode.d0.loss_cls: 1.0642  decode.d0.loss_mask: 0.4398  decode.d0.loss_dice: 0.4166  decode.d1.loss_cls: 0.4497  decode.d1.loss_mask: 0.4516  decode.d1.loss_dice: 0.4123  decode.d2.loss_cls: 0.4437  decode.d2.loss_mask: 0.4305  decode.d2.loss_dice: 0.3799  decode.d3.loss_cls: 0.4484  decode.d3.loss_mask: 0.4153  decode.d3.loss_dice: 0.3423  decode.d4.loss_cls: 0.4067  decode.d4.loss_mask: 0.4158  decode.d4.loss_dice: 0.3533  decode.d5.loss_cls: 0.3913  decode.d5.loss_mask: 0.4330  decode.d5.loss_dice: 0.3967  decode.d6.loss_cls: 0.3869  decode.d6.loss_mask: 0.4234  decode.d6.loss_dice: 0.3983  decode.d7.loss_cls: 0.4631  decode.d7.loss_mask: 0.4286  decode.d7.loss_dice: 0.3973  decode.d8.loss_cls: 0.4268  decode.d8.loss_mask: 0.4380  decode.d8.loss_dice: 0.4088
07/31 18:29:36 - mmengine - INFO - Iter(train) [ 7050/80000]  base_lr: 9.2034e-05 lr: 9.2034e-06  eta: 9:49:08  time: 0.4836  data_time: 0.0090  memory: 5896  grad_norm: 160.0002  loss: 9.2274  decode.loss_cls: 0.2829  decode.loss_mask: 0.2416  decode.loss_dice: 0.3020  decode.d0.loss_cls: 1.1730  decode.d0.loss_mask: 0.2493  decode.d0.loss_dice: 0.3443  decode.d1.loss_cls: 0.3824  decode.d1.loss_mask: 0.2508  decode.d1.loss_dice: 0.3447  decode.d2.loss_cls: 0.2543  decode.d2.loss_mask: 0.2432  decode.d2.loss_dice: 0.3162  decode.d3.loss_cls: 0.2406  decode.d3.loss_mask: 0.2416  decode.d3.loss_dice: 0.2942  decode.d4.loss_cls: 0.2543  decode.d4.loss_mask: 0.2426  decode.d4.loss_dice: 0.3029  decode.d5.loss_cls: 0.2471  decode.d5.loss_mask: 0.2458  decode.d5.loss_dice: 0.3229  decode.d6.loss_cls: 0.2618  decode.d6.loss_mask: 0.2410  decode.d6.loss_dice: 0.3092  decode.d7.loss_cls: 0.2543  decode.d7.loss_mask: 0.2397  decode.d7.loss_dice: 0.3102  decode.d8.loss_cls: 0.2807  decode.d8.loss_mask: 0.2402  decode.d8.loss_dice: 0.3136
07/31 18:30:01 - mmengine - INFO - Iter(train) [ 7100/80000]  base_lr: 9.1977e-05 lr: 9.1977e-06  eta: 9:48:44  time: 0.4838  data_time: 0.0092  memory: 5920  grad_norm: 272.0059  loss: 13.5900  decode.loss_cls: 0.4328  decode.loss_mask: 0.4202  decode.loss_dice: 0.4454  decode.d0.loss_cls: 1.1057  decode.d0.loss_mask: 0.4593  decode.d0.loss_dice: 0.4797  decode.d1.loss_cls: 0.5148  decode.d1.loss_mask: 0.4019  decode.d1.loss_dice: 0.4536  decode.d2.loss_cls: 0.4560  decode.d2.loss_mask: 0.3980  decode.d2.loss_dice: 0.4312  decode.d3.loss_cls: 0.3924  decode.d3.loss_mask: 0.3911  decode.d3.loss_dice: 0.4094  decode.d4.loss_cls: 0.4247  decode.d4.loss_mask: 0.3837  decode.d4.loss_dice: 0.3998  decode.d5.loss_cls: 0.5398  decode.d5.loss_mask: 0.3901  decode.d5.loss_dice: 0.4032  decode.d6.loss_cls: 0.3969  decode.d6.loss_mask: 0.4112  decode.d6.loss_dice: 0.4075  decode.d7.loss_cls: 0.4557  decode.d7.loss_mask: 0.4386  decode.d7.loss_dice: 0.4251  decode.d8.loss_cls: 0.4697  decode.d8.loss_mask: 0.4166  decode.d8.loss_dice: 0.4360
07/31 18:30:25 - mmengine - INFO - Iter(train) [ 7150/80000]  base_lr: 9.1920e-05 lr: 9.1920e-06  eta: 9:48:19  time: 0.4835  data_time: 0.0092  memory: 5896  grad_norm: 205.5517  loss: 8.7408  decode.loss_cls: 0.2325  decode.loss_mask: 0.2524  decode.loss_dice: 0.2780  decode.d0.loss_cls: 1.1807  decode.d0.loss_mask: 0.2802  decode.d0.loss_dice: 0.3782  decode.d1.loss_cls: 0.2906  decode.d1.loss_mask: 0.2508  decode.d1.loss_dice: 0.2903  decode.d2.loss_cls: 0.2459  decode.d2.loss_mask: 0.2475  decode.d2.loss_dice: 0.2886  decode.d3.loss_cls: 0.2411  decode.d3.loss_mask: 0.2418  decode.d3.loss_dice: 0.2722  decode.d4.loss_cls: 0.2366  decode.d4.loss_mask: 0.2496  decode.d4.loss_dice: 0.2954  decode.d5.loss_cls: 0.2107  decode.d5.loss_mask: 0.2491  decode.d5.loss_dice: 0.2758  decode.d6.loss_cls: 0.2018  decode.d6.loss_mask: 0.2486  decode.d6.loss_dice: 0.2901  decode.d7.loss_cls: 0.2174  decode.d7.loss_mask: 0.2489  decode.d7.loss_dice: 0.2763  decode.d8.loss_cls: 0.2173  decode.d8.loss_mask: 0.2603  decode.d8.loss_dice: 0.2920
07/31 18:30:49 - mmengine - INFO - Iter(train) [ 7200/80000]  base_lr: 9.1863e-05 lr: 9.1863e-06  eta: 9:47:54  time: 0.4833  data_time: 0.0091  memory: 5898  grad_norm: 205.5093  loss: 11.4675  decode.loss_cls: 0.4129  decode.loss_mask: 0.3072  decode.loss_dice: 0.3295  decode.d0.loss_cls: 1.3518  decode.d0.loss_mask: 0.3709  decode.d0.loss_dice: 0.4209  decode.d1.loss_cls: 0.4459  decode.d1.loss_mask: 0.3366  decode.d1.loss_dice: 0.3383  decode.d2.loss_cls: 0.3656  decode.d2.loss_mask: 0.3144  decode.d2.loss_dice: 0.3283  decode.d3.loss_cls: 0.3636  decode.d3.loss_mask: 0.3031  decode.d3.loss_dice: 0.3166  decode.d4.loss_cls: 0.3672  decode.d4.loss_mask: 0.3157  decode.d4.loss_dice: 0.3159  decode.d5.loss_cls: 0.3965  decode.d5.loss_mask: 0.3178  decode.d5.loss_dice: 0.3231  decode.d6.loss_cls: 0.3324  decode.d6.loss_mask: 0.3105  decode.d6.loss_dice: 0.3200  decode.d7.loss_cls: 0.4128  decode.d7.loss_mask: 0.3256  decode.d7.loss_dice: 0.3334  decode.d8.loss_cls: 0.4392  decode.d8.loss_mask: 0.3231  decode.d8.loss_dice: 0.3287
07/31 18:31:13 - mmengine - INFO - Iter(train) [ 7250/80000]  base_lr: 9.1807e-05 lr: 9.1807e-06  eta: 9:47:30  time: 0.4832  data_time: 0.0092  memory: 5933  grad_norm: 423.2264  loss: 12.8350  decode.loss_cls: 0.3441  decode.loss_mask: 0.3966  decode.loss_dice: 0.3770  decode.d0.loss_cls: 1.1753  decode.d0.loss_mask: 0.4852  decode.d0.loss_dice: 0.4409  decode.d1.loss_cls: 0.5847  decode.d1.loss_mask: 0.3815  decode.d1.loss_dice: 0.3952  decode.d2.loss_cls: 0.5323  decode.d2.loss_mask: 0.3885  decode.d2.loss_dice: 0.3862  decode.d3.loss_cls: 0.3103  decode.d3.loss_mask: 0.4444  decode.d3.loss_dice: 0.3921  decode.d4.loss_cls: 0.3352  decode.d4.loss_mask: 0.4398  decode.d4.loss_dice: 0.4024  decode.d5.loss_cls: 0.3371  decode.d5.loss_mask: 0.4517  decode.d5.loss_dice: 0.4179  decode.d6.loss_cls: 0.3670  decode.d6.loss_mask: 0.3991  decode.d6.loss_dice: 0.3783  decode.d7.loss_cls: 0.3258  decode.d7.loss_mask: 0.3899  decode.d7.loss_dice: 0.3722  decode.d8.loss_cls: 0.3755  decode.d8.loss_mask: 0.4161  decode.d8.loss_dice: 0.3926
07/31 18:31:37 - mmengine - INFO - Iter(train) [ 7300/80000]  base_lr: 9.1750e-05 lr: 9.1750e-06  eta: 9:47:05  time: 0.4838  data_time: 0.0091  memory: 5933  grad_norm: 299.0064  loss: 13.5990  decode.loss_cls: 0.4708  decode.loss_mask: 0.3747  decode.loss_dice: 0.4710  decode.d0.loss_cls: 1.2980  decode.d0.loss_mask: 0.4017  decode.d0.loss_dice: 0.5016  decode.d1.loss_cls: 0.5832  decode.d1.loss_mask: 0.3366  decode.d1.loss_dice: 0.4342  decode.d2.loss_cls: 0.5061  decode.d2.loss_mask: 0.3464  decode.d2.loss_dice: 0.4641  decode.d3.loss_cls: 0.4525  decode.d3.loss_mask: 0.3301  decode.d3.loss_dice: 0.4295  decode.d4.loss_cls: 0.4232  decode.d4.loss_mask: 0.3199  decode.d4.loss_dice: 0.4055  decode.d5.loss_cls: 0.4331  decode.d5.loss_mask: 0.3201  decode.d5.loss_dice: 0.4298  decode.d6.loss_cls: 0.4040  decode.d6.loss_mask: 0.3585  decode.d6.loss_dice: 0.4701  decode.d7.loss_cls: 0.4866  decode.d7.loss_mask: 0.3550  decode.d7.loss_dice: 0.4733  decode.d8.loss_cls: 0.4970  decode.d8.loss_mask: 0.3653  decode.d8.loss_dice: 0.4570
07/31 18:32:02 - mmengine - INFO - Iter(train) [ 7350/80000]  base_lr: 9.1693e-05 lr: 9.1693e-06  eta: 9:46:42  time: 0.4837  data_time: 0.0093  memory: 5920  grad_norm: 170.7013  loss: 10.7562  decode.loss_cls: 0.2964  decode.loss_mask: 0.2867  decode.loss_dice: 0.3298  decode.d0.loss_cls: 1.3058  decode.d0.loss_mask: 0.3118  decode.d0.loss_dice: 0.3888  decode.d1.loss_cls: 0.4784  decode.d1.loss_mask: 0.2978  decode.d1.loss_dice: 0.3522  decode.d2.loss_cls: 0.3799  decode.d2.loss_mask: 0.2907  decode.d2.loss_dice: 0.3653  decode.d3.loss_cls: 0.3988  decode.d3.loss_mask: 0.2750  decode.d3.loss_dice: 0.3121  decode.d4.loss_cls: 0.3606  decode.d4.loss_mask: 0.2742  decode.d4.loss_dice: 0.2973  decode.d5.loss_cls: 0.3574  decode.d5.loss_mask: 0.2882  decode.d5.loss_dice: 0.3156  decode.d6.loss_cls: 0.3425  decode.d6.loss_mask: 0.2756  decode.d6.loss_dice: 0.2996  decode.d7.loss_cls: 0.3256  decode.d7.loss_mask: 0.2790  decode.d7.loss_dice: 0.3091  decode.d8.loss_cls: 0.3470  decode.d8.loss_mask: 0.2939  decode.d8.loss_dice: 0.3210
07/31 18:32:26 - mmengine - INFO - Iter(train) [ 7400/80000]  base_lr: 9.1636e-05 lr: 9.1636e-06  eta: 9:46:17  time: 0.4829  data_time: 0.0092  memory: 5916  grad_norm: 199.9089  loss: 11.4845  decode.loss_cls: 0.2863  decode.loss_mask: 0.4790  decode.loss_dice: 0.3294  decode.d0.loss_cls: 1.0314  decode.d0.loss_mask: 0.4482  decode.d0.loss_dice: 0.3678  decode.d1.loss_cls: 0.4112  decode.d1.loss_mask: 0.4204  decode.d1.loss_dice: 0.3109  decode.d2.loss_cls: 0.3609  decode.d2.loss_mask: 0.4101  decode.d2.loss_dice: 0.2822  decode.d3.loss_cls: 0.3624  decode.d3.loss_mask: 0.4015  decode.d3.loss_dice: 0.2830  decode.d4.loss_cls: 0.2911  decode.d4.loss_mask: 0.4674  decode.d4.loss_dice: 0.3125  decode.d5.loss_cls: 0.3675  decode.d5.loss_mask: 0.4030  decode.d5.loss_dice: 0.2805  decode.d6.loss_cls: 0.2656  decode.d6.loss_mask: 0.5006  decode.d6.loss_dice: 0.3122  decode.d7.loss_cls: 0.3547  decode.d7.loss_mask: 0.3971  decode.d7.loss_dice: 0.2893  decode.d8.loss_cls: 0.2987  decode.d8.loss_mask: 0.4486  decode.d8.loss_dice: 0.3107
07/31 18:32:50 - mmengine - INFO - Iter(train) [ 7450/80000]  base_lr: 9.1579e-05 lr: 9.1579e-06  eta: 9:45:53  time: 0.4827  data_time: 0.0093  memory: 5918  grad_norm: 229.3484  loss: 12.9653  decode.loss_cls: 0.4999  decode.loss_mask: 0.4087  decode.loss_dice: 0.3586  decode.d0.loss_cls: 1.2424  decode.d0.loss_mask: 0.4056  decode.d0.loss_dice: 0.3903  decode.d1.loss_cls: 0.6080  decode.d1.loss_mask: 0.3835  decode.d1.loss_dice: 0.3729  decode.d2.loss_cls: 0.4800  decode.d2.loss_mask: 0.3952  decode.d2.loss_dice: 0.3715  decode.d3.loss_cls: 0.4514  decode.d3.loss_mask: 0.4063  decode.d3.loss_dice: 0.3667  decode.d4.loss_cls: 0.4354  decode.d4.loss_mask: 0.3945  decode.d4.loss_dice: 0.3653  decode.d5.loss_cls: 0.3802  decode.d5.loss_mask: 0.4113  decode.d5.loss_dice: 0.3618  decode.d6.loss_cls: 0.3598  decode.d6.loss_mask: 0.4287  decode.d6.loss_dice: 0.3556  decode.d7.loss_cls: 0.4140  decode.d7.loss_mask: 0.3841  decode.d7.loss_dice: 0.3684  decode.d8.loss_cls: 0.4324  decode.d8.loss_mask: 0.3913  decode.d8.loss_dice: 0.3415
07/31 18:33:14 - mmengine - INFO - Iter(train) [ 7500/80000]  base_lr: 9.1523e-05 lr: 9.1523e-06  eta: 9:45:28  time: 0.4835  data_time: 0.0093  memory: 5918  grad_norm: 140.3468  loss: 10.9463  decode.loss_cls: 0.3754  decode.loss_mask: 0.2764  decode.loss_dice: 0.2997  decode.d0.loss_cls: 1.3831  decode.d0.loss_mask: 0.2835  decode.d0.loss_dice: 0.3426  decode.d1.loss_cls: 0.5503  decode.d1.loss_mask: 0.2828  decode.d1.loss_dice: 0.3059  decode.d2.loss_cls: 0.4272  decode.d2.loss_mask: 0.2810  decode.d2.loss_dice: 0.2757  decode.d3.loss_cls: 0.4245  decode.d3.loss_mask: 0.2876  decode.d3.loss_dice: 0.2842  decode.d4.loss_cls: 0.3980  decode.d4.loss_mask: 0.2878  decode.d4.loss_dice: 0.3054  decode.d5.loss_cls: 0.3805  decode.d5.loss_mask: 0.2822  decode.d5.loss_dice: 0.2974  decode.d6.loss_cls: 0.3865  decode.d6.loss_mask: 0.2905  decode.d6.loss_dice: 0.3270  decode.d7.loss_cls: 0.3944  decode.d7.loss_mask: 0.2821  decode.d7.loss_dice: 0.2896  decode.d8.loss_cls: 0.3735  decode.d8.loss_mask: 0.2804  decode.d8.loss_dice: 0.2911
07/31 18:33:38 - mmengine - INFO - Iter(train) [ 7550/80000]  base_lr: 9.1466e-05 lr: 9.1466e-06  eta: 9:45:04  time: 0.4845  data_time: 0.0092  memory: 5883  grad_norm: 149.4608  loss: 9.8554  decode.loss_cls: 0.3424  decode.loss_mask: 0.2363  decode.loss_dice: 0.3028  decode.d0.loss_cls: 1.1437  decode.d0.loss_mask: 0.2434  decode.d0.loss_dice: 0.3504  decode.d1.loss_cls: 0.5449  decode.d1.loss_mask: 0.2367  decode.d1.loss_dice: 0.2973  decode.d2.loss_cls: 0.3828  decode.d2.loss_mask: 0.2354  decode.d2.loss_dice: 0.2843  decode.d3.loss_cls: 0.3233  decode.d3.loss_mask: 0.2346  decode.d3.loss_dice: 0.3075  decode.d4.loss_cls: 0.3173  decode.d4.loss_mask: 0.2363  decode.d4.loss_dice: 0.3125  decode.d5.loss_cls: 0.3028  decode.d5.loss_mask: 0.2393  decode.d5.loss_dice: 0.3207  decode.d6.loss_cls: 0.3362  decode.d6.loss_mask: 0.2348  decode.d6.loss_dice: 0.2995  decode.d7.loss_cls: 0.3293  decode.d7.loss_mask: 0.2347  decode.d7.loss_dice: 0.2984  decode.d8.loss_cls: 0.3504  decode.d8.loss_mask: 0.2383  decode.d8.loss_dice: 0.3391
07/31 18:34:03 - mmengine - INFO - Iter(train) [ 7600/80000]  base_lr: 9.1409e-05 lr: 9.1409e-06  eta: 9:44:40  time: 0.4852  data_time: 0.0092  memory: 5916  grad_norm: 188.3200  loss: 11.2991  decode.loss_cls: 0.3526  decode.loss_mask: 0.2787  decode.loss_dice: 0.3381  decode.d0.loss_cls: 1.3678  decode.d0.loss_mask: 0.3076  decode.d0.loss_dice: 0.3905  decode.d1.loss_cls: 0.4864  decode.d1.loss_mask: 0.2823  decode.d1.loss_dice: 0.3512  decode.d2.loss_cls: 0.3812  decode.d2.loss_mask: 0.2956  decode.d2.loss_dice: 0.3657  decode.d3.loss_cls: 0.3337  decode.d3.loss_mask: 0.2734  decode.d3.loss_dice: 0.3302  decode.d4.loss_cls: 0.3721  decode.d4.loss_mask: 0.2862  decode.d4.loss_dice: 0.3065  decode.d5.loss_cls: 0.4283  decode.d5.loss_mask: 0.2862  decode.d5.loss_dice: 0.3251  decode.d6.loss_cls: 0.3997  decode.d6.loss_mask: 0.2918  decode.d6.loss_dice: 0.3760  decode.d7.loss_cls: 0.4423  decode.d7.loss_mask: 0.3180  decode.d7.loss_dice: 0.3481  decode.d8.loss_cls: 0.4010  decode.d8.loss_mask: 0.2732  decode.d8.loss_dice: 0.3097
07/31 18:34:27 - mmengine - INFO - Iter(train) [ 7650/80000]  base_lr: 9.1352e-05 lr: 9.1352e-06  eta: 9:44:15  time: 0.4837  data_time: 0.0092  memory: 5916  grad_norm: 142.0091  loss: 9.7102  decode.loss_cls: 0.2635  decode.loss_mask: 0.3152  decode.loss_dice: 0.3151  decode.d0.loss_cls: 0.9854  decode.d0.loss_mask: 0.3322  decode.d0.loss_dice: 0.4143  decode.d1.loss_cls: 0.4258  decode.d1.loss_mask: 0.3122  decode.d1.loss_dice: 0.3399  decode.d2.loss_cls: 0.2738  decode.d2.loss_mask: 0.3215  decode.d2.loss_dice: 0.3333  decode.d3.loss_cls: 0.2253  decode.d3.loss_mask: 0.3053  decode.d3.loss_dice: 0.3003  decode.d4.loss_cls: 0.2135  decode.d4.loss_mask: 0.3124  decode.d4.loss_dice: 0.3048  decode.d5.loss_cls: 0.2148  decode.d5.loss_mask: 0.3072  decode.d5.loss_dice: 0.3114  decode.d6.loss_cls: 0.2226  decode.d6.loss_mask: 0.3068  decode.d6.loss_dice: 0.3012  decode.d7.loss_cls: 0.2302  decode.d7.loss_mask: 0.3102  decode.d7.loss_dice: 0.3201  decode.d8.loss_cls: 0.2499  decode.d8.loss_mask: 0.3123  decode.d8.loss_dice: 0.3300
07/31 18:34:51 - mmengine - INFO - Iter(train) [ 7700/80000]  base_lr: 9.1295e-05 lr: 9.1295e-06  eta: 9:43:51  time: 0.4846  data_time: 0.0093  memory: 5918  grad_norm: 166.3563  loss: 10.4131  decode.loss_cls: 0.3067  decode.loss_mask: 0.2322  decode.loss_dice: 0.3299  decode.d0.loss_cls: 1.2174  decode.d0.loss_mask: 0.2702  decode.d0.loss_dice: 0.4339  decode.d1.loss_cls: 0.4682  decode.d1.loss_mask: 0.2615  decode.d1.loss_dice: 0.3510  decode.d2.loss_cls: 0.4128  decode.d2.loss_mask: 0.2518  decode.d2.loss_dice: 0.3289  decode.d3.loss_cls: 0.2967  decode.d3.loss_mask: 0.2357  decode.d3.loss_dice: 0.3537  decode.d4.loss_cls: 0.3468  decode.d4.loss_mask: 0.2375  decode.d4.loss_dice: 0.3306  decode.d5.loss_cls: 0.3085  decode.d5.loss_mask: 0.2392  decode.d5.loss_dice: 0.3447  decode.d6.loss_cls: 0.3389  decode.d6.loss_mask: 0.2410  decode.d6.loss_dice: 0.3391  decode.d7.loss_cls: 0.3627  decode.d7.loss_mask: 0.2467  decode.d7.loss_dice: 0.3419  decode.d8.loss_cls: 0.3962  decode.d8.loss_mask: 0.2410  decode.d8.loss_dice: 0.3475
07/31 18:35:15 - mmengine - INFO - Iter(train) [ 7750/80000]  base_lr: 9.1238e-05 lr: 9.1238e-06  eta: 9:43:27  time: 0.4842  data_time: 0.0093  memory: 5932  grad_norm: 188.8271  loss: 13.5286  decode.loss_cls: 0.5059  decode.loss_mask: 0.4371  decode.loss_dice: 0.4106  decode.d0.loss_cls: 1.2700  decode.d0.loss_mask: 0.3928  decode.d0.loss_dice: 0.4594  decode.d1.loss_cls: 0.6132  decode.d1.loss_mask: 0.3448  decode.d1.loss_dice: 0.3736  decode.d2.loss_cls: 0.4811  decode.d2.loss_mask: 0.3585  decode.d2.loss_dice: 0.3763  decode.d3.loss_cls: 0.4997  decode.d3.loss_mask: 0.4627  decode.d3.loss_dice: 0.4002  decode.d4.loss_cls: 0.5158  decode.d4.loss_mask: 0.3517  decode.d4.loss_dice: 0.3804  decode.d5.loss_cls: 0.5161  decode.d5.loss_mask: 0.3563  decode.d5.loss_dice: 0.3932  decode.d6.loss_cls: 0.4385  decode.d6.loss_mask: 0.3551  decode.d6.loss_dice: 0.3939  decode.d7.loss_cls: 0.4771  decode.d7.loss_mask: 0.3665  decode.d7.loss_dice: 0.3628  decode.d8.loss_cls: 0.4919  decode.d8.loss_mask: 0.3713  decode.d8.loss_dice: 0.3722
07/31 18:35:39 - mmengine - INFO - Iter(train) [ 7800/80000]  base_lr: 9.1182e-05 lr: 9.1182e-06  eta: 9:43:02  time: 0.4848  data_time: 0.0094  memory: 5988  grad_norm: 224.0794  loss: 13.7858  decode.loss_cls: 0.5605  decode.loss_mask: 0.3447  decode.loss_dice: 0.3880  decode.d0.loss_cls: 1.3600  decode.d0.loss_mask: 0.3739  decode.d0.loss_dice: 0.4594  decode.d1.loss_cls: 0.7112  decode.d1.loss_mask: 0.3435  decode.d1.loss_dice: 0.4195  decode.d2.loss_cls: 0.5638  decode.d2.loss_mask: 0.3443  decode.d2.loss_dice: 0.4041  decode.d3.loss_cls: 0.4781  decode.d3.loss_mask: 0.3411  decode.d3.loss_dice: 0.3829  decode.d4.loss_cls: 0.5040  decode.d4.loss_mask: 0.3488  decode.d4.loss_dice: 0.3968  decode.d5.loss_cls: 0.5027  decode.d5.loss_mask: 0.3424  decode.d5.loss_dice: 0.4052  decode.d6.loss_cls: 0.4982  decode.d6.loss_mask: 0.3424  decode.d6.loss_dice: 0.3769  decode.d7.loss_cls: 0.5359  decode.d7.loss_mask: 0.3500  decode.d7.loss_dice: 0.3913  decode.d8.loss_cls: 0.5783  decode.d8.loss_mask: 0.3424  decode.d8.loss_dice: 0.3956
07/31 18:36:04 - mmengine - INFO - Iter(train) [ 7850/80000]  base_lr: 9.1125e-05 lr: 9.1125e-06  eta: 9:42:38  time: 0.4847  data_time: 0.0093  memory: 5898  grad_norm: 159.8939  loss: 11.0398  decode.loss_cls: 0.3663  decode.loss_mask: 0.2370  decode.loss_dice: 0.3585  decode.d0.loss_cls: 1.3155  decode.d0.loss_mask: 0.2872  decode.d0.loss_dice: 0.4389  decode.d1.loss_cls: 0.5077  decode.d1.loss_mask: 0.2393  decode.d1.loss_dice: 0.3337  decode.d2.loss_cls: 0.4992  decode.d2.loss_mask: 0.2410  decode.d2.loss_dice: 0.3191  decode.d3.loss_cls: 0.4813  decode.d3.loss_mask: 0.2242  decode.d3.loss_dice: 0.2920  decode.d4.loss_cls: 0.4834  decode.d4.loss_mask: 0.2251  decode.d4.loss_dice: 0.3318  decode.d5.loss_cls: 0.4341  decode.d5.loss_mask: 0.2341  decode.d5.loss_dice: 0.3318  decode.d6.loss_cls: 0.3867  decode.d6.loss_mask: 0.2333  decode.d6.loss_dice: 0.3323  decode.d7.loss_cls: 0.3702  decode.d7.loss_mask: 0.2317  decode.d7.loss_dice: 0.3200  decode.d8.loss_cls: 0.4184  decode.d8.loss_mask: 0.2302  decode.d8.loss_dice: 0.3356
07/31 18:36:28 - mmengine - INFO - Iter(train) [ 7900/80000]  base_lr: 9.1068e-05 lr: 9.1068e-06  eta: 9:42:14  time: 0.4839  data_time: 0.0090  memory: 5897  grad_norm: 109.3418  loss: 8.3817  decode.loss_cls: 0.2268  decode.loss_mask: 0.2353  decode.loss_dice: 0.2710  decode.d0.loss_cls: 1.2069  decode.d0.loss_mask: 0.2586  decode.d0.loss_dice: 0.3056  decode.d1.loss_cls: 0.2780  decode.d1.loss_mask: 0.2422  decode.d1.loss_dice: 0.3013  decode.d2.loss_cls: 0.2059  decode.d2.loss_mask: 0.2402  decode.d2.loss_dice: 0.2734  decode.d3.loss_cls: 0.2341  decode.d3.loss_mask: 0.2328  decode.d3.loss_dice: 0.2557  decode.d4.loss_cls: 0.2298  decode.d4.loss_mask: 0.2448  decode.d4.loss_dice: 0.2725  decode.d5.loss_cls: 0.2196  decode.d5.loss_mask: 0.2434  decode.d5.loss_dice: 0.2635  decode.d6.loss_cls: 0.2095  decode.d6.loss_mask: 0.2375  decode.d6.loss_dice: 0.2557  decode.d7.loss_cls: 0.1979  decode.d7.loss_mask: 0.2351  decode.d7.loss_dice: 0.2691  decode.d8.loss_cls: 0.2190  decode.d8.loss_mask: 0.2417  decode.d8.loss_dice: 0.2746
07/31 18:36:52 - mmengine - INFO - Iter(train) [ 7950/80000]  base_lr: 9.1011e-05 lr: 9.1011e-06  eta: 9:41:50  time: 0.4838  data_time: 0.0092  memory: 5973  grad_norm: 177.9496  loss: 11.0454  decode.loss_cls: 0.3688  decode.loss_mask: 0.2686  decode.loss_dice: 0.3757  decode.d0.loss_cls: 1.2830  decode.d0.loss_mask: 0.2952  decode.d0.loss_dice: 0.4280  decode.d1.loss_cls: 0.4904  decode.d1.loss_mask: 0.2741  decode.d1.loss_dice: 0.3705  decode.d2.loss_cls: 0.4116  decode.d2.loss_mask: 0.2696  decode.d2.loss_dice: 0.3636  decode.d3.loss_cls: 0.4081  decode.d3.loss_mask: 0.2650  decode.d3.loss_dice: 0.3378  decode.d4.loss_cls: 0.3413  decode.d4.loss_mask: 0.2706  decode.d4.loss_dice: 0.3720  decode.d5.loss_cls: 0.3535  decode.d5.loss_mask: 0.2749  decode.d5.loss_dice: 0.3561  decode.d6.loss_cls: 0.3379  decode.d6.loss_mask: 0.2698  decode.d6.loss_dice: 0.3532  decode.d7.loss_cls: 0.3441  decode.d7.loss_mask: 0.2649  decode.d7.loss_dice: 0.3617  decode.d8.loss_cls: 0.3163  decode.d8.loss_mask: 0.2662  decode.d8.loss_dice: 0.3530
07/31 18:37:16 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250731_173226
07/31 18:37:16 - mmengine - INFO - Iter(train) [ 8000/80000]  base_lr: 9.0954e-05 lr: 9.0954e-06  eta: 9:41:25  time: 0.4834  data_time: 0.0090  memory: 5895  grad_norm: 115.8853  loss: 8.8940  decode.loss_cls: 0.2075  decode.loss_mask: 0.2686  decode.loss_dice: 0.2762  decode.d0.loss_cls: 1.1743  decode.d0.loss_mask: 0.2887  decode.d0.loss_dice: 0.3190  decode.d1.loss_cls: 0.3082  decode.d1.loss_mask: 0.2828  decode.d1.loss_dice: 0.2987  decode.d2.loss_cls: 0.2232  decode.d2.loss_mask: 0.2759  decode.d2.loss_dice: 0.2880  decode.d3.loss_cls: 0.2212  decode.d3.loss_mask: 0.2708  decode.d3.loss_dice: 0.2958  decode.d4.loss_cls: 0.2221  decode.d4.loss_mask: 0.2631  decode.d4.loss_dice: 0.2965  decode.d5.loss_cls: 0.2142  decode.d5.loss_mask: 0.2694  decode.d5.loss_dice: 0.2784  decode.d6.loss_cls: 0.2178  decode.d6.loss_mask: 0.2677  decode.d6.loss_dice: 0.2867  decode.d7.loss_cls: 0.2218  decode.d7.loss_mask: 0.2703  decode.d7.loss_dice: 0.2925  decode.d8.loss_cls: 0.2175  decode.d8.loss_mask: 0.2764  decode.d8.loss_dice: 0.3006
07/31 18:37:41 - mmengine - INFO - Iter(train) [ 8050/80000]  base_lr: 9.0897e-05 lr: 9.0897e-06  eta: 9:41:01  time: 0.4851  data_time: 0.0092  memory: 5916  grad_norm: 189.4620  loss: 10.4112  decode.loss_cls: 0.2391  decode.loss_mask: 0.2877  decode.loss_dice: 0.3547  decode.d0.loss_cls: 1.2287  decode.d0.loss_mask: 0.2808  decode.d0.loss_dice: 0.3621  decode.d1.loss_cls: 0.4853  decode.d1.loss_mask: 0.2809  decode.d1.loss_dice: 0.3379  decode.d2.loss_cls: 0.3906  decode.d2.loss_mask: 0.2777  decode.d2.loss_dice: 0.3397  decode.d3.loss_cls: 0.2698  decode.d3.loss_mask: 0.2925  decode.d3.loss_dice: 0.3737  decode.d4.loss_cls: 0.3261  decode.d4.loss_mask: 0.2776  decode.d4.loss_dice: 0.3485  decode.d5.loss_cls: 0.2614  decode.d5.loss_mask: 0.2748  decode.d5.loss_dice: 0.3345  decode.d6.loss_cls: 0.3088  decode.d6.loss_mask: 0.2923  decode.d6.loss_dice: 0.3496  decode.d7.loss_cls: 0.3131  decode.d7.loss_mask: 0.2901  decode.d7.loss_dice: 0.3524  decode.d8.loss_cls: 0.2398  decode.d8.loss_mask: 0.2873  decode.d8.loss_dice: 0.3537
07/31 18:38:05 - mmengine - INFO - Iter(train) [ 8100/80000]  base_lr: 9.0841e-05 lr: 9.0841e-06  eta: 9:40:37  time: 0.4844  data_time: 0.0092  memory: 5900  grad_norm: 120.0007  loss: 9.3512  decode.loss_cls: 0.2387  decode.loss_mask: 0.2601  decode.loss_dice: 0.3001  decode.d0.loss_cls: 1.0604  decode.d0.loss_mask: 0.2674  decode.d0.loss_dice: 0.3435  decode.d1.loss_cls: 0.4393  decode.d1.loss_mask: 0.2552  decode.d1.loss_dice: 0.2934  decode.d2.loss_cls: 0.3106  decode.d2.loss_mask: 0.2623  decode.d2.loss_dice: 0.2956  decode.d3.loss_cls: 0.2812  decode.d3.loss_mask: 0.2561  decode.d3.loss_dice: 0.2993  decode.d4.loss_cls: 0.3133  decode.d4.loss_mask: 0.2656  decode.d4.loss_dice: 0.3016  decode.d5.loss_cls: 0.2611  decode.d5.loss_mask: 0.2606  decode.d5.loss_dice: 0.3138  decode.d6.loss_cls: 0.2970  decode.d6.loss_mask: 0.2561  decode.d6.loss_dice: 0.2883  decode.d7.loss_cls: 0.2904  decode.d7.loss_mask: 0.2544  decode.d7.loss_dice: 0.2918  decode.d8.loss_cls: 0.2507  decode.d8.loss_mask: 0.2558  decode.d8.loss_dice: 0.2874
07/31 18:38:29 - mmengine - INFO - Iter(train) [ 8150/80000]  base_lr: 9.0784e-05 lr: 9.0784e-06  eta: 9:40:13  time: 0.4844  data_time: 0.0092  memory: 5883  grad_norm: 240.2368  loss: 11.3870  decode.loss_cls: 0.2110  decode.loss_mask: 0.3465  decode.loss_dice: 0.4554  decode.d0.loss_cls: 1.3557  decode.d0.loss_mask: 0.3629  decode.d0.loss_dice: 0.4826  decode.d1.loss_cls: 0.3686  decode.d1.loss_mask: 0.3334  decode.d1.loss_dice: 0.4483  decode.d2.loss_cls: 0.2317  decode.d2.loss_mask: 0.3396  decode.d2.loss_dice: 0.4579  decode.d3.loss_cls: 0.2005  decode.d3.loss_mask: 0.3206  decode.d3.loss_dice: 0.4214  decode.d4.loss_cls: 0.2118  decode.d4.loss_mask: 0.3275  decode.d4.loss_dice: 0.4582  decode.d5.loss_cls: 0.2248  decode.d5.loss_mask: 0.3373  decode.d5.loss_dice: 0.4715  decode.d6.loss_cls: 0.1978  decode.d6.loss_mask: 0.3355  decode.d6.loss_dice: 0.4405  decode.d7.loss_cls: 0.2312  decode.d7.loss_mask: 0.3273  decode.d7.loss_dice: 0.4394  decode.d8.loss_cls: 0.2733  decode.d8.loss_mask: 0.3292  decode.d8.loss_dice: 0.4455
07/31 18:38:53 - mmengine - INFO - Iter(train) [ 8200/80000]  base_lr: 9.0727e-05 lr: 9.0727e-06  eta: 9:39:50  time: 0.4842  data_time: 0.0092  memory: 5896  grad_norm: 329.6797  loss: 8.5953  decode.loss_cls: 0.1218  decode.loss_mask: 0.2598  decode.loss_dice: 0.3133  decode.d0.loss_cls: 1.3046  decode.d0.loss_mask: 0.2764  decode.d0.loss_dice: 0.3346  decode.d1.loss_cls: 0.3216  decode.d1.loss_mask: 0.2865  decode.d1.loss_dice: 0.3435  decode.d2.loss_cls: 0.1819  decode.d2.loss_mask: 0.2700  decode.d2.loss_dice: 0.3101  decode.d3.loss_cls: 0.1560  decode.d3.loss_mask: 0.2622  decode.d3.loss_dice: 0.2931  decode.d4.loss_cls: 0.1485  decode.d4.loss_mask: 0.2694  decode.d4.loss_dice: 0.3064  decode.d5.loss_cls: 0.1501  decode.d5.loss_mask: 0.2573  decode.d5.loss_dice: 0.3124  decode.d6.loss_cls: 0.1315  decode.d6.loss_mask: 0.2591  decode.d6.loss_dice: 0.3019  decode.d7.loss_cls: 0.1361  decode.d7.loss_mask: 0.2575  decode.d7.loss_dice: 0.3132  decode.d8.loss_cls: 0.1499  decode.d8.loss_mask: 0.2578  decode.d8.loss_dice: 0.3089
07/31 18:39:18 - mmengine - INFO - Iter(train) [ 8250/80000]  base_lr: 9.0670e-05 lr: 9.0670e-06  eta: 9:39:26  time: 0.4844  data_time: 0.0092  memory: 5918  grad_norm: 128.7758  loss: 10.1744  decode.loss_cls: 0.3015  decode.loss_mask: 0.3119  decode.loss_dice: 0.3400  decode.d0.loss_cls: 1.0843  decode.d0.loss_mask: 0.3075  decode.d0.loss_dice: 0.4043  decode.d1.loss_cls: 0.4394  decode.d1.loss_mask: 0.2962  decode.d1.loss_dice: 0.3329  decode.d2.loss_cls: 0.2655  decode.d2.loss_mask: 0.2983  decode.d2.loss_dice: 0.3296  decode.d3.loss_cls: 0.2706  decode.d3.loss_mask: 0.2944  decode.d3.loss_dice: 0.3212  decode.d4.loss_cls: 0.2648  decode.d4.loss_mask: 0.2975  decode.d4.loss_dice: 0.3149  decode.d5.loss_cls: 0.2865  decode.d5.loss_mask: 0.2949  decode.d5.loss_dice: 0.3481  decode.d6.loss_cls: 0.2993  decode.d6.loss_mask: 0.2904  decode.d6.loss_dice: 0.3317  decode.d7.loss_cls: 0.2890  decode.d7.loss_mask: 0.2970  decode.d7.loss_dice: 0.3345  decode.d8.loss_cls: 0.2935  decode.d8.loss_mask: 0.2880  decode.d8.loss_dice: 0.3468
07/31 18:39:42 - mmengine - INFO - Iter(train) [ 8300/80000]  base_lr: 9.0613e-05 lr: 9.0613e-06  eta: 9:39:02  time: 0.4851  data_time: 0.0090  memory: 5897  grad_norm: 225.1181  loss: 10.0706  decode.loss_cls: 0.2896  decode.loss_mask: 0.3307  decode.loss_dice: 0.3206  decode.d0.loss_cls: 1.1615  decode.d0.loss_mask: 0.3386  decode.d0.loss_dice: 0.3322  decode.d1.loss_cls: 0.2646  decode.d1.loss_mask: 0.3090  decode.d1.loss_dice: 0.3079  decode.d2.loss_cls: 0.2319  decode.d2.loss_mask: 0.3145  decode.d2.loss_dice: 0.2997  decode.d3.loss_cls: 0.2212  decode.d3.loss_mask: 0.3074  decode.d3.loss_dice: 0.3058  decode.d4.loss_cls: 0.3166  decode.d4.loss_mask: 0.3053  decode.d4.loss_dice: 0.2770  decode.d5.loss_cls: 0.3212  decode.d5.loss_mask: 0.3124  decode.d5.loss_dice: 0.3004  decode.d6.loss_cls: 0.3027  decode.d6.loss_mask: 0.3198  decode.d6.loss_dice: 0.2901  decode.d7.loss_cls: 0.3784  decode.d7.loss_mask: 0.3364  decode.d7.loss_dice: 0.3039  decode.d8.loss_cls: 0.3690  decode.d8.loss_mask: 0.3160  decode.d8.loss_dice: 0.2861
07/31 18:40:06 - mmengine - INFO - Iter(train) [ 8350/80000]  base_lr: 9.0556e-05 lr: 9.0556e-06  eta: 9:38:37  time: 0.4848  data_time: 0.0092  memory: 5920  grad_norm: 310.2923  loss: 10.3266  decode.loss_cls: 0.2615  decode.loss_mask: 0.3602  decode.loss_dice: 0.2997  decode.d0.loss_cls: 1.0843  decode.d0.loss_mask: 0.3646  decode.d0.loss_dice: 0.3301  decode.d1.loss_cls: 0.2788  decode.d1.loss_mask: 0.3793  decode.d1.loss_dice: 0.3417  decode.d2.loss_cls: 0.3099  decode.d2.loss_mask: 0.3711  decode.d2.loss_dice: 0.2935  decode.d3.loss_cls: 0.2915  decode.d3.loss_mask: 0.3730  decode.d3.loss_dice: 0.2968  decode.d4.loss_cls: 0.2742  decode.d4.loss_mask: 0.3720  decode.d4.loss_dice: 0.3020  decode.d5.loss_cls: 0.2418  decode.d5.loss_mask: 0.3780  decode.d5.loss_dice: 0.2916  decode.d6.loss_cls: 0.2561  decode.d6.loss_mask: 0.3708  decode.d6.loss_dice: 0.3048  decode.d7.loss_cls: 0.2627  decode.d7.loss_mask: 0.3720  decode.d7.loss_dice: 0.2833  decode.d8.loss_cls: 0.2938  decode.d8.loss_mask: 0.3674  decode.d8.loss_dice: 0.3200
07/31 18:40:30 - mmengine - INFO - Iter(train) [ 8400/80000]  base_lr: 9.0499e-05 lr: 9.0499e-06  eta: 9:38:13  time: 0.4847  data_time: 0.0090  memory: 5918  grad_norm: 237.1921  loss: 11.0157  decode.loss_cls: 0.2521  decode.loss_mask: 0.3378  decode.loss_dice: 0.3882  decode.d0.loss_cls: 1.2179  decode.d0.loss_mask: 0.3271  decode.d0.loss_dice: 0.4243  decode.d1.loss_cls: 0.4073  decode.d1.loss_mask: 0.3303  decode.d1.loss_dice: 0.3834  decode.d2.loss_cls: 0.3087  decode.d2.loss_mask: 0.3188  decode.d2.loss_dice: 0.3831  decode.d3.loss_cls: 0.3272  decode.d3.loss_mask: 0.3117  decode.d3.loss_dice: 0.3495  decode.d4.loss_cls: 0.3609  decode.d4.loss_mask: 0.3173  decode.d4.loss_dice: 0.3441  decode.d5.loss_cls: 0.3131  decode.d5.loss_mask: 0.3298  decode.d5.loss_dice: 0.3570  decode.d6.loss_cls: 0.2883  decode.d6.loss_mask: 0.3282  decode.d6.loss_dice: 0.3532  decode.d7.loss_cls: 0.2912  decode.d7.loss_mask: 0.3257  decode.d7.loss_dice: 0.3540  decode.d8.loss_cls: 0.2919  decode.d8.loss_mask: 0.3319  decode.d8.loss_dice: 0.3616
07/31 18:40:55 - mmengine - INFO - Iter(train) [ 8450/80000]  base_lr: 9.0443e-05 lr: 9.0443e-06  eta: 9:37:49  time: 0.4850  data_time: 0.0089  memory: 5896  grad_norm: 141.0743  loss: 10.1810  decode.loss_cls: 0.2449  decode.loss_mask: 0.2760  decode.loss_dice: 0.3715  decode.d0.loss_cls: 1.1938  decode.d0.loss_mask: 0.2707  decode.d0.loss_dice: 0.3998  decode.d1.loss_cls: 0.4266  decode.d1.loss_mask: 0.2765  decode.d1.loss_dice: 0.3477  decode.d2.loss_cls: 0.3122  decode.d2.loss_mask: 0.2793  decode.d2.loss_dice: 0.3646  decode.d3.loss_cls: 0.2800  decode.d3.loss_mask: 0.2883  decode.d3.loss_dice: 0.3626  decode.d4.loss_cls: 0.2589  decode.d4.loss_mask: 0.2877  decode.d4.loss_dice: 0.3574  decode.d5.loss_cls: 0.2263  decode.d5.loss_mask: 0.2849  decode.d5.loss_dice: 0.3732  decode.d6.loss_cls: 0.2695  decode.d6.loss_mask: 0.2816  decode.d6.loss_dice: 0.3607  decode.d7.loss_cls: 0.2769  decode.d7.loss_mask: 0.2775  decode.d7.loss_dice: 0.3470  decode.d8.loss_cls: 0.2472  decode.d8.loss_mask: 0.2720  decode.d8.loss_dice: 0.3656
07/31 18:41:19 - mmengine - INFO - Iter(train) [ 8500/80000]  base_lr: 9.0386e-05 lr: 9.0386e-06  eta: 9:37:25  time: 0.4845  data_time: 0.0090  memory: 5897  grad_norm: 548.6799  loss: 10.2017  decode.loss_cls: 0.2791  decode.loss_mask: 0.2636  decode.loss_dice: 0.3106  decode.d0.loss_cls: 1.2109  decode.d0.loss_mask: 0.2843  decode.d0.loss_dice: 0.3605  decode.d1.loss_cls: 0.3895  decode.d1.loss_mask: 0.2837  decode.d1.loss_dice: 0.3434  decode.d2.loss_cls: 0.3188  decode.d2.loss_mask: 0.2820  decode.d2.loss_dice: 0.3353  decode.d3.loss_cls: 0.2827  decode.d3.loss_mask: 0.2685  decode.d3.loss_dice: 0.3037  decode.d4.loss_cls: 0.3167  decode.d4.loss_mask: 0.2757  decode.d4.loss_dice: 0.3347  decode.d5.loss_cls: 0.3340  decode.d5.loss_mask: 0.2753  decode.d5.loss_dice: 0.3272  decode.d6.loss_cls: 0.3674  decode.d6.loss_mask: 0.2695  decode.d6.loss_dice: 0.3378  decode.d7.loss_cls: 0.3488  decode.d7.loss_mask: 0.2738  decode.d7.loss_dice: 0.3353  decode.d8.loss_cls: 0.2963  decode.d8.loss_mask: 0.2702  decode.d8.loss_dice: 0.3224
07/31 18:41:43 - mmengine - INFO - Iter(train) [ 8550/80000]  base_lr: 9.0329e-05 lr: 9.0329e-06  eta: 9:37:00  time: 0.4838  data_time: 0.0094  memory: 5899  grad_norm: 87.5911  loss: 8.4440  decode.loss_cls: 0.1289  decode.loss_mask: 0.3584  decode.loss_dice: 0.2542  decode.d0.loss_cls: 0.9469  decode.d0.loss_mask: 0.3626  decode.d0.loss_dice: 0.2626  decode.d1.loss_cls: 0.1493  decode.d1.loss_mask: 0.3581  decode.d1.loss_dice: 0.2498  decode.d2.loss_cls: 0.1562  decode.d2.loss_mask: 0.3583  decode.d2.loss_dice: 0.2495  decode.d3.loss_cls: 0.1951  decode.d3.loss_mask: 0.3533  decode.d3.loss_dice: 0.2446  decode.d4.loss_cls: 0.1681  decode.d4.loss_mask: 0.3586  decode.d4.loss_dice: 0.2514  decode.d5.loss_cls: 0.1716  decode.d5.loss_mask: 0.3602  decode.d5.loss_dice: 0.2544  decode.d6.loss_cls: 0.1278  decode.d6.loss_mask: 0.3580  decode.d6.loss_dice: 0.2536  decode.d7.loss_cls: 0.1433  decode.d7.loss_mask: 0.3599  decode.d7.loss_dice: 0.2612  decode.d8.loss_cls: 0.1415  decode.d8.loss_mask: 0.3536  decode.d8.loss_dice: 0.2529
07/31 18:42:07 - mmengine - INFO - Iter(train) [ 8600/80000]  base_lr: 9.0272e-05 lr: 9.0272e-06  eta: 9:36:36  time: 0.4836  data_time: 0.0092  memory: 5934  grad_norm: 154.7989  loss: 12.8952  decode.loss_cls: 0.4470  decode.loss_mask: 0.3736  decode.loss_dice: 0.3789  decode.d0.loss_cls: 1.1511  decode.d0.loss_mask: 0.3283  decode.d0.loss_dice: 0.4033  decode.d1.loss_cls: 0.6671  decode.d1.loss_mask: 0.3013  decode.d1.loss_dice: 0.3590  decode.d2.loss_cls: 0.4661  decode.d2.loss_mask: 0.3193  decode.d2.loss_dice: 0.3782  decode.d3.loss_cls: 0.4883  decode.d3.loss_mask: 0.3269  decode.d3.loss_dice: 0.3722  decode.d4.loss_cls: 0.5381  decode.d4.loss_mask: 0.3121  decode.d4.loss_dice: 0.3738  decode.d5.loss_cls: 0.4573  decode.d5.loss_mask: 0.3422  decode.d5.loss_dice: 0.3833  decode.d6.loss_cls: 0.4850  decode.d6.loss_mask: 0.3774  decode.d6.loss_dice: 0.3911  decode.d7.loss_cls: 0.5064  decode.d7.loss_mask: 0.3522  decode.d7.loss_dice: 0.3877  decode.d8.loss_cls: 0.4820  decode.d8.loss_mask: 0.3733  decode.d8.loss_dice: 0.3728
07/31 18:42:31 - mmengine - INFO - Iter(train) [ 8650/80000]  base_lr: 9.0215e-05 lr: 9.0215e-06  eta: 9:36:11  time: 0.4846  data_time: 0.0091  memory: 5918  grad_norm: 137.1350  loss: 8.9454  decode.loss_cls: 0.2321  decode.loss_mask: 0.2505  decode.loss_dice: 0.2830  decode.d0.loss_cls: 1.1401  decode.d0.loss_mask: 0.2716  decode.d0.loss_dice: 0.3157  decode.d1.loss_cls: 0.3461  decode.d1.loss_mask: 0.2503  decode.d1.loss_dice: 0.2815  decode.d2.loss_cls: 0.2559  decode.d2.loss_mask: 0.2465  decode.d2.loss_dice: 0.2608  decode.d3.loss_cls: 0.2868  decode.d3.loss_mask: 0.2498  decode.d3.loss_dice: 0.2745  decode.d4.loss_cls: 0.2509  decode.d4.loss_mask: 0.2597  decode.d4.loss_dice: 0.2777  decode.d5.loss_cls: 0.3039  decode.d5.loss_mask: 0.2447  decode.d5.loss_dice: 0.2675  decode.d6.loss_cls: 0.2950  decode.d6.loss_mask: 0.2484  decode.d6.loss_dice: 0.2719  decode.d7.loss_cls: 0.2623  decode.d7.loss_mask: 0.2476  decode.d7.loss_dice: 0.2732  decode.d8.loss_cls: 0.2823  decode.d8.loss_mask: 0.2451  decode.d8.loss_dice: 0.2700
07/31 18:42:56 - mmengine - INFO - Iter(train) [ 8700/80000]  base_lr: 9.0158e-05 lr: 9.0158e-06  eta: 9:35:47  time: 0.4840  data_time: 0.0091  memory: 5916  grad_norm: 104.9657  loss: 8.4641  decode.loss_cls: 0.1698  decode.loss_mask: 0.2543  decode.loss_dice: 0.2954  decode.d0.loss_cls: 1.1771  decode.d0.loss_mask: 0.2596  decode.d0.loss_dice: 0.3068  decode.d1.loss_cls: 0.2523  decode.d1.loss_mask: 0.2496  decode.d1.loss_dice: 0.2971  decode.d2.loss_cls: 0.2304  decode.d2.loss_mask: 0.2525  decode.d2.loss_dice: 0.3045  decode.d3.loss_cls: 0.2261  decode.d3.loss_mask: 0.2485  decode.d3.loss_dice: 0.2744  decode.d4.loss_cls: 0.1906  decode.d4.loss_mask: 0.2584  decode.d4.loss_dice: 0.2807  decode.d5.loss_cls: 0.1803  decode.d5.loss_mask: 0.2544  decode.d5.loss_dice: 0.2883  decode.d6.loss_cls: 0.1761  decode.d6.loss_mask: 0.2569  decode.d6.loss_dice: 0.2870  decode.d7.loss_cls: 0.1841  decode.d7.loss_mask: 0.2663  decode.d7.loss_dice: 0.3003  decode.d8.loss_cls: 0.1855  decode.d8.loss_mask: 0.2604  decode.d8.loss_dice: 0.2961
07/31 18:43:20 - mmengine - INFO - Iter(train) [ 8750/80000]  base_lr: 9.0101e-05 lr: 9.0101e-06  eta: 9:35:23  time: 0.4846  data_time: 0.0092  memory: 5934  grad_norm: 219.4686  loss: 10.4477  decode.loss_cls: 0.2790  decode.loss_mask: 0.2904  decode.loss_dice: 0.3199  decode.d0.loss_cls: 1.1129  decode.d0.loss_mask: 0.3002  decode.d0.loss_dice: 0.3369  decode.d1.loss_cls: 0.5140  decode.d1.loss_mask: 0.2905  decode.d1.loss_dice: 0.3068  decode.d2.loss_cls: 0.4028  decode.d2.loss_mask: 0.2874  decode.d2.loss_dice: 0.3113  decode.d3.loss_cls: 0.3369  decode.d3.loss_mask: 0.2951  decode.d3.loss_dice: 0.3171  decode.d4.loss_cls: 0.3505  decode.d4.loss_mask: 0.2985  decode.d4.loss_dice: 0.3255  decode.d5.loss_cls: 0.3227  decode.d5.loss_mask: 0.2943  decode.d5.loss_dice: 0.3506  decode.d6.loss_cls: 0.3337  decode.d6.loss_mask: 0.2934  decode.d6.loss_dice: 0.3397  decode.d7.loss_cls: 0.3545  decode.d7.loss_mask: 0.2905  decode.d7.loss_dice: 0.3286  decode.d8.loss_cls: 0.2431  decode.d8.loss_mask: 0.2927  decode.d8.loss_dice: 0.3282
07/31 18:43:44 - mmengine - INFO - Iter(train) [ 8800/80000]  base_lr: 9.0044e-05 lr: 9.0044e-06  eta: 9:34:59  time: 0.4842  data_time: 0.0093  memory: 5918  grad_norm: 146.0802  loss: 13.5417  decode.loss_cls: 0.5232  decode.loss_mask: 0.3442  decode.loss_dice: 0.3748  decode.d0.loss_cls: 1.3353  decode.d0.loss_mask: 0.3530  decode.d0.loss_dice: 0.4127  decode.d1.loss_cls: 0.6625  decode.d1.loss_mask: 0.3532  decode.d1.loss_dice: 0.3920  decode.d2.loss_cls: 0.6040  decode.d2.loss_mask: 0.3490  decode.d2.loss_dice: 0.3829  decode.d3.loss_cls: 0.4999  decode.d3.loss_mask: 0.3443  decode.d3.loss_dice: 0.3685  decode.d4.loss_cls: 0.4997  decode.d4.loss_mask: 0.3439  decode.d4.loss_dice: 0.3599  decode.d5.loss_cls: 0.5154  decode.d5.loss_mask: 0.3519  decode.d5.loss_dice: 0.3798  decode.d6.loss_cls: 0.4676  decode.d6.loss_mask: 0.3437  decode.d6.loss_dice: 0.3790  decode.d7.loss_cls: 0.4930  decode.d7.loss_mask: 0.3558  decode.d7.loss_dice: 0.3955  decode.d8.loss_cls: 0.6073  decode.d8.loss_mask: 0.3485  decode.d8.loss_dice: 0.4014
07/31 18:44:08 - mmengine - INFO - Iter(train) [ 8850/80000]  base_lr: 8.9987e-05 lr: 8.9987e-06  eta: 9:34:35  time: 0.4844  data_time: 0.0092  memory: 5897  grad_norm: 152.3525  loss: 11.0899  decode.loss_cls: 0.3783  decode.loss_mask: 0.2599  decode.loss_dice: 0.3821  decode.d0.loss_cls: 1.2997  decode.d0.loss_mask: 0.2638  decode.d0.loss_dice: 0.4192  decode.d1.loss_cls: 0.4982  decode.d1.loss_mask: 0.2380  decode.d1.loss_dice: 0.3282  decode.d2.loss_cls: 0.3737  decode.d2.loss_mask: 0.2472  decode.d2.loss_dice: 0.3702  decode.d3.loss_cls: 0.3936  decode.d3.loss_mask: 0.2447  decode.d3.loss_dice: 0.3562  decode.d4.loss_cls: 0.3418  decode.d4.loss_mask: 0.2360  decode.d4.loss_dice: 0.3334  decode.d5.loss_cls: 0.3694  decode.d5.loss_mask: 0.2570  decode.d5.loss_dice: 0.3857  decode.d6.loss_cls: 0.4104  decode.d6.loss_mask: 0.2511  decode.d6.loss_dice: 0.3968  decode.d7.loss_cls: 0.3987  decode.d7.loss_mask: 0.2628  decode.d7.loss_dice: 0.4192  decode.d8.loss_cls: 0.3286  decode.d8.loss_mask: 0.2664  decode.d8.loss_dice: 0.3797
07/31 18:44:33 - mmengine - INFO - Iter(train) [ 8900/80000]  base_lr: 8.9930e-05 lr: 8.9930e-06  eta: 9:34:11  time: 0.4843  data_time: 0.0092  memory: 5918  grad_norm: 113.6787  loss: 8.8392  decode.loss_cls: 0.2539  decode.loss_mask: 0.2511  decode.loss_dice: 0.3081  decode.d0.loss_cls: 1.2632  decode.d0.loss_mask: 0.2548  decode.d0.loss_dice: 0.3134  decode.d1.loss_cls: 0.3011  decode.d1.loss_mask: 0.2558  decode.d1.loss_dice: 0.2992  decode.d2.loss_cls: 0.2092  decode.d2.loss_mask: 0.2446  decode.d2.loss_dice: 0.2958  decode.d3.loss_cls: 0.2261  decode.d3.loss_mask: 0.2423  decode.d3.loss_dice: 0.3009  decode.d4.loss_cls: 0.1980  decode.d4.loss_mask: 0.2483  decode.d4.loss_dice: 0.3002  decode.d5.loss_cls: 0.1871  decode.d5.loss_mask: 0.2404  decode.d5.loss_dice: 0.3005  decode.d6.loss_cls: 0.2081  decode.d6.loss_mask: 0.2432  decode.d6.loss_dice: 0.2780  decode.d7.loss_cls: 0.2498  decode.d7.loss_mask: 0.2468  decode.d7.loss_dice: 0.3036  decode.d8.loss_cls: 0.2617  decode.d8.loss_mask: 0.2524  decode.d8.loss_dice: 0.3017
07/31 18:44:57 - mmengine - INFO - Iter(train) [ 8950/80000]  base_lr: 8.9873e-05 lr: 8.9873e-06  eta: 9:33:46  time: 0.4838  data_time: 0.0092  memory: 5933  grad_norm: 371.1520  loss: 9.6548  decode.loss_cls: 0.1859  decode.loss_mask: 0.3244  decode.loss_dice: 0.3198  decode.d0.loss_cls: 1.2905  decode.d0.loss_mask: 0.3630  decode.d0.loss_dice: 0.3766  decode.d1.loss_cls: 0.2664  decode.d1.loss_mask: 0.3248  decode.d1.loss_dice: 0.3333  decode.d2.loss_cls: 0.2139  decode.d2.loss_mask: 0.3146  decode.d2.loss_dice: 0.3010  decode.d3.loss_cls: 0.2317  decode.d3.loss_mask: 0.3136  decode.d3.loss_dice: 0.2788  decode.d4.loss_cls: 0.2686  decode.d4.loss_mask: 0.3202  decode.d4.loss_dice: 0.3075  decode.d5.loss_cls: 0.2040  decode.d5.loss_mask: 0.3239  decode.d5.loss_dice: 0.3110  decode.d6.loss_cls: 0.1749  decode.d6.loss_mask: 0.3240  decode.d6.loss_dice: 0.3110  decode.d7.loss_cls: 0.2129  decode.d7.loss_mask: 0.3244  decode.d7.loss_dice: 0.3099  decode.d8.loss_cls: 0.1916  decode.d8.loss_mask: 0.3227  decode.d8.loss_dice: 0.3100
07/31 18:45:21 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250731_173226
07/31 18:45:21 - mmengine - INFO - Iter(train) [ 9000/80000]  base_lr: 8.9817e-05 lr: 8.9817e-06  eta: 9:33:22  time: 0.4837  data_time: 0.0092  memory: 5882  grad_norm: 257.1636  loss: 9.7045  decode.loss_cls: 0.2126  decode.loss_mask: 0.2687  decode.loss_dice: 0.3432  decode.d0.loss_cls: 1.0800  decode.d0.loss_mask: 0.3094  decode.d0.loss_dice: 0.4113  decode.d1.loss_cls: 0.3625  decode.d1.loss_mask: 0.2855  decode.d1.loss_dice: 0.3572  decode.d2.loss_cls: 0.2199  decode.d2.loss_mask: 0.2819  decode.d2.loss_dice: 0.3352  decode.d3.loss_cls: 0.2358  decode.d3.loss_mask: 0.2839  decode.d3.loss_dice: 0.3555  decode.d4.loss_cls: 0.1862  decode.d4.loss_mask: 0.2972  decode.d4.loss_dice: 0.3738  decode.d5.loss_cls: 0.2414  decode.d5.loss_mask: 0.2957  decode.d5.loss_dice: 0.3742  decode.d6.loss_cls: 0.2092  decode.d6.loss_mask: 0.2836  decode.d6.loss_dice: 0.3714  decode.d7.loss_cls: 0.1865  decode.d7.loss_mask: 0.2723  decode.d7.loss_dice: 0.3564  decode.d8.loss_cls: 0.2675  decode.d8.loss_mask: 0.2768  decode.d8.loss_dice: 0.3697
07/31 18:45:45 - mmengine - INFO - Iter(train) [ 9050/80000]  base_lr: 8.9760e-05 lr: 8.9760e-06  eta: 9:32:57  time: 0.4845  data_time: 0.0092  memory: 5973  grad_norm: 165.5427  loss: 12.5972  decode.loss_cls: 0.3645  decode.loss_mask: 0.2810  decode.loss_dice: 0.4329  decode.d0.loss_cls: 1.3975  decode.d0.loss_mask: 0.2970  decode.d0.loss_dice: 0.4794  decode.d1.loss_cls: 0.5126  decode.d1.loss_mask: 0.2869  decode.d1.loss_dice: 0.4321  decode.d2.loss_cls: 0.4452  decode.d2.loss_mask: 0.2894  decode.d2.loss_dice: 0.4423  decode.d3.loss_cls: 0.5017  decode.d3.loss_mask: 0.2698  decode.d3.loss_dice: 0.4443  decode.d4.loss_cls: 0.4306  decode.d4.loss_mask: 0.2871  decode.d4.loss_dice: 0.4719  decode.d5.loss_cls: 0.3892  decode.d5.loss_mask: 0.2761  decode.d5.loss_dice: 0.4599  decode.d6.loss_cls: 0.4406  decode.d6.loss_mask: 0.2727  decode.d6.loss_dice: 0.4459  decode.d7.loss_cls: 0.3967  decode.d7.loss_mask: 0.2819  decode.d7.loss_dice: 0.4669  decode.d8.loss_cls: 0.3679  decode.d8.loss_mask: 0.2858  decode.d8.loss_dice: 0.4472
07/31 18:46:10 - mmengine - INFO - Iter(train) [ 9100/80000]  base_lr: 8.9703e-05 lr: 8.9703e-06  eta: 9:32:33  time: 0.4846  data_time: 0.0092  memory: 5896  grad_norm: 148.1621  loss: 10.4123  decode.loss_cls: 0.4366  decode.loss_mask: 0.2424  decode.loss_dice: 0.2899  decode.d0.loss_cls: 1.2336  decode.d0.loss_mask: 0.2491  decode.d0.loss_dice: 0.3124  decode.d1.loss_cls: 0.5487  decode.d1.loss_mask: 0.2414  decode.d1.loss_dice: 0.2822  decode.d2.loss_cls: 0.4686  decode.d2.loss_mask: 0.2458  decode.d2.loss_dice: 0.3119  decode.d3.loss_cls: 0.3414  decode.d3.loss_mask: 0.2510  decode.d3.loss_dice: 0.2975  decode.d4.loss_cls: 0.4145  decode.d4.loss_mask: 0.2438  decode.d4.loss_dice: 0.2966  decode.d5.loss_cls: 0.3703  decode.d5.loss_mask: 0.2412  decode.d5.loss_dice: 0.2964  decode.d6.loss_cls: 0.4244  decode.d6.loss_mask: 0.2512  decode.d6.loss_dice: 0.2929  decode.d7.loss_cls: 0.3813  decode.d7.loss_mask: 0.2401  decode.d7.loss_dice: 0.2881  decode.d8.loss_cls: 0.3814  decode.d8.loss_mask: 0.2408  decode.d8.loss_dice: 0.2970
07/31 18:46:34 - mmengine - INFO - Iter(train) [ 9150/80000]  base_lr: 8.9646e-05 lr: 8.9646e-06  eta: 9:32:09  time: 0.4844  data_time: 0.0092  memory: 5973  grad_norm: 244.6741  loss: 8.3774  decode.loss_cls: 0.2169  decode.loss_mask: 0.2357  decode.loss_dice: 0.2747  decode.d0.loss_cls: 1.1508  decode.d0.loss_mask: 0.2598  decode.d0.loss_dice: 0.3194  decode.d1.loss_cls: 0.3174  decode.d1.loss_mask: 0.2436  decode.d1.loss_dice: 0.2657  decode.d2.loss_cls: 0.2484  decode.d2.loss_mask: 0.2435  decode.d2.loss_dice: 0.2815  decode.d3.loss_cls: 0.2529  decode.d3.loss_mask: 0.2422  decode.d3.loss_dice: 0.2615  decode.d4.loss_cls: 0.2164  decode.d4.loss_mask: 0.2505  decode.d4.loss_dice: 0.2977  decode.d5.loss_cls: 0.1764  decode.d5.loss_mask: 0.2439  decode.d5.loss_dice: 0.2753  decode.d6.loss_cls: 0.1962  decode.d6.loss_mask: 0.2387  decode.d6.loss_dice: 0.2733  decode.d7.loss_cls: 0.1868  decode.d7.loss_mask: 0.2355  decode.d7.loss_dice: 0.2798  decode.d8.loss_cls: 0.1792  decode.d8.loss_mask: 0.2383  decode.d8.loss_dice: 0.2752
07/31 18:46:58 - mmengine - INFO - Iter(train) [ 9200/80000]  base_lr: 8.9589e-05 lr: 8.9589e-06  eta: 9:31:45  time: 0.4840  data_time: 0.0091  memory: 5896  grad_norm: 171.2792  loss: 8.9038  decode.loss_cls: 0.1710  decode.loss_mask: 0.2696  decode.loss_dice: 0.2708  decode.d0.loss_cls: 1.2796  decode.d0.loss_mask: 0.3104  decode.d0.loss_dice: 0.3515  decode.d1.loss_cls: 0.3754  decode.d1.loss_mask: 0.2747  decode.d1.loss_dice: 0.2934  decode.d2.loss_cls: 0.2994  decode.d2.loss_mask: 0.2668  decode.d2.loss_dice: 0.2966  decode.d3.loss_cls: 0.2619  decode.d3.loss_mask: 0.2627  decode.d3.loss_dice: 0.2721  decode.d4.loss_cls: 0.2066  decode.d4.loss_mask: 0.2658  decode.d4.loss_dice: 0.2767  decode.d5.loss_cls: 0.2162  decode.d5.loss_mask: 0.2657  decode.d5.loss_dice: 0.2763  decode.d6.loss_cls: 0.1544  decode.d6.loss_mask: 0.2727  decode.d6.loss_dice: 0.2783  decode.d7.loss_cls: 0.1969  decode.d7.loss_mask: 0.2692  decode.d7.loss_dice: 0.2731  decode.d8.loss_cls: 0.1560  decode.d8.loss_mask: 0.2703  decode.d8.loss_dice: 0.2700
07/31 18:47:22 - mmengine - INFO - Iter(train) [ 9250/80000]  base_lr: 8.9532e-05 lr: 8.9532e-06  eta: 9:31:20  time: 0.4853  data_time: 0.0093  memory: 5918  grad_norm: 358.7905  loss: 11.7552  decode.loss_cls: 0.4035  decode.loss_mask: 0.3171  decode.loss_dice: 0.4158  decode.d0.loss_cls: 1.3304  decode.d0.loss_mask: 0.3082  decode.d0.loss_dice: 0.3983  decode.d1.loss_cls: 0.4183  decode.d1.loss_mask: 0.2961  decode.d1.loss_dice: 0.3880  decode.d2.loss_cls: 0.3148  decode.d2.loss_mask: 0.3058  decode.d2.loss_dice: 0.4244  decode.d3.loss_cls: 0.2988  decode.d3.loss_mask: 0.3038  decode.d3.loss_dice: 0.4239  decode.d4.loss_cls: 0.3315  decode.d4.loss_mask: 0.2991  decode.d4.loss_dice: 0.4274  decode.d5.loss_cls: 0.3482  decode.d5.loss_mask: 0.2957  decode.d5.loss_dice: 0.3736  decode.d6.loss_cls: 0.3594  decode.d6.loss_mask: 0.3015  decode.d6.loss_dice: 0.4184  decode.d7.loss_cls: 0.3960  decode.d7.loss_mask: 0.2966  decode.d7.loss_dice: 0.3922  decode.d8.loss_cls: 0.4639  decode.d8.loss_mask: 0.3009  decode.d8.loss_dice: 0.4037
07/31 18:47:47 - mmengine - INFO - Iter(train) [ 9300/80000]  base_lr: 8.9475e-05 lr: 8.9475e-06  eta: 9:30:57  time: 0.4847  data_time: 0.0093  memory: 5934  grad_norm: 282.9641  loss: 11.5436  decode.loss_cls: 0.3572  decode.loss_mask: 0.3177  decode.loss_dice: 0.4046  decode.d0.loss_cls: 1.2767  decode.d0.loss_mask: 0.2942  decode.d0.loss_dice: 0.4239  decode.d1.loss_cls: 0.4397  decode.d1.loss_mask: 0.3280  decode.d1.loss_dice: 0.4183  decode.d2.loss_cls: 0.3894  decode.d2.loss_mask: 0.3143  decode.d2.loss_dice: 0.3954  decode.d3.loss_cls: 0.2887  decode.d3.loss_mask: 0.3117  decode.d3.loss_dice: 0.3890  decode.d4.loss_cls: 0.3474  decode.d4.loss_mask: 0.3226  decode.d4.loss_dice: 0.4000  decode.d5.loss_cls: 0.2842  decode.d5.loss_mask: 0.3182  decode.d5.loss_dice: 0.4047  decode.d6.loss_cls: 0.2740  decode.d6.loss_mask: 0.3170  decode.d6.loss_dice: 0.3868  decode.d7.loss_cls: 0.2771  decode.d7.loss_mask: 0.3426  decode.d7.loss_dice: 0.4125  decode.d8.loss_cls: 0.3468  decode.d8.loss_mask: 0.3455  decode.d8.loss_dice: 0.4156
07/31 18:48:11 - mmengine - INFO - Iter(train) [ 9350/80000]  base_lr: 8.9418e-05 lr: 8.9418e-06  eta: 9:30:33  time: 0.4880  data_time: 0.0095  memory: 5988  grad_norm: 92.9884  loss: 8.4347  decode.loss_cls: 0.1385  decode.loss_mask: 0.3136  decode.loss_dice: 0.2794  decode.d0.loss_cls: 1.0331  decode.d0.loss_mask: 0.3287  decode.d0.loss_dice: 0.3090  decode.d1.loss_cls: 0.2116  decode.d1.loss_mask: 0.3225  decode.d1.loss_dice: 0.2944  decode.d2.loss_cls: 0.1582  decode.d2.loss_mask: 0.3200  decode.d2.loss_dice: 0.2894  decode.d3.loss_cls: 0.1365  decode.d3.loss_mask: 0.3256  decode.d3.loss_dice: 0.2782  decode.d4.loss_cls: 0.1323  decode.d4.loss_mask: 0.3195  decode.d4.loss_dice: 0.2877  decode.d5.loss_cls: 0.1182  decode.d5.loss_mask: 0.3206  decode.d5.loss_dice: 0.2855  decode.d6.loss_cls: 0.1362  decode.d6.loss_mask: 0.3190  decode.d6.loss_dice: 0.2806  decode.d7.loss_cls: 0.1276  decode.d7.loss_mask: 0.3126  decode.d7.loss_dice: 0.2892  decode.d8.loss_cls: 0.1834  decode.d8.loss_mask: 0.3115  decode.d8.loss_dice: 0.2720
07/31 18:48:35 - mmengine - INFO - Iter(train) [ 9400/80000]  base_lr: 8.9361e-05 lr: 8.9361e-06  eta: 9:30:09  time: 0.4845  data_time: 0.0093  memory: 5918  grad_norm: 158.9623  loss: 12.0387  decode.loss_cls: 0.3708  decode.loss_mask: 0.3448  decode.loss_dice: 0.3921  decode.d0.loss_cls: 0.9768  decode.d0.loss_mask: 0.3330  decode.d0.loss_dice: 0.4483  decode.d1.loss_cls: 0.5243  decode.d1.loss_mask: 0.3290  decode.d1.loss_dice: 0.3979  decode.d2.loss_cls: 0.4388  decode.d2.loss_mask: 0.3461  decode.d2.loss_dice: 0.3990  decode.d3.loss_cls: 0.3643  decode.d3.loss_mask: 0.3519  decode.d3.loss_dice: 0.3915  decode.d4.loss_cls: 0.4610  decode.d4.loss_mask: 0.3486  decode.d4.loss_dice: 0.4055  decode.d5.loss_cls: 0.3975  decode.d5.loss_mask: 0.3478  decode.d5.loss_dice: 0.3951  decode.d6.loss_cls: 0.3462  decode.d6.loss_mask: 0.3506  decode.d6.loss_dice: 0.3998  decode.d7.loss_cls: 0.3704  decode.d7.loss_mask: 0.3499  decode.d7.loss_dice: 0.4102  decode.d8.loss_cls: 0.3075  decode.d8.loss_mask: 0.3410  decode.d8.loss_dice: 0.3993
07/31 18:48:59 - mmengine - INFO - Iter(train) [ 9450/80000]  base_lr: 8.9304e-05 lr: 8.9304e-06  eta: 9:29:45  time: 0.4850  data_time: 0.0093  memory: 5974  grad_norm: 133.4888  loss: 9.1504  decode.loss_cls: 0.3062  decode.loss_mask: 0.2402  decode.loss_dice: 0.2755  decode.d0.loss_cls: 1.2114  decode.d0.loss_mask: 0.2563  decode.d0.loss_dice: 0.2916  decode.d1.loss_cls: 0.3996  decode.d1.loss_mask: 0.2462  decode.d1.loss_dice: 0.2978  decode.d2.loss_cls: 0.2932  decode.d2.loss_mask: 0.2397  decode.d2.loss_dice: 0.2767  decode.d3.loss_cls: 0.2967  decode.d3.loss_mask: 0.2376  decode.d3.loss_dice: 0.2822  decode.d4.loss_cls: 0.2698  decode.d4.loss_mask: 0.2394  decode.d4.loss_dice: 0.2820  decode.d5.loss_cls: 0.2902  decode.d5.loss_mask: 0.2422  decode.d5.loss_dice: 0.2788  decode.d6.loss_cls: 0.2615  decode.d6.loss_mask: 0.2376  decode.d6.loss_dice: 0.2785  decode.d7.loss_cls: 0.2579  decode.d7.loss_mask: 0.2399  decode.d7.loss_dice: 0.2893  decode.d8.loss_cls: 0.3027  decode.d8.loss_mask: 0.2421  decode.d8.loss_dice: 0.2878
07/31 18:49:24 - mmengine - INFO - Iter(train) [ 9500/80000]  base_lr: 8.9247e-05 lr: 8.9247e-06  eta: 9:29:21  time: 0.4838  data_time: 0.0090  memory: 5916  grad_norm: 136.6000  loss: 6.8121  decode.loss_cls: 0.0574  decode.loss_mask: 0.2610  decode.loss_dice: 0.2492  decode.d0.loss_cls: 0.9240  decode.d0.loss_mask: 0.2817  decode.d0.loss_dice: 0.2760  decode.d1.loss_cls: 0.1200  decode.d1.loss_mask: 0.2724  decode.d1.loss_dice: 0.2698  decode.d2.loss_cls: 0.0748  decode.d2.loss_mask: 0.2620  decode.d2.loss_dice: 0.2632  decode.d3.loss_cls: 0.0776  decode.d3.loss_mask: 0.2589  decode.d3.loss_dice: 0.2552  decode.d4.loss_cls: 0.0618  decode.d4.loss_mask: 0.2587  decode.d4.loss_dice: 0.2599  decode.d5.loss_cls: 0.0594  decode.d5.loss_mask: 0.2650  decode.d5.loss_dice: 0.2681  decode.d6.loss_cls: 0.0665  decode.d6.loss_mask: 0.2619  decode.d6.loss_dice: 0.2574  decode.d7.loss_cls: 0.0566  decode.d7.loss_mask: 0.2649  decode.d7.loss_dice: 0.2582  decode.d8.loss_cls: 0.0555  decode.d8.loss_mask: 0.2654  decode.d8.loss_dice: 0.2496
07/31 18:49:48 - mmengine - INFO - Iter(train) [ 9550/80000]  base_lr: 8.9190e-05 lr: 8.9190e-06  eta: 9:28:56  time: 0.4846  data_time: 0.0093  memory: 5918  grad_norm: 191.6569  loss: 13.3164  decode.loss_cls: 0.3263  decode.loss_mask: 0.3791  decode.loss_dice: 0.4628  decode.d0.loss_cls: 1.2861  decode.d0.loss_mask: 0.4334  decode.d0.loss_dice: 0.5413  decode.d1.loss_cls: 0.4693  decode.d1.loss_mask: 0.3992  decode.d1.loss_dice: 0.5019  decode.d2.loss_cls: 0.4418  decode.d2.loss_mask: 0.3867  decode.d2.loss_dice: 0.4794  decode.d3.loss_cls: 0.2886  decode.d3.loss_mask: 0.3785  decode.d3.loss_dice: 0.4677  decode.d4.loss_cls: 0.2901  decode.d4.loss_mask: 0.3780  decode.d4.loss_dice: 0.4670  decode.d5.loss_cls: 0.3880  decode.d5.loss_mask: 0.3784  decode.d5.loss_dice: 0.5006  decode.d6.loss_cls: 0.3778  decode.d6.loss_mask: 0.3759  decode.d6.loss_dice: 0.4750  decode.d7.loss_cls: 0.3518  decode.d7.loss_mask: 0.3831  decode.d7.loss_dice: 0.4890  decode.d8.loss_cls: 0.3211  decode.d8.loss_mask: 0.3809  decode.d8.loss_dice: 0.5175
07/31 18:50:12 - mmengine - INFO - Iter(train) [ 9600/80000]  base_lr: 8.9133e-05 lr: 8.9133e-06  eta: 9:28:33  time: 0.4847  data_time: 0.0091  memory: 5916  grad_norm: 231.0188  loss: 11.0367  decode.loss_cls: 0.3187  decode.loss_mask: 0.2141  decode.loss_dice: 0.3667  decode.d0.loss_cls: 1.3874  decode.d0.loss_mask: 0.2404  decode.d0.loss_dice: 0.4086  decode.d1.loss_cls: 0.5619  decode.d1.loss_mask: 0.2240  decode.d1.loss_dice: 0.3528  decode.d2.loss_cls: 0.4657  decode.d2.loss_mask: 0.2167  decode.d2.loss_dice: 0.3536  decode.d3.loss_cls: 0.3976  decode.d3.loss_mask: 0.2158  decode.d3.loss_dice: 0.3578  decode.d4.loss_cls: 0.4827  decode.d4.loss_mask: 0.2158  decode.d4.loss_dice: 0.3611  decode.d5.loss_cls: 0.4169  decode.d5.loss_mask: 0.2182  decode.d5.loss_dice: 0.3524  decode.d6.loss_cls: 0.4206  decode.d6.loss_mask: 0.2192  decode.d6.loss_dice: 0.3484  decode.d7.loss_cls: 0.4064  decode.d7.loss_mask: 0.2258  decode.d7.loss_dice: 0.3750  decode.d8.loss_cls: 0.3287  decode.d8.loss_mask: 0.2203  decode.d8.loss_dice: 0.3634
07/31 18:50:36 - mmengine - INFO - Iter(train) [ 9650/80000]  base_lr: 8.9076e-05 lr: 8.9076e-06  eta: 9:28:09  time: 0.4841  data_time: 0.0091  memory: 5918  grad_norm: 148.7024  loss: 10.8252  decode.loss_cls: 0.2491  decode.loss_mask: 0.2700  decode.loss_dice: 0.4024  decode.d0.loss_cls: 1.2113  decode.d0.loss_mask: 0.2865  decode.d0.loss_dice: 0.4425  decode.d1.loss_cls: 0.4693  decode.d1.loss_mask: 0.2727  decode.d1.loss_dice: 0.4160  decode.d2.loss_cls: 0.3452  decode.d2.loss_mask: 0.3253  decode.d2.loss_dice: 0.4218  decode.d3.loss_cls: 0.2585  decode.d3.loss_mask: 0.2804  decode.d3.loss_dice: 0.3913  decode.d4.loss_cls: 0.3658  decode.d4.loss_mask: 0.2739  decode.d4.loss_dice: 0.3689  decode.d5.loss_cls: 0.2824  decode.d5.loss_mask: 0.2675  decode.d5.loss_dice: 0.3883  decode.d6.loss_cls: 0.3647  decode.d6.loss_mask: 0.2543  decode.d6.loss_dice: 0.3741  decode.d7.loss_cls: 0.2698  decode.d7.loss_mask: 0.2725  decode.d7.loss_dice: 0.3761  decode.d8.loss_cls: 0.2643  decode.d8.loss_mask: 0.2758  decode.d8.loss_dice: 0.3845
07/31 18:51:01 - mmengine - INFO - Iter(train) [ 9700/80000]  base_lr: 8.9019e-05 lr: 8.9019e-06  eta: 9:27:45  time: 0.4850  data_time: 0.0093  memory: 5916  grad_norm: 153.4630  loss: 11.0811  decode.loss_cls: 0.3288  decode.loss_mask: 0.3298  decode.loss_dice: 0.3845  decode.d0.loss_cls: 1.1936  decode.d0.loss_mask: 0.3091  decode.d0.loss_dice: 0.3956  decode.d1.loss_cls: 0.4028  decode.d1.loss_mask: 0.3230  decode.d1.loss_dice: 0.3709  decode.d2.loss_cls: 0.3859  decode.d2.loss_mask: 0.3115  decode.d2.loss_dice: 0.3850  decode.d3.loss_cls: 0.3058  decode.d3.loss_mask: 0.3039  decode.d3.loss_dice: 0.3488  decode.d4.loss_cls: 0.2691  decode.d4.loss_mask: 0.3046  decode.d4.loss_dice: 0.3622  decode.d5.loss_cls: 0.2547  decode.d5.loss_mask: 0.3282  decode.d5.loss_dice: 0.4025  decode.d6.loss_cls: 0.2861  decode.d6.loss_mask: 0.3427  decode.d6.loss_dice: 0.3831  decode.d7.loss_cls: 0.2761  decode.d7.loss_mask: 0.3276  decode.d7.loss_dice: 0.4218  decode.d8.loss_cls: 0.3110  decode.d8.loss_mask: 0.3194  decode.d8.loss_dice: 0.4129
07/31 18:51:25 - mmengine - INFO - Iter(train) [ 9750/80000]  base_lr: 8.8962e-05 lr: 8.8962e-06  eta: 9:27:21  time: 0.4844  data_time: 0.0093  memory: 5920  grad_norm: 104.1978  loss: 9.0263  decode.loss_cls: 0.1703  decode.loss_mask: 0.3088  decode.loss_dice: 0.2998  decode.d0.loss_cls: 1.1697  decode.d0.loss_mask: 0.3280  decode.d0.loss_dice: 0.3159  decode.d1.loss_cls: 0.2699  decode.d1.loss_mask: 0.3167  decode.d1.loss_dice: 0.3001  decode.d2.loss_cls: 0.2430  decode.d2.loss_mask: 0.3109  decode.d2.loss_dice: 0.3011  decode.d3.loss_cls: 0.1709  decode.d3.loss_mask: 0.3028  decode.d3.loss_dice: 0.2953  decode.d4.loss_cls: 0.1874  decode.d4.loss_mask: 0.3077  decode.d4.loss_dice: 0.2879  decode.d5.loss_cls: 0.1959  decode.d5.loss_mask: 0.3113  decode.d5.loss_dice: 0.2971  decode.d6.loss_cls: 0.1546  decode.d6.loss_mask: 0.3100  decode.d6.loss_dice: 0.2861  decode.d7.loss_cls: 0.1996  decode.d7.loss_mask: 0.3131  decode.d7.loss_dice: 0.2919  decode.d8.loss_cls: 0.1689  decode.d8.loss_mask: 0.3110  decode.d8.loss_dice: 0.3005
07/31 18:51:49 - mmengine - INFO - Iter(train) [ 9800/80000]  base_lr: 8.8905e-05 lr: 8.8905e-06  eta: 9:26:57  time: 0.4845  data_time: 0.0093  memory: 5937  grad_norm: 110.7722  loss: 9.4333  decode.loss_cls: 0.3062  decode.loss_mask: 0.2436  decode.loss_dice: 0.3082  decode.d0.loss_cls: 1.1338  decode.d0.loss_mask: 0.2587  decode.d0.loss_dice: 0.3019  decode.d1.loss_cls: 0.4058  decode.d1.loss_mask: 0.2505  decode.d1.loss_dice: 0.2953  decode.d2.loss_cls: 0.3651  decode.d2.loss_mask: 0.2486  decode.d2.loss_dice: 0.2816  decode.d3.loss_cls: 0.3568  decode.d3.loss_mask: 0.2464  decode.d3.loss_dice: 0.2708  decode.d4.loss_cls: 0.3230  decode.d4.loss_mask: 0.2489  decode.d4.loss_dice: 0.2749  decode.d5.loss_cls: 0.2806  decode.d5.loss_mask: 0.2492  decode.d5.loss_dice: 0.2612  decode.d6.loss_cls: 0.3088  decode.d6.loss_mask: 0.2460  decode.d6.loss_dice: 0.2655  decode.d7.loss_cls: 0.3187  decode.d7.loss_mask: 0.2479  decode.d7.loss_dice: 0.2795  decode.d8.loss_cls: 0.3390  decode.d8.loss_mask: 0.2450  decode.d8.loss_dice: 0.2719
07/31 18:52:13 - mmengine - INFO - Iter(train) [ 9850/80000]  base_lr: 8.8848e-05 lr: 8.8848e-06  eta: 9:26:33  time: 0.4854  data_time: 0.0091  memory: 5916  grad_norm: 90.6932  loss: 9.3980  decode.loss_cls: 0.2558  decode.loss_mask: 0.2610  decode.loss_dice: 0.3431  decode.d0.loss_cls: 1.2788  decode.d0.loss_mask: 0.2568  decode.d0.loss_dice: 0.3090  decode.d1.loss_cls: 0.3213  decode.d1.loss_mask: 0.2536  decode.d1.loss_dice: 0.3208  decode.d2.loss_cls: 0.2861  decode.d2.loss_mask: 0.2508  decode.d2.loss_dice: 0.3541  decode.d3.loss_cls: 0.1849  decode.d3.loss_mask: 0.2551  decode.d3.loss_dice: 0.3327  decode.d4.loss_cls: 0.1767  decode.d4.loss_mask: 0.2594  decode.d4.loss_dice: 0.3717  decode.d5.loss_cls: 0.2364  decode.d5.loss_mask: 0.2557  decode.d5.loss_dice: 0.3510  decode.d6.loss_cls: 0.1994  decode.d6.loss_mask: 0.2588  decode.d6.loss_dice: 0.3582  decode.d7.loss_cls: 0.2082  decode.d7.loss_mask: 0.2564  decode.d7.loss_dice: 0.3651  decode.d8.loss_cls: 0.2340  decode.d8.loss_mask: 0.2598  decode.d8.loss_dice: 0.3433
07/31 18:52:38 - mmengine - INFO - Iter(train) [ 9900/80000]  base_lr: 8.8791e-05 lr: 8.8791e-06  eta: 9:26:09  time: 0.4837  data_time: 0.0091  memory: 5916  grad_norm: 180.1347  loss: 11.7829  decode.loss_cls: 0.2477  decode.loss_mask: 0.3869  decode.loss_dice: 0.3875  decode.d0.loss_cls: 1.0473  decode.d0.loss_mask: 0.3901  decode.d0.loss_dice: 0.4651  decode.d1.loss_cls: 0.5251  decode.d1.loss_mask: 0.4021  decode.d1.loss_dice: 0.3874  decode.d2.loss_cls: 0.3176  decode.d2.loss_mask: 0.3930  decode.d2.loss_dice: 0.3962  decode.d3.loss_cls: 0.2870  decode.d3.loss_mask: 0.4024  decode.d3.loss_dice: 0.4109  decode.d4.loss_cls: 0.3057  decode.d4.loss_mask: 0.3858  decode.d4.loss_dice: 0.3879  decode.d5.loss_cls: 0.3598  decode.d5.loss_mask: 0.3923  decode.d5.loss_dice: 0.3870  decode.d6.loss_cls: 0.2652  decode.d6.loss_mask: 0.3899  decode.d6.loss_dice: 0.3880  decode.d7.loss_cls: 0.2399  decode.d7.loss_mask: 0.3916  decode.d7.loss_dice: 0.3978  decode.d8.loss_cls: 0.2513  decode.d8.loss_mask: 0.3955  decode.d8.loss_dice: 0.3988
07/31 18:53:02 - mmengine - INFO - Iter(train) [ 9950/80000]  base_lr: 8.8734e-05 lr: 8.8734e-06  eta: 9:25:45  time: 0.4835  data_time: 0.0090  memory: 5918  grad_norm: 190.6234  loss: 10.9190  decode.loss_cls: 0.3173  decode.loss_mask: 0.3142  decode.loss_dice: 0.3154  decode.d0.loss_cls: 1.1471  decode.d0.loss_mask: 0.3355  decode.d0.loss_dice: 0.3481  decode.d1.loss_cls: 0.4481  decode.d1.loss_mask: 0.3227  decode.d1.loss_dice: 0.3309  decode.d2.loss_cls: 0.3389  decode.d2.loss_mask: 0.3263  decode.d2.loss_dice: 0.3378  decode.d3.loss_cls: 0.3295  decode.d3.loss_mask: 0.3237  decode.d3.loss_dice: 0.3415  decode.d4.loss_cls: 0.3321  decode.d4.loss_mask: 0.3244  decode.d4.loss_dice: 0.3508  decode.d5.loss_cls: 0.3410  decode.d5.loss_mask: 0.3207  decode.d5.loss_dice: 0.3498  decode.d6.loss_cls: 0.3475  decode.d6.loss_mask: 0.3183  decode.d6.loss_dice: 0.3473  decode.d7.loss_cls: 0.3799  decode.d7.loss_mask: 0.3225  decode.d7.loss_dice: 0.3505  decode.d8.loss_cls: 0.3099  decode.d8.loss_mask: 0.3190  decode.d8.loss_dice: 0.3284
07/31 18:53:26 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250731_173226
07/31 18:53:26 - mmengine - INFO - Iter(train) [10000/80000]  base_lr: 8.8677e-05 lr: 8.8677e-06  eta: 9:25:20  time: 0.4845  data_time: 0.0090  memory: 5882  grad_norm: 206.7128  loss: 10.3070  decode.loss_cls: 0.2599  decode.loss_mask: 0.2564  decode.loss_dice: 0.3483  decode.d0.loss_cls: 1.1462  decode.d0.loss_mask: 0.2849  decode.d0.loss_dice: 0.4293  decode.d1.loss_cls: 0.4415  decode.d1.loss_mask: 0.2638  decode.d1.loss_dice: 0.3828  decode.d2.loss_cls: 0.4080  decode.d2.loss_mask: 0.2569  decode.d2.loss_dice: 0.3621  decode.d3.loss_cls: 0.2985  decode.d3.loss_mask: 0.2506  decode.d3.loss_dice: 0.3386  decode.d4.loss_cls: 0.2707  decode.d4.loss_mask: 0.2523  decode.d4.loss_dice: 0.3505  decode.d5.loss_cls: 0.3203  decode.d5.loss_mask: 0.2512  decode.d5.loss_dice: 0.3557  decode.d6.loss_cls: 0.3053  decode.d6.loss_mask: 0.2570  decode.d6.loss_dice: 0.3686  decode.d7.loss_cls: 0.3116  decode.d7.loss_mask: 0.2649  decode.d7.loss_dice: 0.3681  decode.d8.loss_cls: 0.2932  decode.d8.loss_mask: 0.2563  decode.d8.loss_dice: 0.3535
07/31 18:53:26 - mmengine - INFO - Saving checkpoint at 10000 iterations
07/31 18:53:52 - mmengine - INFO - Iter(train) [10050/80000]  base_lr: 8.8620e-05 lr: 8.8620e-06  eta: 9:25:11  time: 0.4840  data_time: 0.0090  memory: 5918  grad_norm: 97.4953  loss: 9.4802  decode.loss_cls: 0.2610  decode.loss_mask: 0.2935  decode.loss_dice: 0.3298  decode.d0.loss_cls: 1.0512  decode.d0.loss_mask: 0.3041  decode.d0.loss_dice: 0.3551  decode.d1.loss_cls: 0.3230  decode.d1.loss_mask: 0.2965  decode.d1.loss_dice: 0.3358  decode.d2.loss_cls: 0.1957  decode.d2.loss_mask: 0.2949  decode.d2.loss_dice: 0.3455  decode.d3.loss_cls: 0.2057  decode.d3.loss_mask: 0.2914  decode.d3.loss_dice: 0.3221  decode.d4.loss_cls: 0.2452  decode.d4.loss_mask: 0.2914  decode.d4.loss_dice: 0.3354  decode.d5.loss_cls: 0.2183  decode.d5.loss_mask: 0.2953  decode.d5.loss_dice: 0.3329  decode.d6.loss_cls: 0.2090  decode.d6.loss_mask: 0.2946  decode.d6.loss_dice: 0.3302  decode.d7.loss_cls: 0.2354  decode.d7.loss_mask: 0.2924  decode.d7.loss_dice: 0.3377  decode.d8.loss_cls: 0.2304  decode.d8.loss_mask: 0.2957  decode.d8.loss_dice: 0.3311
07/31 18:54:17 - mmengine - INFO - Iter(train) [10100/80000]  base_lr: 8.8563e-05 lr: 8.8563e-06  eta: 9:24:46  time: 0.4843  data_time: 0.0090  memory: 5936  grad_norm: 100.5939  loss: 7.6391  decode.loss_cls: 0.0616  decode.loss_mask: 0.2905  decode.loss_dice: 0.2816  decode.d0.loss_cls: 1.0600  decode.d0.loss_mask: 0.3172  decode.d0.loss_dice: 0.3509  decode.d1.loss_cls: 0.1476  decode.d1.loss_mask: 0.3041  decode.d1.loss_dice: 0.2863  decode.d2.loss_cls: 0.0960  decode.d2.loss_mask: 0.2867  decode.d2.loss_dice: 0.2841  decode.d3.loss_cls: 0.0834  decode.d3.loss_mask: 0.2824  decode.d3.loss_dice: 0.2782  decode.d4.loss_cls: 0.0808  decode.d4.loss_mask: 0.2839  decode.d4.loss_dice: 0.2816  decode.d5.loss_cls: 0.0850  decode.d5.loss_mask: 0.2905  decode.d5.loss_dice: 0.2842  decode.d6.loss_cls: 0.0717  decode.d6.loss_mask: 0.2854  decode.d6.loss_dice: 0.2774  decode.d7.loss_cls: 0.0722  decode.d7.loss_mask: 0.2869  decode.d7.loss_dice: 0.2841  decode.d8.loss_cls: 0.0699  decode.d8.loss_mask: 0.2911  decode.d8.loss_dice: 0.2838
07/31 18:54:41 - mmengine - INFO - Iter(train) [10150/80000]  base_lr: 8.8506e-05 lr: 8.8506e-06  eta: 9:24:22  time: 0.4843  data_time: 0.0091  memory: 5973  grad_norm: 118.0290  loss: 10.0984  decode.loss_cls: 0.1972  decode.loss_mask: 0.2847  decode.loss_dice: 0.3885  decode.d0.loss_cls: 1.0906  decode.d0.loss_mask: 0.3009  decode.d0.loss_dice: 0.4053  decode.d1.loss_cls: 0.3859  decode.d1.loss_mask: 0.2925  decode.d1.loss_dice: 0.3536  decode.d2.loss_cls: 0.2597  decode.d2.loss_mask: 0.2929  decode.d2.loss_dice: 0.3685  decode.d3.loss_cls: 0.2890  decode.d3.loss_mask: 0.2877  decode.d3.loss_dice: 0.3516  decode.d4.loss_cls: 0.2999  decode.d4.loss_mask: 0.2939  decode.d4.loss_dice: 0.3568  decode.d5.loss_cls: 0.2500  decode.d5.loss_mask: 0.2907  decode.d5.loss_dice: 0.3632  decode.d6.loss_cls: 0.2554  decode.d6.loss_mask: 0.2874  decode.d6.loss_dice: 0.3536  decode.d7.loss_cls: 0.2405  decode.d7.loss_mask: 0.2912  decode.d7.loss_dice: 0.3870  decode.d8.loss_cls: 0.2254  decode.d8.loss_mask: 0.2869  decode.d8.loss_dice: 0.3680
07/31 18:55:05 - mmengine - INFO - Iter(train) [10200/80000]  base_lr: 8.8449e-05 lr: 8.8449e-06  eta: 9:23:58  time: 0.4832  data_time: 0.0092  memory: 5881  grad_norm: 265.7989  loss: 12.4621  decode.loss_cls: 0.4299  decode.loss_mask: 0.3218  decode.loss_dice: 0.3485  decode.d0.loss_cls: 1.2353  decode.d0.loss_mask: 0.3420  decode.d0.loss_dice: 0.3611  decode.d1.loss_cls: 0.5680  decode.d1.loss_mask: 0.3218  decode.d1.loss_dice: 0.3596  decode.d2.loss_cls: 0.5660  decode.d2.loss_mask: 0.3115  decode.d2.loss_dice: 0.3593  decode.d3.loss_cls: 0.5404  decode.d3.loss_mask: 0.3121  decode.d3.loss_dice: 0.3340  decode.d4.loss_cls: 0.5393  decode.d4.loss_mask: 0.3111  decode.d4.loss_dice: 0.3472  decode.d5.loss_cls: 0.4841  decode.d5.loss_mask: 0.3216  decode.d5.loss_dice: 0.3570  decode.d6.loss_cls: 0.5273  decode.d6.loss_mask: 0.3196  decode.d6.loss_dice: 0.3438  decode.d7.loss_cls: 0.4377  decode.d7.loss_mask: 0.3224  decode.d7.loss_dice: 0.3441  decode.d8.loss_cls: 0.3910  decode.d8.loss_mask: 0.3198  decode.d8.loss_dice: 0.3849
07/31 18:55:29 - mmengine - INFO - Iter(train) [10250/80000]  base_lr: 8.8392e-05 lr: 8.8392e-06  eta: 9:23:33  time: 0.4834  data_time: 0.0091  memory: 5919  grad_norm: 131.3584  loss: 9.0078  decode.loss_cls: 0.2289  decode.loss_mask: 0.2977  decode.loss_dice: 0.3028  decode.d0.loss_cls: 0.9871  decode.d0.loss_mask: 0.3022  decode.d0.loss_dice: 0.3545  decode.d1.loss_cls: 0.2622  decode.d1.loss_mask: 0.2946  decode.d1.loss_dice: 0.3010  decode.d2.loss_cls: 0.2221  decode.d2.loss_mask: 0.2973  decode.d2.loss_dice: 0.2974  decode.d3.loss_cls: 0.2174  decode.d3.loss_mask: 0.2966  decode.d3.loss_dice: 0.3029  decode.d4.loss_cls: 0.2123  decode.d4.loss_mask: 0.2938  decode.d4.loss_dice: 0.3015  decode.d5.loss_cls: 0.2055  decode.d5.loss_mask: 0.2994  decode.d5.loss_dice: 0.2890  decode.d6.loss_cls: 0.1964  decode.d6.loss_mask: 0.2947  decode.d6.loss_dice: 0.2884  decode.d7.loss_cls: 0.2621  decode.d7.loss_mask: 0.2937  decode.d7.loss_dice: 0.3020  decode.d8.loss_cls: 0.2127  decode.d8.loss_mask: 0.2947  decode.d8.loss_dice: 0.2969
07/31 18:55:54 - mmengine - INFO - Iter(train) [10300/80000]  base_lr: 8.8335e-05 lr: 8.8335e-06  eta: 9:23:10  time: 0.4841  data_time: 0.0092  memory: 5896  grad_norm: 114.0140  loss: 10.7654  decode.loss_cls: 0.3127  decode.loss_mask: 0.2599  decode.loss_dice: 0.4133  decode.d0.loss_cls: 1.1951  decode.d0.loss_mask: 0.2527  decode.d0.loss_dice: 0.4688  decode.d1.loss_cls: 0.3982  decode.d1.loss_mask: 0.2517  decode.d1.loss_dice: 0.4070  decode.d2.loss_cls: 0.3165  decode.d2.loss_mask: 0.2466  decode.d2.loss_dice: 0.3948  decode.d3.loss_cls: 0.3323  decode.d3.loss_mask: 0.2465  decode.d3.loss_dice: 0.4033  decode.d4.loss_cls: 0.3049  decode.d4.loss_mask: 0.2456  decode.d4.loss_dice: 0.3810  decode.d5.loss_cls: 0.3099  decode.d5.loss_mask: 0.2467  decode.d5.loss_dice: 0.3887  decode.d6.loss_cls: 0.3619  decode.d6.loss_mask: 0.2458  decode.d6.loss_dice: 0.3797  decode.d7.loss_cls: 0.3780  decode.d7.loss_mask: 0.2517  decode.d7.loss_dice: 0.3913  decode.d8.loss_cls: 0.3450  decode.d8.loss_mask: 0.2522  decode.d8.loss_dice: 0.3837
07/31 18:56:18 - mmengine - INFO - Iter(train) [10350/80000]  base_lr: 8.8278e-05 lr: 8.8278e-06  eta: 9:22:45  time: 0.4844  data_time: 0.0092  memory: 5916  grad_norm: 143.0722  loss: 7.8556  decode.loss_cls: 0.1593  decode.loss_mask: 0.2570  decode.loss_dice: 0.2686  decode.d0.loss_cls: 1.0313  decode.d0.loss_mask: 0.2600  decode.d0.loss_dice: 0.3330  decode.d1.loss_cls: 0.2530  decode.d1.loss_mask: 0.2566  decode.d1.loss_dice: 0.2601  decode.d2.loss_cls: 0.1723  decode.d2.loss_mask: 0.2699  decode.d2.loss_dice: 0.2676  decode.d3.loss_cls: 0.1842  decode.d3.loss_mask: 0.2528  decode.d3.loss_dice: 0.2594  decode.d4.loss_cls: 0.1528  decode.d4.loss_mask: 0.2560  decode.d4.loss_dice: 0.2717  decode.d5.loss_cls: 0.1375  decode.d5.loss_mask: 0.2571  decode.d5.loss_dice: 0.2687  decode.d6.loss_cls: 0.1421  decode.d6.loss_mask: 0.2616  decode.d6.loss_dice: 0.2677  decode.d7.loss_cls: 0.1420  decode.d7.loss_mask: 0.2650  decode.d7.loss_dice: 0.2720  decode.d8.loss_cls: 0.1515  decode.d8.loss_mask: 0.2549  decode.d8.loss_dice: 0.2698
07/31 18:56:42 - mmengine - INFO - Iter(train) [10400/80000]  base_lr: 8.8221e-05 lr: 8.8221e-06  eta: 9:22:21  time: 0.4844  data_time: 0.0092  memory: 5881  grad_norm: 190.1733  loss: 12.3024  decode.loss_cls: 0.2476  decode.loss_mask: 0.4914  decode.loss_dice: 0.4153  decode.d0.loss_cls: 1.2685  decode.d0.loss_mask: 0.3662  decode.d0.loss_dice: 0.4708  decode.d1.loss_cls: 0.4424  decode.d1.loss_mask: 0.3014  decode.d1.loss_dice: 0.3964  decode.d2.loss_cls: 0.3508  decode.d2.loss_mask: 0.3437  decode.d2.loss_dice: 0.4055  decode.d3.loss_cls: 0.3869  decode.d3.loss_mask: 0.2772  decode.d3.loss_dice: 0.4059  decode.d4.loss_cls: 0.3744  decode.d4.loss_mask: 0.3379  decode.d4.loss_dice: 0.4298  decode.d5.loss_cls: 0.3644  decode.d5.loss_mask: 0.4049  decode.d5.loss_dice: 0.3891  decode.d6.loss_cls: 0.3676  decode.d6.loss_mask: 0.3683  decode.d6.loss_dice: 0.4213  decode.d7.loss_cls: 0.3535  decode.d7.loss_mask: 0.3452  decode.d7.loss_dice: 0.4014  decode.d8.loss_cls: 0.3845  decode.d8.loss_mask: 0.3774  decode.d8.loss_dice: 0.4127
07/31 18:57:06 - mmengine - INFO - Iter(train) [10450/80000]  base_lr: 8.8164e-05 lr: 8.8164e-06  eta: 9:21:56  time: 0.4841  data_time: 0.0092  memory: 5931  grad_norm: 564.0779  loss: 12.4044  decode.loss_cls: 0.2580  decode.loss_mask: 0.3744  decode.loss_dice: 0.3979  decode.d0.loss_cls: 1.2166  decode.d0.loss_mask: 0.3570  decode.d0.loss_dice: 0.4291  decode.d1.loss_cls: 0.3662  decode.d1.loss_mask: 0.3970  decode.d1.loss_dice: 0.4388  decode.d2.loss_cls: 0.4881  decode.d2.loss_mask: 0.3636  decode.d2.loss_dice: 0.4060  decode.d3.loss_cls: 0.3769  decode.d3.loss_mask: 0.3710  decode.d3.loss_dice: 0.3849  decode.d4.loss_cls: 0.3315  decode.d4.loss_mask: 0.4204  decode.d4.loss_dice: 0.3987  decode.d5.loss_cls: 0.3336  decode.d5.loss_mask: 0.4521  decode.d5.loss_dice: 0.4324  decode.d6.loss_cls: 0.3011  decode.d6.loss_mask: 0.3989  decode.d6.loss_dice: 0.3962  decode.d7.loss_cls: 0.3172  decode.d7.loss_mask: 0.4021  decode.d7.loss_dice: 0.3994  decode.d8.loss_cls: 0.3145  decode.d8.loss_mask: 0.4487  decode.d8.loss_dice: 0.4323
07/31 18:57:31 - mmengine - INFO - Iter(train) [10500/80000]  base_lr: 8.8107e-05 lr: 8.8107e-06  eta: 9:21:32  time: 0.4845  data_time: 0.0092  memory: 5897  grad_norm: 115.4320  loss: 10.3091  decode.loss_cls: 0.1168  decode.loss_mask: 0.3644  decode.loss_dice: 0.3842  decode.d0.loss_cls: 1.0769  decode.d0.loss_mask: 0.4088  decode.d0.loss_dice: 0.4385  decode.d1.loss_cls: 0.3045  decode.d1.loss_mask: 0.3599  decode.d1.loss_dice: 0.3842  decode.d2.loss_cls: 0.1508  decode.d2.loss_mask: 0.3659  decode.d2.loss_dice: 0.3859  decode.d3.loss_cls: 0.2003  decode.d3.loss_mask: 0.3851  decode.d3.loss_dice: 0.3753  decode.d4.loss_cls: 0.2148  decode.d4.loss_mask: 0.3632  decode.d4.loss_dice: 0.3747  decode.d5.loss_cls: 0.1882  decode.d5.loss_mask: 0.3699  decode.d5.loss_dice: 0.3845  decode.d6.loss_cls: 0.1548  decode.d6.loss_mask: 0.3696  decode.d6.loss_dice: 0.3728  decode.d7.loss_cls: 0.1458  decode.d7.loss_mask: 0.3805  decode.d7.loss_dice: 0.3881  decode.d8.loss_cls: 0.1221  decode.d8.loss_mask: 0.3778  decode.d8.loss_dice: 0.4008
07/31 18:57:55 - mmengine - INFO - Iter(train) [10550/80000]  base_lr: 8.8050e-05 lr: 8.8050e-06  eta: 9:21:08  time: 0.4850  data_time: 0.0093  memory: 5933  grad_norm: 141.3562  loss: 10.2356  decode.loss_cls: 0.2021  decode.loss_mask: 0.3718  decode.loss_dice: 0.3622  decode.d0.loss_cls: 1.1192  decode.d0.loss_mask: 0.3167  decode.d0.loss_dice: 0.3717  decode.d1.loss_cls: 0.3590  decode.d1.loss_mask: 0.3101  decode.d1.loss_dice: 0.3459  decode.d2.loss_cls: 0.3343  decode.d2.loss_mask: 0.3045  decode.d2.loss_dice: 0.3278  decode.d3.loss_cls: 0.2649  decode.d3.loss_mask: 0.3072  decode.d3.loss_dice: 0.3281  decode.d4.loss_cls: 0.3036  decode.d4.loss_mask: 0.3056  decode.d4.loss_dice: 0.3284  decode.d5.loss_cls: 0.2545  decode.d5.loss_mask: 0.3207  decode.d5.loss_dice: 0.3422  decode.d6.loss_cls: 0.2278  decode.d6.loss_mask: 0.3283  decode.d6.loss_dice: 0.3538  decode.d7.loss_cls: 0.2934  decode.d7.loss_mask: 0.3165  decode.d7.loss_dice: 0.3252  decode.d8.loss_cls: 0.2354  decode.d8.loss_mask: 0.3246  decode.d8.loss_dice: 0.3502
07/31 18:58:19 - mmengine - INFO - Iter(train) [10600/80000]  base_lr: 8.7993e-05 lr: 8.7993e-06  eta: 9:20:44  time: 0.4851  data_time: 0.0092  memory: 5916  grad_norm: 169.0113  loss: 10.4254  decode.loss_cls: 0.3632  decode.loss_mask: 0.2834  decode.loss_dice: 0.3191  decode.d0.loss_cls: 1.2005  decode.d0.loss_mask: 0.3044  decode.d0.loss_dice: 0.3885  decode.d1.loss_cls: 0.3580  decode.d1.loss_mask: 0.2871  decode.d1.loss_dice: 0.3528  decode.d2.loss_cls: 0.4028  decode.d2.loss_mask: 0.2773  decode.d2.loss_dice: 0.3100  decode.d3.loss_cls: 0.3137  decode.d3.loss_mask: 0.2814  decode.d3.loss_dice: 0.3059  decode.d4.loss_cls: 0.3268  decode.d4.loss_mask: 0.2834  decode.d4.loss_dice: 0.3116  decode.d5.loss_cls: 0.2821  decode.d5.loss_mask: 0.2819  decode.d5.loss_dice: 0.3194  decode.d6.loss_cls: 0.3107  decode.d6.loss_mask: 0.2782  decode.d6.loss_dice: 0.3151  decode.d7.loss_cls: 0.3728  decode.d7.loss_mask: 0.2842  decode.d7.loss_dice: 0.3219  decode.d8.loss_cls: 0.3810  decode.d8.loss_mask: 0.2820  decode.d8.loss_dice: 0.3264
07/31 18:58:43 - mmengine - INFO - Iter(train) [10650/80000]  base_lr: 8.7936e-05 lr: 8.7936e-06  eta: 9:20:19  time: 0.4850  data_time: 0.0093  memory: 5931  grad_norm: 181.0594  loss: 10.2413  decode.loss_cls: 0.3255  decode.loss_mask: 0.2325  decode.loss_dice: 0.3157  decode.d0.loss_cls: 1.3206  decode.d0.loss_mask: 0.2253  decode.d0.loss_dice: 0.3635  decode.d1.loss_cls: 0.4112  decode.d1.loss_mask: 0.2369  decode.d1.loss_dice: 0.3398  decode.d2.loss_cls: 0.4104  decode.d2.loss_mask: 0.2311  decode.d2.loss_dice: 0.3197  decode.d3.loss_cls: 0.3515  decode.d3.loss_mask: 0.2294  decode.d3.loss_dice: 0.3176  decode.d4.loss_cls: 0.3452  decode.d4.loss_mask: 0.2304  decode.d4.loss_dice: 0.3194  decode.d5.loss_cls: 0.3641  decode.d5.loss_mask: 0.2285  decode.d5.loss_dice: 0.3166  decode.d6.loss_cls: 0.3919  decode.d6.loss_mask: 0.2284  decode.d6.loss_dice: 0.3037  decode.d7.loss_cls: 0.4206  decode.d7.loss_mask: 0.2265  decode.d7.loss_dice: 0.3044  decode.d8.loss_cls: 0.3486  decode.d8.loss_mask: 0.2377  decode.d8.loss_dice: 0.3447
07/31 18:59:08 - mmengine - INFO - Iter(train) [10700/80000]  base_lr: 8.7879e-05 lr: 8.7879e-06  eta: 9:19:55  time: 0.4853  data_time: 0.0093  memory: 5899  grad_norm: 150.4958  loss: 11.4355  decode.loss_cls: 0.3406  decode.loss_mask: 0.3361  decode.loss_dice: 0.3606  decode.d0.loss_cls: 1.2563  decode.d0.loss_mask: 0.3267  decode.d0.loss_dice: 0.4369  decode.d1.loss_cls: 0.5277  decode.d1.loss_mask: 0.3309  decode.d1.loss_dice: 0.3801  decode.d2.loss_cls: 0.3338  decode.d2.loss_mask: 0.3378  decode.d2.loss_dice: 0.3559  decode.d3.loss_cls: 0.3415  decode.d3.loss_mask: 0.3334  decode.d3.loss_dice: 0.3591  decode.d4.loss_cls: 0.3480  decode.d4.loss_mask: 0.3313  decode.d4.loss_dice: 0.3566  decode.d5.loss_cls: 0.3159  decode.d5.loss_mask: 0.3340  decode.d5.loss_dice: 0.3499  decode.d6.loss_cls: 0.3141  decode.d6.loss_mask: 0.3262  decode.d6.loss_dice: 0.3549  decode.d7.loss_cls: 0.3177  decode.d7.loss_mask: 0.3298  decode.d7.loss_dice: 0.3519  decode.d8.loss_cls: 0.3644  decode.d8.loss_mask: 0.3282  decode.d8.loss_dice: 0.3551
07/31 18:59:32 - mmengine - INFO - Iter(train) [10750/80000]  base_lr: 8.7822e-05 lr: 8.7822e-06  eta: 9:19:31  time: 0.4852  data_time: 0.0094  memory: 5881  grad_norm: 186.9211  loss: 10.4173  decode.loss_cls: 0.2629  decode.loss_mask: 0.2969  decode.loss_dice: 0.3673  decode.d0.loss_cls: 1.0491  decode.d0.loss_mask: 0.3134  decode.d0.loss_dice: 0.4000  decode.d1.loss_cls: 0.3825  decode.d1.loss_mask: 0.3019  decode.d1.loss_dice: 0.3776  decode.d2.loss_cls: 0.3296  decode.d2.loss_mask: 0.3031  decode.d2.loss_dice: 0.3886  decode.d3.loss_cls: 0.2366  decode.d3.loss_mask: 0.2989  decode.d3.loss_dice: 0.3679  decode.d4.loss_cls: 0.2464  decode.d4.loss_mask: 0.3000  decode.d4.loss_dice: 0.3834  decode.d5.loss_cls: 0.2648  decode.d5.loss_mask: 0.2989  decode.d5.loss_dice: 0.3911  decode.d6.loss_cls: 0.2868  decode.d6.loss_mask: 0.2979  decode.d6.loss_dice: 0.3758  decode.d7.loss_cls: 0.3103  decode.d7.loss_mask: 0.2974  decode.d7.loss_dice: 0.3787  decode.d8.loss_cls: 0.2328  decode.d8.loss_mask: 0.2992  decode.d8.loss_dice: 0.3771
07/31 18:59:56 - mmengine - INFO - Iter(train) [10800/80000]  base_lr: 8.7765e-05 lr: 8.7765e-06  eta: 9:19:08  time: 0.4838  data_time: 0.0091  memory: 5895  grad_norm: 211.7528  loss: 9.5622  decode.loss_cls: 0.2888  decode.loss_mask: 0.2659  decode.loss_dice: 0.3352  decode.d0.loss_cls: 1.0246  decode.d0.loss_mask: 0.3075  decode.d0.loss_dice: 0.3619  decode.d1.loss_cls: 0.4055  decode.d1.loss_mask: 0.2632  decode.d1.loss_dice: 0.3171  decode.d2.loss_cls: 0.2823  decode.d2.loss_mask: 0.2656  decode.d2.loss_dice: 0.3353  decode.d3.loss_cls: 0.2490  decode.d3.loss_mask: 0.2553  decode.d3.loss_dice: 0.3223  decode.d4.loss_cls: 0.2535  decode.d4.loss_mask: 0.2562  decode.d4.loss_dice: 0.3022  decode.d5.loss_cls: 0.2679  decode.d5.loss_mask: 0.2638  decode.d5.loss_dice: 0.3262  decode.d6.loss_cls: 0.3044  decode.d6.loss_mask: 0.2692  decode.d6.loss_dice: 0.3330  decode.d7.loss_cls: 0.2854  decode.d7.loss_mask: 0.2607  decode.d7.loss_dice: 0.3215  decode.d8.loss_cls: 0.2507  decode.d8.loss_mask: 0.2684  decode.d8.loss_dice: 0.3194
07/31 19:00:20 - mmengine - INFO - Iter(train) [10850/80000]  base_lr: 8.7708e-05 lr: 8.7708e-06  eta: 9:18:43  time: 0.4852  data_time: 0.0093  memory: 5896  grad_norm: 142.8475  loss: 8.8976  decode.loss_cls: 0.2044  decode.loss_mask: 0.2483  decode.loss_dice: 0.3249  decode.d0.loss_cls: 1.1025  decode.d0.loss_mask: 0.2677  decode.d0.loss_dice: 0.3762  decode.d1.loss_cls: 0.3954  decode.d1.loss_mask: 0.2444  decode.d1.loss_dice: 0.3466  decode.d2.loss_cls: 0.2196  decode.d2.loss_mask: 0.2434  decode.d2.loss_dice: 0.3388  decode.d3.loss_cls: 0.2201  decode.d3.loss_mask: 0.2429  decode.d3.loss_dice: 0.3319  decode.d4.loss_cls: 0.1955  decode.d4.loss_mask: 0.2435  decode.d4.loss_dice: 0.3187  decode.d5.loss_cls: 0.1818  decode.d5.loss_mask: 0.2402  decode.d5.loss_dice: 0.3205  decode.d6.loss_cls: 0.1697  decode.d6.loss_mask: 0.2391  decode.d6.loss_dice: 0.3183  decode.d7.loss_cls: 0.2174  decode.d7.loss_mask: 0.2406  decode.d7.loss_dice: 0.3145  decode.d8.loss_cls: 0.2186  decode.d8.loss_mask: 0.2475  decode.d8.loss_dice: 0.3248
07/31 19:00:45 - mmengine - INFO - Iter(train) [10900/80000]  base_lr: 8.7650e-05 lr: 8.7650e-06  eta: 9:18:19  time: 0.4843  data_time: 0.0092  memory: 5918  grad_norm: 484.9374  loss: 11.8846  decode.loss_cls: 0.3395  decode.loss_mask: 0.3541  decode.loss_dice: 0.3949  decode.d0.loss_cls: 1.1332  decode.d0.loss_mask: 0.3344  decode.d0.loss_dice: 0.3865  decode.d1.loss_cls: 0.4069  decode.d1.loss_mask: 0.3282  decode.d1.loss_dice: 0.3507  decode.d2.loss_cls: 0.3865  decode.d2.loss_mask: 0.3366  decode.d2.loss_dice: 0.3758  decode.d3.loss_cls: 0.4147  decode.d3.loss_mask: 0.3497  decode.d3.loss_dice: 0.3774  decode.d4.loss_cls: 0.3716  decode.d4.loss_mask: 0.3581  decode.d4.loss_dice: 0.4061  decode.d5.loss_cls: 0.4363  decode.d5.loss_mask: 0.3338  decode.d5.loss_dice: 0.3855  decode.d6.loss_cls: 0.3382  decode.d6.loss_mask: 0.3595  decode.d6.loss_dice: 0.4049  decode.d7.loss_cls: 0.3380  decode.d7.loss_mask: 0.3550  decode.d7.loss_dice: 0.4165  decode.d8.loss_cls: 0.3254  decode.d8.loss_mask: 0.3628  decode.d8.loss_dice: 0.4237
07/31 19:01:09 - mmengine - INFO - Iter(train) [10950/80000]  base_lr: 8.7593e-05 lr: 8.7593e-06  eta: 9:17:55  time: 0.4855  data_time: 0.0092  memory: 5919  grad_norm: 111.0760  loss: 8.9732  decode.loss_cls: 0.2570  decode.loss_mask: 0.2285  decode.loss_dice: 0.3033  decode.d0.loss_cls: 1.0807  decode.d0.loss_mask: 0.2489  decode.d0.loss_dice: 0.3687  decode.d1.loss_cls: 0.2836  decode.d1.loss_mask: 0.2409  decode.d1.loss_dice: 0.3237  decode.d2.loss_cls: 0.2762  decode.d2.loss_mask: 0.2451  decode.d2.loss_dice: 0.3272  decode.d3.loss_cls: 0.2697  decode.d3.loss_mask: 0.2332  decode.d3.loss_dice: 0.2969  decode.d4.loss_cls: 0.2290  decode.d4.loss_mask: 0.2503  decode.d4.loss_dice: 0.3259  decode.d5.loss_cls: 0.2383  decode.d5.loss_mask: 0.2521  decode.d5.loss_dice: 0.3175  decode.d6.loss_cls: 0.2399  decode.d6.loss_mask: 0.2292  decode.d6.loss_dice: 0.3091  decode.d7.loss_cls: 0.2538  decode.d7.loss_mask: 0.2315  decode.d7.loss_dice: 0.3102  decode.d8.loss_cls: 0.2300  decode.d8.loss_mask: 0.2333  decode.d8.loss_dice: 0.3396
07/31 19:01:33 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250731_173226
07/31 19:01:33 - mmengine - INFO - Iter(train) [11000/80000]  base_lr: 8.7536e-05 lr: 8.7536e-06  eta: 9:17:31  time: 0.4877  data_time: 0.0093  memory: 5895  grad_norm: 187.2191  loss: 9.5462  decode.loss_cls: 0.3099  decode.loss_mask: 0.2556  decode.loss_dice: 0.2914  decode.d0.loss_cls: 1.2527  decode.d0.loss_mask: 0.2574  decode.d0.loss_dice: 0.3035  decode.d1.loss_cls: 0.2968  decode.d1.loss_mask: 0.2555  decode.d1.loss_dice: 0.2742  decode.d2.loss_cls: 0.3247  decode.d2.loss_mask: 0.2552  decode.d2.loss_dice: 0.2869  decode.d3.loss_cls: 0.3369  decode.d3.loss_mask: 0.2447  decode.d3.loss_dice: 0.2881  decode.d4.loss_cls: 0.3103  decode.d4.loss_mask: 0.2478  decode.d4.loss_dice: 0.2857  decode.d5.loss_cls: 0.3317  decode.d5.loss_mask: 0.2504  decode.d5.loss_dice: 0.2816  decode.d6.loss_cls: 0.3428  decode.d6.loss_mask: 0.2532  decode.d6.loss_dice: 0.2829  decode.d7.loss_cls: 0.3343  decode.d7.loss_mask: 0.2585  decode.d7.loss_dice: 0.2674  decode.d8.loss_cls: 0.3199  decode.d8.loss_mask: 0.2545  decode.d8.loss_dice: 0.2919
07/31 19:01:57 - mmengine - INFO - Iter(train) [11050/80000]  base_lr: 8.7479e-05 lr: 8.7479e-06  eta: 9:17:07  time: 0.4845  data_time: 0.0092  memory: 5918  grad_norm: 98.8009  loss: 7.2207  decode.loss_cls: 0.0854  decode.loss_mask: 0.2471  decode.loss_dice: 0.2822  decode.d0.loss_cls: 0.9098  decode.d0.loss_mask: 0.2597  decode.d0.loss_dice: 0.3048  decode.d1.loss_cls: 0.1503  decode.d1.loss_mask: 0.2549  decode.d1.loss_dice: 0.2877  decode.d2.loss_cls: 0.1198  decode.d2.loss_mask: 0.2479  decode.d2.loss_dice: 0.2794  decode.d3.loss_cls: 0.1097  decode.d3.loss_mask: 0.2507  decode.d3.loss_dice: 0.2741  decode.d4.loss_cls: 0.0938  decode.d4.loss_mask: 0.2484  decode.d4.loss_dice: 0.2838  decode.d5.loss_cls: 0.1005  decode.d5.loss_mask: 0.2494  decode.d5.loss_dice: 0.2854  decode.d6.loss_cls: 0.0957  decode.d6.loss_mask: 0.2492  decode.d6.loss_dice: 0.2784  decode.d7.loss_cls: 0.1014  decode.d7.loss_mask: 0.2464  decode.d7.loss_dice: 0.2885  decode.d8.loss_cls: 0.1018  decode.d8.loss_mask: 0.2476  decode.d8.loss_dice: 0.2869
07/31 19:02:22 - mmengine - INFO - Iter(train) [11100/80000]  base_lr: 8.7422e-05 lr: 8.7422e-06  eta: 9:16:44  time: 0.4848  data_time: 0.0094  memory: 5936  grad_norm: 165.4807  loss: 7.9355  decode.loss_cls: 0.1380  decode.loss_mask: 0.2603  decode.loss_dice: 0.2587  decode.d0.loss_cls: 1.0207  decode.d0.loss_mask: 0.2921  decode.d0.loss_dice: 0.2639  decode.d1.loss_cls: 0.2974  decode.d1.loss_mask: 0.2621  decode.d1.loss_dice: 0.2551  decode.d2.loss_cls: 0.2120  decode.d2.loss_mask: 0.2560  decode.d2.loss_dice: 0.2467  decode.d3.loss_cls: 0.1764  decode.d3.loss_mask: 0.2564  decode.d3.loss_dice: 0.2593  decode.d4.loss_cls: 0.1602  decode.d4.loss_mask: 0.2553  decode.d4.loss_dice: 0.2572  decode.d5.loss_cls: 0.1875  decode.d5.loss_mask: 0.2578  decode.d5.loss_dice: 0.2607  decode.d6.loss_cls: 0.1874  decode.d6.loss_mask: 0.2564  decode.d6.loss_dice: 0.2545  decode.d7.loss_cls: 0.1870  decode.d7.loss_mask: 0.2609  decode.d7.loss_dice: 0.2643  decode.d8.loss_cls: 0.1779  decode.d8.loss_mask: 0.2532  decode.d8.loss_dice: 0.2604
07/31 19:02:46 - mmengine - INFO - Iter(train) [11150/80000]  base_lr: 8.7365e-05 lr: 8.7365e-06  eta: 9:16:19  time: 0.4848  data_time: 0.0095  memory: 5881  grad_norm: 197.0682  loss: 8.9771  decode.loss_cls: 0.2519  decode.loss_mask: 0.3090  decode.loss_dice: 0.2836  decode.d0.loss_cls: 1.1949  decode.d0.loss_mask: 0.3194  decode.d0.loss_dice: 0.2743  decode.d1.loss_cls: 0.3121  decode.d1.loss_mask: 0.3177  decode.d1.loss_dice: 0.2850  decode.d2.loss_cls: 0.1805  decode.d2.loss_mask: 0.3163  decode.d2.loss_dice: 0.2870  decode.d3.loss_cls: 0.1659  decode.d3.loss_mask: 0.3202  decode.d3.loss_dice: 0.2807  decode.d4.loss_cls: 0.1847  decode.d4.loss_mask: 0.3135  decode.d4.loss_dice: 0.2574  decode.d5.loss_cls: 0.1920  decode.d5.loss_mask: 0.3171  decode.d5.loss_dice: 0.2547  decode.d6.loss_cls: 0.1992  decode.d6.loss_mask: 0.3207  decode.d6.loss_dice: 0.2657  decode.d7.loss_cls: 0.1888  decode.d7.loss_mask: 0.3107  decode.d7.loss_dice: 0.2659  decode.d8.loss_cls: 0.2086  decode.d8.loss_mask: 0.3164  decode.d8.loss_dice: 0.2830
07/31 19:03:10 - mmengine - INFO - Iter(train) [11200/80000]  base_lr: 8.7308e-05 lr: 8.7308e-06  eta: 9:15:55  time: 0.4842  data_time: 0.0095  memory: 5896  grad_norm: 137.8915  loss: 10.6692  decode.loss_cls: 0.1969  decode.loss_mask: 0.4323  decode.loss_dice: 0.3353  decode.d0.loss_cls: 0.9358  decode.d0.loss_mask: 0.4473  decode.d0.loss_dice: 0.3755  decode.d1.loss_cls: 0.2506  decode.d1.loss_mask: 0.4520  decode.d1.loss_dice: 0.3659  decode.d2.loss_cls: 0.2707  decode.d2.loss_mask: 0.4339  decode.d2.loss_dice: 0.3605  decode.d3.loss_cls: 0.1709  decode.d3.loss_mask: 0.4344  decode.d3.loss_dice: 0.3466  decode.d4.loss_cls: 0.1839  decode.d4.loss_mask: 0.4312  decode.d4.loss_dice: 0.3473  decode.d5.loss_cls: 0.1759  decode.d5.loss_mask: 0.4333  decode.d5.loss_dice: 0.3653  decode.d6.loss_cls: 0.2008  decode.d6.loss_mask: 0.4347  decode.d6.loss_dice: 0.3488  decode.d7.loss_cls: 0.1715  decode.d7.loss_mask: 0.4380  decode.d7.loss_dice: 0.3518  decode.d8.loss_cls: 0.2201  decode.d8.loss_mask: 0.4319  decode.d8.loss_dice: 0.3264
07/31 19:03:35 - mmengine - INFO - Iter(train) [11250/80000]  base_lr: 8.7251e-05 lr: 8.7251e-06  eta: 9:15:31  time: 0.4847  data_time: 0.0094  memory: 5916  grad_norm: 227.0949  loss: 9.8493  decode.loss_cls: 0.1961  decode.loss_mask: 0.2953  decode.loss_dice: 0.3692  decode.d0.loss_cls: 1.0328  decode.d0.loss_mask: 0.3203  decode.d0.loss_dice: 0.3930  decode.d1.loss_cls: 0.2940  decode.d1.loss_mask: 0.2957  decode.d1.loss_dice: 0.3737  decode.d2.loss_cls: 0.2192  decode.d2.loss_mask: 0.3000  decode.d2.loss_dice: 0.3763  decode.d3.loss_cls: 0.2186  decode.d3.loss_mask: 0.2954  decode.d3.loss_dice: 0.3742  decode.d4.loss_cls: 0.2184  decode.d4.loss_mask: 0.2989  decode.d4.loss_dice: 0.3804  decode.d5.loss_cls: 0.2078  decode.d5.loss_mask: 0.2938  decode.d5.loss_dice: 0.3683  decode.d6.loss_cls: 0.2315  decode.d6.loss_mask: 0.2955  decode.d6.loss_dice: 0.3642  decode.d7.loss_cls: 0.2518  decode.d7.loss_mask: 0.3002  decode.d7.loss_dice: 0.3626  decode.d8.loss_cls: 0.2489  decode.d8.loss_mask: 0.3050  decode.d8.loss_dice: 0.3682
07/31 19:03:59 - mmengine - INFO - Iter(train) [11300/80000]  base_lr: 8.7194e-05 lr: 8.7194e-06  eta: 9:15:07  time: 0.4854  data_time: 0.0096  memory: 5934  grad_norm: 166.0351  loss: 8.5491  decode.loss_cls: 0.1297  decode.loss_mask: 0.2632  decode.loss_dice: 0.3054  decode.d0.loss_cls: 1.1075  decode.d0.loss_mask: 0.2551  decode.d0.loss_dice: 0.2969  decode.d1.loss_cls: 0.2997  decode.d1.loss_mask: 0.2701  decode.d1.loss_dice: 0.3036  decode.d2.loss_cls: 0.1928  decode.d2.loss_mask: 0.2546  decode.d2.loss_dice: 0.3081  decode.d3.loss_cls: 0.1686  decode.d3.loss_mask: 0.2758  decode.d3.loss_dice: 0.3116  decode.d4.loss_cls: 0.1977  decode.d4.loss_mask: 0.2624  decode.d4.loss_dice: 0.3149  decode.d5.loss_cls: 0.1924  decode.d5.loss_mask: 0.2680  decode.d5.loss_dice: 0.3013  decode.d6.loss_cls: 0.2471  decode.d6.loss_mask: 0.2599  decode.d6.loss_dice: 0.2865  decode.d7.loss_cls: 0.1953  decode.d7.loss_mask: 0.2761  decode.d7.loss_dice: 0.3074  decode.d8.loss_cls: 0.1367  decode.d8.loss_mask: 0.2629  decode.d8.loss_dice: 0.2983
07/31 19:04:23 - mmengine - INFO - Iter(train) [11350/80000]  base_lr: 8.7137e-05 lr: 8.7137e-06  eta: 9:14:42  time: 0.4845  data_time: 0.0093  memory: 5918  grad_norm: 134.6618  loss: 13.1110  decode.loss_cls: 0.5725  decode.loss_mask: 0.3117  decode.loss_dice: 0.3910  decode.d0.loss_cls: 1.3063  decode.d0.loss_mask: 0.3225  decode.d0.loss_dice: 0.4467  decode.d1.loss_cls: 0.4955  decode.d1.loss_mask: 0.3121  decode.d1.loss_dice: 0.3984  decode.d2.loss_cls: 0.4679  decode.d2.loss_mask: 0.3164  decode.d2.loss_dice: 0.3749  decode.d3.loss_cls: 0.4840  decode.d3.loss_mask: 0.3170  decode.d3.loss_dice: 0.3752  decode.d4.loss_cls: 0.5346  decode.d4.loss_mask: 0.3114  decode.d4.loss_dice: 0.3738  decode.d5.loss_cls: 0.5270  decode.d5.loss_mask: 0.3120  decode.d5.loss_dice: 0.3868  decode.d6.loss_cls: 0.4904  decode.d6.loss_mask: 0.3136  decode.d6.loss_dice: 0.4328  decode.d7.loss_cls: 0.5606  decode.d7.loss_mask: 0.3036  decode.d7.loss_dice: 0.3956  decode.d8.loss_cls: 0.5499  decode.d8.loss_mask: 0.3090  decode.d8.loss_dice: 0.4177
07/31 19:04:47 - mmengine - INFO - Iter(train) [11400/80000]  base_lr: 8.7079e-05 lr: 8.7079e-06  eta: 9:14:18  time: 0.4844  data_time: 0.0095  memory: 5916  grad_norm: 185.4172  loss: 11.2302  decode.loss_cls: 0.3266  decode.loss_mask: 0.3216  decode.loss_dice: 0.3401  decode.d0.loss_cls: 1.1863  decode.d0.loss_mask: 0.3556  decode.d0.loss_dice: 0.3909  decode.d1.loss_cls: 0.3652  decode.d1.loss_mask: 0.3477  decode.d1.loss_dice: 0.4213  decode.d2.loss_cls: 0.3326  decode.d2.loss_mask: 0.3352  decode.d2.loss_dice: 0.3704  decode.d3.loss_cls: 0.4104  decode.d3.loss_mask: 0.3001  decode.d3.loss_dice: 0.3543  decode.d4.loss_cls: 0.3269  decode.d4.loss_mask: 0.3075  decode.d4.loss_dice: 0.3554  decode.d5.loss_cls: 0.3720  decode.d5.loss_mask: 0.3305  decode.d5.loss_dice: 0.3451  decode.d6.loss_cls: 0.3139  decode.d6.loss_mask: 0.3281  decode.d6.loss_dice: 0.3497  decode.d7.loss_cls: 0.3071  decode.d7.loss_mask: 0.3237  decode.d7.loss_dice: 0.3668  decode.d8.loss_cls: 0.3534  decode.d8.loss_mask: 0.3345  decode.d8.loss_dice: 0.3574
07/31 19:05:11 - mmengine - INFO - Iter(train) [11450/80000]  base_lr: 8.7022e-05 lr: 8.7022e-06  eta: 9:13:54  time: 0.4852  data_time: 0.0094  memory: 5918  grad_norm: 143.9855  loss: 7.7998  decode.loss_cls: 0.1690  decode.loss_mask: 0.2210  decode.loss_dice: 0.2690  decode.d0.loss_cls: 1.0568  decode.d0.loss_mask: 0.2475  decode.d0.loss_dice: 0.3366  decode.d1.loss_cls: 0.2891  decode.d1.loss_mask: 0.2317  decode.d1.loss_dice: 0.2697  decode.d2.loss_cls: 0.2215  decode.d2.loss_mask: 0.2220  decode.d2.loss_dice: 0.2563  decode.d3.loss_cls: 0.1997  decode.d3.loss_mask: 0.2213  decode.d3.loss_dice: 0.2570  decode.d4.loss_cls: 0.1951  decode.d4.loss_mask: 0.2213  decode.d4.loss_dice: 0.2749  decode.d5.loss_cls: 0.1895  decode.d5.loss_mask: 0.2229  decode.d5.loss_dice: 0.2613  decode.d6.loss_cls: 0.1616  decode.d6.loss_mask: 0.2206  decode.d6.loss_dice: 0.2629  decode.d7.loss_cls: 0.1618  decode.d7.loss_mask: 0.2193  decode.d7.loss_dice: 0.2608  decode.d8.loss_cls: 0.1910  decode.d8.loss_mask: 0.2199  decode.d8.loss_dice: 0.2689
07/31 19:05:36 - mmengine - INFO - Iter(train) [11500/80000]  base_lr: 8.6965e-05 lr: 8.6965e-06  eta: 9:13:29  time: 0.4844  data_time: 0.0093  memory: 5896  grad_norm: 117.2100  loss: 8.9011  decode.loss_cls: 0.2539  decode.loss_mask: 0.2601  decode.loss_dice: 0.3026  decode.d0.loss_cls: 0.9955  decode.d0.loss_mask: 0.2710  decode.d0.loss_dice: 0.3584  decode.d1.loss_cls: 0.2990  decode.d1.loss_mask: 0.2654  decode.d1.loss_dice: 0.3217  decode.d2.loss_cls: 0.2657  decode.d2.loss_mask: 0.2578  decode.d2.loss_dice: 0.3088  decode.d3.loss_cls: 0.2433  decode.d3.loss_mask: 0.2601  decode.d3.loss_dice: 0.2949  decode.d4.loss_cls: 0.1946  decode.d4.loss_mask: 0.2650  decode.d4.loss_dice: 0.3156  decode.d5.loss_cls: 0.2281  decode.d5.loss_mask: 0.2619  decode.d5.loss_dice: 0.3052  decode.d6.loss_cls: 0.2258  decode.d6.loss_mask: 0.2583  decode.d6.loss_dice: 0.3134  decode.d7.loss_cls: 0.2262  decode.d7.loss_mask: 0.2609  decode.d7.loss_dice: 0.3035  decode.d8.loss_cls: 0.2245  decode.d8.loss_mask: 0.2593  decode.d8.loss_dice: 0.3006
07/31 19:06:00 - mmengine - INFO - Iter(train) [11550/80000]  base_lr: 8.6908e-05 lr: 8.6908e-06  eta: 9:13:05  time: 0.4846  data_time: 0.0094  memory: 5971  grad_norm: 274.8274  loss: 11.2772  decode.loss_cls: 0.3116  decode.loss_mask: 0.3522  decode.loss_dice: 0.3801  decode.d0.loss_cls: 1.2457  decode.d0.loss_mask: 0.2826  decode.d0.loss_dice: 0.4247  decode.d1.loss_cls: 0.4983  decode.d1.loss_mask: 0.2658  decode.d1.loss_dice: 0.3434  decode.d2.loss_cls: 0.4644  decode.d2.loss_mask: 0.2859  decode.d2.loss_dice: 0.3589  decode.d3.loss_cls: 0.3476  decode.d3.loss_mask: 0.2892  decode.d3.loss_dice: 0.3500  decode.d4.loss_cls: 0.3735  decode.d4.loss_mask: 0.2846  decode.d4.loss_dice: 0.3556  decode.d5.loss_cls: 0.4124  decode.d5.loss_mask: 0.2567  decode.d5.loss_dice: 0.3448  decode.d6.loss_cls: 0.3817  decode.d6.loss_mask: 0.2827  decode.d6.loss_dice: 0.3655  decode.d7.loss_cls: 0.3549  decode.d7.loss_mask: 0.3359  decode.d7.loss_dice: 0.3640  decode.d8.loss_cls: 0.3260  decode.d8.loss_mask: 0.2730  decode.d8.loss_dice: 0.3654
07/31 19:06:24 - mmengine - INFO - Iter(train) [11600/80000]  base_lr: 8.6851e-05 lr: 8.6851e-06  eta: 9:12:41  time: 0.4849  data_time: 0.0093  memory: 5986  grad_norm: 213.1342  loss: 11.6647  decode.loss_cls: 0.4131  decode.loss_mask: 0.2377  decode.loss_dice: 0.3680  decode.d0.loss_cls: 1.3311  decode.d0.loss_mask: 0.2400  decode.d0.loss_dice: 0.4177  decode.d1.loss_cls: 0.5234  decode.d1.loss_mask: 0.2586  decode.d1.loss_dice: 0.4094  decode.d2.loss_cls: 0.4271  decode.d2.loss_mask: 0.2592  decode.d2.loss_dice: 0.3938  decode.d3.loss_cls: 0.4302  decode.d3.loss_mask: 0.2803  decode.d3.loss_dice: 0.3753  decode.d4.loss_cls: 0.3886  decode.d4.loss_mask: 0.2538  decode.d4.loss_dice: 0.3853  decode.d5.loss_cls: 0.4390  decode.d5.loss_mask: 0.2422  decode.d5.loss_dice: 0.3792  decode.d6.loss_cls: 0.4324  decode.d6.loss_mask: 0.2350  decode.d6.loss_dice: 0.3883  decode.d7.loss_cls: 0.4273  decode.d7.loss_mask: 0.2457  decode.d7.loss_dice: 0.4016  decode.d8.loss_cls: 0.4667  decode.d8.loss_mask: 0.2334  decode.d8.loss_dice: 0.3812
07/31 19:06:48 - mmengine - INFO - Iter(train) [11650/80000]  base_lr: 8.6794e-05 lr: 8.6794e-06  eta: 9:12:17  time: 0.4849  data_time: 0.0093  memory: 5933  grad_norm: 206.2961  loss: 10.8606  decode.loss_cls: 0.3653  decode.loss_mask: 0.3037  decode.loss_dice: 0.3786  decode.d0.loss_cls: 1.0737  decode.d0.loss_mask: 0.3037  decode.d0.loss_dice: 0.4296  decode.d1.loss_cls: 0.4874  decode.d1.loss_mask: 0.2927  decode.d1.loss_dice: 0.3788  decode.d2.loss_cls: 0.3301  decode.d2.loss_mask: 0.2828  decode.d2.loss_dice: 0.3736  decode.d3.loss_cls: 0.3170  decode.d3.loss_mask: 0.2835  decode.d3.loss_dice: 0.3763  decode.d4.loss_cls: 0.3034  decode.d4.loss_mask: 0.2826  decode.d4.loss_dice: 0.3679  decode.d5.loss_cls: 0.2842  decode.d5.loss_mask: 0.2944  decode.d5.loss_dice: 0.3606  decode.d6.loss_cls: 0.3081  decode.d6.loss_mask: 0.3021  decode.d6.loss_dice: 0.3824  decode.d7.loss_cls: 0.3100  decode.d7.loss_mask: 0.3024  decode.d7.loss_dice: 0.3808  decode.d8.loss_cls: 0.2891  decode.d8.loss_mask: 0.3074  decode.d8.loss_dice: 0.4085
07/31 19:07:13 - mmengine - INFO - Iter(train) [11700/80000]  base_lr: 8.6737e-05 lr: 8.6737e-06  eta: 9:11:53  time: 0.4852  data_time: 0.0094  memory: 5934  grad_norm: 127.2457  loss: 7.6105  decode.loss_cls: 0.1971  decode.loss_mask: 0.2427  decode.loss_dice: 0.2916  decode.d0.loss_cls: 1.0118  decode.d0.loss_mask: 0.2375  decode.d0.loss_dice: 0.3062  decode.d1.loss_cls: 0.2160  decode.d1.loss_mask: 0.2436  decode.d1.loss_dice: 0.3002  decode.d2.loss_cls: 0.1658  decode.d2.loss_mask: 0.2450  decode.d2.loss_dice: 0.2976  decode.d3.loss_cls: 0.0903  decode.d3.loss_mask: 0.2379  decode.d3.loss_dice: 0.2711  decode.d4.loss_cls: 0.1304  decode.d4.loss_mask: 0.2393  decode.d4.loss_dice: 0.2823  decode.d5.loss_cls: 0.1320  decode.d5.loss_mask: 0.2340  decode.d5.loss_dice: 0.2743  decode.d6.loss_cls: 0.1366  decode.d6.loss_mask: 0.2359  decode.d6.loss_dice: 0.2762  decode.d7.loss_cls: 0.1341  decode.d7.loss_mask: 0.2415  decode.d7.loss_dice: 0.2814  decode.d8.loss_cls: 0.1384  decode.d8.loss_mask: 0.2414  decode.d8.loss_dice: 0.2785
07/31 19:07:37 - mmengine - INFO - Iter(train) [11750/80000]  base_lr: 8.6679e-05 lr: 8.6679e-06  eta: 9:11:29  time: 0.4859  data_time: 0.0094  memory: 5931  grad_norm: 165.6840  loss: 10.4199  decode.loss_cls: 0.2333  decode.loss_mask: 0.2593  decode.loss_dice: 0.3987  decode.d0.loss_cls: 1.3292  decode.d0.loss_mask: 0.2760  decode.d0.loss_dice: 0.4525  decode.d1.loss_cls: 0.3457  decode.d1.loss_mask: 0.2734  decode.d1.loss_dice: 0.4111  decode.d2.loss_cls: 0.3338  decode.d2.loss_mask: 0.2696  decode.d2.loss_dice: 0.4071  decode.d3.loss_cls: 0.2767  decode.d3.loss_mask: 0.2664  decode.d3.loss_dice: 0.3983  decode.d4.loss_cls: 0.2508  decode.d4.loss_mask: 0.2662  decode.d4.loss_dice: 0.3888  decode.d5.loss_cls: 0.3060  decode.d5.loss_mask: 0.2634  decode.d5.loss_dice: 0.3952  decode.d6.loss_cls: 0.2124  decode.d6.loss_mask: 0.2589  decode.d6.loss_dice: 0.3827  decode.d7.loss_cls: 0.2368  decode.d7.loss_mask: 0.2592  decode.d7.loss_dice: 0.3826  decode.d8.loss_cls: 0.2353  decode.d8.loss_mask: 0.2591  decode.d8.loss_dice: 0.3913
07/31 19:08:01 - mmengine - INFO - Iter(train) [11800/80000]  base_lr: 8.6622e-05 lr: 8.6622e-06  eta: 9:11:05  time: 0.4859  data_time: 0.0096  memory: 5896  grad_norm: 156.4282  loss: 8.4334  decode.loss_cls: 0.1437  decode.loss_mask: 0.2585  decode.loss_dice: 0.3220  decode.d0.loss_cls: 1.0497  decode.d0.loss_mask: 0.2707  decode.d0.loss_dice: 0.3799  decode.d1.loss_cls: 0.2469  decode.d1.loss_mask: 0.2597  decode.d1.loss_dice: 0.3417  decode.d2.loss_cls: 0.1589  decode.d2.loss_mask: 0.2607  decode.d2.loss_dice: 0.3082  decode.d3.loss_cls: 0.1813  decode.d3.loss_mask: 0.2609  decode.d3.loss_dice: 0.2983  decode.d4.loss_cls: 0.1925  decode.d4.loss_mask: 0.2622  decode.d4.loss_dice: 0.3192  decode.d5.loss_cls: 0.1449  decode.d5.loss_mask: 0.2590  decode.d5.loss_dice: 0.3124  decode.d6.loss_cls: 0.1871  decode.d6.loss_mask: 0.2576  decode.d6.loss_dice: 0.3046  decode.d7.loss_cls: 0.1726  decode.d7.loss_mask: 0.2593  decode.d7.loss_dice: 0.3077  decode.d8.loss_cls: 0.1454  decode.d8.loss_mask: 0.2565  decode.d8.loss_dice: 0.3114
07/31 19:08:26 - mmengine - INFO - Iter(train) [11850/80000]  base_lr: 8.6565e-05 lr: 8.6565e-06  eta: 9:10:40  time: 0.4844  data_time: 0.0092  memory: 5934  grad_norm: 156.2564  loss: 9.2737  decode.loss_cls: 0.3299  decode.loss_mask: 0.2085  decode.loss_dice: 0.3031  decode.d0.loss_cls: 1.0512  decode.d0.loss_mask: 0.2171  decode.d0.loss_dice: 0.3432  decode.d1.loss_cls: 0.4387  decode.d1.loss_mask: 0.2148  decode.d1.loss_dice: 0.3151  decode.d2.loss_cls: 0.3551  decode.d2.loss_mask: 0.2127  decode.d2.loss_dice: 0.2923  decode.d3.loss_cls: 0.3418  decode.d3.loss_mask: 0.2106  decode.d3.loss_dice: 0.2894  decode.d4.loss_cls: 0.3213  decode.d4.loss_mask: 0.2048  decode.d4.loss_dice: 0.2732  decode.d5.loss_cls: 0.3474  decode.d5.loss_mask: 0.2059  decode.d5.loss_dice: 0.2719  decode.d6.loss_cls: 0.3313  decode.d6.loss_mask: 0.2061  decode.d6.loss_dice: 0.2830  decode.d7.loss_cls: 0.3250  decode.d7.loss_mask: 0.2118  decode.d7.loss_dice: 0.3124  decode.d8.loss_cls: 0.3376  decode.d8.loss_mask: 0.2093  decode.d8.loss_dice: 0.3094
