==========================================
SLURM_JOB_ID = 2466247
SLURM_NODELIST = gnode080
SLURM_JOB_GPUS = 2
==========================================
07/25 17:22:54 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.23 (main, Jun  5 2025, 13:40:20) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1953804578
    GPU 0: NVIDIA GeForce RTX 2080 Ti
    CUDA_HOME: /opt/cuda-12.1/
    NVCC: Cuda compilation tools, release 12.1, V12.1.66
    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
    PyTorch: 2.1.2
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1953804578
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

07/25 17:22:54 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=16, enable=False)
backbone_embed_multi = dict(decay_mult=0.0, lr_mult=0.1)
backbone_norm_multi = dict(decay_mult=0.0, lr_mult=0.1)
crop_size = (
    512,
    1024,
)
custom_keys = dict({
    'absolute_pos_embed':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone':
    dict(decay_mult=1.0, lr_mult=0.1),
    'backbone.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.patch_embed.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.2.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.3.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.4.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.5.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'level_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_feat':
    dict(decay_mult=0.0, lr_mult=1.0),
    'relative_position_bias_table':
    dict(decay_mult=0.0, lr_mult=0.1)
})
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        512,
        1024,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    test_cfg=dict(size_divisor=32),
    type='SegDataPreProcessor')
data_root = '/scratch/seg_benchmark/seg_FULL/'
dataset_type = 'YourDataset_BIG'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False, interval=5000, save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'))
default_scope = 'mmseg'
depths = [
    2,
    2,
    6,
    2,
]
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
img_suffix = '.jpg'
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        attn_drop_rate=0.0,
        depths=[
            2,
            2,
            6,
            2,
        ],
        drop_path_rate=0.3,
        drop_rate=0.0,
        embed_dims=96,
        frozen_stages=-1,
        init_cfg=dict(
            checkpoint=
            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth',
            type='Pretrained'),
        mlp_ratio=4,
        num_heads=[
            3,
            6,
            12,
            24,
        ],
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        patch_norm=True,
        qk_scale=None,
        qkv_bias=True,
        type='SwinTransformer',
        window_size=7,
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            1024,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        test_cfg=dict(size_divisor=32),
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            96,
            192,
            384,
            768,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=57,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 57
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict({
            'absolute_pos_embed':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone':
            dict(decay_mult=1.0, lr_mult=0.1),
            'backbone.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.patch_embed.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.2.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.3.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.4.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.5.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'level_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_feat':
            dict(decay_mult=0.0, lr_mult=1.0),
            'relative_position_bias_table':
            dict(decay_mult=0.0, lr_mult=0.1)
        }),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=80000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth'
resume = True
seg_map_suffix = '.png'
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/seg_benchmark/seg_FULL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2048,
        1024,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(
    max_iters=80000, type='IterBasedTrainLoop', val_interval=80000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        data_prefix=dict(img_path='train/images', seg_map_path='train/masks'),
        data_root='/scratch/seg_benchmark/seg_FULL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                max_size=4096,
                resize_type='ResizeShortestEdge',
                scales=[
                    512,
                    614,
                    716,
                    819,
                    921,
                    1024,
                    1126,
                    1228,
                    1331,
                    1433,
                    1536,
                    1638,
                    1740,
                    1843,
                    1945,
                    2048,
                ],
                type='RandomChoiceResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    512,
                    1024,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        max_size=4096,
        resize_type='ResizeShortestEdge',
        scales=[
            512,
            614,
            716,
            819,
            921,
            1024,
            1126,
            1228,
            1331,
            1433,
            1536,
            1638,
            1740,
            1843,
            1945,
            2048,
        ],
        type='RandomChoiceResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        1024,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/seg_benchmark/seg_FULL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '/scratch/seg_benchmark/FULL/mask2former_swin_T'

07/25 17:23:01 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
07/25 17:23:01 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:weight_decay=0.05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:decay_mult=1.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr=1e-05
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:weight_decay=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr_mult=0.1
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:decay_mult=0.0
07/25 17:23:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:decay_mult=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:decay_mult=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:decay_mult=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:weight_decay=0.05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:decay_mult=1.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:weight_decay=0.05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:decay_mult=1.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:decay_mult=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:decay_mult=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:decay_mult=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:decay_mult=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:weight_decay=0.05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:decay_mult=1.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:weight_decay=0.05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:decay_mult=1.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:decay_mult=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:decay_mult=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:decay_mult=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:decay_mult=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:decay_mult=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:decay_mult=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:decay_mult=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr=1e-05
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr_mult=0.1
07/25 17:23:03 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:decay_mult=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
07/25 17:23:03 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
07/25 17:23:03 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth
07/25 17:23:04 - mmengine - INFO - Auto resumed from the latest checkpoint /scratch/seg_benchmark/FULL/mask2former_swin_T/iter_5000.pth.
Loads checkpoint by local backend from path: /scratch/seg_benchmark/FULL/mask2former_swin_T/iter_5000.pth
07/25 17:23:04 - mmengine - INFO - Load checkpoint from /scratch/seg_benchmark/FULL/mask2former_swin_T/iter_5000.pth
07/25 17:23:04 - mmengine - INFO - resumed epoch: 0, iter: 5000
07/25 17:23:04 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
07/25 17:23:04 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
07/25 17:23:04 - mmengine - INFO - Checkpoints will be saved to /scratch/seg_benchmark/FULL/mask2former_swin_T.
07/25 17:23:04 - mmengine - WARNING - Advance dataloader 5000 steps to skip data that has already been trained
/home2/yasharora120/miniconda3/envs/mmseg/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400441250/work/aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
07/25 17:27:07 - mmengine - INFO - Iter(train) [ 5050/80000]  base_lr: 9.4301e-05 lr: 9.4301e-06  eta: 4 days, 5:08:50  time: 0.4780  data_time: 0.0079  memory: 9304  grad_norm: 136.8821  loss: 15.8184  decode.loss_cls: 0.7720  decode.loss_mask: 0.3108  decode.loss_dice: 0.3843  decode.d0.loss_cls: 1.7961  decode.d0.loss_mask: 0.3200  decode.d0.loss_dice: 0.4711  decode.d1.loss_cls: 0.9435  decode.d1.loss_mask: 0.2975  decode.d1.loss_dice: 0.3730  decode.d2.loss_cls: 0.7308  decode.d2.loss_mask: 0.2990  decode.d2.loss_dice: 0.3626  decode.d3.loss_cls: 0.7545  decode.d3.loss_mask: 0.2973  decode.d3.loss_dice: 0.3601  decode.d4.loss_cls: 0.7344  decode.d4.loss_mask: 0.3008  decode.d4.loss_dice: 0.3906  decode.d5.loss_cls: 0.7475  decode.d5.loss_mask: 0.2951  decode.d5.loss_dice: 0.3652  decode.d6.loss_cls: 0.8494  decode.d6.loss_mask: 0.3040  decode.d6.loss_dice: 0.3735  decode.d7.loss_cls: 0.8002  decode.d7.loss_mask: 0.3020  decode.d7.loss_dice: 0.3827  decode.d8.loss_cls: 0.7935  decode.d8.loss_mask: 0.3041  decode.d8.loss_dice: 0.4029
07/25 17:27:31 - mmengine - INFO - Iter(train) [ 5100/80000]  base_lr: 9.4245e-05 lr: 9.4245e-06  eta: 2 days, 7:33:46  time: 0.4793  data_time: 0.0081  memory: 5906  grad_norm: 459.4050  loss: 16.0667  decode.loss_cls: 0.6945  decode.loss_mask: 0.3794  decode.loss_dice: 0.4151  decode.d0.loss_cls: 1.7437  decode.d0.loss_mask: 0.3820  decode.d0.loss_dice: 0.4615  decode.d1.loss_cls: 0.8097  decode.d1.loss_mask: 0.3646  decode.d1.loss_dice: 0.3812  decode.d2.loss_cls: 0.7494  decode.d2.loss_mask: 0.3565  decode.d2.loss_dice: 0.4115  decode.d3.loss_cls: 0.6900  decode.d3.loss_mask: 0.3514  decode.d3.loss_dice: 0.4035  decode.d4.loss_cls: 0.7115  decode.d4.loss_mask: 0.3565  decode.d4.loss_dice: 0.4068  decode.d5.loss_cls: 0.7289  decode.d5.loss_mask: 0.3694  decode.d5.loss_dice: 0.3830  decode.d6.loss_cls: 0.7189  decode.d6.loss_mask: 0.3770  decode.d6.loss_dice: 0.4344  decode.d7.loss_cls: 0.7224  decode.d7.loss_mask: 0.3614  decode.d7.loss_dice: 0.3890  decode.d8.loss_cls: 0.7693  decode.d8.loss_mask: 0.3558  decode.d8.loss_dice: 0.3882
07/25 17:27:55 - mmengine - INFO - Iter(train) [ 5150/80000]  base_lr: 9.4188e-05 lr: 9.4188e-06  eta: 1 day, 16:21:07  time: 0.4814  data_time: 0.0080  memory: 5885  grad_norm: 133.5845  loss: 12.9582  decode.loss_cls: 0.5505  decode.loss_mask: 0.2717  decode.loss_dice: 0.3175  decode.d0.loss_cls: 1.5091  decode.d0.loss_mask: 0.2906  decode.d0.loss_dice: 0.4182  decode.d1.loss_cls: 0.7069  decode.d1.loss_mask: 0.2709  decode.d1.loss_dice: 0.3124  decode.d2.loss_cls: 0.6295  decode.d2.loss_mask: 0.2649  decode.d2.loss_dice: 0.3280  decode.d3.loss_cls: 0.5794  decode.d3.loss_mask: 0.2701  decode.d3.loss_dice: 0.3134  decode.d4.loss_cls: 0.6102  decode.d4.loss_mask: 0.2629  decode.d4.loss_dice: 0.3167  decode.d5.loss_cls: 0.6048  decode.d5.loss_mask: 0.2674  decode.d5.loss_dice: 0.3258  decode.d6.loss_cls: 0.6392  decode.d6.loss_mask: 0.2737  decode.d6.loss_dice: 0.3028  decode.d7.loss_cls: 0.5990  decode.d7.loss_mask: 0.2682  decode.d7.loss_dice: 0.3024  decode.d8.loss_cls: 0.5706  decode.d8.loss_mask: 0.2661  decode.d8.loss_dice: 0.3153
07/25 17:28:19 - mmengine - INFO - Iter(train) [ 5200/80000]  base_lr: 9.4132e-05 lr: 9.4132e-06  eta: 1 day, 8:45:00  time: 0.4828  data_time: 0.0082  memory: 5906  grad_norm: 173.5078  loss: 16.9705  decode.loss_cls: 0.7592  decode.loss_mask: 0.3777  decode.loss_dice: 0.4524  decode.d0.loss_cls: 1.8239  decode.d0.loss_mask: 0.3797  decode.d0.loss_dice: 0.5504  decode.d1.loss_cls: 1.0629  decode.d1.loss_mask: 0.3394  decode.d1.loss_dice: 0.4042  decode.d2.loss_cls: 0.7639  decode.d2.loss_mask: 0.3279  decode.d2.loss_dice: 0.4232  decode.d3.loss_cls: 0.7384  decode.d3.loss_mask: 0.3425  decode.d3.loss_dice: 0.4093  decode.d4.loss_cls: 0.7128  decode.d4.loss_mask: 0.3470  decode.d4.loss_dice: 0.4130  decode.d5.loss_cls: 0.7594  decode.d5.loss_mask: 0.3230  decode.d5.loss_dice: 0.3982  decode.d6.loss_cls: 0.7918  decode.d6.loss_mask: 0.3202  decode.d6.loss_dice: 0.4271  decode.d7.loss_cls: 0.8034  decode.d7.loss_mask: 0.3854  decode.d7.loss_dice: 0.4488  decode.d8.loss_cls: 0.7987  decode.d8.loss_mask: 0.4426  decode.d8.loss_dice: 0.4444
07/25 17:28:44 - mmengine - INFO - Iter(train) [ 5250/80000]  base_lr: 9.4075e-05 lr: 9.4075e-06  eta: 1 day, 4:11:27  time: 0.4839  data_time: 0.0084  memory: 5906  grad_norm: 173.8104  loss: 13.2724  decode.loss_cls: 0.5372  decode.loss_mask: 0.3036  decode.loss_dice: 0.3066  decode.d0.loss_cls: 1.6217  decode.d0.loss_mask: 0.3378  decode.d0.loss_dice: 0.3743  decode.d1.loss_cls: 0.6962  decode.d1.loss_mask: 0.3266  decode.d1.loss_dice: 0.2980  decode.d2.loss_cls: 0.6244  decode.d2.loss_mask: 0.3102  decode.d2.loss_dice: 0.3070  decode.d3.loss_cls: 0.5975  decode.d3.loss_mask: 0.3266  decode.d3.loss_dice: 0.3190  decode.d4.loss_cls: 0.5535  decode.d4.loss_mask: 0.3240  decode.d4.loss_dice: 0.3181  decode.d5.loss_cls: 0.6165  decode.d5.loss_mask: 0.3126  decode.d5.loss_dice: 0.3092  decode.d6.loss_cls: 0.5769  decode.d6.loss_mask: 0.3153  decode.d6.loss_dice: 0.3285  decode.d7.loss_cls: 0.5439  decode.d7.loss_mask: 0.3196  decode.d7.loss_dice: 0.3330  decode.d8.loss_cls: 0.5126  decode.d8.loss_mask: 0.3126  decode.d8.loss_dice: 0.3093
07/25 17:29:08 - mmengine - INFO - Iter(train) [ 5300/80000]  base_lr: 9.4018e-05 lr: 9.4018e-06  eta: 1 day, 1:08:52  time: 0.4836  data_time: 0.0082  memory: 5888  grad_norm: 174.2087  loss: 19.1249  decode.loss_cls: 0.9814  decode.loss_mask: 0.3059  decode.loss_dice: 0.4012  decode.d0.loss_cls: 2.1845  decode.d0.loss_mask: 0.3547  decode.d0.loss_dice: 0.5542  decode.d1.loss_cls: 1.0992  decode.d1.loss_mask: 0.3496  decode.d1.loss_dice: 0.4411  decode.d2.loss_cls: 1.0260  decode.d2.loss_mask: 0.3471  decode.d2.loss_dice: 0.4532  decode.d3.loss_cls: 0.9867  decode.d3.loss_mask: 0.3655  decode.d3.loss_dice: 0.4428  decode.d4.loss_cls: 1.0375  decode.d4.loss_mask: 0.3419  decode.d4.loss_dice: 0.4574  decode.d5.loss_cls: 1.0149  decode.d5.loss_mask: 0.3304  decode.d5.loss_dice: 0.4452  decode.d6.loss_cls: 0.9829  decode.d6.loss_mask: 0.3302  decode.d6.loss_dice: 0.3954  decode.d7.loss_cls: 1.0014  decode.d7.loss_mask: 0.3360  decode.d7.loss_dice: 0.4248  decode.d8.loss_cls: 1.0147  decode.d8.loss_mask: 0.3003  decode.d8.loss_dice: 0.4188
07/25 17:29:32 - mmengine - INFO - Iter(train) [ 5350/80000]  base_lr: 9.3962e-05 lr: 9.3962e-06  eta: 22:58:19  time: 0.4829  data_time: 0.0084  memory: 5923  grad_norm: 175.0712  loss: 13.7010  decode.loss_cls: 0.5148  decode.loss_mask: 0.3296  decode.loss_dice: 0.3728  decode.d0.loss_cls: 1.5162  decode.d0.loss_mask: 0.3598  decode.d0.loss_dice: 0.4053  decode.d1.loss_cls: 0.7572  decode.d1.loss_mask: 0.3034  decode.d1.loss_dice: 0.3581  decode.d2.loss_cls: 0.6116  decode.d2.loss_mask: 0.3094  decode.d2.loss_dice: 0.3542  decode.d3.loss_cls: 0.5647  decode.d3.loss_mask: 0.2993  decode.d3.loss_dice: 0.3469  decode.d4.loss_cls: 0.5761  decode.d4.loss_mask: 0.3018  decode.d4.loss_dice: 0.3453  decode.d5.loss_cls: 0.5947  decode.d5.loss_mask: 0.3022  decode.d5.loss_dice: 0.3456  decode.d6.loss_cls: 0.5946  decode.d6.loss_mask: 0.3143  decode.d6.loss_dice: 0.3613  decode.d7.loss_cls: 0.6429  decode.d7.loss_mask: 0.3022  decode.d7.loss_dice: 0.3359  decode.d8.loss_cls: 0.5966  decode.d8.loss_mask: 0.3152  decode.d8.loss_dice: 0.3690
07/25 17:29:56 - mmengine - INFO - Iter(train) [ 5400/80000]  base_lr: 9.3905e-05 lr: 9.3905e-06  eta: 21:20:16  time: 0.4830  data_time: 0.0083  memory: 5885  grad_norm: 230.7899  loss: 16.1960  decode.loss_cls: 0.7380  decode.loss_mask: 0.3846  decode.loss_dice: 0.4018  decode.d0.loss_cls: 1.6768  decode.d0.loss_mask: 0.4276  decode.d0.loss_dice: 0.4489  decode.d1.loss_cls: 0.8458  decode.d1.loss_mask: 0.3835  decode.d1.loss_dice: 0.3892  decode.d2.loss_cls: 0.7265  decode.d2.loss_mask: 0.3684  decode.d2.loss_dice: 0.3934  decode.d3.loss_cls: 0.6947  decode.d3.loss_mask: 0.3816  decode.d3.loss_dice: 0.3830  decode.d4.loss_cls: 0.7103  decode.d4.loss_mask: 0.3787  decode.d4.loss_dice: 0.3912  decode.d5.loss_cls: 0.7302  decode.d5.loss_mask: 0.3904  decode.d5.loss_dice: 0.3944  decode.d6.loss_cls: 0.7676  decode.d6.loss_mask: 0.3728  decode.d6.loss_dice: 0.3597  decode.d7.loss_cls: 0.7578  decode.d7.loss_mask: 0.3979  decode.d7.loss_dice: 0.3918  decode.d8.loss_cls: 0.7185  decode.d8.loss_mask: 0.3874  decode.d8.loss_dice: 0.4034
07/25 17:30:20 - mmengine - INFO - Iter(train) [ 5450/80000]  base_lr: 9.3848e-05 lr: 9.3848e-06  eta: 20:03:58  time: 0.4841  data_time: 0.0083  memory: 5912  grad_norm: 169.9136  loss: 13.8227  decode.loss_cls: 0.6027  decode.loss_mask: 0.2902  decode.loss_dice: 0.3855  decode.d0.loss_cls: 1.8116  decode.d0.loss_mask: 0.3263  decode.d0.loss_dice: 0.4883  decode.d1.loss_cls: 0.7552  decode.d1.loss_mask: 0.2759  decode.d1.loss_dice: 0.3683  decode.d2.loss_cls: 0.6231  decode.d2.loss_mask: 0.2776  decode.d2.loss_dice: 0.3430  decode.d3.loss_cls: 0.5430  decode.d3.loss_mask: 0.2800  decode.d3.loss_dice: 0.3578  decode.d4.loss_cls: 0.5620  decode.d4.loss_mask: 0.2847  decode.d4.loss_dice: 0.3765  decode.d5.loss_cls: 0.6021  decode.d5.loss_mask: 0.2794  decode.d5.loss_dice: 0.3525  decode.d6.loss_cls: 0.5466  decode.d6.loss_mask: 0.2785  decode.d6.loss_dice: 0.3409  decode.d7.loss_cls: 0.5115  decode.d7.loss_mask: 0.2849  decode.d7.loss_dice: 0.3787  decode.d8.loss_cls: 0.6323  decode.d8.loss_mask: 0.2865  decode.d8.loss_dice: 0.3769
07/25 17:30:44 - mmengine - INFO - Iter(train) [ 5500/80000]  base_lr: 9.3792e-05 lr: 9.3792e-06  eta: 19:02:48  time: 0.4829  data_time: 0.0081  memory: 5889  grad_norm: 141.8794  loss: 16.0484  decode.loss_cls: 0.8617  decode.loss_mask: 0.2439  decode.loss_dice: 0.3898  decode.d0.loss_cls: 1.7397  decode.d0.loss_mask: 0.2770  decode.d0.loss_dice: 0.4504  decode.d1.loss_cls: 1.0576  decode.d1.loss_mask: 0.2451  decode.d1.loss_dice: 0.3727  decode.d2.loss_cls: 0.8949  decode.d2.loss_mask: 0.2425  decode.d2.loss_dice: 0.3628  decode.d3.loss_cls: 0.8287  decode.d3.loss_mask: 0.2440  decode.d3.loss_dice: 0.3756  decode.d4.loss_cls: 0.7816  decode.d4.loss_mask: 0.2534  decode.d4.loss_dice: 0.3906  decode.d5.loss_cls: 0.8481  decode.d5.loss_mask: 0.2393  decode.d5.loss_dice: 0.3793  decode.d6.loss_cls: 0.8611  decode.d6.loss_mask: 0.2507  decode.d6.loss_dice: 0.3717  decode.d7.loss_cls: 0.7884  decode.d7.loss_mask: 0.2743  decode.d7.loss_dice: 0.3949  decode.d8.loss_cls: 0.9035  decode.d8.loss_mask: 0.3049  decode.d8.loss_dice: 0.4203
07/25 17:31:09 - mmengine - INFO - Iter(train) [ 5550/80000]  base_lr: 9.3735e-05 lr: 9.3735e-06  eta: 18:12:37  time: 0.4812  data_time: 0.0077  memory: 5910  grad_norm: 160.3767  loss: 15.6214  decode.loss_cls: 0.8135  decode.loss_mask: 0.2884  decode.loss_dice: 0.4252  decode.d0.loss_cls: 1.8121  decode.d0.loss_mask: 0.2695  decode.d0.loss_dice: 0.4206  decode.d1.loss_cls: 0.9926  decode.d1.loss_mask: 0.2454  decode.d1.loss_dice: 0.3501  decode.d2.loss_cls: 0.8190  decode.d2.loss_mask: 0.2633  decode.d2.loss_dice: 0.3767  decode.d3.loss_cls: 0.7677  decode.d3.loss_mask: 0.2702  decode.d3.loss_dice: 0.3526  decode.d4.loss_cls: 0.7446  decode.d4.loss_mask: 0.2479  decode.d4.loss_dice: 0.3483  decode.d5.loss_cls: 0.8126  decode.d5.loss_mask: 0.2510  decode.d5.loss_dice: 0.3551  decode.d6.loss_cls: 0.7781  decode.d6.loss_mask: 0.2580  decode.d6.loss_dice: 0.3758  decode.d7.loss_cls: 0.8063  decode.d7.loss_mask: 0.2749  decode.d7.loss_dice: 0.3762  decode.d8.loss_cls: 0.8737  decode.d8.loss_mask: 0.2732  decode.d8.loss_dice: 0.3786
07/25 17:31:33 - mmengine - INFO - Iter(train) [ 5600/80000]  base_lr: 9.3678e-05 lr: 9.3678e-06  eta: 17:30:59  time: 0.4928  data_time: 0.0080  memory: 5892  grad_norm: 185.3209  loss: 14.5659  decode.loss_cls: 0.5864  decode.loss_mask: 0.4206  decode.loss_dice: 0.3787  decode.d0.loss_cls: 1.7119  decode.d0.loss_mask: 0.3622  decode.d0.loss_dice: 0.4045  decode.d1.loss_cls: 0.7566  decode.d1.loss_mask: 0.3648  decode.d1.loss_dice: 0.3550  decode.d2.loss_cls: 0.5906  decode.d2.loss_mask: 0.3590  decode.d2.loss_dice: 0.3688  decode.d3.loss_cls: 0.5477  decode.d3.loss_mask: 0.3764  decode.d3.loss_dice: 0.3743  decode.d4.loss_cls: 0.5469  decode.d4.loss_mask: 0.3726  decode.d4.loss_dice: 0.3613  decode.d5.loss_cls: 0.5513  decode.d5.loss_mask: 0.3661  decode.d5.loss_dice: 0.3517  decode.d6.loss_cls: 0.5988  decode.d6.loss_mask: 0.3722  decode.d6.loss_dice: 0.3550  decode.d7.loss_cls: 0.6097  decode.d7.loss_mask: 0.4195  decode.d7.loss_dice: 0.3938  decode.d8.loss_cls: 0.5844  decode.d8.loss_mask: 0.3707  decode.d8.loss_dice: 0.3540
07/25 17:31:57 - mmengine - INFO - Iter(train) [ 5650/80000]  base_lr: 9.3622e-05 lr: 9.3622e-06  eta: 16:55:31  time: 0.4834  data_time: 0.0080  memory: 5892  grad_norm: 178.5718  loss: 16.5495  decode.loss_cls: 0.7676  decode.loss_mask: 0.2953  decode.loss_dice: 0.3900  decode.d0.loss_cls: 1.9318  decode.d0.loss_mask: 0.3046  decode.d0.loss_dice: 0.5384  decode.d1.loss_cls: 0.9727  decode.d1.loss_mask: 0.3011  decode.d1.loss_dice: 0.4467  decode.d2.loss_cls: 0.8174  decode.d2.loss_mask: 0.2970  decode.d2.loss_dice: 0.4641  decode.d3.loss_cls: 0.7493  decode.d3.loss_mask: 0.3026  decode.d3.loss_dice: 0.4604  decode.d4.loss_cls: 0.7315  decode.d4.loss_mask: 0.3042  decode.d4.loss_dice: 0.4288  decode.d5.loss_cls: 0.7521  decode.d5.loss_mask: 0.2942  decode.d5.loss_dice: 0.4260  decode.d6.loss_cls: 0.8011  decode.d6.loss_mask: 0.2803  decode.d6.loss_dice: 0.3915  decode.d7.loss_cls: 0.7952  decode.d7.loss_mask: 0.2887  decode.d7.loss_dice: 0.4387  decode.d8.loss_cls: 0.8209  decode.d8.loss_mask: 0.2943  decode.d8.loss_dice: 0.4628
07/25 17:32:21 - mmengine - INFO - Iter(train) [ 5700/80000]  base_lr: 9.3565e-05 lr: 9.3565e-06  eta: 16:25:12  time: 0.4886  data_time: 0.0083  memory: 5907  grad_norm: 164.2400  loss: 14.2484  decode.loss_cls: 0.6279  decode.loss_mask: 0.3373  decode.loss_dice: 0.4001  decode.d0.loss_cls: 1.6605  decode.d0.loss_mask: 0.2875  decode.d0.loss_dice: 0.4369  decode.d1.loss_cls: 0.8374  decode.d1.loss_mask: 0.2697  decode.d1.loss_dice: 0.3245  decode.d2.loss_cls: 0.5851  decode.d2.loss_mask: 0.2839  decode.d2.loss_dice: 0.3553  decode.d3.loss_cls: 0.6493  decode.d3.loss_mask: 0.2901  decode.d3.loss_dice: 0.3702  decode.d4.loss_cls: 0.6710  decode.d4.loss_mask: 0.2868  decode.d4.loss_dice: 0.3674  decode.d5.loss_cls: 0.6443  decode.d5.loss_mask: 0.2905  decode.d5.loss_dice: 0.3742  decode.d6.loss_cls: 0.6367  decode.d6.loss_mask: 0.2986  decode.d6.loss_dice: 0.3599  decode.d7.loss_cls: 0.6288  decode.d7.loss_mask: 0.3014  decode.d7.loss_dice: 0.3487  decode.d8.loss_cls: 0.6529  decode.d8.loss_mask: 0.3117  decode.d8.loss_dice: 0.3598
07/25 17:32:45 - mmengine - INFO - Iter(train) [ 5750/80000]  base_lr: 9.3508e-05 lr: 9.3508e-06  eta: 15:58:49  time: 0.4842  data_time: 0.0082  memory: 5909  grad_norm: 155.0767  loss: 18.0116  decode.loss_cls: 0.7627  decode.loss_mask: 0.4094  decode.loss_dice: 0.5055  decode.d0.loss_cls: 1.8140  decode.d0.loss_mask: 0.4073  decode.d0.loss_dice: 0.5150  decode.d1.loss_cls: 0.9232  decode.d1.loss_mask: 0.3997  decode.d1.loss_dice: 0.4751  decode.d2.loss_cls: 0.8426  decode.d2.loss_mask: 0.3899  decode.d2.loss_dice: 0.4512  decode.d3.loss_cls: 0.8065  decode.d3.loss_mask: 0.3863  decode.d3.loss_dice: 0.4721  decode.d4.loss_cls: 0.8419  decode.d4.loss_mask: 0.3919  decode.d4.loss_dice: 0.4659  decode.d5.loss_cls: 0.7606  decode.d5.loss_mask: 0.3971  decode.d5.loss_dice: 0.4545  decode.d6.loss_cls: 0.7765  decode.d6.loss_mask: 0.4065  decode.d6.loss_dice: 0.4935  decode.d7.loss_cls: 0.8832  decode.d7.loss_mask: 0.4016  decode.d7.loss_dice: 0.4771  decode.d8.loss_cls: 0.7866  decode.d8.loss_mask: 0.4144  decode.d8.loss_dice: 0.4996
07/25 17:33:10 - mmengine - INFO - Iter(train) [ 5800/80000]  base_lr: 9.3452e-05 lr: 9.3452e-06  eta: 15:35:42  time: 0.4838  data_time: 0.0080  memory: 5892  grad_norm: 160.8150  loss: 15.7384  decode.loss_cls: 0.7654  decode.loss_mask: 0.2983  decode.loss_dice: 0.4120  decode.d0.loss_cls: 1.8597  decode.d0.loss_mask: 0.3046  decode.d0.loss_dice: 0.4612  decode.d1.loss_cls: 0.7499  decode.d1.loss_mask: 0.3081  decode.d1.loss_dice: 0.4334  decode.d2.loss_cls: 0.7582  decode.d2.loss_mask: 0.3082  decode.d2.loss_dice: 0.4383  decode.d3.loss_cls: 0.6664  decode.d3.loss_mask: 0.2894  decode.d3.loss_dice: 0.4187  decode.d4.loss_cls: 0.7730  decode.d4.loss_mask: 0.2935  decode.d4.loss_dice: 0.4207  decode.d5.loss_cls: 0.7080  decode.d5.loss_mask: 0.3022  decode.d5.loss_dice: 0.4304  decode.d6.loss_cls: 0.7476  decode.d6.loss_mask: 0.3007  decode.d6.loss_dice: 0.4081  decode.d7.loss_cls: 0.7439  decode.d7.loss_mask: 0.3098  decode.d7.loss_dice: 0.4143  decode.d8.loss_cls: 0.7084  decode.d8.loss_mask: 0.3049  decode.d8.loss_dice: 0.4014
07/25 17:33:34 - mmengine - INFO - Iter(train) [ 5850/80000]  base_lr: 9.3395e-05 lr: 9.3395e-06  eta: 15:15:16  time: 0.4854  data_time: 0.0082  memory: 5921  grad_norm: 192.9213  loss: 17.5919  decode.loss_cls: 0.9292  decode.loss_mask: 0.2976  decode.loss_dice: 0.3598  decode.d0.loss_cls: 2.1344  decode.d0.loss_mask: 0.3187  decode.d0.loss_dice: 0.4444  decode.d1.loss_cls: 1.2418  decode.d1.loss_mask: 0.2534  decode.d1.loss_dice: 0.3452  decode.d2.loss_cls: 1.0166  decode.d2.loss_mask: 0.3187  decode.d2.loss_dice: 0.3415  decode.d3.loss_cls: 0.9197  decode.d3.loss_mask: 0.3127  decode.d3.loss_dice: 0.3355  decode.d4.loss_cls: 1.0285  decode.d4.loss_mask: 0.2849  decode.d4.loss_dice: 0.3270  decode.d5.loss_cls: 0.9516  decode.d5.loss_mask: 0.2945  decode.d5.loss_dice: 0.3364  decode.d6.loss_cls: 0.9309  decode.d6.loss_mask: 0.2564  decode.d6.loss_dice: 0.3549  decode.d7.loss_cls: 0.9479  decode.d7.loss_mask: 0.3053  decode.d7.loss_dice: 0.3867  decode.d8.loss_cls: 0.9183  decode.d8.loss_mask: 0.3029  decode.d8.loss_dice: 0.3963
07/25 17:33:58 - mmengine - INFO - Iter(train) [ 5900/80000]  base_lr: 9.3338e-05 lr: 9.3338e-06  eta: 14:57:19  time: 0.5027  data_time: 0.0082  memory: 5905  grad_norm: 154.6384  loss: 15.2869  decode.loss_cls: 0.6339  decode.loss_mask: 0.3620  decode.loss_dice: 0.3774  decode.d0.loss_cls: 1.8832  decode.d0.loss_mask: 0.3302  decode.d0.loss_dice: 0.4014  decode.d1.loss_cls: 0.8767  decode.d1.loss_mask: 0.3752  decode.d1.loss_dice: 0.4048  decode.d2.loss_cls: 0.7136  decode.d2.loss_mask: 0.3344  decode.d2.loss_dice: 0.3715  decode.d3.loss_cls: 0.6468  decode.d3.loss_mask: 0.3373  decode.d3.loss_dice: 0.3765  decode.d4.loss_cls: 0.7416  decode.d4.loss_mask: 0.3364  decode.d4.loss_dice: 0.3554  decode.d5.loss_cls: 0.6705  decode.d5.loss_mask: 0.3471  decode.d5.loss_dice: 0.3422  decode.d6.loss_cls: 0.6142  decode.d6.loss_mask: 0.3586  decode.d6.loss_dice: 0.3620  decode.d7.loss_cls: 0.6831  decode.d7.loss_mask: 0.3497  decode.d7.loss_dice: 0.3486  decode.d8.loss_cls: 0.6530  decode.d8.loss_mask: 0.3420  decode.d8.loss_dice: 0.3578
07/25 17:34:22 - mmengine - INFO - Iter(train) [ 5950/80000]  base_lr: 9.3282e-05 lr: 9.3282e-06  eta: 14:40:57  time: 0.4831  data_time: 0.0081  memory: 5906  grad_norm: 158.1499  loss: 13.6841  decode.loss_cls: 0.6396  decode.loss_mask: 0.2841  decode.loss_dice: 0.3176  decode.d0.loss_cls: 1.7316  decode.d0.loss_mask: 0.3061  decode.d0.loss_dice: 0.3849  decode.d1.loss_cls: 0.7433  decode.d1.loss_mask: 0.2862  decode.d1.loss_dice: 0.3290  decode.d2.loss_cls: 0.6109  decode.d2.loss_mask: 0.2912  decode.d2.loss_dice: 0.3264  decode.d3.loss_cls: 0.6185  decode.d3.loss_mask: 0.2985  decode.d3.loss_dice: 0.3229  decode.d4.loss_cls: 0.5322  decode.d4.loss_mask: 0.3112  decode.d4.loss_dice: 0.3453  decode.d5.loss_cls: 0.5722  decode.d5.loss_mask: 0.3041  decode.d5.loss_dice: 0.3544  decode.d6.loss_cls: 0.6110  decode.d6.loss_mask: 0.3086  decode.d6.loss_dice: 0.3596  decode.d7.loss_cls: 0.6430  decode.d7.loss_mask: 0.2939  decode.d7.loss_dice: 0.3332  decode.d8.loss_cls: 0.6022  decode.d8.loss_mask: 0.3022  decode.d8.loss_dice: 0.3200
07/25 17:34:47 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250725_172252
07/25 17:34:47 - mmengine - INFO - Iter(train) [ 6000/80000]  base_lr: 9.3225e-05 lr: 9.3225e-06  eta: 14:26:12  time: 0.4842  data_time: 0.0080  memory: 5892  grad_norm: 156.0136  loss: 13.1552  decode.loss_cls: 0.5519  decode.loss_mask: 0.2751  decode.loss_dice: 0.3251  decode.d0.loss_cls: 1.6065  decode.d0.loss_mask: 0.3410  decode.d0.loss_dice: 0.3825  decode.d1.loss_cls: 0.7881  decode.d1.loss_mask: 0.3020  decode.d1.loss_dice: 0.3533  decode.d2.loss_cls: 0.5978  decode.d2.loss_mask: 0.2732  decode.d2.loss_dice: 0.3253  decode.d3.loss_cls: 0.5352  decode.d3.loss_mask: 0.2572  decode.d3.loss_dice: 0.3306  decode.d4.loss_cls: 0.5282  decode.d4.loss_mask: 0.2683  decode.d4.loss_dice: 0.3339  decode.d5.loss_cls: 0.5436  decode.d5.loss_mask: 0.2606  decode.d5.loss_dice: 0.3216  decode.d6.loss_cls: 0.5815  decode.d6.loss_mask: 0.2685  decode.d6.loss_dice: 0.3406  decode.d7.loss_cls: 0.5909  decode.d7.loss_mask: 0.2674  decode.d7.loss_dice: 0.3353  decode.d8.loss_cls: 0.6541  decode.d8.loss_mask: 0.2877  decode.d8.loss_dice: 0.3281
07/25 17:35:11 - mmengine - INFO - Iter(train) [ 6050/80000]  base_lr: 9.3168e-05 lr: 9.3168e-06  eta: 14:12:51  time: 0.4880  data_time: 0.0081  memory: 5957  grad_norm: 159.6210  loss: 16.1298  decode.loss_cls: 0.6921  decode.loss_mask: 0.3487  decode.loss_dice: 0.3928  decode.d0.loss_cls: 1.9163  decode.d0.loss_mask: 0.3681  decode.d0.loss_dice: 0.4305  decode.d1.loss_cls: 0.9400  decode.d1.loss_mask: 0.3609  decode.d1.loss_dice: 0.3675  decode.d2.loss_cls: 0.7959  decode.d2.loss_mask: 0.3372  decode.d2.loss_dice: 0.3642  decode.d3.loss_cls: 0.7490  decode.d3.loss_mask: 0.3329  decode.d3.loss_dice: 0.3634  decode.d4.loss_cls: 0.7786  decode.d4.loss_mask: 0.3394  decode.d4.loss_dice: 0.3809  decode.d5.loss_cls: 0.7565  decode.d5.loss_mask: 0.3400  decode.d5.loss_dice: 0.3759  decode.d6.loss_cls: 0.7120  decode.d6.loss_mask: 0.3445  decode.d6.loss_dice: 0.3875  decode.d7.loss_cls: 0.7299  decode.d7.loss_mask: 0.3495  decode.d7.loss_dice: 0.3983  decode.d8.loss_cls: 0.7055  decode.d8.loss_mask: 0.3705  decode.d8.loss_dice: 0.4014
07/25 17:35:35 - mmengine - INFO - Iter(train) [ 6100/80000]  base_lr: 9.3112e-05 lr: 9.3112e-06  eta: 14:00:41  time: 0.4855  data_time: 0.0082  memory: 5921  grad_norm: 175.9272  loss: 13.9211  decode.loss_cls: 0.5850  decode.loss_mask: 0.2686  decode.loss_dice: 0.4333  decode.d0.loss_cls: 1.6808  decode.d0.loss_mask: 0.2682  decode.d0.loss_dice: 0.4732  decode.d1.loss_cls: 0.7685  decode.d1.loss_mask: 0.2509  decode.d1.loss_dice: 0.4177  decode.d2.loss_cls: 0.5676  decode.d2.loss_mask: 0.2631  decode.d2.loss_dice: 0.4331  decode.d3.loss_cls: 0.5448  decode.d3.loss_mask: 0.2563  decode.d3.loss_dice: 0.4260  decode.d4.loss_cls: 0.5602  decode.d4.loss_mask: 0.2477  decode.d4.loss_dice: 0.3876  decode.d5.loss_cls: 0.6001  decode.d5.loss_mask: 0.2476  decode.d5.loss_dice: 0.3856  decode.d6.loss_cls: 0.6316  decode.d6.loss_mask: 0.2463  decode.d6.loss_dice: 0.3782  decode.d7.loss_cls: 0.6818  decode.d7.loss_mask: 0.2411  decode.d7.loss_dice: 0.4020  decode.d8.loss_cls: 0.6010  decode.d8.loss_mask: 0.2504  decode.d8.loss_dice: 0.4227
07/25 17:35:59 - mmengine - INFO - Iter(train) [ 6150/80000]  base_lr: 9.3055e-05 lr: 9.3055e-06  eta: 13:49:34  time: 0.4836  data_time: 0.0080  memory: 5887  grad_norm: 202.7781  loss: 16.1104  decode.loss_cls: 0.7154  decode.loss_mask: 0.3273  decode.loss_dice: 0.4237  decode.d0.loss_cls: 1.7803  decode.d0.loss_mask: 0.3598  decode.d0.loss_dice: 0.4914  decode.d1.loss_cls: 0.7827  decode.d1.loss_mask: 0.3220  decode.d1.loss_dice: 0.4535  decode.d2.loss_cls: 0.7454  decode.d2.loss_mask: 0.3276  decode.d2.loss_dice: 0.4144  decode.d3.loss_cls: 0.7629  decode.d3.loss_mask: 0.3188  decode.d3.loss_dice: 0.4068  decode.d4.loss_cls: 0.7690  decode.d4.loss_mask: 0.3195  decode.d4.loss_dice: 0.3974  decode.d5.loss_cls: 0.8034  decode.d5.loss_mask: 0.3233  decode.d5.loss_dice: 0.3957  decode.d6.loss_cls: 0.7522  decode.d6.loss_mask: 0.3222  decode.d6.loss_dice: 0.3980  decode.d7.loss_cls: 0.7549  decode.d7.loss_mask: 0.3301  decode.d7.loss_dice: 0.4070  decode.d8.loss_cls: 0.7588  decode.d8.loss_mask: 0.3262  decode.d8.loss_dice: 0.4209
07/25 17:36:24 - mmengine - INFO - Iter(train) [ 6200/80000]  base_lr: 9.2998e-05 lr: 9.2998e-06  eta: 13:39:17  time: 0.4849  data_time: 0.0081  memory: 5906  grad_norm: 149.7407  loss: 11.2065  decode.loss_cls: 0.4101  decode.loss_mask: 0.2289  decode.loss_dice: 0.3184  decode.d0.loss_cls: 1.5205  decode.d0.loss_mask: 0.2455  decode.d0.loss_dice: 0.4050  decode.d1.loss_cls: 0.6182  decode.d1.loss_mask: 0.2383  decode.d1.loss_dice: 0.3285  decode.d2.loss_cls: 0.4692  decode.d2.loss_mask: 0.2433  decode.d2.loss_dice: 0.3243  decode.d3.loss_cls: 0.4259  decode.d3.loss_mask: 0.2259  decode.d3.loss_dice: 0.3125  decode.d4.loss_cls: 0.4452  decode.d4.loss_mask: 0.2201  decode.d4.loss_dice: 0.3036  decode.d5.loss_cls: 0.4063  decode.d5.loss_mask: 0.2319  decode.d5.loss_dice: 0.3108  decode.d6.loss_cls: 0.4170  decode.d6.loss_mask: 0.2425  decode.d6.loss_dice: 0.3086  decode.d7.loss_cls: 0.4539  decode.d7.loss_mask: 0.2437  decode.d7.loss_dice: 0.3178  decode.d8.loss_cls: 0.4420  decode.d8.loss_mask: 0.2393  decode.d8.loss_dice: 0.3093
07/25 17:36:48 - mmengine - INFO - Iter(train) [ 6250/80000]  base_lr: 9.2942e-05 lr: 9.2942e-06  eta: 13:29:47  time: 0.4844  data_time: 0.0080  memory: 5885  grad_norm: 168.1717  loss: 13.6208  decode.loss_cls: 0.6128  decode.loss_mask: 0.2429  decode.loss_dice: 0.3252  decode.d0.loss_cls: 1.7831  decode.d0.loss_mask: 0.2365  decode.d0.loss_dice: 0.3839  decode.d1.loss_cls: 0.8288  decode.d1.loss_mask: 0.2351  decode.d1.loss_dice: 0.3215  decode.d2.loss_cls: 0.6639  decode.d2.loss_mask: 0.2400  decode.d2.loss_dice: 0.3262  decode.d3.loss_cls: 0.6374  decode.d3.loss_mask: 0.2575  decode.d3.loss_dice: 0.3314  decode.d4.loss_cls: 0.6863  decode.d4.loss_mask: 0.2495  decode.d4.loss_dice: 0.3302  decode.d5.loss_cls: 0.6628  decode.d5.loss_mask: 0.2665  decode.d5.loss_dice: 0.3334  decode.d6.loss_cls: 0.6167  decode.d6.loss_mask: 0.2522  decode.d6.loss_dice: 0.3226  decode.d7.loss_cls: 0.6711  decode.d7.loss_mask: 0.2462  decode.d7.loss_dice: 0.3163  decode.d8.loss_cls: 0.6460  decode.d8.loss_mask: 0.2505  decode.d8.loss_dice: 0.3444
07/25 17:37:12 - mmengine - INFO - Iter(train) [ 6300/80000]  base_lr: 9.2885e-05 lr: 9.2885e-06  eta: 13:21:00  time: 0.4826  data_time: 0.0077  memory: 5905  grad_norm: 219.5883  loss: 14.3860  decode.loss_cls: 0.5892  decode.loss_mask: 0.3435  decode.loss_dice: 0.3599  decode.d0.loss_cls: 1.5472  decode.d0.loss_mask: 0.4158  decode.d0.loss_dice: 0.4684  decode.d1.loss_cls: 0.7458  decode.d1.loss_mask: 0.3702  decode.d1.loss_dice: 0.3506  decode.d2.loss_cls: 0.6559  decode.d2.loss_mask: 0.3470  decode.d2.loss_dice: 0.3232  decode.d3.loss_cls: 0.5877  decode.d3.loss_mask: 0.3625  decode.d3.loss_dice: 0.3561  decode.d4.loss_cls: 0.6431  decode.d4.loss_mask: 0.3520  decode.d4.loss_dice: 0.3629  decode.d5.loss_cls: 0.5631  decode.d5.loss_mask: 0.3446  decode.d5.loss_dice: 0.3844  decode.d6.loss_cls: 0.5064  decode.d6.loss_mask: 0.3586  decode.d6.loss_dice: 0.4000  decode.d7.loss_cls: 0.5860  decode.d7.loss_mask: 0.3620  decode.d7.loss_dice: 0.3881  decode.d8.loss_cls: 0.5611  decode.d8.loss_mask: 0.3587  decode.d8.loss_dice: 0.3920
07/25 17:37:36 - mmengine - INFO - Iter(train) [ 6350/80000]  base_lr: 9.2828e-05 lr: 9.2828e-06  eta: 13:12:48  time: 0.4839  data_time: 0.0080  memory: 5889  grad_norm: 188.0596  loss: 13.0725  decode.loss_cls: 0.4916  decode.loss_mask: 0.2902  decode.loss_dice: 0.2894  decode.d0.loss_cls: 1.6882  decode.d0.loss_mask: 0.3157  decode.d0.loss_dice: 0.3613  decode.d1.loss_cls: 0.7209  decode.d1.loss_mask: 0.3209  decode.d1.loss_dice: 0.3023  decode.d2.loss_cls: 0.5520  decode.d2.loss_mask: 0.3018  decode.d2.loss_dice: 0.3073  decode.d3.loss_cls: 0.4786  decode.d3.loss_mask: 0.3331  decode.d3.loss_dice: 0.3254  decode.d4.loss_cls: 0.5059  decode.d4.loss_mask: 0.3206  decode.d4.loss_dice: 0.3477  decode.d5.loss_cls: 0.5875  decode.d5.loss_mask: 0.3314  decode.d5.loss_dice: 0.3323  decode.d6.loss_cls: 0.6096  decode.d6.loss_mask: 0.3090  decode.d6.loss_dice: 0.3320  decode.d7.loss_cls: 0.5906  decode.d7.loss_mask: 0.3061  decode.d7.loss_dice: 0.2986  decode.d8.loss_cls: 0.5223  decode.d8.loss_mask: 0.2936  decode.d8.loss_dice: 0.3066
07/25 17:38:00 - mmengine - INFO - Iter(train) [ 6400/80000]  base_lr: 9.2771e-05 lr: 9.2771e-06  eta: 13:05:10  time: 0.4853  data_time: 0.0079  memory: 5888  grad_norm: 339.8944  loss: 17.7687  decode.loss_cls: 0.9676  decode.loss_mask: 0.2638  decode.loss_dice: 0.3285  decode.d0.loss_cls: 2.0952  decode.d0.loss_mask: 0.3645  decode.d0.loss_dice: 0.5244  decode.d1.loss_cls: 0.9509  decode.d1.loss_mask: 0.2980  decode.d1.loss_dice: 0.3688  decode.d2.loss_cls: 0.9330  decode.d2.loss_mask: 0.2689  decode.d2.loss_dice: 0.3797  decode.d3.loss_cls: 0.9290  decode.d3.loss_mask: 0.3023  decode.d3.loss_dice: 0.3789  decode.d4.loss_cls: 0.9464  decode.d4.loss_mask: 0.2812  decode.d4.loss_dice: 0.3895  decode.d5.loss_cls: 0.9578  decode.d5.loss_mask: 0.2967  decode.d5.loss_dice: 0.4189  decode.d6.loss_cls: 1.0699  decode.d6.loss_mask: 0.2617  decode.d6.loss_dice: 0.3795  decode.d7.loss_cls: 1.0206  decode.d7.loss_mask: 0.2867  decode.d7.loss_dice: 0.3897  decode.d8.loss_cls: 1.0379  decode.d8.loss_mask: 0.2882  decode.d8.loss_dice: 0.3907
07/25 17:38:25 - mmengine - INFO - Iter(train) [ 6450/80000]  base_lr: 9.2715e-05 lr: 9.2715e-06  eta: 12:58:07  time: 0.4841  data_time: 0.0080  memory: 5907  grad_norm: 152.7294  loss: 14.4410  decode.loss_cls: 0.6188  decode.loss_mask: 0.3416  decode.loss_dice: 0.3273  decode.d0.loss_cls: 1.7158  decode.d0.loss_mask: 0.3561  decode.d0.loss_dice: 0.4114  decode.d1.loss_cls: 0.8161  decode.d1.loss_mask: 0.3505  decode.d1.loss_dice: 0.3301  decode.d2.loss_cls: 0.7023  decode.d2.loss_mask: 0.3390  decode.d2.loss_dice: 0.3118  decode.d3.loss_cls: 0.6439  decode.d3.loss_mask: 0.3328  decode.d3.loss_dice: 0.3185  decode.d4.loss_cls: 0.6732  decode.d4.loss_mask: 0.3384  decode.d4.loss_dice: 0.3309  decode.d5.loss_cls: 0.6061  decode.d5.loss_mask: 0.3401  decode.d5.loss_dice: 0.3046  decode.d6.loss_cls: 0.6364  decode.d6.loss_mask: 0.3439  decode.d6.loss_dice: 0.3218  decode.d7.loss_cls: 0.6505  decode.d7.loss_mask: 0.3414  decode.d7.loss_dice: 0.3232  decode.d8.loss_cls: 0.6555  decode.d8.loss_mask: 0.3452  decode.d8.loss_dice: 0.3136
07/25 17:38:49 - mmengine - INFO - Iter(train) [ 6500/80000]  base_lr: 9.2658e-05 lr: 9.2658e-06  eta: 12:51:31  time: 0.4943  data_time: 0.0081  memory: 5928  grad_norm: 141.3172  loss: 13.8843  decode.loss_cls: 0.4806  decode.loss_mask: 0.3939  decode.loss_dice: 0.3930  decode.d0.loss_cls: 1.5644  decode.d0.loss_mask: 0.3742  decode.d0.loss_dice: 0.4766  decode.d1.loss_cls: 0.5625  decode.d1.loss_mask: 0.3642  decode.d1.loss_dice: 0.4174  decode.d2.loss_cls: 0.5614  decode.d2.loss_mask: 0.3710  decode.d2.loss_dice: 0.3988  decode.d3.loss_cls: 0.4863  decode.d3.loss_mask: 0.3700  decode.d3.loss_dice: 0.3642  decode.d4.loss_cls: 0.5020  decode.d4.loss_mask: 0.3846  decode.d4.loss_dice: 0.3874  decode.d5.loss_cls: 0.5303  decode.d5.loss_mask: 0.3868  decode.d5.loss_dice: 0.3705  decode.d6.loss_cls: 0.4893  decode.d6.loss_mask: 0.3848  decode.d6.loss_dice: 0.3711  decode.d7.loss_cls: 0.4802  decode.d7.loss_mask: 0.3868  decode.d7.loss_dice: 0.3749  decode.d8.loss_cls: 0.4827  decode.d8.loss_mask: 0.3912  decode.d8.loss_dice: 0.3834
07/25 17:39:13 - mmengine - INFO - Iter(train) [ 6550/80000]  base_lr: 9.2601e-05 lr: 9.2601e-06  eta: 12:45:15  time: 0.4832  data_time: 0.0081  memory: 5909  grad_norm: 398.7587  loss: 12.3850  decode.loss_cls: 0.3860  decode.loss_mask: 0.3281  decode.loss_dice: 0.3230  decode.d0.loss_cls: 1.3780  decode.d0.loss_mask: 0.3661  decode.d0.loss_dice: 0.4779  decode.d1.loss_cls: 0.6750  decode.d1.loss_mask: 0.3317  decode.d1.loss_dice: 0.3283  decode.d2.loss_cls: 0.4778  decode.d2.loss_mask: 0.3342  decode.d2.loss_dice: 0.3268  decode.d3.loss_cls: 0.4669  decode.d3.loss_mask: 0.3450  decode.d3.loss_dice: 0.3301  decode.d4.loss_cls: 0.4431  decode.d4.loss_mask: 0.3459  decode.d4.loss_dice: 0.3282  decode.d5.loss_cls: 0.4242  decode.d5.loss_mask: 0.3327  decode.d5.loss_dice: 0.3412  decode.d6.loss_cls: 0.4538  decode.d6.loss_mask: 0.3314  decode.d6.loss_dice: 0.3289  decode.d7.loss_cls: 0.4126  decode.d7.loss_mask: 0.3483  decode.d7.loss_dice: 0.3391  decode.d8.loss_cls: 0.4101  decode.d8.loss_mask: 0.3345  decode.d8.loss_dice: 0.3362
07/25 17:39:37 - mmengine - INFO - Iter(train) [ 6600/80000]  base_lr: 9.2544e-05 lr: 9.2544e-06  eta: 12:39:22  time: 0.4842  data_time: 0.0081  memory: 5892  grad_norm: 168.7555  loss: 12.4980  decode.loss_cls: 0.5830  decode.loss_mask: 0.2572  decode.loss_dice: 0.3638  decode.d0.loss_cls: 1.6285  decode.d0.loss_mask: 0.2618  decode.d0.loss_dice: 0.3656  decode.d1.loss_cls: 0.6361  decode.d1.loss_mask: 0.2638  decode.d1.loss_dice: 0.2943  decode.d2.loss_cls: 0.5335  decode.d2.loss_mask: 0.2643  decode.d2.loss_dice: 0.2929  decode.d3.loss_cls: 0.5367  decode.d3.loss_mask: 0.2553  decode.d3.loss_dice: 0.2867  decode.d4.loss_cls: 0.5609  decode.d4.loss_mask: 0.2562  decode.d4.loss_dice: 0.2990  decode.d5.loss_cls: 0.5930  decode.d5.loss_mask: 0.2511  decode.d5.loss_dice: 0.3133  decode.d6.loss_cls: 0.5122  decode.d6.loss_mask: 0.2516  decode.d6.loss_dice: 0.2934  decode.d7.loss_cls: 0.5844  decode.d7.loss_mask: 0.2537  decode.d7.loss_dice: 0.3145  decode.d8.loss_cls: 0.6057  decode.d8.loss_mask: 0.2631  decode.d8.loss_dice: 0.3223
07/25 17:40:02 - mmengine - INFO - Iter(train) [ 6650/80000]  base_lr: 9.2488e-05 lr: 9.2488e-06  eta: 12:33:47  time: 0.4840  data_time: 0.0082  memory: 5887  grad_norm: 174.0625  loss: 11.5027  decode.loss_cls: 0.5074  decode.loss_mask: 0.2485  decode.loss_dice: 0.3024  decode.d0.loss_cls: 1.5466  decode.d0.loss_mask: 0.2910  decode.d0.loss_dice: 0.4085  decode.d1.loss_cls: 0.7212  decode.d1.loss_mask: 0.2455  decode.d1.loss_dice: 0.3081  decode.d2.loss_cls: 0.4873  decode.d2.loss_mask: 0.2590  decode.d2.loss_dice: 0.2900  decode.d3.loss_cls: 0.4440  decode.d3.loss_mask: 0.2494  decode.d3.loss_dice: 0.2937  decode.d4.loss_cls: 0.4249  decode.d4.loss_mask: 0.2350  decode.d4.loss_dice: 0.2767  decode.d5.loss_cls: 0.4353  decode.d5.loss_mask: 0.2367  decode.d5.loss_dice: 0.2873  decode.d6.loss_cls: 0.4615  decode.d6.loss_mask: 0.2307  decode.d6.loss_dice: 0.2682  decode.d7.loss_cls: 0.4886  decode.d7.loss_mask: 0.2373  decode.d7.loss_dice: 0.2851  decode.d8.loss_cls: 0.5235  decode.d8.loss_mask: 0.2348  decode.d8.loss_dice: 0.2744
07/25 17:40:26 - mmengine - INFO - Iter(train) [ 6700/80000]  base_lr: 9.2431e-05 lr: 9.2431e-06  eta: 12:28:31  time: 0.4843  data_time: 0.0082  memory: 5905  grad_norm: 136.3021  loss: 10.9553  decode.loss_cls: 0.3554  decode.loss_mask: 0.2624  decode.loss_dice: 0.3025  decode.d0.loss_cls: 1.6398  decode.d0.loss_mask: 0.2566  decode.d0.loss_dice: 0.3489  decode.d1.loss_cls: 0.5323  decode.d1.loss_mask: 0.2713  decode.d1.loss_dice: 0.3150  decode.d2.loss_cls: 0.3887  decode.d2.loss_mask: 0.2691  decode.d2.loss_dice: 0.3192  decode.d3.loss_cls: 0.3525  decode.d3.loss_mask: 0.2678  decode.d3.loss_dice: 0.3402  decode.d4.loss_cls: 0.3504  decode.d4.loss_mask: 0.2607  decode.d4.loss_dice: 0.3195  decode.d5.loss_cls: 0.3589  decode.d5.loss_mask: 0.2606  decode.d5.loss_dice: 0.3047  decode.d6.loss_cls: 0.3374  decode.d6.loss_mask: 0.2670  decode.d6.loss_dice: 0.3213  decode.d7.loss_cls: 0.3554  decode.d7.loss_mask: 0.2626  decode.d7.loss_dice: 0.3271  decode.d8.loss_cls: 0.4502  decode.d8.loss_mask: 0.2607  decode.d8.loss_dice: 0.2972
07/25 17:40:50 - mmengine - INFO - Iter(train) [ 6750/80000]  base_lr: 9.2374e-05 lr: 9.2374e-06  eta: 12:23:40  time: 0.4987  data_time: 0.0090  memory: 5957  grad_norm: 183.8174  loss: 13.8407  decode.loss_cls: 0.5595  decode.loss_mask: 0.3131  decode.loss_dice: 0.3626  decode.d0.loss_cls: 1.5423  decode.d0.loss_mask: 0.3506  decode.d0.loss_dice: 0.4741  decode.d1.loss_cls: 0.6335  decode.d1.loss_mask: 0.3615  decode.d1.loss_dice: 0.3892  decode.d2.loss_cls: 0.5882  decode.d2.loss_mask: 0.3440  decode.d2.loss_dice: 0.3700  decode.d3.loss_cls: 0.5040  decode.d3.loss_mask: 0.3276  decode.d3.loss_dice: 0.3630  decode.d4.loss_cls: 0.5734  decode.d4.loss_mask: 0.3335  decode.d4.loss_dice: 0.3679  decode.d5.loss_cls: 0.5934  decode.d5.loss_mask: 0.3273  decode.d5.loss_dice: 0.3457  decode.d6.loss_cls: 0.5964  decode.d6.loss_mask: 0.3127  decode.d6.loss_dice: 0.3505  decode.d7.loss_cls: 0.6297  decode.d7.loss_mask: 0.3314  decode.d7.loss_dice: 0.3630  decode.d8.loss_cls: 0.5571  decode.d8.loss_mask: 0.3190  decode.d8.loss_dice: 0.3562
07/25 17:41:15 - mmengine - INFO - Iter(train) [ 6800/80000]  base_lr: 9.2317e-05 lr: 9.2317e-06  eta: 12:19:12  time: 0.4879  data_time: 0.0084  memory: 5907  grad_norm: 250.6932  loss: 13.7746  decode.loss_cls: 0.4823  decode.loss_mask: 0.3746  decode.loss_dice: 0.3227  decode.d0.loss_cls: 1.7412  decode.d0.loss_mask: 0.3775  decode.d0.loss_dice: 0.3743  decode.d1.loss_cls: 0.6900  decode.d1.loss_mask: 0.3714  decode.d1.loss_dice: 0.3464  decode.d2.loss_cls: 0.6127  decode.d2.loss_mask: 0.3767  decode.d2.loss_dice: 0.3499  decode.d3.loss_cls: 0.5444  decode.d3.loss_mask: 0.3645  decode.d3.loss_dice: 0.3330  decode.d4.loss_cls: 0.5127  decode.d4.loss_mask: 0.3644  decode.d4.loss_dice: 0.3168  decode.d5.loss_cls: 0.5866  decode.d5.loss_mask: 0.3470  decode.d5.loss_dice: 0.3418  decode.d6.loss_cls: 0.5727  decode.d6.loss_mask: 0.3572  decode.d6.loss_dice: 0.3334  decode.d7.loss_cls: 0.5253  decode.d7.loss_mask: 0.3662  decode.d7.loss_dice: 0.3135  decode.d8.loss_cls: 0.4917  decode.d8.loss_mask: 0.3733  decode.d8.loss_dice: 0.3103
07/25 17:41:39 - mmengine - INFO - Iter(train) [ 6850/80000]  base_lr: 9.2261e-05 lr: 9.2261e-06  eta: 12:14:45  time: 0.4872  data_time: 0.0083  memory: 5905  grad_norm: 224.2502  loss: 12.6476  decode.loss_cls: 0.5149  decode.loss_mask: 0.2970  decode.loss_dice: 0.3056  decode.d0.loss_cls: 1.5096  decode.d0.loss_mask: 0.3427  decode.d0.loss_dice: 0.4098  decode.d1.loss_cls: 0.5809  decode.d1.loss_mask: 0.2887  decode.d1.loss_dice: 0.3269  decode.d2.loss_cls: 0.5544  decode.d2.loss_mask: 0.2852  decode.d2.loss_dice: 0.3281  decode.d3.loss_cls: 0.5156  decode.d3.loss_mask: 0.2870  decode.d3.loss_dice: 0.3086  decode.d4.loss_cls: 0.5071  decode.d4.loss_mask: 0.2992  decode.d4.loss_dice: 0.3314  decode.d5.loss_cls: 0.5251  decode.d5.loss_mask: 0.2923  decode.d5.loss_dice: 0.3218  decode.d6.loss_cls: 0.5500  decode.d6.loss_mask: 0.2953  decode.d6.loss_dice: 0.3120  decode.d7.loss_cls: 0.5763  decode.d7.loss_mask: 0.2939  decode.d7.loss_dice: 0.3218  decode.d8.loss_cls: 0.5362  decode.d8.loss_mask: 0.2969  decode.d8.loss_dice: 0.3333
07/25 17:42:04 - mmengine - INFO - Iter(train) [ 6900/80000]  base_lr: 9.2204e-05 lr: 9.2204e-06  eta: 12:10:33  time: 0.4868  data_time: 0.0082  memory: 5891  grad_norm: 141.5512  loss: 10.8206  decode.loss_cls: 0.3754  decode.loss_mask: 0.3148  decode.loss_dice: 0.3157  decode.d0.loss_cls: 1.3072  decode.d0.loss_mask: 0.3268  decode.d0.loss_dice: 0.3327  decode.d1.loss_cls: 0.4282  decode.d1.loss_mask: 0.3138  decode.d1.loss_dice: 0.2939  decode.d2.loss_cls: 0.3394  decode.d2.loss_mask: 0.3049  decode.d2.loss_dice: 0.3095  decode.d3.loss_cls: 0.3479  decode.d3.loss_mask: 0.3202  decode.d3.loss_dice: 0.3125  decode.d4.loss_cls: 0.3185  decode.d4.loss_mask: 0.3174  decode.d4.loss_dice: 0.3130  decode.d5.loss_cls: 0.3027  decode.d5.loss_mask: 0.3125  decode.d5.loss_dice: 0.3089  decode.d6.loss_cls: 0.3847  decode.d6.loss_mask: 0.3111  decode.d6.loss_dice: 0.3115  decode.d7.loss_cls: 0.3723  decode.d7.loss_mask: 0.3189  decode.d7.loss_dice: 0.3024  decode.d8.loss_cls: 0.3777  decode.d8.loss_mask: 0.3106  decode.d8.loss_dice: 0.3155
07/25 17:42:28 - mmengine - INFO - Iter(train) [ 6950/80000]  base_lr: 9.2147e-05 lr: 9.2147e-06  eta: 12:06:30  time: 0.4857  data_time: 0.0081  memory: 5959  grad_norm: 168.0211  loss: 12.0980  decode.loss_cls: 0.4308  decode.loss_mask: 0.3287  decode.loss_dice: 0.3273  decode.d0.loss_cls: 1.4401  decode.d0.loss_mask: 0.2942  decode.d0.loss_dice: 0.4061  decode.d1.loss_cls: 0.5860  decode.d1.loss_mask: 0.2857  decode.d1.loss_dice: 0.3352  decode.d2.loss_cls: 0.5147  decode.d2.loss_mask: 0.2829  decode.d2.loss_dice: 0.3269  decode.d3.loss_cls: 0.4689  decode.d3.loss_mask: 0.2816  decode.d3.loss_dice: 0.3340  decode.d4.loss_cls: 0.4381  decode.d4.loss_mask: 0.2863  decode.d4.loss_dice: 0.3541  decode.d5.loss_cls: 0.4159  decode.d5.loss_mask: 0.2965  decode.d5.loss_dice: 0.3569  decode.d6.loss_cls: 0.4597  decode.d6.loss_mask: 0.2858  decode.d6.loss_dice: 0.3319  decode.d7.loss_cls: 0.4968  decode.d7.loss_mask: 0.2862  decode.d7.loss_dice: 0.3426  decode.d8.loss_cls: 0.4533  decode.d8.loss_mask: 0.3237  decode.d8.loss_dice: 0.3270
07/25 17:42:52 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250725_172252
07/25 17:42:52 - mmengine - INFO - Iter(train) [ 7000/80000]  base_lr: 9.2090e-05 lr: 9.2090e-06  eta: 12:02:34  time: 0.4837  data_time: 0.0080  memory: 5886  grad_norm: 179.6730  loss: 12.4795  decode.loss_cls: 0.4685  decode.loss_mask: 0.3122  decode.loss_dice: 0.3603  decode.d0.loss_cls: 1.4263  decode.d0.loss_mask: 0.3112  decode.d0.loss_dice: 0.4137  decode.d1.loss_cls: 0.4927  decode.d1.loss_mask: 0.3218  decode.d1.loss_dice: 0.3853  decode.d2.loss_cls: 0.3988  decode.d2.loss_mask: 0.3245  decode.d2.loss_dice: 0.3666  decode.d3.loss_cls: 0.4409  decode.d3.loss_mask: 0.3169  decode.d3.loss_dice: 0.3734  decode.d4.loss_cls: 0.3991  decode.d4.loss_mask: 0.3161  decode.d4.loss_dice: 0.3918  decode.d5.loss_cls: 0.3983  decode.d5.loss_mask: 0.3293  decode.d5.loss_dice: 0.3811  decode.d6.loss_cls: 0.4347  decode.d6.loss_mask: 0.3243  decode.d6.loss_dice: 0.3940  decode.d7.loss_cls: 0.4685  decode.d7.loss_mask: 0.3198  decode.d7.loss_dice: 0.3745  decode.d8.loss_cls: 0.5207  decode.d8.loss_mask: 0.3251  decode.d8.loss_dice: 0.3890
07/25 17:43:16 - mmengine - INFO - Iter(train) [ 7050/80000]  base_lr: 9.2034e-05 lr: 9.2034e-06  eta: 11:58:53  time: 0.4843  data_time: 0.0081  memory: 5907  grad_norm: 145.9128  loss: 13.6123  decode.loss_cls: 0.5366  decode.loss_mask: 0.2661  decode.loss_dice: 0.3736  decode.d0.loss_cls: 1.6268  decode.d0.loss_mask: 0.2896  decode.d0.loss_dice: 0.4248  decode.d1.loss_cls: 0.7180  decode.d1.loss_mask: 0.2763  decode.d1.loss_dice: 0.3688  decode.d2.loss_cls: 0.7028  decode.d2.loss_mask: 0.2705  decode.d2.loss_dice: 0.3725  decode.d3.loss_cls: 0.6289  decode.d3.loss_mask: 0.2587  decode.d3.loss_dice: 0.3522  decode.d4.loss_cls: 0.6283  decode.d4.loss_mask: 0.2569  decode.d4.loss_dice: 0.3640  decode.d5.loss_cls: 0.6207  decode.d5.loss_mask: 0.2615  decode.d5.loss_dice: 0.3639  decode.d6.loss_cls: 0.6332  decode.d6.loss_mask: 0.2614  decode.d6.loss_dice: 0.3616  decode.d7.loss_cls: 0.5579  decode.d7.loss_mask: 0.2670  decode.d7.loss_dice: 0.3567  decode.d8.loss_cls: 0.5860  decode.d8.loss_mask: 0.2686  decode.d8.loss_dice: 0.3586
07/25 17:43:41 - mmengine - INFO - Iter(train) [ 7100/80000]  base_lr: 9.1977e-05 lr: 9.1977e-06  eta: 11:55:18  time: 0.4837  data_time: 0.0080  memory: 5927  grad_norm: 137.1546  loss: 10.2668  decode.loss_cls: 0.3677  decode.loss_mask: 0.2562  decode.loss_dice: 0.2464  decode.d0.loss_cls: 1.3585  decode.d0.loss_mask: 0.2853  decode.d0.loss_dice: 0.2862  decode.d1.loss_cls: 0.4770  decode.d1.loss_mask: 0.2698  decode.d1.loss_dice: 0.2648  decode.d2.loss_cls: 0.4535  decode.d2.loss_mask: 0.2647  decode.d2.loss_dice: 0.2574  decode.d3.loss_cls: 0.3825  decode.d3.loss_mask: 0.2631  decode.d3.loss_dice: 0.2609  decode.d4.loss_cls: 0.4047  decode.d4.loss_mask: 0.2611  decode.d4.loss_dice: 0.2496  decode.d5.loss_cls: 0.4291  decode.d5.loss_mask: 0.2598  decode.d5.loss_dice: 0.2495  decode.d6.loss_cls: 0.4109  decode.d6.loss_mask: 0.2623  decode.d6.loss_dice: 0.2453  decode.d7.loss_cls: 0.4006  decode.d7.loss_mask: 0.2606  decode.d7.loss_dice: 0.2441  decode.d8.loss_cls: 0.3896  decode.d8.loss_mask: 0.2593  decode.d8.loss_dice: 0.2464
07/25 17:44:05 - mmengine - INFO - Iter(train) [ 7150/80000]  base_lr: 9.1920e-05 lr: 9.1920e-06  eta: 11:51:51  time: 0.4838  data_time: 0.0080  memory: 5910  grad_norm: 316.8177  loss: 17.0415  decode.loss_cls: 0.8085  decode.loss_mask: 0.3657  decode.loss_dice: 0.4188  decode.d0.loss_cls: 1.6863  decode.d0.loss_mask: 0.4334  decode.d0.loss_dice: 0.4994  decode.d1.loss_cls: 0.8480  decode.d1.loss_mask: 0.3699  decode.d1.loss_dice: 0.4311  decode.d2.loss_cls: 0.8335  decode.d2.loss_mask: 0.3793  decode.d2.loss_dice: 0.4076  decode.d3.loss_cls: 0.7975  decode.d3.loss_mask: 0.3624  decode.d3.loss_dice: 0.4254  decode.d4.loss_cls: 0.8613  decode.d4.loss_mask: 0.3578  decode.d4.loss_dice: 0.4246  decode.d5.loss_cls: 0.8007  decode.d5.loss_mask: 0.3624  decode.d5.loss_dice: 0.4308  decode.d6.loss_cls: 0.8095  decode.d6.loss_mask: 0.3546  decode.d6.loss_dice: 0.4268  decode.d7.loss_cls: 0.7216  decode.d7.loss_mask: 0.3648  decode.d7.loss_dice: 0.4253  decode.d8.loss_cls: 0.7855  decode.d8.loss_mask: 0.3957  decode.d8.loss_dice: 0.4538
07/25 17:44:29 - mmengine - INFO - Iter(train) [ 7200/80000]  base_lr: 9.1863e-05 lr: 9.1863e-06  eta: 11:48:34  time: 0.4841  data_time: 0.0081  memory: 5959  grad_norm: 213.4218  loss: 12.2790  decode.loss_cls: 0.4888  decode.loss_mask: 0.2570  decode.loss_dice: 0.3287  decode.d0.loss_cls: 1.7517  decode.d0.loss_mask: 0.2695  decode.d0.loss_dice: 0.3514  decode.d1.loss_cls: 0.6249  decode.d1.loss_mask: 0.2416  decode.d1.loss_dice: 0.3063  decode.d2.loss_cls: 0.6150  decode.d2.loss_mask: 0.2470  decode.d2.loss_dice: 0.3079  decode.d3.loss_cls: 0.5803  decode.d3.loss_mask: 0.2405  decode.d3.loss_dice: 0.2904  decode.d4.loss_cls: 0.6053  decode.d4.loss_mask: 0.2475  decode.d4.loss_dice: 0.2930  decode.d5.loss_cls: 0.5695  decode.d5.loss_mask: 0.2404  decode.d5.loss_dice: 0.2823  decode.d6.loss_cls: 0.5243  decode.d6.loss_mask: 0.2405  decode.d6.loss_dice: 0.2885  decode.d7.loss_cls: 0.5163  decode.d7.loss_mask: 0.2592  decode.d7.loss_dice: 0.2970  decode.d8.loss_cls: 0.4588  decode.d8.loss_mask: 0.2602  decode.d8.loss_dice: 0.2950
07/25 17:44:53 - mmengine - INFO - Iter(train) [ 7250/80000]  base_lr: 9.1807e-05 lr: 9.1807e-06  eta: 11:45:24  time: 0.4851  data_time: 0.0082  memory: 5921  grad_norm: 133.5265  loss: 11.7214  decode.loss_cls: 0.3824  decode.loss_mask: 0.2993  decode.loss_dice: 0.3863  decode.d0.loss_cls: 1.4853  decode.d0.loss_mask: 0.2757  decode.d0.loss_dice: 0.4387  decode.d1.loss_cls: 0.5214  decode.d1.loss_mask: 0.2739  decode.d1.loss_dice: 0.3480  decode.d2.loss_cls: 0.3816  decode.d2.loss_mask: 0.2749  decode.d2.loss_dice: 0.3871  decode.d3.loss_cls: 0.3905  decode.d3.loss_mask: 0.2739  decode.d3.loss_dice: 0.3501  decode.d4.loss_cls: 0.3982  decode.d4.loss_mask: 0.2723  decode.d4.loss_dice: 0.3638  decode.d5.loss_cls: 0.4004  decode.d5.loss_mask: 0.2696  decode.d5.loss_dice: 0.3791  decode.d6.loss_cls: 0.3857  decode.d6.loss_mask: 0.2727  decode.d6.loss_dice: 0.3624  decode.d7.loss_cls: 0.4069  decode.d7.loss_mask: 0.2725  decode.d7.loss_dice: 0.3665  decode.d8.loss_cls: 0.4198  decode.d8.loss_mask: 0.2804  decode.d8.loss_dice: 0.4020
07/25 17:45:17 - mmengine - INFO - Iter(train) [ 7300/80000]  base_lr: 9.1750e-05 lr: 9.1750e-06  eta: 11:42:21  time: 0.4848  data_time: 0.0084  memory: 5905  grad_norm: 128.0853  loss: 13.1366  decode.loss_cls: 0.6025  decode.loss_mask: 0.2772  decode.loss_dice: 0.3132  decode.d0.loss_cls: 1.5582  decode.d0.loss_mask: 0.3061  decode.d0.loss_dice: 0.3797  decode.d1.loss_cls: 0.6694  decode.d1.loss_mask: 0.2944  decode.d1.loss_dice: 0.3470  decode.d2.loss_cls: 0.6195  decode.d2.loss_mask: 0.2836  decode.d2.loss_dice: 0.3311  decode.d3.loss_cls: 0.6382  decode.d3.loss_mask: 0.2823  decode.d3.loss_dice: 0.3129  decode.d4.loss_cls: 0.5920  decode.d4.loss_mask: 0.2839  decode.d4.loss_dice: 0.3125  decode.d5.loss_cls: 0.5901  decode.d5.loss_mask: 0.2852  decode.d5.loss_dice: 0.3035  decode.d6.loss_cls: 0.6043  decode.d6.loss_mask: 0.2901  decode.d6.loss_dice: 0.3012  decode.d7.loss_cls: 0.6656  decode.d7.loss_mask: 0.2864  decode.d7.loss_dice: 0.2960  decode.d8.loss_cls: 0.5309  decode.d8.loss_mask: 0.2829  decode.d8.loss_dice: 0.2966
07/25 17:45:42 - mmengine - INFO - Iter(train) [ 7350/80000]  base_lr: 9.1693e-05 lr: 9.1693e-06  eta: 11:39:30  time: 0.4834  data_time: 0.0083  memory: 5906  grad_norm: 399.6112  loss: 14.9787  decode.loss_cls: 0.5021  decode.loss_mask: 0.5103  decode.loss_dice: 0.3710  decode.d0.loss_cls: 1.5463  decode.d0.loss_mask: 0.5870  decode.d0.loss_dice: 0.4761  decode.d1.loss_cls: 0.6053  decode.d1.loss_mask: 0.5286  decode.d1.loss_dice: 0.3821  decode.d2.loss_cls: 0.5744  decode.d2.loss_mask: 0.4654  decode.d2.loss_dice: 0.3586  decode.d3.loss_cls: 0.5243  decode.d3.loss_mask: 0.4685  decode.d3.loss_dice: 0.3640  decode.d4.loss_cls: 0.4896  decode.d4.loss_mask: 0.4796  decode.d4.loss_dice: 0.3909  decode.d5.loss_cls: 0.5317  decode.d5.loss_mask: 0.4808  decode.d5.loss_dice: 0.3670  decode.d6.loss_cls: 0.5040  decode.d6.loss_mask: 0.4665  decode.d6.loss_dice: 0.3607  decode.d7.loss_cls: 0.4799  decode.d7.loss_mask: 0.4837  decode.d7.loss_dice: 0.3696  decode.d8.loss_cls: 0.4751  decode.d8.loss_mask: 0.4762  decode.d8.loss_dice: 0.3591
07/25 17:46:06 - mmengine - INFO - Iter(train) [ 7400/80000]  base_lr: 9.1636e-05 lr: 9.1636e-06  eta: 11:36:40  time: 0.4849  data_time: 0.0084  memory: 5889  grad_norm: 220.0482  loss: 11.3236  decode.loss_cls: 0.4800  decode.loss_mask: 0.2983  decode.loss_dice: 0.2947  decode.d0.loss_cls: 1.4113  decode.d0.loss_mask: 0.2721  decode.d0.loss_dice: 0.3243  decode.d1.loss_cls: 0.5212  decode.d1.loss_mask: 0.2771  decode.d1.loss_dice: 0.2965  decode.d2.loss_cls: 0.5135  decode.d2.loss_mask: 0.2772  decode.d2.loss_dice: 0.2760  decode.d3.loss_cls: 0.4454  decode.d3.loss_mask: 0.2794  decode.d3.loss_dice: 0.2673  decode.d4.loss_cls: 0.4325  decode.d4.loss_mask: 0.2754  decode.d4.loss_dice: 0.2777  decode.d5.loss_cls: 0.4240  decode.d5.loss_mask: 0.2796  decode.d5.loss_dice: 0.2832  decode.d6.loss_cls: 0.4464  decode.d6.loss_mask: 0.2869  decode.d6.loss_dice: 0.2804  decode.d7.loss_cls: 0.4368  decode.d7.loss_mask: 0.2758  decode.d7.loss_dice: 0.3039  decode.d8.loss_cls: 0.5082  decode.d8.loss_mask: 0.2894  decode.d8.loss_dice: 0.2894
07/25 17:46:30 - mmengine - INFO - Iter(train) [ 7450/80000]  base_lr: 9.1579e-05 lr: 9.1579e-06  eta: 11:33:56  time: 0.4831  data_time: 0.0081  memory: 5888  grad_norm: 213.3408  loss: 13.8493  decode.loss_cls: 0.5224  decode.loss_mask: 0.3240  decode.loss_dice: 0.4075  decode.d0.loss_cls: 1.5243  decode.d0.loss_mask: 0.3321  decode.d0.loss_dice: 0.4779  decode.d1.loss_cls: 0.5822  decode.d1.loss_mask: 0.3347  decode.d1.loss_dice: 0.4208  decode.d2.loss_cls: 0.5376  decode.d2.loss_mask: 0.3452  decode.d2.loss_dice: 0.4086  decode.d3.loss_cls: 0.5239  decode.d3.loss_mask: 0.3376  decode.d3.loss_dice: 0.3940  decode.d4.loss_cls: 0.4905  decode.d4.loss_mask: 0.3349  decode.d4.loss_dice: 0.4117  decode.d5.loss_cls: 0.4965  decode.d5.loss_mask: 0.3336  decode.d5.loss_dice: 0.4133  decode.d6.loss_cls: 0.4914  decode.d6.loss_mask: 0.3332  decode.d6.loss_dice: 0.4119  decode.d7.loss_cls: 0.5524  decode.d7.loss_mask: 0.3347  decode.d7.loss_dice: 0.4314  decode.d8.loss_cls: 0.5642  decode.d8.loss_mask: 0.3368  decode.d8.loss_dice: 0.4402
07/25 17:46:54 - mmengine - INFO - Iter(train) [ 7500/80000]  base_lr: 9.1523e-05 lr: 9.1523e-06  eta: 11:31:17  time: 0.4839  data_time: 0.0080  memory: 5888  grad_norm: 198.9716  loss: 10.8879  decode.loss_cls: 0.3080  decode.loss_mask: 0.3003  decode.loss_dice: 0.3258  decode.d0.loss_cls: 1.3084  decode.d0.loss_mask: 0.3117  decode.d0.loss_dice: 0.3772  decode.d1.loss_cls: 0.4734  decode.d1.loss_mask: 0.3096  decode.d1.loss_dice: 0.3530  decode.d2.loss_cls: 0.3688  decode.d2.loss_mask: 0.2990  decode.d2.loss_dice: 0.3344  decode.d3.loss_cls: 0.3477  decode.d3.loss_mask: 0.3062  decode.d3.loss_dice: 0.3372  decode.d4.loss_cls: 0.3503  decode.d4.loss_mask: 0.2943  decode.d4.loss_dice: 0.3357  decode.d5.loss_cls: 0.3499  decode.d5.loss_mask: 0.3034  decode.d5.loss_dice: 0.3428  decode.d6.loss_cls: 0.3301  decode.d6.loss_mask: 0.2881  decode.d6.loss_dice: 0.3275  decode.d7.loss_cls: 0.3710  decode.d7.loss_mask: 0.2889  decode.d7.loss_dice: 0.3181  decode.d8.loss_cls: 0.3264  decode.d8.loss_mask: 0.2868  decode.d8.loss_dice: 0.3139
07/25 17:47:19 - mmengine - INFO - Iter(train) [ 7550/80000]  base_lr: 9.1466e-05 lr: 9.1466e-06  eta: 11:28:43  time: 0.4844  data_time: 0.0082  memory: 5872  grad_norm: 174.5677  loss: 12.0789  decode.loss_cls: 0.5207  decode.loss_mask: 0.2344  decode.loss_dice: 0.2827  decode.d0.loss_cls: 1.5468  decode.d0.loss_mask: 0.2831  decode.d0.loss_dice: 0.4121  decode.d1.loss_cls: 0.6781  decode.d1.loss_mask: 0.2239  decode.d1.loss_dice: 0.3093  decode.d2.loss_cls: 0.5412  decode.d2.loss_mask: 0.2283  decode.d2.loss_dice: 0.3150  decode.d3.loss_cls: 0.5182  decode.d3.loss_mask: 0.2315  decode.d3.loss_dice: 0.3021  decode.d4.loss_cls: 0.5984  decode.d4.loss_mask: 0.2271  decode.d4.loss_dice: 0.3118  decode.d5.loss_cls: 0.5267  decode.d5.loss_mask: 0.2353  decode.d5.loss_dice: 0.3027  decode.d6.loss_cls: 0.5525  decode.d6.loss_mask: 0.2264  decode.d6.loss_dice: 0.3112  decode.d7.loss_cls: 0.5250  decode.d7.loss_mask: 0.2373  decode.d7.loss_dice: 0.3285  decode.d8.loss_cls: 0.5171  decode.d8.loss_mask: 0.2379  decode.d8.loss_dice: 0.3135
07/25 17:47:43 - mmengine - INFO - Iter(train) [ 7600/80000]  base_lr: 9.1409e-05 lr: 9.1409e-06  eta: 11:26:15  time: 0.4846  data_time: 0.0079  memory: 5911  grad_norm: 260.2533  loss: 12.7277  decode.loss_cls: 0.5041  decode.loss_mask: 0.2978  decode.loss_dice: 0.3401  decode.d0.loss_cls: 1.6052  decode.d0.loss_mask: 0.2966  decode.d0.loss_dice: 0.3934  decode.d1.loss_cls: 0.5506  decode.d1.loss_mask: 0.2919  decode.d1.loss_dice: 0.3423  decode.d2.loss_cls: 0.4980  decode.d2.loss_mask: 0.3008  decode.d2.loss_dice: 0.3394  decode.d3.loss_cls: 0.5245  decode.d3.loss_mask: 0.2882  decode.d3.loss_dice: 0.3360  decode.d4.loss_cls: 0.4688  decode.d4.loss_mask: 0.3297  decode.d4.loss_dice: 0.3593  decode.d5.loss_cls: 0.4957  decode.d5.loss_mask: 0.3161  decode.d5.loss_dice: 0.3505  decode.d6.loss_cls: 0.4669  decode.d6.loss_mask: 0.3038  decode.d6.loss_dice: 0.3573  decode.d7.loss_cls: 0.4923  decode.d7.loss_mask: 0.2989  decode.d7.loss_dice: 0.3669  decode.d8.loss_cls: 0.5337  decode.d8.loss_mask: 0.3040  decode.d8.loss_dice: 0.3750
07/25 17:48:07 - mmengine - INFO - Iter(train) [ 7650/80000]  base_lr: 9.1352e-05 lr: 9.1352e-06  eta: 11:23:51  time: 0.4841  data_time: 0.0082  memory: 5906  grad_norm: 124.3289  loss: 11.0261  decode.loss_cls: 0.3401  decode.loss_mask: 0.2923  decode.loss_dice: 0.2861  decode.d0.loss_cls: 1.5820  decode.d0.loss_mask: 0.3242  decode.d0.loss_dice: 0.3792  decode.d1.loss_cls: 0.5657  decode.d1.loss_mask: 0.3075  decode.d1.loss_dice: 0.3261  decode.d2.loss_cls: 0.4402  decode.d2.loss_mask: 0.2970  decode.d2.loss_dice: 0.3188  decode.d3.loss_cls: 0.3628  decode.d3.loss_mask: 0.2943  decode.d3.loss_dice: 0.3151  decode.d4.loss_cls: 0.3723  decode.d4.loss_mask: 0.2930  decode.d4.loss_dice: 0.2969  decode.d5.loss_cls: 0.3351  decode.d5.loss_mask: 0.2949  decode.d5.loss_dice: 0.2821  decode.d6.loss_cls: 0.3232  decode.d6.loss_mask: 0.2919  decode.d6.loss_dice: 0.2919  decode.d7.loss_cls: 0.3435  decode.d7.loss_mask: 0.2946  decode.d7.loss_dice: 0.3036  decode.d8.loss_cls: 0.3123  decode.d8.loss_mask: 0.2895  decode.d8.loss_dice: 0.2698
07/25 17:48:31 - mmengine - INFO - Iter(train) [ 7700/80000]  base_lr: 9.1295e-05 lr: 9.1295e-06  eta: 11:21:32  time: 0.4831  data_time: 0.0082  memory: 5886  grad_norm: 197.2068  loss: 11.0091  decode.loss_cls: 0.4349  decode.loss_mask: 0.2595  decode.loss_dice: 0.3000  decode.d0.loss_cls: 1.5762  decode.d0.loss_mask: 0.2637  decode.d0.loss_dice: 0.3401  decode.d1.loss_cls: 0.5205  decode.d1.loss_mask: 0.2597  decode.d1.loss_dice: 0.2960  decode.d2.loss_cls: 0.4098  decode.d2.loss_mask: 0.2506  decode.d2.loss_dice: 0.3014  decode.d3.loss_cls: 0.4348  decode.d3.loss_mask: 0.2518  decode.d3.loss_dice: 0.3194  decode.d4.loss_cls: 0.3792  decode.d4.loss_mask: 0.2512  decode.d4.loss_dice: 0.3131  decode.d5.loss_cls: 0.3921  decode.d5.loss_mask: 0.2547  decode.d5.loss_dice: 0.3150  decode.d6.loss_cls: 0.3992  decode.d6.loss_mask: 0.2553  decode.d6.loss_dice: 0.3002  decode.d7.loss_cls: 0.3819  decode.d7.loss_mask: 0.2427  decode.d7.loss_dice: 0.2932  decode.d8.loss_cls: 0.4586  decode.d8.loss_mask: 0.2506  decode.d8.loss_dice: 0.3037
07/25 17:48:56 - mmengine - INFO - Iter(train) [ 7750/80000]  base_lr: 9.1238e-05 lr: 9.1238e-06  eta: 11:19:17  time: 0.4847  data_time: 0.0081  memory: 5906  grad_norm: 207.1111  loss: 15.7421  decode.loss_cls: 0.6829  decode.loss_mask: 0.3333  decode.loss_dice: 0.4046  decode.d0.loss_cls: 1.6303  decode.d0.loss_mask: 0.3867  decode.d0.loss_dice: 0.5039  decode.d1.loss_cls: 0.9284  decode.d1.loss_mask: 0.3601  decode.d1.loss_dice: 0.4267  decode.d2.loss_cls: 0.5996  decode.d2.loss_mask: 0.3570  decode.d2.loss_dice: 0.4806  decode.d3.loss_cls: 0.6893  decode.d3.loss_mask: 0.3643  decode.d3.loss_dice: 0.4268  decode.d4.loss_cls: 0.5894  decode.d4.loss_mask: 0.3652  decode.d4.loss_dice: 0.4611  decode.d5.loss_cls: 0.6200  decode.d5.loss_mask: 0.3694  decode.d5.loss_dice: 0.4594  decode.d6.loss_cls: 0.6408  decode.d6.loss_mask: 0.3499  decode.d6.loss_dice: 0.4577  decode.d7.loss_cls: 0.6667  decode.d7.loss_mask: 0.3468  decode.d7.loss_dice: 0.4358  decode.d8.loss_cls: 0.6442  decode.d8.loss_mask: 0.3361  decode.d8.loss_dice: 0.4251
07/25 17:49:20 - mmengine - INFO - Iter(train) [ 7800/80000]  base_lr: 9.1182e-05 lr: 9.1182e-06  eta: 11:17:06  time: 0.4844  data_time: 0.0081  memory: 5876  grad_norm: 209.7031  loss: 11.5115  decode.loss_cls: 0.4763  decode.loss_mask: 0.2653  decode.loss_dice: 0.2999  decode.d0.loss_cls: 1.3675  decode.d0.loss_mask: 0.2551  decode.d0.loss_dice: 0.3520  decode.d1.loss_cls: 0.6014  decode.d1.loss_mask: 0.2534  decode.d1.loss_dice: 0.3106  decode.d2.loss_cls: 0.5110  decode.d2.loss_mask: 0.2507  decode.d2.loss_dice: 0.3053  decode.d3.loss_cls: 0.4467  decode.d3.loss_mask: 0.2556  decode.d3.loss_dice: 0.2903  decode.d4.loss_cls: 0.5300  decode.d4.loss_mask: 0.2599  decode.d4.loss_dice: 0.2992  decode.d5.loss_cls: 0.4860  decode.d5.loss_mask: 0.2582  decode.d5.loss_dice: 0.2982  decode.d6.loss_cls: 0.4878  decode.d6.loss_mask: 0.2635  decode.d6.loss_dice: 0.3167  decode.d7.loss_cls: 0.4244  decode.d7.loss_mask: 0.2580  decode.d7.loss_dice: 0.3093  decode.d8.loss_cls: 0.5011  decode.d8.loss_mask: 0.2741  decode.d8.loss_dice: 0.3039
07/25 17:49:44 - mmengine - INFO - Iter(train) [ 7850/80000]  base_lr: 9.1125e-05 lr: 9.1125e-06  eta: 11:14:58  time: 0.4824  data_time: 0.0079  memory: 5907  grad_norm: 121.3690  loss: 13.3454  decode.loss_cls: 0.6254  decode.loss_mask: 0.2263  decode.loss_dice: 0.3591  decode.d0.loss_cls: 1.3160  decode.d0.loss_mask: 0.2315  decode.d0.loss_dice: 0.4169  decode.d1.loss_cls: 0.7331  decode.d1.loss_mask: 0.2230  decode.d1.loss_dice: 0.3689  decode.d2.loss_cls: 0.8389  decode.d2.loss_mask: 0.2267  decode.d2.loss_dice: 0.3547  decode.d3.loss_cls: 0.6795  decode.d3.loss_mask: 0.2293  decode.d3.loss_dice: 0.3478  decode.d4.loss_cls: 0.6793  decode.d4.loss_mask: 0.2218  decode.d4.loss_dice: 0.3647  decode.d5.loss_cls: 0.6665  decode.d5.loss_mask: 0.2240  decode.d5.loss_dice: 0.3713  decode.d6.loss_cls: 0.6258  decode.d6.loss_mask: 0.2249  decode.d6.loss_dice: 0.3444  decode.d7.loss_cls: 0.6323  decode.d7.loss_mask: 0.2278  decode.d7.loss_dice: 0.3524  decode.d8.loss_cls: 0.6528  decode.d8.loss_mask: 0.2254  decode.d8.loss_dice: 0.3547
07/25 17:50:08 - mmengine - INFO - Iter(train) [ 7900/80000]  base_lr: 9.1068e-05 lr: 9.1068e-06  eta: 11:12:54  time: 0.4850  data_time: 0.0081  memory: 5905  grad_norm: 143.6175  loss: 10.0611  decode.loss_cls: 0.3909  decode.loss_mask: 0.2028  decode.loss_dice: 0.2684  decode.d0.loss_cls: 1.4863  decode.d0.loss_mask: 0.2092  decode.d0.loss_dice: 0.3279  decode.d1.loss_cls: 0.4713  decode.d1.loss_mask: 0.2116  decode.d1.loss_dice: 0.2922  decode.d2.loss_cls: 0.4455  decode.d2.loss_mask: 0.2079  decode.d2.loss_dice: 0.2866  decode.d3.loss_cls: 0.3689  decode.d3.loss_mask: 0.2032  decode.d3.loss_dice: 0.2886  decode.d4.loss_cls: 0.4040  decode.d4.loss_mask: 0.2067  decode.d4.loss_dice: 0.3142  decode.d5.loss_cls: 0.3414  decode.d5.loss_mask: 0.2089  decode.d5.loss_dice: 0.3076  decode.d6.loss_cls: 0.3902  decode.d6.loss_mask: 0.2064  decode.d6.loss_dice: 0.2834  decode.d7.loss_cls: 0.3849  decode.d7.loss_mask: 0.2049  decode.d7.loss_dice: 0.2858  decode.d8.loss_cls: 0.3765  decode.d8.loss_mask: 0.2040  decode.d8.loss_dice: 0.2811
07/25 17:50:33 - mmengine - INFO - Iter(train) [ 7950/80000]  base_lr: 9.1011e-05 lr: 9.1011e-06  eta: 11:10:56  time: 0.4846  data_time: 0.0082  memory: 5888  grad_norm: 134.5580  loss: 10.4704  decode.loss_cls: 0.4061  decode.loss_mask: 0.2477  decode.loss_dice: 0.2714  decode.d0.loss_cls: 1.4844  decode.d0.loss_mask: 0.2678  decode.d0.loss_dice: 0.3279  decode.d1.loss_cls: 0.4017  decode.d1.loss_mask: 0.2653  decode.d1.loss_dice: 0.2926  decode.d2.loss_cls: 0.3712  decode.d2.loss_mask: 0.2670  decode.d2.loss_dice: 0.3238  decode.d3.loss_cls: 0.3703  decode.d3.loss_mask: 0.2470  decode.d3.loss_dice: 0.2805  decode.d4.loss_cls: 0.3943  decode.d4.loss_mask: 0.2519  decode.d4.loss_dice: 0.2708  decode.d5.loss_cls: 0.4083  decode.d5.loss_mask: 0.2509  decode.d5.loss_dice: 0.2774  decode.d6.loss_cls: 0.3643  decode.d6.loss_mask: 0.2517  decode.d6.loss_dice: 0.2835  decode.d7.loss_cls: 0.3822  decode.d7.loss_mask: 0.2513  decode.d7.loss_dice: 0.2974  decode.d8.loss_cls: 0.4105  decode.d8.loss_mask: 0.2520  decode.d8.loss_dice: 0.2994
07/25 17:50:57 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250725_172252
07/25 17:50:57 - mmengine - INFO - Iter(train) [ 8000/80000]  base_lr: 9.0954e-05 lr: 9.0954e-06  eta: 11:09:00  time: 0.4841  data_time: 0.0084  memory: 5959  grad_norm: 171.3274  loss: 12.2275  decode.loss_cls: 0.4446  decode.loss_mask: 0.2949  decode.loss_dice: 0.3497  decode.d0.loss_cls: 1.4235  decode.d0.loss_mask: 0.3017  decode.d0.loss_dice: 0.3726  decode.d1.loss_cls: 0.6011  decode.d1.loss_mask: 0.2935  decode.d1.loss_dice: 0.3126  decode.d2.loss_cls: 0.5067  decode.d2.loss_mask: 0.2946  decode.d2.loss_dice: 0.3321  decode.d3.loss_cls: 0.5407  decode.d3.loss_mask: 0.2946  decode.d3.loss_dice: 0.3104  decode.d4.loss_cls: 0.4905  decode.d4.loss_mask: 0.3072  decode.d4.loss_dice: 0.3392  decode.d5.loss_cls: 0.4639  decode.d5.loss_mask: 0.2902  decode.d5.loss_dice: 0.3405  decode.d6.loss_cls: 0.4546  decode.d6.loss_mask: 0.2952  decode.d6.loss_dice: 0.3337  decode.d7.loss_cls: 0.4780  decode.d7.loss_mask: 0.2978  decode.d7.loss_dice: 0.3236  decode.d8.loss_cls: 0.4957  decode.d8.loss_mask: 0.2966  decode.d8.loss_dice: 0.3475
07/25 17:51:21 - mmengine - INFO - Iter(train) [ 8050/80000]  base_lr: 9.0897e-05 lr: 9.0897e-06  eta: 11:07:06  time: 0.4857  data_time: 0.0083  memory: 5906  grad_norm: 190.2936  loss: 12.1510  decode.loss_cls: 0.4210  decode.loss_mask: 0.3077  decode.loss_dice: 0.3462  decode.d0.loss_cls: 1.4187  decode.d0.loss_mask: 0.3057  decode.d0.loss_dice: 0.4093  decode.d1.loss_cls: 0.6445  decode.d1.loss_mask: 0.3036  decode.d1.loss_dice: 0.3393  decode.d2.loss_cls: 0.4789  decode.d2.loss_mask: 0.3122  decode.d2.loss_dice: 0.3522  decode.d3.loss_cls: 0.4106  decode.d3.loss_mask: 0.3176  decode.d3.loss_dice: 0.3560  decode.d4.loss_cls: 0.4384  decode.d4.loss_mask: 0.3119  decode.d4.loss_dice: 0.3606  decode.d5.loss_cls: 0.4540  decode.d5.loss_mask: 0.3081  decode.d5.loss_dice: 0.3757  decode.d6.loss_cls: 0.4106  decode.d6.loss_mask: 0.2945  decode.d6.loss_dice: 0.3500  decode.d7.loss_cls: 0.4023  decode.d7.loss_mask: 0.2973  decode.d7.loss_dice: 0.3513  decode.d8.loss_cls: 0.4089  decode.d8.loss_mask: 0.2959  decode.d8.loss_dice: 0.3681
07/25 17:51:45 - mmengine - INFO - Iter(train) [ 8100/80000]  base_lr: 9.0841e-05 lr: 9.0841e-06  eta: 11:05:15  time: 0.4846  data_time: 0.0082  memory: 5876  grad_norm: 190.1720  loss: 10.9739  decode.loss_cls: 0.3117  decode.loss_mask: 0.3048  decode.loss_dice: 0.3648  decode.d0.loss_cls: 1.3575  decode.d0.loss_mask: 0.3246  decode.d0.loss_dice: 0.4036  decode.d1.loss_cls: 0.4373  decode.d1.loss_mask: 0.3028  decode.d1.loss_dice: 0.3534  decode.d2.loss_cls: 0.3048  decode.d2.loss_mask: 0.3102  decode.d2.loss_dice: 0.3626  decode.d3.loss_cls: 0.3009  decode.d3.loss_mask: 0.3053  decode.d3.loss_dice: 0.3542  decode.d4.loss_cls: 0.3159  decode.d4.loss_mask: 0.2963  decode.d4.loss_dice: 0.3567  decode.d5.loss_cls: 0.3094  decode.d5.loss_mask: 0.3003  decode.d5.loss_dice: 0.3467  decode.d6.loss_cls: 0.2956  decode.d6.loss_mask: 0.3072  decode.d6.loss_dice: 0.3585  decode.d7.loss_cls: 0.3249  decode.d7.loss_mask: 0.3040  decode.d7.loss_dice: 0.3621  decode.d8.loss_cls: 0.3403  decode.d8.loss_mask: 0.3028  decode.d8.loss_dice: 0.3548
07/25 17:52:09 - mmengine - INFO - Iter(train) [ 8150/80000]  base_lr: 9.0784e-05 lr: 9.0784e-06  eta: 11:03:27  time: 0.4849  data_time: 0.0084  memory: 5885  grad_norm: 201.1326  loss: 13.6340  decode.loss_cls: 0.4648  decode.loss_mask: 0.3771  decode.loss_dice: 0.3756  decode.d0.loss_cls: 1.6088  decode.d0.loss_mask: 0.2880  decode.d0.loss_dice: 0.3954  decode.d1.loss_cls: 0.6881  decode.d1.loss_mask: 0.3013  decode.d1.loss_dice: 0.3371  decode.d2.loss_cls: 0.5887  decode.d2.loss_mask: 0.3549  decode.d2.loss_dice: 0.3589  decode.d3.loss_cls: 0.5611  decode.d3.loss_mask: 0.3378  decode.d3.loss_dice: 0.3578  decode.d4.loss_cls: 0.5513  decode.d4.loss_mask: 0.3612  decode.d4.loss_dice: 0.3722  decode.d5.loss_cls: 0.5632  decode.d5.loss_mask: 0.3427  decode.d5.loss_dice: 0.3798  decode.d6.loss_cls: 0.5203  decode.d6.loss_mask: 0.3575  decode.d6.loss_dice: 0.3690  decode.d7.loss_cls: 0.4973  decode.d7.loss_mask: 0.3357  decode.d7.loss_dice: 0.3692  decode.d8.loss_cls: 0.4608  decode.d8.loss_mask: 0.4060  decode.d8.loss_dice: 0.3525
07/25 17:52:34 - mmengine - INFO - Iter(train) [ 8200/80000]  base_lr: 9.0727e-05 lr: 9.0727e-06  eta: 11:01:41  time: 0.4835  data_time: 0.0082  memory: 5907  grad_norm: 119.8216  loss: 8.5751  decode.loss_cls: 0.2787  decode.loss_mask: 0.1806  decode.loss_dice: 0.2580  decode.d0.loss_cls: 1.2488  decode.d0.loss_mask: 0.1966  decode.d0.loss_dice: 0.3196  decode.d1.loss_cls: 0.4001  decode.d1.loss_mask: 0.1838  decode.d1.loss_dice: 0.2524  decode.d2.loss_cls: 0.3301  decode.d2.loss_mask: 0.1852  decode.d2.loss_dice: 0.2732  decode.d3.loss_cls: 0.2961  decode.d3.loss_mask: 0.1827  decode.d3.loss_dice: 0.2741  decode.d4.loss_cls: 0.3108  decode.d4.loss_mask: 0.1788  decode.d4.loss_dice: 0.2596  decode.d5.loss_cls: 0.3310  decode.d5.loss_mask: 0.1798  decode.d5.loss_dice: 0.2693  decode.d6.loss_cls: 0.2888  decode.d6.loss_mask: 0.1778  decode.d6.loss_dice: 0.2593  decode.d7.loss_cls: 0.2968  decode.d7.loss_mask: 0.1794  decode.d7.loss_dice: 0.2661  decode.d8.loss_cls: 0.2875  decode.d8.loss_mask: 0.1798  decode.d8.loss_dice: 0.2505
07/25 17:52:58 - mmengine - INFO - Iter(train) [ 8250/80000]  base_lr: 9.0670e-05 lr: 9.0670e-06  eta: 10:59:58  time: 0.4845  data_time: 0.0084  memory: 5910  grad_norm: 153.7787  loss: 12.0173  decode.loss_cls: 0.4364  decode.loss_mask: 0.3589  decode.loss_dice: 0.3268  decode.d0.loss_cls: 1.5214  decode.d0.loss_mask: 0.3584  decode.d0.loss_dice: 0.4211  decode.d1.loss_cls: 0.4864  decode.d1.loss_mask: 0.3326  decode.d1.loss_dice: 0.3222  decode.d2.loss_cls: 0.4550  decode.d2.loss_mask: 0.3341  decode.d2.loss_dice: 0.3181  decode.d3.loss_cls: 0.4084  decode.d3.loss_mask: 0.3004  decode.d3.loss_dice: 0.3165  decode.d4.loss_cls: 0.4041  decode.d4.loss_mask: 0.3077  decode.d4.loss_dice: 0.3304  decode.d5.loss_cls: 0.3915  decode.d5.loss_mask: 0.3159  decode.d5.loss_dice: 0.3237  decode.d6.loss_cls: 0.4180  decode.d6.loss_mask: 0.3048  decode.d6.loss_dice: 0.3153  decode.d7.loss_cls: 0.4253  decode.d7.loss_mask: 0.3335  decode.d7.loss_dice: 0.3295  decode.d8.loss_cls: 0.4854  decode.d8.loss_mask: 0.3222  decode.d8.loss_dice: 0.3131
07/25 17:53:22 - mmengine - INFO - Iter(train) [ 8300/80000]  base_lr: 9.0613e-05 lr: 9.0613e-06  eta: 10:58:18  time: 0.4843  data_time: 0.0083  memory: 5906  grad_norm: 151.2838  loss: 14.3962  decode.loss_cls: 0.7218  decode.loss_mask: 0.2485  decode.loss_dice: 0.4383  decode.d0.loss_cls: 1.3568  decode.d0.loss_mask: 0.2815  decode.d0.loss_dice: 0.4926  decode.d1.loss_cls: 0.7315  decode.d1.loss_mask: 0.2813  decode.d1.loss_dice: 0.4450  decode.d2.loss_cls: 0.6622  decode.d2.loss_mask: 0.2553  decode.d2.loss_dice: 0.4013  decode.d3.loss_cls: 0.6031  decode.d3.loss_mask: 0.2541  decode.d3.loss_dice: 0.4436  decode.d4.loss_cls: 0.5934  decode.d4.loss_mask: 0.2490  decode.d4.loss_dice: 0.4309  decode.d5.loss_cls: 0.6295  decode.d5.loss_mask: 0.2520  decode.d5.loss_dice: 0.4250  decode.d6.loss_cls: 0.6435  decode.d6.loss_mask: 0.2769  decode.d6.loss_dice: 0.4563  decode.d7.loss_cls: 0.6130  decode.d7.loss_mask: 0.3064  decode.d7.loss_dice: 0.4859  decode.d8.loss_cls: 0.6736  decode.d8.loss_mask: 0.2765  decode.d8.loss_dice: 0.4677
07/25 17:53:46 - mmengine - INFO - Iter(train) [ 8350/80000]  base_lr: 9.0556e-05 lr: 9.0556e-06  eta: 10:56:39  time: 0.4842  data_time: 0.0083  memory: 5922  grad_norm: 116.8562  loss: 11.6014  decode.loss_cls: 0.4351  decode.loss_mask: 0.2431  decode.loss_dice: 0.3146  decode.d0.loss_cls: 1.2655  decode.d0.loss_mask: 0.2639  decode.d0.loss_dice: 0.3941  decode.d1.loss_cls: 0.6153  decode.d1.loss_mask: 0.2472  decode.d1.loss_dice: 0.3442  decode.d2.loss_cls: 0.5162  decode.d2.loss_mask: 0.2445  decode.d2.loss_dice: 0.3479  decode.d3.loss_cls: 0.5121  decode.d3.loss_mask: 0.2449  decode.d3.loss_dice: 0.3405  decode.d4.loss_cls: 0.4985  decode.d4.loss_mask: 0.2484  decode.d4.loss_dice: 0.3412  decode.d5.loss_cls: 0.5147  decode.d5.loss_mask: 0.2457  decode.d5.loss_dice: 0.3285  decode.d6.loss_cls: 0.4664  decode.d6.loss_mask: 0.2413  decode.d6.loss_dice: 0.3313  decode.d7.loss_cls: 0.4431  decode.d7.loss_mask: 0.2473  decode.d7.loss_dice: 0.3403  decode.d8.loss_cls: 0.4579  decode.d8.loss_mask: 0.2393  decode.d8.loss_dice: 0.3287
07/25 17:54:11 - mmengine - INFO - Iter(train) [ 8400/80000]  base_lr: 9.0499e-05 lr: 9.0499e-06  eta: 10:55:03  time: 0.4851  data_time: 0.0081  memory: 5905  grad_norm: 146.2189  loss: 10.4589  decode.loss_cls: 0.3029  decode.loss_mask: 0.3479  decode.loss_dice: 0.3763  decode.d0.loss_cls: 1.3013  decode.d0.loss_mask: 0.2912  decode.d0.loss_dice: 0.4070  decode.d1.loss_cls: 0.4797  decode.d1.loss_mask: 0.2927  decode.d1.loss_dice: 0.3403  decode.d2.loss_cls: 0.3066  decode.d2.loss_mask: 0.2932  decode.d2.loss_dice: 0.3422  decode.d3.loss_cls: 0.2274  decode.d3.loss_mask: 0.2841  decode.d3.loss_dice: 0.3275  decode.d4.loss_cls: 0.2875  decode.d4.loss_mask: 0.2822  decode.d4.loss_dice: 0.3276  decode.d5.loss_cls: 0.2628  decode.d5.loss_mask: 0.2953  decode.d5.loss_dice: 0.3222  decode.d6.loss_cls: 0.3326  decode.d6.loss_mask: 0.2721  decode.d6.loss_dice: 0.3049  decode.d7.loss_cls: 0.2712  decode.d7.loss_mask: 0.2983  decode.d7.loss_dice: 0.3304  decode.d8.loss_cls: 0.2751  decode.d8.loss_mask: 0.3072  decode.d8.loss_dice: 0.3691
07/25 17:54:35 - mmengine - INFO - Iter(train) [ 8450/80000]  base_lr: 9.0443e-05 lr: 9.0443e-06  eta: 10:53:29  time: 0.4848  data_time: 0.0080  memory: 5905  grad_norm: 144.6268  loss: 11.3985  decode.loss_cls: 0.3358  decode.loss_mask: 0.3123  decode.loss_dice: 0.3504  decode.d0.loss_cls: 1.1945  decode.d0.loss_mask: 0.3052  decode.d0.loss_dice: 0.4040  decode.d1.loss_cls: 0.5372  decode.d1.loss_mask: 0.3220  decode.d1.loss_dice: 0.3737  decode.d2.loss_cls: 0.3952  decode.d2.loss_mask: 0.3075  decode.d2.loss_dice: 0.3639  decode.d3.loss_cls: 0.3941  decode.d3.loss_mask: 0.3103  decode.d3.loss_dice: 0.3446  decode.d4.loss_cls: 0.4173  decode.d4.loss_mask: 0.2955  decode.d4.loss_dice: 0.3427  decode.d5.loss_cls: 0.3342  decode.d5.loss_mask: 0.3089  decode.d5.loss_dice: 0.3650  decode.d6.loss_cls: 0.3365  decode.d6.loss_mask: 0.3137  decode.d6.loss_dice: 0.3634  decode.d7.loss_cls: 0.3475  decode.d7.loss_mask: 0.3182  decode.d7.loss_dice: 0.3509  decode.d8.loss_cls: 0.3718  decode.d8.loss_mask: 0.3161  decode.d8.loss_dice: 0.3659
07/25 17:54:59 - mmengine - INFO - Iter(train) [ 8500/80000]  base_lr: 9.0386e-05 lr: 9.0386e-06  eta: 10:51:59  time: 0.4842  data_time: 0.0082  memory: 5907  grad_norm: 154.8480  loss: 10.7951  decode.loss_cls: 0.3723  decode.loss_mask: 0.2815  decode.loss_dice: 0.3051  decode.d0.loss_cls: 1.5353  decode.d0.loss_mask: 0.3292  decode.d0.loss_dice: 0.3567  decode.d1.loss_cls: 0.4538  decode.d1.loss_mask: 0.2843  decode.d1.loss_dice: 0.3395  decode.d2.loss_cls: 0.3650  decode.d2.loss_mask: 0.2818  decode.d2.loss_dice: 0.3155  decode.d3.loss_cls: 0.3104  decode.d3.loss_mask: 0.2848  decode.d3.loss_dice: 0.3077  decode.d4.loss_cls: 0.3164  decode.d4.loss_mask: 0.2849  decode.d4.loss_dice: 0.3024  decode.d5.loss_cls: 0.3271  decode.d5.loss_mask: 0.2904  decode.d5.loss_dice: 0.3052  decode.d6.loss_cls: 0.3686  decode.d6.loss_mask: 0.2779  decode.d6.loss_dice: 0.2990  decode.d7.loss_cls: 0.3436  decode.d7.loss_mask: 0.2901  decode.d7.loss_dice: 0.3075  decode.d8.loss_cls: 0.3821  decode.d8.loss_mask: 0.2770  decode.d8.loss_dice: 0.2999
07/25 17:55:24 - mmengine - INFO - Iter(train) [ 8550/80000]  base_lr: 9.0329e-05 lr: 9.0329e-06  eta: 10:50:30  time: 0.4866  data_time: 0.0084  memory: 5906  grad_norm: 126.7744  loss: 10.4313  decode.loss_cls: 0.2809  decode.loss_mask: 0.3117  decode.loss_dice: 0.3364  decode.d0.loss_cls: 1.3608  decode.d0.loss_mask: 0.3306  decode.d0.loss_dice: 0.3616  decode.d1.loss_cls: 0.3997  decode.d1.loss_mask: 0.3257  decode.d1.loss_dice: 0.3160  decode.d2.loss_cls: 0.3173  decode.d2.loss_mask: 0.3212  decode.d2.loss_dice: 0.3155  decode.d3.loss_cls: 0.2708  decode.d3.loss_mask: 0.3165  decode.d3.loss_dice: 0.3129  decode.d4.loss_cls: 0.2576  decode.d4.loss_mask: 0.3099  decode.d4.loss_dice: 0.3148  decode.d5.loss_cls: 0.2778  decode.d5.loss_mask: 0.3072  decode.d5.loss_dice: 0.3143  decode.d6.loss_cls: 0.3020  decode.d6.loss_mask: 0.3200  decode.d6.loss_dice: 0.3189  decode.d7.loss_cls: 0.2796  decode.d7.loss_mask: 0.3128  decode.d7.loss_dice: 0.3217  decode.d8.loss_cls: 0.2693  decode.d8.loss_mask: 0.3155  decode.d8.loss_dice: 0.3322
07/25 17:55:48 - mmengine - INFO - Iter(train) [ 8600/80000]  base_lr: 9.0272e-05 lr: 9.0272e-06  eta: 10:49:01  time: 0.4838  data_time: 0.0081  memory: 5885  grad_norm: 275.2930  loss: 12.0360  decode.loss_cls: 0.5260  decode.loss_mask: 0.2882  decode.loss_dice: 0.2960  decode.d0.loss_cls: 1.5719  decode.d0.loss_mask: 0.3199  decode.d0.loss_dice: 0.3443  decode.d1.loss_cls: 0.6579  decode.d1.loss_mask: 0.3001  decode.d1.loss_dice: 0.2840  decode.d2.loss_cls: 0.5681  decode.d2.loss_mask: 0.3163  decode.d2.loss_dice: 0.3531  decode.d3.loss_cls: 0.3846  decode.d3.loss_mask: 0.3032  decode.d3.loss_dice: 0.3366  decode.d4.loss_cls: 0.4295  decode.d4.loss_mask: 0.2964  decode.d4.loss_dice: 0.2811  decode.d5.loss_cls: 0.4268  decode.d5.loss_mask: 0.2937  decode.d5.loss_dice: 0.3114  decode.d6.loss_cls: 0.4502  decode.d6.loss_mask: 0.2805  decode.d6.loss_dice: 0.2895  decode.d7.loss_cls: 0.4395  decode.d7.loss_mask: 0.2964  decode.d7.loss_dice: 0.3049  decode.d8.loss_cls: 0.4922  decode.d8.loss_mask: 0.2905  decode.d8.loss_dice: 0.3032
07/25 17:56:12 - mmengine - INFO - Iter(train) [ 8650/80000]  base_lr: 9.0215e-05 lr: 9.0215e-06  eta: 10:47:35  time: 0.4850  data_time: 0.0079  memory: 5891  grad_norm: 194.3154  loss: 11.0183  decode.loss_cls: 0.5679  decode.loss_mask: 0.2158  decode.loss_dice: 0.3119  decode.d0.loss_cls: 1.4021  decode.d0.loss_mask: 0.2091  decode.d0.loss_dice: 0.3235  decode.d1.loss_cls: 0.5233  decode.d1.loss_mask: 0.2102  decode.d1.loss_dice: 0.3131  decode.d2.loss_cls: 0.4461  decode.d2.loss_mask: 0.2023  decode.d2.loss_dice: 0.3188  decode.d3.loss_cls: 0.3555  decode.d3.loss_mask: 0.2202  decode.d3.loss_dice: 0.3312  decode.d4.loss_cls: 0.4019  decode.d4.loss_mask: 0.2250  decode.d4.loss_dice: 0.3216  decode.d5.loss_cls: 0.4712  decode.d5.loss_mask: 0.2260  decode.d5.loss_dice: 0.3229  decode.d6.loss_cls: 0.4922  decode.d6.loss_mask: 0.2156  decode.d6.loss_dice: 0.3009  decode.d7.loss_cls: 0.5344  decode.d7.loss_mask: 0.2209  decode.d7.loss_dice: 0.3132  decode.d8.loss_cls: 0.5238  decode.d8.loss_mask: 0.2006  decode.d8.loss_dice: 0.2973
07/25 17:56:36 - mmengine - INFO - Iter(train) [ 8700/80000]  base_lr: 9.0158e-05 lr: 9.0158e-06  eta: 10:46:11  time: 0.4858  data_time: 0.0082  memory: 5974  grad_norm: 125.2756  loss: 10.1608  decode.loss_cls: 0.2700  decode.loss_mask: 0.2945  decode.loss_dice: 0.3262  decode.d0.loss_cls: 1.3135  decode.d0.loss_mask: 0.3073  decode.d0.loss_dice: 0.3074  decode.d1.loss_cls: 0.4330  decode.d1.loss_mask: 0.2789  decode.d1.loss_dice: 0.3219  decode.d2.loss_cls: 0.3231  decode.d2.loss_mask: 0.2823  decode.d2.loss_dice: 0.2749  decode.d3.loss_cls: 0.3542  decode.d3.loss_mask: 0.2845  decode.d3.loss_dice: 0.2571  decode.d4.loss_cls: 0.3120  decode.d4.loss_mask: 0.2909  decode.d4.loss_dice: 0.2663  decode.d5.loss_cls: 0.3287  decode.d5.loss_mask: 0.2936  decode.d5.loss_dice: 0.3135  decode.d6.loss_cls: 0.2997  decode.d6.loss_mask: 0.2983  decode.d6.loss_dice: 0.3433  decode.d7.loss_cls: 0.3154  decode.d7.loss_mask: 0.2899  decode.d7.loss_dice: 0.3154  decode.d8.loss_cls: 0.2664  decode.d8.loss_mask: 0.2934  decode.d8.loss_dice: 0.3049
07/25 17:57:01 - mmengine - INFO - Iter(train) [ 8750/80000]  base_lr: 9.0101e-05 lr: 9.0101e-06  eta: 10:44:48  time: 0.4844  data_time: 0.0081  memory: 5905  grad_norm: 142.9521  loss: 10.9750  decode.loss_cls: 0.3006  decode.loss_mask: 0.3145  decode.loss_dice: 0.3828  decode.d0.loss_cls: 1.2704  decode.d0.loss_mask: 0.3325  decode.d0.loss_dice: 0.4174  decode.d1.loss_cls: 0.3791  decode.d1.loss_mask: 0.3299  decode.d1.loss_dice: 0.3661  decode.d2.loss_cls: 0.3171  decode.d2.loss_mask: 0.3330  decode.d2.loss_dice: 0.3520  decode.d3.loss_cls: 0.2165  decode.d3.loss_mask: 0.3203  decode.d3.loss_dice: 0.3539  decode.d4.loss_cls: 0.3617  decode.d4.loss_mask: 0.3181  decode.d4.loss_dice: 0.3314  decode.d5.loss_cls: 0.3096  decode.d5.loss_mask: 0.3133  decode.d5.loss_dice: 0.3621  decode.d6.loss_cls: 0.3214  decode.d6.loss_mask: 0.3225  decode.d6.loss_dice: 0.3716  decode.d7.loss_cls: 0.3171  decode.d7.loss_mask: 0.3251  decode.d7.loss_dice: 0.3683  decode.d8.loss_cls: 0.2791  decode.d8.loss_mask: 0.3197  decode.d8.loss_dice: 0.3677
07/25 17:57:25 - mmengine - INFO - Iter(train) [ 8800/80000]  base_lr: 9.0044e-05 lr: 9.0044e-06  eta: 10:43:30  time: 0.4832  data_time: 0.0082  memory: 5907  grad_norm: 198.2181  loss: 12.1310  decode.loss_cls: 0.4244  decode.loss_mask: 0.3571  decode.loss_dice: 0.3419  decode.d0.loss_cls: 1.2302  decode.d0.loss_mask: 0.3831  decode.d0.loss_dice: 0.4120  decode.d1.loss_cls: 0.4507  decode.d1.loss_mask: 0.3687  decode.d1.loss_dice: 0.3494  decode.d2.loss_cls: 0.4531  decode.d2.loss_mask: 0.3565  decode.d2.loss_dice: 0.3251  decode.d3.loss_cls: 0.4295  decode.d3.loss_mask: 0.3658  decode.d3.loss_dice: 0.3329  decode.d4.loss_cls: 0.3898  decode.d4.loss_mask: 0.3672  decode.d4.loss_dice: 0.3503  decode.d5.loss_cls: 0.4105  decode.d5.loss_mask: 0.3628  decode.d5.loss_dice: 0.3534  decode.d6.loss_cls: 0.4133  decode.d6.loss_mask: 0.3624  decode.d6.loss_dice: 0.3438  decode.d7.loss_cls: 0.3684  decode.d7.loss_mask: 0.3673  decode.d7.loss_dice: 0.3514  decode.d8.loss_cls: 0.4076  decode.d8.loss_mask: 0.3607  decode.d8.loss_dice: 0.3416
07/25 17:57:49 - mmengine - INFO - Iter(train) [ 8850/80000]  base_lr: 8.9987e-05 lr: 8.9987e-06  eta: 10:42:09  time: 0.4843  data_time: 0.0083  memory: 5923  grad_norm: 159.7852  loss: 11.0985  decode.loss_cls: 0.3657  decode.loss_mask: 0.3128  decode.loss_dice: 0.3119  decode.d0.loss_cls: 1.2015  decode.d0.loss_mask: 0.3313  decode.d0.loss_dice: 0.4110  decode.d1.loss_cls: 0.5629  decode.d1.loss_mask: 0.3088  decode.d1.loss_dice: 0.3187  decode.d2.loss_cls: 0.4498  decode.d2.loss_mask: 0.2998  decode.d2.loss_dice: 0.3096  decode.d3.loss_cls: 0.3582  decode.d3.loss_mask: 0.2994  decode.d3.loss_dice: 0.3069  decode.d4.loss_cls: 0.3683  decode.d4.loss_mask: 0.3045  decode.d4.loss_dice: 0.2968  decode.d5.loss_cls: 0.3835  decode.d5.loss_mask: 0.3007  decode.d5.loss_dice: 0.3070  decode.d6.loss_cls: 0.3556  decode.d6.loss_mask: 0.3026  decode.d6.loss_dice: 0.2938  decode.d7.loss_cls: 0.3922  decode.d7.loss_mask: 0.3188  decode.d7.loss_dice: 0.3042  decode.d8.loss_cls: 0.3797  decode.d8.loss_mask: 0.3244  decode.d8.loss_dice: 0.3181
07/25 17:58:13 - mmengine - INFO - Iter(train) [ 8900/80000]  base_lr: 8.9930e-05 lr: 8.9930e-06  eta: 10:40:49  time: 0.4840  data_time: 0.0081  memory: 5907  grad_norm: 247.8563  loss: 12.4362  decode.loss_cls: 0.3681  decode.loss_mask: 0.3218  decode.loss_dice: 0.3839  decode.d0.loss_cls: 1.4147  decode.d0.loss_mask: 0.4109  decode.d0.loss_dice: 0.4209  decode.d1.loss_cls: 0.5171  decode.d1.loss_mask: 0.3074  decode.d1.loss_dice: 0.3730  decode.d2.loss_cls: 0.4981  decode.d2.loss_mask: 0.3009  decode.d2.loss_dice: 0.3658  decode.d3.loss_cls: 0.4089  decode.d3.loss_mask: 0.3112  decode.d3.loss_dice: 0.3809  decode.d4.loss_cls: 0.4339  decode.d4.loss_mask: 0.2912  decode.d4.loss_dice: 0.3771  decode.d5.loss_cls: 0.5261  decode.d5.loss_mask: 0.3083  decode.d5.loss_dice: 0.3901  decode.d6.loss_cls: 0.5107  decode.d6.loss_mask: 0.2936  decode.d6.loss_dice: 0.3672  decode.d7.loss_cls: 0.4246  decode.d7.loss_mask: 0.3029  decode.d7.loss_dice: 0.3829  decode.d8.loss_cls: 0.3768  decode.d8.loss_mask: 0.3044  decode.d8.loss_dice: 0.3631
07/25 17:58:38 - mmengine - INFO - Iter(train) [ 8950/80000]  base_lr: 8.9873e-05 lr: 8.9873e-06  eta: 10:39:31  time: 0.4837  data_time: 0.0081  memory: 5906  grad_norm: 181.5275  loss: 13.3947  decode.loss_cls: 0.5175  decode.loss_mask: 0.3099  decode.loss_dice: 0.3933  decode.d0.loss_cls: 1.4757  decode.d0.loss_mask: 0.3349  decode.d0.loss_dice: 0.4511  decode.d1.loss_cls: 0.5815  decode.d1.loss_mask: 0.3030  decode.d1.loss_dice: 0.4172  decode.d2.loss_cls: 0.5148  decode.d2.loss_mask: 0.2978  decode.d2.loss_dice: 0.4007  decode.d3.loss_cls: 0.5598  decode.d3.loss_mask: 0.2961  decode.d3.loss_dice: 0.3887  decode.d4.loss_cls: 0.5269  decode.d4.loss_mask: 0.2946  decode.d4.loss_dice: 0.3907  decode.d5.loss_cls: 0.5641  decode.d5.loss_mask: 0.2876  decode.d5.loss_dice: 0.3889  decode.d6.loss_cls: 0.5182  decode.d6.loss_mask: 0.2987  decode.d6.loss_dice: 0.4046  decode.d7.loss_cls: 0.4989  decode.d7.loss_mask: 0.3056  decode.d7.loss_dice: 0.3989  decode.d8.loss_cls: 0.5641  decode.d8.loss_mask: 0.3118  decode.d8.loss_dice: 0.3989
07/25 17:59:02 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250725_172252
07/25 17:59:02 - mmengine - INFO - Iter(train) [ 9000/80000]  base_lr: 8.9817e-05 lr: 8.9817e-06  eta: 10:38:15  time: 0.4852  data_time: 0.0082  memory: 5910  grad_norm: 158.3520  loss: 12.8556  decode.loss_cls: 0.4820  decode.loss_mask: 0.3033  decode.loss_dice: 0.4093  decode.d0.loss_cls: 1.3847  decode.d0.loss_mask: 0.3185  decode.d0.loss_dice: 0.4630  decode.d1.loss_cls: 0.6184  decode.d1.loss_mask: 0.2811  decode.d1.loss_dice: 0.4181  decode.d2.loss_cls: 0.4927  decode.d2.loss_mask: 0.2700  decode.d2.loss_dice: 0.3879  decode.d3.loss_cls: 0.4721  decode.d3.loss_mask: 0.2709  decode.d3.loss_dice: 0.3684  decode.d4.loss_cls: 0.4800  decode.d4.loss_mask: 0.2774  decode.d4.loss_dice: 0.3736  decode.d5.loss_cls: 0.5316  decode.d5.loss_mask: 0.2704  decode.d5.loss_dice: 0.3713  decode.d6.loss_cls: 0.5415  decode.d6.loss_mask: 0.2772  decode.d6.loss_dice: 0.3721  decode.d7.loss_cls: 0.5324  decode.d7.loss_mask: 0.2883  decode.d7.loss_dice: 0.3876  decode.d8.loss_cls: 0.5566  decode.d8.loss_mask: 0.2864  decode.d8.loss_dice: 0.3689
07/25 17:59:26 - mmengine - INFO - Iter(train) [ 9050/80000]  base_lr: 8.9760e-05 lr: 8.9760e-06  eta: 10:36:59  time: 0.4841  data_time: 0.0082  memory: 5904  grad_norm: 227.5795  loss: 10.6250  decode.loss_cls: 0.2925  decode.loss_mask: 0.2689  decode.loss_dice: 0.3257  decode.d0.loss_cls: 1.4023  decode.d0.loss_mask: 0.2849  decode.d0.loss_dice: 0.3845  decode.d1.loss_cls: 0.4730  decode.d1.loss_mask: 0.2685  decode.d1.loss_dice: 0.3584  decode.d2.loss_cls: 0.3700  decode.d2.loss_mask: 0.2747  decode.d2.loss_dice: 0.3301  decode.d3.loss_cls: 0.3455  decode.d3.loss_mask: 0.2662  decode.d3.loss_dice: 0.3355  decode.d4.loss_cls: 0.3201  decode.d4.loss_mask: 0.2679  decode.d4.loss_dice: 0.3437  decode.d5.loss_cls: 0.3318  decode.d5.loss_mask: 0.2861  decode.d5.loss_dice: 0.3450  decode.d6.loss_cls: 0.2958  decode.d6.loss_mask: 0.2637  decode.d6.loss_dice: 0.3489  decode.d7.loss_cls: 0.2813  decode.d7.loss_mask: 0.2772  decode.d7.loss_dice: 0.3404  decode.d8.loss_cls: 0.3069  decode.d8.loss_mask: 0.2691  decode.d8.loss_dice: 0.3661
07/25 17:59:50 - mmengine - INFO - Iter(train) [ 9100/80000]  base_lr: 8.9703e-05 lr: 8.9703e-06  eta: 10:35:45  time: 0.4835  data_time: 0.0080  memory: 5888  grad_norm: 133.5390  loss: 10.3393  decode.loss_cls: 0.2125  decode.loss_mask: 0.3263  decode.loss_dice: 0.3490  decode.d0.loss_cls: 1.3019  decode.d0.loss_mask: 0.3362  decode.d0.loss_dice: 0.3899  decode.d1.loss_cls: 0.4023  decode.d1.loss_mask: 0.3251  decode.d1.loss_dice: 0.3738  decode.d2.loss_cls: 0.2890  decode.d2.loss_mask: 0.3254  decode.d2.loss_dice: 0.3635  decode.d3.loss_cls: 0.2454  decode.d3.loss_mask: 0.3286  decode.d3.loss_dice: 0.3523  decode.d4.loss_cls: 0.2469  decode.d4.loss_mask: 0.3199  decode.d4.loss_dice: 0.3640  decode.d5.loss_cls: 0.2063  decode.d5.loss_mask: 0.3258  decode.d5.loss_dice: 0.3639  decode.d6.loss_cls: 0.1740  decode.d6.loss_mask: 0.3228  decode.d6.loss_dice: 0.3490  decode.d7.loss_cls: 0.1807  decode.d7.loss_mask: 0.3304  decode.d7.loss_dice: 0.3697  decode.d8.loss_cls: 0.1879  decode.d8.loss_mask: 0.3226  decode.d8.loss_dice: 0.3545
07/25 18:00:14 - mmengine - INFO - Iter(train) [ 9150/80000]  base_lr: 8.9646e-05 lr: 8.9646e-06  eta: 10:34:32  time: 0.4847  data_time: 0.0080  memory: 5922  grad_norm: 135.3092  loss: 8.7441  decode.loss_cls: 0.1754  decode.loss_mask: 0.3036  decode.loss_dice: 0.2919  decode.d0.loss_cls: 1.1812  decode.d0.loss_mask: 0.3271  decode.d0.loss_dice: 0.3219  decode.d1.loss_cls: 0.2008  decode.d1.loss_mask: 0.3088  decode.d1.loss_dice: 0.2837  decode.d2.loss_cls: 0.1588  decode.d2.loss_mask: 0.3078  decode.d2.loss_dice: 0.2908  decode.d3.loss_cls: 0.1773  decode.d3.loss_mask: 0.3034  decode.d3.loss_dice: 0.2793  decode.d4.loss_cls: 0.1529  decode.d4.loss_mask: 0.3048  decode.d4.loss_dice: 0.2829  decode.d5.loss_cls: 0.1717  decode.d5.loss_mask: 0.3019  decode.d5.loss_dice: 0.2791  decode.d6.loss_cls: 0.1716  decode.d6.loss_mask: 0.3053  decode.d6.loss_dice: 0.2800  decode.d7.loss_cls: 0.1628  decode.d7.loss_mask: 0.3081  decode.d7.loss_dice: 0.2914  decode.d8.loss_cls: 0.2244  decode.d8.loss_mask: 0.3073  decode.d8.loss_dice: 0.2882
07/25 18:00:39 - mmengine - INFO - Iter(train) [ 9200/80000]  base_lr: 8.9589e-05 lr: 8.9589e-06  eta: 10:33:21  time: 0.4869  data_time: 0.0081  memory: 5885  grad_norm: 203.8670  loss: 11.8319  decode.loss_cls: 0.5026  decode.loss_mask: 0.2899  decode.loss_dice: 0.3244  decode.d0.loss_cls: 1.2835  decode.d0.loss_mask: 0.2968  decode.d0.loss_dice: 0.3620  decode.d1.loss_cls: 0.6204  decode.d1.loss_mask: 0.2861  decode.d1.loss_dice: 0.3091  decode.d2.loss_cls: 0.4927  decode.d2.loss_mask: 0.2894  decode.d2.loss_dice: 0.3441  decode.d3.loss_cls: 0.4595  decode.d3.loss_mask: 0.2944  decode.d3.loss_dice: 0.3435  decode.d4.loss_cls: 0.4081  decode.d4.loss_mask: 0.2961  decode.d4.loss_dice: 0.3154  decode.d5.loss_cls: 0.4695  decode.d5.loss_mask: 0.2955  decode.d5.loss_dice: 0.3215  decode.d6.loss_cls: 0.4337  decode.d6.loss_mask: 0.2999  decode.d6.loss_dice: 0.3176  decode.d7.loss_cls: 0.4839  decode.d7.loss_mask: 0.2984  decode.d7.loss_dice: 0.3031  decode.d8.loss_cls: 0.4904  decode.d8.loss_mask: 0.2905  decode.d8.loss_dice: 0.3098
07/25 18:01:03 - mmengine - INFO - Iter(train) [ 9250/80000]  base_lr: 8.9532e-05 lr: 8.9532e-06  eta: 10:32:10  time: 0.4839  data_time: 0.0079  memory: 5906  grad_norm: 225.3579  loss: 11.5961  decode.loss_cls: 0.3928  decode.loss_mask: 0.3250  decode.loss_dice: 0.3310  decode.d0.loss_cls: 1.3658  decode.d0.loss_mask: 0.3495  decode.d0.loss_dice: 0.3533  decode.d1.loss_cls: 0.5749  decode.d1.loss_mask: 0.3317  decode.d1.loss_dice: 0.3089  decode.d2.loss_cls: 0.3839  decode.d2.loss_mask: 0.3256  decode.d2.loss_dice: 0.3247  decode.d3.loss_cls: 0.4436  decode.d3.loss_mask: 0.3250  decode.d3.loss_dice: 0.3134  decode.d4.loss_cls: 0.3485  decode.d4.loss_mask: 0.3398  decode.d4.loss_dice: 0.3320  decode.d5.loss_cls: 0.3521  decode.d5.loss_mask: 0.3310  decode.d5.loss_dice: 0.3346  decode.d6.loss_cls: 0.3746  decode.d6.loss_mask: 0.3258  decode.d6.loss_dice: 0.3149  decode.d7.loss_cls: 0.3902  decode.d7.loss_mask: 0.3200  decode.d7.loss_dice: 0.3143  decode.d8.loss_cls: 0.4222  decode.d8.loss_mask: 0.3299  decode.d8.loss_dice: 0.3172
07/25 18:01:27 - mmengine - INFO - Iter(train) [ 9300/80000]  base_lr: 8.9475e-05 lr: 8.9475e-06  eta: 10:31:01  time: 0.4838  data_time: 0.0082  memory: 5923  grad_norm: 142.9449  loss: 10.0250  decode.loss_cls: 0.2202  decode.loss_mask: 0.2944  decode.loss_dice: 0.3519  decode.d0.loss_cls: 1.1217  decode.d0.loss_mask: 0.3051  decode.d0.loss_dice: 0.3556  decode.d1.loss_cls: 0.3055  decode.d1.loss_mask: 0.3071  decode.d1.loss_dice: 0.3563  decode.d2.loss_cls: 0.3055  decode.d2.loss_mask: 0.2965  decode.d2.loss_dice: 0.3466  decode.d3.loss_cls: 0.2776  decode.d3.loss_mask: 0.2957  decode.d3.loss_dice: 0.3495  decode.d4.loss_cls: 0.2692  decode.d4.loss_mask: 0.2981  decode.d4.loss_dice: 0.3547  decode.d5.loss_cls: 0.2399  decode.d5.loss_mask: 0.3001  decode.d5.loss_dice: 0.3548  decode.d6.loss_cls: 0.2776  decode.d6.loss_mask: 0.2956  decode.d6.loss_dice: 0.3351  decode.d7.loss_cls: 0.2740  decode.d7.loss_mask: 0.2919  decode.d7.loss_dice: 0.3505  decode.d8.loss_cls: 0.2592  decode.d8.loss_mask: 0.2959  decode.d8.loss_dice: 0.3392
07/25 18:01:51 - mmengine - INFO - Iter(train) [ 9350/80000]  base_lr: 8.9418e-05 lr: 8.9418e-06  eta: 10:29:53  time: 0.4845  data_time: 0.0080  memory: 5888  grad_norm: 114.5378  loss: 9.8572  decode.loss_cls: 0.3184  decode.loss_mask: 0.2561  decode.loss_dice: 0.2893  decode.d0.loss_cls: 1.1554  decode.d0.loss_mask: 0.2568  decode.d0.loss_dice: 0.3308  decode.d1.loss_cls: 0.4053  decode.d1.loss_mask: 0.2672  decode.d1.loss_dice: 0.3091  decode.d2.loss_cls: 0.3258  decode.d2.loss_mask: 0.2639  decode.d2.loss_dice: 0.3374  decode.d3.loss_cls: 0.3165  decode.d3.loss_mask: 0.2776  decode.d3.loss_dice: 0.3159  decode.d4.loss_cls: 0.2980  decode.d4.loss_mask: 0.2722  decode.d4.loss_dice: 0.3397  decode.d5.loss_cls: 0.2753  decode.d5.loss_mask: 0.2737  decode.d5.loss_dice: 0.3161  decode.d6.loss_cls: 0.3172  decode.d6.loss_mask: 0.2618  decode.d6.loss_dice: 0.3010  decode.d7.loss_cls: 0.3183  decode.d7.loss_mask: 0.2591  decode.d7.loss_dice: 0.2879  decode.d8.loss_cls: 0.3091  decode.d8.loss_mask: 0.2673  decode.d8.loss_dice: 0.3349
07/25 18:02:16 - mmengine - INFO - Iter(train) [ 9400/80000]  base_lr: 8.9361e-05 lr: 8.9361e-06  eta: 10:28:48  time: 0.4843  data_time: 0.0081  memory: 5922  grad_norm: 158.9528  loss: 11.2656  decode.loss_cls: 0.4617  decode.loss_mask: 0.2443  decode.loss_dice: 0.3088  decode.d0.loss_cls: 1.6588  decode.d0.loss_mask: 0.2652  decode.d0.loss_dice: 0.3240  decode.d1.loss_cls: 0.5544  decode.d1.loss_mask: 0.2581  decode.d1.loss_dice: 0.3189  decode.d2.loss_cls: 0.4436  decode.d2.loss_mask: 0.2438  decode.d2.loss_dice: 0.3078  decode.d3.loss_cls: 0.4323  decode.d3.loss_mask: 0.2449  decode.d3.loss_dice: 0.2970  decode.d4.loss_cls: 0.3994  decode.d4.loss_mask: 0.2479  decode.d4.loss_dice: 0.2956  decode.d5.loss_cls: 0.4065  decode.d5.loss_mask: 0.2421  decode.d5.loss_dice: 0.2947  decode.d6.loss_cls: 0.4628  decode.d6.loss_mask: 0.2422  decode.d6.loss_dice: 0.3039  decode.d7.loss_cls: 0.4729  decode.d7.loss_mask: 0.2420  decode.d7.loss_dice: 0.2859  decode.d8.loss_cls: 0.4642  decode.d8.loss_mask: 0.2422  decode.d8.loss_dice: 0.2995
07/25 18:02:40 - mmengine - INFO - Iter(train) [ 9450/80000]  base_lr: 8.9304e-05 lr: 8.9304e-06  eta: 10:27:42  time: 0.4835  data_time: 0.0083  memory: 5873  grad_norm: 216.1107  loss: 9.2584  decode.loss_cls: 0.2860  decode.loss_mask: 0.2804  decode.loss_dice: 0.2944  decode.d0.loss_cls: 1.1741  decode.d0.loss_mask: 0.2935  decode.d0.loss_dice: 0.3246  decode.d1.loss_cls: 0.2599  decode.d1.loss_mask: 0.2769  decode.d1.loss_dice: 0.2800  decode.d2.loss_cls: 0.2968  decode.d2.loss_mask: 0.2843  decode.d2.loss_dice: 0.2776  decode.d3.loss_cls: 0.2674  decode.d3.loss_mask: 0.2832  decode.d3.loss_dice: 0.2724  decode.d4.loss_cls: 0.3051  decode.d4.loss_mask: 0.2865  decode.d4.loss_dice: 0.2706  decode.d5.loss_cls: 0.2532  decode.d5.loss_mask: 0.2820  decode.d5.loss_dice: 0.2918  decode.d6.loss_cls: 0.2487  decode.d6.loss_mask: 0.2844  decode.d6.loss_dice: 0.2758  decode.d7.loss_cls: 0.2241  decode.d7.loss_mask: 0.2839  decode.d7.loss_dice: 0.2820  decode.d8.loss_cls: 0.2293  decode.d8.loss_mask: 0.3003  decode.d8.loss_dice: 0.2893
07/25 18:03:04 - mmengine - INFO - Iter(train) [ 9500/80000]  base_lr: 8.9247e-05 lr: 8.9247e-06  eta: 10:26:37  time: 0.4837  data_time: 0.0084  memory: 5927  grad_norm: 227.6758  loss: 14.0046  decode.loss_cls: 0.2321  decode.loss_mask: 0.4840  decode.loss_dice: 0.5046  decode.d0.loss_cls: 1.1425  decode.d0.loss_mask: 0.5028  decode.d0.loss_dice: 0.5974  decode.d1.loss_cls: 0.3743  decode.d1.loss_mask: 0.4806  decode.d1.loss_dice: 0.5198  decode.d2.loss_cls: 0.3466  decode.d2.loss_mask: 0.4817  decode.d2.loss_dice: 0.5598  decode.d3.loss_cls: 0.2779  decode.d3.loss_mask: 0.4760  decode.d3.loss_dice: 0.5246  decode.d4.loss_cls: 0.2741  decode.d4.loss_mask: 0.4704  decode.d4.loss_dice: 0.5228  decode.d5.loss_cls: 0.3470  decode.d5.loss_mask: 0.4735  decode.d5.loss_dice: 0.5624  decode.d6.loss_cls: 0.2684  decode.d6.loss_mask: 0.4762  decode.d6.loss_dice: 0.5701  decode.d7.loss_cls: 0.2633  decode.d7.loss_mask: 0.4775  decode.d7.loss_dice: 0.5542  decode.d8.loss_cls: 0.2525  decode.d8.loss_mask: 0.4833  decode.d8.loss_dice: 0.5042
07/25 18:03:28 - mmengine - INFO - Iter(train) [ 9550/80000]  base_lr: 8.9190e-05 lr: 8.9190e-06  eta: 10:25:32  time: 0.4844  data_time: 0.0081  memory: 5910  grad_norm: 163.6487  loss: 10.4451  decode.loss_cls: 0.2961  decode.loss_mask: 0.2616  decode.loss_dice: 0.3077  decode.d0.loss_cls: 1.4386  decode.d0.loss_mask: 0.2907  decode.d0.loss_dice: 0.3320  decode.d1.loss_cls: 0.4372  decode.d1.loss_mask: 0.2692  decode.d1.loss_dice: 0.3421  decode.d2.loss_cls: 0.3621  decode.d2.loss_mask: 0.2663  decode.d2.loss_dice: 0.3216  decode.d3.loss_cls: 0.3508  decode.d3.loss_mask: 0.2807  decode.d3.loss_dice: 0.3126  decode.d4.loss_cls: 0.3234  decode.d4.loss_mask: 0.2665  decode.d4.loss_dice: 0.3155  decode.d5.loss_cls: 0.3506  decode.d5.loss_mask: 0.2739  decode.d5.loss_dice: 0.3153  decode.d6.loss_cls: 0.3732  decode.d6.loss_mask: 0.2708  decode.d6.loss_dice: 0.3230  decode.d7.loss_cls: 0.2842  decode.d7.loss_mask: 0.2668  decode.d7.loss_dice: 0.3175  decode.d8.loss_cls: 0.3078  decode.d8.loss_mask: 0.2683  decode.d8.loss_dice: 0.3191
07/25 18:03:53 - mmengine - INFO - Iter(train) [ 9600/80000]  base_lr: 8.9133e-05 lr: 8.9133e-06  eta: 10:24:28  time: 0.4831  data_time: 0.0083  memory: 5923  grad_norm: 393.7199  loss: 10.0174  decode.loss_cls: 0.3014  decode.loss_mask: 0.2766  decode.loss_dice: 0.2902  decode.d0.loss_cls: 1.2748  decode.d0.loss_mask: 0.2956  decode.d0.loss_dice: 0.3177  decode.d1.loss_cls: 0.4383  decode.d1.loss_mask: 0.2685  decode.d1.loss_dice: 0.2848  decode.d2.loss_cls: 0.3692  decode.d2.loss_mask: 0.2760  decode.d2.loss_dice: 0.2915  decode.d3.loss_cls: 0.4423  decode.d3.loss_mask: 0.2554  decode.d3.loss_dice: 0.2828  decode.d4.loss_cls: 0.3262  decode.d4.loss_mask: 0.2576  decode.d4.loss_dice: 0.2714  decode.d5.loss_cls: 0.3060  decode.d5.loss_mask: 0.2706  decode.d5.loss_dice: 0.2800  decode.d6.loss_cls: 0.3044  decode.d6.loss_mask: 0.2824  decode.d6.loss_dice: 0.2965  decode.d7.loss_cls: 0.3089  decode.d7.loss_mask: 0.2634  decode.d7.loss_dice: 0.2786  decode.d8.loss_cls: 0.3581  decode.d8.loss_mask: 0.2719  decode.d8.loss_dice: 0.2763
07/25 18:04:17 - mmengine - INFO - Iter(train) [ 9650/80000]  base_lr: 8.9076e-05 lr: 8.9076e-06  eta: 10:23:25  time: 0.4847  data_time: 0.0082  memory: 5922  grad_norm: 159.0090  loss: 10.8921  decode.loss_cls: 0.2469  decode.loss_mask: 0.3704  decode.loss_dice: 0.3701  decode.d0.loss_cls: 1.3755  decode.d0.loss_mask: 0.2888  decode.d0.loss_dice: 0.4036  decode.d1.loss_cls: 0.3205  decode.d1.loss_mask: 0.3207  decode.d1.loss_dice: 0.3713  decode.d2.loss_cls: 0.2703  decode.d2.loss_mask: 0.3314  decode.d2.loss_dice: 0.3681  decode.d3.loss_cls: 0.2504  decode.d3.loss_mask: 0.3288  decode.d3.loss_dice: 0.3678  decode.d4.loss_cls: 0.3148  decode.d4.loss_mask: 0.2994  decode.d4.loss_dice: 0.3686  decode.d5.loss_cls: 0.2944  decode.d5.loss_mask: 0.2904  decode.d5.loss_dice: 0.3658  decode.d6.loss_cls: 0.2889  decode.d6.loss_mask: 0.3324  decode.d6.loss_dice: 0.3576  decode.d7.loss_cls: 0.3189  decode.d7.loss_mask: 0.3041  decode.d7.loss_dice: 0.3491  decode.d8.loss_cls: 0.2692  decode.d8.loss_mask: 0.3898  decode.d8.loss_dice: 0.3641
07/25 18:04:41 - mmengine - INFO - Iter(train) [ 9700/80000]  base_lr: 8.9019e-05 lr: 8.9019e-06  eta: 10:22:23  time: 0.4834  data_time: 0.0083  memory: 5906  grad_norm: 154.0348  loss: 9.9699  decode.loss_cls: 0.2573  decode.loss_mask: 0.2984  decode.loss_dice: 0.2801  decode.d0.loss_cls: 1.1358  decode.d0.loss_mask: 0.3255  decode.d0.loss_dice: 0.3838  decode.d1.loss_cls: 0.4289  decode.d1.loss_mask: 0.2959  decode.d1.loss_dice: 0.2844  decode.d2.loss_cls: 0.3374  decode.d2.loss_mask: 0.3032  decode.d2.loss_dice: 0.2869  decode.d3.loss_cls: 0.2905  decode.d3.loss_mask: 0.3045  decode.d3.loss_dice: 0.2844  decode.d4.loss_cls: 0.3724  decode.d4.loss_mask: 0.2981  decode.d4.loss_dice: 0.2819  decode.d5.loss_cls: 0.3440  decode.d5.loss_mask: 0.3040  decode.d5.loss_dice: 0.2947  decode.d6.loss_cls: 0.3113  decode.d6.loss_mask: 0.3064  decode.d6.loss_dice: 0.3111  decode.d7.loss_cls: 0.2585  decode.d7.loss_mask: 0.3004  decode.d7.loss_dice: 0.2868  decode.d8.loss_cls: 0.2233  decode.d8.loss_mask: 0.3036  decode.d8.loss_dice: 0.2765
07/25 18:05:05 - mmengine - INFO - Iter(train) [ 9750/80000]  base_lr: 8.8962e-05 lr: 8.8962e-06  eta: 10:21:22  time: 0.4836  data_time: 0.0084  memory: 5966  grad_norm: 201.6236  loss: 11.7709  decode.loss_cls: 0.4549  decode.loss_mask: 0.2852  decode.loss_dice: 0.2952  decode.d0.loss_cls: 1.6336  decode.d0.loss_mask: 0.3105  decode.d0.loss_dice: 0.3568  decode.d1.loss_cls: 0.5990  decode.d1.loss_mask: 0.2835  decode.d1.loss_dice: 0.3162  decode.d2.loss_cls: 0.4961  decode.d2.loss_mask: 0.3013  decode.d2.loss_dice: 0.2965  decode.d3.loss_cls: 0.4067  decode.d3.loss_mask: 0.2928  decode.d3.loss_dice: 0.2768  decode.d4.loss_cls: 0.3979  decode.d4.loss_mask: 0.2917  decode.d4.loss_dice: 0.2946  decode.d5.loss_cls: 0.3970  decode.d5.loss_mask: 0.2856  decode.d5.loss_dice: 0.3035  decode.d6.loss_cls: 0.4266  decode.d6.loss_mask: 0.3001  decode.d6.loss_dice: 0.3025  decode.d7.loss_cls: 0.4974  decode.d7.loss_mask: 0.3134  decode.d7.loss_dice: 0.3084  decode.d8.loss_cls: 0.4512  decode.d8.loss_mask: 0.2849  decode.d8.loss_dice: 0.3109
07/25 18:05:29 - mmengine - INFO - Iter(train) [ 9800/80000]  base_lr: 8.8905e-05 lr: 8.8905e-06  eta: 10:20:21  time: 0.4842  data_time: 0.0082  memory: 5906  grad_norm: 218.5940  loss: 9.5611  decode.loss_cls: 0.1953  decode.loss_mask: 0.3124  decode.loss_dice: 0.3147  decode.d0.loss_cls: 1.3535  decode.d0.loss_mask: 0.3259  decode.d0.loss_dice: 0.3449  decode.d1.loss_cls: 0.2168  decode.d1.loss_mask: 0.3129  decode.d1.loss_dice: 0.3212  decode.d2.loss_cls: 0.2068  decode.d2.loss_mask: 0.3204  decode.d2.loss_dice: 0.3289  decode.d3.loss_cls: 0.2369  decode.d3.loss_mask: 0.3083  decode.d3.loss_dice: 0.3137  decode.d4.loss_cls: 0.2114  decode.d4.loss_mask: 0.3103  decode.d4.loss_dice: 0.3242  decode.d5.loss_cls: 0.1900  decode.d5.loss_mask: 0.3024  decode.d5.loss_dice: 0.3215  decode.d6.loss_cls: 0.1941  decode.d6.loss_mask: 0.3031  decode.d6.loss_dice: 0.3270  decode.d7.loss_cls: 0.1910  decode.d7.loss_mask: 0.3038  decode.d7.loss_dice: 0.3278  decode.d8.loss_cls: 0.2155  decode.d8.loss_mask: 0.3069  decode.d8.loss_dice: 0.3196
07/25 18:05:54 - mmengine - INFO - Iter(train) [ 9850/80000]  base_lr: 8.8848e-05 lr: 8.8848e-06  eta: 10:19:22  time: 0.4853  data_time: 0.0085  memory: 5922  grad_norm: 158.4303  loss: 11.0776  decode.loss_cls: 0.2752  decode.loss_mask: 0.3653  decode.loss_dice: 0.3360  decode.d0.loss_cls: 1.2685  decode.d0.loss_mask: 0.3735  decode.d0.loss_dice: 0.3687  decode.d1.loss_cls: 0.4948  decode.d1.loss_mask: 0.3622  decode.d1.loss_dice: 0.3449  decode.d2.loss_cls: 0.4281  decode.d2.loss_mask: 0.3519  decode.d2.loss_dice: 0.3360  decode.d3.loss_cls: 0.3364  decode.d3.loss_mask: 0.3457  decode.d3.loss_dice: 0.3290  decode.d4.loss_cls: 0.2612  decode.d4.loss_mask: 0.3508  decode.d4.loss_dice: 0.3328  decode.d5.loss_cls: 0.2711  decode.d5.loss_mask: 0.3489  decode.d5.loss_dice: 0.3331  decode.d6.loss_cls: 0.2588  decode.d6.loss_mask: 0.3502  decode.d6.loss_dice: 0.3365  decode.d7.loss_cls: 0.2446  decode.d7.loss_mask: 0.3501  decode.d7.loss_dice: 0.3425  decode.d8.loss_cls: 0.2734  decode.d8.loss_mask: 0.3576  decode.d8.loss_dice: 0.3499
07/25 18:06:18 - mmengine - INFO - Iter(train) [ 9900/80000]  base_lr: 8.8791e-05 lr: 8.8791e-06  eta: 10:18:24  time: 0.4829  data_time: 0.0082  memory: 5910  grad_norm: 194.8980  loss: 10.5295  decode.loss_cls: 0.2346  decode.loss_mask: 0.3069  decode.loss_dice: 0.3237  decode.d0.loss_cls: 1.2688  decode.d0.loss_mask: 0.3487  decode.d0.loss_dice: 0.4082  decode.d1.loss_cls: 0.3962  decode.d1.loss_mask: 0.3316  decode.d1.loss_dice: 0.3632  decode.d2.loss_cls: 0.3669  decode.d2.loss_mask: 0.2919  decode.d2.loss_dice: 0.3584  decode.d3.loss_cls: 0.2654  decode.d3.loss_mask: 0.3369  decode.d3.loss_dice: 0.3409  decode.d4.loss_cls: 0.2360  decode.d4.loss_mask: 0.2967  decode.d4.loss_dice: 0.3232  decode.d5.loss_cls: 0.2802  decode.d5.loss_mask: 0.3375  decode.d5.loss_dice: 0.3378  decode.d6.loss_cls: 0.3136  decode.d6.loss_mask: 0.2872  decode.d6.loss_dice: 0.3122  decode.d7.loss_cls: 0.2890  decode.d7.loss_mask: 0.3037  decode.d7.loss_dice: 0.3379  decode.d8.loss_cls: 0.2417  decode.d8.loss_mask: 0.3256  decode.d8.loss_dice: 0.3647
07/25 18:06:42 - mmengine - INFO - Iter(train) [ 9950/80000]  base_lr: 8.8734e-05 lr: 8.8734e-06  eta: 10:17:25  time: 0.4830  data_time: 0.0083  memory: 5906  grad_norm: 175.3057  loss: 12.4794  decode.loss_cls: 0.5049  decode.loss_mask: 0.3565  decode.loss_dice: 0.3238  decode.d0.loss_cls: 1.2584  decode.d0.loss_mask: 0.3564  decode.d0.loss_dice: 0.3743  decode.d1.loss_cls: 0.5377  decode.d1.loss_mask: 0.3579  decode.d1.loss_dice: 0.3269  decode.d2.loss_cls: 0.5392  decode.d2.loss_mask: 0.3541  decode.d2.loss_dice: 0.3184  decode.d3.loss_cls: 0.5064  decode.d3.loss_mask: 0.3529  decode.d3.loss_dice: 0.3198  decode.d4.loss_cls: 0.4644  decode.d4.loss_mask: 0.3727  decode.d4.loss_dice: 0.3376  decode.d5.loss_cls: 0.4497  decode.d5.loss_mask: 0.3610  decode.d5.loss_dice: 0.3484  decode.d6.loss_cls: 0.4148  decode.d6.loss_mask: 0.3641  decode.d6.loss_dice: 0.3190  decode.d7.loss_cls: 0.4982  decode.d7.loss_mask: 0.3499  decode.d7.loss_dice: 0.3073  decode.d8.loss_cls: 0.4391  decode.d8.loss_mask: 0.3445  decode.d8.loss_dice: 0.3211
07/25 18:07:06 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250725_172252
07/25 18:07:06 - mmengine - INFO - Iter(train) [10000/80000]  base_lr: 8.8677e-05 lr: 8.8677e-06  eta: 10:16:27  time: 0.4836  data_time: 0.0082  memory: 5885  grad_norm: 178.4689  loss: 13.7759  decode.loss_cls: 0.5641  decode.loss_mask: 0.2770  decode.loss_dice: 0.4244  decode.d0.loss_cls: 1.3640  decode.d0.loss_mask: 0.3301  decode.d0.loss_dice: 0.4896  decode.d1.loss_cls: 0.7918  decode.d1.loss_mask: 0.2729  decode.d1.loss_dice: 0.3709  decode.d2.loss_cls: 0.6174  decode.d2.loss_mask: 0.2832  decode.d2.loss_dice: 0.4332  decode.d3.loss_cls: 0.5691  decode.d3.loss_mask: 0.2781  decode.d3.loss_dice: 0.4111  decode.d4.loss_cls: 0.5258  decode.d4.loss_mask: 0.3369  decode.d4.loss_dice: 0.4426  decode.d5.loss_cls: 0.5420  decode.d5.loss_mask: 0.2793  decode.d5.loss_dice: 0.4491  decode.d6.loss_cls: 0.5670  decode.d6.loss_mask: 0.2733  decode.d6.loss_dice: 0.3756  decode.d7.loss_cls: 0.6169  decode.d7.loss_mask: 0.2743  decode.d7.loss_dice: 0.4016  decode.d8.loss_cls: 0.4943  decode.d8.loss_mask: 0.2820  decode.d8.loss_dice: 0.4385
07/25 18:07:06 - mmengine - INFO - Saving checkpoint at 10000 iterations
07/25 18:07:33 - mmengine - INFO - Iter(train) [10050/80000]  base_lr: 8.8620e-05 lr: 8.8620e-06  eta: 10:15:59  time: 0.4824  data_time: 0.0082  memory: 5927  grad_norm: 190.6057  loss: 11.3235  decode.loss_cls: 0.4148  decode.loss_mask: 0.2497  decode.loss_dice: 0.3331  decode.d0.loss_cls: 1.4482  decode.d0.loss_mask: 0.2364  decode.d0.loss_dice: 0.3469  decode.d1.loss_cls: 0.5592  decode.d1.loss_mask: 0.2442  decode.d1.loss_dice: 0.3660  decode.d2.loss_cls: 0.5201  decode.d2.loss_mask: 0.2380  decode.d2.loss_dice: 0.3368  decode.d3.loss_cls: 0.4527  decode.d3.loss_mask: 0.2358  decode.d3.loss_dice: 0.3231  decode.d4.loss_cls: 0.4288  decode.d4.loss_mask: 0.2269  decode.d4.loss_dice: 0.3604  decode.d5.loss_cls: 0.3812  decode.d5.loss_mask: 0.2343  decode.d5.loss_dice: 0.3475  decode.d6.loss_cls: 0.3831  decode.d6.loss_mask: 0.2392  decode.d6.loss_dice: 0.3509  decode.d7.loss_cls: 0.4151  decode.d7.loss_mask: 0.2425  decode.d7.loss_dice: 0.3436  decode.d8.loss_cls: 0.4307  decode.d8.loss_mask: 0.2548  decode.d8.loss_dice: 0.3797
07/25 18:07:57 - mmengine - INFO - Iter(train) [10100/80000]  base_lr: 8.8563e-05 lr: 8.8563e-06  eta: 10:15:02  time: 0.4824  data_time: 0.0081  memory: 5906  grad_norm: 227.3361  loss: 11.4449  decode.loss_cls: 0.3034  decode.loss_mask: 0.3125  decode.loss_dice: 0.3568  decode.d0.loss_cls: 1.3078  decode.d0.loss_mask: 0.3249  decode.d0.loss_dice: 0.3868  decode.d1.loss_cls: 0.5161  decode.d1.loss_mask: 0.3145  decode.d1.loss_dice: 0.3646  decode.d2.loss_cls: 0.4953  decode.d2.loss_mask: 0.3085  decode.d2.loss_dice: 0.3428  decode.d3.loss_cls: 0.3839  decode.d3.loss_mask: 0.3101  decode.d3.loss_dice: 0.3418  decode.d4.loss_cls: 0.3413  decode.d4.loss_mask: 0.3129  decode.d4.loss_dice: 0.3567  decode.d5.loss_cls: 0.3832  decode.d5.loss_mask: 0.3115  decode.d5.loss_dice: 0.3574  decode.d6.loss_cls: 0.3837  decode.d6.loss_mask: 0.3066  decode.d6.loss_dice: 0.3246  decode.d7.loss_cls: 0.3447  decode.d7.loss_mask: 0.3171  decode.d7.loss_dice: 0.3406  decode.d8.loss_cls: 0.3401  decode.d8.loss_mask: 0.3105  decode.d8.loss_dice: 0.3443
07/25 18:08:21 - mmengine - INFO - Iter(train) [10150/80000]  base_lr: 8.8506e-05 lr: 8.8506e-06  eta: 10:14:05  time: 0.4846  data_time: 0.0083  memory: 5910  grad_norm: 200.6661  loss: 12.5138  decode.loss_cls: 0.4329  decode.loss_mask: 0.2877  decode.loss_dice: 0.3988  decode.d0.loss_cls: 1.3192  decode.d0.loss_mask: 0.3006  decode.d0.loss_dice: 0.4849  decode.d1.loss_cls: 0.6765  decode.d1.loss_mask: 0.2852  decode.d1.loss_dice: 0.4144  decode.d2.loss_cls: 0.4557  decode.d2.loss_mask: 0.2873  decode.d2.loss_dice: 0.4101  decode.d3.loss_cls: 0.3763  decode.d3.loss_mask: 0.2884  decode.d3.loss_dice: 0.4016  decode.d4.loss_cls: 0.3886  decode.d4.loss_mask: 0.2899  decode.d4.loss_dice: 0.4225  decode.d5.loss_cls: 0.4194  decode.d5.loss_mask: 0.2988  decode.d5.loss_dice: 0.4277  decode.d6.loss_cls: 0.3892  decode.d6.loss_mask: 0.3147  decode.d6.loss_dice: 0.4321  decode.d7.loss_cls: 0.4137  decode.d7.loss_mask: 0.3295  decode.d7.loss_dice: 0.4096  decode.d8.loss_cls: 0.4589  decode.d8.loss_mask: 0.2899  decode.d8.loss_dice: 0.4096
07/25 18:08:45 - mmengine - INFO - Iter(train) [10200/80000]  base_lr: 8.8449e-05 lr: 8.8449e-06  eta: 10:13:09  time: 0.4835  data_time: 0.0082  memory: 5921  grad_norm: 157.3376  loss: 9.3629  decode.loss_cls: 0.3146  decode.loss_mask: 0.2786  decode.loss_dice: 0.2700  decode.d0.loss_cls: 1.2182  decode.d0.loss_mask: 0.2601  decode.d0.loss_dice: 0.2899  decode.d1.loss_cls: 0.4116  decode.d1.loss_mask: 0.2617  decode.d1.loss_dice: 0.2595  decode.d2.loss_cls: 0.3353  decode.d2.loss_mask: 0.2687  decode.d2.loss_dice: 0.2674  decode.d3.loss_cls: 0.3251  decode.d3.loss_mask: 0.2694  decode.d3.loss_dice: 0.2515  decode.d4.loss_cls: 0.2621  decode.d4.loss_mask: 0.2734  decode.d4.loss_dice: 0.2665  decode.d5.loss_cls: 0.2594  decode.d5.loss_mask: 0.2711  decode.d5.loss_dice: 0.2692  decode.d6.loss_cls: 0.2555  decode.d6.loss_mask: 0.2853  decode.d6.loss_dice: 0.2783  decode.d7.loss_cls: 0.2820  decode.d7.loss_mask: 0.2744  decode.d7.loss_dice: 0.2606  decode.d8.loss_cls: 0.3119  decode.d8.loss_mask: 0.2740  decode.d8.loss_dice: 0.2578
07/25 18:09:09 - mmengine - INFO - Iter(train) [10250/80000]  base_lr: 8.8392e-05 lr: 8.8392e-06  eta: 10:12:14  time: 0.4831  data_time: 0.0078  memory: 5888  grad_norm: 164.4468  loss: 9.8018  decode.loss_cls: 0.1820  decode.loss_mask: 0.3203  decode.loss_dice: 0.3473  decode.d0.loss_cls: 1.1493  decode.d0.loss_mask: 0.3304  decode.d0.loss_dice: 0.3983  decode.d1.loss_cls: 0.3370  decode.d1.loss_mask: 0.2990  decode.d1.loss_dice: 0.3172  decode.d2.loss_cls: 0.3676  decode.d2.loss_mask: 0.2966  decode.d2.loss_dice: 0.3077  decode.d3.loss_cls: 0.2969  decode.d3.loss_mask: 0.2924  decode.d3.loss_dice: 0.3170  decode.d4.loss_cls: 0.2558  decode.d4.loss_mask: 0.3038  decode.d4.loss_dice: 0.3260  decode.d5.loss_cls: 0.2201  decode.d5.loss_mask: 0.3012  decode.d5.loss_dice: 0.3180  decode.d6.loss_cls: 0.2065  decode.d6.loss_mask: 0.3042  decode.d6.loss_dice: 0.3240  decode.d7.loss_cls: 0.2133  decode.d7.loss_mask: 0.2970  decode.d7.loss_dice: 0.3052  decode.d8.loss_cls: 0.2220  decode.d8.loss_mask: 0.3117  decode.d8.loss_dice: 0.3344
07/25 18:09:33 - mmengine - INFO - Iter(train) [10300/80000]  base_lr: 8.8335e-05 lr: 8.8335e-06  eta: 10:11:19  time: 0.4839  data_time: 0.0081  memory: 5889  grad_norm: 111.8587  loss: 8.4470  decode.loss_cls: 0.1609  decode.loss_mask: 0.2598  decode.loss_dice: 0.2640  decode.d0.loss_cls: 1.1209  decode.d0.loss_mask: 0.2621  decode.d0.loss_dice: 0.3122  decode.d1.loss_cls: 0.3590  decode.d1.loss_mask: 0.2460  decode.d1.loss_dice: 0.2807  decode.d2.loss_cls: 0.2338  decode.d2.loss_mask: 0.2382  decode.d2.loss_dice: 0.2617  decode.d3.loss_cls: 0.2611  decode.d3.loss_mask: 0.2458  decode.d3.loss_dice: 0.2847  decode.d4.loss_cls: 0.2965  decode.d4.loss_mask: 0.2690  decode.d4.loss_dice: 0.2796  decode.d5.loss_cls: 0.2390  decode.d5.loss_mask: 0.2303  decode.d5.loss_dice: 0.2786  decode.d6.loss_cls: 0.1718  decode.d6.loss_mask: 0.2547  decode.d6.loss_dice: 0.2673  decode.d7.loss_cls: 0.1677  decode.d7.loss_mask: 0.2402  decode.d7.loss_dice: 0.2724  decode.d8.loss_cls: 0.2080  decode.d8.loss_mask: 0.2202  decode.d8.loss_dice: 0.2607
07/25 18:09:58 - mmengine - INFO - Iter(train) [10350/80000]  base_lr: 8.8278e-05 lr: 8.8278e-06  eta: 10:10:26  time: 0.4834  data_time: 0.0080  memory: 5910  grad_norm: 225.2949  loss: 14.3089  decode.loss_cls: 0.4977  decode.loss_mask: 0.3529  decode.loss_dice: 0.3544  decode.d0.loss_cls: 1.4847  decode.d0.loss_mask: 0.4193  decode.d0.loss_dice: 0.4017  decode.d1.loss_cls: 0.6785  decode.d1.loss_mask: 0.3107  decode.d1.loss_dice: 0.3601  decode.d2.loss_cls: 0.7644  decode.d2.loss_mask: 0.3057  decode.d2.loss_dice: 0.3427  decode.d3.loss_cls: 0.7335  decode.d3.loss_mask: 0.3171  decode.d3.loss_dice: 0.3669  decode.d4.loss_cls: 0.6941  decode.d4.loss_mask: 0.3068  decode.d4.loss_dice: 0.3342  decode.d5.loss_cls: 0.6570  decode.d5.loss_mask: 0.3155  decode.d5.loss_dice: 0.3712  decode.d6.loss_cls: 0.6735  decode.d6.loss_mask: 0.3167  decode.d6.loss_dice: 0.3413  decode.d7.loss_cls: 0.6214  decode.d7.loss_mask: 0.3249  decode.d7.loss_dice: 0.3574  decode.d8.loss_cls: 0.6167  decode.d8.loss_mask: 0.3234  decode.d8.loss_dice: 0.3645
07/25 18:10:22 - mmengine - INFO - Iter(train) [10400/80000]  base_lr: 8.8221e-05 lr: 8.8221e-06  eta: 10:09:32  time: 0.4832  data_time: 0.0079  memory: 5928  grad_norm: 110.3777  loss: 8.2133  decode.loss_cls: 0.2525  decode.loss_mask: 0.2072  decode.loss_dice: 0.2498  decode.d0.loss_cls: 1.1971  decode.d0.loss_mask: 0.2154  decode.d0.loss_dice: 0.2924  decode.d1.loss_cls: 0.3370  decode.d1.loss_mask: 0.2056  decode.d1.loss_dice: 0.2463  decode.d2.loss_cls: 0.2979  decode.d2.loss_mask: 0.2043  decode.d2.loss_dice: 0.2444  decode.d3.loss_cls: 0.2706  decode.d3.loss_mask: 0.2157  decode.d3.loss_dice: 0.2600  decode.d4.loss_cls: 0.2766  decode.d4.loss_mask: 0.2117  decode.d4.loss_dice: 0.2285  decode.d5.loss_cls: 0.2263  decode.d5.loss_mask: 0.2145  decode.d5.loss_dice: 0.2347  decode.d6.loss_cls: 0.2300  decode.d6.loss_mask: 0.2143  decode.d6.loss_dice: 0.2668  decode.d7.loss_cls: 0.2976  decode.d7.loss_mask: 0.2051  decode.d7.loss_dice: 0.2199  decode.d8.loss_cls: 0.2378  decode.d8.loss_mask: 0.2049  decode.d8.loss_dice: 0.2486
07/25 18:10:46 - mmengine - INFO - Iter(train) [10450/80000]  base_lr: 8.8164e-05 lr: 8.8164e-06  eta: 10:08:40  time: 0.4849  data_time: 0.0081  memory: 5906  grad_norm: 125.3420  loss: 10.1044  decode.loss_cls: 0.2524  decode.loss_mask: 0.2703  decode.loss_dice: 0.2856  decode.d0.loss_cls: 1.3994  decode.d0.loss_mask: 0.3125  decode.d0.loss_dice: 0.3352  decode.d1.loss_cls: 0.5268  decode.d1.loss_mask: 0.2807  decode.d1.loss_dice: 0.3096  decode.d2.loss_cls: 0.4584  decode.d2.loss_mask: 0.3047  decode.d2.loss_dice: 0.3129  decode.d3.loss_cls: 0.3144  decode.d3.loss_mask: 0.2653  decode.d3.loss_dice: 0.3105  decode.d4.loss_cls: 0.2739  decode.d4.loss_mask: 0.2685  decode.d4.loss_dice: 0.2869  decode.d5.loss_cls: 0.3330  decode.d5.loss_mask: 0.2641  decode.d5.loss_dice: 0.2963  decode.d6.loss_cls: 0.2748  decode.d6.loss_mask: 0.2633  decode.d6.loss_dice: 0.2871  decode.d7.loss_cls: 0.2743  decode.d7.loss_mask: 0.2618  decode.d7.loss_dice: 0.2827  decode.d8.loss_cls: 0.2382  decode.d8.loss_mask: 0.2706  decode.d8.loss_dice: 0.2901
07/25 18:11:10 - mmengine - INFO - Iter(train) [10500/80000]  base_lr: 8.8107e-05 lr: 8.8107e-06  eta: 10:07:48  time: 0.4830  data_time: 0.0079  memory: 5909  grad_norm: 109.4665  loss: 9.5576  decode.loss_cls: 0.3604  decode.loss_mask: 0.2422  decode.loss_dice: 0.2669  decode.d0.loss_cls: 1.1160  decode.d0.loss_mask: 0.2546  decode.d0.loss_dice: 0.2918  decode.d1.loss_cls: 0.4797  decode.d1.loss_mask: 0.2441  decode.d1.loss_dice: 0.2753  decode.d2.loss_cls: 0.3798  decode.d2.loss_mask: 0.2426  decode.d2.loss_dice: 0.2678  decode.d3.loss_cls: 0.3624  decode.d3.loss_mask: 0.2382  decode.d3.loss_dice: 0.2667  decode.d4.loss_cls: 0.3274  decode.d4.loss_mask: 0.2396  decode.d4.loss_dice: 0.2619  decode.d5.loss_cls: 0.3495  decode.d5.loss_mask: 0.2410  decode.d5.loss_dice: 0.2598  decode.d6.loss_cls: 0.3733  decode.d6.loss_mask: 0.2378  decode.d6.loss_dice: 0.2544  decode.d7.loss_cls: 0.3358  decode.d7.loss_mask: 0.2497  decode.d7.loss_dice: 0.2719  decode.d8.loss_cls: 0.3521  decode.d8.loss_mask: 0.2442  decode.d8.loss_dice: 0.2707
07/25 18:11:35 - mmengine - INFO - Iter(train) [10550/80000]  base_lr: 8.8050e-05 lr: 8.8050e-06  eta: 10:06:57  time: 0.4827  data_time: 0.0080  memory: 5906  grad_norm: 205.6407  loss: 10.3920  decode.loss_cls: 0.2718  decode.loss_mask: 0.2989  decode.loss_dice: 0.3740  decode.d0.loss_cls: 1.1866  decode.d0.loss_mask: 0.3365  decode.d0.loss_dice: 0.3811  decode.d1.loss_cls: 0.4787  decode.d1.loss_mask: 0.3281  decode.d1.loss_dice: 0.3506  decode.d2.loss_cls: 0.2799  decode.d2.loss_mask: 0.2952  decode.d2.loss_dice: 0.3384  decode.d3.loss_cls: 0.2449  decode.d3.loss_mask: 0.2966  decode.d3.loss_dice: 0.3520  decode.d4.loss_cls: 0.3327  decode.d4.loss_mask: 0.3088  decode.d4.loss_dice: 0.3449  decode.d5.loss_cls: 0.2495  decode.d5.loss_mask: 0.2975  decode.d5.loss_dice: 0.3626  decode.d6.loss_cls: 0.2506  decode.d6.loss_mask: 0.2917  decode.d6.loss_dice: 0.3400  decode.d7.loss_cls: 0.2597  decode.d7.loss_mask: 0.2860  decode.d7.loss_dice: 0.3283  decode.d8.loss_cls: 0.2628  decode.d8.loss_mask: 0.2962  decode.d8.loss_dice: 0.3673
07/25 18:11:59 - mmengine - INFO - Iter(train) [10600/80000]  base_lr: 8.7993e-05 lr: 8.7993e-06  eta: 10:06:05  time: 0.4838  data_time: 0.0081  memory: 5905  grad_norm: 140.7523  loss: 10.3445  decode.loss_cls: 0.3296  decode.loss_mask: 0.2125  decode.loss_dice: 0.3556  decode.d0.loss_cls: 1.3199  decode.d0.loss_mask: 0.2247  decode.d0.loss_dice: 0.4119  decode.d1.loss_cls: 0.5318  decode.d1.loss_mask: 0.2244  decode.d1.loss_dice: 0.3270  decode.d2.loss_cls: 0.4386  decode.d2.loss_mask: 0.2202  decode.d2.loss_dice: 0.3273  decode.d3.loss_cls: 0.4028  decode.d3.loss_mask: 0.2154  decode.d3.loss_dice: 0.3626  decode.d4.loss_cls: 0.3481  decode.d4.loss_mask: 0.2153  decode.d4.loss_dice: 0.3460  decode.d5.loss_cls: 0.3314  decode.d5.loss_mask: 0.2154  decode.d5.loss_dice: 0.3549  decode.d6.loss_cls: 0.3137  decode.d6.loss_mask: 0.2114  decode.d6.loss_dice: 0.3172  decode.d7.loss_cls: 0.3342  decode.d7.loss_mask: 0.2183  decode.d7.loss_dice: 0.3426  decode.d8.loss_cls: 0.3178  decode.d8.loss_mask: 0.2138  decode.d8.loss_dice: 0.3601
07/25 18:12:23 - mmengine - INFO - Iter(train) [10650/80000]  base_lr: 8.7936e-05 lr: 8.7936e-06  eta: 10:05:14  time: 0.4832  data_time: 0.0081  memory: 5888  grad_norm: 146.1653  loss: 10.2127  decode.loss_cls: 0.2618  decode.loss_mask: 0.3152  decode.loss_dice: 0.3223  decode.d0.loss_cls: 1.0446  decode.d0.loss_mask: 0.3574  decode.d0.loss_dice: 0.3558  decode.d1.loss_cls: 0.3965  decode.d1.loss_mask: 0.2849  decode.d1.loss_dice: 0.2990  decode.d2.loss_cls: 0.4114  decode.d2.loss_mask: 0.2829  decode.d2.loss_dice: 0.2849  decode.d3.loss_cls: 0.4051  decode.d3.loss_mask: 0.2802  decode.d3.loss_dice: 0.3149  decode.d4.loss_cls: 0.3554  decode.d4.loss_mask: 0.2852  decode.d4.loss_dice: 0.2996  decode.d5.loss_cls: 0.3381  decode.d5.loss_mask: 0.2742  decode.d5.loss_dice: 0.2786  decode.d6.loss_cls: 0.3366  decode.d6.loss_mask: 0.2777  decode.d6.loss_dice: 0.3162  decode.d7.loss_cls: 0.3513  decode.d7.loss_mask: 0.2736  decode.d7.loss_dice: 0.2818  decode.d8.loss_cls: 0.3197  decode.d8.loss_mask: 0.3034  decode.d8.loss_dice: 0.3046
07/25 18:12:47 - mmengine - INFO - Iter(train) [10700/80000]  base_lr: 8.7879e-05 lr: 8.7879e-06  eta: 10:04:24  time: 0.4837  data_time: 0.0080  memory: 5877  grad_norm: 169.7031  loss: 11.9950  decode.loss_cls: 0.3363  decode.loss_mask: 0.3425  decode.loss_dice: 0.4486  decode.d0.loss_cls: 1.0589  decode.d0.loss_mask: 0.3601  decode.d0.loss_dice: 0.4770  decode.d1.loss_cls: 0.4704  decode.d1.loss_mask: 0.3404  decode.d1.loss_dice: 0.4184  decode.d2.loss_cls: 0.3347  decode.d2.loss_mask: 0.3378  decode.d2.loss_dice: 0.4234  decode.d3.loss_cls: 0.3071  decode.d3.loss_mask: 0.3484  decode.d3.loss_dice: 0.4293  decode.d4.loss_cls: 0.3420  decode.d4.loss_mask: 0.3392  decode.d4.loss_dice: 0.4137  decode.d5.loss_cls: 0.2721  decode.d5.loss_mask: 0.3487  decode.d5.loss_dice: 0.4386  decode.d6.loss_cls: 0.3114  decode.d6.loss_mask: 0.3523  decode.d6.loss_dice: 0.4466  decode.d7.loss_cls: 0.3616  decode.d7.loss_mask: 0.3550  decode.d7.loss_dice: 0.4409  decode.d8.loss_cls: 0.3339  decode.d8.loss_mask: 0.3490  decode.d8.loss_dice: 0.4566
07/25 18:13:11 - mmengine - INFO - Iter(train) [10750/80000]  base_lr: 8.7822e-05 lr: 8.7822e-06  eta: 10:03:34  time: 0.4853  data_time: 0.0083  memory: 5905  grad_norm: 229.5068  loss: 11.9572  decode.loss_cls: 0.4354  decode.loss_mask: 0.2636  decode.loss_dice: 0.2932  decode.d0.loss_cls: 1.5333  decode.d0.loss_mask: 0.3060  decode.d0.loss_dice: 0.4216  decode.d1.loss_cls: 0.7299  decode.d1.loss_mask: 0.2564  decode.d1.loss_dice: 0.3022  decode.d2.loss_cls: 0.6666  decode.d2.loss_mask: 0.2562  decode.d2.loss_dice: 0.3020  decode.d3.loss_cls: 0.5287  decode.d3.loss_mask: 0.2585  decode.d3.loss_dice: 0.2930  decode.d4.loss_cls: 0.4755  decode.d4.loss_mask: 0.2598  decode.d4.loss_dice: 0.3372  decode.d5.loss_cls: 0.4677  decode.d5.loss_mask: 0.2672  decode.d5.loss_dice: 0.3082  decode.d6.loss_cls: 0.3468  decode.d6.loss_mask: 0.2679  decode.d6.loss_dice: 0.3240  decode.d7.loss_cls: 0.4083  decode.d7.loss_mask: 0.2691  decode.d7.loss_dice: 0.3162  decode.d8.loss_cls: 0.4873  decode.d8.loss_mask: 0.2612  decode.d8.loss_dice: 0.3143
07/25 18:13:36 - mmengine - INFO - Iter(train) [10800/80000]  base_lr: 8.7765e-05 lr: 8.7765e-06  eta: 10:02:45  time: 0.4834  data_time: 0.0080  memory: 5877  grad_norm: 218.6897  loss: 10.6701  decode.loss_cls: 0.3246  decode.loss_mask: 0.3416  decode.loss_dice: 0.3664  decode.d0.loss_cls: 1.1363  decode.d0.loss_mask: 0.2690  decode.d0.loss_dice: 0.3379  decode.d1.loss_cls: 0.3193  decode.d1.loss_mask: 0.2697  decode.d1.loss_dice: 0.3091  decode.d2.loss_cls: 0.3350  decode.d2.loss_mask: 0.2672  decode.d2.loss_dice: 0.3245  decode.d3.loss_cls: 0.3695  decode.d3.loss_mask: 0.2797  decode.d3.loss_dice: 0.3254  decode.d4.loss_cls: 0.3921  decode.d4.loss_mask: 0.2651  decode.d4.loss_dice: 0.3169  decode.d5.loss_cls: 0.3710  decode.d5.loss_mask: 0.2722  decode.d5.loss_dice: 0.3386  decode.d6.loss_cls: 0.4528  decode.d6.loss_mask: 0.3046  decode.d6.loss_dice: 0.3279  decode.d7.loss_cls: 0.4603  decode.d7.loss_mask: 0.2862  decode.d7.loss_dice: 0.3234  decode.d8.loss_cls: 0.3332  decode.d8.loss_mask: 0.2954  decode.d8.loss_dice: 0.3555
07/25 18:14:00 - mmengine - INFO - Iter(train) [10850/80000]  base_lr: 8.7708e-05 lr: 8.7708e-06  eta: 10:01:56  time: 0.4837  data_time: 0.0081  memory: 5909  grad_norm: 100.2584  loss: 7.3776  decode.loss_cls: 0.2093  decode.loss_mask: 0.1672  decode.loss_dice: 0.2528  decode.d0.loss_cls: 1.0894  decode.d0.loss_mask: 0.1746  decode.d0.loss_dice: 0.2731  decode.d1.loss_cls: 0.2999  decode.d1.loss_mask: 0.1693  decode.d1.loss_dice: 0.2724  decode.d2.loss_cls: 0.2147  decode.d2.loss_mask: 0.1768  decode.d2.loss_dice: 0.2879  decode.d3.loss_cls: 0.1747  decode.d3.loss_mask: 0.1761  decode.d3.loss_dice: 0.2734  decode.d4.loss_cls: 0.1625  decode.d4.loss_mask: 0.1783  decode.d4.loss_dice: 0.2729  decode.d5.loss_cls: 0.1590  decode.d5.loss_mask: 0.1889  decode.d5.loss_dice: 0.2819  decode.d6.loss_cls: 0.1839  decode.d6.loss_mask: 0.2016  decode.d6.loss_dice: 0.2753  decode.d7.loss_cls: 0.1777  decode.d7.loss_mask: 0.1939  decode.d7.loss_dice: 0.2902  decode.d8.loss_cls: 0.1715  decode.d8.loss_mask: 0.1674  decode.d8.loss_dice: 0.2608
07/25 18:14:24 - mmengine - INFO - Iter(train) [10900/80000]  base_lr: 8.7650e-05 lr: 8.7650e-06  eta: 10:01:08  time: 0.4863  data_time: 0.0083  memory: 5926  grad_norm: 178.0074  loss: 12.3021  decode.loss_cls: 0.3719  decode.loss_mask: 0.3628  decode.loss_dice: 0.4151  decode.d0.loss_cls: 1.4004  decode.d0.loss_mask: 0.3910  decode.d0.loss_dice: 0.4573  decode.d1.loss_cls: 0.4629  decode.d1.loss_mask: 0.3676  decode.d1.loss_dice: 0.4045  decode.d2.loss_cls: 0.4013  decode.d2.loss_mask: 0.3605  decode.d2.loss_dice: 0.3538  decode.d3.loss_cls: 0.3694  decode.d3.loss_mask: 0.3576  decode.d3.loss_dice: 0.3515  decode.d4.loss_cls: 0.3348  decode.d4.loss_mask: 0.3643  decode.d4.loss_dice: 0.3703  decode.d5.loss_cls: 0.3652  decode.d5.loss_mask: 0.3682  decode.d5.loss_dice: 0.3821  decode.d6.loss_cls: 0.3485  decode.d6.loss_mask: 0.3539  decode.d6.loss_dice: 0.3797  decode.d7.loss_cls: 0.3590  decode.d7.loss_mask: 0.3515  decode.d7.loss_dice: 0.3841  decode.d8.loss_cls: 0.3815  decode.d8.loss_mask: 0.3591  decode.d8.loss_dice: 0.3723
07/25 18:14:48 - mmengine - INFO - Iter(train) [10950/80000]  base_lr: 8.7593e-05 lr: 8.7593e-06  eta: 10:00:21  time: 0.4849  data_time: 0.0084  memory: 5921  grad_norm: 93.7266  loss: 9.5372  decode.loss_cls: 0.3052  decode.loss_mask: 0.3206  decode.loss_dice: 0.3195  decode.d0.loss_cls: 1.1588  decode.d0.loss_mask: 0.3088  decode.d0.loss_dice: 0.3296  decode.d1.loss_cls: 0.3679  decode.d1.loss_mask: 0.2511  decode.d1.loss_dice: 0.2916  decode.d2.loss_cls: 0.3021  decode.d2.loss_mask: 0.2748  decode.d2.loss_dice: 0.3284  decode.d3.loss_cls: 0.2958  decode.d3.loss_mask: 0.2430  decode.d3.loss_dice: 0.2898  decode.d4.loss_cls: 0.2808  decode.d4.loss_mask: 0.2613  decode.d4.loss_dice: 0.3066  decode.d5.loss_cls: 0.3074  decode.d5.loss_mask: 0.2591  decode.d5.loss_dice: 0.3093  decode.d6.loss_cls: 0.2597  decode.d6.loss_mask: 0.3005  decode.d6.loss_dice: 0.3131  decode.d7.loss_cls: 0.1951  decode.d7.loss_mask: 0.2788  decode.d7.loss_dice: 0.2672  decode.d8.loss_cls: 0.2597  decode.d8.loss_mask: 0.2482  decode.d8.loss_dice: 0.3033
07/25 18:15:13 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250725_172252
07/25 18:15:13 - mmengine - INFO - Iter(train) [11000/80000]  base_lr: 8.7536e-05 lr: 8.7536e-06  eta: 9:59:34  time: 0.4857  data_time: 0.0083  memory: 5910  grad_norm: 140.2130  loss: 12.1943  decode.loss_cls: 0.3224  decode.loss_mask: 0.3635  decode.loss_dice: 0.3951  decode.d0.loss_cls: 1.1596  decode.d0.loss_mask: 0.3705  decode.d0.loss_dice: 0.4229  decode.d1.loss_cls: 0.4144  decode.d1.loss_mask: 0.3665  decode.d1.loss_dice: 0.4029  decode.d2.loss_cls: 0.3486  decode.d2.loss_mask: 0.3592  decode.d2.loss_dice: 0.4050  decode.d3.loss_cls: 0.3578  decode.d3.loss_mask: 0.3574  decode.d3.loss_dice: 0.4180  decode.d4.loss_cls: 0.4413  decode.d4.loss_mask: 0.3622  decode.d4.loss_dice: 0.4030  decode.d5.loss_cls: 0.4060  decode.d5.loss_mask: 0.3620  decode.d5.loss_dice: 0.3846  decode.d6.loss_cls: 0.3461  decode.d6.loss_mask: 0.3606  decode.d6.loss_dice: 0.4313  decode.d7.loss_cls: 0.3569  decode.d7.loss_mask: 0.3628  decode.d7.loss_dice: 0.4078  decode.d8.loss_cls: 0.3571  decode.d8.loss_mask: 0.3578  decode.d8.loss_dice: 0.3910
07/25 18:15:37 - mmengine - INFO - Iter(train) [11050/80000]  base_lr: 8.7479e-05 lr: 8.7479e-06  eta: 9:58:48  time: 0.4838  data_time: 0.0084  memory: 5959  grad_norm: 132.1884  loss: 7.9007  decode.loss_cls: 0.1127  decode.loss_mask: 0.2855  decode.loss_dice: 0.2814  decode.d0.loss_cls: 1.0890  decode.d0.loss_mask: 0.2789  decode.d0.loss_dice: 0.3165  decode.d1.loss_cls: 0.2437  decode.d1.loss_mask: 0.2866  decode.d1.loss_dice: 0.2703  decode.d2.loss_cls: 0.1117  decode.d2.loss_mask: 0.2791  decode.d2.loss_dice: 0.2957  decode.d3.loss_cls: 0.0941  decode.d3.loss_mask: 0.2772  decode.d3.loss_dice: 0.2859  decode.d4.loss_cls: 0.1704  decode.d4.loss_mask: 0.2756  decode.d4.loss_dice: 0.2605  decode.d5.loss_cls: 0.1270  decode.d5.loss_mask: 0.2771  decode.d5.loss_dice: 0.2751  decode.d6.loss_cls: 0.0895  decode.d6.loss_mask: 0.2820  decode.d6.loss_dice: 0.2768  decode.d7.loss_cls: 0.0923  decode.d7.loss_mask: 0.2813  decode.d7.loss_dice: 0.2963  decode.d8.loss_cls: 0.1161  decode.d8.loss_mask: 0.2822  decode.d8.loss_dice: 0.2899
07/25 18:16:01 - mmengine - INFO - Iter(train) [11100/80000]  base_lr: 8.7422e-05 lr: 8.7422e-06  eta: 9:58:01  time: 0.4837  data_time: 0.0084  memory: 5877  grad_norm: 154.6414  loss: 10.3402  decode.loss_cls: 0.3090  decode.loss_mask: 0.2956  decode.loss_dice: 0.3543  decode.d0.loss_cls: 0.9893  decode.d0.loss_mask: 0.3238  decode.d0.loss_dice: 0.4127  decode.d1.loss_cls: 0.3774  decode.d1.loss_mask: 0.2919  decode.d1.loss_dice: 0.3572  decode.d2.loss_cls: 0.2537  decode.d2.loss_mask: 0.2912  decode.d2.loss_dice: 0.3664  decode.d3.loss_cls: 0.2562  decode.d3.loss_mask: 0.2910  decode.d3.loss_dice: 0.3670  decode.d4.loss_cls: 0.3333  decode.d4.loss_mask: 0.2883  decode.d4.loss_dice: 0.3604  decode.d5.loss_cls: 0.3350  decode.d5.loss_mask: 0.2839  decode.d5.loss_dice: 0.3543  decode.d6.loss_cls: 0.2989  decode.d6.loss_mask: 0.2922  decode.d6.loss_dice: 0.3615  decode.d7.loss_cls: 0.2779  decode.d7.loss_mask: 0.2898  decode.d7.loss_dice: 0.3623  decode.d8.loss_cls: 0.3032  decode.d8.loss_mask: 0.2961  decode.d8.loss_dice: 0.3663
07/25 18:16:25 - mmengine - INFO - Iter(train) [11150/80000]  base_lr: 8.7365e-05 lr: 8.7365e-06  eta: 9:57:15  time: 0.4851  data_time: 0.0085  memory: 5923  grad_norm: 196.2815  loss: 12.0575  decode.loss_cls: 0.4087  decode.loss_mask: 0.3038  decode.loss_dice: 0.3316  decode.d0.loss_cls: 1.3314  decode.d0.loss_mask: 0.3164  decode.d0.loss_dice: 0.3698  decode.d1.loss_cls: 0.5879  decode.d1.loss_mask: 0.2974  decode.d1.loss_dice: 0.3531  decode.d2.loss_cls: 0.5039  decode.d2.loss_mask: 0.3147  decode.d2.loss_dice: 0.3581  decode.d3.loss_cls: 0.4281  decode.d3.loss_mask: 0.3011  decode.d3.loss_dice: 0.3325  decode.d4.loss_cls: 0.4481  decode.d4.loss_mask: 0.3013  decode.d4.loss_dice: 0.3453  decode.d5.loss_cls: 0.4468  decode.d5.loss_mask: 0.2975  decode.d5.loss_dice: 0.3282  decode.d6.loss_cls: 0.4935  decode.d6.loss_mask: 0.3043  decode.d6.loss_dice: 0.3196  decode.d7.loss_cls: 0.4884  decode.d7.loss_mask: 0.3041  decode.d7.loss_dice: 0.3261  decode.d8.loss_cls: 0.4681  decode.d8.loss_mask: 0.3063  decode.d8.loss_dice: 0.3411
07/25 18:16:50 - mmengine - INFO - Iter(train) [11200/80000]  base_lr: 8.7308e-05 lr: 8.7308e-06  eta: 9:56:29  time: 0.4849  data_time: 0.0083  memory: 5965  grad_norm: 154.6675  loss: 9.1831  decode.loss_cls: 0.2534  decode.loss_mask: 0.3010  decode.loss_dice: 0.2756  decode.d0.loss_cls: 1.1926  decode.d0.loss_mask: 0.2920  decode.d0.loss_dice: 0.3149  decode.d1.loss_cls: 0.3891  decode.d1.loss_mask: 0.2757  decode.d1.loss_dice: 0.2657  decode.d2.loss_cls: 0.2823  decode.d2.loss_mask: 0.2883  decode.d2.loss_dice: 0.2642  decode.d3.loss_cls: 0.2411  decode.d3.loss_mask: 0.2814  decode.d3.loss_dice: 0.2658  decode.d4.loss_cls: 0.2422  decode.d4.loss_mask: 0.2751  decode.d4.loss_dice: 0.2669  decode.d5.loss_cls: 0.2241  decode.d5.loss_mask: 0.3066  decode.d5.loss_dice: 0.2873  decode.d6.loss_cls: 0.1910  decode.d6.loss_mask: 0.3023  decode.d6.loss_dice: 0.2755  decode.d7.loss_cls: 0.2154  decode.d7.loss_mask: 0.3052  decode.d7.loss_dice: 0.2785  decode.d8.loss_cls: 0.2595  decode.d8.loss_mask: 0.2951  decode.d8.loss_dice: 0.2750
07/25 18:17:14 - mmengine - INFO - Iter(train) [11250/80000]  base_lr: 8.7251e-05 lr: 8.7251e-06  eta: 9:55:43  time: 0.4843  data_time: 0.0084  memory: 5888  grad_norm: 1970.6412  loss: 13.7717  decode.loss_cls: 0.2873  decode.loss_mask: 0.5992  decode.loss_dice: 0.3691  decode.d0.loss_cls: 1.2126  decode.d0.loss_mask: 0.6864  decode.d0.loss_dice: 0.4098  decode.d1.loss_cls: 0.4756  decode.d1.loss_mask: 0.5306  decode.d1.loss_dice: 0.3818  decode.d2.loss_cls: 0.3810  decode.d2.loss_mask: 0.5256  decode.d2.loss_dice: 0.3549  decode.d3.loss_cls: 0.2926  decode.d3.loss_mask: 0.5023  decode.d3.loss_dice: 0.3496  decode.d4.loss_cls: 0.4052  decode.d4.loss_mask: 0.4891  decode.d4.loss_dice: 0.3642  decode.d5.loss_cls: 0.2978  decode.d5.loss_mask: 0.5835  decode.d5.loss_dice: 0.3707  decode.d6.loss_cls: 0.2929  decode.d6.loss_mask: 0.6235  decode.d6.loss_dice: 0.3934  decode.d7.loss_cls: 0.3297  decode.d7.loss_mask: 0.6172  decode.d7.loss_dice: 0.3748  decode.d8.loss_cls: 0.3004  decode.d8.loss_mask: 0.6108  decode.d8.loss_dice: 0.3599
07/25 18:17:38 - mmengine - INFO - Iter(train) [11300/80000]  base_lr: 8.7194e-05 lr: 8.7194e-06  eta: 9:54:58  time: 0.4866  data_time: 0.0085  memory: 5873  grad_norm: 176.7137  loss: 10.1477  decode.loss_cls: 0.1944  decode.loss_mask: 0.3537  decode.loss_dice: 0.3621  decode.d0.loss_cls: 0.9418  decode.d0.loss_mask: 0.3782  decode.d0.loss_dice: 0.4153  decode.d1.loss_cls: 0.2263  decode.d1.loss_mask: 0.3711  decode.d1.loss_dice: 0.3943  decode.d2.loss_cls: 0.2231  decode.d2.loss_mask: 0.3688  decode.d2.loss_dice: 0.3900  decode.d3.loss_cls: 0.1991  decode.d3.loss_mask: 0.3509  decode.d3.loss_dice: 0.3784  decode.d4.loss_cls: 0.2077  decode.d4.loss_mask: 0.3547  decode.d4.loss_dice: 0.3791  decode.d5.loss_cls: 0.2433  decode.d5.loss_mask: 0.3558  decode.d5.loss_dice: 0.3715  decode.d6.loss_cls: 0.1789  decode.d6.loss_mask: 0.3484  decode.d6.loss_dice: 0.3612  decode.d7.loss_cls: 0.1559  decode.d7.loss_mask: 0.3506  decode.d7.loss_dice: 0.3744  decode.d8.loss_cls: 0.1733  decode.d8.loss_mask: 0.3560  decode.d8.loss_dice: 0.3893
07/25 18:18:02 - mmengine - INFO - Iter(train) [11350/80000]  base_lr: 8.7137e-05 lr: 8.7137e-06  eta: 9:54:15  time: 0.4844  data_time: 0.0082  memory: 5923  grad_norm: 196.1295  loss: 11.4254  decode.loss_cls: 0.3704  decode.loss_mask: 0.2485  decode.loss_dice: 0.3649  decode.d0.loss_cls: 1.3615  decode.d0.loss_mask: 0.2512  decode.d0.loss_dice: 0.3587  decode.d1.loss_cls: 0.4875  decode.d1.loss_mask: 0.2617  decode.d1.loss_dice: 0.3696  decode.d2.loss_cls: 0.3884  decode.d2.loss_mask: 0.2655  decode.d2.loss_dice: 0.3819  decode.d3.loss_cls: 0.4497  decode.d3.loss_mask: 0.2565  decode.d3.loss_dice: 0.3793  decode.d4.loss_cls: 0.4110  decode.d4.loss_mask: 0.2633  decode.d4.loss_dice: 0.3848  decode.d5.loss_cls: 0.4122  decode.d5.loss_mask: 0.2566  decode.d5.loss_dice: 0.3892  decode.d6.loss_cls: 0.4858  decode.d6.loss_mask: 0.2555  decode.d6.loss_dice: 0.3556  decode.d7.loss_cls: 0.3673  decode.d7.loss_mask: 0.2603  decode.d7.loss_dice: 0.3728  decode.d8.loss_cls: 0.3937  decode.d8.loss_mask: 0.2510  decode.d8.loss_dice: 0.3711
07/25 18:18:27 - mmengine - INFO - Iter(train) [11400/80000]  base_lr: 8.7079e-05 lr: 8.7079e-06  eta: 9:53:30  time: 0.4850  data_time: 0.0081  memory: 5922  grad_norm: 180.6168  loss: 9.2805  decode.loss_cls: 0.2503  decode.loss_mask: 0.2100  decode.loss_dice: 0.3269  decode.d0.loss_cls: 1.1406  decode.d0.loss_mask: 0.2235  decode.d0.loss_dice: 0.3529  decode.d1.loss_cls: 0.4907  decode.d1.loss_mask: 0.2161  decode.d1.loss_dice: 0.3269  decode.d2.loss_cls: 0.2680  decode.d2.loss_mask: 0.2145  decode.d2.loss_dice: 0.3214  decode.d3.loss_cls: 0.2675  decode.d3.loss_mask: 0.2123  decode.d3.loss_dice: 0.3432  decode.d4.loss_cls: 0.2809  decode.d4.loss_mask: 0.2133  decode.d4.loss_dice: 0.3256  decode.d5.loss_cls: 0.3166  decode.d5.loss_mask: 0.2111  decode.d5.loss_dice: 0.3369  decode.d6.loss_cls: 0.2749  decode.d6.loss_mask: 0.2080  decode.d6.loss_dice: 0.3152  decode.d7.loss_cls: 0.2958  decode.d7.loss_mask: 0.2069  decode.d7.loss_dice: 0.3223  decode.d8.loss_cls: 0.2743  decode.d8.loss_mask: 0.2124  decode.d8.loss_dice: 0.3217
07/25 18:18:51 - mmengine - INFO - Iter(train) [11450/80000]  base_lr: 8.7022e-05 lr: 8.7022e-06  eta: 9:52:46  time: 0.4847  data_time: 0.0082  memory: 5888  grad_norm: 168.3997  loss: 11.4878  decode.loss_cls: 0.3859  decode.loss_mask: 0.3176  decode.loss_dice: 0.4061  decode.d0.loss_cls: 1.2381  decode.d0.loss_mask: 0.2917  decode.d0.loss_dice: 0.3977  decode.d1.loss_cls: 0.4681  decode.d1.loss_mask: 0.2809  decode.d1.loss_dice: 0.4138  decode.d2.loss_cls: 0.3768  decode.d2.loss_mask: 0.2877  decode.d2.loss_dice: 0.4306  decode.d3.loss_cls: 0.3509  decode.d3.loss_mask: 0.2802  decode.d3.loss_dice: 0.3895  decode.d4.loss_cls: 0.3506  decode.d4.loss_mask: 0.2791  decode.d4.loss_dice: 0.3968  decode.d5.loss_cls: 0.3256  decode.d5.loss_mask: 0.2917  decode.d5.loss_dice: 0.4019  decode.d6.loss_cls: 0.2814  decode.d6.loss_mask: 0.2897  decode.d6.loss_dice: 0.3851  decode.d7.loss_cls: 0.3855  decode.d7.loss_mask: 0.2856  decode.d7.loss_dice: 0.3891  decode.d8.loss_cls: 0.3679  decode.d8.loss_mask: 0.3236  decode.d8.loss_dice: 0.4186
07/25 18:19:15 - mmengine - INFO - Iter(train) [11500/80000]  base_lr: 8.6965e-05 lr: 8.6965e-06  eta: 9:52:02  time: 0.4838  data_time: 0.0081  memory: 5965  grad_norm: 104.1893  loss: 11.7802  decode.loss_cls: 0.3489  decode.loss_mask: 0.3366  decode.loss_dice: 0.3845  decode.d0.loss_cls: 1.0964  decode.d0.loss_mask: 0.3595  decode.d0.loss_dice: 0.3947  decode.d1.loss_cls: 0.5709  decode.d1.loss_mask: 0.3366  decode.d1.loss_dice: 0.3561  decode.d2.loss_cls: 0.3682  decode.d2.loss_mask: 0.3344  decode.d2.loss_dice: 0.3536  decode.d3.loss_cls: 0.3504  decode.d3.loss_mask: 0.3337  decode.d3.loss_dice: 0.3969  decode.d4.loss_cls: 0.3537  decode.d4.loss_mask: 0.3368  decode.d4.loss_dice: 0.3605  decode.d5.loss_cls: 0.4094  decode.d5.loss_mask: 0.3364  decode.d5.loss_dice: 0.3530  decode.d6.loss_cls: 0.3733  decode.d6.loss_mask: 0.3371  decode.d6.loss_dice: 0.3663  decode.d7.loss_cls: 0.3787  decode.d7.loss_mask: 0.3392  decode.d7.loss_dice: 0.3806  decode.d8.loss_cls: 0.4394  decode.d8.loss_mask: 0.3380  decode.d8.loss_dice: 0.3561
07/25 18:19:39 - mmengine - INFO - Iter(train) [11550/80000]  base_lr: 8.6908e-05 lr: 8.6908e-06  eta: 9:51:19  time: 0.4849  data_time: 0.0084  memory: 5888  grad_norm: 98.2791  loss: 8.9167  decode.loss_cls: 0.1400  decode.loss_mask: 0.2969  decode.loss_dice: 0.2863  decode.d0.loss_cls: 1.2559  decode.d0.loss_mask: 0.3132  decode.d0.loss_dice: 0.2889  decode.d1.loss_cls: 0.2905  decode.d1.loss_mask: 0.2979  decode.d1.loss_dice: 0.2632  decode.d2.loss_cls: 0.2016  decode.d2.loss_mask: 0.3038  decode.d2.loss_dice: 0.3001  decode.d3.loss_cls: 0.1745  decode.d3.loss_mask: 0.3011  decode.d3.loss_dice: 0.2785  decode.d4.loss_cls: 0.1869  decode.d4.loss_mask: 0.3035  decode.d4.loss_dice: 0.2930  decode.d5.loss_cls: 0.2098  decode.d5.loss_mask: 0.3003  decode.d5.loss_dice: 0.2917  decode.d6.loss_cls: 0.2564  decode.d6.loss_mask: 0.2995  decode.d6.loss_dice: 0.2792  decode.d7.loss_cls: 0.1655  decode.d7.loss_mask: 0.2980  decode.d7.loss_dice: 0.2825  decode.d8.loss_cls: 0.1844  decode.d8.loss_mask: 0.3038  decode.d8.loss_dice: 0.2698
07/25 18:20:04 - mmengine - INFO - Iter(train) [11600/80000]  base_lr: 8.6851e-05 lr: 8.6851e-06  eta: 9:50:35  time: 0.4852  data_time: 0.0080  memory: 5959  grad_norm: 141.1443  loss: 7.6785  decode.loss_cls: 0.1874  decode.loss_mask: 0.1919  decode.loss_dice: 0.2335  decode.d0.loss_cls: 1.4349  decode.d0.loss_mask: 0.2107  decode.d0.loss_dice: 0.3012  decode.d1.loss_cls: 0.3316  decode.d1.loss_mask: 0.1930  decode.d1.loss_dice: 0.2466  decode.d2.loss_cls: 0.2298  decode.d2.loss_mask: 0.1870  decode.d2.loss_dice: 0.2426  decode.d3.loss_cls: 0.1857  decode.d3.loss_mask: 0.1867  decode.d3.loss_dice: 0.2283  decode.d4.loss_cls: 0.1647  decode.d4.loss_mask: 0.1870  decode.d4.loss_dice: 0.2287  decode.d5.loss_cls: 0.2069  decode.d5.loss_mask: 0.1916  decode.d5.loss_dice: 0.2528  decode.d6.loss_cls: 0.2181  decode.d6.loss_mask: 0.1899  decode.d6.loss_dice: 0.2246  decode.d7.loss_cls: 0.1772  decode.d7.loss_mask: 0.1910  decode.d7.loss_dice: 0.2556  decode.d8.loss_cls: 0.1748  decode.d8.loss_mask: 0.1904  decode.d8.loss_dice: 0.2344
07/25 18:20:28 - mmengine - INFO - Iter(train) [11650/80000]  base_lr: 8.6794e-05 lr: 8.6794e-06  eta: 9:49:53  time: 0.4850  data_time: 0.0082  memory: 5910  grad_norm: 168.4871  loss: 7.2696  decode.loss_cls: 0.1299  decode.loss_mask: 0.2331  decode.loss_dice: 0.2636  decode.d0.loss_cls: 0.9967  decode.d0.loss_mask: 0.2349  decode.d0.loss_dice: 0.3177  decode.d1.loss_cls: 0.1820  decode.d1.loss_mask: 0.2301  decode.d1.loss_dice: 0.2940  decode.d2.loss_cls: 0.1647  decode.d2.loss_mask: 0.2666  decode.d2.loss_dice: 0.2527  decode.d3.loss_cls: 0.1434  decode.d3.loss_mask: 0.2418  decode.d3.loss_dice: 0.2471  decode.d4.loss_cls: 0.1151  decode.d4.loss_mask: 0.2273  decode.d4.loss_dice: 0.2481  decode.d5.loss_cls: 0.1258  decode.d5.loss_mask: 0.2315  decode.d5.loss_dice: 0.2523  decode.d6.loss_cls: 0.1250  decode.d6.loss_mask: 0.2485  decode.d6.loss_dice: 0.2709  decode.d7.loss_cls: 0.1308  decode.d7.loss_mask: 0.2334  decode.d7.loss_dice: 0.2524  decode.d8.loss_cls: 0.1219  decode.d8.loss_mask: 0.2324  decode.d8.loss_dice: 0.2560
07/25 18:20:52 - mmengine - INFO - Iter(train) [11700/80000]  base_lr: 8.6737e-05 lr: 8.6737e-06  eta: 9:49:10  time: 0.4859  data_time: 0.0085  memory: 5888  grad_norm: 186.3595  loss: 12.3949  decode.loss_cls: 0.4765  decode.loss_mask: 0.3309  decode.loss_dice: 0.3550  decode.d0.loss_cls: 1.3542  decode.d0.loss_mask: 0.3440  decode.d0.loss_dice: 0.3869  decode.d1.loss_cls: 0.4718  decode.d1.loss_mask: 0.3425  decode.d1.loss_dice: 0.3534  decode.d2.loss_cls: 0.4363  decode.d2.loss_mask: 0.3380  decode.d2.loss_dice: 0.3636  decode.d3.loss_cls: 0.4259  decode.d3.loss_mask: 0.3301  decode.d3.loss_dice: 0.3587  decode.d4.loss_cls: 0.4381  decode.d4.loss_mask: 0.3351  decode.d4.loss_dice: 0.3644  decode.d5.loss_cls: 0.4608  decode.d5.loss_mask: 0.3271  decode.d5.loss_dice: 0.3645  decode.d6.loss_cls: 0.4818  decode.d6.loss_mask: 0.3360  decode.d6.loss_dice: 0.3651  decode.d7.loss_cls: 0.4745  decode.d7.loss_mask: 0.3358  decode.d7.loss_dice: 0.3439  decode.d8.loss_cls: 0.4387  decode.d8.loss_mask: 0.3281  decode.d8.loss_dice: 0.3332
07/25 18:21:16 - mmengine - INFO - Iter(train) [11750/80000]  base_lr: 8.6679e-05 lr: 8.6679e-06  eta: 9:48:28  time: 0.4853  data_time: 0.0084  memory: 5905  grad_norm: 124.8581  loss: 8.5979  decode.loss_cls: 0.2800  decode.loss_mask: 0.2017  decode.loss_dice: 0.2576  decode.d0.loss_cls: 1.2888  decode.d0.loss_mask: 0.1992  decode.d0.loss_dice: 0.2860  decode.d1.loss_cls: 0.4295  decode.d1.loss_mask: 0.1967  decode.d1.loss_dice: 0.2766  decode.d2.loss_cls: 0.3049  decode.d2.loss_mask: 0.1940  decode.d2.loss_dice: 0.2812  decode.d3.loss_cls: 0.2662  decode.d3.loss_mask: 0.1938  decode.d3.loss_dice: 0.2555  decode.d4.loss_cls: 0.2780  decode.d4.loss_mask: 0.1951  decode.d4.loss_dice: 0.2641  decode.d5.loss_cls: 0.2902  decode.d5.loss_mask: 0.1958  decode.d5.loss_dice: 0.2600  decode.d6.loss_cls: 0.2900  decode.d6.loss_mask: 0.1971  decode.d6.loss_dice: 0.2751  decode.d7.loss_cls: 0.2458  decode.d7.loss_mask: 0.1971  decode.d7.loss_dice: 0.2582  decode.d8.loss_cls: 0.2676  decode.d8.loss_mask: 0.2018  decode.d8.loss_dice: 0.2704
07/25 18:21:41 - mmengine - INFO - Iter(train) [11800/80000]  base_lr: 8.6622e-05 lr: 8.6622e-06  eta: 9:47:46  time: 0.4847  data_time: 0.0083  memory: 5885  grad_norm: 165.9008  loss: 7.8189  decode.loss_cls: 0.2012  decode.loss_mask: 0.1983  decode.loss_dice: 0.2457  decode.d0.loss_cls: 1.1844  decode.d0.loss_mask: 0.2100  decode.d0.loss_dice: 0.2558  decode.d1.loss_cls: 0.3254  decode.d1.loss_mask: 0.2077  decode.d1.loss_dice: 0.2356  decode.d2.loss_cls: 0.3557  decode.d2.loss_mask: 0.2043  decode.d2.loss_dice: 0.2265  decode.d3.loss_cls: 0.2866  decode.d3.loss_mask: 0.2068  decode.d3.loss_dice: 0.2384  decode.d4.loss_cls: 0.2602  decode.d4.loss_mask: 0.2012  decode.d4.loss_dice: 0.2283  decode.d5.loss_cls: 0.2086  decode.d5.loss_mask: 0.2054  decode.d5.loss_dice: 0.2295  decode.d6.loss_cls: 0.2063  decode.d6.loss_mask: 0.1994  decode.d6.loss_dice: 0.2224  decode.d7.loss_cls: 0.2015  decode.d7.loss_mask: 0.2021  decode.d7.loss_dice: 0.2261  decode.d8.loss_cls: 0.2223  decode.d8.loss_mask: 0.1965  decode.d8.loss_dice: 0.2266
07/25 18:22:05 - mmengine - INFO - Iter(train) [11850/80000]  base_lr: 8.6565e-05 lr: 8.6565e-06  eta: 9:47:04  time: 0.4848  data_time: 0.0084  memory: 5905  grad_norm: 168.4873  loss: 11.9342  decode.loss_cls: 0.4782  decode.loss_mask: 0.2849  decode.loss_dice: 0.3476  decode.d0.loss_cls: 1.3246  decode.d0.loss_mask: 0.2938  decode.d0.loss_dice: 0.3826  decode.d1.loss_cls: 0.5798  decode.d1.loss_mask: 0.2836  decode.d1.loss_dice: 0.3510  decode.d2.loss_cls: 0.4373  decode.d2.loss_mask: 0.2848  decode.d2.loss_dice: 0.3335  decode.d3.loss_cls: 0.4639  decode.d3.loss_mask: 0.2830  decode.d3.loss_dice: 0.3481  decode.d4.loss_cls: 0.5400  decode.d4.loss_mask: 0.2840  decode.d4.loss_dice: 0.3430  decode.d5.loss_cls: 0.5218  decode.d5.loss_mask: 0.2807  decode.d5.loss_dice: 0.3480  decode.d6.loss_cls: 0.3955  decode.d6.loss_mask: 0.2787  decode.d6.loss_dice: 0.3457  decode.d7.loss_cls: 0.3642  decode.d7.loss_mask: 0.2860  decode.d7.loss_dice: 0.3510  decode.d8.loss_cls: 0.4990  decode.d8.loss_mask: 0.2816  decode.d8.loss_dice: 0.3379
07/25 18:22:29 - mmengine - INFO - Iter(train) [11900/80000]  base_lr: 8.6508e-05 lr: 8.6508e-06  eta: 9:46:23  time: 0.4847  data_time: 0.0087  memory: 5959  grad_norm: 127.8476  loss: 10.1341  decode.loss_cls: 0.4219  decode.loss_mask: 0.2702  decode.loss_dice: 0.3196  decode.d0.loss_cls: 0.9953  decode.d0.loss_mask: 0.2760  decode.d0.loss_dice: 0.3732  decode.d1.loss_cls: 0.4036  decode.d1.loss_mask: 0.2794  decode.d1.loss_dice: 0.3290  decode.d2.loss_cls: 0.3512  decode.d2.loss_mask: 0.2654  decode.d2.loss_dice: 0.3311  decode.d3.loss_cls: 0.3185  decode.d3.loss_mask: 0.2668  decode.d3.loss_dice: 0.3225  decode.d4.loss_cls: 0.3291  decode.d4.loss_mask: 0.2688  decode.d4.loss_dice: 0.3328  decode.d5.loss_cls: 0.2924  decode.d5.loss_mask: 0.2674  decode.d5.loss_dice: 0.3315  decode.d6.loss_cls: 0.2762  decode.d6.loss_mask: 0.2695  decode.d6.loss_dice: 0.3451  decode.d7.loss_cls: 0.3452  decode.d7.loss_mask: 0.2715  decode.d7.loss_dice: 0.3449  decode.d8.loss_cls: 0.3501  decode.d8.loss_mask: 0.2700  decode.d8.loss_dice: 0.3157
07/25 18:22:54 - mmengine - INFO - Iter(train) [11950/80000]  base_lr: 8.6451e-05 lr: 8.6451e-06  eta: 9:45:43  time: 0.4874  data_time: 0.0086  memory: 5906  grad_norm: 243.4942  loss: 12.2320  decode.loss_cls: 0.3031  decode.loss_mask: 0.3481  decode.loss_dice: 0.4526  decode.d0.loss_cls: 1.1299  decode.d0.loss_mask: 0.3635  decode.d0.loss_dice: 0.4236  decode.d1.loss_cls: 0.4978  decode.d1.loss_mask: 0.3611  decode.d1.loss_dice: 0.4007  decode.d2.loss_cls: 0.3547  decode.d2.loss_mask: 0.3572  decode.d2.loss_dice: 0.4106  decode.d3.loss_cls: 0.2882  decode.d3.loss_mask: 0.3484  decode.d3.loss_dice: 0.4199  decode.d4.loss_cls: 0.3532  decode.d4.loss_mask: 0.3469  decode.d4.loss_dice: 0.4381  decode.d5.loss_cls: 0.3573  decode.d5.loss_mask: 0.3445  decode.d5.loss_dice: 0.4457  decode.d6.loss_cls: 0.4331  decode.d6.loss_mask: 0.3524  decode.d6.loss_dice: 0.4268  decode.d7.loss_cls: 0.3731  decode.d7.loss_mask: 0.3555  decode.d7.loss_dice: 0.4478  decode.d8.loss_cls: 0.3060  decode.d8.loss_mask: 0.3479  decode.d8.loss_dice: 0.4442
07/25 18:23:18 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250725_172252
07/25 18:23:18 - mmengine - INFO - Iter(train) [12000/80000]  base_lr: 8.6394e-05 lr: 8.6394e-06  eta: 9:45:02  time: 0.4851  data_time: 0.0083  memory: 5891  grad_norm: 111.5531  loss: 7.9854  decode.loss_cls: 0.2345  decode.loss_mask: 0.2319  decode.loss_dice: 0.2516  decode.d0.loss_cls: 1.0945  decode.d0.loss_mask: 0.2369  decode.d0.loss_dice: 0.2633  decode.d1.loss_cls: 0.3415  decode.d1.loss_mask: 0.2295  decode.d1.loss_dice: 0.2396  decode.d2.loss_cls: 0.2375  decode.d2.loss_mask: 0.2352  decode.d2.loss_dice: 0.2583  decode.d3.loss_cls: 0.2240  decode.d3.loss_mask: 0.2294  decode.d3.loss_dice: 0.2422  decode.d4.loss_cls: 0.2260  decode.d4.loss_mask: 0.2293  decode.d4.loss_dice: 0.2370  decode.d5.loss_cls: 0.1913  decode.d5.loss_mask: 0.2318  decode.d5.loss_dice: 0.2551  decode.d6.loss_cls: 0.1936  decode.d6.loss_mask: 0.2281  decode.d6.loss_dice: 0.2515  decode.d7.loss_cls: 0.1895  decode.d7.loss_mask: 0.2318  decode.d7.loss_dice: 0.2611  decode.d8.loss_cls: 0.2287  decode.d8.loss_mask: 0.2347  decode.d8.loss_dice: 0.2463
07/25 18:23:42 - mmengine - INFO - Iter(train) [12050/80000]  base_lr: 8.6336e-05 lr: 8.6336e-06  eta: 9:44:21  time: 0.4847  data_time: 0.0085  memory: 5888  grad_norm: 203.7939  loss: 9.9128  decode.loss_cls: 0.3067  decode.loss_mask: 0.2797  decode.loss_dice: 0.2758  decode.d0.loss_cls: 1.1658  decode.d0.loss_mask: 0.2910  decode.d0.loss_dice: 0.3354  decode.d1.loss_cls: 0.3125  decode.d1.loss_mask: 0.2741  decode.d1.loss_dice: 0.2997  decode.d2.loss_cls: 0.2839  decode.d2.loss_mask: 0.2812  decode.d2.loss_dice: 0.3161  decode.d3.loss_cls: 0.3169  decode.d3.loss_mask: 0.2982  decode.d3.loss_dice: 0.3056  decode.d4.loss_cls: 0.3208  decode.d4.loss_mask: 0.2988  decode.d4.loss_dice: 0.3050  decode.d5.loss_cls: 0.3291  decode.d5.loss_mask: 0.2997  decode.d5.loss_dice: 0.3135  decode.d6.loss_cls: 0.2743  decode.d6.loss_mask: 0.3199  decode.d6.loss_dice: 0.3106  decode.d7.loss_cls: 0.3460  decode.d7.loss_mask: 0.2831  decode.d7.loss_dice: 0.2912  decode.d8.loss_cls: 0.3132  decode.d8.loss_mask: 0.2791  decode.d8.loss_dice: 0.2857
07/25 18:24:06 - mmengine - INFO - Iter(train) [12100/80000]  base_lr: 8.6279e-05 lr: 8.6279e-06  eta: 9:43:41  time: 0.4857  data_time: 0.0086  memory: 5891  grad_norm: 141.2616  loss: 9.5110  decode.loss_cls: 0.3274  decode.loss_mask: 0.2089  decode.loss_dice: 0.2915  decode.d0.loss_cls: 1.3337  decode.d0.loss_mask: 0.2092  decode.d0.loss_dice: 0.3153  decode.d1.loss_cls: 0.5105  decode.d1.loss_mask: 0.2051  decode.d1.loss_dice: 0.2923  decode.d2.loss_cls: 0.3262  decode.d2.loss_mask: 0.2057  decode.d2.loss_dice: 0.3048  decode.d3.loss_cls: 0.3329  decode.d3.loss_mask: 0.2073  decode.d3.loss_dice: 0.2866  decode.d4.loss_cls: 0.3563  decode.d4.loss_mask: 0.2037  decode.d4.loss_dice: 0.2915  decode.d5.loss_cls: 0.3394  decode.d5.loss_mask: 0.2072  decode.d5.loss_dice: 0.3021  decode.d6.loss_cls: 0.3217  decode.d6.loss_mask: 0.2071  decode.d6.loss_dice: 0.2873  decode.d7.loss_cls: 0.3285  decode.d7.loss_mask: 0.2080  decode.d7.loss_dice: 0.2820  decode.d8.loss_cls: 0.3344  decode.d8.loss_mask: 0.2072  decode.d8.loss_dice: 0.2770
07/25 18:24:31 - mmengine - INFO - Iter(train) [12150/80000]  base_lr: 8.6222e-05 lr: 8.6222e-06  eta: 9:43:00  time: 0.4844  data_time: 0.0085  memory: 5912  grad_norm: 195.3169  loss: 10.4025  decode.loss_cls: 0.2826  decode.loss_mask: 0.2905  decode.loss_dice: 0.3447  decode.d0.loss_cls: 1.1194  decode.d0.loss_mask: 0.3097  decode.d0.loss_dice: 0.4016  decode.d1.loss_cls: 0.4750  decode.d1.loss_mask: 0.2895  decode.d1.loss_dice: 0.3464  decode.d2.loss_cls: 0.3787  decode.d2.loss_mask: 0.2976  decode.d2.loss_dice: 0.3536  decode.d3.loss_cls: 0.3264  decode.d3.loss_mask: 0.2903  decode.d3.loss_dice: 0.3483  decode.d4.loss_cls: 0.2843  decode.d4.loss_mask: 0.2892  decode.d4.loss_dice: 0.3514  decode.d5.loss_cls: 0.2441  decode.d5.loss_mask: 0.2864  decode.d5.loss_dice: 0.3460  decode.d6.loss_cls: 0.2788  decode.d6.loss_mask: 0.2945  decode.d6.loss_dice: 0.3403  decode.d7.loss_cls: 0.2609  decode.d7.loss_mask: 0.2890  decode.d7.loss_dice: 0.3540  decode.d8.loss_cls: 0.2822  decode.d8.loss_mask: 0.2904  decode.d8.loss_dice: 0.3567
07/25 18:24:55 - mmengine - INFO - Iter(train) [12200/80000]  base_lr: 8.6165e-05 lr: 8.6165e-06  eta: 9:42:20  time: 0.4849  data_time: 0.0082  memory: 5906  grad_norm: 178.5802  loss: 8.6921  decode.loss_cls: 0.1576  decode.loss_mask: 0.2921  decode.loss_dice: 0.3030  decode.d0.loss_cls: 1.0310  decode.d0.loss_mask: 0.3006  decode.d0.loss_dice: 0.3308  decode.d1.loss_cls: 0.1934  decode.d1.loss_mask: 0.2971  decode.d1.loss_dice: 0.3113  decode.d2.loss_cls: 0.1869  decode.d2.loss_mask: 0.2985  decode.d2.loss_dice: 0.3135  decode.d3.loss_cls: 0.2280  decode.d3.loss_mask: 0.2939  decode.d3.loss_dice: 0.2948  decode.d4.loss_cls: 0.1955  decode.d4.loss_mask: 0.2921  decode.d4.loss_dice: 0.2993  decode.d5.loss_cls: 0.1923  decode.d5.loss_mask: 0.2905  decode.d5.loss_dice: 0.2956  decode.d6.loss_cls: 0.1878  decode.d6.loss_mask: 0.2895  decode.d6.loss_dice: 0.2972  decode.d7.loss_cls: 0.1663  decode.d7.loss_mask: 0.2931  decode.d7.loss_dice: 0.3095  decode.d8.loss_cls: 0.1611  decode.d8.loss_mask: 0.2895  decode.d8.loss_dice: 0.3003
07/25 18:25:19 - mmengine - INFO - Iter(train) [12250/80000]  base_lr: 8.6108e-05 lr: 8.6108e-06  eta: 9:41:40  time: 0.4838  data_time: 0.0083  memory: 5966  grad_norm: 99.7113  loss: 7.3895  decode.loss_cls: 0.1422  decode.loss_mask: 0.2471  decode.loss_dice: 0.2473  decode.d0.loss_cls: 1.0340  decode.d0.loss_mask: 0.2583  decode.d0.loss_dice: 0.2834  decode.d1.loss_cls: 0.2856  decode.d1.loss_mask: 0.2464  decode.d1.loss_dice: 0.2537  decode.d2.loss_cls: 0.1607  decode.d2.loss_mask: 0.2468  decode.d2.loss_dice: 0.2579  decode.d3.loss_cls: 0.1607  decode.d3.loss_mask: 0.2439  decode.d3.loss_dice: 0.2529  decode.d4.loss_cls: 0.1271  decode.d4.loss_mask: 0.2467  decode.d4.loss_dice: 0.2554  decode.d5.loss_cls: 0.1285  decode.d5.loss_mask: 0.2458  decode.d5.loss_dice: 0.2549  decode.d6.loss_cls: 0.0846  decode.d6.loss_mask: 0.2481  decode.d6.loss_dice: 0.2508  decode.d7.loss_cls: 0.0821  decode.d7.loss_mask: 0.2475  decode.d7.loss_dice: 0.2521  decode.d8.loss_cls: 0.1451  decode.d8.loss_mask: 0.2481  decode.d8.loss_dice: 0.2521
07/25 18:25:43 - mmengine - INFO - Iter(train) [12300/80000]  base_lr: 8.6051e-05 lr: 8.6051e-06  eta: 9:41:01  time: 0.4861  data_time: 0.0084  memory: 5910  grad_norm: 133.3465  loss: 12.6100  decode.loss_cls: 0.5129  decode.loss_mask: 0.2893  decode.loss_dice: 0.3320  decode.d0.loss_cls: 1.3084  decode.d0.loss_mask: 0.2889  decode.d0.loss_dice: 0.3805  decode.d1.loss_cls: 0.6765  decode.d1.loss_mask: 0.2949  decode.d1.loss_dice: 0.3498  decode.d2.loss_cls: 0.5481  decode.d2.loss_mask: 0.2846  decode.d2.loss_dice: 0.3455  decode.d3.loss_cls: 0.4973  decode.d3.loss_mask: 0.2801  decode.d3.loss_dice: 0.3720  decode.d4.loss_cls: 0.5597  decode.d4.loss_mask: 0.2779  decode.d4.loss_dice: 0.3432  decode.d5.loss_cls: 0.5209  decode.d5.loss_mask: 0.2701  decode.d5.loss_dice: 0.3279  decode.d6.loss_cls: 0.5384  decode.d6.loss_mask: 0.2784  decode.d6.loss_dice: 0.3418  decode.d7.loss_cls: 0.5616  decode.d7.loss_mask: 0.3145  decode.d7.loss_dice: 0.3459  decode.d8.loss_cls: 0.5032  decode.d8.loss_mask: 0.3191  decode.d8.loss_dice: 0.3465
07/25 18:26:08 - mmengine - INFO - Iter(train) [12350/80000]  base_lr: 8.5993e-05 lr: 8.5993e-06  eta: 9:40:22  time: 0.4847  data_time: 0.0084  memory: 5911  grad_norm: 128.9150  loss: 8.6435  decode.loss_cls: 0.2178  decode.loss_mask: 0.2548  decode.loss_dice: 0.2662  decode.d0.loss_cls: 1.0850  decode.d0.loss_mask: 0.2674  decode.d0.loss_dice: 0.2940  decode.d1.loss_cls: 0.3626  decode.d1.loss_mask: 0.2648  decode.d1.loss_dice: 0.2553  decode.d2.loss_cls: 0.2747  decode.d2.loss_mask: 0.2823  decode.d2.loss_dice: 0.2737  decode.d3.loss_cls: 0.3098  decode.d3.loss_mask: 0.2700  decode.d3.loss_dice: 0.2581  decode.d4.loss_cls: 0.2312  decode.d4.loss_mask: 0.2541  decode.d4.loss_dice: 0.2668  decode.d5.loss_cls: 0.2346  decode.d5.loss_mask: 0.2639  decode.d5.loss_dice: 0.2648  decode.d6.loss_cls: 0.2072  decode.d6.loss_mask: 0.2609  decode.d6.loss_dice: 0.2544  decode.d7.loss_cls: 0.2137  decode.d7.loss_mask: 0.2601  decode.d7.loss_dice: 0.2533  decode.d8.loss_cls: 0.2274  decode.d8.loss_mask: 0.2605  decode.d8.loss_dice: 0.2540
07/25 18:26:32 - mmengine - INFO - Iter(train) [12400/80000]  base_lr: 8.5936e-05 lr: 8.5936e-06  eta: 9:39:43  time: 0.4873  data_time: 0.0083  memory: 5958  grad_norm: 231.5076  loss: 8.9656  decode.loss_cls: 0.2790  decode.loss_mask: 0.2359  decode.loss_dice: 0.2818  decode.d0.loss_cls: 1.0941  decode.d0.loss_mask: 0.2439  decode.d0.loss_dice: 0.2925  decode.d1.loss_cls: 0.2597  decode.d1.loss_mask: 0.2365  decode.d1.loss_dice: 0.3013  decode.d2.loss_cls: 0.2956  decode.d2.loss_mask: 0.2380  decode.d2.loss_dice: 0.3001  decode.d3.loss_cls: 0.3217  decode.d3.loss_mask: 0.2345  decode.d3.loss_dice: 0.2827  decode.d4.loss_cls: 0.3064  decode.d4.loss_mask: 0.2355  decode.d4.loss_dice: 0.2785  decode.d5.loss_cls: 0.2876  decode.d5.loss_mask: 0.2370  decode.d5.loss_dice: 0.2820  decode.d6.loss_cls: 0.2949  decode.d6.loss_mask: 0.2312  decode.d6.loss_dice: 0.2774  decode.d7.loss_cls: 0.2939  decode.d7.loss_mask: 0.2299  decode.d7.loss_dice: 0.2816  decode.d8.loss_cls: 0.3201  decode.d8.loss_mask: 0.2299  decode.d8.loss_dice: 0.2823
07/25 18:26:56 - mmengine - INFO - Iter(train) [12450/80000]  base_lr: 8.5879e-05 lr: 8.5879e-06  eta: 9:39:05  time: 0.4976  data_time: 0.0081  memory: 5922  grad_norm: 221.2824  loss: 9.1742  decode.loss_cls: 0.2737  decode.loss_mask: 0.2512  decode.loss_dice: 0.2988  decode.d0.loss_cls: 1.1780  decode.d0.loss_mask: 0.2866  decode.d0.loss_dice: 0.3443  decode.d1.loss_cls: 0.2870  decode.d1.loss_mask: 0.2646  decode.d1.loss_dice: 0.3132  decode.d2.loss_cls: 0.2881  decode.d2.loss_mask: 0.2510  decode.d2.loss_dice: 0.2815  decode.d3.loss_cls: 0.2491  decode.d3.loss_mask: 0.2520  decode.d3.loss_dice: 0.2882  decode.d4.loss_cls: 0.2688  decode.d4.loss_mask: 0.2481  decode.d4.loss_dice: 0.2949  decode.d5.loss_cls: 0.2647  decode.d5.loss_mask: 0.2612  decode.d5.loss_dice: 0.2980  decode.d6.loss_cls: 0.2595  decode.d6.loss_mask: 0.2603  decode.d6.loss_dice: 0.3026  decode.d7.loss_cls: 0.2569  decode.d7.loss_mask: 0.2502  decode.d7.loss_dice: 0.2905  decode.d8.loss_cls: 0.2800  decode.d8.loss_mask: 0.2494  decode.d8.loss_dice: 0.2818
07/25 18:27:21 - mmengine - INFO - Iter(train) [12500/80000]  base_lr: 8.5822e-05 lr: 8.5822e-06  eta: 9:38:26  time: 0.4846  data_time: 0.0080  memory: 5892  grad_norm: 127.8897  loss: 8.9297  decode.loss_cls: 0.3047  decode.loss_mask: 0.1725  decode.loss_dice: 0.3123  decode.d0.loss_cls: 1.2217  decode.d0.loss_mask: 0.1746  decode.d0.loss_dice: 0.3300  decode.d1.loss_cls: 0.3529  decode.d1.loss_mask: 0.1710  decode.d1.loss_dice: 0.3548  decode.d2.loss_cls: 0.2944  decode.d2.loss_mask: 0.1642  decode.d2.loss_dice: 0.3235  decode.d3.loss_cls: 0.3244  decode.d3.loss_mask: 0.1627  decode.d3.loss_dice: 0.2969  decode.d4.loss_cls: 0.3146  decode.d4.loss_mask: 0.1686  decode.d4.loss_dice: 0.3481  decode.d5.loss_cls: 0.3313  decode.d5.loss_mask: 0.1631  decode.d5.loss_dice: 0.2978  decode.d6.loss_cls: 0.3278  decode.d6.loss_mask: 0.1724  decode.d6.loss_dice: 0.3088  decode.d7.loss_cls: 0.2756  decode.d7.loss_mask: 0.1715  decode.d7.loss_dice: 0.3275  decode.d8.loss_cls: 0.2775  decode.d8.loss_mask: 0.1753  decode.d8.loss_dice: 0.3093
07/25 18:27:45 - mmengine - INFO - Iter(train) [12550/80000]  base_lr: 8.5765e-05 lr: 8.5765e-06  eta: 9:37:47  time: 0.4854  data_time: 0.0084  memory: 5907  grad_norm: 108.3925  loss: 7.7336  decode.loss_cls: 0.1417  decode.loss_mask: 0.2451  decode.loss_dice: 0.2518  decode.d0.loss_cls: 1.1694  decode.d0.loss_mask: 0.2643  decode.d0.loss_dice: 0.2848  decode.d1.loss_cls: 0.2182  decode.d1.loss_mask: 0.2490  decode.d1.loss_dice: 0.2618  decode.d2.loss_cls: 0.1697  decode.d2.loss_mask: 0.2492  decode.d2.loss_dice: 0.2553  decode.d3.loss_cls: 0.1575  decode.d3.loss_mask: 0.2413  decode.d3.loss_dice: 0.2510  decode.d4.loss_cls: 0.1914  decode.d4.loss_mask: 0.2434  decode.d4.loss_dice: 0.2555  decode.d5.loss_cls: 0.1367  decode.d5.loss_mask: 0.2489  decode.d5.loss_dice: 0.2579  decode.d6.loss_cls: 0.1866  decode.d6.loss_mask: 0.2484  decode.d6.loss_dice: 0.2589  decode.d7.loss_cls: 0.1455  decode.d7.loss_mask: 0.2480  decode.d7.loss_dice: 0.2584  decode.d8.loss_cls: 0.1387  decode.d8.loss_mask: 0.2454  decode.d8.loss_dice: 0.2599
07/25 18:28:09 - mmengine - INFO - Iter(train) [12600/80000]  base_lr: 8.5707e-05 lr: 8.5707e-06  eta: 9:37:08  time: 0.4851  data_time: 0.0084  memory: 5906  grad_norm: 322.4414  loss: 9.7714  decode.loss_cls: 0.2224  decode.loss_mask: 0.3325  decode.loss_dice: 0.3172  decode.d0.loss_cls: 1.0240  decode.d0.loss_mask: 0.3727  decode.d0.loss_dice: 0.3601  decode.d1.loss_cls: 0.2714  decode.d1.loss_mask: 0.3445  decode.d1.loss_dice: 0.2981  decode.d2.loss_cls: 0.2772  decode.d2.loss_mask: 0.3378  decode.d2.loss_dice: 0.2993  decode.d3.loss_cls: 0.3064  decode.d3.loss_mask: 0.3326  decode.d3.loss_dice: 0.2964  decode.d4.loss_cls: 0.2275  decode.d4.loss_mask: 0.3407  decode.d4.loss_dice: 0.2941  decode.d5.loss_cls: 0.2347  decode.d5.loss_mask: 0.3398  decode.d5.loss_dice: 0.3029  decode.d6.loss_cls: 0.2475  decode.d6.loss_mask: 0.3285  decode.d6.loss_dice: 0.3045  decode.d7.loss_cls: 0.2293  decode.d7.loss_mask: 0.3371  decode.d7.loss_dice: 0.3050  decode.d8.loss_cls: 0.2469  decode.d8.loss_mask: 0.3379  decode.d8.loss_dice: 0.3025
07/25 18:28:33 - mmengine - INFO - Iter(train) [12650/80000]  base_lr: 8.5650e-05 lr: 8.5650e-06  eta: 9:36:30  time: 0.4842  data_time: 0.0082  memory: 5905  grad_norm: 233.8372  loss: 12.4096  decode.loss_cls: 0.3999  decode.loss_mask: 0.4041  decode.loss_dice: 0.3609  decode.d0.loss_cls: 1.1536  decode.d0.loss_mask: 0.4317  decode.d0.loss_dice: 0.4072  decode.d1.loss_cls: 0.4977  decode.d1.loss_mask: 0.4125  decode.d1.loss_dice: 0.3715  decode.d2.loss_cls: 0.3489  decode.d2.loss_mask: 0.4096  decode.d2.loss_dice: 0.3778  decode.d3.loss_cls: 0.3556  decode.d3.loss_mask: 0.3964  decode.d3.loss_dice: 0.3673  decode.d4.loss_cls: 0.3902  decode.d4.loss_mask: 0.3987  decode.d4.loss_dice: 0.3530  decode.d5.loss_cls: 0.3736  decode.d5.loss_mask: 0.4034  decode.d5.loss_dice: 0.3642  decode.d6.loss_cls: 0.3766  decode.d6.loss_mask: 0.3997  decode.d6.loss_dice: 0.3534  decode.d7.loss_cls: 0.4049  decode.d7.loss_mask: 0.4119  decode.d7.loss_dice: 0.3695  decode.d8.loss_cls: 0.3998  decode.d8.loss_mask: 0.3685  decode.d8.loss_dice: 0.3476
07/25 18:28:58 - mmengine - INFO - Iter(train) [12700/80000]  base_lr: 8.5593e-05 lr: 8.5593e-06  eta: 9:35:52  time: 0.4861  data_time: 0.0084  memory: 5906  grad_norm: 195.4029  loss: 9.0471  decode.loss_cls: 0.1752  decode.loss_mask: 0.3819  decode.loss_dice: 0.3377  decode.d0.loss_cls: 1.2269  decode.d0.loss_mask: 0.2564  decode.d0.loss_dice: 0.3108  decode.d1.loss_cls: 0.2216  decode.d1.loss_mask: 0.2758  decode.d1.loss_dice: 0.2996  decode.d2.loss_cls: 0.2472  decode.d2.loss_mask: 0.2674  decode.d2.loss_dice: 0.2759  decode.d3.loss_cls: 0.2129  decode.d3.loss_mask: 0.2762  decode.d3.loss_dice: 0.2919  decode.d4.loss_cls: 0.2116  decode.d4.loss_mask: 0.2751  decode.d4.loss_dice: 0.3159  decode.d5.loss_cls: 0.1835  decode.d5.loss_mask: 0.2750  decode.d5.loss_dice: 0.3091  decode.d6.loss_cls: 0.1566  decode.d6.loss_mask: 0.2762  decode.d6.loss_dice: 0.3079  decode.d7.loss_cls: 0.1705  decode.d7.loss_mask: 0.3037  decode.d7.loss_dice: 0.3393  decode.d8.loss_cls: 0.1855  decode.d8.loss_mask: 0.3474  decode.d8.loss_dice: 0.3324
07/25 18:29:22 - mmengine - INFO - Iter(train) [12750/80000]  base_lr: 8.5536e-05 lr: 8.5536e-06  eta: 9:35:16  time: 0.5027  data_time: 0.0084  memory: 5910  grad_norm: 77.0489  loss: 7.8872  decode.loss_cls: 0.1781  decode.loss_mask: 0.2049  decode.loss_dice: 0.3063  decode.d0.loss_cls: 1.0574  decode.d0.loss_mask: 0.2145  decode.d0.loss_dice: 0.3329  decode.d1.loss_cls: 0.2967  decode.d1.loss_mask: 0.2078  decode.d1.loss_dice: 0.3023  decode.d2.loss_cls: 0.2202  decode.d2.loss_mask: 0.2059  decode.d2.loss_dice: 0.3031  decode.d3.loss_cls: 0.1704  decode.d3.loss_mask: 0.2028  decode.d3.loss_dice: 0.2957  decode.d4.loss_cls: 0.1699  decode.d4.loss_mask: 0.2033  decode.d4.loss_dice: 0.2875  decode.d5.loss_cls: 0.1943  decode.d5.loss_mask: 0.2047  decode.d5.loss_dice: 0.3026  decode.d6.loss_cls: 0.1485  decode.d6.loss_mask: 0.2029  decode.d6.loss_dice: 0.2919  decode.d7.loss_cls: 0.1829  decode.d7.loss_mask: 0.2043  decode.d7.loss_dice: 0.2935  decode.d8.loss_cls: 0.1812  decode.d8.loss_mask: 0.2048  decode.d8.loss_dice: 0.3161
