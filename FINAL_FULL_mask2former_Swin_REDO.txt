==========================================
SLURM_JOB_ID = 2467972
SLURM_NODELIST = gnode070
SLURM_JOB_GPUS = 2
==========================================
07/29 22:57:11 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.23 (main, Jun  5 2025, 13:40:20) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 268722126
    GPU 0: NVIDIA GeForce RTX 2080 Ti
    CUDA_HOME: /opt/cuda-12.1/
    NVCC: Cuda compilation tools, release 12.1, V12.1.66
    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
    PyTorch: 2.1.2
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 268722126
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

07/29 22:57:12 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=16, enable=False)
backbone_embed_multi = dict(decay_mult=0.0, lr_mult=0.1)
backbone_norm_multi = dict(decay_mult=0.0, lr_mult=0.1)
crop_size = (
    512,
    1024,
)
custom_keys = dict({
    'absolute_pos_embed':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone':
    dict(decay_mult=1.0, lr_mult=0.1),
    'backbone.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.patch_embed.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.2.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.3.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.4.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.5.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'level_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_feat':
    dict(decay_mult=0.0, lr_mult=1.0),
    'relative_position_bias_table':
    dict(decay_mult=0.0, lr_mult=0.1)
})
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        512,
        1024,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    test_cfg=dict(size_divisor=32),
    type='SegDataPreProcessor')
data_root = '/scratch/seg_benchmark/seg_full_redone_FINAL/'
dataset_type = 'YourDataset_BIG'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False, interval=5000, save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'))
default_scope = 'mmseg'
depths = [
    2,
    2,
    6,
    2,
]
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
img_suffix = '.jpg'
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        attn_drop_rate=0.0,
        depths=[
            2,
            2,
            6,
            2,
        ],
        drop_path_rate=0.3,
        drop_rate=0.0,
        embed_dims=96,
        frozen_stages=-1,
        init_cfg=dict(
            checkpoint=
            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth',
            type='Pretrained'),
        mlp_ratio=4,
        num_heads=[
            3,
            6,
            12,
            24,
        ],
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        patch_norm=True,
        qk_scale=None,
        qkv_bias=True,
        type='SwinTransformer',
        window_size=7,
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            1024,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        test_cfg=dict(size_divisor=32),
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            96,
            192,
            384,
            768,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=57,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 57
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict({
            'absolute_pos_embed':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone':
            dict(decay_mult=1.0, lr_mult=0.1),
            'backbone.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.patch_embed.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.2.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.3.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.4.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.5.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'level_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_feat':
            dict(decay_mult=0.0, lr_mult=1.0),
            'relative_position_bias_table':
            dict(decay_mult=0.0, lr_mult=0.1)
        }),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=80000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth'
resume = False
seg_map_suffix = '.png'
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/seg_benchmark/seg_full_redone_FINAL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    classwise=True, iou_metrics=[
        'mIoU',
    ], type='IoUNanAbsent')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2048,
        1024,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(
    max_iters=80000, type='IterBasedTrainLoop', val_interval=80000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        data_prefix=dict(img_path='train/images', seg_map_path='train/masks'),
        data_root='/scratch/seg_benchmark/seg_full_redone_FINAL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                max_size=4096,
                resize_type='ResizeShortestEdge',
                scales=[
                    512,
                    614,
                    716,
                    819,
                    921,
                    1024,
                    1126,
                    1228,
                    1331,
                    1433,
                    1536,
                    1638,
                    1740,
                    1843,
                    1945,
                    2048,
                ],
                type='RandomChoiceResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    512,
                    1024,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        max_size=4096,
        resize_type='ResizeShortestEdge',
        scales=[
            512,
            614,
            716,
            819,
            921,
            1024,
            1126,
            1228,
            1331,
            1433,
            1536,
            1638,
            1740,
            1843,
            1945,
            2048,
        ],
        type='RandomChoiceResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        1024,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/seg_benchmark/seg_full_redone_FINAL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '/scratch/seg_benchmark/FINAL_seg_full_redone_redo/mask2former_swin_T'

07/29 22:57:18 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
07/29 22:57:18 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:weight_decay=0.05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:decay_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr=1e-05
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr_mult=0.1
07/29 22:57:19 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
07/29 22:57:19 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
07/29 22:57:19 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth
07/29 22:57:20 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
07/29 22:57:20 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
07/29 22:57:20 - mmengine - INFO - Checkpoints will be saved to /scratch/seg_benchmark/FINAL_seg_full_redone_redo/mask2former_swin_T.
/home2/yasharora120/miniconda3/envs/mmseg/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400441250/work/aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
07/29 22:57:50 - mmengine - INFO - Iter(train) [   50/80000]  base_lr: 9.9945e-05 lr: 9.9945e-06  eta: 13:01:43  time: 0.5437  data_time: 0.0178  memory: 8941  grad_norm: 171.8597  loss: 103.9920  decode.loss_cls: 4.1432  decode.loss_mask: 2.3344  decode.loss_dice: 4.2695  decode.d0.loss_cls: 8.4132  decode.d0.loss_mask: 2.0026  decode.d0.loss_dice: 3.7703  decode.d1.loss_cls: 3.6773  decode.d1.loss_mask: 1.9644  decode.d1.loss_dice: 3.7676  decode.d2.loss_cls: 3.6982  decode.d2.loss_mask: 1.9671  decode.d2.loss_dice: 3.7332  decode.d3.loss_cls: 3.6448  decode.d3.loss_mask: 2.0208  decode.d3.loss_dice: 3.7495  decode.d4.loss_cls: 3.6856  decode.d4.loss_mask: 2.0464  decode.d4.loss_dice: 3.7987  decode.d5.loss_cls: 3.8362  decode.d5.loss_mask: 2.0711  decode.d5.loss_dice: 3.8980  decode.d6.loss_cls: 4.0073  decode.d6.loss_mask: 2.1487  decode.d6.loss_dice: 4.0436  decode.d7.loss_cls: 4.1110  decode.d7.loss_mask: 2.1774  decode.d7.loss_dice: 4.2759  decode.d8.loss_cls: 4.1316  decode.d8.loss_mask: 2.3205  decode.d8.loss_dice: 4.2836
07/29 22:58:16 - mmengine - INFO - Iter(train) [  100/80000]  base_lr: 9.9889e-05 lr: 9.9889e-06  eta: 12:26:21  time: 0.5277  data_time: 0.0139  memory: 5896  grad_norm: 261.6641  loss: 79.3737  decode.loss_cls: 3.0859  decode.loss_mask: 1.5008  decode.loss_dice: 3.1307  decode.d0.loss_cls: 8.3150  decode.d0.loss_mask: 1.4052  decode.d0.loss_dice: 3.0555  decode.d1.loss_cls: 2.9804  decode.d1.loss_mask: 1.4099  decode.d1.loss_dice: 2.9759  decode.d2.loss_cls: 2.7318  decode.d2.loss_mask: 1.4515  decode.d2.loss_dice: 2.9479  decode.d3.loss_cls: 2.7607  decode.d3.loss_mask: 1.4954  decode.d3.loss_dice: 2.9600  decode.d4.loss_cls: 2.8109  decode.d4.loss_mask: 1.5630  decode.d4.loss_dice: 2.9486  decode.d5.loss_cls: 2.9025  decode.d5.loss_mask: 1.4423  decode.d5.loss_dice: 2.9927  decode.d6.loss_cls: 2.9521  decode.d6.loss_mask: 1.5386  decode.d6.loss_dice: 2.9719  decode.d7.loss_cls: 2.9772  decode.d7.loss_mask: 1.5079  decode.d7.loss_dice: 3.0063  decode.d8.loss_cls: 2.9643  decode.d8.loss_mask: 1.5396  decode.d8.loss_dice: 3.0492
07/29 22:58:43 - mmengine - INFO - Iter(train) [  150/80000]  base_lr: 9.9832e-05 lr: 9.9832e-06  eta: 12:13:54  time: 0.5361  data_time: 0.0133  memory: 5918  grad_norm: 415.0028  loss: 74.3453  decode.loss_cls: 3.0522  decode.loss_mask: 1.4019  decode.loss_dice: 2.9157  decode.d0.loss_cls: 8.1988  decode.d0.loss_mask: 1.2685  decode.d0.loss_dice: 2.8375  decode.d1.loss_cls: 2.7270  decode.d1.loss_mask: 1.2819  decode.d1.loss_dice: 2.7174  decode.d2.loss_cls: 2.5454  decode.d2.loss_mask: 1.3628  decode.d2.loss_dice: 2.6973  decode.d3.loss_cls: 2.4953  decode.d3.loss_mask: 1.3811  decode.d3.loss_dice: 2.6993  decode.d4.loss_cls: 2.6396  decode.d4.loss_mask: 1.4455  decode.d4.loss_dice: 2.6887  decode.d5.loss_cls: 2.6712  decode.d5.loss_mask: 1.4362  decode.d5.loss_dice: 2.7613  decode.d6.loss_cls: 2.7609  decode.d6.loss_mask: 1.3973  decode.d6.loss_dice: 2.7721  decode.d7.loss_cls: 2.9425  decode.d7.loss_mask: 1.3274  decode.d7.loss_dice: 2.7910  decode.d8.loss_cls: 2.9405  decode.d8.loss_mask: 1.4179  decode.d8.loss_dice: 2.7711
07/29 22:59:10 - mmengine - INFO - Iter(train) [  200/80000]  base_lr: 9.9776e-05 lr: 9.9776e-06  eta: 12:08:56  time: 0.5362  data_time: 0.0133  memory: 5916  grad_norm: 303.1180  loss: 61.7630  decode.loss_cls: 2.7836  decode.loss_mask: 1.1234  decode.loss_dice: 1.8468  decode.d0.loss_cls: 7.8892  decode.d0.loss_mask: 1.1536  decode.d0.loss_dice: 2.0545  decode.d1.loss_cls: 2.3248  decode.d1.loss_mask: 1.2471  decode.d1.loss_dice: 1.9280  decode.d2.loss_cls: 2.3224  decode.d2.loss_mask: 1.2392  decode.d2.loss_dice: 1.8928  decode.d3.loss_cls: 2.5479  decode.d3.loss_mask: 1.2813  decode.d3.loss_dice: 1.9192  decode.d4.loss_cls: 2.6005  decode.d4.loss_mask: 1.2077  decode.d4.loss_dice: 1.8667  decode.d5.loss_cls: 2.5694  decode.d5.loss_mask: 1.2471  decode.d5.loss_dice: 1.8305  decode.d6.loss_cls: 2.6531  decode.d6.loss_mask: 1.1521  decode.d6.loss_dice: 1.8078  decode.d7.loss_cls: 2.7330  decode.d7.loss_mask: 1.1394  decode.d7.loss_dice: 1.7565  decode.d8.loss_cls: 2.7772  decode.d8.loss_mask: 1.0783  decode.d8.loss_dice: 1.7899
07/29 22:59:37 - mmengine - INFO - Iter(train) [  250/80000]  base_lr: 9.9720e-05 lr: 9.9720e-06  eta: 12:04:58  time: 0.5337  data_time: 0.0135  memory: 5934  grad_norm: 450.4031  loss: 53.3895  decode.loss_cls: 2.2183  decode.loss_mask: 1.0658  decode.loss_dice: 1.5583  decode.d0.loss_cls: 7.8533  decode.d0.loss_mask: 1.0359  decode.d0.loss_dice: 1.8060  decode.d1.loss_cls: 2.0304  decode.d1.loss_mask: 1.2188  decode.d1.loss_dice: 1.7050  decode.d2.loss_cls: 1.9053  decode.d2.loss_mask: 1.1503  decode.d2.loss_dice: 1.6567  decode.d3.loss_cls: 2.0510  decode.d3.loss_mask: 1.0608  decode.d3.loss_dice: 1.6160  decode.d4.loss_cls: 1.9663  decode.d4.loss_mask: 1.0556  decode.d4.loss_dice: 1.5583  decode.d5.loss_cls: 1.9685  decode.d5.loss_mask: 1.0660  decode.d5.loss_dice: 1.5816  decode.d6.loss_cls: 2.0930  decode.d6.loss_mask: 1.0830  decode.d6.loss_dice: 1.5693  decode.d7.loss_cls: 2.0998  decode.d7.loss_mask: 1.1014  decode.d7.loss_dice: 1.5578  decode.d8.loss_cls: 2.1369  decode.d8.loss_mask: 1.0717  decode.d8.loss_dice: 1.5485
07/29 23:00:03 - mmengine - INFO - Iter(train) [  300/80000]  base_lr: 9.9664e-05 lr: 9.9664e-06  eta: 12:02:06  time: 0.5371  data_time: 0.0138  memory: 5898  grad_norm: 447.7351  loss: 53.6630  decode.loss_cls: 2.5525  decode.loss_mask: 0.9678  decode.loss_dice: 1.3566  decode.d0.loss_cls: 7.6372  decode.d0.loss_mask: 1.0873  decode.d0.loss_dice: 1.7374  decode.d1.loss_cls: 2.3168  decode.d1.loss_mask: 1.1002  decode.d1.loss_dice: 1.4839  decode.d2.loss_cls: 2.3406  decode.d2.loss_mask: 1.0301  decode.d2.loss_dice: 1.4075  decode.d3.loss_cls: 2.3662  decode.d3.loss_mask: 1.0149  decode.d3.loss_dice: 1.4083  decode.d4.loss_cls: 2.3915  decode.d4.loss_mask: 1.0211  decode.d4.loss_dice: 1.3674  decode.d5.loss_cls: 2.4747  decode.d5.loss_mask: 0.9199  decode.d5.loss_dice: 1.2813  decode.d6.loss_cls: 2.4903  decode.d6.loss_mask: 1.0010  decode.d6.loss_dice: 1.3293  decode.d7.loss_cls: 2.5464  decode.d7.loss_mask: 0.9487  decode.d7.loss_dice: 1.2975  decode.d8.loss_cls: 2.4676  decode.d8.loss_mask: 1.0145  decode.d8.loss_dice: 1.3045
07/29 23:00:30 - mmengine - INFO - Iter(train) [  350/80000]  base_lr: 9.9607e-05 lr: 9.9607e-06  eta: 11:59:20  time: 0.5347  data_time: 0.0134  memory: 5897  grad_norm: 510.4919  loss: 55.5394  decode.loss_cls: 2.7543  decode.loss_mask: 0.9235  decode.loss_dice: 1.3289  decode.d0.loss_cls: 7.6366  decode.d0.loss_mask: 1.0167  decode.d0.loss_dice: 1.6752  decode.d1.loss_cls: 2.6760  decode.d1.loss_mask: 0.9557  decode.d1.loss_dice: 1.3856  decode.d2.loss_cls: 2.6485  decode.d2.loss_mask: 0.9765  decode.d2.loss_dice: 1.3823  decode.d3.loss_cls: 2.6644  decode.d3.loss_mask: 0.9964  decode.d3.loss_dice: 1.3654  decode.d4.loss_cls: 2.7187  decode.d4.loss_mask: 0.9045  decode.d4.loss_dice: 1.3909  decode.d5.loss_cls: 2.7462  decode.d5.loss_mask: 0.9210  decode.d5.loss_dice: 1.3574  decode.d6.loss_cls: 2.7027  decode.d6.loss_mask: 0.9422  decode.d6.loss_dice: 1.3299  decode.d7.loss_cls: 2.7850  decode.d7.loss_mask: 0.9248  decode.d7.loss_dice: 1.3879  decode.d8.loss_cls: 2.7174  decode.d8.loss_mask: 0.9547  decode.d8.loss_dice: 1.3701
07/29 23:00:57 - mmengine - INFO - Iter(train) [  400/80000]  base_lr: 9.9551e-05 lr: 9.9551e-06  eta: 11:57:10  time: 0.5333  data_time: 0.0137  memory: 5916  grad_norm: 275.3822  loss: 50.7832  decode.loss_cls: 2.7631  decode.loss_mask: 0.8249  decode.loss_dice: 1.1964  decode.d0.loss_cls: 7.3205  decode.d0.loss_mask: 0.8795  decode.d0.loss_dice: 1.4652  decode.d1.loss_cls: 2.3621  decode.d1.loss_mask: 0.8973  decode.d1.loss_dice: 1.2606  decode.d2.loss_cls: 2.3968  decode.d2.loss_mask: 0.8653  decode.d2.loss_dice: 1.1918  decode.d3.loss_cls: 2.4145  decode.d3.loss_mask: 0.8650  decode.d3.loss_dice: 1.1256  decode.d4.loss_cls: 2.5136  decode.d4.loss_mask: 0.8327  decode.d4.loss_dice: 1.0920  decode.d5.loss_cls: 2.5177  decode.d5.loss_mask: 0.8170  decode.d5.loss_dice: 1.1077  decode.d6.loss_cls: 2.6570  decode.d6.loss_mask: 0.8207  decode.d6.loss_dice: 1.1181  decode.d7.loss_cls: 2.7147  decode.d7.loss_mask: 0.8363  decode.d7.loss_dice: 1.1573  decode.d8.loss_cls: 2.7545  decode.d8.loss_mask: 0.8418  decode.d8.loss_dice: 1.1735
07/29 23:01:23 - mmengine - INFO - Iter(train) [  450/80000]  base_lr: 9.9495e-05 lr: 9.9495e-06  eta: 11:55:10  time: 0.5327  data_time: 0.0134  memory: 5933  grad_norm: 434.9601  loss: 50.3673  decode.loss_cls: 2.7273  decode.loss_mask: 0.8380  decode.loss_dice: 1.1583  decode.d0.loss_cls: 7.2814  decode.d0.loss_mask: 0.9520  decode.d0.loss_dice: 1.5240  decode.d1.loss_cls: 2.4955  decode.d1.loss_mask: 0.8558  decode.d1.loss_dice: 1.1507  decode.d2.loss_cls: 2.5133  decode.d2.loss_mask: 0.8405  decode.d2.loss_dice: 1.0949  decode.d3.loss_cls: 2.4995  decode.d3.loss_mask: 0.8323  decode.d3.loss_dice: 1.0548  decode.d4.loss_cls: 2.4601  decode.d4.loss_mask: 0.8863  decode.d4.loss_dice: 1.1207  decode.d5.loss_cls: 2.5765  decode.d5.loss_mask: 0.8028  decode.d5.loss_dice: 1.1309  decode.d6.loss_cls: 2.5963  decode.d6.loss_mask: 0.7928  decode.d6.loss_dice: 1.0731  decode.d7.loss_cls: 2.6443  decode.d7.loss_mask: 0.7742  decode.d7.loss_dice: 1.0454  decode.d8.loss_cls: 2.6883  decode.d8.loss_mask: 0.8789  decode.d8.loss_dice: 1.0786
07/29 23:01:50 - mmengine - INFO - Iter(train) [  500/80000]  base_lr: 9.9438e-05 lr: 9.9438e-06  eta: 11:53:53  time: 0.5402  data_time: 0.0139  memory: 5918  grad_norm: 332.1237  loss: 49.9947  decode.loss_cls: 2.5763  decode.loss_mask: 0.9758  decode.loss_dice: 1.1746  decode.d0.loss_cls: 7.2353  decode.d0.loss_mask: 0.9032  decode.d0.loss_dice: 1.3995  decode.d1.loss_cls: 2.4922  decode.d1.loss_mask: 0.8748  decode.d1.loss_dice: 1.1945  decode.d2.loss_cls: 2.4730  decode.d2.loss_mask: 0.8827  decode.d2.loss_dice: 1.1275  decode.d3.loss_cls: 2.4428  decode.d3.loss_mask: 0.8831  decode.d3.loss_dice: 1.0824  decode.d4.loss_cls: 2.4683  decode.d4.loss_mask: 0.7827  decode.d4.loss_dice: 1.0030  decode.d5.loss_cls: 2.4561  decode.d5.loss_mask: 0.8202  decode.d5.loss_dice: 1.1183  decode.d6.loss_cls: 2.5479  decode.d6.loss_mask: 0.8075  decode.d6.loss_dice: 1.0799  decode.d7.loss_cls: 2.5578  decode.d7.loss_mask: 0.8934  decode.d7.loss_dice: 1.1121  decode.d8.loss_cls: 2.6233  decode.d8.loss_mask: 0.8873  decode.d8.loss_dice: 1.1190
07/29 23:02:16 - mmengine - INFO - Iter(train) [  550/80000]  base_lr: 9.9382e-05 lr: 9.9382e-06  eta: 11:52:30  time: 0.5331  data_time: 0.0136  memory: 5881  grad_norm: 365.0720  loss: 41.4431  decode.loss_cls: 2.2258  decode.loss_mask: 0.6507  decode.loss_dice: 0.7868  decode.d0.loss_cls: 7.0607  decode.d0.loss_mask: 0.7938  decode.d0.loss_dice: 1.1827  decode.d1.loss_cls: 2.1420  decode.d1.loss_mask: 0.7329  decode.d1.loss_dice: 0.8539  decode.d2.loss_cls: 2.0174  decode.d2.loss_mask: 0.6839  decode.d2.loss_dice: 0.7820  decode.d3.loss_cls: 1.9959  decode.d3.loss_mask: 0.7576  decode.d3.loss_dice: 0.7482  decode.d4.loss_cls: 2.0608  decode.d4.loss_mask: 0.7171  decode.d4.loss_dice: 0.7681  decode.d5.loss_cls: 2.0675  decode.d5.loss_mask: 0.7299  decode.d5.loss_dice: 0.8075  decode.d6.loss_cls: 2.1276  decode.d6.loss_mask: 0.6655  decode.d6.loss_dice: 0.7487  decode.d7.loss_cls: 2.1946  decode.d7.loss_mask: 0.6371  decode.d7.loss_dice: 0.7783  decode.d8.loss_cls: 2.2047  decode.d8.loss_mask: 0.6895  decode.d8.loss_dice: 0.8319
07/29 23:02:43 - mmengine - INFO - Iter(train) [  600/80000]  base_lr: 9.9326e-05 lr: 9.9326e-06  eta: 11:51:21  time: 0.5268  data_time: 0.0129  memory: 5916  grad_norm: 408.8713  loss: 43.7355  decode.loss_cls: 2.4467  decode.loss_mask: 0.6596  decode.loss_dice: 0.8807  decode.d0.loss_cls: 6.9604  decode.d0.loss_mask: 0.6579  decode.d0.loss_dice: 1.2602  decode.d1.loss_cls: 2.4540  decode.d1.loss_mask: 0.6121  decode.d1.loss_dice: 0.9357  decode.d2.loss_cls: 2.3506  decode.d2.loss_mask: 0.6355  decode.d2.loss_dice: 0.8569  decode.d3.loss_cls: 2.3185  decode.d3.loss_mask: 0.5854  decode.d3.loss_dice: 0.8540  decode.d4.loss_cls: 2.3573  decode.d4.loss_mask: 0.5810  decode.d4.loss_dice: 0.8357  decode.d5.loss_cls: 2.3413  decode.d5.loss_mask: 0.6092  decode.d5.loss_dice: 0.8320  decode.d6.loss_cls: 2.3479  decode.d6.loss_mask: 0.6313  decode.d6.loss_dice: 0.8453  decode.d7.loss_cls: 2.4454  decode.d7.loss_mask: 0.6200  decode.d7.loss_dice: 0.8326  decode.d8.loss_cls: 2.4361  decode.d8.loss_mask: 0.6648  decode.d8.loss_dice: 0.8873
07/29 23:03:10 - mmengine - INFO - Iter(train) [  650/80000]  base_lr: 9.9270e-05 lr: 9.9270e-06  eta: 11:50:21  time: 0.5341  data_time: 0.0137  memory: 5897  grad_norm: 409.9087  loss: 38.3639  decode.loss_cls: 2.1093  decode.loss_mask: 0.6999  decode.loss_dice: 0.6657  decode.d0.loss_cls: 6.8752  decode.d0.loss_mask: 0.7196  decode.d0.loss_dice: 1.0091  decode.d1.loss_cls: 2.1381  decode.d1.loss_mask: 0.5678  decode.d1.loss_dice: 0.6174  decode.d2.loss_cls: 1.9210  decode.d2.loss_mask: 0.6075  decode.d2.loss_dice: 0.6627  decode.d3.loss_cls: 1.9197  decode.d3.loss_mask: 0.5456  decode.d3.loss_dice: 0.6538  decode.d4.loss_cls: 1.9837  decode.d4.loss_mask: 0.5665  decode.d4.loss_dice: 0.6459  decode.d5.loss_cls: 1.9455  decode.d5.loss_mask: 0.6515  decode.d5.loss_dice: 0.6457  decode.d6.loss_cls: 2.0085  decode.d6.loss_mask: 0.6623  decode.d6.loss_dice: 0.6495  decode.d7.loss_cls: 2.0835  decode.d7.loss_mask: 0.6650  decode.d7.loss_dice: 0.6475  decode.d8.loss_cls: 2.1475  decode.d8.loss_mask: 0.6723  decode.d8.loss_dice: 0.6764
07/29 23:03:36 - mmengine - INFO - Iter(train) [  700/80000]  base_lr: 9.9213e-05 lr: 9.9213e-06  eta: 11:49:29  time: 0.5298  data_time: 0.0133  memory: 5881  grad_norm: 276.9328  loss: 40.8743  decode.loss_cls: 2.4063  decode.loss_mask: 0.5685  decode.loss_dice: 0.6734  decode.d0.loss_cls: 6.7079  decode.d0.loss_mask: 0.6070  decode.d0.loss_dice: 0.9618  decode.d1.loss_cls: 2.4270  decode.d1.loss_mask: 0.5569  decode.d1.loss_dice: 0.7395  decode.d2.loss_cls: 2.2897  decode.d2.loss_mask: 0.5672  decode.d2.loss_dice: 0.7505  decode.d3.loss_cls: 2.2294  decode.d3.loss_mask: 0.5998  decode.d3.loss_dice: 0.7056  decode.d4.loss_cls: 2.3175  decode.d4.loss_mask: 0.5564  decode.d4.loss_dice: 0.6733  decode.d5.loss_cls: 2.3355  decode.d5.loss_mask: 0.5602  decode.d5.loss_dice: 0.6607  decode.d6.loss_cls: 2.4173  decode.d6.loss_mask: 0.5793  decode.d6.loss_dice: 0.6631  decode.d7.loss_cls: 2.4690  decode.d7.loss_mask: 0.5633  decode.d7.loss_dice: 0.6618  decode.d8.loss_cls: 2.3747  decode.d8.loss_mask: 0.5834  decode.d8.loss_dice: 0.6683
07/29 23:04:03 - mmengine - INFO - Iter(train) [  750/80000]  base_lr: 9.9157e-05 lr: 9.9157e-06  eta: 11:48:13  time: 0.5216  data_time: 0.0128  memory: 5932  grad_norm: 261.4521  loss: 39.1576  decode.loss_cls: 2.3283  decode.loss_mask: 0.4953  decode.loss_dice: 0.6504  decode.d0.loss_cls: 6.6502  decode.d0.loss_mask: 0.5466  decode.d0.loss_dice: 1.0006  decode.d1.loss_cls: 2.3055  decode.d1.loss_mask: 0.5085  decode.d1.loss_dice: 0.6999  decode.d2.loss_cls: 2.2953  decode.d2.loss_mask: 0.5122  decode.d2.loss_dice: 0.6395  decode.d3.loss_cls: 2.1937  decode.d3.loss_mask: 0.4988  decode.d3.loss_dice: 0.6372  decode.d4.loss_cls: 2.2028  decode.d4.loss_mask: 0.5043  decode.d4.loss_dice: 0.6534  decode.d5.loss_cls: 2.1997  decode.d5.loss_mask: 0.5393  decode.d5.loss_dice: 0.6819  decode.d6.loss_cls: 2.2485  decode.d6.loss_mask: 0.5146  decode.d6.loss_dice: 0.6763  decode.d7.loss_cls: 2.3417  decode.d7.loss_mask: 0.4937  decode.d7.loss_dice: 0.6581  decode.d8.loss_cls: 2.3568  decode.d8.loss_mask: 0.4857  decode.d8.loss_dice: 0.6384
07/29 23:04:29 - mmengine - INFO - Iter(train) [  800/80000]  base_lr: 9.9101e-05 lr: 9.9101e-06  eta: 11:47:10  time: 0.5310  data_time: 0.0132  memory: 5916  grad_norm: 261.6988  loss: 38.8493  decode.loss_cls: 2.2904  decode.loss_mask: 0.4537  decode.loss_dice: 0.6534  decode.d0.loss_cls: 6.5692  decode.d0.loss_mask: 0.5728  decode.d0.loss_dice: 0.9977  decode.d1.loss_cls: 2.3599  decode.d1.loss_mask: 0.4689  decode.d1.loss_dice: 0.7050  decode.d2.loss_cls: 2.2435  decode.d2.loss_mask: 0.4877  decode.d2.loss_dice: 0.6827  decode.d3.loss_cls: 2.2399  decode.d3.loss_mask: 0.4609  decode.d3.loss_dice: 0.6408  decode.d4.loss_cls: 2.2596  decode.d4.loss_mask: 0.4610  decode.d4.loss_dice: 0.6729  decode.d5.loss_cls: 2.3100  decode.d5.loss_mask: 0.4573  decode.d5.loss_dice: 0.6668  decode.d6.loss_cls: 2.2724  decode.d6.loss_mask: 0.4680  decode.d6.loss_dice: 0.6504  decode.d7.loss_cls: 2.3282  decode.d7.loss_mask: 0.4687  decode.d7.loss_dice: 0.6600  decode.d8.loss_cls: 2.2473  decode.d8.loss_mask: 0.4545  decode.d8.loss_dice: 0.6457
07/29 23:04:55 - mmengine - INFO - Iter(train) [  850/80000]  base_lr: 9.9044e-05 lr: 9.9044e-06  eta: 11:45:52  time: 0.5265  data_time: 0.0132  memory: 5933  grad_norm: 327.8991  loss: 39.4190  decode.loss_cls: 2.2271  decode.loss_mask: 0.5883  decode.loss_dice: 0.7671  decode.d0.loss_cls: 6.3996  decode.d0.loss_mask: 0.6109  decode.d0.loss_dice: 1.0395  decode.d1.loss_cls: 2.2468  decode.d1.loss_mask: 0.5417  decode.d1.loss_dice: 0.7388  decode.d2.loss_cls: 2.2457  decode.d2.loss_mask: 0.5086  decode.d2.loss_dice: 0.6688  decode.d3.loss_cls: 2.1980  decode.d3.loss_mask: 0.5594  decode.d3.loss_dice: 0.6780  decode.d4.loss_cls: 2.2202  decode.d4.loss_mask: 0.5827  decode.d4.loss_dice: 0.7119  decode.d5.loss_cls: 2.1780  decode.d5.loss_mask: 0.5307  decode.d5.loss_dice: 0.7049  decode.d6.loss_cls: 2.1879  decode.d6.loss_mask: 0.5688  decode.d6.loss_dice: 0.7728  decode.d7.loss_cls: 2.1438  decode.d7.loss_mask: 0.5490  decode.d7.loss_dice: 0.7376  decode.d8.loss_cls: 2.2245  decode.d8.loss_mask: 0.5599  decode.d8.loss_dice: 0.7279
07/29 23:05:21 - mmengine - INFO - Iter(train) [  900/80000]  base_lr: 9.8988e-05 lr: 9.8988e-06  eta: 11:44:42  time: 0.5268  data_time: 0.0133  memory: 5916  grad_norm: 349.6784  loss: 38.1483  decode.loss_cls: 2.2849  decode.loss_mask: 0.5458  decode.loss_dice: 0.6221  decode.d0.loss_cls: 6.2667  decode.d0.loss_mask: 0.6181  decode.d0.loss_dice: 0.9141  decode.d1.loss_cls: 2.3009  decode.d1.loss_mask: 0.5592  decode.d1.loss_dice: 0.6459  decode.d2.loss_cls: 2.2090  decode.d2.loss_mask: 0.5418  decode.d2.loss_dice: 0.6219  decode.d3.loss_cls: 2.1508  decode.d3.loss_mask: 0.5212  decode.d3.loss_dice: 0.6451  decode.d4.loss_cls: 2.1797  decode.d4.loss_mask: 0.5308  decode.d4.loss_dice: 0.6273  decode.d5.loss_cls: 2.1317  decode.d5.loss_mask: 0.4889  decode.d5.loss_dice: 0.6053  decode.d6.loss_cls: 2.1878  decode.d6.loss_mask: 0.5180  decode.d6.loss_dice: 0.6137  decode.d7.loss_cls: 2.2753  decode.d7.loss_mask: 0.5198  decode.d7.loss_dice: 0.6297  decode.d8.loss_cls: 2.2685  decode.d8.loss_mask: 0.5094  decode.d8.loss_dice: 0.6146
07/29 23:05:48 - mmengine - INFO - Iter(train) [  950/80000]  base_lr: 9.8932e-05 lr: 9.8932e-06  eta: 11:43:32  time: 0.5301  data_time: 0.0131  memory: 5896  grad_norm: 332.4097  loss: 33.9206  decode.loss_cls: 1.8984  decode.loss_mask: 0.4814  decode.loss_dice: 0.5379  decode.d0.loss_cls: 5.9996  decode.d0.loss_mask: 0.5926  decode.d0.loss_dice: 0.7880  decode.d1.loss_cls: 2.0176  decode.d1.loss_mask: 0.5285  decode.d1.loss_dice: 0.5859  decode.d2.loss_cls: 1.8905  decode.d2.loss_mask: 0.4716  decode.d2.loss_dice: 0.5408  decode.d3.loss_cls: 1.8088  decode.d3.loss_mask: 0.5203  decode.d3.loss_dice: 0.5378  decode.d4.loss_cls: 1.8348  decode.d4.loss_mask: 0.4955  decode.d4.loss_dice: 0.5609  decode.d5.loss_cls: 1.8527  decode.d5.loss_mask: 0.4860  decode.d5.loss_dice: 0.5907  decode.d6.loss_cls: 1.8578  decode.d6.loss_mask: 0.4900  decode.d6.loss_dice: 0.5817  decode.d7.loss_cls: 1.9231  decode.d7.loss_mask: 0.5102  decode.d7.loss_dice: 0.5882  decode.d8.loss_cls: 1.9497  decode.d8.loss_mask: 0.4769  decode.d8.loss_dice: 0.5230
07/29 23:06:14 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/29 23:06:14 - mmengine - INFO - Iter(train) [ 1000/80000]  base_lr: 9.8875e-05 lr: 9.8875e-06  eta: 11:42:42  time: 0.5335  data_time: 0.0132  memory: 5919  grad_norm: 186.5144  loss: 30.2568  decode.loss_cls: 1.7718  decode.loss_mask: 0.3847  decode.loss_dice: 0.4268  decode.d0.loss_cls: 5.8999  decode.d0.loss_mask: 0.4725  decode.d0.loss_dice: 0.6094  decode.d1.loss_cls: 1.8231  decode.d1.loss_mask: 0.4167  decode.d1.loss_dice: 0.4536  decode.d2.loss_cls: 1.7425  decode.d2.loss_mask: 0.3870  decode.d2.loss_dice: 0.4359  decode.d3.loss_cls: 1.7100  decode.d3.loss_mask: 0.3761  decode.d3.loss_dice: 0.4116  decode.d4.loss_cls: 1.7187  decode.d4.loss_mask: 0.3815  decode.d4.loss_dice: 0.4090  decode.d5.loss_cls: 1.7595  decode.d5.loss_mask: 0.4010  decode.d5.loss_dice: 0.4243  decode.d6.loss_cls: 1.7290  decode.d6.loss_mask: 0.3964  decode.d6.loss_dice: 0.4498  decode.d7.loss_cls: 1.7574  decode.d7.loss_mask: 0.4081  decode.d7.loss_dice: 0.4735  decode.d8.loss_cls: 1.7928  decode.d8.loss_mask: 0.3899  decode.d8.loss_dice: 0.4446
07/29 23:06:40 - mmengine - INFO - Iter(train) [ 1050/80000]  base_lr: 9.8819e-05 lr: 9.8819e-06  eta: 11:41:54  time: 0.5291  data_time: 0.0129  memory: 5918  grad_norm: 322.4876  loss: 36.6531  decode.loss_cls: 2.3104  decode.loss_mask: 0.4835  decode.loss_dice: 0.5794  decode.d0.loss_cls: 5.8237  decode.d0.loss_mask: 0.5724  decode.d0.loss_dice: 0.8076  decode.d1.loss_cls: 2.3278  decode.d1.loss_mask: 0.4775  decode.d1.loss_dice: 0.5656  decode.d2.loss_cls: 2.2023  decode.d2.loss_mask: 0.4447  decode.d2.loss_dice: 0.5350  decode.d3.loss_cls: 2.1301  decode.d3.loss_mask: 0.4732  decode.d3.loss_dice: 0.5436  decode.d4.loss_cls: 2.2336  decode.d4.loss_mask: 0.4590  decode.d4.loss_dice: 0.5510  decode.d5.loss_cls: 2.2313  decode.d5.loss_mask: 0.4678  decode.d5.loss_dice: 0.5971  decode.d6.loss_cls: 2.2800  decode.d6.loss_mask: 0.4494  decode.d6.loss_dice: 0.5279  decode.d7.loss_cls: 2.2552  decode.d7.loss_mask: 0.4561  decode.d7.loss_dice: 0.5442  decode.d8.loss_cls: 2.2453  decode.d8.loss_mask: 0.5057  decode.d8.loss_dice: 0.5729
07/29 23:07:07 - mmengine - INFO - Iter(train) [ 1100/80000]  base_lr: 9.8763e-05 lr: 9.8763e-06  eta: 11:41:11  time: 0.5280  data_time: 0.0127  memory: 5932  grad_norm: 387.3609  loss: 35.1674  decode.loss_cls: 1.9861  decode.loss_mask: 0.4906  decode.loss_dice: 0.6057  decode.d0.loss_cls: 5.6460  decode.d0.loss_mask: 0.5669  decode.d0.loss_dice: 0.8546  decode.d1.loss_cls: 2.0381  decode.d1.loss_mask: 0.6020  decode.d1.loss_dice: 0.6717  decode.d2.loss_cls: 2.0742  decode.d2.loss_mask: 0.5550  decode.d2.loss_dice: 0.6092  decode.d3.loss_cls: 1.9873  decode.d3.loss_mask: 0.5270  decode.d3.loss_dice: 0.5810  decode.d4.loss_cls: 2.0479  decode.d4.loss_mask: 0.4825  decode.d4.loss_dice: 0.5413  decode.d5.loss_cls: 2.0125  decode.d5.loss_mask: 0.5040  decode.d5.loss_dice: 0.5749  decode.d6.loss_cls: 1.9547  decode.d6.loss_mask: 0.4890  decode.d6.loss_dice: 0.6074  decode.d7.loss_cls: 1.9504  decode.d7.loss_mask: 0.5050  decode.d7.loss_dice: 0.6144  decode.d8.loss_cls: 1.9784  decode.d8.loss_mask: 0.4921  decode.d8.loss_dice: 0.6175
07/29 23:07:34 - mmengine - INFO - Iter(train) [ 1150/80000]  base_lr: 9.8706e-05 lr: 9.8706e-06  eta: 11:40:39  time: 0.5297  data_time: 0.0134  memory: 5899  grad_norm: 624.6925  loss: 34.3897  decode.loss_cls: 1.7849  decode.loss_mask: 0.5175  decode.loss_dice: 0.6287  decode.d0.loss_cls: 5.6421  decode.d0.loss_mask: 0.5334  decode.d0.loss_dice: 0.8467  decode.d1.loss_cls: 2.2209  decode.d1.loss_mask: 0.4960  decode.d1.loss_dice: 0.6220  decode.d2.loss_cls: 1.9123  decode.d2.loss_mask: 0.5215  decode.d2.loss_dice: 0.5989  decode.d3.loss_cls: 1.8772  decode.d3.loss_mask: 0.4909  decode.d3.loss_dice: 0.6011  decode.d4.loss_cls: 1.8518  decode.d4.loss_mask: 0.5021  decode.d4.loss_dice: 0.5970  decode.d5.loss_cls: 1.9462  decode.d5.loss_mask: 0.5844  decode.d5.loss_dice: 0.5838  decode.d6.loss_cls: 1.9671  decode.d6.loss_mask: 0.4980  decode.d6.loss_dice: 0.6027  decode.d7.loss_cls: 1.8053  decode.d7.loss_mask: 0.5092  decode.d7.loss_dice: 0.6264  decode.d8.loss_cls: 1.8377  decode.d8.loss_mask: 0.5664  decode.d8.loss_dice: 0.6174
07/29 23:08:00 - mmengine - INFO - Iter(train) [ 1200/80000]  base_lr: 9.8650e-05 lr: 9.8650e-06  eta: 11:40:21  time: 0.5314  data_time: 0.0129  memory: 5973  grad_norm: 191.7652  loss: 30.5240  decode.loss_cls: 1.8936  decode.loss_mask: 0.3803  decode.loss_dice: 0.3727  decode.d0.loss_cls: 5.4136  decode.d0.loss_mask: 0.4971  decode.d0.loss_dice: 0.6125  decode.d1.loss_cls: 2.0142  decode.d1.loss_mask: 0.3948  decode.d1.loss_dice: 0.4233  decode.d2.loss_cls: 1.8690  decode.d2.loss_mask: 0.4116  decode.d2.loss_dice: 0.4011  decode.d3.loss_cls: 1.7560  decode.d3.loss_mask: 0.4120  decode.d3.loss_dice: 0.4042  decode.d4.loss_cls: 1.8162  decode.d4.loss_mask: 0.3856  decode.d4.loss_dice: 0.3993  decode.d5.loss_cls: 1.8707  decode.d5.loss_mask: 0.3851  decode.d5.loss_dice: 0.4049  decode.d6.loss_cls: 1.8972  decode.d6.loss_mask: 0.3680  decode.d6.loss_dice: 0.3894  decode.d7.loss_cls: 1.9381  decode.d7.loss_mask: 0.3814  decode.d7.loss_dice: 0.3828  decode.d8.loss_cls: 1.8966  decode.d8.loss_mask: 0.3771  decode.d8.loss_dice: 0.3755
07/29 23:08:27 - mmengine - INFO - Iter(train) [ 1250/80000]  base_lr: 9.8594e-05 lr: 9.8594e-06  eta: 11:39:41  time: 0.5293  data_time: 0.0133  memory: 5918  grad_norm: 288.8755  loss: 32.6053  decode.loss_cls: 1.8406  decode.loss_mask: 0.5298  decode.loss_dice: 0.5046  decode.d0.loss_cls: 5.3478  decode.d0.loss_mask: 0.5965  decode.d0.loss_dice: 0.7336  decode.d1.loss_cls: 2.0810  decode.d1.loss_mask: 0.4882  decode.d1.loss_dice: 0.4823  decode.d2.loss_cls: 1.8317  decode.d2.loss_mask: 0.5234  decode.d2.loss_dice: 0.4787  decode.d3.loss_cls: 1.7943  decode.d3.loss_mask: 0.5784  decode.d3.loss_dice: 0.4795  decode.d4.loss_cls: 1.8272  decode.d4.loss_mask: 0.5821  decode.d4.loss_dice: 0.4961  decode.d5.loss_cls: 1.8431  decode.d5.loss_mask: 0.5389  decode.d5.loss_dice: 0.4965  decode.d6.loss_cls: 1.8170  decode.d6.loss_mask: 0.5135  decode.d6.loss_dice: 0.5003  decode.d7.loss_cls: 1.9240  decode.d7.loss_mask: 0.4595  decode.d7.loss_dice: 0.4953  decode.d8.loss_cls: 1.8902  decode.d8.loss_mask: 0.4602  decode.d8.loss_dice: 0.4712
07/29 23:08:53 - mmengine - INFO - Iter(train) [ 1300/80000]  base_lr: 9.8537e-05 lr: 9.8537e-06  eta: 11:39:00  time: 0.5264  data_time: 0.0128  memory: 5931  grad_norm: 306.2938  loss: 35.0231  decode.loss_cls: 2.1941  decode.loss_mask: 0.5160  decode.loss_dice: 0.5126  decode.d0.loss_cls: 5.2801  decode.d0.loss_mask: 0.5597  decode.d0.loss_dice: 0.7301  decode.d1.loss_cls: 2.3518  decode.d1.loss_mask: 0.5396  decode.d1.loss_dice: 0.4985  decode.d2.loss_cls: 2.1746  decode.d2.loss_mask: 0.5304  decode.d2.loss_dice: 0.4660  decode.d3.loss_cls: 2.0894  decode.d3.loss_mask: 0.4978  decode.d3.loss_dice: 0.4492  decode.d4.loss_cls: 2.1286  decode.d4.loss_mask: 0.5178  decode.d4.loss_dice: 0.4691  decode.d5.loss_cls: 2.1075  decode.d5.loss_mask: 0.5066  decode.d5.loss_dice: 0.4739  decode.d6.loss_cls: 2.0996  decode.d6.loss_mask: 0.4846  decode.d6.loss_dice: 0.4473  decode.d7.loss_cls: 2.2019  decode.d7.loss_mask: 0.4911  decode.d7.loss_dice: 0.4920  decode.d8.loss_cls: 2.2269  decode.d8.loss_mask: 0.4864  decode.d8.loss_dice: 0.5000
07/29 23:09:20 - mmengine - INFO - Iter(train) [ 1350/80000]  base_lr: 9.8481e-05 lr: 9.8481e-06  eta: 11:38:27  time: 0.5277  data_time: 0.0132  memory: 5934  grad_norm: 300.9450  loss: 30.4003  decode.loss_cls: 1.7345  decode.loss_mask: 0.4919  decode.loss_dice: 0.5214  decode.d0.loss_cls: 5.0312  decode.d0.loss_mask: 0.4613  decode.d0.loss_dice: 0.6458  decode.d1.loss_cls: 1.8333  decode.d1.loss_mask: 0.4706  decode.d1.loss_dice: 0.4944  decode.d2.loss_cls: 1.7089  decode.d2.loss_mask: 0.4466  decode.d2.loss_dice: 0.4827  decode.d3.loss_cls: 1.6508  decode.d3.loss_mask: 0.4620  decode.d3.loss_dice: 0.4942  decode.d4.loss_cls: 1.7156  decode.d4.loss_mask: 0.4591  decode.d4.loss_dice: 0.4960  decode.d5.loss_cls: 1.6379  decode.d5.loss_mask: 0.4956  decode.d5.loss_dice: 0.5213  decode.d6.loss_cls: 1.6695  decode.d6.loss_mask: 0.4786  decode.d6.loss_dice: 0.5205  decode.d7.loss_cls: 1.7380  decode.d7.loss_mask: 0.4560  decode.d7.loss_dice: 0.5214  decode.d8.loss_cls: 1.7224  decode.d8.loss_mask: 0.5014  decode.d8.loss_dice: 0.5374
07/29 23:09:46 - mmengine - INFO - Iter(train) [ 1400/80000]  base_lr: 9.8425e-05 lr: 9.8425e-06  eta: 11:37:56  time: 0.5309  data_time: 0.0133  memory: 5933  grad_norm: 339.9252  loss: 31.6956  decode.loss_cls: 1.9185  decode.loss_mask: 0.4573  decode.loss_dice: 0.4960  decode.d0.loss_cls: 4.9074  decode.d0.loss_mask: 0.5087  decode.d0.loss_dice: 0.6382  decode.d1.loss_cls: 2.0308  decode.d1.loss_mask: 0.4668  decode.d1.loss_dice: 0.5055  decode.d2.loss_cls: 1.9033  decode.d2.loss_mask: 0.4259  decode.d2.loss_dice: 0.4657  decode.d3.loss_cls: 1.9099  decode.d3.loss_mask: 0.4468  decode.d3.loss_dice: 0.4833  decode.d4.loss_cls: 1.8642  decode.d4.loss_mask: 0.4623  decode.d4.loss_dice: 0.4852  decode.d5.loss_cls: 1.8799  decode.d5.loss_mask: 0.4911  decode.d5.loss_dice: 0.4928  decode.d6.loss_cls: 1.8668  decode.d6.loss_mask: 0.4611  decode.d6.loss_dice: 0.4672  decode.d7.loss_cls: 1.9282  decode.d7.loss_mask: 0.4714  decode.d7.loss_dice: 0.4664  decode.d8.loss_cls: 1.8597  decode.d8.loss_mask: 0.4454  decode.d8.loss_dice: 0.4897
07/29 23:10:13 - mmengine - INFO - Iter(train) [ 1450/80000]  base_lr: 9.8368e-05 lr: 9.8368e-06  eta: 11:37:16  time: 0.5316  data_time: 0.0136  memory: 5934  grad_norm: 270.2286  loss: 33.8509  decode.loss_cls: 2.0302  decode.loss_mask: 0.5262  decode.loss_dice: 0.5167  decode.d0.loss_cls: 4.9042  decode.d0.loss_mask: 0.5398  decode.d0.loss_dice: 0.7403  decode.d1.loss_cls: 2.1471  decode.d1.loss_mask: 0.5034  decode.d1.loss_dice: 0.5279  decode.d2.loss_cls: 1.9345  decode.d2.loss_mask: 0.5269  decode.d2.loss_dice: 0.4995  decode.d3.loss_cls: 1.9974  decode.d3.loss_mask: 0.5124  decode.d3.loss_dice: 0.5108  decode.d4.loss_cls: 1.9433  decode.d4.loss_mask: 0.4825  decode.d4.loss_dice: 0.4891  decode.d5.loss_cls: 2.0453  decode.d5.loss_mask: 0.5135  decode.d5.loss_dice: 0.5109  decode.d6.loss_cls: 2.0786  decode.d6.loss_mask: 0.4914  decode.d6.loss_dice: 0.5092  decode.d7.loss_cls: 2.1345  decode.d7.loss_mask: 0.5049  decode.d7.loss_dice: 0.5429  decode.d8.loss_cls: 2.2113  decode.d8.loss_mask: 0.4619  decode.d8.loss_dice: 0.5144
07/29 23:10:39 - mmengine - INFO - Iter(train) [ 1500/80000]  base_lr: 9.8312e-05 lr: 9.8312e-06  eta: 11:36:57  time: 0.5390  data_time: 0.0135  memory: 5898  grad_norm: 244.9925  loss: 29.0916  decode.loss_cls: 1.6702  decode.loss_mask: 0.4898  decode.loss_dice: 0.4740  decode.d0.loss_cls: 4.5961  decode.d0.loss_mask: 0.4621  decode.d0.loss_dice: 0.6985  decode.d1.loss_cls: 1.9946  decode.d1.loss_mask: 0.3947  decode.d1.loss_dice: 0.4631  decode.d2.loss_cls: 1.6221  decode.d2.loss_mask: 0.4532  decode.d2.loss_dice: 0.4705  decode.d3.loss_cls: 1.6813  decode.d3.loss_mask: 0.4144  decode.d3.loss_dice: 0.4584  decode.d4.loss_cls: 1.6290  decode.d4.loss_mask: 0.4052  decode.d4.loss_dice: 0.4556  decode.d5.loss_cls: 1.6339  decode.d5.loss_mask: 0.4508  decode.d5.loss_dice: 0.4693  decode.d6.loss_cls: 1.5494  decode.d6.loss_mask: 0.4724  decode.d6.loss_dice: 0.4555  decode.d7.loss_cls: 1.6938  decode.d7.loss_mask: 0.4433  decode.d7.loss_dice: 0.4855  decode.d8.loss_cls: 1.7917  decode.d8.loss_mask: 0.3835  decode.d8.loss_dice: 0.4298
07/29 23:11:06 - mmengine - INFO - Iter(train) [ 1550/80000]  base_lr: 9.8256e-05 lr: 9.8256e-06  eta: 11:36:32  time: 0.5333  data_time: 0.0135  memory: 5916  grad_norm: 249.2580  loss: 31.4856  decode.loss_cls: 1.8118  decode.loss_mask: 0.4508  decode.loss_dice: 0.5551  decode.d0.loss_cls: 4.5975  decode.d0.loss_mask: 0.4907  decode.d0.loss_dice: 0.7792  decode.d1.loss_cls: 2.0743  decode.d1.loss_mask: 0.4360  decode.d1.loss_dice: 0.6185  decode.d2.loss_cls: 1.9350  decode.d2.loss_mask: 0.3939  decode.d2.loss_dice: 0.5575  decode.d3.loss_cls: 1.8896  decode.d3.loss_mask: 0.4092  decode.d3.loss_dice: 0.5445  decode.d4.loss_cls: 1.8236  decode.d4.loss_mask: 0.4196  decode.d4.loss_dice: 0.5748  decode.d5.loss_cls: 1.8163  decode.d5.loss_mask: 0.4284  decode.d5.loss_dice: 0.5610  decode.d6.loss_cls: 1.8175  decode.d6.loss_mask: 0.4313  decode.d6.loss_dice: 0.5539  decode.d7.loss_cls: 1.8673  decode.d7.loss_mask: 0.3990  decode.d7.loss_dice: 0.5314  decode.d8.loss_cls: 1.7905  decode.d8.loss_mask: 0.4064  decode.d8.loss_dice: 0.5211
07/29 23:11:33 - mmengine - INFO - Iter(train) [ 1600/80000]  base_lr: 9.8199e-05 lr: 9.8199e-06  eta: 11:36:05  time: 0.5337  data_time: 0.0134  memory: 5879  grad_norm: 159.2039  loss: 25.9294  decode.loss_cls: 1.5692  decode.loss_mask: 0.2793  decode.loss_dice: 0.3736  decode.d0.loss_cls: 4.3592  decode.d0.loss_mask: 0.2975  decode.d0.loss_dice: 0.5400  decode.d1.loss_cls: 1.8470  decode.d1.loss_mask: 0.2816  decode.d1.loss_dice: 0.4145  decode.d2.loss_cls: 1.6581  decode.d2.loss_mask: 0.2796  decode.d2.loss_dice: 0.4375  decode.d3.loss_cls: 1.6751  decode.d3.loss_mask: 0.2699  decode.d3.loss_dice: 0.4130  decode.d4.loss_cls: 1.6384  decode.d4.loss_mask: 0.2687  decode.d4.loss_dice: 0.3951  decode.d5.loss_cls: 1.5107  decode.d5.loss_mask: 0.2777  decode.d5.loss_dice: 0.4021  decode.d6.loss_cls: 1.4631  decode.d6.loss_mask: 0.2814  decode.d6.loss_dice: 0.4289  decode.d7.loss_cls: 1.5978  decode.d7.loss_mask: 0.2829  decode.d7.loss_dice: 0.3951  decode.d8.loss_cls: 1.6044  decode.d8.loss_mask: 0.2846  decode.d8.loss_dice: 0.4032
07/29 23:12:00 - mmengine - INFO - Iter(train) [ 1650/80000]  base_lr: 9.8143e-05 lr: 9.8143e-06  eta: 11:35:45  time: 0.5365  data_time: 0.0141  memory: 5931  grad_norm: 304.7121  loss: 31.9916  decode.loss_cls: 1.9773  decode.loss_mask: 0.4328  decode.loss_dice: 0.5222  decode.d0.loss_cls: 4.3204  decode.d0.loss_mask: 0.4935  decode.d0.loss_dice: 0.6849  decode.d1.loss_cls: 2.0926  decode.d1.loss_mask: 0.4536  decode.d1.loss_dice: 0.5566  decode.d2.loss_cls: 1.9458  decode.d2.loss_mask: 0.3916  decode.d2.loss_dice: 0.5220  decode.d3.loss_cls: 1.9552  decode.d3.loss_mask: 0.4226  decode.d3.loss_dice: 0.5098  decode.d4.loss_cls: 1.9585  decode.d4.loss_mask: 0.4476  decode.d4.loss_dice: 0.5601  decode.d5.loss_cls: 1.8568  decode.d5.loss_mask: 0.5188  decode.d5.loss_dice: 0.5948  decode.d6.loss_cls: 1.7432  decode.d6.loss_mask: 0.5854  decode.d6.loss_dice: 0.5779  decode.d7.loss_cls: 1.9124  decode.d7.loss_mask: 0.4784  decode.d7.loss_dice: 0.5584  decode.d8.loss_cls: 1.9641  decode.d8.loss_mask: 0.4235  decode.d8.loss_dice: 0.5307
07/29 23:12:26 - mmengine - INFO - Iter(train) [ 1700/80000]  base_lr: 9.8087e-05 lr: 9.8087e-06  eta: 11:35:21  time: 0.5305  data_time: 0.0132  memory: 5897  grad_norm: 319.2275  loss: 25.4469  decode.loss_cls: 1.3314  decode.loss_mask: 0.4462  decode.loss_dice: 0.4418  decode.d0.loss_cls: 4.0626  decode.d0.loss_mask: 0.5208  decode.d0.loss_dice: 0.6237  decode.d1.loss_cls: 1.6893  decode.d1.loss_mask: 0.4178  decode.d1.loss_dice: 0.4229  decode.d2.loss_cls: 1.3954  decode.d2.loss_mask: 0.4263  decode.d2.loss_dice: 0.4148  decode.d3.loss_cls: 1.3894  decode.d3.loss_mask: 0.4294  decode.d3.loss_dice: 0.3996  decode.d4.loss_cls: 1.3752  decode.d4.loss_mask: 0.4288  decode.d4.loss_dice: 0.3984  decode.d5.loss_cls: 1.3417  decode.d5.loss_mask: 0.4559  decode.d5.loss_dice: 0.4195  decode.d6.loss_cls: 1.2941  decode.d6.loss_mask: 0.4432  decode.d6.loss_dice: 0.4158  decode.d7.loss_cls: 1.3555  decode.d7.loss_mask: 0.4501  decode.d7.loss_dice: 0.4135  decode.d8.loss_cls: 1.3499  decode.d8.loss_mask: 0.4541  decode.d8.loss_dice: 0.4397
07/29 23:12:53 - mmengine - INFO - Iter(train) [ 1750/80000]  base_lr: 9.8030e-05 lr: 9.8030e-06  eta: 11:34:49  time: 0.5290  data_time: 0.0131  memory: 5916  grad_norm: 198.8456  loss: 26.6663  decode.loss_cls: 1.6111  decode.loss_mask: 0.3269  decode.loss_dice: 0.4500  decode.d0.loss_cls: 3.9514  decode.d0.loss_mask: 0.3722  decode.d0.loss_dice: 0.5648  decode.d1.loss_cls: 1.9248  decode.d1.loss_mask: 0.3108  decode.d1.loss_dice: 0.4242  decode.d2.loss_cls: 1.6908  decode.d2.loss_mask: 0.3049  decode.d2.loss_dice: 0.4117  decode.d3.loss_cls: 1.6697  decode.d3.loss_mask: 0.2940  decode.d3.loss_dice: 0.4146  decode.d4.loss_cls: 1.6111  decode.d4.loss_mask: 0.3079  decode.d4.loss_dice: 0.4433  decode.d5.loss_cls: 1.6049  decode.d5.loss_mask: 0.3336  decode.d5.loss_dice: 0.4451  decode.d6.loss_cls: 1.6238  decode.d6.loss_mask: 0.3239  decode.d6.loss_dice: 0.4326  decode.d7.loss_cls: 1.6472  decode.d7.loss_mask: 0.3215  decode.d7.loss_dice: 0.4375  decode.d8.loss_cls: 1.6249  decode.d8.loss_mask: 0.3253  decode.d8.loss_dice: 0.4619
07/29 23:13:19 - mmengine - INFO - Iter(train) [ 1800/80000]  base_lr: 9.7974e-05 lr: 9.7974e-06  eta: 11:34:08  time: 0.5239  data_time: 0.0127  memory: 5895  grad_norm: 277.3731  loss: 26.6768  decode.loss_cls: 1.4864  decode.loss_mask: 0.4886  decode.loss_dice: 0.4040  decode.d0.loss_cls: 3.7952  decode.d0.loss_mask: 0.5901  decode.d0.loss_dice: 0.5726  decode.d1.loss_cls: 1.6363  decode.d1.loss_mask: 0.4709  decode.d1.loss_dice: 0.4332  decode.d2.loss_cls: 1.6030  decode.d2.loss_mask: 0.4408  decode.d2.loss_dice: 0.4092  decode.d3.loss_cls: 1.4976  decode.d3.loss_mask: 0.4846  decode.d3.loss_dice: 0.4120  decode.d4.loss_cls: 1.5138  decode.d4.loss_mask: 0.4981  decode.d4.loss_dice: 0.4327  decode.d5.loss_cls: 1.5002  decode.d5.loss_mask: 0.4774  decode.d5.loss_dice: 0.4192  decode.d6.loss_cls: 1.4405  decode.d6.loss_mask: 0.4498  decode.d6.loss_dice: 0.4037  decode.d7.loss_cls: 1.4428  decode.d7.loss_mask: 0.5177  decode.d7.loss_dice: 0.4528  decode.d8.loss_cls: 1.5155  decode.d8.loss_mask: 0.4841  decode.d8.loss_dice: 0.4038
07/29 23:13:45 - mmengine - INFO - Iter(train) [ 1850/80000]  base_lr: 9.7917e-05 lr: 9.7917e-06  eta: 11:33:31  time: 0.5295  data_time: 0.0131  memory: 5898  grad_norm: 181.4252  loss: 23.6067  decode.loss_cls: 1.3294  decode.loss_mask: 0.3694  decode.loss_dice: 0.3894  decode.d0.loss_cls: 3.5994  decode.d0.loss_mask: 0.3780  decode.d0.loss_dice: 0.5304  decode.d1.loss_cls: 1.5723  decode.d1.loss_mask: 0.4097  decode.d1.loss_dice: 0.4153  decode.d2.loss_cls: 1.3137  decode.d2.loss_mask: 0.3876  decode.d2.loss_dice: 0.3906  decode.d3.loss_cls: 1.3527  decode.d3.loss_mask: 0.3725  decode.d3.loss_dice: 0.4003  decode.d4.loss_cls: 1.3083  decode.d4.loss_mask: 0.3765  decode.d4.loss_dice: 0.3925  decode.d5.loss_cls: 1.2559  decode.d5.loss_mask: 0.3700  decode.d5.loss_dice: 0.3911  decode.d6.loss_cls: 1.2628  decode.d6.loss_mask: 0.3756  decode.d6.loss_dice: 0.3957  decode.d7.loss_cls: 1.3523  decode.d7.loss_mask: 0.3631  decode.d7.loss_dice: 0.4028  decode.d8.loss_cls: 1.3706  decode.d8.loss_mask: 0.3798  decode.d8.loss_dice: 0.3990
07/29 23:14:12 - mmengine - INFO - Iter(train) [ 1900/80000]  base_lr: 9.7861e-05 lr: 9.7861e-06  eta: 11:33:05  time: 0.5331  data_time: 0.0135  memory: 5896  grad_norm: 156.3929  loss: 23.7835  decode.loss_cls: 1.4101  decode.loss_mask: 0.3882  decode.loss_dice: 0.4052  decode.d0.loss_cls: 3.5577  decode.d0.loss_mask: 0.4479  decode.d0.loss_dice: 0.5346  decode.d1.loss_cls: 1.5697  decode.d1.loss_mask: 0.4328  decode.d1.loss_dice: 0.4293  decode.d2.loss_cls: 1.2726  decode.d2.loss_mask: 0.3958  decode.d2.loss_dice: 0.4005  decode.d3.loss_cls: 1.2551  decode.d3.loss_mask: 0.3823  decode.d3.loss_dice: 0.3769  decode.d4.loss_cls: 1.3184  decode.d4.loss_mask: 0.3974  decode.d4.loss_dice: 0.4027  decode.d5.loss_cls: 1.3020  decode.d5.loss_mask: 0.4277  decode.d5.loss_dice: 0.4111  decode.d6.loss_cls: 1.1916  decode.d6.loss_mask: 0.4169  decode.d6.loss_dice: 0.4178  decode.d7.loss_cls: 1.2646  decode.d7.loss_mask: 0.4135  decode.d7.loss_dice: 0.4433  decode.d8.loss_cls: 1.3458  decode.d8.loss_mask: 0.3915  decode.d8.loss_dice: 0.3803
07/29 23:14:39 - mmengine - INFO - Iter(train) [ 1950/80000]  base_lr: 9.7805e-05 lr: 9.7805e-06  eta: 11:32:43  time: 0.5335  data_time: 0.0134  memory: 5896  grad_norm: 153.6762  loss: 24.2397  decode.loss_cls: 1.3756  decode.loss_mask: 0.3706  decode.loss_dice: 0.3960  decode.d0.loss_cls: 3.5113  decode.d0.loss_mask: 0.4338  decode.d0.loss_dice: 0.5108  decode.d1.loss_cls: 1.7326  decode.d1.loss_mask: 0.3747  decode.d1.loss_dice: 0.4320  decode.d2.loss_cls: 1.4997  decode.d2.loss_mask: 0.3426  decode.d2.loss_dice: 0.3811  decode.d3.loss_cls: 1.4428  decode.d3.loss_mask: 0.3520  decode.d3.loss_dice: 0.3932  decode.d4.loss_cls: 1.4337  decode.d4.loss_mask: 0.3443  decode.d4.loss_dice: 0.3897  decode.d5.loss_cls: 1.3922  decode.d5.loss_mask: 0.3415  decode.d5.loss_dice: 0.3921  decode.d6.loss_cls: 1.3788  decode.d6.loss_mask: 0.3457  decode.d6.loss_dice: 0.3711  decode.d7.loss_cls: 1.3481  decode.d7.loss_mask: 0.3639  decode.d7.loss_dice: 0.4014  decode.d8.loss_cls: 1.4356  decode.d8.loss_mask: 0.3602  decode.d8.loss_dice: 0.3926
07/29 23:15:05 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/29 23:15:05 - mmengine - INFO - Iter(train) [ 2000/80000]  base_lr: 9.7748e-05 lr: 9.7748e-06  eta: 11:32:17  time: 0.5334  data_time: 0.0136  memory: 5920  grad_norm: 382.6934  loss: 22.4970  decode.loss_cls: 1.1463  decode.loss_mask: 0.4906  decode.loss_dice: 0.4062  decode.d0.loss_cls: 3.1800  decode.d0.loss_mask: 0.5135  decode.d0.loss_dice: 0.4712  decode.d1.loss_cls: 1.3866  decode.d1.loss_mask: 0.4966  decode.d1.loss_dice: 0.3921  decode.d2.loss_cls: 1.2852  decode.d2.loss_mask: 0.4475  decode.d2.loss_dice: 0.3758  decode.d3.loss_cls: 1.1543  decode.d3.loss_mask: 0.4394  decode.d3.loss_dice: 0.3735  decode.d4.loss_cls: 1.1503  decode.d4.loss_mask: 0.4566  decode.d4.loss_dice: 0.3986  decode.d5.loss_cls: 1.0876  decode.d5.loss_mask: 0.4651  decode.d5.loss_dice: 0.4241  decode.d6.loss_cls: 1.1225  decode.d6.loss_mask: 0.4535  decode.d6.loss_dice: 0.3869  decode.d7.loss_cls: 1.1289  decode.d7.loss_mask: 0.4494  decode.d7.loss_dice: 0.4159  decode.d8.loss_cls: 1.1008  decode.d8.loss_mask: 0.4655  decode.d8.loss_dice: 0.4324
07/29 23:15:32 - mmengine - INFO - Iter(train) [ 2050/80000]  base_lr: 9.7692e-05 lr: 9.7692e-06  eta: 11:31:45  time: 0.5306  data_time: 0.0133  memory: 5897  grad_norm: 226.6742  loss: 26.6166  decode.loss_cls: 1.5345  decode.loss_mask: 0.4136  decode.loss_dice: 0.5080  decode.d0.loss_cls: 3.3291  decode.d0.loss_mask: 0.5105  decode.d0.loss_dice: 0.7047  decode.d1.loss_cls: 1.7514  decode.d1.loss_mask: 0.4018  decode.d1.loss_dice: 0.5312  decode.d2.loss_cls: 1.5232  decode.d2.loss_mask: 0.3826  decode.d2.loss_dice: 0.5289  decode.d3.loss_cls: 1.5437  decode.d3.loss_mask: 0.3771  decode.d3.loss_dice: 0.4884  decode.d4.loss_cls: 1.5344  decode.d4.loss_mask: 0.3918  decode.d4.loss_dice: 0.5217  decode.d5.loss_cls: 1.5474  decode.d5.loss_mask: 0.3895  decode.d5.loss_dice: 0.5202  decode.d6.loss_cls: 1.5414  decode.d6.loss_mask: 0.3749  decode.d6.loss_dice: 0.5065  decode.d7.loss_cls: 1.4847  decode.d7.loss_mask: 0.3828  decode.d7.loss_dice: 0.5281  decode.d8.loss_cls: 1.4913  decode.d8.loss_mask: 0.3932  decode.d8.loss_dice: 0.4799
07/29 23:15:59 - mmengine - INFO - Iter(train) [ 2100/80000]  base_lr: 9.7635e-05 lr: 9.7635e-06  eta: 11:31:17  time: 0.5228  data_time: 0.0125  memory: 5920  grad_norm: 226.1390  loss: 21.8256  decode.loss_cls: 1.0567  decode.loss_mask: 0.4600  decode.loss_dice: 0.4010  decode.d0.loss_cls: 3.1362  decode.d0.loss_mask: 0.4040  decode.d0.loss_dice: 0.4954  decode.d1.loss_cls: 1.4508  decode.d1.loss_mask: 0.3627  decode.d1.loss_dice: 0.3949  decode.d2.loss_cls: 1.2139  decode.d2.loss_mask: 0.3789  decode.d2.loss_dice: 0.4193  decode.d3.loss_cls: 1.1857  decode.d3.loss_mask: 0.3578  decode.d3.loss_dice: 0.3884  decode.d4.loss_cls: 1.1000  decode.d4.loss_mask: 0.3785  decode.d4.loss_dice: 0.4075  decode.d5.loss_cls: 1.1329  decode.d5.loss_mask: 0.3917  decode.d5.loss_dice: 0.3917  decode.d6.loss_cls: 1.1216  decode.d6.loss_mask: 0.4074  decode.d6.loss_dice: 0.3990  decode.d7.loss_cls: 1.0881  decode.d7.loss_mask: 0.4437  decode.d7.loss_dice: 0.4401  decode.d8.loss_cls: 1.1195  decode.d8.loss_mask: 0.4581  decode.d8.loss_dice: 0.4402
07/29 23:16:25 - mmengine - INFO - Iter(train) [ 2150/80000]  base_lr: 9.7579e-05 lr: 9.7579e-06  eta: 11:30:37  time: 0.5177  data_time: 0.0122  memory: 5916  grad_norm: 238.7792  loss: 22.0812  decode.loss_cls: 1.2400  decode.loss_mask: 0.3009  decode.loss_dice: 0.3915  decode.d0.loss_cls: 3.0274  decode.d0.loss_mask: 0.3258  decode.d0.loss_dice: 0.5119  decode.d1.loss_cls: 1.5364  decode.d1.loss_mask: 0.3410  decode.d1.loss_dice: 0.4422  decode.d2.loss_cls: 1.3300  decode.d2.loss_mask: 0.3158  decode.d2.loss_dice: 0.4279  decode.d3.loss_cls: 1.2693  decode.d3.loss_mask: 0.3126  decode.d3.loss_dice: 0.3760  decode.d4.loss_cls: 1.2513  decode.d4.loss_mask: 0.3255  decode.d4.loss_dice: 0.3932  decode.d5.loss_cls: 1.2273  decode.d5.loss_mask: 0.3131  decode.d5.loss_dice: 0.4155  decode.d6.loss_cls: 1.2744  decode.d6.loss_mask: 0.3107  decode.d6.loss_dice: 0.3891  decode.d7.loss_cls: 1.2641  decode.d7.loss_mask: 0.3153  decode.d7.loss_dice: 0.4240  decode.d8.loss_cls: 1.2692  decode.d8.loss_mask: 0.3252  decode.d8.loss_dice: 0.4347
07/29 23:16:51 - mmengine - INFO - Iter(train) [ 2200/80000]  base_lr: 9.7523e-05 lr: 9.7523e-06  eta: 11:29:59  time: 0.5243  data_time: 0.0130  memory: 5897  grad_norm: 494.2508  loss: 23.2495  decode.loss_cls: 1.2879  decode.loss_mask: 0.4687  decode.loss_dice: 0.5271  decode.d0.loss_cls: 2.8948  decode.d0.loss_mask: 0.3894  decode.d0.loss_dice: 0.5626  decode.d1.loss_cls: 1.5265  decode.d1.loss_mask: 0.3958  decode.d1.loss_dice: 0.4639  decode.d2.loss_cls: 1.2439  decode.d2.loss_mask: 0.3800  decode.d2.loss_dice: 0.4525  decode.d3.loss_cls: 1.2015  decode.d3.loss_mask: 0.3743  decode.d3.loss_dice: 0.4635  decode.d4.loss_cls: 1.2631  decode.d4.loss_mask: 0.4552  decode.d4.loss_dice: 0.4619  decode.d5.loss_cls: 1.1034  decode.d5.loss_mask: 0.5121  decode.d5.loss_dice: 0.4611  decode.d6.loss_cls: 1.1259  decode.d6.loss_mask: 0.4902  decode.d6.loss_dice: 0.4631  decode.d7.loss_cls: 1.1793  decode.d7.loss_mask: 0.4438  decode.d7.loss_dice: 0.4593  decode.d8.loss_cls: 1.1930  decode.d8.loss_mask: 0.4994  decode.d8.loss_dice: 0.5064
07/29 23:17:17 - mmengine - INFO - Iter(train) [ 2250/80000]  base_lr: 9.7466e-05 lr: 9.7466e-06  eta: 11:29:23  time: 0.5232  data_time: 0.0126  memory: 5896  grad_norm: 177.9919  loss: 22.7276  decode.loss_cls: 1.3964  decode.loss_mask: 0.2987  decode.loss_dice: 0.3951  decode.d0.loss_cls: 2.9812  decode.d0.loss_mask: 0.3294  decode.d0.loss_dice: 0.5407  decode.d1.loss_cls: 1.5560  decode.d1.loss_mask: 0.3365  decode.d1.loss_dice: 0.4317  decode.d2.loss_cls: 1.4204  decode.d2.loss_mask: 0.3240  decode.d2.loss_dice: 0.4160  decode.d3.loss_cls: 1.4083  decode.d3.loss_mask: 0.3120  decode.d3.loss_dice: 0.3813  decode.d4.loss_cls: 1.3359  decode.d4.loss_mask: 0.3129  decode.d4.loss_dice: 0.4045  decode.d5.loss_cls: 1.3035  decode.d5.loss_mask: 0.3081  decode.d5.loss_dice: 0.3797  decode.d6.loss_cls: 1.3364  decode.d6.loss_mask: 0.3031  decode.d6.loss_dice: 0.3752  decode.d7.loss_cls: 1.3335  decode.d7.loss_mask: 0.3183  decode.d7.loss_dice: 0.4134  decode.d8.loss_cls: 1.3380  decode.d8.loss_mask: 0.3236  decode.d8.loss_dice: 0.4135
07/29 23:17:43 - mmengine - INFO - Iter(train) [ 2300/80000]  base_lr: 9.7410e-05 lr: 9.7410e-06  eta: 11:28:35  time: 0.5143  data_time: 0.0120  memory: 5896  grad_norm: 156.6387  loss: 23.2708  decode.loss_cls: 1.4500  decode.loss_mask: 0.3843  decode.loss_dice: 0.4303  decode.d0.loss_cls: 2.9879  decode.d0.loss_mask: 0.3402  decode.d0.loss_dice: 0.5270  decode.d1.loss_cls: 1.7564  decode.d1.loss_mask: 0.3063  decode.d1.loss_dice: 0.3920  decode.d2.loss_cls: 1.3899  decode.d2.loss_mask: 0.3057  decode.d2.loss_dice: 0.3944  decode.d3.loss_cls: 1.4427  decode.d3.loss_mask: 0.3269  decode.d3.loss_dice: 0.4086  decode.d4.loss_cls: 1.4614  decode.d4.loss_mask: 0.3092  decode.d4.loss_dice: 0.3831  decode.d5.loss_cls: 1.3331  decode.d5.loss_mask: 0.3296  decode.d5.loss_dice: 0.3935  decode.d6.loss_cls: 1.3850  decode.d6.loss_mask: 0.3037  decode.d6.loss_dice: 0.4074  decode.d7.loss_cls: 1.3884  decode.d7.loss_mask: 0.3071  decode.d7.loss_dice: 0.4056  decode.d8.loss_cls: 1.2624  decode.d8.loss_mask: 0.3455  decode.d8.loss_dice: 0.4130
07/29 23:18:10 - mmengine - INFO - Iter(train) [ 2350/80000]  base_lr: 9.7353e-05 lr: 9.7353e-06  eta: 11:28:05  time: 0.5325  data_time: 0.0133  memory: 5899  grad_norm: 195.1828  loss: 22.9670  decode.loss_cls: 1.2708  decode.loss_mask: 0.3876  decode.loss_dice: 0.4749  decode.d0.loss_cls: 2.6988  decode.d0.loss_mask: 0.3902  decode.d0.loss_dice: 0.5639  decode.d1.loss_cls: 1.5461  decode.d1.loss_mask: 0.3447  decode.d1.loss_dice: 0.4471  decode.d2.loss_cls: 1.2797  decode.d2.loss_mask: 0.3559  decode.d2.loss_dice: 0.4581  decode.d3.loss_cls: 1.2672  decode.d3.loss_mask: 0.3513  decode.d3.loss_dice: 0.4654  decode.d4.loss_cls: 1.2704  decode.d4.loss_mask: 0.3464  decode.d4.loss_dice: 0.4431  decode.d5.loss_cls: 1.3003  decode.d5.loss_mask: 0.3665  decode.d5.loss_dice: 0.4463  decode.d6.loss_cls: 1.2619  decode.d6.loss_mask: 0.3573  decode.d6.loss_dice: 0.4495  decode.d7.loss_cls: 1.4061  decode.d7.loss_mask: 0.3450  decode.d7.loss_dice: 0.4454  decode.d8.loss_cls: 1.3908  decode.d8.loss_mask: 0.3856  decode.d8.loss_dice: 0.4506
07/29 23:18:37 - mmengine - INFO - Iter(train) [ 2400/80000]  base_lr: 9.7297e-05 lr: 9.7297e-06  eta: 11:27:45  time: 0.5349  data_time: 0.0134  memory: 5934  grad_norm: 264.9108  loss: 20.5413  decode.loss_cls: 0.8770  decode.loss_mask: 0.5225  decode.loss_dice: 0.5027  decode.d0.loss_cls: 2.4316  decode.d0.loss_mask: 0.5613  decode.d0.loss_dice: 0.5398  decode.d1.loss_cls: 1.0684  decode.d1.loss_mask: 0.5142  decode.d1.loss_dice: 0.4897  decode.d2.loss_cls: 0.9437  decode.d2.loss_mask: 0.4968  decode.d2.loss_dice: 0.4957  decode.d3.loss_cls: 0.8675  decode.d3.loss_mask: 0.4946  decode.d3.loss_dice: 0.5069  decode.d4.loss_cls: 0.8429  decode.d4.loss_mask: 0.5065  decode.d4.loss_dice: 0.5151  decode.d5.loss_cls: 0.8730  decode.d5.loss_mask: 0.5010  decode.d5.loss_dice: 0.4910  decode.d6.loss_cls: 0.8839  decode.d6.loss_mask: 0.4938  decode.d6.loss_dice: 0.4582  decode.d7.loss_cls: 0.8593  decode.d7.loss_mask: 0.4941  decode.d7.loss_dice: 0.4512  decode.d8.loss_cls: 0.8506  decode.d8.loss_mask: 0.5072  decode.d8.loss_dice: 0.5010
07/29 23:19:03 - mmengine - INFO - Iter(train) [ 2450/80000]  base_lr: 9.7241e-05 lr: 9.7241e-06  eta: 11:27:24  time: 0.5377  data_time: 0.0135  memory: 5896  grad_norm: 273.7163  loss: 21.8389  decode.loss_cls: 1.2038  decode.loss_mask: 0.4208  decode.loss_dice: 0.4842  decode.d0.loss_cls: 2.6341  decode.d0.loss_mask: 0.4448  decode.d0.loss_dice: 0.5127  decode.d1.loss_cls: 1.5118  decode.d1.loss_mask: 0.3860  decode.d1.loss_dice: 0.4177  decode.d2.loss_cls: 1.1814  decode.d2.loss_mask: 0.3998  decode.d2.loss_dice: 0.4590  decode.d3.loss_cls: 1.1697  decode.d3.loss_mask: 0.3777  decode.d3.loss_dice: 0.4020  decode.d4.loss_cls: 1.1219  decode.d4.loss_mask: 0.3975  decode.d4.loss_dice: 0.4318  decode.d5.loss_cls: 1.0979  decode.d5.loss_mask: 0.4037  decode.d5.loss_dice: 0.4456  decode.d6.loss_cls: 1.0493  decode.d6.loss_mask: 0.4174  decode.d6.loss_dice: 0.4560  decode.d7.loss_cls: 1.0979  decode.d7.loss_mask: 0.4107  decode.d7.loss_dice: 0.4774  decode.d8.loss_cls: 1.1753  decode.d8.loss_mask: 0.3976  decode.d8.loss_dice: 0.4533
07/29 23:19:30 - mmengine - INFO - Iter(train) [ 2500/80000]  base_lr: 9.7184e-05 lr: 9.7184e-06  eta: 11:27:06  time: 0.5379  data_time: 0.0132  memory: 5916  grad_norm: 264.6834  loss: 24.4478  decode.loss_cls: 1.4041  decode.loss_mask: 0.4007  decode.loss_dice: 0.5208  decode.d0.loss_cls: 2.6251  decode.d0.loss_mask: 0.4392  decode.d0.loss_dice: 0.6366  decode.d1.loss_cls: 1.5627  decode.d1.loss_mask: 0.4286  decode.d1.loss_dice: 0.4889  decode.d2.loss_cls: 1.3361  decode.d2.loss_mask: 0.4301  decode.d2.loss_dice: 0.5212  decode.d3.loss_cls: 1.2786  decode.d3.loss_mask: 0.3989  decode.d3.loss_dice: 0.4943  decode.d4.loss_cls: 1.2724  decode.d4.loss_mask: 0.4194  decode.d4.loss_dice: 0.5447  decode.d5.loss_cls: 1.4312  decode.d5.loss_mask: 0.3843  decode.d5.loss_dice: 0.5296  decode.d6.loss_cls: 1.3951  decode.d6.loss_mask: 0.3980  decode.d6.loss_dice: 0.5108  decode.d7.loss_cls: 1.3909  decode.d7.loss_mask: 0.3937  decode.d7.loss_dice: 0.5189  decode.d8.loss_cls: 1.3916  decode.d8.loss_mask: 0.3906  decode.d8.loss_dice: 0.5108
07/29 23:19:57 - mmengine - INFO - Iter(train) [ 2550/80000]  base_lr: 9.7128e-05 lr: 9.7128e-06  eta: 11:26:49  time: 0.5390  data_time: 0.0136  memory: 5916  grad_norm: 333.5964  loss: 22.2170  decode.loss_cls: 1.2543  decode.loss_mask: 0.3623  decode.loss_dice: 0.5485  decode.d0.loss_cls: 2.4832  decode.d0.loss_mask: 0.3987  decode.d0.loss_dice: 0.6185  decode.d1.loss_cls: 1.3549  decode.d1.loss_mask: 0.3802  decode.d1.loss_dice: 0.5462  decode.d2.loss_cls: 1.2448  decode.d2.loss_mask: 0.3520  decode.d2.loss_dice: 0.5646  decode.d3.loss_cls: 1.1740  decode.d3.loss_mask: 0.3469  decode.d3.loss_dice: 0.5595  decode.d4.loss_cls: 1.1228  decode.d4.loss_mask: 0.3531  decode.d4.loss_dice: 0.5467  decode.d5.loss_cls: 1.0484  decode.d5.loss_mask: 0.3497  decode.d5.loss_dice: 0.5479  decode.d6.loss_cls: 1.0781  decode.d6.loss_mask: 0.3525  decode.d6.loss_dice: 0.5285  decode.d7.loss_cls: 1.1133  decode.d7.loss_mask: 0.3643  decode.d7.loss_dice: 0.5581  decode.d8.loss_cls: 1.1709  decode.d8.loss_mask: 0.3527  decode.d8.loss_dice: 0.5414
07/29 23:20:24 - mmengine - INFO - Iter(train) [ 2600/80000]  base_lr: 9.7071e-05 lr: 9.7071e-06  eta: 11:26:28  time: 0.5356  data_time: 0.0137  memory: 5916  grad_norm: 205.6045  loss: 21.0855  decode.loss_cls: 1.2294  decode.loss_mask: 0.3894  decode.loss_dice: 0.3684  decode.d0.loss_cls: 2.5960  decode.d0.loss_mask: 0.4309  decode.d0.loss_dice: 0.5079  decode.d1.loss_cls: 1.4755  decode.d1.loss_mask: 0.3687  decode.d1.loss_dice: 0.3852  decode.d2.loss_cls: 1.1658  decode.d2.loss_mask: 0.3326  decode.d2.loss_dice: 0.3482  decode.d3.loss_cls: 1.2033  decode.d3.loss_mask: 0.3452  decode.d3.loss_dice: 0.3774  decode.d4.loss_cls: 1.2425  decode.d4.loss_mask: 0.3376  decode.d4.loss_dice: 0.3453  decode.d5.loss_cls: 1.1476  decode.d5.loss_mask: 0.4020  decode.d5.loss_dice: 0.3827  decode.d6.loss_cls: 1.1708  decode.d6.loss_mask: 0.3722  decode.d6.loss_dice: 0.3731  decode.d7.loss_cls: 1.1661  decode.d7.loss_mask: 0.3643  decode.d7.loss_dice: 0.3755  decode.d8.loss_cls: 1.1954  decode.d8.loss_mask: 0.3488  decode.d8.loss_dice: 0.3377
07/29 23:20:51 - mmengine - INFO - Iter(train) [ 2650/80000]  base_lr: 9.7015e-05 lr: 9.7015e-06  eta: 11:26:11  time: 0.5384  data_time: 0.0138  memory: 5920  grad_norm: 281.1752  loss: 21.0160  decode.loss_cls: 1.0133  decode.loss_mask: 0.4116  decode.loss_dice: 0.4603  decode.d0.loss_cls: 2.4842  decode.d0.loss_mask: 0.3889  decode.d0.loss_dice: 0.4795  decode.d1.loss_cls: 1.4482  decode.d1.loss_mask: 0.4130  decode.d1.loss_dice: 0.3992  decode.d2.loss_cls: 1.1183  decode.d2.loss_mask: 0.4178  decode.d2.loss_dice: 0.4121  decode.d3.loss_cls: 1.0405  decode.d3.loss_mask: 0.4063  decode.d3.loss_dice: 0.4238  decode.d4.loss_cls: 1.0601  decode.d4.loss_mask: 0.4119  decode.d4.loss_dice: 0.4348  decode.d5.loss_cls: 1.0774  decode.d5.loss_mask: 0.4227  decode.d5.loss_dice: 0.4444  decode.d6.loss_cls: 1.0331  decode.d6.loss_mask: 0.4073  decode.d6.loss_dice: 0.4496  decode.d7.loss_cls: 1.0357  decode.d7.loss_mask: 0.4380  decode.d7.loss_dice: 0.4734  decode.d8.loss_cls: 1.0856  decode.d8.loss_mask: 0.4537  decode.d8.loss_dice: 0.4712
07/29 23:21:18 - mmengine - INFO - Iter(train) [ 2700/80000]  base_lr: 9.6958e-05 lr: 9.6958e-06  eta: 11:25:53  time: 0.5358  data_time: 0.0132  memory: 5896  grad_norm: 307.5414  loss: 21.6550  decode.loss_cls: 1.2976  decode.loss_mask: 0.3540  decode.loss_dice: 0.4305  decode.d0.loss_cls: 2.4093  decode.d0.loss_mask: 0.4321  decode.d0.loss_dice: 0.5906  decode.d1.loss_cls: 1.4385  decode.d1.loss_mask: 0.4243  decode.d1.loss_dice: 0.4686  decode.d2.loss_cls: 1.2182  decode.d2.loss_mask: 0.3871  decode.d2.loss_dice: 0.4598  decode.d3.loss_cls: 1.0799  decode.d3.loss_mask: 0.3690  decode.d3.loss_dice: 0.4272  decode.d4.loss_cls: 1.1383  decode.d4.loss_mask: 0.3752  decode.d4.loss_dice: 0.4378  decode.d5.loss_cls: 1.1989  decode.d5.loss_mask: 0.3610  decode.d5.loss_dice: 0.4287  decode.d6.loss_cls: 1.1515  decode.d6.loss_mask: 0.3810  decode.d6.loss_dice: 0.4204  decode.d7.loss_cls: 1.1383  decode.d7.loss_mask: 0.3972  decode.d7.loss_dice: 0.4451  decode.d8.loss_cls: 1.1548  decode.d8.loss_mask: 0.4035  decode.d8.loss_dice: 0.4370
07/29 23:21:45 - mmengine - INFO - Iter(train) [ 2750/80000]  base_lr: 9.6902e-05 lr: 9.6902e-06  eta: 11:25:29  time: 0.5398  data_time: 0.0137  memory: 5919  grad_norm: 278.0120  loss: 23.1627  decode.loss_cls: 1.4029  decode.loss_mask: 0.3390  decode.loss_dice: 0.4406  decode.d0.loss_cls: 2.5933  decode.d0.loss_mask: 0.3466  decode.d0.loss_dice: 0.5316  decode.d1.loss_cls: 1.6419  decode.d1.loss_mask: 0.3161  decode.d1.loss_dice: 0.4078  decode.d2.loss_cls: 1.4201  decode.d2.loss_mask: 0.3124  decode.d2.loss_dice: 0.4035  decode.d3.loss_cls: 1.4149  decode.d3.loss_mask: 0.3061  decode.d3.loss_dice: 0.3923  decode.d4.loss_cls: 1.4249  decode.d4.loss_mask: 0.3139  decode.d4.loss_dice: 0.4113  decode.d5.loss_cls: 1.3786  decode.d5.loss_mask: 0.3438  decode.d5.loss_dice: 0.4259  decode.d6.loss_cls: 1.4041  decode.d6.loss_mask: 0.3692  decode.d6.loss_dice: 0.4554  decode.d7.loss_cls: 1.3695  decode.d7.loss_mask: 0.3552  decode.d7.loss_dice: 0.4540  decode.d8.loss_cls: 1.4169  decode.d8.loss_mask: 0.3405  decode.d8.loss_dice: 0.4305
07/29 23:22:11 - mmengine - INFO - Iter(train) [ 2800/80000]  base_lr: 9.6846e-05 lr: 9.6846e-06  eta: 11:25:03  time: 0.5262  data_time: 0.0131  memory: 5879  grad_norm: 299.2063  loss: 20.6151  decode.loss_cls: 1.0989  decode.loss_mask: 0.3887  decode.loss_dice: 0.4227  decode.d0.loss_cls: 2.3895  decode.d0.loss_mask: 0.3720  decode.d0.loss_dice: 0.5395  decode.d1.loss_cls: 1.5211  decode.d1.loss_mask: 0.3530  decode.d1.loss_dice: 0.4392  decode.d2.loss_cls: 1.1802  decode.d2.loss_mask: 0.3255  decode.d2.loss_dice: 0.3950  decode.d3.loss_cls: 1.1020  decode.d3.loss_mask: 0.3483  decode.d3.loss_dice: 0.4053  decode.d4.loss_cls: 1.0765  decode.d4.loss_mask: 0.3689  decode.d4.loss_dice: 0.4144  decode.d5.loss_cls: 1.0564  decode.d5.loss_mask: 0.4043  decode.d5.loss_dice: 0.4154  decode.d6.loss_cls: 1.0638  decode.d6.loss_mask: 0.3720  decode.d6.loss_dice: 0.4073  decode.d7.loss_cls: 1.0864  decode.d7.loss_mask: 0.3755  decode.d7.loss_dice: 0.3985  decode.d8.loss_cls: 1.1257  decode.d8.loss_mask: 0.3668  decode.d8.loss_dice: 0.4024
07/29 23:22:38 - mmengine - INFO - Iter(train) [ 2850/80000]  base_lr: 9.6789e-05 lr: 9.6789e-06  eta: 11:24:34  time: 0.5286  data_time: 0.0130  memory: 5918  grad_norm: 216.5530  loss: 18.8668  decode.loss_cls: 0.9308  decode.loss_mask: 0.4772  decode.loss_dice: 0.3889  decode.d0.loss_cls: 2.0679  decode.d0.loss_mask: 0.4250  decode.d0.loss_dice: 0.4487  decode.d1.loss_cls: 1.1549  decode.d1.loss_mask: 0.3749  decode.d1.loss_dice: 0.3350  decode.d2.loss_cls: 0.9418  decode.d2.loss_mask: 0.3891  decode.d2.loss_dice: 0.3512  decode.d3.loss_cls: 0.9423  decode.d3.loss_mask: 0.4301  decode.d3.loss_dice: 0.3670  decode.d4.loss_cls: 0.9473  decode.d4.loss_mask: 0.4661  decode.d4.loss_dice: 0.3798  decode.d5.loss_cls: 0.9090  decode.d5.loss_mask: 0.4794  decode.d5.loss_dice: 0.3783  decode.d6.loss_cls: 0.8877  decode.d6.loss_mask: 0.4902  decode.d6.loss_dice: 0.3753  decode.d7.loss_cls: 0.9219  decode.d7.loss_mask: 0.4491  decode.d7.loss_dice: 0.3724  decode.d8.loss_cls: 0.9431  decode.d8.loss_mask: 0.4821  decode.d8.loss_dice: 0.3603
07/29 23:23:04 - mmengine - INFO - Iter(train) [ 2900/80000]  base_lr: 9.6733e-05 lr: 9.6733e-06  eta: 11:24:02  time: 0.5250  data_time: 0.0129  memory: 5897  grad_norm: 174.5856  loss: 19.6527  decode.loss_cls: 1.0528  decode.loss_mask: 0.3382  decode.loss_dice: 0.5096  decode.d0.loss_cls: 2.0742  decode.d0.loss_mask: 0.3586  decode.d0.loss_dice: 0.5750  decode.d1.loss_cls: 1.2663  decode.d1.loss_mask: 0.3472  decode.d1.loss_dice: 0.4321  decode.d2.loss_cls: 1.0648  decode.d2.loss_mask: 0.3368  decode.d2.loss_dice: 0.4384  decode.d3.loss_cls: 0.9984  decode.d3.loss_mask: 0.3437  decode.d3.loss_dice: 0.4437  decode.d4.loss_cls: 0.9804  decode.d4.loss_mask: 0.3397  decode.d4.loss_dice: 0.4583  decode.d5.loss_cls: 0.9984  decode.d5.loss_mask: 0.3532  decode.d5.loss_dice: 0.4893  decode.d6.loss_cls: 1.0478  decode.d6.loss_mask: 0.3408  decode.d6.loss_dice: 0.4682  decode.d7.loss_cls: 1.0058  decode.d7.loss_mask: 0.3415  decode.d7.loss_dice: 0.4637  decode.d8.loss_cls: 0.9400  decode.d8.loss_mask: 0.3514  decode.d8.loss_dice: 0.4944
07/29 23:23:31 - mmengine - INFO - Iter(train) [ 2950/80000]  base_lr: 9.6676e-05 lr: 9.6676e-06  eta: 11:23:36  time: 0.5235  data_time: 0.0126  memory: 5933  grad_norm: 203.6582  loss: 18.1964  decode.loss_cls: 0.9137  decode.loss_mask: 0.3273  decode.loss_dice: 0.4083  decode.d0.loss_cls: 2.1120  decode.d0.loss_mask: 0.3205  decode.d0.loss_dice: 0.4840  decode.d1.loss_cls: 1.2439  decode.d1.loss_mask: 0.3272  decode.d1.loss_dice: 0.4106  decode.d2.loss_cls: 0.9633  decode.d2.loss_mask: 0.3249  decode.d2.loss_dice: 0.3953  decode.d3.loss_cls: 0.9856  decode.d3.loss_mask: 0.3277  decode.d3.loss_dice: 0.3952  decode.d4.loss_cls: 0.9564  decode.d4.loss_mask: 0.3227  decode.d4.loss_dice: 0.3998  decode.d5.loss_cls: 0.9036  decode.d5.loss_mask: 0.3178  decode.d5.loss_dice: 0.4069  decode.d6.loss_cls: 0.9285  decode.d6.loss_mask: 0.3179  decode.d6.loss_dice: 0.4226  decode.d7.loss_cls: 0.8876  decode.d7.loss_mask: 0.3239  decode.d7.loss_dice: 0.4260  decode.d8.loss_cls: 0.8996  decode.d8.loss_mask: 0.3218  decode.d8.loss_dice: 0.4221
07/29 23:23:57 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/29 23:23:57 - mmengine - INFO - Iter(train) [ 3000/80000]  base_lr: 9.6620e-05 lr: 9.6620e-06  eta: 11:23:01  time: 0.5267  data_time: 0.0128  memory: 5897  grad_norm: 336.2882  loss: 19.9357  decode.loss_cls: 0.9790  decode.loss_mask: 0.4564  decode.loss_dice: 0.4500  decode.d0.loss_cls: 2.0874  decode.d0.loss_mask: 0.4223  decode.d0.loss_dice: 0.5078  decode.d1.loss_cls: 1.3165  decode.d1.loss_mask: 0.4132  decode.d1.loss_dice: 0.4132  decode.d2.loss_cls: 1.0425  decode.d2.loss_mask: 0.4271  decode.d2.loss_dice: 0.4203  decode.d3.loss_cls: 0.9881  decode.d3.loss_mask: 0.4113  decode.d3.loss_dice: 0.4278  decode.d4.loss_cls: 1.0178  decode.d4.loss_mask: 0.4322  decode.d4.loss_dice: 0.4090  decode.d5.loss_cls: 0.9002  decode.d5.loss_mask: 0.4461  decode.d5.loss_dice: 0.4486  decode.d6.loss_cls: 0.9035  decode.d6.loss_mask: 0.4561  decode.d6.loss_dice: 0.4546  decode.d7.loss_cls: 0.9169  decode.d7.loss_mask: 0.4415  decode.d7.loss_dice: 0.4765  decode.d8.loss_cls: 0.9772  decode.d8.loss_mask: 0.4542  decode.d8.loss_dice: 0.4385
07/29 23:24:23 - mmengine - INFO - Iter(train) [ 3050/80000]  base_lr: 9.6563e-05 lr: 9.6563e-06  eta: 11:22:27  time: 0.5278  data_time: 0.0130  memory: 5883  grad_norm: 220.3163  loss: 17.9986  decode.loss_cls: 0.8534  decode.loss_mask: 0.4053  decode.loss_dice: 0.4265  decode.d0.loss_cls: 1.9603  decode.d0.loss_mask: 0.4002  decode.d0.loss_dice: 0.4719  decode.d1.loss_cls: 1.1245  decode.d1.loss_mask: 0.4212  decode.d1.loss_dice: 0.4066  decode.d2.loss_cls: 0.8227  decode.d2.loss_mask: 0.4104  decode.d2.loss_dice: 0.4417  decode.d3.loss_cls: 0.8209  decode.d3.loss_mask: 0.3939  decode.d3.loss_dice: 0.3850  decode.d4.loss_cls: 0.8389  decode.d4.loss_mask: 0.4112  decode.d4.loss_dice: 0.4280  decode.d5.loss_cls: 0.7829  decode.d5.loss_mask: 0.4203  decode.d5.loss_dice: 0.4625  decode.d6.loss_cls: 0.7865  decode.d6.loss_mask: 0.4185  decode.d6.loss_dice: 0.4098  decode.d7.loss_cls: 0.8004  decode.d7.loss_mask: 0.4083  decode.d7.loss_dice: 0.4089  decode.d8.loss_cls: 0.8330  decode.d8.loss_mask: 0.4279  decode.d8.loss_dice: 0.4171
07/29 23:24:50 - mmengine - INFO - Iter(train) [ 3100/80000]  base_lr: 9.6507e-05 lr: 9.6507e-06  eta: 11:21:54  time: 0.5290  data_time: 0.0128  memory: 5896  grad_norm: 297.5967  loss: 21.3709  decode.loss_cls: 1.1550  decode.loss_mask: 0.3280  decode.loss_dice: 0.4034  decode.d0.loss_cls: 2.2973  decode.d0.loss_mask: 0.3709  decode.d0.loss_dice: 0.4905  decode.d1.loss_cls: 1.4653  decode.d1.loss_mask: 0.3772  decode.d1.loss_dice: 0.4141  decode.d2.loss_cls: 1.2793  decode.d2.loss_mask: 0.3578  decode.d2.loss_dice: 0.3961  decode.d3.loss_cls: 1.2338  decode.d3.loss_mask: 0.3427  decode.d3.loss_dice: 0.4165  decode.d4.loss_cls: 1.2566  decode.d4.loss_mask: 0.3564  decode.d4.loss_dice: 0.4180  decode.d5.loss_cls: 1.1926  decode.d5.loss_mask: 0.3645  decode.d5.loss_dice: 0.4252  decode.d6.loss_cls: 1.2442  decode.d6.loss_mask: 0.3715  decode.d6.loss_dice: 0.4200  decode.d7.loss_cls: 1.2186  decode.d7.loss_mask: 0.3497  decode.d7.loss_dice: 0.4252  decode.d8.loss_cls: 1.1901  decode.d8.loss_mask: 0.3721  decode.d8.loss_dice: 0.4384
07/29 23:25:16 - mmengine - INFO - Iter(train) [ 3150/80000]  base_lr: 9.6450e-05 lr: 9.6450e-06  eta: 11:21:27  time: 0.5354  data_time: 0.0135  memory: 5919  grad_norm: 206.8193  loss: 16.8015  decode.loss_cls: 0.7510  decode.loss_mask: 0.4033  decode.loss_dice: 0.3409  decode.d0.loss_cls: 1.8478  decode.d0.loss_mask: 0.3974  decode.d0.loss_dice: 0.4205  decode.d1.loss_cls: 1.0698  decode.d1.loss_mask: 0.3903  decode.d1.loss_dice: 0.3761  decode.d2.loss_cls: 0.8935  decode.d2.loss_mask: 0.3821  decode.d2.loss_dice: 0.3725  decode.d3.loss_cls: 0.7953  decode.d3.loss_mask: 0.3770  decode.d3.loss_dice: 0.3594  decode.d4.loss_cls: 0.8650  decode.d4.loss_mask: 0.3927  decode.d4.loss_dice: 0.3471  decode.d5.loss_cls: 0.8632  decode.d5.loss_mask: 0.3723  decode.d5.loss_dice: 0.3374  decode.d6.loss_cls: 0.7374  decode.d6.loss_mask: 0.3736  decode.d6.loss_dice: 0.3529  decode.d7.loss_cls: 0.7446  decode.d7.loss_mask: 0.3821  decode.d7.loss_dice: 0.3476  decode.d8.loss_cls: 0.7439  decode.d8.loss_mask: 0.4009  decode.d8.loss_dice: 0.3635
07/29 23:25:43 - mmengine - INFO - Iter(train) [ 3200/80000]  base_lr: 9.6394e-05 lr: 9.6394e-06  eta: 11:20:57  time: 0.5286  data_time: 0.0130  memory: 5918  grad_norm: 342.4828  loss: 15.8941  decode.loss_cls: 0.8377  decode.loss_mask: 0.3319  decode.loss_dice: 0.2992  decode.d0.loss_cls: 1.9316  decode.d0.loss_mask: 0.3693  decode.d0.loss_dice: 0.3724  decode.d1.loss_cls: 0.9704  decode.d1.loss_mask: 0.3631  decode.d1.loss_dice: 0.3380  decode.d2.loss_cls: 0.7243  decode.d2.loss_mask: 0.3659  decode.d2.loss_dice: 0.3279  decode.d3.loss_cls: 0.6861  decode.d3.loss_mask: 0.3946  decode.d3.loss_dice: 0.3183  decode.d4.loss_cls: 0.6975  decode.d4.loss_mask: 0.4051  decode.d4.loss_dice: 0.3297  decode.d5.loss_cls: 0.7115  decode.d5.loss_mask: 0.3668  decode.d5.loss_dice: 0.3330  decode.d6.loss_cls: 0.7871  decode.d6.loss_mask: 0.3857  decode.d6.loss_dice: 0.3171  decode.d7.loss_cls: 0.8196  decode.d7.loss_mask: 0.3384  decode.d7.loss_dice: 0.2967  decode.d8.loss_cls: 0.8427  decode.d8.loss_mask: 0.3329  decode.d8.loss_dice: 0.2995
07/29 23:26:09 - mmengine - INFO - Iter(train) [ 3250/80000]  base_lr: 9.6337e-05 lr: 9.6337e-06  eta: 11:20:30  time: 0.5366  data_time: 0.0135  memory: 5916  grad_norm: 232.0588  loss: 14.9051  decode.loss_cls: 0.5837  decode.loss_mask: 0.3825  decode.loss_dice: 0.4021  decode.d0.loss_cls: 1.8107  decode.d0.loss_mask: 0.3966  decode.d0.loss_dice: 0.3743  decode.d1.loss_cls: 0.7661  decode.d1.loss_mask: 0.3838  decode.d1.loss_dice: 0.3574  decode.d2.loss_cls: 0.6728  decode.d2.loss_mask: 0.3606  decode.d2.loss_dice: 0.3472  decode.d3.loss_cls: 0.6706  decode.d3.loss_mask: 0.3552  decode.d3.loss_dice: 0.3301  decode.d4.loss_cls: 0.6418  decode.d4.loss_mask: 0.3619  decode.d4.loss_dice: 0.3637  decode.d5.loss_cls: 0.5711  decode.d5.loss_mask: 0.3694  decode.d5.loss_dice: 0.3713  decode.d6.loss_cls: 0.5853  decode.d6.loss_mask: 0.3684  decode.d6.loss_dice: 0.3626  decode.d7.loss_cls: 0.6149  decode.d7.loss_mask: 0.3767  decode.d7.loss_dice: 0.3690  decode.d8.loss_cls: 0.6031  decode.d8.loss_mask: 0.3732  decode.d8.loss_dice: 0.3793
07/29 23:26:36 - mmengine - INFO - Iter(train) [ 3300/80000]  base_lr: 9.6281e-05 lr: 9.6281e-06  eta: 11:20:11  time: 0.5382  data_time: 0.0133  memory: 5936  grad_norm: 245.4645  loss: 18.2239  decode.loss_cls: 0.9687  decode.loss_mask: 0.3000  decode.loss_dice: 0.4715  decode.d0.loss_cls: 2.1052  decode.d0.loss_mask: 0.2983  decode.d0.loss_dice: 0.5719  decode.d1.loss_cls: 1.1329  decode.d1.loss_mask: 0.3054  decode.d1.loss_dice: 0.5158  decode.d2.loss_cls: 0.9169  decode.d2.loss_mask: 0.2801  decode.d2.loss_dice: 0.4527  decode.d3.loss_cls: 0.8458  decode.d3.loss_mask: 0.2757  decode.d3.loss_dice: 0.4719  decode.d4.loss_cls: 0.9547  decode.d4.loss_mask: 0.2740  decode.d4.loss_dice: 0.4542  decode.d5.loss_cls: 0.9090  decode.d5.loss_mask: 0.2779  decode.d5.loss_dice: 0.4320  decode.d6.loss_cls: 0.9064  decode.d6.loss_mask: 0.2720  decode.d6.loss_dice: 0.4757  decode.d7.loss_cls: 0.9979  decode.d7.loss_mask: 0.2609  decode.d7.loss_dice: 0.4299  decode.d8.loss_cls: 0.9438  decode.d8.loss_mask: 0.2830  decode.d8.loss_dice: 0.4395
07/29 23:27:03 - mmengine - INFO - Iter(train) [ 3350/80000]  base_lr: 9.6224e-05 lr: 9.6224e-06  eta: 11:19:50  time: 0.5329  data_time: 0.0132  memory: 5973  grad_norm: 171.4141  loss: 17.7040  decode.loss_cls: 0.9210  decode.loss_mask: 0.3245  decode.loss_dice: 0.3984  decode.d0.loss_cls: 2.0643  decode.d0.loss_mask: 0.3386  decode.d0.loss_dice: 0.4455  decode.d1.loss_cls: 1.2032  decode.d1.loss_mask: 0.3593  decode.d1.loss_dice: 0.3859  decode.d2.loss_cls: 0.8704  decode.d2.loss_mask: 0.3408  decode.d2.loss_dice: 0.4149  decode.d3.loss_cls: 0.9123  decode.d3.loss_mask: 0.3370  decode.d3.loss_dice: 0.3912  decode.d4.loss_cls: 0.8365  decode.d4.loss_mask: 0.3529  decode.d4.loss_dice: 0.3784  decode.d5.loss_cls: 0.8536  decode.d5.loss_mask: 0.3482  decode.d5.loss_dice: 0.3701  decode.d6.loss_cls: 0.8884  decode.d6.loss_mask: 0.3280  decode.d6.loss_dice: 0.3783  decode.d7.loss_cls: 0.9542  decode.d7.loss_mask: 0.3362  decode.d7.loss_dice: 0.3761  decode.d8.loss_cls: 0.8678  decode.d8.loss_mask: 0.3264  decode.d8.loss_dice: 0.4016
07/29 23:27:30 - mmengine - INFO - Iter(train) [ 3400/80000]  base_lr: 9.6168e-05 lr: 9.6168e-06  eta: 11:19:23  time: 0.5312  data_time: 0.0129  memory: 5916  grad_norm: 208.0764  loss: 17.0595  decode.loss_cls: 0.7168  decode.loss_mask: 0.4113  decode.loss_dice: 0.4447  decode.d0.loss_cls: 1.7888  decode.d0.loss_mask: 0.3964  decode.d0.loss_dice: 0.4940  decode.d1.loss_cls: 1.0618  decode.d1.loss_mask: 0.3407  decode.d1.loss_dice: 0.4091  decode.d2.loss_cls: 0.8096  decode.d2.loss_mask: 0.3280  decode.d2.loss_dice: 0.4013  decode.d3.loss_cls: 0.8021  decode.d3.loss_mask: 0.3480  decode.d3.loss_dice: 0.3981  decode.d4.loss_cls: 0.7923  decode.d4.loss_mask: 0.3541  decode.d4.loss_dice: 0.4391  decode.d5.loss_cls: 0.8192  decode.d5.loss_mask: 0.3802  decode.d5.loss_dice: 0.4307  decode.d6.loss_cls: 0.7455  decode.d6.loss_mask: 0.3394  decode.d6.loss_dice: 0.4361  decode.d7.loss_cls: 0.7630  decode.d7.loss_mask: 0.3341  decode.d7.loss_dice: 0.4539  decode.d8.loss_cls: 0.8188  decode.d8.loss_mask: 0.3579  decode.d8.loss_dice: 0.4441
07/29 23:27:56 - mmengine - INFO - Iter(train) [ 3450/80000]  base_lr: 9.6111e-05 lr: 9.6111e-06  eta: 11:18:51  time: 0.5283  data_time: 0.0130  memory: 5897  grad_norm: 197.9960  loss: 15.8679  decode.loss_cls: 0.7568  decode.loss_mask: 0.3247  decode.loss_dice: 0.3983  decode.d0.loss_cls: 1.7997  decode.d0.loss_mask: 0.2961  decode.d0.loss_dice: 0.4478  decode.d1.loss_cls: 0.9980  decode.d1.loss_mask: 0.2952  decode.d1.loss_dice: 0.3674  decode.d2.loss_cls: 0.7219  decode.d2.loss_mask: 0.3381  decode.d2.loss_dice: 0.4260  decode.d3.loss_cls: 0.6332  decode.d3.loss_mask: 0.3373  decode.d3.loss_dice: 0.4165  decode.d4.loss_cls: 0.6773  decode.d4.loss_mask: 0.3072  decode.d4.loss_dice: 0.4187  decode.d5.loss_cls: 0.6991  decode.d5.loss_mask: 0.3266  decode.d5.loss_dice: 0.4239  decode.d6.loss_cls: 0.6581  decode.d6.loss_mask: 0.3472  decode.d6.loss_dice: 0.4310  decode.d7.loss_cls: 0.7461  decode.d7.loss_mask: 0.3382  decode.d7.loss_dice: 0.4177  decode.d8.loss_cls: 0.8216  decode.d8.loss_mask: 0.3034  decode.d8.loss_dice: 0.3949
07/29 23:28:23 - mmengine - INFO - Iter(train) [ 3500/80000]  base_lr: 9.6055e-05 lr: 9.6055e-06  eta: 11:18:21  time: 0.5320  data_time: 0.0137  memory: 5918  grad_norm: 170.9409  loss: 18.9930  decode.loss_cls: 0.9332  decode.loss_mask: 0.3674  decode.loss_dice: 0.4186  decode.d0.loss_cls: 2.0445  decode.d0.loss_mask: 0.3802  decode.d0.loss_dice: 0.4432  decode.d1.loss_cls: 1.2131  decode.d1.loss_mask: 0.3678  decode.d1.loss_dice: 0.4172  decode.d2.loss_cls: 1.0474  decode.d2.loss_mask: 0.3555  decode.d2.loss_dice: 0.3882  decode.d3.loss_cls: 0.9920  decode.d3.loss_mask: 0.3489  decode.d3.loss_dice: 0.3915  decode.d4.loss_cls: 0.9977  decode.d4.loss_mask: 0.3725  decode.d4.loss_dice: 0.4194  decode.d5.loss_cls: 0.9417  decode.d5.loss_mask: 0.3693  decode.d5.loss_dice: 0.4294  decode.d6.loss_cls: 0.9491  decode.d6.loss_mask: 0.3673  decode.d6.loss_dice: 0.4188  decode.d7.loss_cls: 1.0627  decode.d7.loss_mask: 0.3670  decode.d7.loss_dice: 0.4183  decode.d8.loss_cls: 0.9870  decode.d8.loss_mask: 0.3781  decode.d8.loss_dice: 0.4059
07/29 23:28:49 - mmengine - INFO - Iter(train) [ 3550/80000]  base_lr: 9.5998e-05 lr: 9.5998e-06  eta: 11:17:55  time: 0.5336  data_time: 0.0135  memory: 5937  grad_norm: 206.8656  loss: 16.5048  decode.loss_cls: 0.8512  decode.loss_mask: 0.3086  decode.loss_dice: 0.3502  decode.d0.loss_cls: 2.0894  decode.d0.loss_mask: 0.3468  decode.d0.loss_dice: 0.4516  decode.d1.loss_cls: 1.2392  decode.d1.loss_mask: 0.2833  decode.d1.loss_dice: 0.3182  decode.d2.loss_cls: 0.9412  decode.d2.loss_mask: 0.2841  decode.d2.loss_dice: 0.3243  decode.d3.loss_cls: 0.8385  decode.d3.loss_mask: 0.2776  decode.d3.loss_dice: 0.3104  decode.d4.loss_cls: 0.8787  decode.d4.loss_mask: 0.2724  decode.d4.loss_dice: 0.3103  decode.d5.loss_cls: 0.8324  decode.d5.loss_mask: 0.2862  decode.d5.loss_dice: 0.3184  decode.d6.loss_cls: 0.7979  decode.d6.loss_mask: 0.3036  decode.d6.loss_dice: 0.3236  decode.d7.loss_cls: 0.8656  decode.d7.loss_mask: 0.2920  decode.d7.loss_dice: 0.3177  decode.d8.loss_cls: 0.8706  decode.d8.loss_mask: 0.2925  decode.d8.loss_dice: 0.3281
07/29 23:29:16 - mmengine - INFO - Iter(train) [ 3600/80000]  base_lr: 9.5942e-05 lr: 9.5942e-06  eta: 11:17:27  time: 0.5261  data_time: 0.0129  memory: 5933  grad_norm: 308.8797  loss: 17.3529  decode.loss_cls: 0.7882  decode.loss_mask: 0.4510  decode.loss_dice: 0.4035  decode.d0.loss_cls: 1.9672  decode.d0.loss_mask: 0.4275  decode.d0.loss_dice: 0.4762  decode.d1.loss_cls: 0.9252  decode.d1.loss_mask: 0.4463  decode.d1.loss_dice: 0.3923  decode.d2.loss_cls: 0.7464  decode.d2.loss_mask: 0.3812  decode.d2.loss_dice: 0.3758  decode.d3.loss_cls: 0.8305  decode.d3.loss_mask: 0.3950  decode.d3.loss_dice: 0.3925  decode.d4.loss_cls: 0.8511  decode.d4.loss_mask: 0.3832  decode.d4.loss_dice: 0.3927  decode.d5.loss_cls: 0.7530  decode.d5.loss_mask: 0.3778  decode.d5.loss_dice: 0.3826  decode.d6.loss_cls: 0.7371  decode.d6.loss_mask: 0.4489  decode.d6.loss_dice: 0.3883  decode.d7.loss_cls: 0.7240  decode.d7.loss_mask: 0.4694  decode.d7.loss_dice: 0.3978  decode.d8.loss_cls: 0.8064  decode.d8.loss_mask: 0.4310  decode.d8.loss_dice: 0.4110
07/29 23:29:42 - mmengine - INFO - Iter(train) [ 3650/80000]  base_lr: 9.5885e-05 lr: 9.5885e-06  eta: 11:16:59  time: 0.5303  data_time: 0.0132  memory: 5918  grad_norm: 274.4809  loss: 18.4965  decode.loss_cls: 0.8769  decode.loss_mask: 0.3850  decode.loss_dice: 0.4458  decode.d0.loss_cls: 2.0764  decode.d0.loss_mask: 0.3450  decode.d0.loss_dice: 0.4649  decode.d1.loss_cls: 1.3025  decode.d1.loss_mask: 0.3578  decode.d1.loss_dice: 0.4177  decode.d2.loss_cls: 0.9726  decode.d2.loss_mask: 0.3423  decode.d2.loss_dice: 0.3975  decode.d3.loss_cls: 0.9749  decode.d3.loss_mask: 0.3425  decode.d3.loss_dice: 0.4338  decode.d4.loss_cls: 0.8758  decode.d4.loss_mask: 0.3453  decode.d4.loss_dice: 0.4151  decode.d5.loss_cls: 0.8907  decode.d5.loss_mask: 0.3580  decode.d5.loss_dice: 0.4107  decode.d6.loss_cls: 0.8357  decode.d6.loss_mask: 0.4054  decode.d6.loss_dice: 0.4769  decode.d7.loss_cls: 0.8389  decode.d7.loss_mask: 0.3768  decode.d7.loss_dice: 0.4494  decode.d8.loss_cls: 0.8783  decode.d8.loss_mask: 0.3820  decode.d8.loss_dice: 0.4218
07/29 23:29:56 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/29 23:30:09 - mmengine - INFO - Iter(train) [ 3700/80000]  base_lr: 9.5829e-05 lr: 9.5829e-06  eta: 11:16:29  time: 0.5298  data_time: 0.0134  memory: 5896  grad_norm: 124.8683  loss: 13.0750  decode.loss_cls: 0.5208  decode.loss_mask: 0.2749  decode.loss_dice: 0.2862  decode.d0.loss_cls: 1.8264  decode.d0.loss_mask: 0.3017  decode.d0.loss_dice: 0.3514  decode.d1.loss_cls: 0.7386  decode.d1.loss_mask: 0.2886  decode.d1.loss_dice: 0.2988  decode.d2.loss_cls: 0.6500  decode.d2.loss_mask: 0.2856  decode.d2.loss_dice: 0.2877  decode.d3.loss_cls: 0.5807  decode.d3.loss_mask: 0.2831  decode.d3.loss_dice: 0.3091  decode.d4.loss_cls: 0.6155  decode.d4.loss_mask: 0.2873  decode.d4.loss_dice: 0.3130  decode.d5.loss_cls: 0.5987  decode.d5.loss_mask: 0.2795  decode.d5.loss_dice: 0.2793  decode.d6.loss_cls: 0.5477  decode.d6.loss_mask: 0.2780  decode.d6.loss_dice: 0.2880  decode.d7.loss_cls: 0.5772  decode.d7.loss_mask: 0.2748  decode.d7.loss_dice: 0.2802  decode.d8.loss_cls: 0.6052  decode.d8.loss_mask: 0.2768  decode.d8.loss_dice: 0.2903
07/29 23:30:35 - mmengine - INFO - Iter(train) [ 3750/80000]  base_lr: 9.5772e-05 lr: 9.5772e-06  eta: 11:16:00  time: 0.5280  data_time: 0.0132  memory: 5918  grad_norm: 267.9656  loss: 15.4775  decode.loss_cls: 0.7595  decode.loss_mask: 0.2748  decode.loss_dice: 0.3787  decode.d0.loss_cls: 1.9237  decode.d0.loss_mask: 0.2435  decode.d0.loss_dice: 0.4517  decode.d1.loss_cls: 1.0417  decode.d1.loss_mask: 0.2508  decode.d1.loss_dice: 0.3610  decode.d2.loss_cls: 0.7604  decode.d2.loss_mask: 0.2759  decode.d2.loss_dice: 0.3794  decode.d3.loss_cls: 0.7238  decode.d3.loss_mask: 0.2744  decode.d3.loss_dice: 0.3531  decode.d4.loss_cls: 0.7265  decode.d4.loss_mask: 0.2464  decode.d4.loss_dice: 0.3477  decode.d5.loss_cls: 0.8172  decode.d5.loss_mask: 0.2427  decode.d5.loss_dice: 0.3589  decode.d6.loss_cls: 0.7909  decode.d6.loss_mask: 0.2552  decode.d6.loss_dice: 0.3458  decode.d7.loss_cls: 0.8404  decode.d7.loss_mask: 0.2682  decode.d7.loss_dice: 0.3486  decode.d8.loss_cls: 0.7965  decode.d8.loss_mask: 0.2765  decode.d8.loss_dice: 0.3637
07/29 23:31:02 - mmengine - INFO - Iter(train) [ 3800/80000]  base_lr: 9.5716e-05 lr: 9.5716e-06  eta: 11:15:31  time: 0.5343  data_time: 0.0135  memory: 5916  grad_norm: 304.2752  loss: 20.7971  decode.loss_cls: 0.8967  decode.loss_mask: 0.5076  decode.loss_dice: 0.5413  decode.d0.loss_cls: 1.8603  decode.d0.loss_mask: 0.4823  decode.d0.loss_dice: 0.6276  decode.d1.loss_cls: 1.1732  decode.d1.loss_mask: 0.5009  decode.d1.loss_dice: 0.5536  decode.d2.loss_cls: 1.1175  decode.d2.loss_mask: 0.4874  decode.d2.loss_dice: 0.5320  decode.d3.loss_cls: 0.9141  decode.d3.loss_mask: 0.5053  decode.d3.loss_dice: 0.5442  decode.d4.loss_cls: 0.8543  decode.d4.loss_mask: 0.4873  decode.d4.loss_dice: 0.5316  decode.d5.loss_cls: 0.8917  decode.d5.loss_mask: 0.4867  decode.d5.loss_dice: 0.5167  decode.d6.loss_cls: 0.8124  decode.d6.loss_mask: 0.4935  decode.d6.loss_dice: 0.5559  decode.d7.loss_cls: 0.8134  decode.d7.loss_mask: 0.5420  decode.d7.loss_dice: 0.5612  decode.d8.loss_cls: 0.9701  decode.d8.loss_mask: 0.5058  decode.d8.loss_dice: 0.5306
07/29 23:31:28 - mmengine - INFO - Iter(train) [ 3850/80000]  base_lr: 9.5659e-05 lr: 9.5659e-06  eta: 11:15:01  time: 0.5283  data_time: 0.0132  memory: 5916  grad_norm: 260.4887  loss: 14.2548  decode.loss_cls: 0.5940  decode.loss_mask: 0.3358  decode.loss_dice: 0.3670  decode.d0.loss_cls: 1.8815  decode.d0.loss_mask: 0.3173  decode.d0.loss_dice: 0.4475  decode.d1.loss_cls: 0.9126  decode.d1.loss_mask: 0.3116  decode.d1.loss_dice: 0.3461  decode.d2.loss_cls: 0.6161  decode.d2.loss_mask: 0.2924  decode.d2.loss_dice: 0.3466  decode.d3.loss_cls: 0.5799  decode.d3.loss_mask: 0.2956  decode.d3.loss_dice: 0.3375  decode.d4.loss_cls: 0.5717  decode.d4.loss_mask: 0.3082  decode.d4.loss_dice: 0.3373  decode.d5.loss_cls: 0.5213  decode.d5.loss_mask: 0.3192  decode.d5.loss_dice: 0.3735  decode.d6.loss_cls: 0.5616  decode.d6.loss_mask: 0.3283  decode.d6.loss_dice: 0.3673  decode.d7.loss_cls: 0.6124  decode.d7.loss_mask: 0.3138  decode.d7.loss_dice: 0.3810  decode.d8.loss_cls: 0.6152  decode.d8.loss_mask: 0.3144  decode.d8.loss_dice: 0.3480
07/29 23:31:55 - mmengine - INFO - Iter(train) [ 3900/80000]  base_lr: 9.5603e-05 lr: 9.5603e-06  eta: 11:14:31  time: 0.5289  data_time: 0.0132  memory: 5895  grad_norm: 366.1444  loss: 18.2245  decode.loss_cls: 0.7031  decode.loss_mask: 0.4824  decode.loss_dice: 0.6365  decode.d0.loss_cls: 1.7396  decode.d0.loss_mask: 0.3976  decode.d0.loss_dice: 0.5368  decode.d1.loss_cls: 0.8432  decode.d1.loss_mask: 0.4148  decode.d1.loss_dice: 0.5357  decode.d2.loss_cls: 0.7391  decode.d2.loss_mask: 0.4066  decode.d2.loss_dice: 0.5071  decode.d3.loss_cls: 0.6527  decode.d3.loss_mask: 0.3923  decode.d3.loss_dice: 0.5213  decode.d4.loss_cls: 0.6522  decode.d4.loss_mask: 0.4282  decode.d4.loss_dice: 0.5670  decode.d5.loss_cls: 0.7018  decode.d5.loss_mask: 0.4167  decode.d5.loss_dice: 0.5531  decode.d6.loss_cls: 0.7294  decode.d6.loss_mask: 0.4500  decode.d6.loss_dice: 0.6088  decode.d7.loss_cls: 0.7140  decode.d7.loss_mask: 0.4375  decode.d7.loss_dice: 0.6305  decode.d8.loss_cls: 0.6861  decode.d8.loss_mask: 0.5035  decode.d8.loss_dice: 0.6369
07/29 23:32:21 - mmengine - INFO - Iter(train) [ 3950/80000]  base_lr: 9.5546e-05 lr: 9.5546e-06  eta: 11:13:58  time: 0.5248  data_time: 0.0130  memory: 5936  grad_norm: 312.5097  loss: 17.5014  decode.loss_cls: 0.7547  decode.loss_mask: 0.4706  decode.loss_dice: 0.4007  decode.d0.loss_cls: 1.7179  decode.d0.loss_mask: 0.4499  decode.d0.loss_dice: 0.4256  decode.d1.loss_cls: 0.9083  decode.d1.loss_mask: 0.4568  decode.d1.loss_dice: 0.4013  decode.d2.loss_cls: 0.7145  decode.d2.loss_mask: 0.4313  decode.d2.loss_dice: 0.4166  decode.d3.loss_cls: 0.7869  decode.d3.loss_mask: 0.4118  decode.d3.loss_dice: 0.3858  decode.d4.loss_cls: 0.8744  decode.d4.loss_mask: 0.4589  decode.d4.loss_dice: 0.3928  decode.d5.loss_cls: 0.8354  decode.d5.loss_mask: 0.4658  decode.d5.loss_dice: 0.3935  decode.d6.loss_cls: 0.7601  decode.d6.loss_mask: 0.4478  decode.d6.loss_dice: 0.4169  decode.d7.loss_cls: 0.8227  decode.d7.loss_mask: 0.4136  decode.d7.loss_dice: 0.4117  decode.d8.loss_cls: 0.8232  decode.d8.loss_mask: 0.4484  decode.d8.loss_dice: 0.4033
07/29 23:32:47 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/29 23:32:47 - mmengine - INFO - Iter(train) [ 4000/80000]  base_lr: 9.5490e-05 lr: 9.5490e-06  eta: 11:13:25  time: 0.5201  data_time: 0.0131  memory: 5986  grad_norm: 259.3094  loss: 15.9370  decode.loss_cls: 0.7906  decode.loss_mask: 0.3168  decode.loss_dice: 0.4675  decode.d0.loss_cls: 1.7550  decode.d0.loss_mask: 0.3240  decode.d0.loss_dice: 0.4910  decode.d1.loss_cls: 1.0138  decode.d1.loss_mask: 0.3212  decode.d1.loss_dice: 0.4220  decode.d2.loss_cls: 0.7955  decode.d2.loss_mask: 0.3377  decode.d2.loss_dice: 0.4059  decode.d3.loss_cls: 0.7063  decode.d3.loss_mask: 0.3280  decode.d3.loss_dice: 0.4150  decode.d4.loss_cls: 0.7066  decode.d4.loss_mask: 0.3210  decode.d4.loss_dice: 0.4091  decode.d5.loss_cls: 0.6522  decode.d5.loss_mask: 0.3364  decode.d5.loss_dice: 0.4533  decode.d6.loss_cls: 0.6065  decode.d6.loss_mask: 0.3222  decode.d6.loss_dice: 0.4403  decode.d7.loss_cls: 0.6686  decode.d7.loss_mask: 0.3182  decode.d7.loss_dice: 0.4463  decode.d8.loss_cls: 0.6221  decode.d8.loss_mask: 0.3135  decode.d8.loss_dice: 0.4305
07/29 23:33:13 - mmengine - INFO - Iter(train) [ 4050/80000]  base_lr: 9.5433e-05 lr: 9.5433e-06  eta: 11:12:54  time: 0.5253  data_time: 0.0126  memory: 5898  grad_norm: 219.0007  loss: 16.3773  decode.loss_cls: 0.7896  decode.loss_mask: 0.3734  decode.loss_dice: 0.3467  decode.d0.loss_cls: 1.7646  decode.d0.loss_mask: 0.3696  decode.d0.loss_dice: 0.4014  decode.d1.loss_cls: 0.9636  decode.d1.loss_mask: 0.3970  decode.d1.loss_dice: 0.3741  decode.d2.loss_cls: 0.6591  decode.d2.loss_mask: 0.4195  decode.d2.loss_dice: 0.3930  decode.d3.loss_cls: 0.6891  decode.d3.loss_mask: 0.4248  decode.d3.loss_dice: 0.3789  decode.d4.loss_cls: 0.7482  decode.d4.loss_mask: 0.4239  decode.d4.loss_dice: 0.3963  decode.d5.loss_cls: 0.7718  decode.d5.loss_mask: 0.4053  decode.d5.loss_dice: 0.3918  decode.d6.loss_cls: 0.6921  decode.d6.loss_mask: 0.3993  decode.d6.loss_dice: 0.3894  decode.d7.loss_cls: 0.7873  decode.d7.loss_mask: 0.3696  decode.d7.loss_dice: 0.3647  decode.d8.loss_cls: 0.7554  decode.d8.loss_mask: 0.3791  decode.d8.loss_dice: 0.3586
07/29 23:33:40 - mmengine - INFO - Iter(train) [ 4100/80000]  base_lr: 9.5377e-05 lr: 9.5377e-06  eta: 11:12:26  time: 0.5317  data_time: 0.0134  memory: 5971  grad_norm: 177.3869  loss: 14.8608  decode.loss_cls: 0.5547  decode.loss_mask: 0.3167  decode.loss_dice: 0.4137  decode.d0.loss_cls: 1.7590  decode.d0.loss_mask: 0.3346  decode.d0.loss_dice: 0.4673  decode.d1.loss_cls: 0.9562  decode.d1.loss_mask: 0.3425  decode.d1.loss_dice: 0.3911  decode.d2.loss_cls: 0.7236  decode.d2.loss_mask: 0.3156  decode.d2.loss_dice: 0.3867  decode.d3.loss_cls: 0.6118  decode.d3.loss_mask: 0.3103  decode.d3.loss_dice: 0.3805  decode.d4.loss_cls: 0.5644  decode.d4.loss_mask: 0.3112  decode.d4.loss_dice: 0.3963  decode.d5.loss_cls: 0.5820  decode.d5.loss_mask: 0.3222  decode.d5.loss_dice: 0.4188  decode.d6.loss_cls: 0.6162  decode.d6.loss_mask: 0.3198  decode.d6.loss_dice: 0.4102  decode.d7.loss_cls: 0.5609  decode.d7.loss_mask: 0.3213  decode.d7.loss_dice: 0.4193  decode.d8.loss_cls: 0.6262  decode.d8.loss_mask: 0.3201  decode.d8.loss_dice: 0.4076
07/29 23:34:06 - mmengine - INFO - Iter(train) [ 4150/80000]  base_lr: 9.5320e-05 lr: 9.5320e-06  eta: 11:11:59  time: 0.5288  data_time: 0.0134  memory: 5895  grad_norm: 488.9188  loss: 16.4694  decode.loss_cls: 0.5835  decode.loss_mask: 0.5532  decode.loss_dice: 0.4388  decode.d0.loss_cls: 1.5318  decode.d0.loss_mask: 0.5044  decode.d0.loss_dice: 0.4716  decode.d1.loss_cls: 0.8081  decode.d1.loss_mask: 0.5147  decode.d1.loss_dice: 0.4378  decode.d2.loss_cls: 0.5951  decode.d2.loss_mask: 0.5154  decode.d2.loss_dice: 0.4355  decode.d3.loss_cls: 0.6179  decode.d3.loss_mask: 0.5093  decode.d3.loss_dice: 0.4052  decode.d4.loss_cls: 0.5928  decode.d4.loss_mask: 0.4942  decode.d4.loss_dice: 0.4020  decode.d5.loss_cls: 0.5713  decode.d5.loss_mask: 0.4960  decode.d5.loss_dice: 0.3907  decode.d6.loss_cls: 0.5984  decode.d6.loss_mask: 0.5010  decode.d6.loss_dice: 0.4305  decode.d7.loss_cls: 0.6005  decode.d7.loss_mask: 0.4971  decode.d7.loss_dice: 0.4221  decode.d8.loss_cls: 0.6036  decode.d8.loss_mask: 0.5168  decode.d8.loss_dice: 0.4301
07/29 23:34:33 - mmengine - INFO - Iter(train) [ 4200/80000]  base_lr: 9.5263e-05 lr: 9.5263e-06  eta: 11:11:34  time: 0.5366  data_time: 0.0131  memory: 5934  grad_norm: 146.8025  loss: 14.0336  decode.loss_cls: 0.6070  decode.loss_mask: 0.2866  decode.loss_dice: 0.3589  decode.d0.loss_cls: 2.0792  decode.d0.loss_mask: 0.2588  decode.d0.loss_dice: 0.3786  decode.d1.loss_cls: 0.7899  decode.d1.loss_mask: 0.2592  decode.d1.loss_dice: 0.3607  decode.d2.loss_cls: 0.6008  decode.d2.loss_mask: 0.2461  decode.d2.loss_dice: 0.3527  decode.d3.loss_cls: 0.6287  decode.d3.loss_mask: 0.2513  decode.d3.loss_dice: 0.3555  decode.d4.loss_cls: 0.6693  decode.d4.loss_mask: 0.2524  decode.d4.loss_dice: 0.3518  decode.d5.loss_cls: 0.6043  decode.d5.loss_mask: 0.2611  decode.d5.loss_dice: 0.3349  decode.d6.loss_cls: 0.6681  decode.d6.loss_mask: 0.2610  decode.d6.loss_dice: 0.3453  decode.d7.loss_cls: 0.6274  decode.d7.loss_mask: 0.2721  decode.d7.loss_dice: 0.3553  decode.d8.loss_cls: 0.6076  decode.d8.loss_mask: 0.2470  decode.d8.loss_dice: 0.3618
07/29 23:35:00 - mmengine - INFO - Iter(train) [ 4250/80000]  base_lr: 9.5207e-05 lr: 9.5207e-06  eta: 11:11:05  time: 0.5213  data_time: 0.0126  memory: 5898  grad_norm: 215.9415  loss: 14.1232  decode.loss_cls: 0.5568  decode.loss_mask: 0.3594  decode.loss_dice: 0.3731  decode.d0.loss_cls: 1.6022  decode.d0.loss_mask: 0.3702  decode.d0.loss_dice: 0.4479  decode.d1.loss_cls: 0.7922  decode.d1.loss_mask: 0.3600  decode.d1.loss_dice: 0.3822  decode.d2.loss_cls: 0.6287  decode.d2.loss_mask: 0.3544  decode.d2.loss_dice: 0.3690  decode.d3.loss_cls: 0.5236  decode.d3.loss_mask: 0.3396  decode.d3.loss_dice: 0.3598  decode.d4.loss_cls: 0.5434  decode.d4.loss_mask: 0.3280  decode.d4.loss_dice: 0.3691  decode.d5.loss_cls: 0.5500  decode.d5.loss_mask: 0.3237  decode.d5.loss_dice: 0.3516  decode.d6.loss_cls: 0.5687  decode.d6.loss_mask: 0.3288  decode.d6.loss_dice: 0.3535  decode.d7.loss_cls: 0.5663  decode.d7.loss_mask: 0.3332  decode.d7.loss_dice: 0.3624  decode.d8.loss_cls: 0.5662  decode.d8.loss_mask: 0.3791  decode.d8.loss_dice: 0.3803
07/29 23:35:26 - mmengine - INFO - Iter(train) [ 4300/80000]  base_lr: 9.5150e-05 lr: 9.5150e-06  eta: 11:10:38  time: 0.5290  data_time: 0.0129  memory: 5918  grad_norm: 186.7846  loss: 14.7261  decode.loss_cls: 0.5679  decode.loss_mask: 0.3239  decode.loss_dice: 0.4275  decode.d0.loss_cls: 1.7166  decode.d0.loss_mask: 0.3479  decode.d0.loss_dice: 0.4928  decode.d1.loss_cls: 0.8111  decode.d1.loss_mask: 0.3248  decode.d1.loss_dice: 0.4192  decode.d2.loss_cls: 0.6303  decode.d2.loss_mask: 0.3327  decode.d2.loss_dice: 0.4762  decode.d3.loss_cls: 0.5601  decode.d3.loss_mask: 0.3398  decode.d3.loss_dice: 0.4725  decode.d4.loss_cls: 0.5370  decode.d4.loss_mask: 0.3224  decode.d4.loss_dice: 0.4294  decode.d5.loss_cls: 0.5299  decode.d5.loss_mask: 0.3129  decode.d5.loss_dice: 0.4419  decode.d6.loss_cls: 0.5692  decode.d6.loss_mask: 0.3188  decode.d6.loss_dice: 0.4226  decode.d7.loss_cls: 0.5606  decode.d7.loss_mask: 0.3118  decode.d7.loss_dice: 0.4254  decode.d8.loss_cls: 0.5381  decode.d8.loss_mask: 0.3171  decode.d8.loss_dice: 0.4459
07/29 23:35:52 - mmengine - INFO - Iter(train) [ 4350/80000]  base_lr: 9.5094e-05 lr: 9.5094e-06  eta: 11:10:07  time: 0.5196  data_time: 0.0130  memory: 5897  grad_norm: 173.4107  loss: 12.8778  decode.loss_cls: 0.5675  decode.loss_mask: 0.2962  decode.loss_dice: 0.3749  decode.d0.loss_cls: 1.5933  decode.d0.loss_mask: 0.3097  decode.d0.loss_dice: 0.4074  decode.d1.loss_cls: 0.6508  decode.d1.loss_mask: 0.3084  decode.d1.loss_dice: 0.3859  decode.d2.loss_cls: 0.5241  decode.d2.loss_mask: 0.3043  decode.d2.loss_dice: 0.3709  decode.d3.loss_cls: 0.4230  decode.d3.loss_mask: 0.3212  decode.d3.loss_dice: 0.4020  decode.d4.loss_cls: 0.3830  decode.d4.loss_mask: 0.3222  decode.d4.loss_dice: 0.3906  decode.d5.loss_cls: 0.4011  decode.d5.loss_mask: 0.3326  decode.d5.loss_dice: 0.4080  decode.d6.loss_cls: 0.4167  decode.d6.loss_mask: 0.3220  decode.d6.loss_dice: 0.3838  decode.d7.loss_cls: 0.4001  decode.d7.loss_mask: 0.3096  decode.d7.loss_dice: 0.3929  decode.d8.loss_cls: 0.4812  decode.d8.loss_mask: 0.3086  decode.d8.loss_dice: 0.3858
07/29 23:36:19 - mmengine - INFO - Iter(train) [ 4400/80000]  base_lr: 9.5037e-05 lr: 9.5037e-06  eta: 11:09:36  time: 0.5244  data_time: 0.0129  memory: 5933  grad_norm: 156.0285  loss: 16.8025  decode.loss_cls: 0.7519  decode.loss_mask: 0.3653  decode.loss_dice: 0.3715  decode.d0.loss_cls: 2.1427  decode.d0.loss_mask: 0.3823  decode.d0.loss_dice: 0.4621  decode.d1.loss_cls: 1.1309  decode.d1.loss_mask: 0.3805  decode.d1.loss_dice: 0.4153  decode.d2.loss_cls: 0.8250  decode.d2.loss_mask: 0.3645  decode.d2.loss_dice: 0.3448  decode.d3.loss_cls: 0.7233  decode.d3.loss_mask: 0.3621  decode.d3.loss_dice: 0.3737  decode.d4.loss_cls: 0.7132  decode.d4.loss_mask: 0.3710  decode.d4.loss_dice: 0.3659  decode.d5.loss_cls: 0.7831  decode.d5.loss_mask: 0.3783  decode.d5.loss_dice: 0.3676  decode.d6.loss_cls: 0.7107  decode.d6.loss_mask: 0.3656  decode.d6.loss_dice: 0.3705  decode.d7.loss_cls: 0.7619  decode.d7.loss_mask: 0.3673  decode.d7.loss_dice: 0.3281  decode.d8.loss_cls: 0.7952  decode.d8.loss_mask: 0.3702  decode.d8.loss_dice: 0.3580
07/29 23:36:45 - mmengine - INFO - Iter(train) [ 4450/80000]  base_lr: 9.4981e-05 lr: 9.4981e-06  eta: 11:09:09  time: 0.5321  data_time: 0.0130  memory: 5934  grad_norm: 165.9782  loss: 13.2008  decode.loss_cls: 0.4769  decode.loss_mask: 0.3370  decode.loss_dice: 0.3173  decode.d0.loss_cls: 1.4380  decode.d0.loss_mask: 0.3354  decode.d0.loss_dice: 0.4185  decode.d1.loss_cls: 0.7171  decode.d1.loss_mask: 0.3613  decode.d1.loss_dice: 0.4133  decode.d2.loss_cls: 0.6052  decode.d2.loss_mask: 0.3445  decode.d2.loss_dice: 0.3770  decode.d3.loss_cls: 0.4431  decode.d3.loss_mask: 0.3408  decode.d3.loss_dice: 0.3711  decode.d4.loss_cls: 0.4763  decode.d4.loss_mask: 0.3210  decode.d4.loss_dice: 0.3739  decode.d5.loss_cls: 0.5443  decode.d5.loss_mask: 0.3283  decode.d5.loss_dice: 0.3726  decode.d6.loss_cls: 0.4500  decode.d6.loss_mask: 0.3332  decode.d6.loss_dice: 0.3488  decode.d7.loss_cls: 0.5315  decode.d7.loss_mask: 0.3305  decode.d7.loss_dice: 0.3677  decode.d8.loss_cls: 0.4711  decode.d8.loss_mask: 0.3273  decode.d8.loss_dice: 0.3280
07/29 23:37:12 - mmengine - INFO - Iter(train) [ 4500/80000]  base_lr: 9.4924e-05 lr: 9.4924e-06  eta: 11:08:38  time: 0.5237  data_time: 0.0126  memory: 5931  grad_norm: 404.6798  loss: 14.1398  decode.loss_cls: 0.6043  decode.loss_mask: 0.3446  decode.loss_dice: 0.3283  decode.d0.loss_cls: 1.6131  decode.d0.loss_mask: 0.3678  decode.d0.loss_dice: 0.4212  decode.d1.loss_cls: 0.8580  decode.d1.loss_mask: 0.3431  decode.d1.loss_dice: 0.3428  decode.d2.loss_cls: 0.6254  decode.d2.loss_mask: 0.3599  decode.d2.loss_dice: 0.3642  decode.d3.loss_cls: 0.5795  decode.d3.loss_mask: 0.3527  decode.d3.loss_dice: 0.3329  decode.d4.loss_cls: 0.6089  decode.d4.loss_mask: 0.3506  decode.d4.loss_dice: 0.3257  decode.d5.loss_cls: 0.6363  decode.d5.loss_mask: 0.3411  decode.d5.loss_dice: 0.3413  decode.d6.loss_cls: 0.5245  decode.d6.loss_mask: 0.3397  decode.d6.loss_dice: 0.3508  decode.d7.loss_cls: 0.5207  decode.d7.loss_mask: 0.3369  decode.d7.loss_dice: 0.3207  decode.d8.loss_cls: 0.6011  decode.d8.loss_mask: 0.3441  decode.d8.loss_dice: 0.3594
07/29 23:37:38 - mmengine - INFO - Iter(train) [ 4550/80000]  base_lr: 9.4867e-05 lr: 9.4867e-06  eta: 11:08:08  time: 0.5315  data_time: 0.0132  memory: 5918  grad_norm: 188.3572  loss: 14.8152  decode.loss_cls: 0.6621  decode.loss_mask: 0.3389  decode.loss_dice: 0.4237  decode.d0.loss_cls: 1.6298  decode.d0.loss_mask: 0.3398  decode.d0.loss_dice: 0.4427  decode.d1.loss_cls: 0.7954  decode.d1.loss_mask: 0.3360  decode.d1.loss_dice: 0.3987  decode.d2.loss_cls: 0.6411  decode.d2.loss_mask: 0.3289  decode.d2.loss_dice: 0.4014  decode.d3.loss_cls: 0.5476  decode.d3.loss_mask: 0.3262  decode.d3.loss_dice: 0.4120  decode.d4.loss_cls: 0.5843  decode.d4.loss_mask: 0.3256  decode.d4.loss_dice: 0.4298  decode.d5.loss_cls: 0.6224  decode.d5.loss_mask: 0.3292  decode.d5.loss_dice: 0.4425  decode.d6.loss_cls: 0.6086  decode.d6.loss_mask: 0.3291  decode.d6.loss_dice: 0.3953  decode.d7.loss_cls: 0.5920  decode.d7.loss_mask: 0.3318  decode.d7.loss_dice: 0.4067  decode.d8.loss_cls: 0.6515  decode.d8.loss_mask: 0.3234  decode.d8.loss_dice: 0.4187
07/29 23:38:04 - mmengine - INFO - Iter(train) [ 4600/80000]  base_lr: 9.4811e-05 lr: 9.4811e-06  eta: 11:07:39  time: 0.5285  data_time: 0.0128  memory: 5895  grad_norm: 435.1632  loss: 16.9080  decode.loss_cls: 0.7308  decode.loss_mask: 0.4298  decode.loss_dice: 0.4249  decode.d0.loss_cls: 1.8993  decode.d0.loss_mask: 0.4252  decode.d0.loss_dice: 0.4586  decode.d1.loss_cls: 0.7721  decode.d1.loss_mask: 0.5047  decode.d1.loss_dice: 0.4846  decode.d2.loss_cls: 0.7091  decode.d2.loss_mask: 0.4482  decode.d2.loss_dice: 0.4314  decode.d3.loss_cls: 0.5893  decode.d3.loss_mask: 0.4355  decode.d3.loss_dice: 0.4356  decode.d4.loss_cls: 0.7364  decode.d4.loss_mask: 0.4129  decode.d4.loss_dice: 0.3969  decode.d5.loss_cls: 0.6576  decode.d5.loss_mask: 0.4229  decode.d5.loss_dice: 0.4072  decode.d6.loss_cls: 0.7075  decode.d6.loss_mask: 0.4046  decode.d6.loss_dice: 0.4037  decode.d7.loss_cls: 0.7775  decode.d7.loss_mask: 0.4190  decode.d7.loss_dice: 0.4201  decode.d8.loss_cls: 0.7262  decode.d8.loss_mask: 0.4148  decode.d8.loss_dice: 0.4215
07/29 23:38:31 - mmengine - INFO - Iter(train) [ 4650/80000]  base_lr: 9.4754e-05 lr: 9.4754e-06  eta: 11:07:11  time: 0.5342  data_time: 0.0137  memory: 5896  grad_norm: 296.3015  loss: 17.1051  decode.loss_cls: 0.7656  decode.loss_mask: 0.3506  decode.loss_dice: 0.4697  decode.d0.loss_cls: 1.7926  decode.d0.loss_mask: 0.3553  decode.d0.loss_dice: 0.5882  decode.d1.loss_cls: 0.8997  decode.d1.loss_mask: 0.3827  decode.d1.loss_dice: 0.5583  decode.d2.loss_cls: 0.7778  decode.d2.loss_mask: 0.3616  decode.d2.loss_dice: 0.4751  decode.d3.loss_cls: 0.7642  decode.d3.loss_mask: 0.3577  decode.d3.loss_dice: 0.4680  decode.d4.loss_cls: 0.7228  decode.d4.loss_mask: 0.3552  decode.d4.loss_dice: 0.4611  decode.d5.loss_cls: 0.7117  decode.d5.loss_mask: 0.3414  decode.d5.loss_dice: 0.4400  decode.d6.loss_cls: 0.6837  decode.d6.loss_mask: 0.3537  decode.d6.loss_dice: 0.4625  decode.d7.loss_cls: 0.7689  decode.d7.loss_mask: 0.3477  decode.d7.loss_dice: 0.4974  decode.d8.loss_cls: 0.7533  decode.d8.loss_mask: 0.3477  decode.d8.loss_dice: 0.4908
07/29 23:38:57 - mmengine - INFO - Iter(train) [ 4700/80000]  base_lr: 9.4698e-05 lr: 9.4698e-06  eta: 11:06:40  time: 0.5210  data_time: 0.0127  memory: 5918  grad_norm: 238.9813  loss: 13.3096  decode.loss_cls: 0.5546  decode.loss_mask: 0.3004  decode.loss_dice: 0.3943  decode.d0.loss_cls: 1.4233  decode.d0.loss_mask: 0.2998  decode.d0.loss_dice: 0.4334  decode.d1.loss_cls: 0.6834  decode.d1.loss_mask: 0.2993  decode.d1.loss_dice: 0.3954  decode.d2.loss_cls: 0.5499  decode.d2.loss_mask: 0.2980  decode.d2.loss_dice: 0.3852  decode.d3.loss_cls: 0.5204  decode.d3.loss_mask: 0.2894  decode.d3.loss_dice: 0.3491  decode.d4.loss_cls: 0.5376  decode.d4.loss_mask: 0.2865  decode.d4.loss_dice: 0.3518  decode.d5.loss_cls: 0.5263  decode.d5.loss_mask: 0.2855  decode.d5.loss_dice: 0.3616  decode.d6.loss_cls: 0.5100  decode.d6.loss_mask: 0.2875  decode.d6.loss_dice: 0.3983  decode.d7.loss_cls: 0.5341  decode.d7.loss_mask: 0.3061  decode.d7.loss_dice: 0.3904  decode.d8.loss_cls: 0.6002  decode.d8.loss_mask: 0.3300  decode.d8.loss_dice: 0.4280
07/29 23:39:23 - mmengine - INFO - Iter(train) [ 4750/80000]  base_lr: 9.4641e-05 lr: 9.4641e-06  eta: 11:06:10  time: 0.5266  data_time: 0.0130  memory: 5897  grad_norm: 231.8507  loss: 16.2499  decode.loss_cls: 0.6547  decode.loss_mask: 0.3028  decode.loss_dice: 0.4808  decode.d0.loss_cls: 1.9685  decode.d0.loss_mask: 0.3232  decode.d0.loss_dice: 0.5649  decode.d1.loss_cls: 0.9626  decode.d1.loss_mask: 0.2918  decode.d1.loss_dice: 0.4436  decode.d2.loss_cls: 0.8608  decode.d2.loss_mask: 0.2939  decode.d2.loss_dice: 0.4414  decode.d3.loss_cls: 0.7007  decode.d3.loss_mask: 0.2955  decode.d3.loss_dice: 0.4485  decode.d4.loss_cls: 0.6594  decode.d4.loss_mask: 0.3307  decode.d4.loss_dice: 0.5030  decode.d5.loss_cls: 0.6302  decode.d5.loss_mask: 0.3424  decode.d5.loss_dice: 0.4612  decode.d6.loss_cls: 0.6372  decode.d6.loss_mask: 0.3524  decode.d6.loss_dice: 0.4572  decode.d7.loss_cls: 0.5945  decode.d7.loss_mask: 0.2992  decode.d7.loss_dice: 0.4686  decode.d8.loss_cls: 0.7005  decode.d8.loss_mask: 0.3034  decode.d8.loss_dice: 0.4762
07/29 23:39:50 - mmengine - INFO - Iter(train) [ 4800/80000]  base_lr: 9.4584e-05 lr: 9.4584e-06  eta: 11:05:37  time: 0.5280  data_time: 0.0131  memory: 5973  grad_norm: 157.2310  loss: 15.0934  decode.loss_cls: 0.6305  decode.loss_mask: 0.3981  decode.loss_dice: 0.4124  decode.d0.loss_cls: 1.4129  decode.d0.loss_mask: 0.4038  decode.d0.loss_dice: 0.4498  decode.d1.loss_cls: 0.8089  decode.d1.loss_mask: 0.4169  decode.d1.loss_dice: 0.4269  decode.d2.loss_cls: 0.6752  decode.d2.loss_mask: 0.4057  decode.d2.loss_dice: 0.3961  decode.d3.loss_cls: 0.4841  decode.d3.loss_mask: 0.4040  decode.d3.loss_dice: 0.3932  decode.d4.loss_cls: 0.5333  decode.d4.loss_mask: 0.4003  decode.d4.loss_dice: 0.4157  decode.d5.loss_cls: 0.5512  decode.d5.loss_mask: 0.4073  decode.d5.loss_dice: 0.4225  decode.d6.loss_cls: 0.5717  decode.d6.loss_mask: 0.4070  decode.d6.loss_dice: 0.4058  decode.d7.loss_cls: 0.5885  decode.d7.loss_mask: 0.4088  decode.d7.loss_dice: 0.4285  decode.d8.loss_cls: 0.6073  decode.d8.loss_mask: 0.4050  decode.d8.loss_dice: 0.4220
07/29 23:40:16 - mmengine - INFO - Iter(train) [ 4850/80000]  base_lr: 9.4528e-05 lr: 9.4528e-06  eta: 11:05:10  time: 0.5290  data_time: 0.0136  memory: 5937  grad_norm: 164.6204  loss: 14.2201  decode.loss_cls: 0.5838  decode.loss_mask: 0.4628  decode.loss_dice: 0.3913  decode.d0.loss_cls: 1.6545  decode.d0.loss_mask: 0.3672  decode.d0.loss_dice: 0.4370  decode.d1.loss_cls: 0.6634  decode.d1.loss_mask: 0.3745  decode.d1.loss_dice: 0.3657  decode.d2.loss_cls: 0.4556  decode.d2.loss_mask: 0.3653  decode.d2.loss_dice: 0.3545  decode.d3.loss_cls: 0.4553  decode.d3.loss_mask: 0.3474  decode.d3.loss_dice: 0.3422  decode.d4.loss_cls: 0.5325  decode.d4.loss_mask: 0.3540  decode.d4.loss_dice: 0.3642  decode.d5.loss_cls: 0.5534  decode.d5.loss_mask: 0.3587  decode.d5.loss_dice: 0.3845  decode.d6.loss_cls: 0.5337  decode.d6.loss_mask: 0.3683  decode.d6.loss_dice: 0.4061  decode.d7.loss_cls: 0.5552  decode.d7.loss_mask: 0.4088  decode.d7.loss_dice: 0.3985  decode.d8.loss_cls: 0.5432  decode.d8.loss_mask: 0.4128  decode.d8.loss_dice: 0.4255
07/29 23:40:43 - mmengine - INFO - Iter(train) [ 4900/80000]  base_lr: 9.4471e-05 lr: 9.4471e-06  eta: 11:04:43  time: 0.5296  data_time: 0.0132  memory: 5934  grad_norm: 473.5248  loss: 16.5246  decode.loss_cls: 0.5933  decode.loss_mask: 0.4530  decode.loss_dice: 0.4915  decode.d0.loss_cls: 1.7442  decode.d0.loss_mask: 0.5089  decode.d0.loss_dice: 0.5582  decode.d1.loss_cls: 0.7243  decode.d1.loss_mask: 0.4857  decode.d1.loss_dice: 0.4939  decode.d2.loss_cls: 0.6096  decode.d2.loss_mask: 0.4533  decode.d2.loss_dice: 0.5121  decode.d3.loss_cls: 0.4936  decode.d3.loss_mask: 0.4743  decode.d3.loss_dice: 0.4873  decode.d4.loss_cls: 0.4791  decode.d4.loss_mask: 0.4651  decode.d4.loss_dice: 0.4928  decode.d5.loss_cls: 0.5058  decode.d5.loss_mask: 0.4947  decode.d5.loss_dice: 0.4940  decode.d6.loss_cls: 0.4816  decode.d6.loss_mask: 0.4590  decode.d6.loss_dice: 0.4971  decode.d7.loss_cls: 0.5521  decode.d7.loss_mask: 0.4873  decode.d7.loss_dice: 0.5191  decode.d8.loss_cls: 0.5778  decode.d8.loss_mask: 0.4381  decode.d8.loss_dice: 0.4979
07/29 23:41:09 - mmengine - INFO - Iter(train) [ 4950/80000]  base_lr: 9.4415e-05 lr: 9.4415e-06  eta: 11:04:19  time: 0.5312  data_time: 0.0135  memory: 5971  grad_norm: 157.6805  loss: 12.5807  decode.loss_cls: 0.3993  decode.loss_mask: 0.3419  decode.loss_dice: 0.3688  decode.d0.loss_cls: 1.4759  decode.d0.loss_mask: 0.3718  decode.d0.loss_dice: 0.4283  decode.d1.loss_cls: 0.5833  decode.d1.loss_mask: 0.3171  decode.d1.loss_dice: 0.3673  decode.d2.loss_cls: 0.4552  decode.d2.loss_mask: 0.3348  decode.d2.loss_dice: 0.3804  decode.d3.loss_cls: 0.3553  decode.d3.loss_mask: 0.3400  decode.d3.loss_dice: 0.3800  decode.d4.loss_cls: 0.4089  decode.d4.loss_mask: 0.3411  decode.d4.loss_dice: 0.3804  decode.d5.loss_cls: 0.4019  decode.d5.loss_mask: 0.3348  decode.d5.loss_dice: 0.3698  decode.d6.loss_cls: 0.3849  decode.d6.loss_mask: 0.3373  decode.d6.loss_dice: 0.3704  decode.d7.loss_cls: 0.4830  decode.d7.loss_mask: 0.3373  decode.d7.loss_dice: 0.3954  decode.d8.loss_cls: 0.4132  decode.d8.loss_mask: 0.3373  decode.d8.loss_dice: 0.3859
07/29 23:41:36 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/29 23:41:36 - mmengine - INFO - Iter(train) [ 5000/80000]  base_lr: 9.4358e-05 lr: 9.4358e-06  eta: 11:03:55  time: 0.5362  data_time: 0.0134  memory: 5918  grad_norm: 184.9373  loss: 13.5904  decode.loss_cls: 0.5099  decode.loss_mask: 0.3666  decode.loss_dice: 0.3530  decode.d0.loss_cls: 1.4187  decode.d0.loss_mask: 0.3929  decode.d0.loss_dice: 0.4024  decode.d1.loss_cls: 0.5848  decode.d1.loss_mask: 0.3980  decode.d1.loss_dice: 0.4215  decode.d2.loss_cls: 0.4829  decode.d2.loss_mask: 0.3819  decode.d2.loss_dice: 0.3567  decode.d3.loss_cls: 0.4693  decode.d3.loss_mask: 0.3677  decode.d3.loss_dice: 0.3766  decode.d4.loss_cls: 0.4969  decode.d4.loss_mask: 0.3703  decode.d4.loss_dice: 0.3524  decode.d5.loss_cls: 0.4661  decode.d5.loss_mask: 0.3826  decode.d5.loss_dice: 0.3763  decode.d6.loss_cls: 0.5196  decode.d6.loss_mask: 0.3704  decode.d6.loss_dice: 0.3682  decode.d7.loss_cls: 0.5785  decode.d7.loss_mask: 0.3639  decode.d7.loss_dice: 0.3587  decode.d8.loss_cls: 0.5554  decode.d8.loss_mask: 0.3680  decode.d8.loss_dice: 0.3800
07/29 23:41:36 - mmengine - INFO - Saving checkpoint at 5000 iterations
07/29 23:42:06 - mmengine - INFO - Iter(train) [ 5050/80000]  base_lr: 9.4301e-05 lr: 9.4301e-06  eta: 11:04:15  time: 0.5390  data_time: 0.0140  memory: 5920  grad_norm: 160.6680  loss: 12.1228  decode.loss_cls: 0.5592  decode.loss_mask: 0.2429  decode.loss_dice: 0.2655  decode.d0.loss_cls: 1.4418  decode.d0.loss_mask: 0.2632  decode.d0.loss_dice: 0.3156  decode.d1.loss_cls: 0.7945  decode.d1.loss_mask: 0.2602  decode.d1.loss_dice: 0.2780  decode.d2.loss_cls: 0.6562  decode.d2.loss_mask: 0.2655  decode.d2.loss_dice: 0.2691  decode.d3.loss_cls: 0.6180  decode.d3.loss_mask: 0.2534  decode.d3.loss_dice: 0.2862  decode.d4.loss_cls: 0.6057  decode.d4.loss_mask: 0.2612  decode.d4.loss_dice: 0.2780  decode.d5.loss_cls: 0.5411  decode.d5.loss_mask: 0.2497  decode.d5.loss_dice: 0.2387  decode.d6.loss_cls: 0.5215  decode.d6.loss_mask: 0.2516  decode.d6.loss_dice: 0.2557  decode.d7.loss_cls: 0.5495  decode.d7.loss_mask: 0.2524  decode.d7.loss_dice: 0.2537  decode.d8.loss_cls: 0.5832  decode.d8.loss_mask: 0.2535  decode.d8.loss_dice: 0.2581
07/29 23:42:32 - mmengine - INFO - Iter(train) [ 5100/80000]  base_lr: 9.4245e-05 lr: 9.4245e-06  eta: 11:03:49  time: 0.5324  data_time: 0.0137  memory: 5897  grad_norm: 178.4771  loss: 13.6017  decode.loss_cls: 0.5098  decode.loss_mask: 0.3280  decode.loss_dice: 0.3611  decode.d0.loss_cls: 1.6425  decode.d0.loss_mask: 0.3355  decode.d0.loss_dice: 0.4483  decode.d1.loss_cls: 0.8071  decode.d1.loss_mask: 0.3239  decode.d1.loss_dice: 0.3641  decode.d2.loss_cls: 0.5104  decode.d2.loss_mask: 0.3209  decode.d2.loss_dice: 0.3828  decode.d3.loss_cls: 0.4893  decode.d3.loss_mask: 0.3473  decode.d3.loss_dice: 0.3530  decode.d4.loss_cls: 0.4897  decode.d4.loss_mask: 0.3517  decode.d4.loss_dice: 0.3592  decode.d5.loss_cls: 0.6172  decode.d5.loss_mask: 0.2918  decode.d5.loss_dice: 0.3446  decode.d6.loss_cls: 0.5566  decode.d6.loss_mask: 0.3098  decode.d6.loss_dice: 0.3565  decode.d7.loss_cls: 0.5401  decode.d7.loss_mask: 0.3033  decode.d7.loss_dice: 0.3476  decode.d8.loss_cls: 0.5469  decode.d8.loss_mask: 0.3156  decode.d8.loss_dice: 0.3470
07/29 23:42:59 - mmengine - INFO - Iter(train) [ 5150/80000]  base_lr: 9.4188e-05 lr: 9.4188e-06  eta: 11:03:23  time: 0.5354  data_time: 0.0139  memory: 5916  grad_norm: 186.0964  loss: 14.3890  decode.loss_cls: 0.4809  decode.loss_mask: 0.3809  decode.loss_dice: 0.4073  decode.d0.loss_cls: 1.6154  decode.d0.loss_mask: 0.4129  decode.d0.loss_dice: 0.4403  decode.d1.loss_cls: 0.5853  decode.d1.loss_mask: 0.4038  decode.d1.loss_dice: 0.4038  decode.d2.loss_cls: 0.5586  decode.d2.loss_mask: 0.3833  decode.d2.loss_dice: 0.3805  decode.d3.loss_cls: 0.5173  decode.d3.loss_mask: 0.3999  decode.d3.loss_dice: 0.3940  decode.d4.loss_cls: 0.5055  decode.d4.loss_mask: 0.3901  decode.d4.loss_dice: 0.3827  decode.d5.loss_cls: 0.5357  decode.d5.loss_mask: 0.3996  decode.d5.loss_dice: 0.3991  decode.d6.loss_cls: 0.5507  decode.d6.loss_mask: 0.3874  decode.d6.loss_dice: 0.3837  decode.d7.loss_cls: 0.5765  decode.d7.loss_mask: 0.4003  decode.d7.loss_dice: 0.3745  decode.d8.loss_cls: 0.5631  decode.d8.loss_mask: 0.3751  decode.d8.loss_dice: 0.4011
07/29 23:43:26 - mmengine - INFO - Iter(train) [ 5200/80000]  base_lr: 9.4132e-05 lr: 9.4132e-06  eta: 11:02:55  time: 0.5295  data_time: 0.0138  memory: 5896  grad_norm: 132.7614  loss: 11.7357  decode.loss_cls: 0.4159  decode.loss_mask: 0.2945  decode.loss_dice: 0.3243  decode.d0.loss_cls: 1.3691  decode.d0.loss_mask: 0.2928  decode.d0.loss_dice: 0.3602  decode.d1.loss_cls: 0.6095  decode.d1.loss_mask: 0.2973  decode.d1.loss_dice: 0.3258  decode.d2.loss_cls: 0.4549  decode.d2.loss_mask: 0.2928  decode.d2.loss_dice: 0.3182  decode.d3.loss_cls: 0.4803  decode.d3.loss_mask: 0.2921  decode.d3.loss_dice: 0.3099  decode.d4.loss_cls: 0.4536  decode.d4.loss_mask: 0.2905  decode.d4.loss_dice: 0.3227  decode.d5.loss_cls: 0.4674  decode.d5.loss_mask: 0.2916  decode.d5.loss_dice: 0.3122  decode.d6.loss_cls: 0.4297  decode.d6.loss_mask: 0.2922  decode.d6.loss_dice: 0.3125  decode.d7.loss_cls: 0.4564  decode.d7.loss_mask: 0.2997  decode.d7.loss_dice: 0.3116  decode.d8.loss_cls: 0.4357  decode.d8.loss_mask: 0.2971  decode.d8.loss_dice: 0.3252
07/29 23:43:52 - mmengine - INFO - Iter(train) [ 5250/80000]  base_lr: 9.4075e-05 lr: 9.4075e-06  eta: 11:02:28  time: 0.5328  data_time: 0.0137  memory: 5934  grad_norm: 193.0376  loss: 14.5952  decode.loss_cls: 0.5318  decode.loss_mask: 0.3374  decode.loss_dice: 0.4206  decode.d0.loss_cls: 1.5379  decode.d0.loss_mask: 0.3482  decode.d0.loss_dice: 0.5112  decode.d1.loss_cls: 0.8366  decode.d1.loss_mask: 0.3562  decode.d1.loss_dice: 0.4328  decode.d2.loss_cls: 0.5897  decode.d2.loss_mask: 0.3485  decode.d2.loss_dice: 0.4208  decode.d3.loss_cls: 0.5599  decode.d3.loss_mask: 0.3439  decode.d3.loss_dice: 0.4553  decode.d4.loss_cls: 0.5204  decode.d4.loss_mask: 0.3438  decode.d4.loss_dice: 0.4201  decode.d5.loss_cls: 0.5996  decode.d5.loss_mask: 0.3354  decode.d5.loss_dice: 0.4181  decode.d6.loss_cls: 0.5445  decode.d6.loss_mask: 0.3412  decode.d6.loss_dice: 0.4156  decode.d7.loss_cls: 0.5885  decode.d7.loss_mask: 0.3306  decode.d7.loss_dice: 0.4236  decode.d8.loss_cls: 0.5149  decode.d8.loss_mask: 0.3356  decode.d8.loss_dice: 0.4325
07/29 23:44:19 - mmengine - INFO - Iter(train) [ 5300/80000]  base_lr: 9.4018e-05 lr: 9.4018e-06  eta: 11:02:00  time: 0.5286  data_time: 0.0136  memory: 5916  grad_norm: 225.9972  loss: 12.5717  decode.loss_cls: 0.5059  decode.loss_mask: 0.2859  decode.loss_dice: 0.3054  decode.d0.loss_cls: 1.5904  decode.d0.loss_mask: 0.3040  decode.d0.loss_dice: 0.3461  decode.d1.loss_cls: 0.7274  decode.d1.loss_mask: 0.3024  decode.d1.loss_dice: 0.3132  decode.d2.loss_cls: 0.5475  decode.d2.loss_mask: 0.2880  decode.d2.loss_dice: 0.3128  decode.d3.loss_cls: 0.5041  decode.d3.loss_mask: 0.2905  decode.d3.loss_dice: 0.3050  decode.d4.loss_cls: 0.5015  decode.d4.loss_mask: 0.2943  decode.d4.loss_dice: 0.3195  decode.d5.loss_cls: 0.5065  decode.d5.loss_mask: 0.2961  decode.d5.loss_dice: 0.3191  decode.d6.loss_cls: 0.5294  decode.d6.loss_mask: 0.2927  decode.d6.loss_dice: 0.3427  decode.d7.loss_cls: 0.5428  decode.d7.loss_mask: 0.2905  decode.d7.loss_dice: 0.3117  decode.d8.loss_cls: 0.4986  decode.d8.loss_mask: 0.2903  decode.d8.loss_dice: 0.3075
07/29 23:44:45 - mmengine - INFO - Iter(train) [ 5350/80000]  base_lr: 9.3962e-05 lr: 9.3962e-06  eta: 11:01:35  time: 0.5351  data_time: 0.0135  memory: 5971  grad_norm: 256.3617  loss: 14.4010  decode.loss_cls: 0.4904  decode.loss_mask: 0.3418  decode.loss_dice: 0.4253  decode.d0.loss_cls: 1.6737  decode.d0.loss_mask: 0.3567  decode.d0.loss_dice: 0.5474  decode.d1.loss_cls: 0.8209  decode.d1.loss_mask: 0.3197  decode.d1.loss_dice: 0.4277  decode.d2.loss_cls: 0.6163  decode.d2.loss_mask: 0.3220  decode.d2.loss_dice: 0.4291  decode.d3.loss_cls: 0.5483  decode.d3.loss_mask: 0.3057  decode.d3.loss_dice: 0.4079  decode.d4.loss_cls: 0.5873  decode.d4.loss_mask: 0.3116  decode.d4.loss_dice: 0.4090  decode.d5.loss_cls: 0.5057  decode.d5.loss_mask: 0.3345  decode.d5.loss_dice: 0.4354  decode.d6.loss_cls: 0.4677  decode.d6.loss_mask: 0.3198  decode.d6.loss_dice: 0.4181  decode.d7.loss_cls: 0.4824  decode.d7.loss_mask: 0.3633  decode.d7.loss_dice: 0.4479  decode.d8.loss_cls: 0.5334  decode.d8.loss_mask: 0.3455  decode.d8.loss_dice: 0.4064
07/29 23:45:12 - mmengine - INFO - Iter(train) [ 5400/80000]  base_lr: 9.3905e-05 lr: 9.3905e-06  eta: 11:01:05  time: 0.5229  data_time: 0.0127  memory: 5918  grad_norm: 146.6938  loss: 12.8263  decode.loss_cls: 0.3891  decode.loss_mask: 0.2756  decode.loss_dice: 0.3817  decode.d0.loss_cls: 1.3843  decode.d0.loss_mask: 0.2978  decode.d0.loss_dice: 0.4382  decode.d1.loss_cls: 0.7848  decode.d1.loss_mask: 0.2893  decode.d1.loss_dice: 0.4159  decode.d2.loss_cls: 0.5350  decode.d2.loss_mask: 0.2910  decode.d2.loss_dice: 0.4374  decode.d3.loss_cls: 0.4675  decode.d3.loss_mask: 0.2850  decode.d3.loss_dice: 0.4069  decode.d4.loss_cls: 0.5144  decode.d4.loss_mask: 0.2972  decode.d4.loss_dice: 0.3930  decode.d5.loss_cls: 0.4389  decode.d5.loss_mask: 0.2870  decode.d5.loss_dice: 0.3976  decode.d6.loss_cls: 0.4572  decode.d6.loss_mask: 0.2786  decode.d6.loss_dice: 0.4018  decode.d7.loss_cls: 0.5034  decode.d7.loss_mask: 0.2779  decode.d7.loss_dice: 0.3744  decode.d8.loss_cls: 0.4581  decode.d8.loss_mask: 0.2803  decode.d8.loss_dice: 0.3868
07/29 23:45:38 - mmengine - INFO - Iter(train) [ 5450/80000]  base_lr: 9.3848e-05 lr: 9.3848e-06  eta: 11:00:37  time: 0.5314  data_time: 0.0136  memory: 5916  grad_norm: 184.7410  loss: 10.5707  decode.loss_cls: 0.3150  decode.loss_mask: 0.2772  decode.loss_dice: 0.3368  decode.d0.loss_cls: 1.4235  decode.d0.loss_mask: 0.3027  decode.d0.loss_dice: 0.3830  decode.d1.loss_cls: 0.4483  decode.d1.loss_mask: 0.2944  decode.d1.loss_dice: 0.3296  decode.d2.loss_cls: 0.3419  decode.d2.loss_mask: 0.2892  decode.d2.loss_dice: 0.3321  decode.d3.loss_cls: 0.3417  decode.d3.loss_mask: 0.2758  decode.d3.loss_dice: 0.3268  decode.d4.loss_cls: 0.3116  decode.d4.loss_mask: 0.2771  decode.d4.loss_dice: 0.3535  decode.d5.loss_cls: 0.2824  decode.d5.loss_mask: 0.2806  decode.d5.loss_dice: 0.3508  decode.d6.loss_cls: 0.2764  decode.d6.loss_mask: 0.2819  decode.d6.loss_dice: 0.3486  decode.d7.loss_cls: 0.2803  decode.d7.loss_mask: 0.2776  decode.d7.loss_dice: 0.3493  decode.d8.loss_cls: 0.2546  decode.d8.loss_mask: 0.2804  decode.d8.loss_dice: 0.3476
07/29 23:46:05 - mmengine - INFO - Iter(train) [ 5500/80000]  base_lr: 9.3792e-05 lr: 9.3792e-06  eta: 11:00:08  time: 0.5227  data_time: 0.0129  memory: 5899  grad_norm: 137.4583  loss: 10.0739  decode.loss_cls: 0.3095  decode.loss_mask: 0.2713  decode.loss_dice: 0.2773  decode.d0.loss_cls: 1.2930  decode.d0.loss_mask: 0.2787  decode.d0.loss_dice: 0.3058  decode.d1.loss_cls: 0.4781  decode.d1.loss_mask: 0.2796  decode.d1.loss_dice: 0.3069  decode.d2.loss_cls: 0.3606  decode.d2.loss_mask: 0.2786  decode.d2.loss_dice: 0.2986  decode.d3.loss_cls: 0.3082  decode.d3.loss_mask: 0.2667  decode.d3.loss_dice: 0.2894  decode.d4.loss_cls: 0.3568  decode.d4.loss_mask: 0.2706  decode.d4.loss_dice: 0.2996  decode.d5.loss_cls: 0.3560  decode.d5.loss_mask: 0.2703  decode.d5.loss_dice: 0.2903  decode.d6.loss_cls: 0.3271  decode.d6.loss_mask: 0.2691  decode.d6.loss_dice: 0.2675  decode.d7.loss_cls: 0.3624  decode.d7.loss_mask: 0.2693  decode.d7.loss_dice: 0.2698  decode.d8.loss_cls: 0.3073  decode.d8.loss_mask: 0.2716  decode.d8.loss_dice: 0.2837
07/29 23:46:31 - mmengine - INFO - Iter(train) [ 5550/80000]  base_lr: 9.3735e-05 lr: 9.3735e-06  eta: 10:59:39  time: 0.5283  data_time: 0.0132  memory: 5916  grad_norm: 182.8797  loss: 11.6924  decode.loss_cls: 0.3392  decode.loss_mask: 0.3516  decode.loss_dice: 0.3672  decode.d0.loss_cls: 1.5280  decode.d0.loss_mask: 0.3829  decode.d0.loss_dice: 0.3803  decode.d1.loss_cls: 0.4851  decode.d1.loss_mask: 0.3433  decode.d1.loss_dice: 0.3882  decode.d2.loss_cls: 0.3216  decode.d2.loss_mask: 0.3331  decode.d2.loss_dice: 0.3806  decode.d3.loss_cls: 0.2522  decode.d3.loss_mask: 0.3362  decode.d3.loss_dice: 0.3724  decode.d4.loss_cls: 0.3153  decode.d4.loss_mask: 0.3358  decode.d4.loss_dice: 0.3617  decode.d5.loss_cls: 0.3221  decode.d5.loss_mask: 0.3372  decode.d5.loss_dice: 0.3652  decode.d6.loss_cls: 0.3708  decode.d6.loss_mask: 0.3340  decode.d6.loss_dice: 0.3499  decode.d7.loss_cls: 0.3062  decode.d7.loss_mask: 0.3334  decode.d7.loss_dice: 0.3487  decode.d8.loss_cls: 0.3275  decode.d8.loss_mask: 0.3515  decode.d8.loss_dice: 0.3706
07/29 23:46:58 - mmengine - INFO - Iter(train) [ 5600/80000]  base_lr: 9.3678e-05 lr: 9.3678e-06  eta: 10:59:12  time: 0.5307  data_time: 0.0134  memory: 5933  grad_norm: 296.8452  loss: 11.8191  decode.loss_cls: 0.3844  decode.loss_mask: 0.3573  decode.loss_dice: 0.2637  decode.d0.loss_cls: 1.4552  decode.d0.loss_mask: 0.4042  decode.d0.loss_dice: 0.3570  decode.d1.loss_cls: 0.4922  decode.d1.loss_mask: 0.4097  decode.d1.loss_dice: 0.3368  decode.d2.loss_cls: 0.4319  decode.d2.loss_mask: 0.3683  decode.d2.loss_dice: 0.2694  decode.d3.loss_cls: 0.3716  decode.d3.loss_mask: 0.3854  decode.d3.loss_dice: 0.2863  decode.d4.loss_cls: 0.3425  decode.d4.loss_mask: 0.3754  decode.d4.loss_dice: 0.2821  decode.d5.loss_cls: 0.4711  decode.d5.loss_mask: 0.3547  decode.d5.loss_dice: 0.2652  decode.d6.loss_cls: 0.4503  decode.d6.loss_mask: 0.3536  decode.d6.loss_dice: 0.2694  decode.d7.loss_cls: 0.4214  decode.d7.loss_mask: 0.3626  decode.d7.loss_dice: 0.2694  decode.d8.loss_cls: 0.3805  decode.d8.loss_mask: 0.3667  decode.d8.loss_dice: 0.2808
07/29 23:47:24 - mmengine - INFO - Iter(train) [ 5650/80000]  base_lr: 9.3622e-05 lr: 9.3622e-06  eta: 10:58:45  time: 0.5291  data_time: 0.0134  memory: 5931  grad_norm: 176.3761  loss: 11.3107  decode.loss_cls: 0.4140  decode.loss_mask: 0.3433  decode.loss_dice: 0.3024  decode.d0.loss_cls: 1.2966  decode.d0.loss_mask: 0.3509  decode.d0.loss_dice: 0.3390  decode.d1.loss_cls: 0.4629  decode.d1.loss_mask: 0.3637  decode.d1.loss_dice: 0.3353  decode.d2.loss_cls: 0.3402  decode.d2.loss_mask: 0.3501  decode.d2.loss_dice: 0.3179  decode.d3.loss_cls: 0.2935  decode.d3.loss_mask: 0.3459  decode.d3.loss_dice: 0.3114  decode.d4.loss_cls: 0.3168  decode.d4.loss_mask: 0.3548  decode.d4.loss_dice: 0.3235  decode.d5.loss_cls: 0.3882  decode.d5.loss_mask: 0.3436  decode.d5.loss_dice: 0.3132  decode.d6.loss_cls: 0.3300  decode.d6.loss_mask: 0.3465  decode.d6.loss_dice: 0.3066  decode.d7.loss_cls: 0.3187  decode.d7.loss_mask: 0.3608  decode.d7.loss_dice: 0.3366  decode.d8.loss_cls: 0.4514  decode.d8.loss_mask: 0.3486  decode.d8.loss_dice: 0.3045
07/29 23:47:51 - mmengine - INFO - Iter(train) [ 5700/80000]  base_lr: 9.3565e-05 lr: 9.3565e-06  eta: 10:58:16  time: 0.5326  data_time: 0.0128  memory: 5934  grad_norm: 235.4131  loss: 14.3293  decode.loss_cls: 0.5304  decode.loss_mask: 0.4063  decode.loss_dice: 0.4151  decode.d0.loss_cls: 1.4947  decode.d0.loss_mask: 0.3922  decode.d0.loss_dice: 0.4436  decode.d1.loss_cls: 0.5216  decode.d1.loss_mask: 0.4040  decode.d1.loss_dice: 0.3928  decode.d2.loss_cls: 0.5059  decode.d2.loss_mask: 0.4012  decode.d2.loss_dice: 0.4082  decode.d3.loss_cls: 0.5392  decode.d3.loss_mask: 0.3945  decode.d3.loss_dice: 0.3926  decode.d4.loss_cls: 0.5517  decode.d4.loss_mask: 0.4034  decode.d4.loss_dice: 0.4042  decode.d5.loss_cls: 0.5129  decode.d5.loss_mask: 0.3911  decode.d5.loss_dice: 0.3888  decode.d6.loss_cls: 0.4422  decode.d6.loss_mask: 0.4145  decode.d6.loss_dice: 0.4259  decode.d7.loss_cls: 0.5347  decode.d7.loss_mask: 0.4015  decode.d7.loss_dice: 0.4137  decode.d8.loss_cls: 0.5798  decode.d8.loss_mask: 0.4008  decode.d8.loss_dice: 0.4218
07/29 23:48:17 - mmengine - INFO - Iter(train) [ 5750/80000]  base_lr: 9.3508e-05 lr: 9.3508e-06  eta: 10:57:47  time: 0.5215  data_time: 0.0127  memory: 5932  grad_norm: 266.5567  loss: 14.7623  decode.loss_cls: 0.5160  decode.loss_mask: 0.4063  decode.loss_dice: 0.4360  decode.d0.loss_cls: 1.2999  decode.d0.loss_mask: 0.3749  decode.d0.loss_dice: 0.4461  decode.d1.loss_cls: 0.6635  decode.d1.loss_mask: 0.3747  decode.d1.loss_dice: 0.4513  decode.d2.loss_cls: 0.6627  decode.d2.loss_mask: 0.3702  decode.d2.loss_dice: 0.4159  decode.d3.loss_cls: 0.6043  decode.d3.loss_mask: 0.3533  decode.d3.loss_dice: 0.4160  decode.d4.loss_cls: 0.5889  decode.d4.loss_mask: 0.3786  decode.d4.loss_dice: 0.4238  decode.d5.loss_cls: 0.5954  decode.d5.loss_mask: 0.3831  decode.d5.loss_dice: 0.4274  decode.d6.loss_cls: 0.6779  decode.d6.loss_mask: 0.3689  decode.d6.loss_dice: 0.4528  decode.d7.loss_cls: 0.5482  decode.d7.loss_mask: 0.3744  decode.d7.loss_dice: 0.4445  decode.d8.loss_cls: 0.4981  decode.d8.loss_mask: 0.3865  decode.d8.loss_dice: 0.4224
07/29 23:48:43 - mmengine - INFO - Iter(train) [ 5800/80000]  base_lr: 9.3452e-05 lr: 9.3452e-06  eta: 10:57:19  time: 0.5292  data_time: 0.0137  memory: 5897  grad_norm: 130.6905  loss: 10.6144  decode.loss_cls: 0.3852  decode.loss_mask: 0.2374  decode.loss_dice: 0.2886  decode.d0.loss_cls: 1.5136  decode.d0.loss_mask: 0.2594  decode.d0.loss_dice: 0.3327  decode.d1.loss_cls: 0.5448  decode.d1.loss_mask: 0.2385  decode.d1.loss_dice: 0.3062  decode.d2.loss_cls: 0.4674  decode.d2.loss_mask: 0.2351  decode.d2.loss_dice: 0.3013  decode.d3.loss_cls: 0.4600  decode.d3.loss_mask: 0.2237  decode.d3.loss_dice: 0.2683  decode.d4.loss_cls: 0.4273  decode.d4.loss_mask: 0.2232  decode.d4.loss_dice: 0.2653  decode.d5.loss_cls: 0.4606  decode.d5.loss_mask: 0.2286  decode.d5.loss_dice: 0.2662  decode.d6.loss_cls: 0.3824  decode.d6.loss_mask: 0.2242  decode.d6.loss_dice: 0.2688  decode.d7.loss_cls: 0.3932  decode.d7.loss_mask: 0.2235  decode.d7.loss_dice: 0.2676  decode.d8.loss_cls: 0.4017  decode.d8.loss_mask: 0.2321  decode.d8.loss_dice: 0.2875
07/29 23:49:10 - mmengine - INFO - Iter(train) [ 5850/80000]  base_lr: 9.3395e-05 lr: 9.3395e-06  eta: 10:56:51  time: 0.5311  data_time: 0.0135  memory: 5896  grad_norm: 332.8455  loss: 13.4007  decode.loss_cls: 0.4396  decode.loss_mask: 0.3393  decode.loss_dice: 0.3677  decode.d0.loss_cls: 1.5177  decode.d0.loss_mask: 0.2918  decode.d0.loss_dice: 0.3859  decode.d1.loss_cls: 0.5634  decode.d1.loss_mask: 0.3403  decode.d1.loss_dice: 0.3740  decode.d2.loss_cls: 0.5425  decode.d2.loss_mask: 0.3546  decode.d2.loss_dice: 0.3479  decode.d3.loss_cls: 0.5316  decode.d3.loss_mask: 0.3350  decode.d3.loss_dice: 0.3356  decode.d4.loss_cls: 0.5176  decode.d4.loss_mask: 0.3621  decode.d4.loss_dice: 0.3574  decode.d5.loss_cls: 0.5644  decode.d5.loss_mask: 0.3777  decode.d5.loss_dice: 0.3524  decode.d6.loss_cls: 0.5343  decode.d6.loss_mask: 0.3717  decode.d6.loss_dice: 0.3776  decode.d7.loss_cls: 0.5272  decode.d7.loss_mask: 0.4013  decode.d7.loss_dice: 0.3832  decode.d8.loss_cls: 0.4812  decode.d8.loss_mask: 0.3433  decode.d8.loss_dice: 0.3827
07/29 23:49:36 - mmengine - INFO - Iter(train) [ 5900/80000]  base_lr: 9.3338e-05 lr: 9.3338e-06  eta: 10:56:23  time: 0.5290  data_time: 0.0136  memory: 5933  grad_norm: 223.6544  loss: 12.1560  decode.loss_cls: 0.5059  decode.loss_mask: 0.2588  decode.loss_dice: 0.2898  decode.d0.loss_cls: 1.4257  decode.d0.loss_mask: 0.2774  decode.d0.loss_dice: 0.3432  decode.d1.loss_cls: 0.6818  decode.d1.loss_mask: 0.2755  decode.d1.loss_dice: 0.3298  decode.d2.loss_cls: 0.4579  decode.d2.loss_mask: 0.2970  decode.d2.loss_dice: 0.3423  decode.d3.loss_cls: 0.5516  decode.d3.loss_mask: 0.2660  decode.d3.loss_dice: 0.3028  decode.d4.loss_cls: 0.4979  decode.d4.loss_mask: 0.2755  decode.d4.loss_dice: 0.3049  decode.d5.loss_cls: 0.5104  decode.d5.loss_mask: 0.2949  decode.d5.loss_dice: 0.3110  decode.d6.loss_cls: 0.4901  decode.d6.loss_mask: 0.2671  decode.d6.loss_dice: 0.3236  decode.d7.loss_cls: 0.5339  decode.d7.loss_mask: 0.2873  decode.d7.loss_dice: 0.3378  decode.d8.loss_cls: 0.5406  decode.d8.loss_mask: 0.2725  decode.d8.loss_dice: 0.3033
07/29 23:50:03 - mmengine - INFO - Iter(train) [ 5950/80000]  base_lr: 9.3282e-05 lr: 9.3282e-06  eta: 10:55:57  time: 0.5321  data_time: 0.0132  memory: 5918  grad_norm: 222.7144  loss: 15.5765  decode.loss_cls: 0.6708  decode.loss_mask: 0.3550  decode.loss_dice: 0.4796  decode.d0.loss_cls: 1.5673  decode.d0.loss_mask: 0.3313  decode.d0.loss_dice: 0.4794  decode.d1.loss_cls: 0.7259  decode.d1.loss_mask: 0.3246  decode.d1.loss_dice: 0.4336  decode.d2.loss_cls: 0.6645  decode.d2.loss_mask: 0.3340  decode.d2.loss_dice: 0.4907  decode.d3.loss_cls: 0.6144  decode.d3.loss_mask: 0.3313  decode.d3.loss_dice: 0.4245  decode.d4.loss_cls: 0.6267  decode.d4.loss_mask: 0.3335  decode.d4.loss_dice: 0.4453  decode.d5.loss_cls: 0.6367  decode.d5.loss_mask: 0.3383  decode.d5.loss_dice: 0.4499  decode.d6.loss_cls: 0.7174  decode.d6.loss_mask: 0.3520  decode.d6.loss_dice: 0.4568  decode.d7.loss_cls: 0.7257  decode.d7.loss_mask: 0.3354  decode.d7.loss_dice: 0.4534  decode.d8.loss_cls: 0.7193  decode.d8.loss_mask: 0.3376  decode.d8.loss_dice: 0.4214
07/29 23:50:30 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/29 23:50:30 - mmengine - INFO - Iter(train) [ 6000/80000]  base_lr: 9.3225e-05 lr: 9.3225e-06  eta: 10:55:31  time: 0.5256  data_time: 0.0128  memory: 5916  grad_norm: 268.4981  loss: 14.4630  decode.loss_cls: 0.4557  decode.loss_mask: 0.4866  decode.loss_dice: 0.3763  decode.d0.loss_cls: 1.5086  decode.d0.loss_mask: 0.5003  decode.d0.loss_dice: 0.4223  decode.d1.loss_cls: 0.5356  decode.d1.loss_mask: 0.4750  decode.d1.loss_dice: 0.3924  decode.d2.loss_cls: 0.5177  decode.d2.loss_mask: 0.4686  decode.d2.loss_dice: 0.3642  decode.d3.loss_cls: 0.4273  decode.d3.loss_mask: 0.5064  decode.d3.loss_dice: 0.3932  decode.d4.loss_cls: 0.5142  decode.d4.loss_mask: 0.4982  decode.d4.loss_dice: 0.3751  decode.d5.loss_cls: 0.4262  decode.d5.loss_mask: 0.4933  decode.d5.loss_dice: 0.3721  decode.d6.loss_cls: 0.4198  decode.d6.loss_mask: 0.4859  decode.d6.loss_dice: 0.3788  decode.d7.loss_cls: 0.4718  decode.d7.loss_mask: 0.4838  decode.d7.loss_dice: 0.3885  decode.d8.loss_cls: 0.4691  decode.d8.loss_mask: 0.4774  decode.d8.loss_dice: 0.3787
07/29 23:50:56 - mmengine - INFO - Iter(train) [ 6050/80000]  base_lr: 9.3168e-05 lr: 9.3168e-06  eta: 10:55:05  time: 0.5363  data_time: 0.0135  memory: 5918  grad_norm: 176.4225  loss: 11.6713  decode.loss_cls: 0.3926  decode.loss_mask: 0.2736  decode.loss_dice: 0.3574  decode.d0.loss_cls: 1.3721  decode.d0.loss_mask: 0.2880  decode.d0.loss_dice: 0.4376  decode.d1.loss_cls: 0.5329  decode.d1.loss_mask: 0.2867  decode.d1.loss_dice: 0.3869  decode.d2.loss_cls: 0.4586  decode.d2.loss_mask: 0.2770  decode.d2.loss_dice: 0.3743  decode.d3.loss_cls: 0.3969  decode.d3.loss_mask: 0.2850  decode.d3.loss_dice: 0.3866  decode.d4.loss_cls: 0.3704  decode.d4.loss_mask: 0.2779  decode.d4.loss_dice: 0.3698  decode.d5.loss_cls: 0.4205  decode.d5.loss_mask: 0.3008  decode.d5.loss_dice: 0.3825  decode.d6.loss_cls: 0.3718  decode.d6.loss_mask: 0.3379  decode.d6.loss_dice: 0.3862  decode.d7.loss_cls: 0.3454  decode.d7.loss_mask: 0.2757  decode.d7.loss_dice: 0.3437  decode.d8.loss_cls: 0.3661  decode.d8.loss_mask: 0.2735  decode.d8.loss_dice: 0.3427
07/29 23:51:23 - mmengine - INFO - Iter(train) [ 6100/80000]  base_lr: 9.3112e-05 lr: 9.3112e-06  eta: 10:54:37  time: 0.5290  data_time: 0.0129  memory: 5882  grad_norm: 766.8734  loss: 14.1188  decode.loss_cls: 0.4297  decode.loss_mask: 0.4001  decode.loss_dice: 0.4372  decode.d0.loss_cls: 1.4389  decode.d0.loss_mask: 0.4015  decode.d0.loss_dice: 0.4109  decode.d1.loss_cls: 0.5887  decode.d1.loss_mask: 0.3880  decode.d1.loss_dice: 0.4522  decode.d2.loss_cls: 0.4533  decode.d2.loss_mask: 0.4002  decode.d2.loss_dice: 0.4537  decode.d3.loss_cls: 0.4083  decode.d3.loss_mask: 0.3906  decode.d3.loss_dice: 0.4173  decode.d4.loss_cls: 0.4352  decode.d4.loss_mask: 0.4207  decode.d4.loss_dice: 0.4645  decode.d5.loss_cls: 0.4961  decode.d5.loss_mask: 0.4188  decode.d5.loss_dice: 0.4520  decode.d6.loss_cls: 0.5061  decode.d6.loss_mask: 0.4145  decode.d6.loss_dice: 0.4030  decode.d7.loss_cls: 0.4781  decode.d7.loss_mask: 0.4040  decode.d7.loss_dice: 0.4414  decode.d8.loss_cls: 0.4481  decode.d8.loss_mask: 0.4088  decode.d8.loss_dice: 0.4566
07/29 23:51:49 - mmengine - INFO - Iter(train) [ 6150/80000]  base_lr: 9.3055e-05 lr: 9.3055e-06  eta: 10:54:09  time: 0.5291  data_time: 0.0133  memory: 5933  grad_norm: 236.9459  loss: 14.4673  decode.loss_cls: 0.5392  decode.loss_mask: 0.3921  decode.loss_dice: 0.4074  decode.d0.loss_cls: 1.4984  decode.d0.loss_mask: 0.3887  decode.d0.loss_dice: 0.4370  decode.d1.loss_cls: 0.5756  decode.d1.loss_mask: 0.3739  decode.d1.loss_dice: 0.4075  decode.d2.loss_cls: 0.5994  decode.d2.loss_mask: 0.3832  decode.d2.loss_dice: 0.4077  decode.d3.loss_cls: 0.4845  decode.d3.loss_mask: 0.3829  decode.d3.loss_dice: 0.4516  decode.d4.loss_cls: 0.5103  decode.d4.loss_mask: 0.4017  decode.d4.loss_dice: 0.4316  decode.d5.loss_cls: 0.5095  decode.d5.loss_mask: 0.3962  decode.d5.loss_dice: 0.4367  decode.d6.loss_cls: 0.5314  decode.d6.loss_mask: 0.3788  decode.d6.loss_dice: 0.4215  decode.d7.loss_cls: 0.5460  decode.d7.loss_mask: 0.3883  decode.d7.loss_dice: 0.4075  decode.d8.loss_cls: 0.5563  decode.d8.loss_mask: 0.4057  decode.d8.loss_dice: 0.4165
07/29 23:52:16 - mmengine - INFO - Iter(train) [ 6200/80000]  base_lr: 9.2998e-05 lr: 9.2998e-06  eta: 10:53:41  time: 0.5336  data_time: 0.0135  memory: 5931  grad_norm: 255.8845  loss: 11.7462  decode.loss_cls: 0.3822  decode.loss_mask: 0.3132  decode.loss_dice: 0.2925  decode.d0.loss_cls: 1.4997  decode.d0.loss_mask: 0.3299  decode.d0.loss_dice: 0.3794  decode.d1.loss_cls: 0.5438  decode.d1.loss_mask: 0.3320  decode.d1.loss_dice: 0.3160  decode.d2.loss_cls: 0.4950  decode.d2.loss_mask: 0.3377  decode.d2.loss_dice: 0.3329  decode.d3.loss_cls: 0.4391  decode.d3.loss_mask: 0.3286  decode.d3.loss_dice: 0.3112  decode.d4.loss_cls: 0.4538  decode.d4.loss_mask: 0.3079  decode.d4.loss_dice: 0.3022  decode.d5.loss_cls: 0.4144  decode.d5.loss_mask: 0.3048  decode.d5.loss_dice: 0.3017  decode.d6.loss_cls: 0.4154  decode.d6.loss_mask: 0.3156  decode.d6.loss_dice: 0.3069  decode.d7.loss_cls: 0.3841  decode.d7.loss_mask: 0.3170  decode.d7.loss_dice: 0.2900  decode.d8.loss_cls: 0.3850  decode.d8.loss_mask: 0.3091  decode.d8.loss_dice: 0.3052
07/29 23:52:42 - mmengine - INFO - Iter(train) [ 6250/80000]  base_lr: 9.2942e-05 lr: 9.2942e-06  eta: 10:53:13  time: 0.5281  data_time: 0.0132  memory: 5916  grad_norm: 181.5481  loss: 11.7825  decode.loss_cls: 0.4920  decode.loss_mask: 0.2638  decode.loss_dice: 0.3212  decode.d0.loss_cls: 1.4280  decode.d0.loss_mask: 0.2779  decode.d0.loss_dice: 0.3528  decode.d1.loss_cls: 0.5968  decode.d1.loss_mask: 0.2611  decode.d1.loss_dice: 0.3355  decode.d2.loss_cls: 0.4445  decode.d2.loss_mask: 0.2480  decode.d2.loss_dice: 0.3188  decode.d3.loss_cls: 0.4370  decode.d3.loss_mask: 0.2537  decode.d3.loss_dice: 0.3363  decode.d4.loss_cls: 0.4935  decode.d4.loss_mask: 0.2477  decode.d4.loss_dice: 0.3108  decode.d5.loss_cls: 0.4954  decode.d5.loss_mask: 0.2492  decode.d5.loss_dice: 0.3122  decode.d6.loss_cls: 0.4756  decode.d6.loss_mask: 0.2488  decode.d6.loss_dice: 0.3165  decode.d7.loss_cls: 0.5080  decode.d7.loss_mask: 0.2609  decode.d7.loss_dice: 0.3132  decode.d8.loss_cls: 0.6044  decode.d8.loss_mask: 0.2509  decode.d8.loss_dice: 0.3277
07/29 23:53:09 - mmengine - INFO - Iter(train) [ 6300/80000]  base_lr: 9.2885e-05 lr: 9.2885e-06  eta: 10:52:47  time: 0.5349  data_time: 0.0133  memory: 5916  grad_norm: 123.6848  loss: 11.0426  decode.loss_cls: 0.3094  decode.loss_mask: 0.3078  decode.loss_dice: 0.3558  decode.d0.loss_cls: 1.4409  decode.d0.loss_mask: 0.2924  decode.d0.loss_dice: 0.3895  decode.d1.loss_cls: 0.4891  decode.d1.loss_mask: 0.2843  decode.d1.loss_dice: 0.3358  decode.d2.loss_cls: 0.4044  decode.d2.loss_mask: 0.2940  decode.d2.loss_dice: 0.3567  decode.d3.loss_cls: 0.3618  decode.d3.loss_mask: 0.2897  decode.d3.loss_dice: 0.3449  decode.d4.loss_cls: 0.2954  decode.d4.loss_mask: 0.2838  decode.d4.loss_dice: 0.3152  decode.d5.loss_cls: 0.3582  decode.d5.loss_mask: 0.2810  decode.d5.loss_dice: 0.3220  decode.d6.loss_cls: 0.3420  decode.d6.loss_mask: 0.2784  decode.d6.loss_dice: 0.3249  decode.d7.loss_cls: 0.3481  decode.d7.loss_mask: 0.2847  decode.d7.loss_dice: 0.3209  decode.d8.loss_cls: 0.4003  decode.d8.loss_mask: 0.2879  decode.d8.loss_dice: 0.3432
07/29 23:53:35 - mmengine - INFO - Iter(train) [ 6350/80000]  base_lr: 9.2828e-05 lr: 9.2828e-06  eta: 10:52:20  time: 0.5344  data_time: 0.0133  memory: 5986  grad_norm: 224.1035  loss: 12.4140  decode.loss_cls: 0.4613  decode.loss_mask: 0.3221  decode.loss_dice: 0.3709  decode.d0.loss_cls: 1.3227  decode.d0.loss_mask: 0.3394  decode.d0.loss_dice: 0.4373  decode.d1.loss_cls: 0.6483  decode.d1.loss_mask: 0.3201  decode.d1.loss_dice: 0.3939  decode.d2.loss_cls: 0.4473  decode.d2.loss_mask: 0.3220  decode.d2.loss_dice: 0.3802  decode.d3.loss_cls: 0.4720  decode.d3.loss_mask: 0.3081  decode.d3.loss_dice: 0.3817  decode.d4.loss_cls: 0.4158  decode.d4.loss_mask: 0.3099  decode.d4.loss_dice: 0.3655  decode.d5.loss_cls: 0.4683  decode.d5.loss_mask: 0.3033  decode.d5.loss_dice: 0.3589  decode.d6.loss_cls: 0.4013  decode.d6.loss_mask: 0.3103  decode.d6.loss_dice: 0.3623  decode.d7.loss_cls: 0.3786  decode.d7.loss_mask: 0.3079  decode.d7.loss_dice: 0.3649  decode.d8.loss_cls: 0.4596  decode.d8.loss_mask: 0.3089  decode.d8.loss_dice: 0.3712
07/29 23:54:02 - mmengine - INFO - Iter(train) [ 6400/80000]  base_lr: 9.2771e-05 lr: 9.2771e-06  eta: 10:51:54  time: 0.5325  data_time: 0.0131  memory: 5918  grad_norm: 158.5368  loss: 11.5496  decode.loss_cls: 0.4283  decode.loss_mask: 0.2853  decode.loss_dice: 0.3578  decode.d0.loss_cls: 1.3178  decode.d0.loss_mask: 0.2763  decode.d0.loss_dice: 0.3920  decode.d1.loss_cls: 0.4854  decode.d1.loss_mask: 0.2854  decode.d1.loss_dice: 0.3844  decode.d2.loss_cls: 0.3507  decode.d2.loss_mask: 0.3074  decode.d2.loss_dice: 0.4035  decode.d3.loss_cls: 0.3299  decode.d3.loss_mask: 0.2904  decode.d3.loss_dice: 0.3524  decode.d4.loss_cls: 0.4161  decode.d4.loss_mask: 0.2849  decode.d4.loss_dice: 0.3568  decode.d5.loss_cls: 0.3740  decode.d5.loss_mask: 0.2889  decode.d5.loss_dice: 0.3939  decode.d6.loss_cls: 0.3560  decode.d6.loss_mask: 0.3047  decode.d6.loss_dice: 0.3791  decode.d7.loss_cls: 0.3577  decode.d7.loss_mask: 0.2895  decode.d7.loss_dice: 0.3682  decode.d8.loss_cls: 0.4533  decode.d8.loss_mask: 0.2985  decode.d8.loss_dice: 0.3810
07/29 23:54:28 - mmengine - INFO - Iter(train) [ 6450/80000]  base_lr: 9.2715e-05 lr: 9.2715e-06  eta: 10:51:28  time: 0.5285  data_time: 0.0131  memory: 5916  grad_norm: 331.7546  loss: 15.8545  decode.loss_cls: 0.5367  decode.loss_mask: 0.4019  decode.loss_dice: 0.4902  decode.d0.loss_cls: 1.6273  decode.d0.loss_mask: 0.3774  decode.d0.loss_dice: 0.5124  decode.d1.loss_cls: 0.7150  decode.d1.loss_mask: 0.3874  decode.d1.loss_dice: 0.4837  decode.d2.loss_cls: 0.6561  decode.d2.loss_mask: 0.4057  decode.d2.loss_dice: 0.4951  decode.d3.loss_cls: 0.5026  decode.d3.loss_mask: 0.3869  decode.d3.loss_dice: 0.4710  decode.d4.loss_cls: 0.5208  decode.d4.loss_mask: 0.4000  decode.d4.loss_dice: 0.4378  decode.d5.loss_cls: 0.5792  decode.d5.loss_mask: 0.3966  decode.d5.loss_dice: 0.4774  decode.d6.loss_cls: 0.5976  decode.d6.loss_mask: 0.3987  decode.d6.loss_dice: 0.4801  decode.d7.loss_cls: 0.6188  decode.d7.loss_mask: 0.4438  decode.d7.loss_dice: 0.5138  decode.d8.loss_cls: 0.6571  decode.d8.loss_mask: 0.4060  decode.d8.loss_dice: 0.4775
07/29 23:54:55 - mmengine - INFO - Iter(train) [ 6500/80000]  base_lr: 9.2658e-05 lr: 9.2658e-06  eta: 10:51:02  time: 0.5343  data_time: 0.0137  memory: 5985  grad_norm: 227.5842  loss: 13.3262  decode.loss_cls: 0.4753  decode.loss_mask: 0.3466  decode.loss_dice: 0.3899  decode.d0.loss_cls: 1.4541  decode.d0.loss_mask: 0.3707  decode.d0.loss_dice: 0.4743  decode.d1.loss_cls: 0.7247  decode.d1.loss_mask: 0.3678  decode.d1.loss_dice: 0.3931  decode.d2.loss_cls: 0.5584  decode.d2.loss_mask: 0.3374  decode.d2.loss_dice: 0.3921  decode.d3.loss_cls: 0.4386  decode.d3.loss_mask: 0.3366  decode.d3.loss_dice: 0.3817  decode.d4.loss_cls: 0.4563  decode.d4.loss_mask: 0.3541  decode.d4.loss_dice: 0.4040  decode.d5.loss_cls: 0.4547  decode.d5.loss_mask: 0.3578  decode.d5.loss_dice: 0.3978  decode.d6.loss_cls: 0.4155  decode.d6.loss_mask: 0.3509  decode.d6.loss_dice: 0.3930  decode.d7.loss_cls: 0.4181  decode.d7.loss_mask: 0.3392  decode.d7.loss_dice: 0.3832  decode.d8.loss_cls: 0.4195  decode.d8.loss_mask: 0.3586  decode.d8.loss_dice: 0.3820
07/29 23:55:22 - mmengine - INFO - Iter(train) [ 6550/80000]  base_lr: 9.2601e-05 lr: 9.2601e-06  eta: 10:50:35  time: 0.5308  data_time: 0.0129  memory: 5919  grad_norm: 319.2883  loss: 13.4855  decode.loss_cls: 0.4938  decode.loss_mask: 0.3538  decode.loss_dice: 0.3509  decode.d0.loss_cls: 1.5637  decode.d0.loss_mask: 0.4033  decode.d0.loss_dice: 0.4031  decode.d1.loss_cls: 0.6474  decode.d1.loss_mask: 0.3810  decode.d1.loss_dice: 0.3645  decode.d2.loss_cls: 0.5981  decode.d2.loss_mask: 0.3512  decode.d2.loss_dice: 0.3605  decode.d3.loss_cls: 0.5445  decode.d3.loss_mask: 0.3543  decode.d3.loss_dice: 0.3542  decode.d4.loss_cls: 0.4751  decode.d4.loss_mask: 0.3602  decode.d4.loss_dice: 0.3822  decode.d5.loss_cls: 0.5151  decode.d5.loss_mask: 0.3413  decode.d5.loss_dice: 0.3218  decode.d6.loss_cls: 0.4218  decode.d6.loss_mask: 0.3783  decode.d6.loss_dice: 0.3615  decode.d7.loss_cls: 0.5256  decode.d7.loss_mask: 0.3513  decode.d7.loss_dice: 0.3486  decode.d8.loss_cls: 0.4614  decode.d8.loss_mask: 0.3446  decode.d8.loss_dice: 0.3726
07/29 23:55:48 - mmengine - INFO - Iter(train) [ 6600/80000]  base_lr: 9.2544e-05 lr: 9.2544e-06  eta: 10:50:07  time: 0.5293  data_time: 0.0135  memory: 5971  grad_norm: 149.8553  loss: 12.9268  decode.loss_cls: 0.4910  decode.loss_mask: 0.3074  decode.loss_dice: 0.3707  decode.d0.loss_cls: 1.3591  decode.d0.loss_mask: 0.3151  decode.d0.loss_dice: 0.4200  decode.d1.loss_cls: 0.6339  decode.d1.loss_mask: 0.3264  decode.d1.loss_dice: 0.3841  decode.d2.loss_cls: 0.4914  decode.d2.loss_mask: 0.3309  decode.d2.loss_dice: 0.3969  decode.d3.loss_cls: 0.4579  decode.d3.loss_mask: 0.3226  decode.d3.loss_dice: 0.3722  decode.d4.loss_cls: 0.4739  decode.d4.loss_mask: 0.3207  decode.d4.loss_dice: 0.3628  decode.d5.loss_cls: 0.4804  decode.d5.loss_mask: 0.3121  decode.d5.loss_dice: 0.3658  decode.d6.loss_cls: 0.5564  decode.d6.loss_mask: 0.3042  decode.d6.loss_dice: 0.3548  decode.d7.loss_cls: 0.5607  decode.d7.loss_mask: 0.3084  decode.d7.loss_dice: 0.3563  decode.d8.loss_cls: 0.4704  decode.d8.loss_mask: 0.3282  decode.d8.loss_dice: 0.3920
07/29 23:56:14 - mmengine - INFO - Iter(train) [ 6650/80000]  base_lr: 9.2488e-05 lr: 9.2488e-06  eta: 10:49:39  time: 0.5305  data_time: 0.0132  memory: 5881  grad_norm: 125.5749  loss: 10.5302  decode.loss_cls: 0.3334  decode.loss_mask: 0.3083  decode.loss_dice: 0.3282  decode.d0.loss_cls: 1.1177  decode.d0.loss_mask: 0.3091  decode.d0.loss_dice: 0.3581  decode.d1.loss_cls: 0.4185  decode.d1.loss_mask: 0.3255  decode.d1.loss_dice: 0.3319  decode.d2.loss_cls: 0.3161  decode.d2.loss_mask: 0.3186  decode.d2.loss_dice: 0.3246  decode.d3.loss_cls: 0.3693  decode.d3.loss_mask: 0.3177  decode.d3.loss_dice: 0.3455  decode.d4.loss_cls: 0.3541  decode.d4.loss_mask: 0.3168  decode.d4.loss_dice: 0.3254  decode.d5.loss_cls: 0.2981  decode.d5.loss_mask: 0.3129  decode.d5.loss_dice: 0.3197  decode.d6.loss_cls: 0.2997  decode.d6.loss_mask: 0.3053  decode.d6.loss_dice: 0.3188  decode.d7.loss_cls: 0.2990  decode.d7.loss_mask: 0.3100  decode.d7.loss_dice: 0.3260  decode.d8.loss_cls: 0.2899  decode.d8.loss_mask: 0.3092  decode.d8.loss_dice: 0.3228
07/29 23:56:41 - mmengine - INFO - Iter(train) [ 6700/80000]  base_lr: 9.2431e-05 lr: 9.2431e-06  eta: 10:49:11  time: 0.5306  data_time: 0.0134  memory: 5918  grad_norm: 161.1627  loss: 9.6317  decode.loss_cls: 0.2361  decode.loss_mask: 0.3073  decode.loss_dice: 0.2917  decode.d0.loss_cls: 1.3273  decode.d0.loss_mask: 0.2991  decode.d0.loss_dice: 0.3109  decode.d1.loss_cls: 0.3914  decode.d1.loss_mask: 0.2915  decode.d1.loss_dice: 0.2905  decode.d2.loss_cls: 0.2884  decode.d2.loss_mask: 0.2983  decode.d2.loss_dice: 0.3009  decode.d3.loss_cls: 0.2793  decode.d3.loss_mask: 0.3007  decode.d3.loss_dice: 0.2970  decode.d4.loss_cls: 0.2523  decode.d4.loss_mask: 0.2933  decode.d4.loss_dice: 0.2943  decode.d5.loss_cls: 0.2465  decode.d5.loss_mask: 0.2979  decode.d5.loss_dice: 0.3043  decode.d6.loss_cls: 0.2363  decode.d6.loss_mask: 0.2896  decode.d6.loss_dice: 0.2794  decode.d7.loss_cls: 0.2318  decode.d7.loss_mask: 0.2965  decode.d7.loss_dice: 0.2807  decode.d8.loss_cls: 0.2377  decode.d8.loss_mask: 0.2926  decode.d8.loss_dice: 0.2883
07/29 23:57:08 - mmengine - INFO - Iter(train) [ 6750/80000]  base_lr: 9.2374e-05 lr: 9.2374e-06  eta: 10:48:47  time: 0.5305  data_time: 0.0137  memory: 5971  grad_norm: 163.4689  loss: 12.4667  decode.loss_cls: 0.3189  decode.loss_mask: 0.3424  decode.loss_dice: 0.4403  decode.d0.loss_cls: 1.3127  decode.d0.loss_mask: 0.3374  decode.d0.loss_dice: 0.3920  decode.d1.loss_cls: 0.5880  decode.d1.loss_mask: 0.3237  decode.d1.loss_dice: 0.4234  decode.d2.loss_cls: 0.5019  decode.d2.loss_mask: 0.3060  decode.d2.loss_dice: 0.4142  decode.d3.loss_cls: 0.3815  decode.d3.loss_mask: 0.3034  decode.d3.loss_dice: 0.4128  decode.d4.loss_cls: 0.2739  decode.d4.loss_mask: 0.3350  decode.d4.loss_dice: 0.4600  decode.d5.loss_cls: 0.2565  decode.d5.loss_mask: 0.3472  decode.d5.loss_dice: 0.4774  decode.d6.loss_cls: 0.3784  decode.d6.loss_mask: 0.3377  decode.d6.loss_dice: 0.4672  decode.d7.loss_cls: 0.3128  decode.d7.loss_mask: 0.3563  decode.d7.loss_dice: 0.5025  decode.d8.loss_cls: 0.3766  decode.d8.loss_mask: 0.3438  decode.d8.loss_dice: 0.4428
07/29 23:57:34 - mmengine - INFO - Iter(train) [ 6800/80000]  base_lr: 9.2317e-05 lr: 9.2317e-06  eta: 10:48:19  time: 0.5307  data_time: 0.0129  memory: 5918  grad_norm: 105.0205  loss: 10.5980  decode.loss_cls: 0.3378  decode.loss_mask: 0.2757  decode.loss_dice: 0.3186  decode.d0.loss_cls: 1.5687  decode.d0.loss_mask: 0.2689  decode.d0.loss_dice: 0.3076  decode.d1.loss_cls: 0.4467  decode.d1.loss_mask: 0.2730  decode.d1.loss_dice: 0.3092  decode.d2.loss_cls: 0.3381  decode.d2.loss_mask: 0.2771  decode.d2.loss_dice: 0.2870  decode.d3.loss_cls: 0.3712  decode.d3.loss_mask: 0.2752  decode.d3.loss_dice: 0.2980  decode.d4.loss_cls: 0.3210  decode.d4.loss_mask: 0.2712  decode.d4.loss_dice: 0.2880  decode.d5.loss_cls: 0.3500  decode.d5.loss_mask: 0.2773  decode.d5.loss_dice: 0.3009  decode.d6.loss_cls: 0.3648  decode.d6.loss_mask: 0.2708  decode.d6.loss_dice: 0.3179  decode.d7.loss_cls: 0.3832  decode.d7.loss_mask: 0.2695  decode.d7.loss_dice: 0.2925  decode.d8.loss_cls: 0.3699  decode.d8.loss_mask: 0.2736  decode.d8.loss_dice: 0.2946
07/29 23:58:00 - mmengine - INFO - Iter(train) [ 6850/80000]  base_lr: 9.2261e-05 lr: 9.2261e-06  eta: 10:47:50  time: 0.5274  data_time: 0.0132  memory: 5916  grad_norm: 182.9612  loss: 11.0244  decode.loss_cls: 0.4854  decode.loss_mask: 0.2642  decode.loss_dice: 0.3828  decode.d0.loss_cls: 1.4932  decode.d0.loss_mask: 0.2693  decode.d0.loss_dice: 0.4142  decode.d1.loss_cls: 0.3981  decode.d1.loss_mask: 0.2722  decode.d1.loss_dice: 0.3827  decode.d2.loss_cls: 0.2435  decode.d2.loss_mask: 0.2652  decode.d2.loss_dice: 0.3742  decode.d3.loss_cls: 0.3191  decode.d3.loss_mask: 0.2622  decode.d3.loss_dice: 0.3775  decode.d4.loss_cls: 0.2656  decode.d4.loss_mask: 0.2569  decode.d4.loss_dice: 0.3527  decode.d5.loss_cls: 0.3183  decode.d5.loss_mask: 0.2607  decode.d5.loss_dice: 0.3430  decode.d6.loss_cls: 0.3289  decode.d6.loss_mask: 0.2639  decode.d6.loss_dice: 0.3797  decode.d7.loss_cls: 0.3088  decode.d7.loss_mask: 0.2777  decode.d7.loss_dice: 0.4013  decode.d8.loss_cls: 0.3954  decode.d8.loss_mask: 0.2700  decode.d8.loss_dice: 0.3979
07/29 23:58:27 - mmengine - INFO - Iter(train) [ 6900/80000]  base_lr: 9.2204e-05 lr: 9.2204e-06  eta: 10:47:22  time: 0.5224  data_time: 0.0127  memory: 5898  grad_norm: 219.3889  loss: 10.9665  decode.loss_cls: 0.2691  decode.loss_mask: 0.3287  decode.loss_dice: 0.3618  decode.d0.loss_cls: 1.1300  decode.d0.loss_mask: 0.3495  decode.d0.loss_dice: 0.3784  decode.d1.loss_cls: 0.5103  decode.d1.loss_mask: 0.3383  decode.d1.loss_dice: 0.3756  decode.d2.loss_cls: 0.2936  decode.d2.loss_mask: 0.3285  decode.d2.loss_dice: 0.3604  decode.d3.loss_cls: 0.2706  decode.d3.loss_mask: 0.3301  decode.d3.loss_dice: 0.3614  decode.d4.loss_cls: 0.3083  decode.d4.loss_mask: 0.3362  decode.d4.loss_dice: 0.3547  decode.d5.loss_cls: 0.2785  decode.d5.loss_mask: 0.3306  decode.d5.loss_dice: 0.3648  decode.d6.loss_cls: 0.3058  decode.d6.loss_mask: 0.3358  decode.d6.loss_dice: 0.3521  decode.d7.loss_cls: 0.3342  decode.d7.loss_mask: 0.3362  decode.d7.loss_dice: 0.3589  decode.d8.loss_cls: 0.2837  decode.d8.loss_mask: 0.3337  decode.d8.loss_dice: 0.3665
07/29 23:58:53 - mmengine - INFO - Iter(train) [ 6950/80000]  base_lr: 9.2147e-05 lr: 9.2147e-06  eta: 10:46:54  time: 0.5261  data_time: 0.0131  memory: 5918  grad_norm: 190.5293  loss: 13.5710  decode.loss_cls: 0.4009  decode.loss_mask: 0.3630  decode.loss_dice: 0.4450  decode.d0.loss_cls: 1.4627  decode.d0.loss_mask: 0.3784  decode.d0.loss_dice: 0.4755  decode.d1.loss_cls: 0.6151  decode.d1.loss_mask: 0.3647  decode.d1.loss_dice: 0.4548  decode.d2.loss_cls: 0.5062  decode.d2.loss_mask: 0.3571  decode.d2.loss_dice: 0.4318  decode.d3.loss_cls: 0.4660  decode.d3.loss_mask: 0.3515  decode.d3.loss_dice: 0.4138  decode.d4.loss_cls: 0.4251  decode.d4.loss_mask: 0.3603  decode.d4.loss_dice: 0.4457  decode.d5.loss_cls: 0.4788  decode.d5.loss_mask: 0.3575  decode.d5.loss_dice: 0.4188  decode.d6.loss_cls: 0.4252  decode.d6.loss_mask: 0.3580  decode.d6.loss_dice: 0.4607  decode.d7.loss_cls: 0.3861  decode.d7.loss_mask: 0.3687  decode.d7.loss_dice: 0.4499  decode.d8.loss_cls: 0.3707  decode.d8.loss_mask: 0.3526  decode.d8.loss_dice: 0.4260
07/29 23:59:20 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/29 23:59:20 - mmengine - INFO - Iter(train) [ 7000/80000]  base_lr: 9.2090e-05 lr: 9.2090e-06  eta: 10:46:25  time: 0.5302  data_time: 0.0136  memory: 5896  grad_norm: 304.2857  loss: 14.5367  decode.loss_cls: 0.5554  decode.loss_mask: 0.4368  decode.loss_dice: 0.3748  decode.d0.loss_cls: 1.1738  decode.d0.loss_mask: 0.5110  decode.d0.loss_dice: 0.4319  decode.d1.loss_cls: 0.5562  decode.d1.loss_mask: 0.5105  decode.d1.loss_dice: 0.4287  decode.d2.loss_cls: 0.5206  decode.d2.loss_mask: 0.4841  decode.d2.loss_dice: 0.3987  decode.d3.loss_cls: 0.4782  decode.d3.loss_mask: 0.4731  decode.d3.loss_dice: 0.4082  decode.d4.loss_cls: 0.4765  decode.d4.loss_mask: 0.4612  decode.d4.loss_dice: 0.3837  decode.d5.loss_cls: 0.5371  decode.d5.loss_mask: 0.4421  decode.d5.loss_dice: 0.4005  decode.d6.loss_cls: 0.5035  decode.d6.loss_mask: 0.4372  decode.d6.loss_dice: 0.3868  decode.d7.loss_cls: 0.5414  decode.d7.loss_mask: 0.4660  decode.d7.loss_dice: 0.4012  decode.d8.loss_cls: 0.5611  decode.d8.loss_mask: 0.4488  decode.d8.loss_dice: 0.3480
07/29 23:59:46 - mmengine - INFO - Iter(train) [ 7050/80000]  base_lr: 9.2034e-05 lr: 9.2034e-06  eta: 10:45:57  time: 0.5300  data_time: 0.0135  memory: 5896  grad_norm: 159.2936  loss: 9.9099  decode.loss_cls: 0.2902  decode.loss_mask: 0.2487  decode.loss_dice: 0.3289  decode.d0.loss_cls: 1.1488  decode.d0.loss_mask: 0.2721  decode.d0.loss_dice: 0.3773  decode.d1.loss_cls: 0.4167  decode.d1.loss_mask: 0.2784  decode.d1.loss_dice: 0.3735  decode.d2.loss_cls: 0.3311  decode.d2.loss_mask: 0.2659  decode.d2.loss_dice: 0.3357  decode.d3.loss_cls: 0.2993  decode.d3.loss_mask: 0.2534  decode.d3.loss_dice: 0.3378  decode.d4.loss_cls: 0.2646  decode.d4.loss_mask: 0.2517  decode.d4.loss_dice: 0.3240  decode.d5.loss_cls: 0.2794  decode.d5.loss_mask: 0.2545  decode.d5.loss_dice: 0.3255  decode.d6.loss_cls: 0.3028  decode.d6.loss_mask: 0.2526  decode.d6.loss_dice: 0.3171  decode.d7.loss_cls: 0.3415  decode.d7.loss_mask: 0.2523  decode.d7.loss_dice: 0.3164  decode.d8.loss_cls: 0.2954  decode.d8.loss_mask: 0.2505  decode.d8.loss_dice: 0.3239
07/30 00:00:13 - mmengine - INFO - Iter(train) [ 7100/80000]  base_lr: 9.1977e-05 lr: 9.1977e-06  eta: 10:45:31  time: 0.5325  data_time: 0.0135  memory: 5920  grad_norm: 358.2725  loss: 12.8282  decode.loss_cls: 0.3196  decode.loss_mask: 0.4410  decode.loss_dice: 0.3738  decode.d0.loss_cls: 1.3353  decode.d0.loss_mask: 0.4424  decode.d0.loss_dice: 0.4286  decode.d1.loss_cls: 0.5075  decode.d1.loss_mask: 0.3566  decode.d1.loss_dice: 0.3983  decode.d2.loss_cls: 0.3357  decode.d2.loss_mask: 0.3815  decode.d2.loss_dice: 0.3784  decode.d3.loss_cls: 0.4001  decode.d3.loss_mask: 0.3927  decode.d3.loss_dice: 0.3785  decode.d4.loss_cls: 0.4265  decode.d4.loss_mask: 0.4017  decode.d4.loss_dice: 0.4004  decode.d5.loss_cls: 0.3475  decode.d5.loss_mask: 0.4140  decode.d5.loss_dice: 0.3820  decode.d6.loss_cls: 0.3769  decode.d6.loss_mask: 0.4523  decode.d6.loss_dice: 0.3932  decode.d7.loss_cls: 0.3498  decode.d7.loss_mask: 0.4474  decode.d7.loss_dice: 0.3788  decode.d8.loss_cls: 0.3758  decode.d8.loss_mask: 0.4146  decode.d8.loss_dice: 0.3974
07/30 00:00:39 - mmengine - INFO - Iter(train) [ 7150/80000]  base_lr: 9.1920e-05 lr: 9.1920e-06  eta: 10:45:05  time: 0.5296  data_time: 0.0133  memory: 5896  grad_norm: 158.7283  loss: 9.4825  decode.loss_cls: 0.2103  decode.loss_mask: 0.2910  decode.loss_dice: 0.3450  decode.d0.loss_cls: 1.1421  decode.d0.loss_mask: 0.2545  decode.d0.loss_dice: 0.4018  decode.d1.loss_cls: 0.4407  decode.d1.loss_mask: 0.2712  decode.d1.loss_dice: 0.3411  decode.d2.loss_cls: 0.2695  decode.d2.loss_mask: 0.2471  decode.d2.loss_dice: 0.3407  decode.d3.loss_cls: 0.2592  decode.d3.loss_mask: 0.2458  decode.d3.loss_dice: 0.3367  decode.d4.loss_cls: 0.2286  decode.d4.loss_mask: 0.2648  decode.d4.loss_dice: 0.3320  decode.d5.loss_cls: 0.2427  decode.d5.loss_mask: 0.2526  decode.d5.loss_dice: 0.3283  decode.d6.loss_cls: 0.2539  decode.d6.loss_mask: 0.2357  decode.d6.loss_dice: 0.3012  decode.d7.loss_cls: 0.2478  decode.d7.loss_mask: 0.2404  decode.d7.loss_dice: 0.3267  decode.d8.loss_cls: 0.1916  decode.d8.loss_mask: 0.2950  decode.d8.loss_dice: 0.3443
07/30 00:01:06 - mmengine - INFO - Iter(train) [ 7200/80000]  base_lr: 9.1863e-05 lr: 9.1863e-06  eta: 10:44:36  time: 0.5287  data_time: 0.0133  memory: 5898  grad_norm: 269.3748  loss: 11.7782  decode.loss_cls: 0.2773  decode.loss_mask: 0.3643  decode.loss_dice: 0.3739  decode.d0.loss_cls: 1.3218  decode.d0.loss_mask: 0.3767  decode.d0.loss_dice: 0.4388  decode.d1.loss_cls: 0.4090  decode.d1.loss_mask: 0.3946  decode.d1.loss_dice: 0.4325  decode.d2.loss_cls: 0.3351  decode.d2.loss_mask: 0.3499  decode.d2.loss_dice: 0.3667  decode.d3.loss_cls: 0.4301  decode.d3.loss_mask: 0.3396  decode.d3.loss_dice: 0.3413  decode.d4.loss_cls: 0.3729  decode.d4.loss_mask: 0.3435  decode.d4.loss_dice: 0.3478  decode.d5.loss_cls: 0.3095  decode.d5.loss_mask: 0.3568  decode.d5.loss_dice: 0.3836  decode.d6.loss_cls: 0.2773  decode.d6.loss_mask: 0.3626  decode.d6.loss_dice: 0.3964  decode.d7.loss_cls: 0.3113  decode.d7.loss_mask: 0.3626  decode.d7.loss_dice: 0.3791  decode.d8.loss_cls: 0.3111  decode.d8.loss_mask: 0.3501  decode.d8.loss_dice: 0.3620
07/30 00:01:32 - mmengine - INFO - Iter(train) [ 7250/80000]  base_lr: 9.1807e-05 lr: 9.1807e-06  eta: 10:44:06  time: 0.5204  data_time: 0.0122  memory: 5933  grad_norm: 473.3280  loss: 12.2354  decode.loss_cls: 0.3985  decode.loss_mask: 0.3546  decode.loss_dice: 0.3692  decode.d0.loss_cls: 1.1767  decode.d0.loss_mask: 0.3613  decode.d0.loss_dice: 0.3856  decode.d1.loss_cls: 0.5879  decode.d1.loss_mask: 0.3666  decode.d1.loss_dice: 0.3857  decode.d2.loss_cls: 0.5357  decode.d2.loss_mask: 0.3837  decode.d2.loss_dice: 0.3566  decode.d3.loss_cls: 0.4230  decode.d3.loss_mask: 0.3650  decode.d3.loss_dice: 0.3713  decode.d4.loss_cls: 0.3808  decode.d4.loss_mask: 0.3530  decode.d4.loss_dice: 0.3786  decode.d5.loss_cls: 0.3193  decode.d5.loss_mask: 0.3726  decode.d5.loss_dice: 0.3705  decode.d6.loss_cls: 0.3085  decode.d6.loss_mask: 0.3503  decode.d6.loss_dice: 0.3497  decode.d7.loss_cls: 0.3952  decode.d7.loss_mask: 0.3615  decode.d7.loss_dice: 0.3754  decode.d8.loss_cls: 0.3794  decode.d8.loss_mask: 0.3557  decode.d8.loss_dice: 0.3636
07/30 00:01:58 - mmengine - INFO - Iter(train) [ 7300/80000]  base_lr: 9.1750e-05 lr: 9.1750e-06  eta: 10:43:38  time: 0.5265  data_time: 0.0129  memory: 5933  grad_norm: 281.4647  loss: 13.5989  decode.loss_cls: 0.4877  decode.loss_mask: 0.4376  decode.loss_dice: 0.4272  decode.d0.loss_cls: 1.3119  decode.d0.loss_mask: 0.3395  decode.d0.loss_dice: 0.4084  decode.d1.loss_cls: 0.6488  decode.d1.loss_mask: 0.3581  decode.d1.loss_dice: 0.3908  decode.d2.loss_cls: 0.4733  decode.d2.loss_mask: 0.3607  decode.d2.loss_dice: 0.4067  decode.d3.loss_cls: 0.5594  decode.d3.loss_mask: 0.3460  decode.d3.loss_dice: 0.3937  decode.d4.loss_cls: 0.4912  decode.d4.loss_mask: 0.3629  decode.d4.loss_dice: 0.4132  decode.d5.loss_cls: 0.4530  decode.d5.loss_mask: 0.3626  decode.d5.loss_dice: 0.3920  decode.d6.loss_cls: 0.4394  decode.d6.loss_mask: 0.3839  decode.d6.loss_dice: 0.4243  decode.d7.loss_cls: 0.4852  decode.d7.loss_mask: 0.3694  decode.d7.loss_dice: 0.4057  decode.d8.loss_cls: 0.3964  decode.d8.loss_mask: 0.4246  decode.d8.loss_dice: 0.4454
07/30 00:02:25 - mmengine - INFO - Iter(train) [ 7350/80000]  base_lr: 9.1693e-05 lr: 9.1693e-06  eta: 10:43:12  time: 0.5315  data_time: 0.0131  memory: 5920  grad_norm: 229.1160  loss: 11.1319  decode.loss_cls: 0.3896  decode.loss_mask: 0.2859  decode.loss_dice: 0.2812  decode.d0.loss_cls: 1.3488  decode.d0.loss_mask: 0.3303  decode.d0.loss_dice: 0.3809  decode.d1.loss_cls: 0.5395  decode.d1.loss_mask: 0.3067  decode.d1.loss_dice: 0.3315  decode.d2.loss_cls: 0.4781  decode.d2.loss_mask: 0.3029  decode.d2.loss_dice: 0.3120  decode.d3.loss_cls: 0.3694  decode.d3.loss_mask: 0.3077  decode.d3.loss_dice: 0.3054  decode.d4.loss_cls: 0.3488  decode.d4.loss_mask: 0.3051  decode.d4.loss_dice: 0.3146  decode.d5.loss_cls: 0.3471  decode.d5.loss_mask: 0.3038  decode.d5.loss_dice: 0.3255  decode.d6.loss_cls: 0.3608  decode.d6.loss_mask: 0.2917  decode.d6.loss_dice: 0.2953  decode.d7.loss_cls: 0.3652  decode.d7.loss_mask: 0.2984  decode.d7.loss_dice: 0.3109  decode.d8.loss_cls: 0.3842  decode.d8.loss_mask: 0.3000  decode.d8.loss_dice: 0.3105
07/30 00:02:51 - mmengine - INFO - Iter(train) [ 7400/80000]  base_lr: 9.1636e-05 lr: 9.1636e-06  eta: 10:42:44  time: 0.5215  data_time: 0.0125  memory: 5916  grad_norm: 214.4538  loss: 13.1274  decode.loss_cls: 0.4280  decode.loss_mask: 0.4307  decode.loss_dice: 0.3113  decode.d0.loss_cls: 1.2653  decode.d0.loss_mask: 0.4913  decode.d0.loss_dice: 0.3770  decode.d1.loss_cls: 0.3976  decode.d1.loss_mask: 0.4697  decode.d1.loss_dice: 0.3287  decode.d2.loss_cls: 0.3902  decode.d2.loss_mask: 0.4251  decode.d2.loss_dice: 0.3225  decode.d3.loss_cls: 0.4822  decode.d3.loss_mask: 0.4364  decode.d3.loss_dice: 0.3083  decode.d4.loss_cls: 0.4254  decode.d4.loss_mask: 0.4785  decode.d4.loss_dice: 0.3305  decode.d5.loss_cls: 0.5497  decode.d5.loss_mask: 0.4458  decode.d5.loss_dice: 0.3332  decode.d6.loss_cls: 0.4851  decode.d6.loss_mask: 0.4555  decode.d6.loss_dice: 0.3131  decode.d7.loss_cls: 0.4668  decode.d7.loss_mask: 0.4597  decode.d7.loss_dice: 0.3178  decode.d8.loss_cls: 0.4059  decode.d8.loss_mask: 0.4513  decode.d8.loss_dice: 0.3449
07/30 00:03:18 - mmengine - INFO - Iter(train) [ 7450/80000]  base_lr: 9.1579e-05 lr: 9.1579e-06  eta: 10:42:17  time: 0.5331  data_time: 0.0132  memory: 5918  grad_norm: 284.4045  loss: 11.9427  decode.loss_cls: 0.2782  decode.loss_mask: 0.3685  decode.loss_dice: 0.3779  decode.d0.loss_cls: 1.2147  decode.d0.loss_mask: 0.4129  decode.d0.loss_dice: 0.4578  decode.d1.loss_cls: 0.5092  decode.d1.loss_mask: 0.3752  decode.d1.loss_dice: 0.3797  decode.d2.loss_cls: 0.3268  decode.d2.loss_mask: 0.3711  decode.d2.loss_dice: 0.3823  decode.d3.loss_cls: 0.3167  decode.d3.loss_mask: 0.3811  decode.d3.loss_dice: 0.3699  decode.d4.loss_cls: 0.3648  decode.d4.loss_mask: 0.3771  decode.d4.loss_dice: 0.3695  decode.d5.loss_cls: 0.3813  decode.d5.loss_mask: 0.3740  decode.d5.loss_dice: 0.3799  decode.d6.loss_cls: 0.3115  decode.d6.loss_mask: 0.3684  decode.d6.loss_dice: 0.3757  decode.d7.loss_cls: 0.3104  decode.d7.loss_mask: 0.3665  decode.d7.loss_dice: 0.3781  decode.d8.loss_cls: 0.3134  decode.d8.loss_mask: 0.3720  decode.d8.loss_dice: 0.3782
07/30 00:03:44 - mmengine - INFO - Iter(train) [ 7500/80000]  base_lr: 9.1523e-05 lr: 9.1523e-06  eta: 10:41:50  time: 0.5278  data_time: 0.0131  memory: 5918  grad_norm: 108.0789  loss: 10.4519  decode.loss_cls: 0.3416  decode.loss_mask: 0.2896  decode.loss_dice: 0.3000  decode.d0.loss_cls: 1.2693  decode.d0.loss_mask: 0.2950  decode.d0.loss_dice: 0.3380  decode.d1.loss_cls: 0.4920  decode.d1.loss_mask: 0.2910  decode.d1.loss_dice: 0.2952  decode.d2.loss_cls: 0.3690  decode.d2.loss_mask: 0.2832  decode.d2.loss_dice: 0.2726  decode.d3.loss_cls: 0.3541  decode.d3.loss_mask: 0.2779  decode.d3.loss_dice: 0.2921  decode.d4.loss_cls: 0.3525  decode.d4.loss_mask: 0.2770  decode.d4.loss_dice: 0.2980  decode.d5.loss_cls: 0.3507  decode.d5.loss_mask: 0.2759  decode.d5.loss_dice: 0.2759  decode.d6.loss_cls: 0.3659  decode.d6.loss_mask: 0.2769  decode.d6.loss_dice: 0.3090  decode.d7.loss_cls: 0.4274  decode.d7.loss_mask: 0.2739  decode.d7.loss_dice: 0.2836  decode.d8.loss_cls: 0.3444  decode.d8.loss_mask: 0.2870  decode.d8.loss_dice: 0.2931
07/30 00:04:11 - mmengine - INFO - Iter(train) [ 7550/80000]  base_lr: 9.1466e-05 lr: 9.1466e-06  eta: 10:41:24  time: 0.5305  data_time: 0.0134  memory: 5883  grad_norm: 150.6746  loss: 10.7444  decode.loss_cls: 0.4798  decode.loss_mask: 0.2302  decode.loss_dice: 0.2752  decode.d0.loss_cls: 1.2054  decode.d0.loss_mask: 0.2968  decode.d0.loss_dice: 0.3725  decode.d1.loss_cls: 0.5048  decode.d1.loss_mask: 0.2462  decode.d1.loss_dice: 0.3022  decode.d2.loss_cls: 0.4096  decode.d2.loss_mask: 0.2435  decode.d2.loss_dice: 0.3013  decode.d3.loss_cls: 0.4182  decode.d3.loss_mask: 0.2523  decode.d3.loss_dice: 0.2843  decode.d4.loss_cls: 0.3968  decode.d4.loss_mask: 0.2454  decode.d4.loss_dice: 0.2950  decode.d5.loss_cls: 0.4179  decode.d5.loss_mask: 0.2417  decode.d5.loss_dice: 0.3167  decode.d6.loss_cls: 0.4695  decode.d6.loss_mask: 0.2352  decode.d6.loss_dice: 0.2833  decode.d7.loss_cls: 0.4985  decode.d7.loss_mask: 0.2295  decode.d7.loss_dice: 0.2920  decode.d8.loss_cls: 0.4783  decode.d8.loss_mask: 0.2331  decode.d8.loss_dice: 0.2893
07/30 00:04:38 - mmengine - INFO - Iter(train) [ 7600/80000]  base_lr: 9.1409e-05 lr: 9.1409e-06  eta: 10:40:57  time: 0.5330  data_time: 0.0137  memory: 5916  grad_norm: 120.8352  loss: 9.9439  decode.loss_cls: 0.2684  decode.loss_mask: 0.2768  decode.loss_dice: 0.3087  decode.d0.loss_cls: 1.2479  decode.d0.loss_mask: 0.2801  decode.d0.loss_dice: 0.3838  decode.d1.loss_cls: 0.3320  decode.d1.loss_mask: 0.2772  decode.d1.loss_dice: 0.3275  decode.d2.loss_cls: 0.3681  decode.d2.loss_mask: 0.2668  decode.d2.loss_dice: 0.3283  decode.d3.loss_cls: 0.3250  decode.d3.loss_mask: 0.2683  decode.d3.loss_dice: 0.2910  decode.d4.loss_cls: 0.2990  decode.d4.loss_mask: 0.2641  decode.d4.loss_dice: 0.3280  decode.d5.loss_cls: 0.2616  decode.d5.loss_mask: 0.2671  decode.d5.loss_dice: 0.3123  decode.d6.loss_cls: 0.2697  decode.d6.loss_mask: 0.2730  decode.d6.loss_dice: 0.3310  decode.d7.loss_cls: 0.2499  decode.d7.loss_mask: 0.2651  decode.d7.loss_dice: 0.3574  decode.d8.loss_cls: 0.2851  decode.d8.loss_mask: 0.2808  decode.d8.loss_dice: 0.3499
07/30 00:05:04 - mmengine - INFO - Iter(train) [ 7650/80000]  base_lr: 9.1352e-05 lr: 9.1352e-06  eta: 10:40:30  time: 0.5268  data_time: 0.0132  memory: 5916  grad_norm: 139.5616  loss: 10.1250  decode.loss_cls: 0.2522  decode.loss_mask: 0.3154  decode.loss_dice: 0.3299  decode.d0.loss_cls: 1.0197  decode.d0.loss_mask: 0.3239  decode.d0.loss_dice: 0.3886  decode.d1.loss_cls: 0.3165  decode.d1.loss_mask: 0.3211  decode.d1.loss_dice: 0.3624  decode.d2.loss_cls: 0.2756  decode.d2.loss_mask: 0.3370  decode.d2.loss_dice: 0.3598  decode.d3.loss_cls: 0.3071  decode.d3.loss_mask: 0.3192  decode.d3.loss_dice: 0.3353  decode.d4.loss_cls: 0.2353  decode.d4.loss_mask: 0.3170  decode.d4.loss_dice: 0.3342  decode.d5.loss_cls: 0.2640  decode.d5.loss_mask: 0.3171  decode.d5.loss_dice: 0.3308  decode.d6.loss_cls: 0.2968  decode.d6.loss_mask: 0.3150  decode.d6.loss_dice: 0.3462  decode.d7.loss_cls: 0.2426  decode.d7.loss_mask: 0.3097  decode.d7.loss_dice: 0.3411  decode.d8.loss_cls: 0.2587  decode.d8.loss_mask: 0.3140  decode.d8.loss_dice: 0.3388
07/30 00:05:31 - mmengine - INFO - Iter(train) [ 7700/80000]  base_lr: 9.1295e-05 lr: 9.1295e-06  eta: 10:40:03  time: 0.5321  data_time: 0.0138  memory: 5918  grad_norm: 234.9775  loss: 12.2196  decode.loss_cls: 0.5127  decode.loss_mask: 0.2512  decode.loss_dice: 0.4246  decode.d0.loss_cls: 1.3674  decode.d0.loss_mask: 0.2411  decode.d0.loss_dice: 0.3941  decode.d1.loss_cls: 0.4891  decode.d1.loss_mask: 0.2713  decode.d1.loss_dice: 0.4255  decode.d2.loss_cls: 0.4190  decode.d2.loss_mask: 0.2498  decode.d2.loss_dice: 0.3948  decode.d3.loss_cls: 0.4353  decode.d3.loss_mask: 0.2489  decode.d3.loss_dice: 0.3977  decode.d4.loss_cls: 0.4405  decode.d4.loss_mask: 0.2612  decode.d4.loss_dice: 0.4026  decode.d5.loss_cls: 0.4629  decode.d5.loss_mask: 0.2532  decode.d5.loss_dice: 0.4187  decode.d6.loss_cls: 0.4265  decode.d6.loss_mask: 0.2708  decode.d6.loss_dice: 0.4052  decode.d7.loss_cls: 0.4995  decode.d7.loss_mask: 0.2729  decode.d7.loss_dice: 0.4140  decode.d8.loss_cls: 0.4932  decode.d8.loss_mask: 0.2661  decode.d8.loss_dice: 0.4097
07/30 00:05:57 - mmengine - INFO - Iter(train) [ 7750/80000]  base_lr: 9.1238e-05 lr: 9.1238e-06  eta: 10:39:34  time: 0.5303  data_time: 0.0133  memory: 5932  grad_norm: 247.6787  loss: 12.7233  decode.loss_cls: 0.4061  decode.loss_mask: 0.3556  decode.loss_dice: 0.3512  decode.d0.loss_cls: 1.2482  decode.d0.loss_mask: 0.3633  decode.d0.loss_dice: 0.4012  decode.d1.loss_cls: 0.5287  decode.d1.loss_mask: 0.3642  decode.d1.loss_dice: 0.4014  decode.d2.loss_cls: 0.5594  decode.d2.loss_mask: 0.3444  decode.d2.loss_dice: 0.3598  decode.d3.loss_cls: 0.4470  decode.d3.loss_mask: 0.3473  decode.d3.loss_dice: 0.3987  decode.d4.loss_cls: 0.4017  decode.d4.loss_mask: 0.3580  decode.d4.loss_dice: 0.4085  decode.d5.loss_cls: 0.4842  decode.d5.loss_mask: 0.3365  decode.d5.loss_dice: 0.3869  decode.d6.loss_cls: 0.4933  decode.d6.loss_mask: 0.3469  decode.d6.loss_dice: 0.3706  decode.d7.loss_cls: 0.4531  decode.d7.loss_mask: 0.3348  decode.d7.loss_dice: 0.3466  decode.d8.loss_cls: 0.4175  decode.d8.loss_mask: 0.3488  decode.d8.loss_dice: 0.3595
07/30 00:06:23 - mmengine - INFO - Iter(train) [ 7800/80000]  base_lr: 9.1182e-05 lr: 9.1182e-06  eta: 10:39:06  time: 0.5302  data_time: 0.0134  memory: 5988  grad_norm: 242.3787  loss: 13.5282  decode.loss_cls: 0.4809  decode.loss_mask: 0.3580  decode.loss_dice: 0.4214  decode.d0.loss_cls: 1.3091  decode.d0.loss_mask: 0.3624  decode.d0.loss_dice: 0.4683  decode.d1.loss_cls: 0.5263  decode.d1.loss_mask: 0.3437  decode.d1.loss_dice: 0.4182  decode.d2.loss_cls: 0.5697  decode.d2.loss_mask: 0.3368  decode.d2.loss_dice: 0.4111  decode.d3.loss_cls: 0.4824  decode.d3.loss_mask: 0.3366  decode.d3.loss_dice: 0.3978  decode.d4.loss_cls: 0.5351  decode.d4.loss_mask: 0.3295  decode.d4.loss_dice: 0.3985  decode.d5.loss_cls: 0.4724  decode.d5.loss_mask: 0.3391  decode.d5.loss_dice: 0.3833  decode.d6.loss_cls: 0.4895  decode.d6.loss_mask: 0.3422  decode.d6.loss_dice: 0.3932  decode.d7.loss_cls: 0.5859  decode.d7.loss_mask: 0.3475  decode.d7.loss_dice: 0.4185  decode.d8.loss_cls: 0.5087  decode.d8.loss_mask: 0.3458  decode.d8.loss_dice: 0.4164
07/30 00:06:50 - mmengine - INFO - Iter(train) [ 7850/80000]  base_lr: 9.1125e-05 lr: 9.1125e-06  eta: 10:38:37  time: 0.5282  data_time: 0.0137  memory: 5898  grad_norm: 136.7386  loss: 10.0558  decode.loss_cls: 0.2793  decode.loss_mask: 0.2285  decode.loss_dice: 0.3175  decode.d0.loss_cls: 1.2322  decode.d0.loss_mask: 0.2378  decode.d0.loss_dice: 0.3492  decode.d1.loss_cls: 0.4100  decode.d1.loss_mask: 0.2355  decode.d1.loss_dice: 0.3354  decode.d2.loss_cls: 0.4240  decode.d2.loss_mask: 0.2331  decode.d2.loss_dice: 0.3478  decode.d3.loss_cls: 0.3000  decode.d3.loss_mask: 0.2411  decode.d3.loss_dice: 0.3260  decode.d4.loss_cls: 0.3337  decode.d4.loss_mask: 0.2347  decode.d4.loss_dice: 0.3555  decode.d5.loss_cls: 0.3344  decode.d5.loss_mask: 0.2374  decode.d5.loss_dice: 0.3468  decode.d6.loss_cls: 0.3541  decode.d6.loss_mask: 0.2323  decode.d6.loss_dice: 0.3367  decode.d7.loss_cls: 0.3023  decode.d7.loss_mask: 0.2317  decode.d7.loss_dice: 0.3330  decode.d8.loss_cls: 0.3607  decode.d8.loss_mask: 0.2304  decode.d8.loss_dice: 0.3348
07/30 00:07:16 - mmengine - INFO - Iter(train) [ 7900/80000]  base_lr: 9.1068e-05 lr: 9.1068e-06  eta: 10:38:12  time: 0.5302  data_time: 0.0131  memory: 5897  grad_norm: 133.7835  loss: 9.1121  decode.loss_cls: 0.2545  decode.loss_mask: 0.2449  decode.loss_dice: 0.3094  decode.d0.loss_cls: 1.3186  decode.d0.loss_mask: 0.2401  decode.d0.loss_dice: 0.3279  decode.d1.loss_cls: 0.3238  decode.d1.loss_mask: 0.2346  decode.d1.loss_dice: 0.3132  decode.d2.loss_cls: 0.2401  decode.d2.loss_mask: 0.2382  decode.d2.loss_dice: 0.3200  decode.d3.loss_cls: 0.3023  decode.d3.loss_mask: 0.2356  decode.d3.loss_dice: 0.3084  decode.d4.loss_cls: 0.2023  decode.d4.loss_mask: 0.2492  decode.d4.loss_dice: 0.3218  decode.d5.loss_cls: 0.2237  decode.d5.loss_mask: 0.2407  decode.d5.loss_dice: 0.3130  decode.d6.loss_cls: 0.2010  decode.d6.loss_mask: 0.2339  decode.d6.loss_dice: 0.3114  decode.d7.loss_cls: 0.1984  decode.d7.loss_mask: 0.2419  decode.d7.loss_dice: 0.3266  decode.d8.loss_cls: 0.2663  decode.d8.loss_mask: 0.2476  decode.d8.loss_dice: 0.3225
07/30 00:07:43 - mmengine - INFO - Iter(train) [ 7950/80000]  base_lr: 9.1011e-05 lr: 9.1011e-06  eta: 10:37:44  time: 0.5295  data_time: 0.0131  memory: 5973  grad_norm: 140.6540  loss: 12.1243  decode.loss_cls: 0.4967  decode.loss_mask: 0.2617  decode.loss_dice: 0.3799  decode.d0.loss_cls: 1.3675  decode.d0.loss_mask: 0.2765  decode.d0.loss_dice: 0.3968  decode.d1.loss_cls: 0.5547  decode.d1.loss_mask: 0.2747  decode.d1.loss_dice: 0.3697  decode.d2.loss_cls: 0.4398  decode.d2.loss_mask: 0.2646  decode.d2.loss_dice: 0.3518  decode.d3.loss_cls: 0.4336  decode.d3.loss_mask: 0.2700  decode.d3.loss_dice: 0.3574  decode.d4.loss_cls: 0.4807  decode.d4.loss_mask: 0.2678  decode.d4.loss_dice: 0.3965  decode.d5.loss_cls: 0.4681  decode.d5.loss_mask: 0.2749  decode.d5.loss_dice: 0.3748  decode.d6.loss_cls: 0.4670  decode.d6.loss_mask: 0.2647  decode.d6.loss_dice: 0.3793  decode.d7.loss_cls: 0.4469  decode.d7.loss_mask: 0.2892  decode.d7.loss_dice: 0.3559  decode.d8.loss_cls: 0.5261  decode.d8.loss_mask: 0.2623  decode.d8.loss_dice: 0.3751
07/30 00:08:09 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/30 00:08:09 - mmengine - INFO - Iter(train) [ 8000/80000]  base_lr: 9.0954e-05 lr: 9.0954e-06  eta: 10:37:17  time: 0.5255  data_time: 0.0131  memory: 5895  grad_norm: 148.9612  loss: 9.3601  decode.loss_cls: 0.2766  decode.loss_mask: 0.2789  decode.loss_dice: 0.2712  decode.d0.loss_cls: 1.1890  decode.d0.loss_mask: 0.2925  decode.d0.loss_dice: 0.3025  decode.d1.loss_cls: 0.3650  decode.d1.loss_mask: 0.2760  decode.d1.loss_dice: 0.2785  decode.d2.loss_cls: 0.3497  decode.d2.loss_mask: 0.2808  decode.d2.loss_dice: 0.2648  decode.d3.loss_cls: 0.2964  decode.d3.loss_mask: 0.2794  decode.d3.loss_dice: 0.2707  decode.d4.loss_cls: 0.2715  decode.d4.loss_mask: 0.2694  decode.d4.loss_dice: 0.2663  decode.d5.loss_cls: 0.2477  decode.d5.loss_mask: 0.2702  decode.d5.loss_dice: 0.2923  decode.d6.loss_cls: 0.2611  decode.d6.loss_mask: 0.2691  decode.d6.loss_dice: 0.2706  decode.d7.loss_cls: 0.2651  decode.d7.loss_mask: 0.2724  decode.d7.loss_dice: 0.2621  decode.d8.loss_cls: 0.3016  decode.d8.loss_mask: 0.2741  decode.d8.loss_dice: 0.2946
07/30 00:08:36 - mmengine - INFO - Iter(train) [ 8050/80000]  base_lr: 9.0897e-05 lr: 9.0897e-06  eta: 10:36:49  time: 0.5328  data_time: 0.0137  memory: 5916  grad_norm: 179.7066  loss: 10.5787  decode.loss_cls: 0.3629  decode.loss_mask: 0.2635  decode.loss_dice: 0.3181  decode.d0.loss_cls: 1.3946  decode.d0.loss_mask: 0.2708  decode.d0.loss_dice: 0.3692  decode.d1.loss_cls: 0.4550  decode.d1.loss_mask: 0.2675  decode.d1.loss_dice: 0.3238  decode.d2.loss_cls: 0.4137  decode.d2.loss_mask: 0.2559  decode.d2.loss_dice: 0.3011  decode.d3.loss_cls: 0.4104  decode.d3.loss_mask: 0.2662  decode.d3.loss_dice: 0.3050  decode.d4.loss_cls: 0.3761  decode.d4.loss_mask: 0.2543  decode.d4.loss_dice: 0.3219  decode.d5.loss_cls: 0.2906  decode.d5.loss_mask: 0.2639  decode.d5.loss_dice: 0.3239  decode.d6.loss_cls: 0.3377  decode.d6.loss_mask: 0.2668  decode.d6.loss_dice: 0.3336  decode.d7.loss_cls: 0.2784  decode.d7.loss_mask: 0.2709  decode.d7.loss_dice: 0.3366  decode.d8.loss_cls: 0.3181  decode.d8.loss_mask: 0.2723  decode.d8.loss_dice: 0.3558
07/30 00:09:02 - mmengine - INFO - Iter(train) [ 8100/80000]  base_lr: 9.0841e-05 lr: 9.0841e-06  eta: 10:36:22  time: 0.5270  data_time: 0.0129  memory: 5900  grad_norm: 121.1593  loss: 8.9393  decode.loss_cls: 0.1835  decode.loss_mask: 0.2649  decode.loss_dice: 0.3178  decode.d0.loss_cls: 1.1571  decode.d0.loss_mask: 0.2656  decode.d0.loss_dice: 0.3307  decode.d1.loss_cls: 0.3379  decode.d1.loss_mask: 0.2693  decode.d1.loss_dice: 0.3264  decode.d2.loss_cls: 0.2700  decode.d2.loss_mask: 0.2590  decode.d2.loss_dice: 0.3063  decode.d3.loss_cls: 0.2187  decode.d3.loss_mask: 0.2572  decode.d3.loss_dice: 0.3070  decode.d4.loss_cls: 0.1979  decode.d4.loss_mask: 0.2570  decode.d4.loss_dice: 0.3153  decode.d5.loss_cls: 0.2089  decode.d5.loss_mask: 0.2611  decode.d5.loss_dice: 0.3051  decode.d6.loss_cls: 0.2196  decode.d6.loss_mask: 0.2567  decode.d6.loss_dice: 0.2974  decode.d7.loss_cls: 0.1671  decode.d7.loss_mask: 0.2653  decode.d7.loss_dice: 0.3228  decode.d8.loss_cls: 0.2141  decode.d8.loss_mask: 0.2613  decode.d8.loss_dice: 0.3183
07/30 00:09:29 - mmengine - INFO - Iter(train) [ 8150/80000]  base_lr: 9.0784e-05 lr: 9.0784e-06  eta: 10:35:55  time: 0.5380  data_time: 0.0138  memory: 5883  grad_norm: 199.8782  loss: 12.3540  decode.loss_cls: 0.2756  decode.loss_mask: 0.3383  decode.loss_dice: 0.4330  decode.d0.loss_cls: 1.3892  decode.d0.loss_mask: 0.3940  decode.d0.loss_dice: 0.4942  decode.d1.loss_cls: 0.5131  decode.d1.loss_mask: 0.3241  decode.d1.loss_dice: 0.4392  decode.d2.loss_cls: 0.4037  decode.d2.loss_mask: 0.3244  decode.d2.loss_dice: 0.4243  decode.d3.loss_cls: 0.4009  decode.d3.loss_mask: 0.3309  decode.d3.loss_dice: 0.4262  decode.d4.loss_cls: 0.3479  decode.d4.loss_mask: 0.3382  decode.d4.loss_dice: 0.4378  decode.d5.loss_cls: 0.3736  decode.d5.loss_mask: 0.3221  decode.d5.loss_dice: 0.4263  decode.d6.loss_cls: 0.2966  decode.d6.loss_mask: 0.3292  decode.d6.loss_dice: 0.4276  decode.d7.loss_cls: 0.3164  decode.d7.loss_mask: 0.3324  decode.d7.loss_dice: 0.4500  decode.d8.loss_cls: 0.2767  decode.d8.loss_mask: 0.3280  decode.d8.loss_dice: 0.4402
07/30 00:09:55 - mmengine - INFO - Iter(train) [ 8200/80000]  base_lr: 9.0727e-05 lr: 9.0727e-06  eta: 10:35:31  time: 0.5321  data_time: 0.0131  memory: 5896  grad_norm: 634.8708  loss: 11.1318  decode.loss_cls: 0.2944  decode.loss_mask: 0.3657  decode.loss_dice: 0.3582  decode.d0.loss_cls: 1.3288  decode.d0.loss_mask: 0.2993  decode.d0.loss_dice: 0.3956  decode.d1.loss_cls: 0.4857  decode.d1.loss_mask: 0.2912  decode.d1.loss_dice: 0.3667  decode.d2.loss_cls: 0.2721  decode.d2.loss_mask: 0.2917  decode.d2.loss_dice: 0.3451  decode.d3.loss_cls: 0.3255  decode.d3.loss_mask: 0.3037  decode.d3.loss_dice: 0.3536  decode.d4.loss_cls: 0.3175  decode.d4.loss_mask: 0.3110  decode.d4.loss_dice: 0.3764  decode.d5.loss_cls: 0.2694  decode.d5.loss_mask: 0.3592  decode.d5.loss_dice: 0.3795  decode.d6.loss_cls: 0.2614  decode.d6.loss_mask: 0.3528  decode.d6.loss_dice: 0.3594  decode.d7.loss_cls: 0.2798  decode.d7.loss_mask: 0.3620  decode.d7.loss_dice: 0.3568  decode.d8.loss_cls: 0.3348  decode.d8.loss_mask: 0.3660  decode.d8.loss_dice: 0.3685
07/30 00:10:22 - mmengine - INFO - Iter(train) [ 8250/80000]  base_lr: 9.0670e-05 lr: 9.0670e-06  eta: 10:35:05  time: 0.5322  data_time: 0.0135  memory: 5918  grad_norm: 123.3419  loss: 9.6162  decode.loss_cls: 0.2643  decode.loss_mask: 0.2753  decode.loss_dice: 0.3187  decode.d0.loss_cls: 1.0806  decode.d0.loss_mask: 0.2743  decode.d0.loss_dice: 0.3532  decode.d1.loss_cls: 0.4105  decode.d1.loss_mask: 0.2731  decode.d1.loss_dice: 0.3400  decode.d2.loss_cls: 0.3472  decode.d2.loss_mask: 0.2760  decode.d2.loss_dice: 0.3279  decode.d3.loss_cls: 0.2574  decode.d3.loss_mask: 0.2696  decode.d3.loss_dice: 0.3066  decode.d4.loss_cls: 0.2478  decode.d4.loss_mask: 0.2669  decode.d4.loss_dice: 0.3084  decode.d5.loss_cls: 0.2401  decode.d5.loss_mask: 0.2685  decode.d5.loss_dice: 0.3123  decode.d6.loss_cls: 0.2667  decode.d6.loss_mask: 0.2639  decode.d6.loss_dice: 0.3143  decode.d7.loss_cls: 0.2883  decode.d7.loss_mask: 0.2765  decode.d7.loss_dice: 0.3285  decode.d8.loss_cls: 0.2638  decode.d8.loss_mask: 0.2760  decode.d8.loss_dice: 0.3198
07/30 00:10:49 - mmengine - INFO - Iter(train) [ 8300/80000]  base_lr: 9.0613e-05 lr: 9.0613e-06  eta: 10:34:38  time: 0.5333  data_time: 0.0133  memory: 5897  grad_norm: 161.3761  loss: 9.0788  decode.loss_cls: 0.2155  decode.loss_mask: 0.2825  decode.loss_dice: 0.2847  decode.d0.loss_cls: 1.0990  decode.d0.loss_mask: 0.2987  decode.d0.loss_dice: 0.3251  decode.d1.loss_cls: 0.3009  decode.d1.loss_mask: 0.2975  decode.d1.loss_dice: 0.2940  decode.d2.loss_cls: 0.2446  decode.d2.loss_mask: 0.2922  decode.d2.loss_dice: 0.2761  decode.d3.loss_cls: 0.2450  decode.d3.loss_mask: 0.2909  decode.d3.loss_dice: 0.3124  decode.d4.loss_cls: 0.2120  decode.d4.loss_mask: 0.2925  decode.d4.loss_dice: 0.2929  decode.d5.loss_cls: 0.2328  decode.d5.loss_mask: 0.2914  decode.d5.loss_dice: 0.3057  decode.d6.loss_cls: 0.2098  decode.d6.loss_mask: 0.2871  decode.d6.loss_dice: 0.2824  decode.d7.loss_cls: 0.2398  decode.d7.loss_mask: 0.2862  decode.d7.loss_dice: 0.2788  decode.d8.loss_cls: 0.2307  decode.d8.loss_mask: 0.2841  decode.d8.loss_dice: 0.2937
07/30 00:11:15 - mmengine - INFO - Iter(train) [ 8350/80000]  base_lr: 9.0556e-05 lr: 9.0556e-06  eta: 10:34:11  time: 0.5302  data_time: 0.0135  memory: 5920  grad_norm: 204.6364  loss: 11.0105  decode.loss_cls: 0.3449  decode.loss_mask: 0.3522  decode.loss_dice: 0.3085  decode.d0.loss_cls: 1.1672  decode.d0.loss_mask: 0.3679  decode.d0.loss_dice: 0.3135  decode.d1.loss_cls: 0.3677  decode.d1.loss_mask: 0.3516  decode.d1.loss_dice: 0.3017  decode.d2.loss_cls: 0.4002  decode.d2.loss_mask: 0.3470  decode.d2.loss_dice: 0.2803  decode.d3.loss_cls: 0.4375  decode.d3.loss_mask: 0.3502  decode.d3.loss_dice: 0.2570  decode.d4.loss_cls: 0.3898  decode.d4.loss_mask: 0.3463  decode.d4.loss_dice: 0.2678  decode.d5.loss_cls: 0.3397  decode.d5.loss_mask: 0.3609  decode.d5.loss_dice: 0.3130  decode.d6.loss_cls: 0.3625  decode.d6.loss_mask: 0.3510  decode.d6.loss_dice: 0.2943  decode.d7.loss_cls: 0.3713  decode.d7.loss_mask: 0.3594  decode.d7.loss_dice: 0.2730  decode.d8.loss_cls: 0.3780  decode.d8.loss_mask: 0.3576  decode.d8.loss_dice: 0.2985
07/30 00:11:42 - mmengine - INFO - Iter(train) [ 8400/80000]  base_lr: 9.0499e-05 lr: 9.0499e-06  eta: 10:33:44  time: 0.5268  data_time: 0.0136  memory: 5918  grad_norm: 465.5972  loss: 12.4754  decode.loss_cls: 0.2863  decode.loss_mask: 0.4460  decode.loss_dice: 0.4558  decode.d0.loss_cls: 1.1994  decode.d0.loss_mask: 0.3581  decode.d0.loss_dice: 0.4723  decode.d1.loss_cls: 0.3162  decode.d1.loss_mask: 0.3793  decode.d1.loss_dice: 0.4975  decode.d2.loss_cls: 0.3363  decode.d2.loss_mask: 0.3682  decode.d2.loss_dice: 0.4830  decode.d3.loss_cls: 0.3783  decode.d3.loss_mask: 0.3327  decode.d3.loss_dice: 0.4186  decode.d4.loss_cls: 0.3333  decode.d4.loss_mask: 0.3661  decode.d4.loss_dice: 0.4245  decode.d5.loss_cls: 0.2825  decode.d5.loss_mask: 0.4191  decode.d5.loss_dice: 0.4365  decode.d6.loss_cls: 0.2259  decode.d6.loss_mask: 0.4825  decode.d6.loss_dice: 0.4487  decode.d7.loss_cls: 0.2197  decode.d7.loss_mask: 0.4879  decode.d7.loss_dice: 0.4552  decode.d8.loss_cls: 0.2279  decode.d8.loss_mask: 0.4657  decode.d8.loss_dice: 0.4719
07/30 00:12:08 - mmengine - INFO - Iter(train) [ 8450/80000]  base_lr: 9.0443e-05 lr: 9.0443e-06  eta: 10:33:17  time: 0.5316  data_time: 0.0134  memory: 5896  grad_norm: 171.9604  loss: 11.0493  decode.loss_cls: 0.4002  decode.loss_mask: 0.2876  decode.loss_dice: 0.3419  decode.d0.loss_cls: 1.2804  decode.d0.loss_mask: 0.2792  decode.d0.loss_dice: 0.3696  decode.d1.loss_cls: 0.4711  decode.d1.loss_mask: 0.2828  decode.d1.loss_dice: 0.3733  decode.d2.loss_cls: 0.3675  decode.d2.loss_mask: 0.2827  decode.d2.loss_dice: 0.3344  decode.d3.loss_cls: 0.4197  decode.d3.loss_mask: 0.2785  decode.d3.loss_dice: 0.3450  decode.d4.loss_cls: 0.3652  decode.d4.loss_mask: 0.2727  decode.d4.loss_dice: 0.3385  decode.d5.loss_cls: 0.3677  decode.d5.loss_mask: 0.2790  decode.d5.loss_dice: 0.3527  decode.d6.loss_cls: 0.3851  decode.d6.loss_mask: 0.2781  decode.d6.loss_dice: 0.3432  decode.d7.loss_cls: 0.3700  decode.d7.loss_mask: 0.2758  decode.d7.loss_dice: 0.3229  decode.d8.loss_cls: 0.3554  decode.d8.loss_mask: 0.2841  decode.d8.loss_dice: 0.3449
07/30 00:12:35 - mmengine - INFO - Iter(train) [ 8500/80000]  base_lr: 9.0386e-05 lr: 9.0386e-06  eta: 10:32:50  time: 0.5264  data_time: 0.0126  memory: 5897  grad_norm: 272.4321  loss: 10.0407  decode.loss_cls: 0.2739  decode.loss_mask: 0.2746  decode.loss_dice: 0.3226  decode.d0.loss_cls: 1.2362  decode.d0.loss_mask: 0.2945  decode.d0.loss_dice: 0.3848  decode.d1.loss_cls: 0.4137  decode.d1.loss_mask: 0.2892  decode.d1.loss_dice: 0.3398  decode.d2.loss_cls: 0.2918  decode.d2.loss_mask: 0.2806  decode.d2.loss_dice: 0.3322  decode.d3.loss_cls: 0.3129  decode.d3.loss_mask: 0.2761  decode.d3.loss_dice: 0.3147  decode.d4.loss_cls: 0.2498  decode.d4.loss_mask: 0.2795  decode.d4.loss_dice: 0.3336  decode.d5.loss_cls: 0.2757  decode.d5.loss_mask: 0.2790  decode.d5.loss_dice: 0.3266  decode.d6.loss_cls: 0.2794  decode.d6.loss_mask: 0.2825  decode.d6.loss_dice: 0.3334  decode.d7.loss_cls: 0.2720  decode.d7.loss_mask: 0.2776  decode.d7.loss_dice: 0.3350  decode.d8.loss_cls: 0.2706  decode.d8.loss_mask: 0.2863  decode.d8.loss_dice: 0.3222
07/30 00:13:01 - mmengine - INFO - Iter(train) [ 8550/80000]  base_lr: 9.0329e-05 lr: 9.0329e-06  eta: 10:32:23  time: 0.5285  data_time: 0.0132  memory: 5899  grad_norm: 188.7238  loss: 9.0202  decode.loss_cls: 0.1317  decode.loss_mask: 0.3794  decode.loss_dice: 0.2725  decode.d0.loss_cls: 1.0822  decode.d0.loss_mask: 0.3676  decode.d0.loss_dice: 0.2966  decode.d1.loss_cls: 0.1956  decode.d1.loss_mask: 0.3867  decode.d1.loss_dice: 0.2797  decode.d2.loss_cls: 0.1497  decode.d2.loss_mask: 0.3734  decode.d2.loss_dice: 0.2749  decode.d3.loss_cls: 0.1865  decode.d3.loss_mask: 0.3459  decode.d3.loss_dice: 0.2571  decode.d4.loss_cls: 0.1936  decode.d4.loss_mask: 0.3493  decode.d4.loss_dice: 0.2591  decode.d5.loss_cls: 0.1492  decode.d5.loss_mask: 0.3938  decode.d5.loss_dice: 0.2827  decode.d6.loss_cls: 0.1579  decode.d6.loss_mask: 0.3886  decode.d6.loss_dice: 0.2646  decode.d7.loss_cls: 0.1286  decode.d7.loss_mask: 0.3829  decode.d7.loss_dice: 0.2674  decode.d8.loss_cls: 0.1667  decode.d8.loss_mask: 0.3851  decode.d8.loss_dice: 0.2712
07/30 00:13:28 - mmengine - INFO - Iter(train) [ 8600/80000]  base_lr: 9.0272e-05 lr: 9.0272e-06  eta: 10:31:56  time: 0.5340  data_time: 0.0134  memory: 5934  grad_norm: 206.9474  loss: 10.9685  decode.loss_cls: 0.3835  decode.loss_mask: 0.2770  decode.loss_dice: 0.3434  decode.d0.loss_cls: 1.2832  decode.d0.loss_mask: 0.2925  decode.d0.loss_dice: 0.3539  decode.d1.loss_cls: 0.4875  decode.d1.loss_mask: 0.2856  decode.d1.loss_dice: 0.3338  decode.d2.loss_cls: 0.3604  decode.d2.loss_mask: 0.2821  decode.d2.loss_dice: 0.3506  decode.d3.loss_cls: 0.3566  decode.d3.loss_mask: 0.2782  decode.d3.loss_dice: 0.3240  decode.d4.loss_cls: 0.3924  decode.d4.loss_mask: 0.2675  decode.d4.loss_dice: 0.3289  decode.d5.loss_cls: 0.3701  decode.d5.loss_mask: 0.2741  decode.d5.loss_dice: 0.3386  decode.d6.loss_cls: 0.3795  decode.d6.loss_mask: 0.2769  decode.d6.loss_dice: 0.3281  decode.d7.loss_cls: 0.3712  decode.d7.loss_mask: 0.2965  decode.d7.loss_dice: 0.3529  decode.d8.loss_cls: 0.3606  decode.d8.loss_mask: 0.2907  decode.d8.loss_dice: 0.3482
07/30 00:13:54 - mmengine - INFO - Iter(train) [ 8650/80000]  base_lr: 9.0215e-05 lr: 9.0215e-06  eta: 10:31:30  time: 0.5369  data_time: 0.0137  memory: 5918  grad_norm: 118.6154  loss: 8.6098  decode.loss_cls: 0.2038  decode.loss_mask: 0.2469  decode.loss_dice: 0.2822  decode.d0.loss_cls: 1.2447  decode.d0.loss_mask: 0.2668  decode.d0.loss_dice: 0.3361  decode.d1.loss_cls: 0.2856  decode.d1.loss_mask: 0.2499  decode.d1.loss_dice: 0.2799  decode.d2.loss_cls: 0.2102  decode.d2.loss_mask: 0.2475  decode.d2.loss_dice: 0.2801  decode.d3.loss_cls: 0.2469  decode.d3.loss_mask: 0.2403  decode.d3.loss_dice: 0.2699  decode.d4.loss_cls: 0.2203  decode.d4.loss_mask: 0.2449  decode.d4.loss_dice: 0.2733  decode.d5.loss_cls: 0.2188  decode.d5.loss_mask: 0.2449  decode.d5.loss_dice: 0.2769  decode.d6.loss_cls: 0.2281  decode.d6.loss_mask: 0.2427  decode.d6.loss_dice: 0.2732  decode.d7.loss_cls: 0.2454  decode.d7.loss_mask: 0.2454  decode.d7.loss_dice: 0.2707  decode.d8.loss_cls: 0.2292  decode.d8.loss_mask: 0.2446  decode.d8.loss_dice: 0.2605
07/30 00:14:21 - mmengine - INFO - Iter(train) [ 8700/80000]  base_lr: 9.0158e-05 lr: 9.0158e-06  eta: 10:31:04  time: 0.5289  data_time: 0.0129  memory: 5916  grad_norm: 114.9761  loss: 8.6024  decode.loss_cls: 0.2051  decode.loss_mask: 0.2548  decode.loss_dice: 0.3010  decode.d0.loss_cls: 1.2906  decode.d0.loss_mask: 0.2573  decode.d0.loss_dice: 0.2984  decode.d1.loss_cls: 0.2586  decode.d1.loss_mask: 0.2566  decode.d1.loss_dice: 0.3005  decode.d2.loss_cls: 0.2145  decode.d2.loss_mask: 0.2486  decode.d2.loss_dice: 0.2849  decode.d3.loss_cls: 0.2095  decode.d3.loss_mask: 0.2508  decode.d3.loss_dice: 0.2847  decode.d4.loss_cls: 0.2410  decode.d4.loss_mask: 0.2544  decode.d4.loss_dice: 0.2782  decode.d5.loss_cls: 0.2032  decode.d5.loss_mask: 0.2476  decode.d5.loss_dice: 0.2841  decode.d6.loss_cls: 0.1886  decode.d6.loss_mask: 0.2524  decode.d6.loss_dice: 0.2923  decode.d7.loss_cls: 0.1708  decode.d7.loss_mask: 0.2477  decode.d7.loss_dice: 0.2869  decode.d8.loss_cls: 0.1834  decode.d8.loss_mask: 0.2501  decode.d8.loss_dice: 0.3058
07/30 00:14:47 - mmengine - INFO - Iter(train) [ 8750/80000]  base_lr: 9.0101e-05 lr: 9.0101e-06  eta: 10:30:38  time: 0.5350  data_time: 0.0144  memory: 5934  grad_norm: 229.7718  loss: 10.3408  decode.loss_cls: 0.3149  decode.loss_mask: 0.2916  decode.loss_dice: 0.3221  decode.d0.loss_cls: 1.3321  decode.d0.loss_mask: 0.3045  decode.d0.loss_dice: 0.3799  decode.d1.loss_cls: 0.3655  decode.d1.loss_mask: 0.3016  decode.d1.loss_dice: 0.3461  decode.d2.loss_cls: 0.3726  decode.d2.loss_mask: 0.2982  decode.d2.loss_dice: 0.3330  decode.d3.loss_cls: 0.2998  decode.d3.loss_mask: 0.2917  decode.d3.loss_dice: 0.3327  decode.d4.loss_cls: 0.2554  decode.d4.loss_mask: 0.2863  decode.d4.loss_dice: 0.3174  decode.d5.loss_cls: 0.2820  decode.d5.loss_mask: 0.2893  decode.d5.loss_dice: 0.3314  decode.d6.loss_cls: 0.2722  decode.d6.loss_mask: 0.2846  decode.d6.loss_dice: 0.3290  decode.d7.loss_cls: 0.2580  decode.d7.loss_mask: 0.2867  decode.d7.loss_dice: 0.3150  decode.d8.loss_cls: 0.3282  decode.d8.loss_mask: 0.3038  decode.d8.loss_dice: 0.3152
07/30 00:15:14 - mmengine - INFO - Iter(train) [ 8800/80000]  base_lr: 9.0044e-05 lr: 9.0044e-06  eta: 10:30:13  time: 0.5288  data_time: 0.0132  memory: 5918  grad_norm: 156.3879  loss: 12.8456  decode.loss_cls: 0.4811  decode.loss_mask: 0.3383  decode.loss_dice: 0.3594  decode.d0.loss_cls: 1.4093  decode.d0.loss_mask: 0.3520  decode.d0.loss_dice: 0.3812  decode.d1.loss_cls: 0.6116  decode.d1.loss_mask: 0.3436  decode.d1.loss_dice: 0.3870  decode.d2.loss_cls: 0.5087  decode.d2.loss_mask: 0.3462  decode.d2.loss_dice: 0.3610  decode.d3.loss_cls: 0.4355  decode.d3.loss_mask: 0.3401  decode.d3.loss_dice: 0.3698  decode.d4.loss_cls: 0.4842  decode.d4.loss_mask: 0.3412  decode.d4.loss_dice: 0.3888  decode.d5.loss_cls: 0.4275  decode.d5.loss_mask: 0.3359  decode.d5.loss_dice: 0.3519  decode.d6.loss_cls: 0.4267  decode.d6.loss_mask: 0.3379  decode.d6.loss_dice: 0.3692  decode.d7.loss_cls: 0.4418  decode.d7.loss_mask: 0.3420  decode.d7.loss_dice: 0.3678  decode.d8.loss_cls: 0.4934  decode.d8.loss_mask: 0.3361  decode.d8.loss_dice: 0.3766
07/30 00:15:41 - mmengine - INFO - Iter(train) [ 8850/80000]  base_lr: 8.9987e-05 lr: 8.9987e-06  eta: 10:29:47  time: 0.5327  data_time: 0.0138  memory: 5897  grad_norm: 141.8546  loss: 10.8077  decode.loss_cls: 0.3149  decode.loss_mask: 0.2580  decode.loss_dice: 0.3924  decode.d0.loss_cls: 1.3235  decode.d0.loss_mask: 0.2716  decode.d0.loss_dice: 0.4095  decode.d1.loss_cls: 0.5198  decode.d1.loss_mask: 0.2682  decode.d1.loss_dice: 0.3788  decode.d2.loss_cls: 0.3933  decode.d2.loss_mask: 0.2660  decode.d2.loss_dice: 0.3712  decode.d3.loss_cls: 0.3552  decode.d3.loss_mask: 0.2551  decode.d3.loss_dice: 0.3688  decode.d4.loss_cls: 0.3156  decode.d4.loss_mask: 0.2646  decode.d4.loss_dice: 0.3759  decode.d5.loss_cls: 0.3033  decode.d5.loss_mask: 0.2667  decode.d5.loss_dice: 0.3748  decode.d6.loss_cls: 0.3142  decode.d6.loss_mask: 0.2585  decode.d6.loss_dice: 0.3669  decode.d7.loss_cls: 0.2729  decode.d7.loss_mask: 0.2539  decode.d7.loss_dice: 0.3594  decode.d8.loss_cls: 0.2976  decode.d8.loss_mask: 0.2573  decode.d8.loss_dice: 0.3799
07/30 00:16:07 - mmengine - INFO - Iter(train) [ 8900/80000]  base_lr: 8.9930e-05 lr: 8.9930e-06  eta: 10:29:21  time: 0.5297  data_time: 0.0132  memory: 5918  grad_norm: 116.4646  loss: 10.1430  decode.loss_cls: 0.3319  decode.loss_mask: 0.2483  decode.loss_dice: 0.2949  decode.d0.loss_cls: 1.3444  decode.d0.loss_mask: 0.2593  decode.d0.loss_dice: 0.3380  decode.d1.loss_cls: 0.4453  decode.d1.loss_mask: 0.2670  decode.d1.loss_dice: 0.3184  decode.d2.loss_cls: 0.4279  decode.d2.loss_mask: 0.2559  decode.d2.loss_dice: 0.2972  decode.d3.loss_cls: 0.4189  decode.d3.loss_mask: 0.2556  decode.d3.loss_dice: 0.3010  decode.d4.loss_cls: 0.3713  decode.d4.loss_mask: 0.2514  decode.d4.loss_dice: 0.3152  decode.d5.loss_cls: 0.3127  decode.d5.loss_mask: 0.2501  decode.d5.loss_dice: 0.3121  decode.d6.loss_cls: 0.2343  decode.d6.loss_mask: 0.2483  decode.d6.loss_dice: 0.3061  decode.d7.loss_cls: 0.3219  decode.d7.loss_mask: 0.2484  decode.d7.loss_dice: 0.2975  decode.d8.loss_cls: 0.3287  decode.d8.loss_mask: 0.2453  decode.d8.loss_dice: 0.2957
07/30 00:16:34 - mmengine - INFO - Iter(train) [ 8950/80000]  base_lr: 8.9873e-05 lr: 8.9873e-06  eta: 10:28:55  time: 0.5320  data_time: 0.0131  memory: 5933  grad_norm: 424.2589  loss: 9.4647  decode.loss_cls: 0.2259  decode.loss_mask: 0.3170  decode.loss_dice: 0.3133  decode.d0.loss_cls: 1.1558  decode.d0.loss_mask: 0.3212  decode.d0.loss_dice: 0.3129  decode.d1.loss_cls: 0.2660  decode.d1.loss_mask: 0.3223  decode.d1.loss_dice: 0.2948  decode.d2.loss_cls: 0.3039  decode.d2.loss_mask: 0.3174  decode.d2.loss_dice: 0.2910  decode.d3.loss_cls: 0.2434  decode.d3.loss_mask: 0.3195  decode.d3.loss_dice: 0.2966  decode.d4.loss_cls: 0.2373  decode.d4.loss_mask: 0.3190  decode.d4.loss_dice: 0.3044  decode.d5.loss_cls: 0.2362  decode.d5.loss_mask: 0.3188  decode.d5.loss_dice: 0.3020  decode.d6.loss_cls: 0.1822  decode.d6.loss_mask: 0.3096  decode.d6.loss_dice: 0.2976  decode.d7.loss_cls: 0.2192  decode.d7.loss_mask: 0.3127  decode.d7.loss_dice: 0.2945  decode.d8.loss_cls: 0.2084  decode.d8.loss_mask: 0.3159  decode.d8.loss_dice: 0.3060
07/30 00:17:00 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/30 00:17:00 - mmengine - INFO - Iter(train) [ 9000/80000]  base_lr: 8.9817e-05 lr: 8.9817e-06  eta: 10:28:28  time: 0.5282  data_time: 0.0131  memory: 5882  grad_norm: 230.7503  loss: 11.0122  decode.loss_cls: 0.3075  decode.loss_mask: 0.3112  decode.loss_dice: 0.3626  decode.d0.loss_cls: 1.2347  decode.d0.loss_mask: 0.3252  decode.d0.loss_dice: 0.4056  decode.d1.loss_cls: 0.4502  decode.d1.loss_mask: 0.2909  decode.d1.loss_dice: 0.3526  decode.d2.loss_cls: 0.3919  decode.d2.loss_mask: 0.2894  decode.d2.loss_dice: 0.3627  decode.d3.loss_cls: 0.3361  decode.d3.loss_mask: 0.2948  decode.d3.loss_dice: 0.3668  decode.d4.loss_cls: 0.3078  decode.d4.loss_mask: 0.2937  decode.d4.loss_dice: 0.3409  decode.d5.loss_cls: 0.4015  decode.d5.loss_mask: 0.2942  decode.d5.loss_dice: 0.3539  decode.d6.loss_cls: 0.3379  decode.d6.loss_mask: 0.2874  decode.d6.loss_dice: 0.3623  decode.d7.loss_cls: 0.3003  decode.d7.loss_mask: 0.3101  decode.d7.loss_dice: 0.3697  decode.d8.loss_cls: 0.3467  decode.d8.loss_mask: 0.2882  decode.d8.loss_dice: 0.3355
07/30 00:17:27 - mmengine - INFO - Iter(train) [ 9050/80000]  base_lr: 8.9760e-05 lr: 8.9760e-06  eta: 10:28:02  time: 0.5316  data_time: 0.0133  memory: 5973  grad_norm: 132.2235  loss: 10.9070  decode.loss_cls: 0.2498  decode.loss_mask: 0.2572  decode.loss_dice: 0.3883  decode.d0.loss_cls: 1.3401  decode.d0.loss_mask: 0.2678  decode.d0.loss_dice: 0.4363  decode.d1.loss_cls: 0.4927  decode.d1.loss_mask: 0.2751  decode.d1.loss_dice: 0.3803  decode.d2.loss_cls: 0.3648  decode.d2.loss_mask: 0.2644  decode.d2.loss_dice: 0.4123  decode.d3.loss_cls: 0.3209  decode.d3.loss_mask: 0.2671  decode.d3.loss_dice: 0.4146  decode.d4.loss_cls: 0.3008  decode.d4.loss_mask: 0.2660  decode.d4.loss_dice: 0.4049  decode.d5.loss_cls: 0.3002  decode.d5.loss_mask: 0.2652  decode.d5.loss_dice: 0.4083  decode.d6.loss_cls: 0.2901  decode.d6.loss_mask: 0.2602  decode.d6.loss_dice: 0.3812  decode.d7.loss_cls: 0.2586  decode.d7.loss_mask: 0.2604  decode.d7.loss_dice: 0.4311  decode.d8.loss_cls: 0.2848  decode.d8.loss_mask: 0.2607  decode.d8.loss_dice: 0.4027
07/30 00:17:54 - mmengine - INFO - Iter(train) [ 9100/80000]  base_lr: 8.9703e-05 lr: 8.9703e-06  eta: 10:27:36  time: 0.5342  data_time: 0.0133  memory: 5896  grad_norm: 175.3191  loss: 12.0667  decode.loss_cls: 0.5634  decode.loss_mask: 0.2527  decode.loss_dice: 0.3051  decode.d0.loss_cls: 1.3235  decode.d0.loss_mask: 0.2724  decode.d0.loss_dice: 0.3514  decode.d1.loss_cls: 0.5317  decode.d1.loss_mask: 0.2576  decode.d1.loss_dice: 0.3321  decode.d2.loss_cls: 0.5219  decode.d2.loss_mask: 0.2546  decode.d2.loss_dice: 0.3227  decode.d3.loss_cls: 0.5142  decode.d3.loss_mask: 0.2563  decode.d3.loss_dice: 0.3163  decode.d4.loss_cls: 0.5172  decode.d4.loss_mask: 0.2563  decode.d4.loss_dice: 0.3356  decode.d5.loss_cls: 0.5374  decode.d5.loss_mask: 0.2579  decode.d5.loss_dice: 0.3460  decode.d6.loss_cls: 0.5664  decode.d6.loss_mask: 0.2583  decode.d6.loss_dice: 0.3228  decode.d7.loss_cls: 0.5853  decode.d7.loss_mask: 0.2557  decode.d7.loss_dice: 0.3182  decode.d8.loss_cls: 0.5574  decode.d8.loss_mask: 0.2593  decode.d8.loss_dice: 0.3172
07/30 00:18:20 - mmengine - INFO - Iter(train) [ 9150/80000]  base_lr: 8.9646e-05 lr: 8.9646e-06  eta: 10:27:09  time: 0.5298  data_time: 0.0131  memory: 5973  grad_norm: 245.5775  loss: 9.2423  decode.loss_cls: 0.2308  decode.loss_mask: 0.2504  decode.loss_dice: 0.2785  decode.d0.loss_cls: 1.2413  decode.d0.loss_mask: 0.2858  decode.d0.loss_dice: 0.3431  decode.d1.loss_cls: 0.4107  decode.d1.loss_mask: 0.2506  decode.d1.loss_dice: 0.2911  decode.d2.loss_cls: 0.3426  decode.d2.loss_mask: 0.2539  decode.d2.loss_dice: 0.2776  decode.d3.loss_cls: 0.3765  decode.d3.loss_mask: 0.2544  decode.d3.loss_dice: 0.2730  decode.d4.loss_cls: 0.3203  decode.d4.loss_mask: 0.2471  decode.d4.loss_dice: 0.2703  decode.d5.loss_cls: 0.2082  decode.d5.loss_mask: 0.2542  decode.d5.loss_dice: 0.2782  decode.d6.loss_cls: 0.2345  decode.d6.loss_mask: 0.2482  decode.d6.loss_dice: 0.2771  decode.d7.loss_cls: 0.2309  decode.d7.loss_mask: 0.2476  decode.d7.loss_dice: 0.2826  decode.d8.loss_cls: 0.2494  decode.d8.loss_mask: 0.2508  decode.d8.loss_dice: 0.2826
07/30 00:18:47 - mmengine - INFO - Iter(train) [ 9200/80000]  base_lr: 8.9589e-05 lr: 8.9589e-06  eta: 10:26:43  time: 0.5312  data_time: 0.0134  memory: 5896  grad_norm: 184.9891  loss: 8.9622  decode.loss_cls: 0.1385  decode.loss_mask: 0.2903  decode.loss_dice: 0.2787  decode.d0.loss_cls: 1.3677  decode.d0.loss_mask: 0.2812  decode.d0.loss_dice: 0.3119  decode.d1.loss_cls: 0.3169  decode.d1.loss_mask: 0.3013  decode.d1.loss_dice: 0.2926  decode.d2.loss_cls: 0.2033  decode.d2.loss_mask: 0.3120  decode.d2.loss_dice: 0.3131  decode.d3.loss_cls: 0.2290  decode.d3.loss_mask: 0.3151  decode.d3.loss_dice: 0.2947  decode.d4.loss_cls: 0.1461  decode.d4.loss_mask: 0.3077  decode.d4.loss_dice: 0.2829  decode.d5.loss_cls: 0.1446  decode.d5.loss_mask: 0.3037  decode.d5.loss_dice: 0.2811  decode.d6.loss_cls: 0.1377  decode.d6.loss_mask: 0.3140  decode.d6.loss_dice: 0.2907  decode.d7.loss_cls: 0.1974  decode.d7.loss_mask: 0.3054  decode.d7.loss_dice: 0.2816  decode.d8.loss_cls: 0.1350  decode.d8.loss_mask: 0.3016  decode.d8.loss_dice: 0.2863
07/30 00:19:13 - mmengine - INFO - Iter(train) [ 9250/80000]  base_lr: 8.9532e-05 lr: 8.9532e-06  eta: 10:26:15  time: 0.5319  data_time: 0.0135  memory: 5918  grad_norm: 230.7617  loss: 11.0484  decode.loss_cls: 0.3374  decode.loss_mask: 0.3086  decode.loss_dice: 0.3269  decode.d0.loss_cls: 1.3125  decode.d0.loss_mask: 0.3456  decode.d0.loss_dice: 0.3765  decode.d1.loss_cls: 0.4919  decode.d1.loss_mask: 0.2955  decode.d1.loss_dice: 0.3124  decode.d2.loss_cls: 0.4642  decode.d2.loss_mask: 0.2916  decode.d2.loss_dice: 0.3214  decode.d3.loss_cls: 0.3610  decode.d3.loss_mask: 0.2936  decode.d3.loss_dice: 0.3256  decode.d4.loss_cls: 0.3519  decode.d4.loss_mask: 0.2924  decode.d4.loss_dice: 0.3137  decode.d5.loss_cls: 0.3839  decode.d5.loss_mask: 0.2973  decode.d5.loss_dice: 0.3105  decode.d6.loss_cls: 0.3493  decode.d6.loss_mask: 0.2986  decode.d6.loss_dice: 0.3108  decode.d7.loss_cls: 0.3535  decode.d7.loss_mask: 0.2966  decode.d7.loss_dice: 0.3168  decode.d8.loss_cls: 0.3909  decode.d8.loss_mask: 0.2989  decode.d8.loss_dice: 0.3186
07/30 00:19:40 - mmengine - INFO - Iter(train) [ 9300/80000]  base_lr: 8.9475e-05 lr: 8.9475e-06  eta: 10:25:52  time: 0.5323  data_time: 0.0135  memory: 5934  grad_norm: 171.2413  loss: 9.5365  decode.loss_cls: 0.2001  decode.loss_mask: 0.2795  decode.loss_dice: 0.3403  decode.d0.loss_cls: 1.1144  decode.d0.loss_mask: 0.2755  decode.d0.loss_dice: 0.3459  decode.d1.loss_cls: 0.3038  decode.d1.loss_mask: 0.2956  decode.d1.loss_dice: 0.3732  decode.d2.loss_cls: 0.2288  decode.d2.loss_mask: 0.2864  decode.d2.loss_dice: 0.3502  decode.d3.loss_cls: 0.2432  decode.d3.loss_mask: 0.2747  decode.d3.loss_dice: 0.3298  decode.d4.loss_cls: 0.2378  decode.d4.loss_mask: 0.2787  decode.d4.loss_dice: 0.3428  decode.d5.loss_cls: 0.2181  decode.d5.loss_mask: 0.2743  decode.d5.loss_dice: 0.3453  decode.d6.loss_cls: 0.2227  decode.d6.loss_mask: 0.2806  decode.d6.loss_dice: 0.3432  decode.d7.loss_cls: 0.2237  decode.d7.loss_mask: 0.2850  decode.d7.loss_dice: 0.3653  decode.d8.loss_cls: 0.2515  decode.d8.loss_mask: 0.2812  decode.d8.loss_dice: 0.3451
07/30 00:20:07 - mmengine - INFO - Iter(train) [ 9350/80000]  base_lr: 8.9418e-05 lr: 8.9418e-06  eta: 10:25:26  time: 0.5366  data_time: 0.0135  memory: 5988  grad_norm: 86.6324  loss: 9.1550  decode.loss_cls: 0.2781  decode.loss_mask: 0.2976  decode.loss_dice: 0.2851  decode.d0.loss_cls: 0.9824  decode.d0.loss_mask: 0.3189  decode.d0.loss_dice: 0.2909  decode.d1.loss_cls: 0.2999  decode.d1.loss_mask: 0.3219  decode.d1.loss_dice: 0.2901  decode.d2.loss_cls: 0.2052  decode.d2.loss_mask: 0.3106  decode.d2.loss_dice: 0.2840  decode.d3.loss_cls: 0.2513  decode.d3.loss_mask: 0.3074  decode.d3.loss_dice: 0.2798  decode.d4.loss_cls: 0.2280  decode.d4.loss_mask: 0.3079  decode.d4.loss_dice: 0.2871  decode.d5.loss_cls: 0.2330  decode.d5.loss_mask: 0.3120  decode.d5.loss_dice: 0.2851  decode.d6.loss_cls: 0.2136  decode.d6.loss_mask: 0.3189  decode.d6.loss_dice: 0.2859  decode.d7.loss_cls: 0.2550  decode.d7.loss_mask: 0.3130  decode.d7.loss_dice: 0.2967  decode.d8.loss_cls: 0.2267  decode.d8.loss_mask: 0.3016  decode.d8.loss_dice: 0.2875
07/30 00:20:34 - mmengine - INFO - Iter(train) [ 9400/80000]  base_lr: 8.9361e-05 lr: 8.9361e-06  eta: 10:25:00  time: 0.5344  data_time: 0.0141  memory: 5918  grad_norm: 156.2681  loss: 12.0676  decode.loss_cls: 0.4114  decode.loss_mask: 0.3272  decode.loss_dice: 0.4002  decode.d0.loss_cls: 1.0172  decode.d0.loss_mask: 0.3430  decode.d0.loss_dice: 0.4466  decode.d1.loss_cls: 0.4696  decode.d1.loss_mask: 0.3354  decode.d1.loss_dice: 0.4262  decode.d2.loss_cls: 0.4297  decode.d2.loss_mask: 0.3279  decode.d2.loss_dice: 0.3842  decode.d3.loss_cls: 0.3691  decode.d3.loss_mask: 0.3225  decode.d3.loss_dice: 0.3970  decode.d4.loss_cls: 0.4381  decode.d4.loss_mask: 0.3277  decode.d4.loss_dice: 0.3808  decode.d5.loss_cls: 0.4245  decode.d5.loss_mask: 0.3337  decode.d5.loss_dice: 0.3849  decode.d6.loss_cls: 0.4229  decode.d6.loss_mask: 0.3248  decode.d6.loss_dice: 0.3655  decode.d7.loss_cls: 0.3957  decode.d7.loss_mask: 0.3243  decode.d7.loss_dice: 0.3939  decode.d8.loss_cls: 0.4296  decode.d8.loss_mask: 0.3204  decode.d8.loss_dice: 0.3937
07/30 00:21:00 - mmengine - INFO - Iter(train) [ 9450/80000]  base_lr: 8.9304e-05 lr: 8.9304e-06  eta: 10:24:34  time: 0.5357  data_time: 0.0145  memory: 5974  grad_norm: 135.8002  loss: 9.2896  decode.loss_cls: 0.2963  decode.loss_mask: 0.2253  decode.loss_dice: 0.2733  decode.d0.loss_cls: 1.3224  decode.d0.loss_mask: 0.2524  decode.d0.loss_dice: 0.3426  decode.d1.loss_cls: 0.3713  decode.d1.loss_mask: 0.2383  decode.d1.loss_dice: 0.3160  decode.d2.loss_cls: 0.4205  decode.d2.loss_mask: 0.2229  decode.d2.loss_dice: 0.2775  decode.d3.loss_cls: 0.3620  decode.d3.loss_mask: 0.2207  decode.d3.loss_dice: 0.2679  decode.d4.loss_cls: 0.2969  decode.d4.loss_mask: 0.2248  decode.d4.loss_dice: 0.2791  decode.d5.loss_cls: 0.2390  decode.d5.loss_mask: 0.2245  decode.d5.loss_dice: 0.2818  decode.d6.loss_cls: 0.2658  decode.d6.loss_mask: 0.2227  decode.d6.loss_dice: 0.2740  decode.d7.loss_cls: 0.2955  decode.d7.loss_mask: 0.2283  decode.d7.loss_dice: 0.2905  decode.d8.loss_cls: 0.2488  decode.d8.loss_mask: 0.2273  decode.d8.loss_dice: 0.2814
07/30 00:21:27 - mmengine - INFO - Iter(train) [ 9500/80000]  base_lr: 8.9247e-05 lr: 8.9247e-06  eta: 10:24:07  time: 0.5296  data_time: 0.0136  memory: 5916  grad_norm: 128.8245  loss: 8.0966  decode.loss_cls: 0.1638  decode.loss_mask: 0.2691  decode.loss_dice: 0.2442  decode.d0.loss_cls: 1.0475  decode.d0.loss_mask: 0.2725  decode.d0.loss_dice: 0.2684  decode.d1.loss_cls: 0.2326  decode.d1.loss_mask: 0.2686  decode.d1.loss_dice: 0.2573  decode.d2.loss_cls: 0.3784  decode.d2.loss_mask: 0.2699  decode.d2.loss_dice: 0.2484  decode.d3.loss_cls: 0.2271  decode.d3.loss_mask: 0.2717  decode.d3.loss_dice: 0.2426  decode.d4.loss_cls: 0.1892  decode.d4.loss_mask: 0.2695  decode.d4.loss_dice: 0.2386  decode.d5.loss_cls: 0.1842  decode.d5.loss_mask: 0.2722  decode.d5.loss_dice: 0.2523  decode.d6.loss_cls: 0.1570  decode.d6.loss_mask: 0.2683  decode.d6.loss_dice: 0.2419  decode.d7.loss_cls: 0.1659  decode.d7.loss_mask: 0.2771  decode.d7.loss_dice: 0.2492  decode.d8.loss_cls: 0.1583  decode.d8.loss_mask: 0.2705  decode.d8.loss_dice: 0.2403
07/30 00:21:53 - mmengine - INFO - Iter(train) [ 9550/80000]  base_lr: 8.9190e-05 lr: 8.9190e-06  eta: 10:23:41  time: 0.5332  data_time: 0.0135  memory: 5918  grad_norm: 187.4850  loss: 12.7790  decode.loss_cls: 0.2925  decode.loss_mask: 0.4157  decode.loss_dice: 0.4358  decode.d0.loss_cls: 1.2179  decode.d0.loss_mask: 0.3956  decode.d0.loss_dice: 0.4558  decode.d1.loss_cls: 0.4547  decode.d1.loss_mask: 0.4194  decode.d1.loss_dice: 0.4451  decode.d2.loss_cls: 0.4078  decode.d2.loss_mask: 0.4069  decode.d2.loss_dice: 0.4456  decode.d3.loss_cls: 0.3158  decode.d3.loss_mask: 0.4066  decode.d3.loss_dice: 0.4363  decode.d4.loss_cls: 0.3011  decode.d4.loss_mask: 0.4089  decode.d4.loss_dice: 0.4730  decode.d5.loss_cls: 0.3276  decode.d5.loss_mask: 0.4067  decode.d5.loss_dice: 0.4380  decode.d6.loss_cls: 0.3042  decode.d6.loss_mask: 0.4074  decode.d6.loss_dice: 0.4575  decode.d7.loss_cls: 0.3204  decode.d7.loss_mask: 0.4058  decode.d7.loss_dice: 0.4217  decode.d8.loss_cls: 0.2686  decode.d8.loss_mask: 0.4152  decode.d8.loss_dice: 0.4716
07/30 00:22:20 - mmengine - INFO - Iter(train) [ 9600/80000]  base_lr: 8.9133e-05 lr: 8.9133e-06  eta: 10:23:16  time: 0.5328  data_time: 0.0134  memory: 5916  grad_norm: 162.3382  loss: 11.0241  decode.loss_cls: 0.3861  decode.loss_mask: 0.2355  decode.loss_dice: 0.3185  decode.d0.loss_cls: 1.3283  decode.d0.loss_mask: 0.2500  decode.d0.loss_dice: 0.4096  decode.d1.loss_cls: 0.5975  decode.d1.loss_mask: 0.2471  decode.d1.loss_dice: 0.3785  decode.d2.loss_cls: 0.4593  decode.d2.loss_mask: 0.2428  decode.d2.loss_dice: 0.3517  decode.d3.loss_cls: 0.4329  decode.d3.loss_mask: 0.2408  decode.d3.loss_dice: 0.3462  decode.d4.loss_cls: 0.4007  decode.d4.loss_mask: 0.2411  decode.d4.loss_dice: 0.3676  decode.d5.loss_cls: 0.3946  decode.d5.loss_mask: 0.2440  decode.d5.loss_dice: 0.3502  decode.d6.loss_cls: 0.3995  decode.d6.loss_mask: 0.2407  decode.d6.loss_dice: 0.3348  decode.d7.loss_cls: 0.3324  decode.d7.loss_mask: 0.2402  decode.d7.loss_dice: 0.3433  decode.d8.loss_cls: 0.3460  decode.d8.loss_mask: 0.2377  decode.d8.loss_dice: 0.3265
07/30 00:22:47 - mmengine - INFO - Iter(train) [ 9650/80000]  base_lr: 8.9076e-05 lr: 8.9076e-06  eta: 10:22:49  time: 0.5322  data_time: 0.0137  memory: 5918  grad_norm: 128.0620  loss: 9.9461  decode.loss_cls: 0.2339  decode.loss_mask: 0.2480  decode.loss_dice: 0.3476  decode.d0.loss_cls: 1.1358  decode.d0.loss_mask: 0.2686  decode.d0.loss_dice: 0.3826  decode.d1.loss_cls: 0.4375  decode.d1.loss_mask: 0.2535  decode.d1.loss_dice: 0.3248  decode.d2.loss_cls: 0.2985  decode.d2.loss_mask: 0.2546  decode.d2.loss_dice: 0.3698  decode.d3.loss_cls: 0.3057  decode.d3.loss_mask: 0.2572  decode.d3.loss_dice: 0.3578  decode.d4.loss_cls: 0.3144  decode.d4.loss_mask: 0.2626  decode.d4.loss_dice: 0.3596  decode.d5.loss_cls: 0.2783  decode.d5.loss_mask: 0.2673  decode.d5.loss_dice: 0.3884  decode.d6.loss_cls: 0.2949  decode.d6.loss_mask: 0.2488  decode.d6.loss_dice: 0.3466  decode.d7.loss_cls: 0.2436  decode.d7.loss_mask: 0.2534  decode.d7.loss_dice: 0.3503  decode.d8.loss_cls: 0.2645  decode.d8.loss_mask: 0.2526  decode.d8.loss_dice: 0.3449
07/30 00:23:13 - mmengine - INFO - Iter(train) [ 9700/80000]  base_lr: 8.9019e-05 lr: 8.9019e-06  eta: 10:22:21  time: 0.5295  data_time: 0.0132  memory: 5916  grad_norm: 229.5618  loss: 10.9828  decode.loss_cls: 0.2983  decode.loss_mask: 0.3216  decode.loss_dice: 0.3789  decode.d0.loss_cls: 1.1401  decode.d0.loss_mask: 0.3502  decode.d0.loss_dice: 0.4282  decode.d1.loss_cls: 0.3592  decode.d1.loss_mask: 0.3267  decode.d1.loss_dice: 0.3902  decode.d2.loss_cls: 0.2745  decode.d2.loss_mask: 0.3154  decode.d2.loss_dice: 0.3741  decode.d3.loss_cls: 0.2761  decode.d3.loss_mask: 0.3251  decode.d3.loss_dice: 0.3629  decode.d4.loss_cls: 0.2378  decode.d4.loss_mask: 0.3172  decode.d4.loss_dice: 0.3634  decode.d5.loss_cls: 0.3436  decode.d5.loss_mask: 0.3213  decode.d5.loss_dice: 0.3825  decode.d6.loss_cls: 0.3027  decode.d6.loss_mask: 0.3360  decode.d6.loss_dice: 0.3936  decode.d7.loss_cls: 0.2814  decode.d7.loss_mask: 0.3330  decode.d7.loss_dice: 0.4103  decode.d8.loss_cls: 0.3081  decode.d8.loss_mask: 0.3308  decode.d8.loss_dice: 0.3995
07/30 00:23:39 - mmengine - INFO - Iter(train) [ 9750/80000]  base_lr: 8.8962e-05 lr: 8.8962e-06  eta: 10:21:54  time: 0.5299  data_time: 0.0135  memory: 5920  grad_norm: 114.6712  loss: 9.4528  decode.loss_cls: 0.1547  decode.loss_mask: 0.3181  decode.loss_dice: 0.3301  decode.d0.loss_cls: 1.1216  decode.d0.loss_mask: 0.3725  decode.d0.loss_dice: 0.4029  decode.d1.loss_cls: 0.2791  decode.d1.loss_mask: 0.3239  decode.d1.loss_dice: 0.3335  decode.d2.loss_cls: 0.2270  decode.d2.loss_mask: 0.3171  decode.d2.loss_dice: 0.3090  decode.d3.loss_cls: 0.1678  decode.d3.loss_mask: 0.3219  decode.d3.loss_dice: 0.3247  decode.d4.loss_cls: 0.1796  decode.d4.loss_mask: 0.3185  decode.d4.loss_dice: 0.3243  decode.d5.loss_cls: 0.1897  decode.d5.loss_mask: 0.3260  decode.d5.loss_dice: 0.3379  decode.d6.loss_cls: 0.1891  decode.d6.loss_mask: 0.3173  decode.d6.loss_dice: 0.3178  decode.d7.loss_cls: 0.1961  decode.d7.loss_mask: 0.3171  decode.d7.loss_dice: 0.3382  decode.d8.loss_cls: 0.1414  decode.d8.loss_mask: 0.3185  decode.d8.loss_dice: 0.3371
07/30 00:24:06 - mmengine - INFO - Iter(train) [ 9800/80000]  base_lr: 8.8905e-05 lr: 8.8905e-06  eta: 10:21:29  time: 0.5343  data_time: 0.0133  memory: 5937  grad_norm: 126.9131  loss: 8.5299  decode.loss_cls: 0.2482  decode.loss_mask: 0.2439  decode.loss_dice: 0.2632  decode.d0.loss_cls: 1.1434  decode.d0.loss_mask: 0.2534  decode.d0.loss_dice: 0.3006  decode.d1.loss_cls: 0.3251  decode.d1.loss_mask: 0.2500  decode.d1.loss_dice: 0.3051  decode.d2.loss_cls: 0.2778  decode.d2.loss_mask: 0.2477  decode.d2.loss_dice: 0.2806  decode.d3.loss_cls: 0.2279  decode.d3.loss_mask: 0.2454  decode.d3.loss_dice: 0.2878  decode.d4.loss_cls: 0.2400  decode.d4.loss_mask: 0.2397  decode.d4.loss_dice: 0.2695  decode.d5.loss_cls: 0.2199  decode.d5.loss_mask: 0.2417  decode.d5.loss_dice: 0.2740  decode.d6.loss_cls: 0.2166  decode.d6.loss_mask: 0.2440  decode.d6.loss_dice: 0.2647  decode.d7.loss_cls: 0.1989  decode.d7.loss_mask: 0.2454  decode.d7.loss_dice: 0.2704  decode.d8.loss_cls: 0.1948  decode.d8.loss_mask: 0.2450  decode.d8.loss_dice: 0.2651
07/30 00:24:33 - mmengine - INFO - Iter(train) [ 9850/80000]  base_lr: 8.8848e-05 lr: 8.8848e-06  eta: 10:21:04  time: 0.5366  data_time: 0.0136  memory: 5916  grad_norm: 97.8269  loss: 10.3091  decode.loss_cls: 0.2650  decode.loss_mask: 0.2692  decode.loss_dice: 0.3858  decode.d0.loss_cls: 1.2101  decode.d0.loss_mask: 0.2724  decode.d0.loss_dice: 0.3461  decode.d1.loss_cls: 0.3627  decode.d1.loss_mask: 0.2698  decode.d1.loss_dice: 0.3495  decode.d2.loss_cls: 0.3316  decode.d2.loss_mask: 0.2689  decode.d2.loss_dice: 0.3884  decode.d3.loss_cls: 0.3158  decode.d3.loss_mask: 0.2663  decode.d3.loss_dice: 0.3738  decode.d4.loss_cls: 0.2455  decode.d4.loss_mask: 0.2689  decode.d4.loss_dice: 0.3622  decode.d5.loss_cls: 0.3011  decode.d5.loss_mask: 0.2673  decode.d5.loss_dice: 0.3715  decode.d6.loss_cls: 0.2903  decode.d6.loss_mask: 0.2711  decode.d6.loss_dice: 0.3767  decode.d7.loss_cls: 0.2919  decode.d7.loss_mask: 0.2718  decode.d7.loss_dice: 0.3657  decode.d8.loss_cls: 0.2815  decode.d8.loss_mask: 0.2754  decode.d8.loss_dice: 0.3929
07/30 00:25:00 - mmengine - INFO - Iter(train) [ 9900/80000]  base_lr: 8.8791e-05 lr: 8.8791e-06  eta: 10:20:39  time: 0.5314  data_time: 0.0136  memory: 5916  grad_norm: 162.7447  loss: 12.3361  decode.loss_cls: 0.2935  decode.loss_mask: 0.3861  decode.loss_dice: 0.4021  decode.d0.loss_cls: 1.1037  decode.d0.loss_mask: 0.3798  decode.d0.loss_dice: 0.4510  decode.d1.loss_cls: 0.4838  decode.d1.loss_mask: 0.4134  decode.d1.loss_dice: 0.4626  decode.d2.loss_cls: 0.3076  decode.d2.loss_mask: 0.3892  decode.d2.loss_dice: 0.4454  decode.d3.loss_cls: 0.3108  decode.d3.loss_mask: 0.3958  decode.d3.loss_dice: 0.4438  decode.d4.loss_cls: 0.2990  decode.d4.loss_mask: 0.3866  decode.d4.loss_dice: 0.4338  decode.d5.loss_cls: 0.3561  decode.d5.loss_mask: 0.3883  decode.d5.loss_dice: 0.4294  decode.d6.loss_cls: 0.2604  decode.d6.loss_mask: 0.3875  decode.d6.loss_dice: 0.4194  decode.d7.loss_cls: 0.3593  decode.d7.loss_mask: 0.3952  decode.d7.loss_dice: 0.4232  decode.d8.loss_cls: 0.3187  decode.d8.loss_mask: 0.3881  decode.d8.loss_dice: 0.4226
07/30 00:25:27 - mmengine - INFO - Iter(train) [ 9950/80000]  base_lr: 8.8734e-05 lr: 8.8734e-06  eta: 10:20:13  time: 0.5364  data_time: 0.0139  memory: 5918  grad_norm: 171.3838  loss: 11.9536  decode.loss_cls: 0.3928  decode.loss_mask: 0.3718  decode.loss_dice: 0.3320  decode.d0.loss_cls: 1.2523  decode.d0.loss_mask: 0.3834  decode.d0.loss_dice: 0.3320  decode.d1.loss_cls: 0.3914  decode.d1.loss_mask: 0.3848  decode.d1.loss_dice: 0.3293  decode.d2.loss_cls: 0.4118  decode.d2.loss_mask: 0.3537  decode.d2.loss_dice: 0.3141  decode.d3.loss_cls: 0.4086  decode.d3.loss_mask: 0.3659  decode.d3.loss_dice: 0.3123  decode.d4.loss_cls: 0.4000  decode.d4.loss_mask: 0.3437  decode.d4.loss_dice: 0.3142  decode.d5.loss_cls: 0.4200  decode.d5.loss_mask: 0.3390  decode.d5.loss_dice: 0.3112  decode.d6.loss_cls: 0.4418  decode.d6.loss_mask: 0.3749  decode.d6.loss_dice: 0.3305  decode.d7.loss_cls: 0.4097  decode.d7.loss_mask: 0.4009  decode.d7.loss_dice: 0.3387  decode.d8.loss_cls: 0.4462  decode.d8.loss_mask: 0.4052  decode.d8.loss_dice: 0.3414
07/30 00:25:53 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/30 00:25:53 - mmengine - INFO - Iter(train) [10000/80000]  base_lr: 8.8677e-05 lr: 8.8677e-06  eta: 10:19:48  time: 0.5350  data_time: 0.0139  memory: 5882  grad_norm: 167.9411  loss: 10.8964  decode.loss_cls: 0.2976  decode.loss_mask: 0.2620  decode.loss_dice: 0.3967  decode.d0.loss_cls: 1.1274  decode.d0.loss_mask: 0.2868  decode.d0.loss_dice: 0.4080  decode.d1.loss_cls: 0.5140  decode.d1.loss_mask: 0.2899  decode.d1.loss_dice: 0.4018  decode.d2.loss_cls: 0.3913  decode.d2.loss_mask: 0.2735  decode.d2.loss_dice: 0.4103  decode.d3.loss_cls: 0.4218  decode.d3.loss_mask: 0.2562  decode.d3.loss_dice: 0.3939  decode.d4.loss_cls: 0.3382  decode.d4.loss_mask: 0.2631  decode.d4.loss_dice: 0.3838  decode.d5.loss_cls: 0.3134  decode.d5.loss_mask: 0.2576  decode.d5.loss_dice: 0.3889  decode.d6.loss_cls: 0.3142  decode.d6.loss_mask: 0.2529  decode.d6.loss_dice: 0.3778  decode.d7.loss_cls: 0.3268  decode.d7.loss_mask: 0.2573  decode.d7.loss_dice: 0.3757  decode.d8.loss_cls: 0.2855  decode.d8.loss_mask: 0.2604  decode.d8.loss_dice: 0.3695
07/30 00:25:53 - mmengine - INFO - Saving checkpoint at 10000 iterations
07/30 00:26:23 - mmengine - INFO - Iter(train) [10050/80000]  base_lr: 8.8620e-05 lr: 8.8620e-06  eta: 10:19:43  time: 0.5362  data_time: 0.0144  memory: 5918  grad_norm: 116.3102  loss: 9.8408  decode.loss_cls: 0.3011  decode.loss_mask: 0.2972  decode.loss_dice: 0.3405  decode.d0.loss_cls: 0.9987  decode.d0.loss_mask: 0.3107  decode.d0.loss_dice: 0.3558  decode.d1.loss_cls: 0.3393  decode.d1.loss_mask: 0.2946  decode.d1.loss_dice: 0.3467  decode.d2.loss_cls: 0.2748  decode.d2.loss_mask: 0.3009  decode.d2.loss_dice: 0.3524  decode.d3.loss_cls: 0.2444  decode.d3.loss_mask: 0.2973  decode.d3.loss_dice: 0.3365  decode.d4.loss_cls: 0.2648  decode.d4.loss_mask: 0.3016  decode.d4.loss_dice: 0.3478  decode.d5.loss_cls: 0.2470  decode.d5.loss_mask: 0.2986  decode.d5.loss_dice: 0.3322  decode.d6.loss_cls: 0.2583  decode.d6.loss_mask: 0.2922  decode.d6.loss_dice: 0.3373  decode.d7.loss_cls: 0.2474  decode.d7.loss_mask: 0.2924  decode.d7.loss_dice: 0.3284  decode.d8.loss_cls: 0.2693  decode.d8.loss_mask: 0.2955  decode.d8.loss_dice: 0.3371
07/30 00:26:50 - mmengine - INFO - Iter(train) [10100/80000]  base_lr: 8.8563e-05 lr: 8.8563e-06  eta: 10:19:16  time: 0.5267  data_time: 0.0128  memory: 5936  grad_norm: 89.7920  loss: 7.6638  decode.loss_cls: 0.0663  decode.loss_mask: 0.2887  decode.loss_dice: 0.2997  decode.d0.loss_cls: 1.1129  decode.d0.loss_mask: 0.3094  decode.d0.loss_dice: 0.3179  decode.d1.loss_cls: 0.0907  decode.d1.loss_mask: 0.2998  decode.d1.loss_dice: 0.3269  decode.d2.loss_cls: 0.0751  decode.d2.loss_mask: 0.2926  decode.d2.loss_dice: 0.3189  decode.d3.loss_cls: 0.0598  decode.d3.loss_mask: 0.2874  decode.d3.loss_dice: 0.3037  decode.d4.loss_cls: 0.0344  decode.d4.loss_mask: 0.2878  decode.d4.loss_dice: 0.3048  decode.d5.loss_cls: 0.0359  decode.d5.loss_mask: 0.2963  decode.d5.loss_dice: 0.3096  decode.d6.loss_cls: 0.0310  decode.d6.loss_mask: 0.2893  decode.d6.loss_dice: 0.3163  decode.d7.loss_cls: 0.0348  decode.d7.loss_mask: 0.2991  decode.d7.loss_dice: 0.3082  decode.d8.loss_cls: 0.0674  decode.d8.loss_mask: 0.2919  decode.d8.loss_dice: 0.3072
07/30 00:27:16 - mmengine - INFO - Iter(train) [10150/80000]  base_lr: 8.8506e-05 lr: 8.8506e-06  eta: 10:18:50  time: 0.5320  data_time: 0.0140  memory: 5973  grad_norm: 240.6450  loss: 9.9165  decode.loss_cls: 0.2259  decode.loss_mask: 0.3098  decode.loss_dice: 0.3500  decode.d0.loss_cls: 1.1503  decode.d0.loss_mask: 0.2932  decode.d0.loss_dice: 0.3875  decode.d1.loss_cls: 0.3425  decode.d1.loss_mask: 0.3103  decode.d1.loss_dice: 0.3835  decode.d2.loss_cls: 0.2605  decode.d2.loss_mask: 0.3005  decode.d2.loss_dice: 0.3157  decode.d3.loss_cls: 0.2196  decode.d3.loss_mask: 0.3088  decode.d3.loss_dice: 0.3689  decode.d4.loss_cls: 0.2507  decode.d4.loss_mask: 0.3103  decode.d4.loss_dice: 0.3537  decode.d5.loss_cls: 0.2345  decode.d5.loss_mask: 0.3117  decode.d5.loss_dice: 0.3575  decode.d6.loss_cls: 0.1883  decode.d6.loss_mask: 0.3104  decode.d6.loss_dice: 0.3362  decode.d7.loss_cls: 0.2174  decode.d7.loss_mask: 0.3032  decode.d7.loss_dice: 0.3545  decode.d8.loss_cls: 0.1965  decode.d8.loss_mask: 0.2993  decode.d8.loss_dice: 0.3655
07/30 00:27:43 - mmengine - INFO - Iter(train) [10200/80000]  base_lr: 8.8449e-05 lr: 8.8449e-06  eta: 10:18:23  time: 0.5301  data_time: 0.0135  memory: 5881  grad_norm: 169.9603  loss: 11.0659  decode.loss_cls: 0.3000  decode.loss_mask: 0.3012  decode.loss_dice: 0.3471  decode.d0.loss_cls: 1.1581  decode.d0.loss_mask: 0.3160  decode.d0.loss_dice: 0.3680  decode.d1.loss_cls: 0.5360  decode.d1.loss_mask: 0.3125  decode.d1.loss_dice: 0.3646  decode.d2.loss_cls: 0.4739  decode.d2.loss_mask: 0.3076  decode.d2.loss_dice: 0.3653  decode.d3.loss_cls: 0.3549  decode.d3.loss_mask: 0.3010  decode.d3.loss_dice: 0.3477  decode.d4.loss_cls: 0.3725  decode.d4.loss_mask: 0.3065  decode.d4.loss_dice: 0.3438  decode.d5.loss_cls: 0.2899  decode.d5.loss_mask: 0.3068  decode.d5.loss_dice: 0.3508  decode.d6.loss_cls: 0.3379  decode.d6.loss_mask: 0.3080  decode.d6.loss_dice: 0.3683  decode.d7.loss_cls: 0.3447  decode.d7.loss_mask: 0.3001  decode.d7.loss_dice: 0.3497  decode.d8.loss_cls: 0.2993  decode.d8.loss_mask: 0.2981  decode.d8.loss_dice: 0.3358
07/30 00:28:09 - mmengine - INFO - Iter(train) [10250/80000]  base_lr: 8.8392e-05 lr: 8.8392e-06  eta: 10:17:57  time: 0.5338  data_time: 0.0137  memory: 5919  grad_norm: 107.4174  loss: 8.8169  decode.loss_cls: 0.2466  decode.loss_mask: 0.2756  decode.loss_dice: 0.3157  decode.d0.loss_cls: 0.9180  decode.d0.loss_mask: 0.2931  decode.d0.loss_dice: 0.3358  decode.d1.loss_cls: 0.2788  decode.d1.loss_mask: 0.2869  decode.d1.loss_dice: 0.3155  decode.d2.loss_cls: 0.2205  decode.d2.loss_mask: 0.2822  decode.d2.loss_dice: 0.3081  decode.d3.loss_cls: 0.2242  decode.d3.loss_mask: 0.2843  decode.d3.loss_dice: 0.3152  decode.d4.loss_cls: 0.1858  decode.d4.loss_mask: 0.2835  decode.d4.loss_dice: 0.3199  decode.d5.loss_cls: 0.1610  decode.d5.loss_mask: 0.2819  decode.d5.loss_dice: 0.3161  decode.d6.loss_cls: 0.1223  decode.d6.loss_mask: 0.2828  decode.d6.loss_dice: 0.3040  decode.d7.loss_cls: 0.2458  decode.d7.loss_mask: 0.2788  decode.d7.loss_dice: 0.3210  decode.d8.loss_cls: 0.2354  decode.d8.loss_mask: 0.2705  decode.d8.loss_dice: 0.3075
07/30 00:28:36 - mmengine - INFO - Iter(train) [10300/80000]  base_lr: 8.8335e-05 lr: 8.8335e-06  eta: 10:17:32  time: 0.5347  data_time: 0.0137  memory: 5896  grad_norm: 97.8847  loss: 11.2627  decode.loss_cls: 0.3403  decode.loss_mask: 0.2471  decode.loss_dice: 0.3848  decode.d0.loss_cls: 1.2403  decode.d0.loss_mask: 0.2517  decode.d0.loss_dice: 0.3842  decode.d1.loss_cls: 0.5498  decode.d1.loss_mask: 0.2535  decode.d1.loss_dice: 0.3857  decode.d2.loss_cls: 0.3881  decode.d2.loss_mask: 0.2527  decode.d2.loss_dice: 0.4064  decode.d3.loss_cls: 0.3084  decode.d3.loss_mask: 0.2526  decode.d3.loss_dice: 0.3880  decode.d4.loss_cls: 0.4356  decode.d4.loss_mask: 0.2506  decode.d4.loss_dice: 0.3727  decode.d5.loss_cls: 0.4010  decode.d5.loss_mask: 0.2490  decode.d5.loss_dice: 0.4056  decode.d6.loss_cls: 0.4326  decode.d6.loss_mask: 0.2512  decode.d6.loss_dice: 0.3795  decode.d7.loss_cls: 0.4065  decode.d7.loss_mask: 0.2522  decode.d7.loss_dice: 0.3877  decode.d8.loss_cls: 0.3250  decode.d8.loss_mask: 0.2940  decode.d8.loss_dice: 0.3857
07/30 00:29:03 - mmengine - INFO - Iter(train) [10350/80000]  base_lr: 8.8278e-05 lr: 8.8278e-06  eta: 10:17:06  time: 0.5276  data_time: 0.0127  memory: 5916  grad_norm: 196.3854  loss: 8.7322  decode.loss_cls: 0.1724  decode.loss_mask: 0.2837  decode.loss_dice: 0.3025  decode.d0.loss_cls: 1.1384  decode.d0.loss_mask: 0.2743  decode.d0.loss_dice: 0.2992  decode.d1.loss_cls: 0.3112  decode.d1.loss_mask: 0.2802  decode.d1.loss_dice: 0.2730  decode.d2.loss_cls: 0.1895  decode.d2.loss_mask: 0.3030  decode.d2.loss_dice: 0.2972  decode.d3.loss_cls: 0.1490  decode.d3.loss_mask: 0.2992  decode.d3.loss_dice: 0.2934  decode.d4.loss_cls: 0.1610  decode.d4.loss_mask: 0.2950  decode.d4.loss_dice: 0.2951  decode.d5.loss_cls: 0.1700  decode.d5.loss_mask: 0.2922  decode.d5.loss_dice: 0.3065  decode.d6.loss_cls: 0.2274  decode.d6.loss_mask: 0.3025  decode.d6.loss_dice: 0.2874  decode.d7.loss_cls: 0.2097  decode.d7.loss_mask: 0.2954  decode.d7.loss_dice: 0.2931  decode.d8.loss_cls: 0.1564  decode.d8.loss_mask: 0.2891  decode.d8.loss_dice: 0.2851
07/30 00:29:29 - mmengine - INFO - Iter(train) [10400/80000]  base_lr: 8.8221e-05 lr: 8.8221e-06  eta: 10:16:38  time: 0.5308  data_time: 0.0129  memory: 5881  grad_norm: 179.8973  loss: 11.5802  decode.loss_cls: 0.2218  decode.loss_mask: 0.4954  decode.loss_dice: 0.3806  decode.d0.loss_cls: 1.2473  decode.d0.loss_mask: 0.2940  decode.d0.loss_dice: 0.4038  decode.d1.loss_cls: 0.3827  decode.d1.loss_mask: 0.3158  decode.d1.loss_dice: 0.4017  decode.d2.loss_cls: 0.3507  decode.d2.loss_mask: 0.4699  decode.d2.loss_dice: 0.3893  decode.d3.loss_cls: 0.3661  decode.d3.loss_mask: 0.3017  decode.d3.loss_dice: 0.3780  decode.d4.loss_cls: 0.3198  decode.d4.loss_mask: 0.2936  decode.d4.loss_dice: 0.4051  decode.d5.loss_cls: 0.3003  decode.d5.loss_mask: 0.2983  decode.d5.loss_dice: 0.3976  decode.d6.loss_cls: 0.3080  decode.d6.loss_mask: 0.3251  decode.d6.loss_dice: 0.4019  decode.d7.loss_cls: 0.3268  decode.d7.loss_mask: 0.4064  decode.d7.loss_dice: 0.4028  decode.d8.loss_cls: 0.3056  decode.d8.loss_mask: 0.2868  decode.d8.loss_dice: 0.4035
07/30 00:29:56 - mmengine - INFO - Iter(train) [10450/80000]  base_lr: 8.8164e-05 lr: 8.8164e-06  eta: 10:16:11  time: 0.5276  data_time: 0.0131  memory: 5931  grad_norm: 165.0953  loss: 10.2138  decode.loss_cls: 0.2309  decode.loss_mask: 0.2871  decode.loss_dice: 0.3649  decode.d0.loss_cls: 1.0865  decode.d0.loss_mask: 0.3081  decode.d0.loss_dice: 0.4034  decode.d1.loss_cls: 0.3928  decode.d1.loss_mask: 0.2969  decode.d1.loss_dice: 0.3848  decode.d2.loss_cls: 0.3491  decode.d2.loss_mask: 0.3033  decode.d2.loss_dice: 0.3624  decode.d3.loss_cls: 0.2641  decode.d3.loss_mask: 0.2960  decode.d3.loss_dice: 0.3561  decode.d4.loss_cls: 0.2455  decode.d4.loss_mask: 0.3015  decode.d4.loss_dice: 0.3593  decode.d5.loss_cls: 0.2426  decode.d5.loss_mask: 0.2932  decode.d5.loss_dice: 0.3577  decode.d6.loss_cls: 0.2366  decode.d6.loss_mask: 0.2956  decode.d6.loss_dice: 0.3775  decode.d7.loss_cls: 0.2701  decode.d7.loss_mask: 0.3050  decode.d7.loss_dice: 0.3552  decode.d8.loss_cls: 0.2509  decode.d8.loss_mask: 0.2860  decode.d8.loss_dice: 0.3507
07/30 00:30:22 - mmengine - INFO - Iter(train) [10500/80000]  base_lr: 8.8107e-05 lr: 8.8107e-06  eta: 10:15:45  time: 0.5332  data_time: 0.0135  memory: 5897  grad_norm: 120.9343  loss: 9.5764  decode.loss_cls: 0.1445  decode.loss_mask: 0.3522  decode.loss_dice: 0.3488  decode.d0.loss_cls: 1.0751  decode.d0.loss_mask: 0.3471  decode.d0.loss_dice: 0.3499  decode.d1.loss_cls: 0.3117  decode.d1.loss_mask: 0.3325  decode.d1.loss_dice: 0.3532  decode.d2.loss_cls: 0.1664  decode.d2.loss_mask: 0.3231  decode.d2.loss_dice: 0.3514  decode.d3.loss_cls: 0.1578  decode.d3.loss_mask: 0.3257  decode.d3.loss_dice: 0.3446  decode.d4.loss_cls: 0.1918  decode.d4.loss_mask: 0.3203  decode.d4.loss_dice: 0.3394  decode.d5.loss_cls: 0.1906  decode.d5.loss_mask: 0.3194  decode.d5.loss_dice: 0.3409  decode.d6.loss_cls: 0.1869  decode.d6.loss_mask: 0.3202  decode.d6.loss_dice: 0.3372  decode.d7.loss_cls: 0.2086  decode.d7.loss_mask: 0.3235  decode.d7.loss_dice: 0.3424  decode.d8.loss_cls: 0.1520  decode.d8.loss_mask: 0.3604  decode.d8.loss_dice: 0.3586
07/30 00:30:49 - mmengine - INFO - Iter(train) [10550/80000]  base_lr: 8.8050e-05 lr: 8.8050e-06  eta: 10:15:18  time: 0.5297  data_time: 0.0134  memory: 5933  grad_norm: 123.0443  loss: 10.5767  decode.loss_cls: 0.2318  decode.loss_mask: 0.3132  decode.loss_dice: 0.3282  decode.d0.loss_cls: 1.2356  decode.d0.loss_mask: 0.3315  decode.d0.loss_dice: 0.4115  decode.d1.loss_cls: 0.4509  decode.d1.loss_mask: 0.3260  decode.d1.loss_dice: 0.3494  decode.d2.loss_cls: 0.3983  decode.d2.loss_mask: 0.3093  decode.d2.loss_dice: 0.3326  decode.d3.loss_cls: 0.3952  decode.d3.loss_mask: 0.3075  decode.d3.loss_dice: 0.3258  decode.d4.loss_cls: 0.2594  decode.d4.loss_mask: 0.3074  decode.d4.loss_dice: 0.3325  decode.d5.loss_cls: 0.2549  decode.d5.loss_mask: 0.3090  decode.d5.loss_dice: 0.3249  decode.d6.loss_cls: 0.2959  decode.d6.loss_mask: 0.3052  decode.d6.loss_dice: 0.3207  decode.d7.loss_cls: 0.2468  decode.d7.loss_mask: 0.3088  decode.d7.loss_dice: 0.3347  decode.d8.loss_cls: 0.2518  decode.d8.loss_mask: 0.3079  decode.d8.loss_dice: 0.3702
07/30 00:31:15 - mmengine - INFO - Iter(train) [10600/80000]  base_lr: 8.7993e-05 lr: 8.7993e-06  eta: 10:14:51  time: 0.5321  data_time: 0.0133  memory: 5916  grad_norm: 132.9100  loss: 9.8479  decode.loss_cls: 0.2289  decode.loss_mask: 0.2874  decode.loss_dice: 0.3082  decode.d0.loss_cls: 1.1775  decode.d0.loss_mask: 0.3057  decode.d0.loss_dice: 0.3648  decode.d1.loss_cls: 0.4236  decode.d1.loss_mask: 0.3031  decode.d1.loss_dice: 0.3324  decode.d2.loss_cls: 0.2783  decode.d2.loss_mask: 0.2983  decode.d2.loss_dice: 0.3290  decode.d3.loss_cls: 0.2844  decode.d3.loss_mask: 0.2915  decode.d3.loss_dice: 0.3067  decode.d4.loss_cls: 0.2978  decode.d4.loss_mask: 0.2944  decode.d4.loss_dice: 0.3129  decode.d5.loss_cls: 0.2332  decode.d5.loss_mask: 0.2934  decode.d5.loss_dice: 0.3199  decode.d6.loss_cls: 0.2626  decode.d6.loss_mask: 0.2886  decode.d6.loss_dice: 0.3095  decode.d7.loss_cls: 0.2882  decode.d7.loss_mask: 0.2888  decode.d7.loss_dice: 0.3057  decode.d8.loss_cls: 0.2325  decode.d8.loss_mask: 0.2935  decode.d8.loss_dice: 0.3069
07/30 00:31:42 - mmengine - INFO - Iter(train) [10650/80000]  base_lr: 8.7936e-05 lr: 8.7936e-06  eta: 10:14:24  time: 0.5250  data_time: 0.0131  memory: 5931  grad_norm: 113.8970  loss: 9.6170  decode.loss_cls: 0.2026  decode.loss_mask: 0.2804  decode.loss_dice: 0.3575  decode.d0.loss_cls: 1.2524  decode.d0.loss_mask: 0.2243  decode.d0.loss_dice: 0.3605  decode.d1.loss_cls: 0.4157  decode.d1.loss_mask: 0.2272  decode.d1.loss_dice: 0.3657  decode.d2.loss_cls: 0.3078  decode.d2.loss_mask: 0.2316  decode.d2.loss_dice: 0.3473  decode.d3.loss_cls: 0.2454  decode.d3.loss_mask: 0.2362  decode.d3.loss_dice: 0.3606  decode.d4.loss_cls: 0.1744  decode.d4.loss_mask: 0.2523  decode.d4.loss_dice: 0.3759  decode.d5.loss_cls: 0.2446  decode.d5.loss_mask: 0.2380  decode.d5.loss_dice: 0.3861  decode.d6.loss_cls: 0.2553  decode.d6.loss_mask: 0.2333  decode.d6.loss_dice: 0.3565  decode.d7.loss_cls: 0.1867  decode.d7.loss_mask: 0.2719  decode.d7.loss_dice: 0.3527  decode.d8.loss_cls: 0.2240  decode.d8.loss_mask: 0.2920  decode.d8.loss_dice: 0.3583
07/30 00:32:08 - mmengine - INFO - Iter(train) [10700/80000]  base_lr: 8.7879e-05 lr: 8.7879e-06  eta: 10:13:57  time: 0.5298  data_time: 0.0136  memory: 5899  grad_norm: 167.5824  loss: 12.7109  decode.loss_cls: 0.4564  decode.loss_mask: 0.3481  decode.loss_dice: 0.3776  decode.d0.loss_cls: 1.3954  decode.d0.loss_mask: 0.3290  decode.d0.loss_dice: 0.4237  decode.d1.loss_cls: 0.4670  decode.d1.loss_mask: 0.3344  decode.d1.loss_dice: 0.3974  decode.d2.loss_cls: 0.4160  decode.d2.loss_mask: 0.3493  decode.d2.loss_dice: 0.4062  decode.d3.loss_cls: 0.3936  decode.d3.loss_mask: 0.3234  decode.d3.loss_dice: 0.3815  decode.d4.loss_cls: 0.3748  decode.d4.loss_mask: 0.3620  decode.d4.loss_dice: 0.3741  decode.d5.loss_cls: 0.5081  decode.d5.loss_mask: 0.3622  decode.d5.loss_dice: 0.3857  decode.d6.loss_cls: 0.4687  decode.d6.loss_mask: 0.3743  decode.d6.loss_dice: 0.3673  decode.d7.loss_cls: 0.5141  decode.d7.loss_mask: 0.3512  decode.d7.loss_dice: 0.3698  decode.d8.loss_cls: 0.4227  decode.d8.loss_mask: 0.3187  decode.d8.loss_dice: 0.3583
07/30 00:32:35 - mmengine - INFO - Iter(train) [10750/80000]  base_lr: 8.7822e-05 lr: 8.7822e-06  eta: 10:13:30  time: 0.5281  data_time: 0.0134  memory: 5881  grad_norm: 187.0278  loss: 11.7633  decode.loss_cls: 0.3486  decode.loss_mask: 0.3014  decode.loss_dice: 0.3782  decode.d0.loss_cls: 1.3409  decode.d0.loss_mask: 0.3124  decode.d0.loss_dice: 0.4437  decode.d1.loss_cls: 0.4239  decode.d1.loss_mask: 0.3047  decode.d1.loss_dice: 0.3998  decode.d2.loss_cls: 0.3951  decode.d2.loss_mask: 0.3102  decode.d2.loss_dice: 0.4055  decode.d3.loss_cls: 0.3802  decode.d3.loss_mask: 0.2932  decode.d3.loss_dice: 0.3823  decode.d4.loss_cls: 0.3579  decode.d4.loss_mask: 0.2949  decode.d4.loss_dice: 0.3842  decode.d5.loss_cls: 0.4559  decode.d5.loss_mask: 0.3019  decode.d5.loss_dice: 0.4015  decode.d6.loss_cls: 0.3574  decode.d6.loss_mask: 0.2964  decode.d6.loss_dice: 0.3944  decode.d7.loss_cls: 0.3279  decode.d7.loss_mask: 0.2983  decode.d7.loss_dice: 0.3852  decode.d8.loss_cls: 0.4069  decode.d8.loss_mask: 0.3050  decode.d8.loss_dice: 0.3753
07/30 00:33:01 - mmengine - INFO - Iter(train) [10800/80000]  base_lr: 8.7765e-05 lr: 8.7765e-06  eta: 10:13:03  time: 0.5259  data_time: 0.0135  memory: 5895  grad_norm: 126.4274  loss: 9.0750  decode.loss_cls: 0.2352  decode.loss_mask: 0.2714  decode.loss_dice: 0.3110  decode.d0.loss_cls: 1.0392  decode.d0.loss_mask: 0.2850  decode.d0.loss_dice: 0.3025  decode.d1.loss_cls: 0.3576  decode.d1.loss_mask: 0.2821  decode.d1.loss_dice: 0.2930  decode.d2.loss_cls: 0.2412  decode.d2.loss_mask: 0.2806  decode.d2.loss_dice: 0.3014  decode.d3.loss_cls: 0.2683  decode.d3.loss_mask: 0.2739  decode.d3.loss_dice: 0.2743  decode.d4.loss_cls: 0.2717  decode.d4.loss_mask: 0.2703  decode.d4.loss_dice: 0.3015  decode.d5.loss_cls: 0.2497  decode.d5.loss_mask: 0.2736  decode.d5.loss_dice: 0.2988  decode.d6.loss_cls: 0.2376  decode.d6.loss_mask: 0.2695  decode.d6.loss_dice: 0.2926  decode.d7.loss_cls: 0.2312  decode.d7.loss_mask: 0.2691  decode.d7.loss_dice: 0.2984  decode.d8.loss_cls: 0.2111  decode.d8.loss_mask: 0.2702  decode.d8.loss_dice: 0.3130
07/30 00:33:28 - mmengine - INFO - Iter(train) [10850/80000]  base_lr: 8.7708e-05 lr: 8.7708e-06  eta: 10:12:36  time: 0.5316  data_time: 0.0133  memory: 5896  grad_norm: 203.5224  loss: 8.8803  decode.loss_cls: 0.1920  decode.loss_mask: 0.2419  decode.loss_dice: 0.3006  decode.d0.loss_cls: 1.2079  decode.d0.loss_mask: 0.2491  decode.d0.loss_dice: 0.3661  decode.d1.loss_cls: 0.3072  decode.d1.loss_mask: 0.2383  decode.d1.loss_dice: 0.3198  decode.d2.loss_cls: 0.2436  decode.d2.loss_mask: 0.2387  decode.d2.loss_dice: 0.3226  decode.d3.loss_cls: 0.1948  decode.d3.loss_mask: 0.2389  decode.d3.loss_dice: 0.3338  decode.d4.loss_cls: 0.1899  decode.d4.loss_mask: 0.2404  decode.d4.loss_dice: 0.3325  decode.d5.loss_cls: 0.2463  decode.d5.loss_mask: 0.2415  decode.d5.loss_dice: 0.3225  decode.d6.loss_cls: 0.2099  decode.d6.loss_mask: 0.2381  decode.d6.loss_dice: 0.3023  decode.d7.loss_cls: 0.2139  decode.d7.loss_mask: 0.2367  decode.d7.loss_dice: 0.3241  decode.d8.loss_cls: 0.2148  decode.d8.loss_mask: 0.2390  decode.d8.loss_dice: 0.3331
07/30 00:33:54 - mmengine - INFO - Iter(train) [10900/80000]  base_lr: 8.7650e-05 lr: 8.7650e-06  eta: 10:12:08  time: 0.5271  data_time: 0.0133  memory: 5918  grad_norm: 448.0834  loss: 11.0610  decode.loss_cls: 0.3690  decode.loss_mask: 0.2977  decode.loss_dice: 0.3579  decode.d0.loss_cls: 1.0730  decode.d0.loss_mask: 0.3141  decode.d0.loss_dice: 0.3774  decode.d1.loss_cls: 0.4023  decode.d1.loss_mask: 0.3117  decode.d1.loss_dice: 0.3529  decode.d2.loss_cls: 0.4149  decode.d2.loss_mask: 0.3014  decode.d2.loss_dice: 0.3490  decode.d3.loss_cls: 0.3840  decode.d3.loss_mask: 0.2984  decode.d3.loss_dice: 0.3429  decode.d4.loss_cls: 0.3619  decode.d4.loss_mask: 0.3030  decode.d4.loss_dice: 0.3625  decode.d5.loss_cls: 0.3800  decode.d5.loss_mask: 0.2985  decode.d5.loss_dice: 0.3541  decode.d6.loss_cls: 0.4013  decode.d6.loss_mask: 0.2996  decode.d6.loss_dice: 0.3319  decode.d7.loss_cls: 0.3774  decode.d7.loss_mask: 0.2938  decode.d7.loss_dice: 0.3520  decode.d8.loss_cls: 0.3467  decode.d8.loss_mask: 0.2995  decode.d8.loss_dice: 0.3524
07/30 00:34:21 - mmengine - INFO - Iter(train) [10950/80000]  base_lr: 8.7593e-05 lr: 8.7593e-06  eta: 10:11:41  time: 0.5326  data_time: 0.0127  memory: 5919  grad_norm: 162.7397  loss: 9.2274  decode.loss_cls: 0.2889  decode.loss_mask: 0.2184  decode.loss_dice: 0.2886  decode.d0.loss_cls: 1.1868  decode.d0.loss_mask: 0.2356  decode.d0.loss_dice: 0.3188  decode.d1.loss_cls: 0.2904  decode.d1.loss_mask: 0.2369  decode.d1.loss_dice: 0.3106  decode.d2.loss_cls: 0.3323  decode.d2.loss_mask: 0.2317  decode.d2.loss_dice: 0.3239  decode.d3.loss_cls: 0.3108  decode.d3.loss_mask: 0.2249  decode.d3.loss_dice: 0.2934  decode.d4.loss_cls: 0.2533  decode.d4.loss_mask: 0.2242  decode.d4.loss_dice: 0.3125  decode.d5.loss_cls: 0.2421  decode.d5.loss_mask: 0.2287  decode.d5.loss_dice: 0.3338  decode.d6.loss_cls: 0.3529  decode.d6.loss_mask: 0.2211  decode.d6.loss_dice: 0.2884  decode.d7.loss_cls: 0.3173  decode.d7.loss_mask: 0.2245  decode.d7.loss_dice: 0.3230  decode.d8.loss_cls: 0.2811  decode.d8.loss_mask: 0.2176  decode.d8.loss_dice: 0.3150
07/30 00:34:47 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/30 00:34:47 - mmengine - INFO - Iter(train) [11000/80000]  base_lr: 8.7536e-05 lr: 8.7536e-06  eta: 10:11:13  time: 0.5256  data_time: 0.0130  memory: 5895  grad_norm: 160.7201  loss: 9.2206  decode.loss_cls: 0.2634  decode.loss_mask: 0.2431  decode.loss_dice: 0.2899  decode.d0.loss_cls: 1.2836  decode.d0.loss_mask: 0.2578  decode.d0.loss_dice: 0.3131  decode.d1.loss_cls: 0.4766  decode.d1.loss_mask: 0.2458  decode.d1.loss_dice: 0.2815  decode.d2.loss_cls: 0.2667  decode.d2.loss_mask: 0.2540  decode.d2.loss_dice: 0.2945  decode.d3.loss_cls: 0.2643  decode.d3.loss_mask: 0.2476  decode.d3.loss_dice: 0.2951  decode.d4.loss_cls: 0.2156  decode.d4.loss_mask: 0.2443  decode.d4.loss_dice: 0.2747  decode.d5.loss_cls: 0.2961  decode.d5.loss_mask: 0.2412  decode.d5.loss_dice: 0.2898  decode.d6.loss_cls: 0.3112  decode.d6.loss_mask: 0.2434  decode.d6.loss_dice: 0.2746  decode.d7.loss_cls: 0.2545  decode.d7.loss_mask: 0.2472  decode.d7.loss_dice: 0.2765  decode.d8.loss_cls: 0.2672  decode.d8.loss_mask: 0.2382  decode.d8.loss_dice: 0.2690
07/30 00:35:13 - mmengine - INFO - Iter(train) [11050/80000]  base_lr: 8.7479e-05 lr: 8.7479e-06  eta: 10:10:45  time: 0.5307  data_time: 0.0133  memory: 5918  grad_norm: 102.5989  loss: 8.3062  decode.loss_cls: 0.2222  decode.loss_mask: 0.2650  decode.loss_dice: 0.3214  decode.d0.loss_cls: 1.0488  decode.d0.loss_mask: 0.2699  decode.d0.loss_dice: 0.3366  decode.d1.loss_cls: 0.2391  decode.d1.loss_mask: 0.2550  decode.d1.loss_dice: 0.3119  decode.d2.loss_cls: 0.1114  decode.d2.loss_mask: 0.2481  decode.d2.loss_dice: 0.3093  decode.d3.loss_cls: 0.1251  decode.d3.loss_mask: 0.2482  decode.d3.loss_dice: 0.3209  decode.d4.loss_cls: 0.1285  decode.d4.loss_mask: 0.2479  decode.d4.loss_dice: 0.3049  decode.d5.loss_cls: 0.1729  decode.d5.loss_mask: 0.2518  decode.d5.loss_dice: 0.3159  decode.d6.loss_cls: 0.1522  decode.d6.loss_mask: 0.2635  decode.d6.loss_dice: 0.3097  decode.d7.loss_cls: 0.1619  decode.d7.loss_mask: 0.2750  decode.d7.loss_dice: 0.3078  decode.d8.loss_cls: 0.1968  decode.d8.loss_mask: 0.2597  decode.d8.loss_dice: 0.3246
07/30 00:35:40 - mmengine - INFO - Iter(train) [11100/80000]  base_lr: 8.7422e-05 lr: 8.7422e-06  eta: 10:10:19  time: 0.5333  data_time: 0.0138  memory: 5936  grad_norm: 156.2546  loss: 8.5843  decode.loss_cls: 0.2286  decode.loss_mask: 0.2526  decode.loss_dice: 0.2646  decode.d0.loss_cls: 1.0870  decode.d0.loss_mask: 0.2748  decode.d0.loss_dice: 0.2703  decode.d1.loss_cls: 0.3438  decode.d1.loss_mask: 0.2650  decode.d1.loss_dice: 0.2765  decode.d2.loss_cls: 0.3601  decode.d2.loss_mask: 0.2495  decode.d2.loss_dice: 0.2599  decode.d3.loss_cls: 0.2840  decode.d3.loss_mask: 0.2522  decode.d3.loss_dice: 0.2611  decode.d4.loss_cls: 0.2586  decode.d4.loss_mask: 0.2540  decode.d4.loss_dice: 0.2477  decode.d5.loss_cls: 0.2098  decode.d5.loss_mask: 0.2597  decode.d5.loss_dice: 0.2679  decode.d6.loss_cls: 0.2634  decode.d6.loss_mask: 0.2571  decode.d6.loss_dice: 0.2632  decode.d7.loss_cls: 0.1705  decode.d7.loss_mask: 0.2535  decode.d7.loss_dice: 0.2628  decode.d8.loss_cls: 0.1388  decode.d8.loss_mask: 0.2693  decode.d8.loss_dice: 0.2780
07/30 00:36:07 - mmengine - INFO - Iter(train) [11150/80000]  base_lr: 8.7365e-05 lr: 8.7365e-06  eta: 10:09:52  time: 0.5289  data_time: 0.0131  memory: 5881  grad_norm: 269.5899  loss: 11.1527  decode.loss_cls: 0.2935  decode.loss_mask: 0.4592  decode.loss_dice: 0.2836  decode.d0.loss_cls: 1.3010  decode.d0.loss_mask: 0.3383  decode.d0.loss_dice: 0.3141  decode.d1.loss_cls: 0.4697  decode.d1.loss_mask: 0.3318  decode.d1.loss_dice: 0.2814  decode.d2.loss_cls: 0.4205  decode.d2.loss_mask: 0.3201  decode.d2.loss_dice: 0.2783  decode.d3.loss_cls: 0.4055  decode.d3.loss_mask: 0.3227  decode.d3.loss_dice: 0.2678  decode.d4.loss_cls: 0.3659  decode.d4.loss_mask: 0.3359  decode.d4.loss_dice: 0.3164  decode.d5.loss_cls: 0.3506  decode.d5.loss_mask: 0.3172  decode.d5.loss_dice: 0.2694  decode.d6.loss_cls: 0.2996  decode.d6.loss_mask: 0.3355  decode.d6.loss_dice: 0.3064  decode.d7.loss_cls: 0.3197  decode.d7.loss_mask: 0.3778  decode.d7.loss_dice: 0.3217  decode.d8.loss_cls: 0.3074  decode.d8.loss_mask: 0.5212  decode.d8.loss_dice: 0.3205
07/30 00:36:33 - mmengine - INFO - Iter(train) [11200/80000]  base_lr: 8.7308e-05 lr: 8.7308e-06  eta: 10:09:25  time: 0.5343  data_time: 0.0137  memory: 5896  grad_norm: 102.3733  loss: 10.4811  decode.loss_cls: 0.1480  decode.loss_mask: 0.4409  decode.loss_dice: 0.3567  decode.d0.loss_cls: 0.9127  decode.d0.loss_mask: 0.4451  decode.d0.loss_dice: 0.4055  decode.d1.loss_cls: 0.2862  decode.d1.loss_mask: 0.4435  decode.d1.loss_dice: 0.3583  decode.d2.loss_cls: 0.2048  decode.d2.loss_mask: 0.4411  decode.d2.loss_dice: 0.3519  decode.d3.loss_cls: 0.1528  decode.d3.loss_mask: 0.4353  decode.d3.loss_dice: 0.3537  decode.d4.loss_cls: 0.1682  decode.d4.loss_mask: 0.4261  decode.d4.loss_dice: 0.3487  decode.d5.loss_cls: 0.1700  decode.d5.loss_mask: 0.4317  decode.d5.loss_dice: 0.3527  decode.d6.loss_cls: 0.1678  decode.d6.loss_mask: 0.4343  decode.d6.loss_dice: 0.3571  decode.d7.loss_cls: 0.1537  decode.d7.loss_mask: 0.4327  decode.d7.loss_dice: 0.3525  decode.d8.loss_cls: 0.1532  decode.d8.loss_mask: 0.4407  decode.d8.loss_dice: 0.3552
07/30 00:37:00 - mmengine - INFO - Iter(train) [11250/80000]  base_lr: 8.7251e-05 lr: 8.7251e-06  eta: 10:08:59  time: 0.5363  data_time: 0.0137  memory: 5916  grad_norm: 134.1514  loss: 9.5707  decode.loss_cls: 0.1462  decode.loss_mask: 0.2922  decode.loss_dice: 0.3904  decode.d0.loss_cls: 1.0321  decode.d0.loss_mask: 0.2951  decode.d0.loss_dice: 0.4111  decode.d1.loss_cls: 0.2089  decode.d1.loss_mask: 0.2950  decode.d1.loss_dice: 0.4159  decode.d2.loss_cls: 0.1869  decode.d2.loss_mask: 0.2882  decode.d2.loss_dice: 0.4025  decode.d3.loss_cls: 0.2319  decode.d3.loss_mask: 0.2855  decode.d3.loss_dice: 0.4008  decode.d4.loss_cls: 0.1717  decode.d4.loss_mask: 0.2884  decode.d4.loss_dice: 0.4133  decode.d5.loss_cls: 0.1743  decode.d5.loss_mask: 0.2870  decode.d5.loss_dice: 0.3929  decode.d6.loss_cls: 0.1654  decode.d6.loss_mask: 0.2899  decode.d6.loss_dice: 0.3978  decode.d7.loss_cls: 0.1884  decode.d7.loss_mask: 0.2866  decode.d7.loss_dice: 0.3841  decode.d8.loss_cls: 0.1754  decode.d8.loss_mask: 0.2866  decode.d8.loss_dice: 0.3862
07/30 00:37:27 - mmengine - INFO - Iter(train) [11300/80000]  base_lr: 8.7194e-05 lr: 8.7194e-06  eta: 10:08:33  time: 0.5312  data_time: 0.0130  memory: 5934  grad_norm: 96.6240  loss: 8.7534  decode.loss_cls: 0.2202  decode.loss_mask: 0.2485  decode.loss_dice: 0.3197  decode.d0.loss_cls: 1.0430  decode.d0.loss_mask: 0.2570  decode.d0.loss_dice: 0.3251  decode.d1.loss_cls: 0.3318  decode.d1.loss_mask: 0.2533  decode.d1.loss_dice: 0.2963  decode.d2.loss_cls: 0.2776  decode.d2.loss_mask: 0.2577  decode.d2.loss_dice: 0.3018  decode.d3.loss_cls: 0.2222  decode.d3.loss_mask: 0.2517  decode.d3.loss_dice: 0.2936  decode.d4.loss_cls: 0.2018  decode.d4.loss_mask: 0.2468  decode.d4.loss_dice: 0.3049  decode.d5.loss_cls: 0.2096  decode.d5.loss_mask: 0.2512  decode.d5.loss_dice: 0.3005  decode.d6.loss_cls: 0.1910  decode.d6.loss_mask: 0.2577  decode.d6.loss_dice: 0.3065  decode.d7.loss_cls: 0.1927  decode.d7.loss_mask: 0.2677  decode.d7.loss_dice: 0.3139  decode.d8.loss_cls: 0.2195  decode.d8.loss_mask: 0.2618  decode.d8.loss_dice: 0.3283
07/30 00:37:53 - mmengine - INFO - Iter(train) [11350/80000]  base_lr: 8.7137e-05 lr: 8.7137e-06  eta: 10:08:07  time: 0.5326  data_time: 0.0138  memory: 5918  grad_norm: 170.9301  loss: 12.4331  decode.loss_cls: 0.4202  decode.loss_mask: 0.3263  decode.loss_dice: 0.3443  decode.d0.loss_cls: 1.2305  decode.d0.loss_mask: 0.3318  decode.d0.loss_dice: 0.4053  decode.d1.loss_cls: 0.5693  decode.d1.loss_mask: 0.3107  decode.d1.loss_dice: 0.3637  decode.d2.loss_cls: 0.4993  decode.d2.loss_mask: 0.3423  decode.d2.loss_dice: 0.3756  decode.d3.loss_cls: 0.4313  decode.d3.loss_mask: 0.3353  decode.d3.loss_dice: 0.3417  decode.d4.loss_cls: 0.3966  decode.d4.loss_mask: 0.3492  decode.d4.loss_dice: 0.3874  decode.d5.loss_cls: 0.4493  decode.d5.loss_mask: 0.3438  decode.d5.loss_dice: 0.3631  decode.d6.loss_cls: 0.5035  decode.d6.loss_mask: 0.3073  decode.d6.loss_dice: 0.3820  decode.d7.loss_cls: 0.5227  decode.d7.loss_mask: 0.3018  decode.d7.loss_dice: 0.3457  decode.d8.loss_cls: 0.4544  decode.d8.loss_mask: 0.3309  decode.d8.loss_dice: 0.3675
07/30 00:38:20 - mmengine - INFO - Iter(train) [11400/80000]  base_lr: 8.7079e-05 lr: 8.7079e-06  eta: 10:07:40  time: 0.5316  data_time: 0.0133  memory: 5916  grad_norm: 227.3659  loss: 12.5750  decode.loss_cls: 0.3514  decode.loss_mask: 0.4215  decode.loss_dice: 0.3779  decode.d0.loss_cls: 1.3271  decode.d0.loss_mask: 0.4167  decode.d0.loss_dice: 0.4521  decode.d1.loss_cls: 0.5021  decode.d1.loss_mask: 0.4034  decode.d1.loss_dice: 0.3869  decode.d2.loss_cls: 0.4029  decode.d2.loss_mask: 0.3549  decode.d2.loss_dice: 0.3617  decode.d3.loss_cls: 0.3642  decode.d3.loss_mask: 0.3427  decode.d3.loss_dice: 0.3563  decode.d4.loss_cls: 0.3078  decode.d4.loss_mask: 0.4368  decode.d4.loss_dice: 0.3735  decode.d5.loss_cls: 0.4369  decode.d5.loss_mask: 0.4145  decode.d5.loss_dice: 0.3617  decode.d6.loss_cls: 0.3690  decode.d6.loss_mask: 0.4044  decode.d6.loss_dice: 0.3634  decode.d7.loss_cls: 0.3728  decode.d7.loss_mask: 0.4014  decode.d7.loss_dice: 0.3691  decode.d8.loss_cls: 0.3553  decode.d8.loss_mask: 0.3948  decode.d8.loss_dice: 0.3918
07/30 00:38:46 - mmengine - INFO - Iter(train) [11450/80000]  base_lr: 8.7022e-05 lr: 8.7022e-06  eta: 10:07:13  time: 0.5304  data_time: 0.0134  memory: 5918  grad_norm: 160.5083  loss: 8.3271  decode.loss_cls: 0.2290  decode.loss_mask: 0.2380  decode.loss_dice: 0.2753  decode.d0.loss_cls: 1.0735  decode.d0.loss_mask: 0.2386  decode.d0.loss_dice: 0.3369  decode.d1.loss_cls: 0.3482  decode.d1.loss_mask: 0.2257  decode.d1.loss_dice: 0.2923  decode.d2.loss_cls: 0.2100  decode.d2.loss_mask: 0.2277  decode.d2.loss_dice: 0.2679  decode.d3.loss_cls: 0.2116  decode.d3.loss_mask: 0.2274  decode.d3.loss_dice: 0.2697  decode.d4.loss_cls: 0.2294  decode.d4.loss_mask: 0.2348  decode.d4.loss_dice: 0.2697  decode.d5.loss_cls: 0.2302  decode.d5.loss_mask: 0.2364  decode.d5.loss_dice: 0.2557  decode.d6.loss_cls: 0.2106  decode.d6.loss_mask: 0.2324  decode.d6.loss_dice: 0.2633  decode.d7.loss_cls: 0.2134  decode.d7.loss_mask: 0.2329  decode.d7.loss_dice: 0.2778  decode.d8.loss_cls: 0.2447  decode.d8.loss_mask: 0.2411  decode.d8.loss_dice: 0.2830
07/30 00:39:13 - mmengine - INFO - Iter(train) [11500/80000]  base_lr: 8.6965e-05 lr: 8.6965e-06  eta: 10:06:45  time: 0.5294  data_time: 0.0138  memory: 5896  grad_norm: 150.9752  loss: 10.0620  decode.loss_cls: 0.3166  decode.loss_mask: 0.2995  decode.loss_dice: 0.3299  decode.d0.loss_cls: 0.9997  decode.d0.loss_mask: 0.3021  decode.d0.loss_dice: 0.4074  decode.d1.loss_cls: 0.3614  decode.d1.loss_mask: 0.2873  decode.d1.loss_dice: 0.3369  decode.d2.loss_cls: 0.3052  decode.d2.loss_mask: 0.2948  decode.d2.loss_dice: 0.3328  decode.d3.loss_cls: 0.2731  decode.d3.loss_mask: 0.2971  decode.d3.loss_dice: 0.3345  decode.d4.loss_cls: 0.2737  decode.d4.loss_mask: 0.2954  decode.d4.loss_dice: 0.3311  decode.d5.loss_cls: 0.3138  decode.d5.loss_mask: 0.2954  decode.d5.loss_dice: 0.3337  decode.d6.loss_cls: 0.2748  decode.d6.loss_mask: 0.2966  decode.d6.loss_dice: 0.3348  decode.d7.loss_cls: 0.2898  decode.d7.loss_mask: 0.2936  decode.d7.loss_dice: 0.3275  decode.d8.loss_cls: 0.2864  decode.d8.loss_mask: 0.3004  decode.d8.loss_dice: 0.3366
07/30 00:39:39 - mmengine - INFO - Iter(train) [11550/80000]  base_lr: 8.6908e-05 lr: 8.6908e-06  eta: 10:06:18  time: 0.5325  data_time: 0.0132  memory: 5971  grad_norm: 299.7928  loss: 9.7163  decode.loss_cls: 0.1541  decode.loss_mask: 0.3085  decode.loss_dice: 0.3319  decode.d0.loss_cls: 1.2700  decode.d0.loss_mask: 0.3551  decode.d0.loss_dice: 0.4024  decode.d1.loss_cls: 0.4336  decode.d1.loss_mask: 0.2992  decode.d1.loss_dice: 0.3310  decode.d2.loss_cls: 0.2575  decode.d2.loss_mask: 0.3153  decode.d2.loss_dice: 0.3559  decode.d3.loss_cls: 0.2545  decode.d3.loss_mask: 0.2917  decode.d3.loss_dice: 0.3104  decode.d4.loss_cls: 0.2113  decode.d4.loss_mask: 0.3115  decode.d4.loss_dice: 0.3307  decode.d5.loss_cls: 0.1697  decode.d5.loss_mask: 0.3065  decode.d5.loss_dice: 0.3302  decode.d6.loss_cls: 0.1627  decode.d6.loss_mask: 0.3034  decode.d6.loss_dice: 0.3336  decode.d7.loss_cls: 0.1642  decode.d7.loss_mask: 0.3036  decode.d7.loss_dice: 0.3427  decode.d8.loss_cls: 0.1410  decode.d8.loss_mask: 0.3031  decode.d8.loss_dice: 0.3311
07/30 00:40:06 - mmengine - INFO - Iter(train) [11600/80000]  base_lr: 8.6851e-05 lr: 8.6851e-06  eta: 10:05:51  time: 0.5258  data_time: 0.0131  memory: 5986  grad_norm: 167.0492  loss: 10.3487  decode.loss_cls: 0.3037  decode.loss_mask: 0.2328  decode.loss_dice: 0.3133  decode.d0.loss_cls: 1.3952  decode.d0.loss_mask: 0.2352  decode.d0.loss_dice: 0.3456  decode.d1.loss_cls: 0.5667  decode.d1.loss_mask: 0.2338  decode.d1.loss_dice: 0.3274  decode.d2.loss_cls: 0.4037  decode.d2.loss_mask: 0.2302  decode.d2.loss_dice: 0.3263  decode.d3.loss_cls: 0.3257  decode.d3.loss_mask: 0.2283  decode.d3.loss_dice: 0.3202  decode.d4.loss_cls: 0.3037  decode.d4.loss_mask: 0.2326  decode.d4.loss_dice: 0.3294  decode.d5.loss_cls: 0.3562  decode.d5.loss_mask: 0.2332  decode.d5.loss_dice: 0.3091  decode.d6.loss_cls: 0.3790  decode.d6.loss_mask: 0.2335  decode.d6.loss_dice: 0.3042  decode.d7.loss_cls: 0.3913  decode.d7.loss_mask: 0.2323  decode.d7.loss_dice: 0.3231  decode.d8.loss_cls: 0.3772  decode.d8.loss_mask: 0.2307  decode.d8.loss_dice: 0.3250
07/30 00:40:32 - mmengine - INFO - Iter(train) [11650/80000]  base_lr: 8.6794e-05 lr: 8.6794e-06  eta: 10:05:24  time: 0.5316  data_time: 0.0134  memory: 5933  grad_norm: 248.0813  loss: 10.9999  decode.loss_cls: 0.2881  decode.loss_mask: 0.2925  decode.loss_dice: 0.3381  decode.d0.loss_cls: 1.1985  decode.d0.loss_mask: 0.3034  decode.d0.loss_dice: 0.4099  decode.d1.loss_cls: 0.4451  decode.d1.loss_mask: 0.3086  decode.d1.loss_dice: 0.3393  decode.d2.loss_cls: 0.3673  decode.d2.loss_mask: 0.2954  decode.d2.loss_dice: 0.3536  decode.d3.loss_cls: 0.3905  decode.d3.loss_mask: 0.2917  decode.d3.loss_dice: 0.3641  decode.d4.loss_cls: 0.3525  decode.d4.loss_mask: 0.2912  decode.d4.loss_dice: 0.3478  decode.d5.loss_cls: 0.3641  decode.d5.loss_mask: 0.2974  decode.d5.loss_dice: 0.3637  decode.d6.loss_cls: 0.3830  decode.d6.loss_mask: 0.2901  decode.d6.loss_dice: 0.3324  decode.d7.loss_cls: 0.2999  decode.d7.loss_mask: 0.2988  decode.d7.loss_dice: 0.3630  decode.d8.loss_cls: 0.3732  decode.d8.loss_mask: 0.2929  decode.d8.loss_dice: 0.3636
07/30 00:40:59 - mmengine - INFO - Iter(train) [11700/80000]  base_lr: 8.6737e-05 lr: 8.6737e-06  eta: 10:04:59  time: 0.5319  data_time: 0.0134  memory: 5934  grad_norm: 105.5995  loss: 7.7162  decode.loss_cls: 0.1575  decode.loss_mask: 0.2375  decode.loss_dice: 0.2921  decode.d0.loss_cls: 1.1439  decode.d0.loss_mask: 0.2499  decode.d0.loss_dice: 0.3504  decode.d1.loss_cls: 0.2554  decode.d1.loss_mask: 0.2470  decode.d1.loss_dice: 0.3092  decode.d2.loss_cls: 0.1699  decode.d2.loss_mask: 0.2452  decode.d2.loss_dice: 0.2923  decode.d3.loss_cls: 0.1540  decode.d3.loss_mask: 0.2396  decode.d3.loss_dice: 0.2787  decode.d4.loss_cls: 0.1238  decode.d4.loss_mask: 0.2400  decode.d4.loss_dice: 0.2668  decode.d5.loss_cls: 0.1222  decode.d5.loss_mask: 0.2422  decode.d5.loss_dice: 0.2696  decode.d6.loss_cls: 0.0882  decode.d6.loss_mask: 0.2465  decode.d6.loss_dice: 0.2772  decode.d7.loss_cls: 0.0859  decode.d7.loss_mask: 0.2425  decode.d7.loss_dice: 0.2702  decode.d8.loss_cls: 0.1017  decode.d8.loss_mask: 0.2413  decode.d8.loss_dice: 0.2756
07/30 00:41:26 - mmengine - INFO - Iter(train) [11750/80000]  base_lr: 8.6679e-05 lr: 8.6679e-06  eta: 10:04:33  time: 0.5330  data_time: 0.0134  memory: 5931  grad_norm: 140.7686  loss: 11.3943  decode.loss_cls: 0.3314  decode.loss_mask: 0.2742  decode.loss_dice: 0.3871  decode.d0.loss_cls: 1.3328  decode.d0.loss_mask: 0.2873  decode.d0.loss_dice: 0.4178  decode.d1.loss_cls: 0.5092  decode.d1.loss_mask: 0.2771  decode.d1.loss_dice: 0.3936  decode.d2.loss_cls: 0.3365  decode.d2.loss_mask: 0.2786  decode.d2.loss_dice: 0.3993  decode.d3.loss_cls: 0.3659  decode.d3.loss_mask: 0.2695  decode.d3.loss_dice: 0.3828  decode.d4.loss_cls: 0.3945  decode.d4.loss_mask: 0.2692  decode.d4.loss_dice: 0.3799  decode.d5.loss_cls: 0.3337  decode.d5.loss_mask: 0.2633  decode.d5.loss_dice: 0.3781  decode.d6.loss_cls: 0.3280  decode.d6.loss_mask: 0.2763  decode.d6.loss_dice: 0.3899  decode.d7.loss_cls: 0.3852  decode.d7.loss_mask: 0.2714  decode.d7.loss_dice: 0.3877  decode.d8.loss_cls: 0.4148  decode.d8.loss_mask: 0.2727  decode.d8.loss_dice: 0.4062
07/30 00:41:52 - mmengine - INFO - Iter(train) [11800/80000]  base_lr: 8.6622e-05 lr: 8.6622e-06  eta: 10:04:05  time: 0.5322  data_time: 0.0134  memory: 5896  grad_norm: 150.6106  loss: 9.1815  decode.loss_cls: 0.3022  decode.loss_mask: 0.2672  decode.loss_dice: 0.4066  decode.d0.loss_cls: 1.1087  decode.d0.loss_mask: 0.2784  decode.d0.loss_dice: 0.3349  decode.d1.loss_cls: 0.2439  decode.d1.loss_mask: 0.2684  decode.d1.loss_dice: 0.3197  decode.d2.loss_cls: 0.2383  decode.d2.loss_mask: 0.2605  decode.d2.loss_dice: 0.3136  decode.d3.loss_cls: 0.2027  decode.d3.loss_mask: 0.2579  decode.d3.loss_dice: 0.2942  decode.d4.loss_cls: 0.1852  decode.d4.loss_mask: 0.2587  decode.d4.loss_dice: 0.2985  decode.d5.loss_cls: 0.1880  decode.d5.loss_mask: 0.2621  decode.d5.loss_dice: 0.3360  decode.d6.loss_cls: 0.2035  decode.d6.loss_mask: 0.2642  decode.d6.loss_dice: 0.3606  decode.d7.loss_cls: 0.2549  decode.d7.loss_mask: 0.2604  decode.d7.loss_dice: 0.3415  decode.d8.loss_cls: 0.2344  decode.d8.loss_mask: 0.2647  decode.d8.loss_dice: 0.3716
07/30 00:42:19 - mmengine - INFO - Iter(train) [11850/80000]  base_lr: 8.6565e-05 lr: 8.6565e-06  eta: 10:03:40  time: 0.5366  data_time: 0.0137  memory: 5934  grad_norm: 116.5002  loss: 9.7888  decode.loss_cls: 0.3237  decode.loss_mask: 0.2118  decode.loss_dice: 0.2981  decode.d0.loss_cls: 1.1694  decode.d0.loss_mask: 0.2157  decode.d0.loss_dice: 0.3236  decode.d1.loss_cls: 0.4413  decode.d1.loss_mask: 0.2232  decode.d1.loss_dice: 0.3059  decode.d2.loss_cls: 0.3966  decode.d2.loss_mask: 0.2181  decode.d2.loss_dice: 0.2955  decode.d3.loss_cls: 0.4524  decode.d3.loss_mask: 0.2124  decode.d3.loss_dice: 0.3097  decode.d4.loss_cls: 0.3773  decode.d4.loss_mask: 0.2089  decode.d4.loss_dice: 0.2982  decode.d5.loss_cls: 0.3845  decode.d5.loss_mask: 0.2089  decode.d5.loss_dice: 0.2901  decode.d6.loss_cls: 0.3530  decode.d6.loss_mask: 0.2168  decode.d6.loss_dice: 0.2891  decode.d7.loss_cls: 0.3601  decode.d7.loss_mask: 0.2161  decode.d7.loss_dice: 0.3041  decode.d8.loss_cls: 0.3715  decode.d8.loss_mask: 0.2117  decode.d8.loss_dice: 0.3011
07/30 00:42:45 - mmengine - INFO - Iter(train) [11900/80000]  base_lr: 8.6508e-05 lr: 8.6508e-06  eta: 10:03:14  time: 0.5353  data_time: 0.0133  memory: 5971  grad_norm: 93.9793  loss: 7.5484  decode.loss_cls: 0.1515  decode.loss_mask: 0.1866  decode.loss_dice: 0.2865  decode.d0.loss_cls: 1.1329  decode.d0.loss_mask: 0.2011  decode.d0.loss_dice: 0.3329  decode.d1.loss_cls: 0.3077  decode.d1.loss_mask: 0.1854  decode.d1.loss_dice: 0.2838  decode.d2.loss_cls: 0.1321  decode.d2.loss_mask: 0.1840  decode.d2.loss_dice: 0.2882  decode.d3.loss_cls: 0.1559  decode.d3.loss_mask: 0.1840  decode.d3.loss_dice: 0.2950  decode.d4.loss_cls: 0.1872  decode.d4.loss_mask: 0.1840  decode.d4.loss_dice: 0.2811  decode.d5.loss_cls: 0.1826  decode.d5.loss_mask: 0.1837  decode.d5.loss_dice: 0.2767  decode.d6.loss_cls: 0.1636  decode.d6.loss_mask: 0.1826  decode.d6.loss_dice: 0.2844  decode.d7.loss_cls: 0.1616  decode.d7.loss_mask: 0.1859  decode.d7.loss_dice: 0.2901  decode.d8.loss_cls: 0.1973  decode.d8.loss_mask: 0.1882  decode.d8.loss_dice: 0.2917
07/30 00:43:12 - mmengine - INFO - Iter(train) [11950/80000]  base_lr: 8.6451e-05 lr: 8.6451e-06  eta: 10:02:48  time: 0.5328  data_time: 0.0132  memory: 5918  grad_norm: 83.3418  loss: 9.4360  decode.loss_cls: 0.2971  decode.loss_mask: 0.2179  decode.loss_dice: 0.3171  decode.d0.loss_cls: 1.0640  decode.d0.loss_mask: 0.2259  decode.d0.loss_dice: 0.3522  decode.d1.loss_cls: 0.3905  decode.d1.loss_mask: 0.2191  decode.d1.loss_dice: 0.3301  decode.d2.loss_cls: 0.3665  decode.d2.loss_mask: 0.2174  decode.d2.loss_dice: 0.3140  decode.d3.loss_cls: 0.3056  decode.d3.loss_mask: 0.2229  decode.d3.loss_dice: 0.3460  decode.d4.loss_cls: 0.2786  decode.d4.loss_mask: 0.2144  decode.d4.loss_dice: 0.3383  decode.d5.loss_cls: 0.3087  decode.d5.loss_mask: 0.2166  decode.d5.loss_dice: 0.3346  decode.d6.loss_cls: 0.3233  decode.d6.loss_mask: 0.2188  decode.d6.loss_dice: 0.3333  decode.d7.loss_cls: 0.2838  decode.d7.loss_mask: 0.2168  decode.d7.loss_dice: 0.3448  decode.d8.loss_cls: 0.3029  decode.d8.loss_mask: 0.2150  decode.d8.loss_dice: 0.3200
07/30 00:43:39 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/30 00:43:39 - mmengine - INFO - Iter(train) [12000/80000]  base_lr: 8.6394e-05 lr: 8.6394e-06  eta: 10:02:22  time: 0.5357  data_time: 0.0137  memory: 5898  grad_norm: 126.6541  loss: 6.9845  decode.loss_cls: 0.1176  decode.loss_mask: 0.2268  decode.loss_dice: 0.2794  decode.d0.loss_cls: 0.9139  decode.d0.loss_mask: 0.2344  decode.d0.loss_dice: 0.2927  decode.d1.loss_cls: 0.2020  decode.d1.loss_mask: 0.2120  decode.d1.loss_dice: 0.2605  decode.d2.loss_cls: 0.1571  decode.d2.loss_mask: 0.2046  decode.d2.loss_dice: 0.2647  decode.d3.loss_cls: 0.1312  decode.d3.loss_mask: 0.2074  decode.d3.loss_dice: 0.2525  decode.d4.loss_cls: 0.1555  decode.d4.loss_mask: 0.2068  decode.d4.loss_dice: 0.2458  decode.d5.loss_cls: 0.1894  decode.d5.loss_mask: 0.2063  decode.d5.loss_dice: 0.2624  decode.d6.loss_cls: 0.1063  decode.d6.loss_mask: 0.2063  decode.d6.loss_dice: 0.2554  decode.d7.loss_cls: 0.1020  decode.d7.loss_mask: 0.2114  decode.d7.loss_dice: 0.2787  decode.d8.loss_cls: 0.1072  decode.d8.loss_mask: 0.2184  decode.d8.loss_dice: 0.2759
07/30 00:44:05 - mmengine - INFO - Iter(train) [12050/80000]  base_lr: 8.6336e-05 lr: 8.6336e-06  eta: 10:01:56  time: 0.5267  data_time: 0.0137  memory: 5931  grad_norm: 120.7329  loss: 7.8666  decode.loss_cls: 0.2165  decode.loss_mask: 0.2775  decode.loss_dice: 0.2566  decode.d0.loss_cls: 0.9104  decode.d0.loss_mask: 0.2867  decode.d0.loss_dice: 0.2764  decode.d1.loss_cls: 0.1891  decode.d1.loss_mask: 0.2825  decode.d1.loss_dice: 0.2625  decode.d2.loss_cls: 0.1544  decode.d2.loss_mask: 0.2835  decode.d2.loss_dice: 0.2631  decode.d3.loss_cls: 0.1197  decode.d3.loss_mask: 0.2798  decode.d3.loss_dice: 0.2587  decode.d4.loss_cls: 0.1529  decode.d4.loss_mask: 0.2833  decode.d4.loss_dice: 0.2540  decode.d5.loss_cls: 0.1794  decode.d5.loss_mask: 0.2808  decode.d5.loss_dice: 0.2588  decode.d6.loss_cls: 0.1695  decode.d6.loss_mask: 0.2761  decode.d6.loss_dice: 0.2583  decode.d7.loss_cls: 0.1810  decode.d7.loss_mask: 0.2797  decode.d7.loss_dice: 0.2657  decode.d8.loss_cls: 0.1786  decode.d8.loss_mask: 0.2760  decode.d8.loss_dice: 0.2550
07/30 00:44:32 - mmengine - INFO - Iter(train) [12100/80000]  base_lr: 8.6279e-05 lr: 8.6279e-06  eta: 10:01:29  time: 0.5308  data_time: 0.0132  memory: 5988  grad_norm: 112.3771  loss: 10.7612  decode.loss_cls: 0.4147  decode.loss_mask: 0.2403  decode.loss_dice: 0.3687  decode.d0.loss_cls: 1.0229  decode.d0.loss_mask: 0.2570  decode.d0.loss_dice: 0.4216  decode.d1.loss_cls: 0.4178  decode.d1.loss_mask: 0.2474  decode.d1.loss_dice: 0.3883  decode.d2.loss_cls: 0.4302  decode.d2.loss_mask: 0.2448  decode.d2.loss_dice: 0.3591  decode.d3.loss_cls: 0.3440  decode.d3.loss_mask: 0.2433  decode.d3.loss_dice: 0.3669  decode.d4.loss_cls: 0.3728  decode.d4.loss_mask: 0.2445  decode.d4.loss_dice: 0.3683  decode.d5.loss_cls: 0.4061  decode.d5.loss_mask: 0.2426  decode.d5.loss_dice: 0.3555  decode.d6.loss_cls: 0.4084  decode.d6.loss_mask: 0.2388  decode.d6.loss_dice: 0.3587  decode.d7.loss_cls: 0.3720  decode.d7.loss_mask: 0.2379  decode.d7.loss_dice: 0.3684  decode.d8.loss_cls: 0.4285  decode.d8.loss_mask: 0.2427  decode.d8.loss_dice: 0.3491
07/30 00:44:59 - mmengine - INFO - Iter(train) [12150/80000]  base_lr: 8.6222e-05 lr: 8.6222e-06  eta: 10:01:03  time: 0.5340  data_time: 0.0141  memory: 5933  grad_norm: 145.6692  loss: 8.6147  decode.loss_cls: 0.1455  decode.loss_mask: 0.3264  decode.loss_dice: 0.3007  decode.d0.loss_cls: 0.9187  decode.d0.loss_mask: 0.3464  decode.d0.loss_dice: 0.3329  decode.d1.loss_cls: 0.2226  decode.d1.loss_mask: 0.3349  decode.d1.loss_dice: 0.2964  decode.d2.loss_cls: 0.1546  decode.d2.loss_mask: 0.3316  decode.d2.loss_dice: 0.2882  decode.d3.loss_cls: 0.0953  decode.d3.loss_mask: 0.3365  decode.d3.loss_dice: 0.3021  decode.d4.loss_cls: 0.1685  decode.d4.loss_mask: 0.3305  decode.d4.loss_dice: 0.2980  decode.d5.loss_cls: 0.1617  decode.d5.loss_mask: 0.3286  decode.d5.loss_dice: 0.2986  decode.d6.loss_cls: 0.1452  decode.d6.loss_mask: 0.3233  decode.d6.loss_dice: 0.2919  decode.d7.loss_cls: 0.1434  decode.d7.loss_mask: 0.3236  decode.d7.loss_dice: 0.2830  decode.d8.loss_cls: 0.1397  decode.d8.loss_mask: 0.3280  decode.d8.loss_dice: 0.3179
07/30 00:45:25 - mmengine - INFO - Iter(train) [12200/80000]  base_lr: 8.6165e-05 lr: 8.6165e-06  eta: 10:00:36  time: 0.5331  data_time: 0.0135  memory: 5918  grad_norm: 136.4354  loss: 8.6020  decode.loss_cls: 0.1122  decode.loss_mask: 0.2769  decode.loss_dice: 0.3477  decode.d0.loss_cls: 1.1391  decode.d0.loss_mask: 0.2833  decode.d0.loss_dice: 0.3834  decode.d1.loss_cls: 0.1958  decode.d1.loss_mask: 0.2780  decode.d1.loss_dice: 0.3581  decode.d2.loss_cls: 0.1780  decode.d2.loss_mask: 0.2749  decode.d2.loss_dice: 0.3382  decode.d3.loss_cls: 0.1434  decode.d3.loss_mask: 0.2743  decode.d3.loss_dice: 0.3500  decode.d4.loss_cls: 0.1134  decode.d4.loss_mask: 0.2722  decode.d4.loss_dice: 0.3450  decode.d5.loss_cls: 0.1335  decode.d5.loss_mask: 0.2736  decode.d5.loss_dice: 0.3544  decode.d6.loss_cls: 0.1075  decode.d6.loss_mask: 0.2747  decode.d6.loss_dice: 0.3615  decode.d7.loss_cls: 0.0886  decode.d7.loss_mask: 0.2757  decode.d7.loss_dice: 0.3499  decode.d8.loss_cls: 0.0847  decode.d8.loss_mask: 0.2775  decode.d8.loss_dice: 0.3564
07/30 00:45:52 - mmengine - INFO - Iter(train) [12250/80000]  base_lr: 8.6108e-05 lr: 8.6108e-06  eta: 10:00:10  time: 0.5315  data_time: 0.0134  memory: 5933  grad_norm: 156.6795  loss: 9.9029  decode.loss_cls: 0.2386  decode.loss_mask: 0.2638  decode.loss_dice: 0.3523  decode.d0.loss_cls: 1.1726  decode.d0.loss_mask: 0.2780  decode.d0.loss_dice: 0.4196  decode.d1.loss_cls: 0.3568  decode.d1.loss_mask: 0.2835  decode.d1.loss_dice: 0.4275  decode.d2.loss_cls: 0.2912  decode.d2.loss_mask: 0.2691  decode.d2.loss_dice: 0.4013  decode.d3.loss_cls: 0.2254  decode.d3.loss_mask: 0.2632  decode.d3.loss_dice: 0.3789  decode.d4.loss_cls: 0.2198  decode.d4.loss_mask: 0.2622  decode.d4.loss_dice: 0.3723  decode.d5.loss_cls: 0.2512  decode.d5.loss_mask: 0.2637  decode.d5.loss_dice: 0.3538  decode.d6.loss_cls: 0.2326  decode.d6.loss_mask: 0.2587  decode.d6.loss_dice: 0.3529  decode.d7.loss_cls: 0.2519  decode.d7.loss_mask: 0.2576  decode.d7.loss_dice: 0.3619  decode.d8.loss_cls: 0.2264  decode.d8.loss_mask: 0.2662  decode.d8.loss_dice: 0.3501
07/30 00:46:19 - mmengine - INFO - Iter(train) [12300/80000]  base_lr: 8.6051e-05 lr: 8.6051e-06  eta: 9:59:44  time: 0.5330  data_time: 0.0136  memory: 5919  grad_norm: 178.0278  loss: 9.6850  decode.loss_cls: 0.2712  decode.loss_mask: 0.3022  decode.loss_dice: 0.3152  decode.d0.loss_cls: 1.2678  decode.d0.loss_mask: 0.3013  decode.d0.loss_dice: 0.3682  decode.d1.loss_cls: 0.2656  decode.d1.loss_mask: 0.3164  decode.d1.loss_dice: 0.3481  decode.d2.loss_cls: 0.2440  decode.d2.loss_mask: 0.3008  decode.d2.loss_dice: 0.3183  decode.d3.loss_cls: 0.1919  decode.d3.loss_mask: 0.3082  decode.d3.loss_dice: 0.3302  decode.d4.loss_cls: 0.2221  decode.d4.loss_mask: 0.3042  decode.d4.loss_dice: 0.3218  decode.d5.loss_cls: 0.2530  decode.d5.loss_mask: 0.3014  decode.d5.loss_dice: 0.3083  decode.d6.loss_cls: 0.1870  decode.d6.loss_mask: 0.3042  decode.d6.loss_dice: 0.3108  decode.d7.loss_cls: 0.2107  decode.d7.loss_mask: 0.3038  decode.d7.loss_dice: 0.3289  decode.d8.loss_cls: 0.2337  decode.d8.loss_mask: 0.3127  decode.d8.loss_dice: 0.3331
07/30 00:46:45 - mmengine - INFO - Iter(train) [12350/80000]  base_lr: 8.5993e-05 lr: 8.5993e-06  eta: 9:59:18  time: 0.5320  data_time: 0.0137  memory: 5896  grad_norm: 186.5598  loss: 8.3274  decode.loss_cls: 0.2078  decode.loss_mask: 0.2292  decode.loss_dice: 0.2814  decode.d0.loss_cls: 1.1609  decode.d0.loss_mask: 0.2498  decode.d0.loss_dice: 0.3568  decode.d1.loss_cls: 0.3686  decode.d1.loss_mask: 0.2312  decode.d1.loss_dice: 0.2877  decode.d2.loss_cls: 0.2106  decode.d2.loss_mask: 0.2304  decode.d2.loss_dice: 0.2854  decode.d3.loss_cls: 0.2212  decode.d3.loss_mask: 0.2278  decode.d3.loss_dice: 0.2877  decode.d4.loss_cls: 0.1940  decode.d4.loss_mask: 0.2270  decode.d4.loss_dice: 0.2858  decode.d5.loss_cls: 0.1876  decode.d5.loss_mask: 0.2296  decode.d5.loss_dice: 0.2826  decode.d6.loss_cls: 0.1803  decode.d6.loss_mask: 0.2271  decode.d6.loss_dice: 0.2659  decode.d7.loss_cls: 0.1762  decode.d7.loss_mask: 0.2318  decode.d7.loss_dice: 0.2729  decode.d8.loss_cls: 0.2171  decode.d8.loss_mask: 0.2269  decode.d8.loss_dice: 0.2860
07/30 00:47:12 - mmengine - INFO - Iter(train) [12400/80000]  base_lr: 8.5936e-05 lr: 8.5936e-06  eta: 9:58:51  time: 0.5309  data_time: 0.0135  memory: 5918  grad_norm: 103.4920  loss: 8.1934  decode.loss_cls: 0.1418  decode.loss_mask: 0.2724  decode.loss_dice: 0.3119  decode.d0.loss_cls: 0.8897  decode.d0.loss_mask: 0.2758  decode.d0.loss_dice: 0.3061  decode.d1.loss_cls: 0.2097  decode.d1.loss_mask: 0.2780  decode.d1.loss_dice: 0.3073  decode.d2.loss_cls: 0.2137  decode.d2.loss_mask: 0.2747  decode.d2.loss_dice: 0.3001  decode.d3.loss_cls: 0.1673  decode.d3.loss_mask: 0.2772  decode.d3.loss_dice: 0.3231  decode.d4.loss_cls: 0.1571  decode.d4.loss_mask: 0.2739  decode.d4.loss_dice: 0.3032  decode.d5.loss_cls: 0.1376  decode.d5.loss_mask: 0.2729  decode.d5.loss_dice: 0.3378  decode.d6.loss_cls: 0.1351  decode.d6.loss_mask: 0.2701  decode.d6.loss_dice: 0.2982  decode.d7.loss_cls: 0.1243  decode.d7.loss_mask: 0.2727  decode.d7.loss_dice: 0.3094  decode.d8.loss_cls: 0.1806  decode.d8.loss_mask: 0.2731  decode.d8.loss_dice: 0.2984
07/30 00:47:38 - mmengine - INFO - Iter(train) [12450/80000]  base_lr: 8.5879e-05 lr: 8.5879e-06  eta: 9:58:23  time: 0.5273  data_time: 0.0130  memory: 5932  grad_norm: 257.7662  loss: 10.0805  decode.loss_cls: 0.2756  decode.loss_mask: 0.2426  decode.loss_dice: 0.3321  decode.d0.loss_cls: 1.1027  decode.d0.loss_mask: 0.2615  decode.d0.loss_dice: 0.4130  decode.d1.loss_cls: 0.4225  decode.d1.loss_mask: 0.2540  decode.d1.loss_dice: 0.3726  decode.d2.loss_cls: 0.3274  decode.d2.loss_mask: 0.2539  decode.d2.loss_dice: 0.3624  decode.d3.loss_cls: 0.3822  decode.d3.loss_mask: 0.2450  decode.d3.loss_dice: 0.3613  decode.d4.loss_cls: 0.3163  decode.d4.loss_mask: 0.2504  decode.d4.loss_dice: 0.3611  decode.d5.loss_cls: 0.2723  decode.d5.loss_mask: 0.2390  decode.d5.loss_dice: 0.3458  decode.d6.loss_cls: 0.2810  decode.d6.loss_mask: 0.2445  decode.d6.loss_dice: 0.3519  decode.d7.loss_cls: 0.3187  decode.d7.loss_mask: 0.2491  decode.d7.loss_dice: 0.3725  decode.d8.loss_cls: 0.2778  decode.d8.loss_mask: 0.2441  decode.d8.loss_dice: 0.3469
07/30 00:48:05 - mmengine - INFO - Iter(train) [12500/80000]  base_lr: 8.5822e-05 lr: 8.5822e-06  eta: 9:57:57  time: 0.5345  data_time: 0.0134  memory: 5919  grad_norm: 93.8886  loss: 10.1935  decode.loss_cls: 0.2806  decode.loss_mask: 0.2677  decode.loss_dice: 0.3542  decode.d0.loss_cls: 1.2207  decode.d0.loss_mask: 0.2697  decode.d0.loss_dice: 0.3648  decode.d1.loss_cls: 0.3708  decode.d1.loss_mask: 0.2700  decode.d1.loss_dice: 0.3707  decode.d2.loss_cls: 0.3228  decode.d2.loss_mask: 0.2637  decode.d2.loss_dice: 0.3478  decode.d3.loss_cls: 0.2870  decode.d3.loss_mask: 0.2657  decode.d3.loss_dice: 0.3437  decode.d4.loss_cls: 0.3079  decode.d4.loss_mask: 0.2628  decode.d4.loss_dice: 0.3360  decode.d5.loss_cls: 0.3520  decode.d5.loss_mask: 0.2670  decode.d5.loss_dice: 0.3442  decode.d6.loss_cls: 0.3280  decode.d6.loss_mask: 0.2619  decode.d6.loss_dice: 0.3348  decode.d7.loss_cls: 0.2876  decode.d7.loss_mask: 0.2635  decode.d7.loss_dice: 0.3452  decode.d8.loss_cls: 0.2971  decode.d8.loss_mask: 0.2603  decode.d8.loss_dice: 0.3452
07/30 00:48:32 - mmengine - INFO - Iter(train) [12550/80000]  base_lr: 8.5765e-05 lr: 8.5765e-06  eta: 9:57:32  time: 0.5351  data_time: 0.0133  memory: 5932  grad_norm: 671.1805  loss: 10.0158  decode.loss_cls: 0.1672  decode.loss_mask: 0.3678  decode.loss_dice: 0.3237  decode.d0.loss_cls: 1.1544  decode.d0.loss_mask: 0.3838  decode.d0.loss_dice: 0.3227  decode.d1.loss_cls: 0.2202  decode.d1.loss_mask: 0.4194  decode.d1.loss_dice: 0.3301  decode.d2.loss_cls: 0.2573  decode.d2.loss_mask: 0.4090  decode.d2.loss_dice: 0.3143  decode.d3.loss_cls: 0.1703  decode.d3.loss_mask: 0.4178  decode.d3.loss_dice: 0.3031  decode.d4.loss_cls: 0.1677  decode.d4.loss_mask: 0.4103  decode.d4.loss_dice: 0.3039  decode.d5.loss_cls: 0.2004  decode.d5.loss_mask: 0.4030  decode.d5.loss_dice: 0.3046  decode.d6.loss_cls: 0.1953  decode.d6.loss_mask: 0.3859  decode.d6.loss_dice: 0.2978  decode.d7.loss_cls: 0.1779  decode.d7.loss_mask: 0.3784  decode.d7.loss_dice: 0.3097  decode.d8.loss_cls: 0.2237  decode.d8.loss_mask: 0.3865  decode.d8.loss_dice: 0.3093
07/30 00:48:58 - mmengine - INFO - Iter(train) [12600/80000]  base_lr: 8.5707e-05 lr: 8.5707e-06  eta: 9:57:05  time: 0.5376  data_time: 0.0138  memory: 5916  grad_norm: 185.3891  loss: 11.4072  decode.loss_cls: 0.4105  decode.loss_mask: 0.2860  decode.loss_dice: 0.3560  decode.d0.loss_cls: 1.1635  decode.d0.loss_mask: 0.3072  decode.d0.loss_dice: 0.3902  decode.d1.loss_cls: 0.4733  decode.d1.loss_mask: 0.2969  decode.d1.loss_dice: 0.3642  decode.d2.loss_cls: 0.3427  decode.d2.loss_mask: 0.2887  decode.d2.loss_dice: 0.3557  decode.d3.loss_cls: 0.4159  decode.d3.loss_mask: 0.2849  decode.d3.loss_dice: 0.3493  decode.d4.loss_cls: 0.4006  decode.d4.loss_mask: 0.2874  decode.d4.loss_dice: 0.3483  decode.d5.loss_cls: 0.5543  decode.d5.loss_mask: 0.2825  decode.d5.loss_dice: 0.3245  decode.d6.loss_cls: 0.4291  decode.d6.loss_mask: 0.2825  decode.d6.loss_dice: 0.3205  decode.d7.loss_cls: 0.3964  decode.d7.loss_mask: 0.2791  decode.d7.loss_dice: 0.3324  decode.d8.loss_cls: 0.4757  decode.d8.loss_mask: 0.2808  decode.d8.loss_dice: 0.3280
07/30 00:49:25 - mmengine - INFO - Iter(train) [12650/80000]  base_lr: 8.5650e-05 lr: 8.5650e-06  eta: 9:56:38  time: 0.5242  data_time: 0.0132  memory: 5900  grad_norm: 79.3894  loss: 6.6238  decode.loss_cls: 0.0699  decode.loss_mask: 0.2426  decode.loss_dice: 0.2547  decode.d0.loss_cls: 0.9185  decode.d0.loss_mask: 0.2526  decode.d0.loss_dice: 0.2536  decode.d1.loss_cls: 0.0989  decode.d1.loss_mask: 0.2458  decode.d1.loss_dice: 0.2587  decode.d2.loss_cls: 0.1262  decode.d2.loss_mask: 0.2395  decode.d2.loss_dice: 0.2433  decode.d3.loss_cls: 0.1068  decode.d3.loss_mask: 0.2402  decode.d3.loss_dice: 0.2484  decode.d4.loss_cls: 0.0900  decode.d4.loss_mask: 0.2362  decode.d4.loss_dice: 0.2416  decode.d5.loss_cls: 0.0644  decode.d5.loss_mask: 0.2424  decode.d5.loss_dice: 0.2621  decode.d6.loss_cls: 0.0682  decode.d6.loss_mask: 0.2422  decode.d6.loss_dice: 0.2488  decode.d7.loss_cls: 0.0804  decode.d7.loss_mask: 0.2375  decode.d7.loss_dice: 0.2384  decode.d8.loss_cls: 0.0725  decode.d8.loss_mask: 0.2388  decode.d8.loss_dice: 0.2605
07/30 00:49:51 - mmengine - INFO - Iter(train) [12700/80000]  base_lr: 8.5593e-05 lr: 8.5593e-06  eta: 9:56:11  time: 0.5311  data_time: 0.0132  memory: 5918  grad_norm: 69.9028  loss: 7.8965  decode.loss_cls: 0.1779  decode.loss_mask: 0.2607  decode.loss_dice: 0.2736  decode.d0.loss_cls: 1.0737  decode.d0.loss_mask: 0.2697  decode.d0.loss_dice: 0.3010  decode.d1.loss_cls: 0.2182  decode.d1.loss_mask: 0.2598  decode.d1.loss_dice: 0.2861  decode.d2.loss_cls: 0.1737  decode.d2.loss_mask: 0.2634  decode.d2.loss_dice: 0.2857  decode.d3.loss_cls: 0.1358  decode.d3.loss_mask: 0.2597  decode.d3.loss_dice: 0.2722  decode.d4.loss_cls: 0.1490  decode.d4.loss_mask: 0.2649  decode.d4.loss_dice: 0.2712  decode.d5.loss_cls: 0.1327  decode.d5.loss_mask: 0.2607  decode.d5.loss_dice: 0.2826  decode.d6.loss_cls: 0.1246  decode.d6.loss_mask: 0.2529  decode.d6.loss_dice: 0.2715  decode.d7.loss_cls: 0.1409  decode.d7.loss_mask: 0.2593  decode.d7.loss_dice: 0.2776  decode.d8.loss_cls: 0.1630  decode.d8.loss_mask: 0.2616  decode.d8.loss_dice: 0.2729
07/30 00:50:17 - mmengine - INFO - Iter(train) [12750/80000]  base_lr: 8.5536e-05 lr: 8.5536e-06  eta: 9:55:43  time: 0.5272  data_time: 0.0129  memory: 5918  grad_norm: 175.4325  loss: 9.4400  decode.loss_cls: 0.3362  decode.loss_mask: 0.2993  decode.loss_dice: 0.3329  decode.d0.loss_cls: 1.0738  decode.d0.loss_mask: 0.2776  decode.d0.loss_dice: 0.3419  decode.d1.loss_cls: 0.2487  decode.d1.loss_mask: 0.2591  decode.d1.loss_dice: 0.3208  decode.d2.loss_cls: 0.2735  decode.d2.loss_mask: 0.2537  decode.d2.loss_dice: 0.3084  decode.d3.loss_cls: 0.2043  decode.d3.loss_mask: 0.2714  decode.d3.loss_dice: 0.3056  decode.d4.loss_cls: 0.2212  decode.d4.loss_mask: 0.2635  decode.d4.loss_dice: 0.3261  decode.d5.loss_cls: 0.2143  decode.d5.loss_mask: 0.2828  decode.d5.loss_dice: 0.3369  decode.d6.loss_cls: 0.2548  decode.d6.loss_mask: 0.2690  decode.d6.loss_dice: 0.3345  decode.d7.loss_cls: 0.2782  decode.d7.loss_mask: 0.2817  decode.d7.loss_dice: 0.3184  decode.d8.loss_cls: 0.3268  decode.d8.loss_mask: 0.2805  decode.d8.loss_dice: 0.3441
07/30 00:50:44 - mmengine - INFO - Iter(train) [12800/80000]  base_lr: 8.5478e-05 lr: 8.5478e-06  eta: 9:55:15  time: 0.5238  data_time: 0.0132  memory: 5933  grad_norm: 143.5123  loss: 10.5102  decode.loss_cls: 0.3184  decode.loss_mask: 0.2921  decode.loss_dice: 0.3409  decode.d0.loss_cls: 1.1454  decode.d0.loss_mask: 0.2893  decode.d0.loss_dice: 0.3719  decode.d1.loss_cls: 0.3845  decode.d1.loss_mask: 0.2908  decode.d1.loss_dice: 0.3648  decode.d2.loss_cls: 0.2817  decode.d2.loss_mask: 0.2895  decode.d2.loss_dice: 0.3602  decode.d3.loss_cls: 0.3232  decode.d3.loss_mask: 0.2828  decode.d3.loss_dice: 0.3439  decode.d4.loss_cls: 0.3026  decode.d4.loss_mask: 0.2880  decode.d4.loss_dice: 0.3598  decode.d5.loss_cls: 0.3166  decode.d5.loss_mask: 0.3033  decode.d5.loss_dice: 0.3624  decode.d6.loss_cls: 0.3404  decode.d6.loss_mask: 0.2871  decode.d6.loss_dice: 0.3440  decode.d7.loss_cls: 0.2937  decode.d7.loss_mask: 0.2937  decode.d7.loss_dice: 0.3475  decode.d8.loss_cls: 0.3439  decode.d8.loss_mask: 0.2958  decode.d8.loss_dice: 0.3519
07/30 00:51:10 - mmengine - INFO - Iter(train) [12850/80000]  base_lr: 8.5421e-05 lr: 8.5421e-06  eta: 9:54:48  time: 0.5293  data_time: 0.0134  memory: 5919  grad_norm: 142.2658  loss: 8.8147  decode.loss_cls: 0.2413  decode.loss_mask: 0.2324  decode.loss_dice: 0.3570  decode.d0.loss_cls: 1.0409  decode.d0.loss_mask: 0.2455  decode.d0.loss_dice: 0.3874  decode.d1.loss_cls: 0.2097  decode.d1.loss_mask: 0.2331  decode.d1.loss_dice: 0.3369  decode.d2.loss_cls: 0.2311  decode.d2.loss_mask: 0.2273  decode.d2.loss_dice: 0.3318  decode.d3.loss_cls: 0.3059  decode.d3.loss_mask: 0.2264  decode.d3.loss_dice: 0.3450  decode.d4.loss_cls: 0.1741  decode.d4.loss_mask: 0.2271  decode.d4.loss_dice: 0.3315  decode.d5.loss_cls: 0.1616  decode.d5.loss_mask: 0.2302  decode.d5.loss_dice: 0.3589  decode.d6.loss_cls: 0.1945  decode.d6.loss_mask: 0.2311  decode.d6.loss_dice: 0.3366  decode.d7.loss_cls: 0.2065  decode.d7.loss_mask: 0.2428  decode.d7.loss_dice: 0.3467  decode.d8.loss_cls: 0.2586  decode.d8.loss_mask: 0.2370  decode.d8.loss_dice: 0.3258
07/30 00:51:37 - mmengine - INFO - Iter(train) [12900/80000]  base_lr: 8.5364e-05 lr: 8.5364e-06  eta: 9:54:22  time: 0.5334  data_time: 0.0137  memory: 5916  grad_norm: 126.5444  loss: 7.1851  decode.loss_cls: 0.1079  decode.loss_mask: 0.2639  decode.loss_dice: 0.2591  decode.d0.loss_cls: 0.9387  decode.d0.loss_mask: 0.2754  decode.d0.loss_dice: 0.3004  decode.d1.loss_cls: 0.1082  decode.d1.loss_mask: 0.2722  decode.d1.loss_dice: 0.2738  decode.d2.loss_cls: 0.1135  decode.d2.loss_mask: 0.2632  decode.d2.loss_dice: 0.2571  decode.d3.loss_cls: 0.0926  decode.d3.loss_mask: 0.2636  decode.d3.loss_dice: 0.2598  decode.d4.loss_cls: 0.1077  decode.d4.loss_mask: 0.2688  decode.d4.loss_dice: 0.2519  decode.d5.loss_cls: 0.1136  decode.d5.loss_mask: 0.2639  decode.d5.loss_dice: 0.2539  decode.d6.loss_cls: 0.1007  decode.d6.loss_mask: 0.2643  decode.d6.loss_dice: 0.2544  decode.d7.loss_cls: 0.1079  decode.d7.loss_mask: 0.2665  decode.d7.loss_dice: 0.2492  decode.d8.loss_cls: 0.1159  decode.d8.loss_mask: 0.2661  decode.d8.loss_dice: 0.2507
07/30 00:52:04 - mmengine - INFO - Iter(train) [12950/80000]  base_lr: 8.5307e-05 lr: 8.5307e-06  eta: 9:53:56  time: 0.5382  data_time: 0.0139  memory: 5896  grad_norm: 104.6933  loss: 9.5300  decode.loss_cls: 0.3751  decode.loss_mask: 0.2388  decode.loss_dice: 0.2810  decode.d0.loss_cls: 1.1527  decode.d0.loss_mask: 0.2453  decode.d0.loss_dice: 0.2968  decode.d1.loss_cls: 0.3507  decode.d1.loss_mask: 0.2420  decode.d1.loss_dice: 0.2825  decode.d2.loss_cls: 0.3947  decode.d2.loss_mask: 0.2417  decode.d2.loss_dice: 0.2973  decode.d3.loss_cls: 0.2825  decode.d3.loss_mask: 0.2415  decode.d3.loss_dice: 0.2649  decode.d4.loss_cls: 0.3239  decode.d4.loss_mask: 0.2440  decode.d4.loss_dice: 0.2992  decode.d5.loss_cls: 0.3182  decode.d5.loss_mask: 0.2489  decode.d5.loss_dice: 0.2913  decode.d6.loss_cls: 0.3266  decode.d6.loss_mask: 0.2465  decode.d6.loss_dice: 0.2737  decode.d7.loss_cls: 0.3354  decode.d7.loss_mask: 0.2489  decode.d7.loss_dice: 0.2857  decode.d8.loss_cls: 0.3663  decode.d8.loss_mask: 0.2456  decode.d8.loss_dice: 0.2884
07/30 00:52:30 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/30 00:52:30 - mmengine - INFO - Iter(train) [13000/80000]  base_lr: 8.5249e-05 lr: 8.5249e-06  eta: 9:53:30  time: 0.5322  data_time: 0.0134  memory: 5971  grad_norm: 83.1404  loss: 8.0912  decode.loss_cls: 0.2562  decode.loss_mask: 0.1975  decode.loss_dice: 0.2546  decode.d0.loss_cls: 1.1012  decode.d0.loss_mask: 0.2062  decode.d0.loss_dice: 0.2937  decode.d1.loss_cls: 0.3375  decode.d1.loss_mask: 0.2014  decode.d1.loss_dice: 0.2716  decode.d2.loss_cls: 0.3093  decode.d2.loss_mask: 0.1989  decode.d2.loss_dice: 0.2586  decode.d3.loss_cls: 0.2145  decode.d3.loss_mask: 0.2002  decode.d3.loss_dice: 0.2670  decode.d4.loss_cls: 0.2027  decode.d4.loss_mask: 0.1996  decode.d4.loss_dice: 0.2421  decode.d5.loss_cls: 0.2376  decode.d5.loss_mask: 0.1990  decode.d5.loss_dice: 0.2558  decode.d6.loss_cls: 0.2784  decode.d6.loss_mask: 0.1969  decode.d6.loss_dice: 0.2622  decode.d7.loss_cls: 0.2703  decode.d7.loss_mask: 0.2020  decode.d7.loss_dice: 0.2592  decode.d8.loss_cls: 0.2344  decode.d8.loss_mask: 0.1993  decode.d8.loss_dice: 0.2830
07/30 00:52:57 - mmengine - INFO - Iter(train) [13050/80000]  base_lr: 8.5192e-05 lr: 8.5192e-06  eta: 9:53:04  time: 0.5364  data_time: 0.0136  memory: 5933  grad_norm: 120.1992  loss: 8.4857  decode.loss_cls: 0.2010  decode.loss_mask: 0.2769  decode.loss_dice: 0.2747  decode.d0.loss_cls: 0.9030  decode.d0.loss_mask: 0.2802  decode.d0.loss_dice: 0.3442  decode.d1.loss_cls: 0.2520  decode.d1.loss_mask: 0.2728  decode.d1.loss_dice: 0.2750  decode.d2.loss_cls: 0.2671  decode.d2.loss_mask: 0.2699  decode.d2.loss_dice: 0.2836  decode.d3.loss_cls: 0.2419  decode.d3.loss_mask: 0.2750  decode.d3.loss_dice: 0.2760  decode.d4.loss_cls: 0.2078  decode.d4.loss_mask: 0.2798  decode.d4.loss_dice: 0.2609  decode.d5.loss_cls: 0.1949  decode.d5.loss_mask: 0.2849  decode.d5.loss_dice: 0.2733  decode.d6.loss_cls: 0.2004  decode.d6.loss_mask: 0.2807  decode.d6.loss_dice: 0.2625  decode.d7.loss_cls: 0.2141  decode.d7.loss_mask: 0.2779  decode.d7.loss_dice: 0.2716  decode.d8.loss_cls: 0.2115  decode.d8.loss_mask: 0.2837  decode.d8.loss_dice: 0.2885
07/30 00:53:24 - mmengine - INFO - Iter(train) [13100/80000]  base_lr: 8.5135e-05 lr: 8.5135e-06  eta: 9:52:37  time: 0.5372  data_time: 0.0133  memory: 5975  grad_norm: 91.9560  loss: 9.5211  decode.loss_cls: 0.2317  decode.loss_mask: 0.2671  decode.loss_dice: 0.3378  decode.d0.loss_cls: 1.0491  decode.d0.loss_mask: 0.2786  decode.d0.loss_dice: 0.3549  decode.d1.loss_cls: 0.2748  decode.d1.loss_mask: 0.2570  decode.d1.loss_dice: 0.3386  decode.d2.loss_cls: 0.2645  decode.d2.loss_mask: 0.2551  decode.d2.loss_dice: 0.3303  decode.d3.loss_cls: 0.2957  decode.d3.loss_mask: 0.2557  decode.d3.loss_dice: 0.3278  decode.d4.loss_cls: 0.2837  decode.d4.loss_mask: 0.2659  decode.d4.loss_dice: 0.3280  decode.d5.loss_cls: 0.2853  decode.d5.loss_mask: 0.2670  decode.d5.loss_dice: 0.3300  decode.d6.loss_cls: 0.2727  decode.d6.loss_mask: 0.2593  decode.d6.loss_dice: 0.3260  decode.d7.loss_cls: 0.2510  decode.d7.loss_mask: 0.2658  decode.d7.loss_dice: 0.3399  decode.d8.loss_cls: 0.2956  decode.d8.loss_mask: 0.2761  decode.d8.loss_dice: 0.3562
07/30 00:53:50 - mmengine - INFO - Iter(train) [13150/80000]  base_lr: 8.5078e-05 lr: 8.5078e-06  eta: 9:52:11  time: 0.5284  data_time: 0.0131  memory: 5881  grad_norm: 89.5475  loss: 9.1990  decode.loss_cls: 0.3759  decode.loss_mask: 0.2493  decode.loss_dice: 0.2654  decode.d0.loss_cls: 0.9537  decode.d0.loss_mask: 0.2638  decode.d0.loss_dice: 0.2808  decode.d1.loss_cls: 0.3215  decode.d1.loss_mask: 0.2541  decode.d1.loss_dice: 0.2672  decode.d2.loss_cls: 0.3465  decode.d2.loss_mask: 0.2537  decode.d2.loss_dice: 0.2755  decode.d3.loss_cls: 0.2925  decode.d3.loss_mask: 0.2520  decode.d3.loss_dice: 0.2718  decode.d4.loss_cls: 0.2977  decode.d4.loss_mask: 0.2519  decode.d4.loss_dice: 0.2816  decode.d5.loss_cls: 0.3501  decode.d5.loss_mask: 0.2493  decode.d5.loss_dice: 0.2728  decode.d6.loss_cls: 0.3226  decode.d6.loss_mask: 0.2512  decode.d6.loss_dice: 0.2699  decode.d7.loss_cls: 0.3251  decode.d7.loss_mask: 0.2503  decode.d7.loss_dice: 0.2707  decode.d8.loss_cls: 0.3554  decode.d8.loss_mask: 0.2573  decode.d8.loss_dice: 0.2694
07/30 00:54:17 - mmengine - INFO - Iter(train) [13200/80000]  base_lr: 8.5020e-05 lr: 8.5020e-06  eta: 9:51:45  time: 0.5312  data_time: 0.0138  memory: 5896  grad_norm: 183.5462  loss: 12.0615  decode.loss_cls: 0.3353  decode.loss_mask: 0.3030  decode.loss_dice: 0.3937  decode.d0.loss_cls: 1.3352  decode.d0.loss_mask: 0.3166  decode.d0.loss_dice: 0.4798  decode.d1.loss_cls: 0.5193  decode.d1.loss_mask: 0.3092  decode.d1.loss_dice: 0.4090  decode.d2.loss_cls: 0.6048  decode.d2.loss_mask: 0.3034  decode.d2.loss_dice: 0.3975  decode.d3.loss_cls: 0.4319  decode.d3.loss_mask: 0.3036  decode.d3.loss_dice: 0.4147  decode.d4.loss_cls: 0.3592  decode.d4.loss_mask: 0.3002  decode.d4.loss_dice: 0.4035  decode.d5.loss_cls: 0.3230  decode.d5.loss_mask: 0.3054  decode.d5.loss_dice: 0.3887  decode.d6.loss_cls: 0.3579  decode.d6.loss_mask: 0.2999  decode.d6.loss_dice: 0.3811  decode.d7.loss_cls: 0.3393  decode.d7.loss_mask: 0.2995  decode.d7.loss_dice: 0.4109  decode.d8.loss_cls: 0.3343  decode.d8.loss_mask: 0.2983  decode.d8.loss_dice: 0.4033
07/30 00:54:43 - mmengine - INFO - Iter(train) [13250/80000]  base_lr: 8.4963e-05 lr: 8.4963e-06  eta: 9:51:17  time: 0.5266  data_time: 0.0133  memory: 5918  grad_norm: 165.2136  loss: 7.5242  decode.loss_cls: 0.1983  decode.loss_mask: 0.2015  decode.loss_dice: 0.2395  decode.d0.loss_cls: 1.1413  decode.d0.loss_mask: 0.1968  decode.d0.loss_dice: 0.2531  decode.d1.loss_cls: 0.2869  decode.d1.loss_mask: 0.2052  decode.d1.loss_dice: 0.2372  decode.d2.loss_cls: 0.2133  decode.d2.loss_mask: 0.1982  decode.d2.loss_dice: 0.2525  decode.d3.loss_cls: 0.2249  decode.d3.loss_mask: 0.1896  decode.d3.loss_dice: 0.2390  decode.d4.loss_cls: 0.1415  decode.d4.loss_mask: 0.2022  decode.d4.loss_dice: 0.2469  decode.d5.loss_cls: 0.1696  decode.d5.loss_mask: 0.2034  decode.d5.loss_dice: 0.2518  decode.d6.loss_cls: 0.1889  decode.d6.loss_mask: 0.1976  decode.d6.loss_dice: 0.2317  decode.d7.loss_cls: 0.2181  decode.d7.loss_mask: 0.2045  decode.d7.loss_dice: 0.2582  decode.d8.loss_cls: 0.2575  decode.d8.loss_mask: 0.2073  decode.d8.loss_dice: 0.2678
07/30 00:55:10 - mmengine - INFO - Iter(train) [13300/80000]  base_lr: 8.4906e-05 lr: 8.4906e-06  eta: 9:50:50  time: 0.5290  data_time: 0.0134  memory: 5916  grad_norm: 204.7930  loss: 10.0804  decode.loss_cls: 0.1939  decode.loss_mask: 0.3539  decode.loss_dice: 0.3595  decode.d0.loss_cls: 1.1275  decode.d0.loss_mask: 0.3713  decode.d0.loss_dice: 0.3820  decode.d1.loss_cls: 0.3244  decode.d1.loss_mask: 0.3558  decode.d1.loss_dice: 0.3592  decode.d2.loss_cls: 0.2222  decode.d2.loss_mask: 0.3563  decode.d2.loss_dice: 0.3713  decode.d3.loss_cls: 0.2128  decode.d3.loss_mask: 0.3523  decode.d3.loss_dice: 0.3566  decode.d4.loss_cls: 0.2007  decode.d4.loss_mask: 0.3483  decode.d4.loss_dice: 0.3435  decode.d5.loss_cls: 0.1773  decode.d5.loss_mask: 0.3466  decode.d5.loss_dice: 0.3425  decode.d6.loss_cls: 0.1681  decode.d6.loss_mask: 0.3524  decode.d6.loss_dice: 0.3404  decode.d7.loss_cls: 0.1910  decode.d7.loss_mask: 0.3483  decode.d7.loss_dice: 0.3338  decode.d8.loss_cls: 0.1876  decode.d8.loss_mask: 0.3505  decode.d8.loss_dice: 0.3507
07/30 00:55:36 - mmengine - INFO - Iter(train) [13350/80000]  base_lr: 8.4848e-05 lr: 8.4848e-06  eta: 9:50:23  time: 0.5260  data_time: 0.0130  memory: 5971  grad_norm: 94.8831  loss: 8.8493  decode.loss_cls: 0.1036  decode.loss_mask: 0.3233  decode.loss_dice: 0.3139  decode.d0.loss_cls: 1.0189  decode.d0.loss_mask: 0.3351  decode.d0.loss_dice: 0.3201  decode.d1.loss_cls: 0.2471  decode.d1.loss_mask: 0.3294  decode.d1.loss_dice: 0.3289  decode.d2.loss_cls: 0.2205  decode.d2.loss_mask: 0.3299  decode.d2.loss_dice: 0.3141  decode.d3.loss_cls: 0.1529  decode.d3.loss_mask: 0.3303  decode.d3.loss_dice: 0.3163  decode.d4.loss_cls: 0.1891  decode.d4.loss_mask: 0.3302  decode.d4.loss_dice: 0.3201  decode.d5.loss_cls: 0.1478  decode.d5.loss_mask: 0.3266  decode.d5.loss_dice: 0.3188  decode.d6.loss_cls: 0.1191  decode.d6.loss_mask: 0.3257  decode.d6.loss_dice: 0.3139  decode.d7.loss_cls: 0.1120  decode.d7.loss_mask: 0.3264  decode.d7.loss_dice: 0.3138  decode.d8.loss_cls: 0.0949  decode.d8.loss_mask: 0.3237  decode.d8.loss_dice: 0.3029
07/30 00:56:03 - mmengine - INFO - Iter(train) [13400/80000]  base_lr: 8.4791e-05 lr: 8.4791e-06  eta: 9:49:56  time: 0.5289  data_time: 0.0135  memory: 5883  grad_norm: 98.3139  loss: 8.3657  decode.loss_cls: 0.2413  decode.loss_mask: 0.2228  decode.loss_dice: 0.2771  decode.d0.loss_cls: 1.0559  decode.d0.loss_mask: 0.2231  decode.d0.loss_dice: 0.2834  decode.d1.loss_cls: 0.3189  decode.d1.loss_mask: 0.2229  decode.d1.loss_dice: 0.2908  decode.d2.loss_cls: 0.3082  decode.d2.loss_mask: 0.2165  decode.d2.loss_dice: 0.2870  decode.d3.loss_cls: 0.1930  decode.d3.loss_mask: 0.2199  decode.d3.loss_dice: 0.2726  decode.d4.loss_cls: 0.2037  decode.d4.loss_mask: 0.2206  decode.d4.loss_dice: 0.2604  decode.d5.loss_cls: 0.2344  decode.d5.loss_mask: 0.2211  decode.d5.loss_dice: 0.2938  decode.d6.loss_cls: 0.2454  decode.d6.loss_mask: 0.2205  decode.d6.loss_dice: 0.2892  decode.d7.loss_cls: 0.2613  decode.d7.loss_mask: 0.2207  decode.d7.loss_dice: 0.2636  decode.d8.loss_cls: 0.2813  decode.d8.loss_mask: 0.2255  decode.d8.loss_dice: 0.2905
07/30 00:56:29 - mmengine - INFO - Iter(train) [13450/80000]  base_lr: 8.4734e-05 lr: 8.4734e-06  eta: 9:49:28  time: 0.5325  data_time: 0.0138  memory: 5900  grad_norm: 154.8788  loss: 7.7344  decode.loss_cls: 0.2014  decode.loss_mask: 0.2444  decode.loss_dice: 0.2401  decode.d0.loss_cls: 0.9834  decode.d0.loss_mask: 0.2703  decode.d0.loss_dice: 0.2706  decode.d1.loss_cls: 0.2250  decode.d1.loss_mask: 0.2529  decode.d1.loss_dice: 0.2691  decode.d2.loss_cls: 0.1639  decode.d2.loss_mask: 0.2490  decode.d2.loss_dice: 0.2487  decode.d3.loss_cls: 0.2066  decode.d3.loss_mask: 0.2468  decode.d3.loss_dice: 0.2403  decode.d4.loss_cls: 0.1974  decode.d4.loss_mask: 0.2474  decode.d4.loss_dice: 0.2436  decode.d5.loss_cls: 0.2091  decode.d5.loss_mask: 0.2488  decode.d5.loss_dice: 0.2508  decode.d6.loss_cls: 0.1906  decode.d6.loss_mask: 0.2467  decode.d6.loss_dice: 0.2342  decode.d7.loss_cls: 0.1945  decode.d7.loss_mask: 0.2478  decode.d7.loss_dice: 0.2388  decode.d8.loss_cls: 0.1825  decode.d8.loss_mask: 0.2482  decode.d8.loss_dice: 0.2418
07/30 00:56:55 - mmengine - INFO - Iter(train) [13500/80000]  base_lr: 8.4677e-05 lr: 8.4677e-06  eta: 9:49:01  time: 0.5320  data_time: 0.0135  memory: 5931  grad_norm: 157.6001  loss: 8.7872  decode.loss_cls: 0.1884  decode.loss_mask: 0.2790  decode.loss_dice: 0.3319  decode.d0.loss_cls: 1.0924  decode.d0.loss_mask: 0.2933  decode.d0.loss_dice: 0.3549  decode.d1.loss_cls: 0.1977  decode.d1.loss_mask: 0.2850  decode.d1.loss_dice: 0.3387  decode.d2.loss_cls: 0.1858  decode.d2.loss_mask: 0.2839  decode.d2.loss_dice: 0.3263  decode.d3.loss_cls: 0.1552  decode.d3.loss_mask: 0.2808  decode.d3.loss_dice: 0.3310  decode.d4.loss_cls: 0.1453  decode.d4.loss_mask: 0.2798  decode.d4.loss_dice: 0.3283  decode.d5.loss_cls: 0.1446  decode.d5.loss_mask: 0.2809  decode.d5.loss_dice: 0.3375  decode.d6.loss_cls: 0.1523  decode.d6.loss_mask: 0.2848  decode.d6.loss_dice: 0.3255  decode.d7.loss_cls: 0.1875  decode.d7.loss_mask: 0.2829  decode.d7.loss_dice: 0.3293  decode.d8.loss_cls: 0.1636  decode.d8.loss_mask: 0.2802  decode.d8.loss_dice: 0.3404
07/30 00:57:22 - mmengine - INFO - Iter(train) [13550/80000]  base_lr: 8.4619e-05 lr: 8.4619e-06  eta: 9:48:35  time: 0.5298  data_time: 0.0131  memory: 5931  grad_norm: 75.3923  loss: 8.4899  decode.loss_cls: 0.1809  decode.loss_mask: 0.2685  decode.loss_dice: 0.2976  decode.d0.loss_cls: 1.0661  decode.d0.loss_mask: 0.2676  decode.d0.loss_dice: 0.3198  decode.d1.loss_cls: 0.2826  decode.d1.loss_mask: 0.2558  decode.d1.loss_dice: 0.2831  decode.d2.loss_cls: 0.1983  decode.d2.loss_mask: 0.2538  decode.d2.loss_dice: 0.3110  decode.d3.loss_cls: 0.1805  decode.d3.loss_mask: 0.2653  decode.d3.loss_dice: 0.3010  decode.d4.loss_cls: 0.1908  decode.d4.loss_mask: 0.2675  decode.d4.loss_dice: 0.2954  decode.d5.loss_cls: 0.1810  decode.d5.loss_mask: 0.2743  decode.d5.loss_dice: 0.3084  decode.d6.loss_cls: 0.2058  decode.d6.loss_mask: 0.2591  decode.d6.loss_dice: 0.2964  decode.d7.loss_cls: 0.1918  decode.d7.loss_mask: 0.2513  decode.d7.loss_dice: 0.2833  decode.d8.loss_cls: 0.1910  decode.d8.loss_mask: 0.2609  decode.d8.loss_dice: 0.3007
07/30 00:57:49 - mmengine - INFO - Iter(train) [13600/80000]  base_lr: 8.4562e-05 lr: 8.4562e-06  eta: 9:48:09  time: 0.5334  data_time: 0.0138  memory: 5973  grad_norm: 214.4853  loss: 11.7327  decode.loss_cls: 0.3350  decode.loss_mask: 0.3974  decode.loss_dice: 0.3769  decode.d0.loss_cls: 1.1519  decode.d0.loss_mask: 0.4092  decode.d0.loss_dice: 0.4079  decode.d1.loss_cls: 0.4320  decode.d1.loss_mask: 0.4187  decode.d1.loss_dice: 0.3635  decode.d2.loss_cls: 0.2843  decode.d2.loss_mask: 0.4040  decode.d2.loss_dice: 0.3792  decode.d3.loss_cls: 0.2444  decode.d3.loss_mask: 0.4064  decode.d3.loss_dice: 0.3608  decode.d4.loss_cls: 0.2074  decode.d4.loss_mask: 0.4390  decode.d4.loss_dice: 0.3919  decode.d5.loss_cls: 0.2640  decode.d5.loss_mask: 0.4153  decode.d5.loss_dice: 0.4139  decode.d6.loss_cls: 0.2768  decode.d6.loss_mask: 0.3940  decode.d6.loss_dice: 0.3794  decode.d7.loss_cls: 0.3271  decode.d7.loss_mask: 0.3987  decode.d7.loss_dice: 0.3659  decode.d8.loss_cls: 0.3094  decode.d8.loss_mask: 0.3930  decode.d8.loss_dice: 0.3852
07/30 00:58:15 - mmengine - INFO - Iter(train) [13650/80000]  base_lr: 8.4505e-05 lr: 8.4505e-06  eta: 9:47:43  time: 0.5294  data_time: 0.0132  memory: 5898  grad_norm: 141.1112  loss: 7.6422  decode.loss_cls: 0.1647  decode.loss_mask: 0.1938  decode.loss_dice: 0.2691  decode.d0.loss_cls: 1.2473  decode.d0.loss_mask: 0.2003  decode.d0.loss_dice: 0.2953  decode.d1.loss_cls: 0.1836  decode.d1.loss_mask: 0.2189  decode.d1.loss_dice: 0.3055  decode.d2.loss_cls: 0.2326  decode.d2.loss_mask: 0.2202  decode.d2.loss_dice: 0.3180  decode.d3.loss_cls: 0.1231  decode.d3.loss_mask: 0.2343  decode.d3.loss_dice: 0.2838  decode.d4.loss_cls: 0.0537  decode.d4.loss_mask: 0.2405  decode.d4.loss_dice: 0.3017  decode.d5.loss_cls: 0.1022  decode.d5.loss_mask: 0.2309  decode.d5.loss_dice: 0.2971  decode.d6.loss_cls: 0.0682  decode.d6.loss_mask: 0.2383  decode.d6.loss_dice: 0.3144  decode.d7.loss_cls: 0.1354  decode.d7.loss_mask: 0.2277  decode.d7.loss_dice: 0.3003  decode.d8.loss_cls: 0.1604  decode.d8.loss_mask: 0.2045  decode.d8.loss_dice: 0.2764
07/30 00:58:42 - mmengine - INFO - Iter(train) [13700/80000]  base_lr: 8.4447e-05 lr: 8.4447e-06  eta: 9:47:17  time: 0.5349  data_time: 0.0137  memory: 5899  grad_norm: 70.3827  loss: 8.8541  decode.loss_cls: 0.2236  decode.loss_mask: 0.2574  decode.loss_dice: 0.3111  decode.d0.loss_cls: 1.0209  decode.d0.loss_mask: 0.2629  decode.d0.loss_dice: 0.3131  decode.d1.loss_cls: 0.4171  decode.d1.loss_mask: 0.2585  decode.d1.loss_dice: 0.3165  decode.d2.loss_cls: 0.2336  decode.d2.loss_mask: 0.2576  decode.d2.loss_dice: 0.3182  decode.d3.loss_cls: 0.1816  decode.d3.loss_mask: 0.2573  decode.d3.loss_dice: 0.3118  decode.d4.loss_cls: 0.2367  decode.d4.loss_mask: 0.2599  decode.d4.loss_dice: 0.3118  decode.d5.loss_cls: 0.2162  decode.d5.loss_mask: 0.2547  decode.d5.loss_dice: 0.3011  decode.d6.loss_cls: 0.2007  decode.d6.loss_mask: 0.2543  decode.d6.loss_dice: 0.3255  decode.d7.loss_cls: 0.2250  decode.d7.loss_mask: 0.2534  decode.d7.loss_dice: 0.3129  decode.d8.loss_cls: 0.1874  decode.d8.loss_mask: 0.2572  decode.d8.loss_dice: 0.3161
07/30 00:59:09 - mmengine - INFO - Iter(train) [13750/80000]  base_lr: 8.4390e-05 lr: 8.4390e-06  eta: 9:46:50  time: 0.5254  data_time: 0.0131  memory: 5971  grad_norm: 49.8078  loss: 7.9893  decode.loss_cls: 0.1688  decode.loss_mask: 0.2191  decode.loss_dice: 0.2787  decode.d0.loss_cls: 1.1395  decode.d0.loss_mask: 0.2270  decode.d0.loss_dice: 0.2705  decode.d1.loss_cls: 0.2479  decode.d1.loss_mask: 0.2247  decode.d1.loss_dice: 0.2563  decode.d2.loss_cls: 0.2683  decode.d2.loss_mask: 0.2175  decode.d2.loss_dice: 0.2489  decode.d3.loss_cls: 0.1665  decode.d3.loss_mask: 0.2230  decode.d3.loss_dice: 0.2523  decode.d4.loss_cls: 0.2583  decode.d4.loss_mask: 0.2204  decode.d4.loss_dice: 0.2693  decode.d5.loss_cls: 0.1857  decode.d5.loss_mask: 0.2186  decode.d5.loss_dice: 0.2545  decode.d6.loss_cls: 0.1890  decode.d6.loss_mask: 0.2256  decode.d6.loss_dice: 0.2929  decode.d7.loss_cls: 0.2501  decode.d7.loss_mask: 0.2174  decode.d7.loss_dice: 0.2608  decode.d8.loss_cls: 0.2858  decode.d8.loss_mask: 0.2182  decode.d8.loss_dice: 0.2339
07/30 00:59:35 - mmengine - INFO - Iter(train) [13800/80000]  base_lr: 8.4333e-05 lr: 8.4333e-06  eta: 9:46:23  time: 0.5345  data_time: 0.0139  memory: 5920  grad_norm: 205.2547  loss: 8.7578  decode.loss_cls: 0.1623  decode.loss_mask: 0.2910  decode.loss_dice: 0.3267  decode.d0.loss_cls: 1.0396  decode.d0.loss_mask: 0.2945  decode.d0.loss_dice: 0.3841  decode.d1.loss_cls: 0.3027  decode.d1.loss_mask: 0.2904  decode.d1.loss_dice: 0.3237  decode.d2.loss_cls: 0.2245  decode.d2.loss_mask: 0.2858  decode.d2.loss_dice: 0.3286  decode.d3.loss_cls: 0.1879  decode.d3.loss_mask: 0.2782  decode.d3.loss_dice: 0.3231  decode.d4.loss_cls: 0.1747  decode.d4.loss_mask: 0.2803  decode.d4.loss_dice: 0.3203  decode.d5.loss_cls: 0.1565  decode.d5.loss_mask: 0.2813  decode.d5.loss_dice: 0.3231  decode.d6.loss_cls: 0.1357  decode.d6.loss_mask: 0.2763  decode.d6.loss_dice: 0.3156  decode.d7.loss_cls: 0.1166  decode.d7.loss_mask: 0.2775  decode.d7.loss_dice: 0.3061  decode.d8.loss_cls: 0.1490  decode.d8.loss_mask: 0.2790  decode.d8.loss_dice: 0.3228
07/30 01:00:02 - mmengine - INFO - Iter(train) [13850/80000]  base_lr: 8.4275e-05 lr: 8.4275e-06  eta: 9:45:56  time: 0.5328  data_time: 0.0141  memory: 5918  grad_norm: 110.4689  loss: 7.7891  decode.loss_cls: 0.1186  decode.loss_mask: 0.2190  decode.loss_dice: 0.3054  decode.d0.loss_cls: 0.9994  decode.d0.loss_mask: 0.2363  decode.d0.loss_dice: 0.3314  decode.d1.loss_cls: 0.2750  decode.d1.loss_mask: 0.2288  decode.d1.loss_dice: 0.2732  decode.d2.loss_cls: 0.1264  decode.d2.loss_mask: 0.2241  decode.d2.loss_dice: 0.2890  decode.d3.loss_cls: 0.2025  decode.d3.loss_mask: 0.2150  decode.d3.loss_dice: 0.2614  decode.d4.loss_cls: 0.2427  decode.d4.loss_mask: 0.2232  decode.d4.loss_dice: 0.2658  decode.d5.loss_cls: 0.1945  decode.d5.loss_mask: 0.2186  decode.d5.loss_dice: 0.2893  decode.d6.loss_cls: 0.1946  decode.d6.loss_mask: 0.2191  decode.d6.loss_dice: 0.2678  decode.d7.loss_cls: 0.1872  decode.d7.loss_mask: 0.2177  decode.d7.loss_dice: 0.3065  decode.d8.loss_cls: 0.1416  decode.d8.loss_mask: 0.2183  decode.d8.loss_dice: 0.2963
07/30 01:00:28 - mmengine - INFO - Iter(train) [13900/80000]  base_lr: 8.4218e-05 lr: 8.4218e-06  eta: 9:45:29  time: 0.5301  data_time: 0.0133  memory: 5918  grad_norm: 143.2784  loss: 9.5380  decode.loss_cls: 0.3054  decode.loss_mask: 0.2438  decode.loss_dice: 0.3165  decode.d0.loss_cls: 1.0976  decode.d0.loss_mask: 0.2610  decode.d0.loss_dice: 0.3431  decode.d1.loss_cls: 0.4241  decode.d1.loss_mask: 0.2561  decode.d1.loss_dice: 0.3440  decode.d2.loss_cls: 0.3128  decode.d2.loss_mask: 0.2460  decode.d2.loss_dice: 0.3237  decode.d3.loss_cls: 0.2939  decode.d3.loss_mask: 0.2439  decode.d3.loss_dice: 0.3024  decode.d4.loss_cls: 0.3049  decode.d4.loss_mask: 0.2405  decode.d4.loss_dice: 0.3093  decode.d5.loss_cls: 0.3007  decode.d5.loss_mask: 0.2463  decode.d5.loss_dice: 0.2976  decode.d6.loss_cls: 0.2920  decode.d6.loss_mask: 0.2454  decode.d6.loss_dice: 0.3001  decode.d7.loss_cls: 0.2181  decode.d7.loss_mask: 0.2627  decode.d7.loss_dice: 0.3220  decode.d8.loss_cls: 0.3163  decode.d8.loss_mask: 0.2484  decode.d8.loss_dice: 0.3193
07/30 01:00:55 - mmengine - INFO - Iter(train) [13950/80000]  base_lr: 8.4161e-05 lr: 8.4161e-06  eta: 9:45:04  time: 0.5308  data_time: 0.0135  memory: 5896  grad_norm: 110.9065  loss: 10.0585  decode.loss_cls: 0.2453  decode.loss_mask: 0.3320  decode.loss_dice: 0.3009  decode.d0.loss_cls: 1.0626  decode.d0.loss_mask: 0.3675  decode.d0.loss_dice: 0.4076  decode.d1.loss_cls: 0.3801  decode.d1.loss_mask: 0.3402  decode.d1.loss_dice: 0.3818  decode.d2.loss_cls: 0.3323  decode.d2.loss_mask: 0.3385  decode.d2.loss_dice: 0.3290  decode.d3.loss_cls: 0.1839  decode.d3.loss_mask: 0.3395  decode.d3.loss_dice: 0.3401  decode.d4.loss_cls: 0.2246  decode.d4.loss_mask: 0.3339  decode.d4.loss_dice: 0.3131  decode.d5.loss_cls: 0.2132  decode.d5.loss_mask: 0.3393  decode.d5.loss_dice: 0.3647  decode.d6.loss_cls: 0.1883  decode.d6.loss_mask: 0.3412  decode.d6.loss_dice: 0.3293  decode.d7.loss_cls: 0.1945  decode.d7.loss_mask: 0.3387  decode.d7.loss_dice: 0.3390  decode.d8.loss_cls: 0.2338  decode.d8.loss_mask: 0.3350  decode.d8.loss_dice: 0.2885
07/30 01:01:22 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/30 01:01:22 - mmengine - INFO - Iter(train) [14000/80000]  base_lr: 8.4103e-05 lr: 8.4103e-06  eta: 9:44:38  time: 0.5330  data_time: 0.0137  memory: 5932  grad_norm: 108.8546  loss: 8.6099  decode.loss_cls: 0.1958  decode.loss_mask: 0.3014  decode.loss_dice: 0.2811  decode.d0.loss_cls: 0.8992  decode.d0.loss_mask: 0.3208  decode.d0.loss_dice: 0.2890  decode.d1.loss_cls: 0.2618  decode.d1.loss_mask: 0.3165  decode.d1.loss_dice: 0.2887  decode.d2.loss_cls: 0.1753  decode.d2.loss_mask: 0.3102  decode.d2.loss_dice: 0.3109  decode.d3.loss_cls: 0.1617  decode.d3.loss_mask: 0.3125  decode.d3.loss_dice: 0.2938  decode.d4.loss_cls: 0.2119  decode.d4.loss_mask: 0.3074  decode.d4.loss_dice: 0.2769  decode.d5.loss_cls: 0.1708  decode.d5.loss_mask: 0.3058  decode.d5.loss_dice: 0.2789  decode.d6.loss_cls: 0.1597  decode.d6.loss_mask: 0.3040  decode.d6.loss_dice: 0.2765  decode.d7.loss_cls: 0.2107  decode.d7.loss_mask: 0.3041  decode.d7.loss_dice: 0.2813  decode.d8.loss_cls: 0.2138  decode.d8.loss_mask: 0.3022  decode.d8.loss_dice: 0.2873
07/30 01:01:48 - mmengine - INFO - Iter(train) [14050/80000]  base_lr: 8.4046e-05 lr: 8.4046e-06  eta: 9:44:11  time: 0.5312  data_time: 0.0130  memory: 5933  grad_norm: 141.0627  loss: 6.5704  decode.loss_cls: 0.0938  decode.loss_mask: 0.2203  decode.loss_dice: 0.2683  decode.d0.loss_cls: 0.8767  decode.d0.loss_mask: 0.2315  decode.d0.loss_dice: 0.2713  decode.d1.loss_cls: 0.1216  decode.d1.loss_mask: 0.2268  decode.d1.loss_dice: 0.2783  decode.d2.loss_cls: 0.1176  decode.d2.loss_mask: 0.2226  decode.d2.loss_dice: 0.2755  decode.d3.loss_cls: 0.1043  decode.d3.loss_mask: 0.2211  decode.d3.loss_dice: 0.2587  decode.d4.loss_cls: 0.0627  decode.d4.loss_mask: 0.2239  decode.d4.loss_dice: 0.2625  decode.d5.loss_cls: 0.0499  decode.d5.loss_mask: 0.2172  decode.d5.loss_dice: 0.2464  decode.d6.loss_cls: 0.1018  decode.d6.loss_mask: 0.2170  decode.d6.loss_dice: 0.2457  decode.d7.loss_cls: 0.1009  decode.d7.loss_mask: 0.2191  decode.d7.loss_dice: 0.2487  decode.d8.loss_cls: 0.1097  decode.d8.loss_mask: 0.2231  decode.d8.loss_dice: 0.2531
07/30 01:02:15 - mmengine - INFO - Iter(train) [14100/80000]  base_lr: 8.3989e-05 lr: 8.3989e-06  eta: 9:43:44  time: 0.5277  data_time: 0.0137  memory: 5897  grad_norm: 106.1166  loss: 9.9911  decode.loss_cls: 0.3499  decode.loss_mask: 0.2940  decode.loss_dice: 0.2881  decode.d0.loss_cls: 1.0391  decode.d0.loss_mask: 0.3017  decode.d0.loss_dice: 0.3065  decode.d1.loss_cls: 0.5117  decode.d1.loss_mask: 0.2849  decode.d1.loss_dice: 0.2729  decode.d2.loss_cls: 0.3121  decode.d2.loss_mask: 0.2891  decode.d2.loss_dice: 0.2600  decode.d3.loss_cls: 0.3390  decode.d3.loss_mask: 0.2887  decode.d3.loss_dice: 0.2767  decode.d4.loss_cls: 0.3842  decode.d4.loss_mask: 0.2901  decode.d4.loss_dice: 0.2788  decode.d5.loss_cls: 0.3999  decode.d5.loss_mask: 0.2868  decode.d5.loss_dice: 0.2652  decode.d6.loss_cls: 0.3499  decode.d6.loss_mask: 0.2893  decode.d6.loss_dice: 0.2558  decode.d7.loss_cls: 0.3431  decode.d7.loss_mask: 0.2881  decode.d7.loss_dice: 0.2688  decode.d8.loss_cls: 0.3112  decode.d8.loss_mask: 0.2925  decode.d8.loss_dice: 0.2729
07/30 01:02:41 - mmengine - INFO - Iter(train) [14150/80000]  base_lr: 8.3931e-05 lr: 8.3931e-06  eta: 9:43:18  time: 0.5338  data_time: 0.0140  memory: 5920  grad_norm: 138.6368  loss: 7.0320  decode.loss_cls: 0.1817  decode.loss_mask: 0.2230  decode.loss_dice: 0.2248  decode.d0.loss_cls: 0.9039  decode.d0.loss_mask: 0.2357  decode.d0.loss_dice: 0.2570  decode.d1.loss_cls: 0.1852  decode.d1.loss_mask: 0.2266  decode.d1.loss_dice: 0.2596  decode.d2.loss_cls: 0.1658  decode.d2.loss_mask: 0.2237  decode.d2.loss_dice: 0.2348  decode.d3.loss_cls: 0.1388  decode.d3.loss_mask: 0.2175  decode.d3.loss_dice: 0.2379  decode.d4.loss_cls: 0.1613  decode.d4.loss_mask: 0.2187  decode.d4.loss_dice: 0.2433  decode.d5.loss_cls: 0.1515  decode.d5.loss_mask: 0.2209  decode.d5.loss_dice: 0.2358  decode.d6.loss_cls: 0.1792  decode.d6.loss_mask: 0.2227  decode.d6.loss_dice: 0.2290  decode.d7.loss_cls: 0.1656  decode.d7.loss_mask: 0.2204  decode.d7.loss_dice: 0.2544  decode.d8.loss_cls: 0.1659  decode.d8.loss_mask: 0.2213  decode.d8.loss_dice: 0.2261
07/30 01:03:08 - mmengine - INFO - Iter(train) [14200/80000]  base_lr: 8.3874e-05 lr: 8.3874e-06  eta: 9:42:51  time: 0.5294  data_time: 0.0134  memory: 5916  grad_norm: 107.0183  loss: 7.0915  decode.loss_cls: 0.1151  decode.loss_mask: 0.2089  decode.loss_dice: 0.2456  decode.d0.loss_cls: 1.1635  decode.d0.loss_mask: 0.2180  decode.d0.loss_dice: 0.2804  decode.d1.loss_cls: 0.1929  decode.d1.loss_mask: 0.2154  decode.d1.loss_dice: 0.2636  decode.d2.loss_cls: 0.2090  decode.d2.loss_mask: 0.2132  decode.d2.loss_dice: 0.2681  decode.d3.loss_cls: 0.1094  decode.d3.loss_mask: 0.2147  decode.d3.loss_dice: 0.2586  decode.d4.loss_cls: 0.1354  decode.d4.loss_mask: 0.2104  decode.d4.loss_dice: 0.2497  decode.d5.loss_cls: 0.1226  decode.d5.loss_mask: 0.2155  decode.d5.loss_dice: 0.2329  decode.d6.loss_cls: 0.1610  decode.d6.loss_mask: 0.2085  decode.d6.loss_dice: 0.2345  decode.d7.loss_cls: 0.1457  decode.d7.loss_mask: 0.2083  decode.d7.loss_dice: 0.2364  decode.d8.loss_cls: 0.0951  decode.d8.loss_mask: 0.2082  decode.d8.loss_dice: 0.2509
07/30 01:03:34 - mmengine - INFO - Iter(train) [14250/80000]  base_lr: 8.3817e-05 lr: 8.3817e-06  eta: 9:42:24  time: 0.5290  data_time: 0.0134  memory: 5896  grad_norm: 208.1643  loss: 11.9066  decode.loss_cls: 0.4588  decode.loss_mask: 0.2573  decode.loss_dice: 0.3442  decode.d0.loss_cls: 1.3018  decode.d0.loss_mask: 0.2486  decode.d0.loss_dice: 0.3688  decode.d1.loss_cls: 0.5620  decode.d1.loss_mask: 0.2714  decode.d1.loss_dice: 0.3882  decode.d2.loss_cls: 0.5589  decode.d2.loss_mask: 0.2648  decode.d2.loss_dice: 0.3675  decode.d3.loss_cls: 0.5246  decode.d3.loss_mask: 0.2561  decode.d3.loss_dice: 0.3228  decode.d4.loss_cls: 0.4826  decode.d4.loss_mask: 0.2444  decode.d4.loss_dice: 0.3564  decode.d5.loss_cls: 0.3954  decode.d5.loss_mask: 0.2670  decode.d5.loss_dice: 0.3629  decode.d6.loss_cls: 0.4529  decode.d6.loss_mask: 0.2670  decode.d6.loss_dice: 0.3569  decode.d7.loss_cls: 0.4889  decode.d7.loss_mask: 0.2623  decode.d7.loss_dice: 0.3504  decode.d8.loss_cls: 0.5209  decode.d8.loss_mask: 0.2462  decode.d8.loss_dice: 0.3566
07/30 01:04:01 - mmengine - INFO - Iter(train) [14300/80000]  base_lr: 8.3759e-05 lr: 8.3759e-06  eta: 9:41:57  time: 0.5271  data_time: 0.0130  memory: 5973  grad_norm: 119.6284  loss: 10.5166  decode.loss_cls: 0.1527  decode.loss_mask: 0.4118  decode.loss_dice: 0.3405  decode.d0.loss_cls: 1.1054  decode.d0.loss_mask: 0.4326  decode.d0.loss_dice: 0.3651  decode.d1.loss_cls: 0.2410  decode.d1.loss_mask: 0.4160  decode.d1.loss_dice: 0.3627  decode.d2.loss_cls: 0.2144  decode.d2.loss_mask: 0.4166  decode.d2.loss_dice: 0.3451  decode.d3.loss_cls: 0.2165  decode.d3.loss_mask: 0.4159  decode.d3.loss_dice: 0.3419  decode.d4.loss_cls: 0.2349  decode.d4.loss_mask: 0.4140  decode.d4.loss_dice: 0.3401  decode.d5.loss_cls: 0.2044  decode.d5.loss_mask: 0.4062  decode.d5.loss_dice: 0.3383  decode.d6.loss_cls: 0.1891  decode.d6.loss_mask: 0.4077  decode.d6.loss_dice: 0.3457  decode.d7.loss_cls: 0.1710  decode.d7.loss_mask: 0.4077  decode.d7.loss_dice: 0.3372  decode.d8.loss_cls: 0.1913  decode.d8.loss_mask: 0.4060  decode.d8.loss_dice: 0.3447
07/30 01:04:27 - mmengine - INFO - Iter(train) [14350/80000]  base_lr: 8.3702e-05 lr: 8.3702e-06  eta: 9:41:30  time: 0.5325  data_time: 0.0135  memory: 5918  grad_norm: 270.9359  loss: 9.5158  decode.loss_cls: 0.2821  decode.loss_mask: 0.3140  decode.loss_dice: 0.2928  decode.d0.loss_cls: 1.1179  decode.d0.loss_mask: 0.3242  decode.d0.loss_dice: 0.3171  decode.d1.loss_cls: 0.2573  decode.d1.loss_mask: 0.2910  decode.d1.loss_dice: 0.2994  decode.d2.loss_cls: 0.2394  decode.d2.loss_mask: 0.2846  decode.d2.loss_dice: 0.3011  decode.d3.loss_cls: 0.2629  decode.d3.loss_mask: 0.2753  decode.d3.loss_dice: 0.2722  decode.d4.loss_cls: 0.2292  decode.d4.loss_mask: 0.3374  decode.d4.loss_dice: 0.2901  decode.d5.loss_cls: 0.3061  decode.d5.loss_mask: 0.2898  decode.d5.loss_dice: 0.2908  decode.d6.loss_cls: 0.2759  decode.d6.loss_mask: 0.2923  decode.d6.loss_dice: 0.2959  decode.d7.loss_cls: 0.2970  decode.d7.loss_mask: 0.3012  decode.d7.loss_dice: 0.2875  decode.d8.loss_cls: 0.3004  decode.d8.loss_mask: 0.2897  decode.d8.loss_dice: 0.3012
07/30 01:04:54 - mmengine - INFO - Iter(train) [14400/80000]  base_lr: 8.3644e-05 lr: 8.3644e-06  eta: 9:41:04  time: 0.5299  data_time: 0.0128  memory: 5898  grad_norm: 112.0698  loss: 8.5800  decode.loss_cls: 0.1437  decode.loss_mask: 0.2593  decode.loss_dice: 0.3093  decode.d0.loss_cls: 1.2159  decode.d0.loss_mask: 0.2671  decode.d0.loss_dice: 0.3004  decode.d1.loss_cls: 0.3620  decode.d1.loss_mask: 0.2603  decode.d1.loss_dice: 0.3357  decode.d2.loss_cls: 0.2166  decode.d2.loss_mask: 0.2722  decode.d2.loss_dice: 0.3366  decode.d3.loss_cls: 0.1777  decode.d3.loss_mask: 0.2596  decode.d3.loss_dice: 0.3088  decode.d4.loss_cls: 0.1574  decode.d4.loss_mask: 0.2623  decode.d4.loss_dice: 0.3029  decode.d5.loss_cls: 0.1515  decode.d5.loss_mask: 0.2568  decode.d5.loss_dice: 0.3108  decode.d6.loss_cls: 0.1522  decode.d6.loss_mask: 0.2573  decode.d6.loss_dice: 0.3094  decode.d7.loss_cls: 0.1223  decode.d7.loss_mask: 0.2606  decode.d7.loss_dice: 0.3179  decode.d8.loss_cls: 0.1237  decode.d8.loss_mask: 0.2622  decode.d8.loss_dice: 0.3074
07/30 01:05:21 - mmengine - INFO - Iter(train) [14450/80000]  base_lr: 8.3587e-05 lr: 8.3587e-06  eta: 9:40:38  time: 0.5291  data_time: 0.0135  memory: 5985  grad_norm: 89.9754  loss: 6.5166  decode.loss_cls: 0.2153  decode.loss_mask: 0.1852  decode.loss_dice: 0.2226  decode.d0.loss_cls: 0.9920  decode.d0.loss_mask: 0.1903  decode.d0.loss_dice: 0.2329  decode.d1.loss_cls: 0.1406  decode.d1.loss_mask: 0.1835  decode.d1.loss_dice: 0.2328  decode.d2.loss_cls: 0.1035  decode.d2.loss_mask: 0.1810  decode.d2.loss_dice: 0.2203  decode.d3.loss_cls: 0.1145  decode.d3.loss_mask: 0.1806  decode.d3.loss_dice: 0.2276  decode.d4.loss_cls: 0.1598  decode.d4.loss_mask: 0.1825  decode.d4.loss_dice: 0.2286  decode.d5.loss_cls: 0.1657  decode.d5.loss_mask: 0.1920  decode.d5.loss_dice: 0.2336  decode.d6.loss_cls: 0.1705  decode.d6.loss_mask: 0.1939  decode.d6.loss_dice: 0.2357  decode.d7.loss_cls: 0.1323  decode.d7.loss_mask: 0.1944  decode.d7.loss_dice: 0.2336  decode.d8.loss_cls: 0.1372  decode.d8.loss_mask: 0.1979  decode.d8.loss_dice: 0.2363
07/30 01:05:47 - mmengine - INFO - Iter(train) [14500/80000]  base_lr: 8.3530e-05 lr: 8.3530e-06  eta: 9:40:11  time: 0.5323  data_time: 0.0137  memory: 5896  grad_norm: 175.6322  loss: 9.2219  decode.loss_cls: 0.2611  decode.loss_mask: 0.2502  decode.loss_dice: 0.2725  decode.d0.loss_cls: 1.0307  decode.d0.loss_mask: 0.2546  decode.d0.loss_dice: 0.3123  decode.d1.loss_cls: 0.4539  decode.d1.loss_mask: 0.2449  decode.d1.loss_dice: 0.3078  decode.d2.loss_cls: 0.3472  decode.d2.loss_mask: 0.2474  decode.d2.loss_dice: 0.2926  decode.d3.loss_cls: 0.3097  decode.d3.loss_mask: 0.2459  decode.d3.loss_dice: 0.2907  decode.d4.loss_cls: 0.2787  decode.d4.loss_mask: 0.2550  decode.d4.loss_dice: 0.3015  decode.d5.loss_cls: 0.2693  decode.d5.loss_mask: 0.2508  decode.d5.loss_dice: 0.2902  decode.d6.loss_cls: 0.2863  decode.d6.loss_mask: 0.2623  decode.d6.loss_dice: 0.3002  decode.d7.loss_cls: 0.2629  decode.d7.loss_mask: 0.2512  decode.d7.loss_dice: 0.2811  decode.d8.loss_cls: 0.2842  decode.d8.loss_mask: 0.2482  decode.d8.loss_dice: 0.2784
07/30 01:06:14 - mmengine - INFO - Iter(train) [14550/80000]  base_lr: 8.3472e-05 lr: 8.3472e-06  eta: 9:39:44  time: 0.5282  data_time: 0.0133  memory: 5937  grad_norm: 73.2216  loss: 7.6624  decode.loss_cls: 0.1033  decode.loss_mask: 0.2361  decode.loss_dice: 0.2773  decode.d0.loss_cls: 1.0480  decode.d0.loss_mask: 0.2411  decode.d0.loss_dice: 0.3273  decode.d1.loss_cls: 0.2324  decode.d1.loss_mask: 0.2412  decode.d1.loss_dice: 0.3144  decode.d2.loss_cls: 0.1428  decode.d2.loss_mask: 0.2342  decode.d2.loss_dice: 0.2974  decode.d3.loss_cls: 0.1454  decode.d3.loss_mask: 0.2370  decode.d3.loss_dice: 0.2918  decode.d4.loss_cls: 0.1678  decode.d4.loss_mask: 0.2336  decode.d4.loss_dice: 0.2955  decode.d5.loss_cls: 0.1392  decode.d5.loss_mask: 0.2375  decode.d5.loss_dice: 0.2908  decode.d6.loss_cls: 0.1395  decode.d6.loss_mask: 0.2364  decode.d6.loss_dice: 0.2765  decode.d7.loss_cls: 0.1039  decode.d7.loss_mask: 0.2390  decode.d7.loss_dice: 0.2926  decode.d8.loss_cls: 0.1103  decode.d8.loss_mask: 0.2424  decode.d8.loss_dice: 0.2878
07/30 01:06:40 - mmengine - INFO - Iter(train) [14600/80000]  base_lr: 8.3415e-05 lr: 8.3415e-06  eta: 9:39:17  time: 0.5282  data_time: 0.0136  memory: 5986  grad_norm: 155.6590  loss: 9.8525  decode.loss_cls: 0.3064  decode.loss_mask: 0.2866  decode.loss_dice: 0.3145  decode.d0.loss_cls: 1.1024  decode.d0.loss_mask: 0.2784  decode.d0.loss_dice: 0.3476  decode.d1.loss_cls: 0.3829  decode.d1.loss_mask: 0.2787  decode.d1.loss_dice: 0.2945  decode.d2.loss_cls: 0.3034  decode.d2.loss_mask: 0.2856  decode.d2.loss_dice: 0.2901  decode.d3.loss_cls: 0.2426  decode.d3.loss_mask: 0.2837  decode.d3.loss_dice: 0.3135  decode.d4.loss_cls: 0.2831  decode.d4.loss_mask: 0.2856  decode.d4.loss_dice: 0.3072  decode.d5.loss_cls: 0.2590  decode.d5.loss_mask: 0.2892  decode.d5.loss_dice: 0.3261  decode.d6.loss_cls: 0.2865  decode.d6.loss_mask: 0.2795  decode.d6.loss_dice: 0.3078  decode.d7.loss_cls: 0.3165  decode.d7.loss_mask: 0.2818  decode.d7.loss_dice: 0.3161  decode.d8.loss_cls: 0.3912  decode.d8.loss_mask: 0.2845  decode.d8.loss_dice: 0.3278
07/30 01:07:07 - mmengine - INFO - Iter(train) [14650/80000]  base_lr: 8.3358e-05 lr: 8.3358e-06  eta: 9:38:50  time: 0.5317  data_time: 0.0136  memory: 5931  grad_norm: 121.6761  loss: 10.2013  decode.loss_cls: 0.2609  decode.loss_mask: 0.2640  decode.loss_dice: 0.3362  decode.d0.loss_cls: 1.3070  decode.d0.loss_mask: 0.2572  decode.d0.loss_dice: 0.3087  decode.d1.loss_cls: 0.3970  decode.d1.loss_mask: 0.2547  decode.d1.loss_dice: 0.3131  decode.d2.loss_cls: 0.4771  decode.d2.loss_mask: 0.2567  decode.d2.loss_dice: 0.3020  decode.d3.loss_cls: 0.4098  decode.d3.loss_mask: 0.2654  decode.d3.loss_dice: 0.3080  decode.d4.loss_cls: 0.3514  decode.d4.loss_mask: 0.2656  decode.d4.loss_dice: 0.2958  decode.d5.loss_cls: 0.3233  decode.d5.loss_mask: 0.2579  decode.d5.loss_dice: 0.3016  decode.d6.loss_cls: 0.3333  decode.d6.loss_mask: 0.2578  decode.d6.loss_dice: 0.2995  decode.d7.loss_cls: 0.3168  decode.d7.loss_mask: 0.2609  decode.d7.loss_dice: 0.3248  decode.d8.loss_cls: 0.2995  decode.d8.loss_mask: 0.2630  decode.d8.loss_dice: 0.3322
07/30 01:07:33 - mmengine - INFO - Iter(train) [14700/80000]  base_lr: 8.3300e-05 lr: 8.3300e-06  eta: 9:38:23  time: 0.5290  data_time: 0.0137  memory: 5971  grad_norm: 167.6504  loss: 10.5189  decode.loss_cls: 0.2473  decode.loss_mask: 0.3401  decode.loss_dice: 0.3590  decode.d0.loss_cls: 1.2047  decode.d0.loss_mask: 0.3418  decode.d0.loss_dice: 0.3703  decode.d1.loss_cls: 0.4633  decode.d1.loss_mask: 0.3365  decode.d1.loss_dice: 0.3552  decode.d2.loss_cls: 0.3177  decode.d2.loss_mask: 0.3314  decode.d2.loss_dice: 0.3458  decode.d3.loss_cls: 0.2547  decode.d3.loss_mask: 0.3343  decode.d3.loss_dice: 0.3383  decode.d4.loss_cls: 0.2436  decode.d4.loss_mask: 0.3364  decode.d4.loss_dice: 0.3515  decode.d5.loss_cls: 0.2443  decode.d5.loss_mask: 0.3356  decode.d5.loss_dice: 0.3340  decode.d6.loss_cls: 0.2161  decode.d6.loss_mask: 0.3231  decode.d6.loss_dice: 0.3474  decode.d7.loss_cls: 0.2341  decode.d7.loss_mask: 0.3270  decode.d7.loss_dice: 0.3551  decode.d8.loss_cls: 0.2444  decode.d8.loss_mask: 0.3316  decode.d8.loss_dice: 0.3542
07/30 01:08:00 - mmengine - INFO - Iter(train) [14750/80000]  base_lr: 8.3243e-05 lr: 8.3243e-06  eta: 9:37:56  time: 0.5320  data_time: 0.0136  memory: 5918  grad_norm: 114.4337  loss: 8.6447  decode.loss_cls: 0.1688  decode.loss_mask: 0.2968  decode.loss_dice: 0.3001  decode.d0.loss_cls: 1.0490  decode.d0.loss_mask: 0.2920  decode.d0.loss_dice: 0.3454  decode.d1.loss_cls: 0.1723  decode.d1.loss_mask: 0.2890  decode.d1.loss_dice: 0.3155  decode.d2.loss_cls: 0.1777  decode.d2.loss_mask: 0.2840  decode.d2.loss_dice: 0.3039  decode.d3.loss_cls: 0.2009  decode.d3.loss_mask: 0.2865  decode.d3.loss_dice: 0.2954  decode.d4.loss_cls: 0.1692  decode.d4.loss_mask: 0.2898  decode.d4.loss_dice: 0.2931  decode.d5.loss_cls: 0.1900  decode.d5.loss_mask: 0.2941  decode.d5.loss_dice: 0.2923  decode.d6.loss_cls: 0.1895  decode.d6.loss_mask: 0.2862  decode.d6.loss_dice: 0.3113  decode.d7.loss_cls: 0.1654  decode.d7.loss_mask: 0.2872  decode.d7.loss_dice: 0.3022  decode.d8.loss_cls: 0.2016  decode.d8.loss_mask: 0.2904  decode.d8.loss_dice: 0.3050
07/30 01:08:26 - mmengine - INFO - Iter(train) [14800/80000]  base_lr: 8.3185e-05 lr: 8.3185e-06  eta: 9:37:29  time: 0.5309  data_time: 0.0133  memory: 5883  grad_norm: 114.1541  loss: 8.9861  decode.loss_cls: 0.2001  decode.loss_mask: 0.2557  decode.loss_dice: 0.3098  decode.d0.loss_cls: 1.2119  decode.d0.loss_mask: 0.2693  decode.d0.loss_dice: 0.3169  decode.d1.loss_cls: 0.3547  decode.d1.loss_mask: 0.2604  decode.d1.loss_dice: 0.3177  decode.d2.loss_cls: 0.2645  decode.d2.loss_mask: 0.2639  decode.d2.loss_dice: 0.2881  decode.d3.loss_cls: 0.1784  decode.d3.loss_mask: 0.2651  decode.d3.loss_dice: 0.2866  decode.d4.loss_cls: 0.2010  decode.d4.loss_mask: 0.2662  decode.d4.loss_dice: 0.2934  decode.d5.loss_cls: 0.2190  decode.d5.loss_mask: 0.2576  decode.d5.loss_dice: 0.3047  decode.d6.loss_cls: 0.2282  decode.d6.loss_mask: 0.2642  decode.d6.loss_dice: 0.3028  decode.d7.loss_cls: 0.2532  decode.d7.loss_mask: 0.2614  decode.d7.loss_dice: 0.3076  decode.d8.loss_cls: 0.2195  decode.d8.loss_mask: 0.2615  decode.d8.loss_dice: 0.3026
07/30 01:08:53 - mmengine - INFO - Iter(train) [14850/80000]  base_lr: 8.3128e-05 lr: 8.3128e-06  eta: 9:37:02  time: 0.5351  data_time: 0.0136  memory: 5920  grad_norm: 74.2906  loss: 6.5598  decode.loss_cls: 0.1479  decode.loss_mask: 0.1847  decode.loss_dice: 0.2250  decode.d0.loss_cls: 1.1103  decode.d0.loss_mask: 0.1930  decode.d0.loss_dice: 0.2305  decode.d1.loss_cls: 0.1879  decode.d1.loss_mask: 0.1896  decode.d1.loss_dice: 0.2262  decode.d2.loss_cls: 0.1469  decode.d2.loss_mask: 0.1872  decode.d2.loss_dice: 0.2199  decode.d3.loss_cls: 0.1485  decode.d3.loss_mask: 0.1867  decode.d3.loss_dice: 0.2224  decode.d4.loss_cls: 0.1453  decode.d4.loss_mask: 0.1850  decode.d4.loss_dice: 0.2322  decode.d5.loss_cls: 0.1123  decode.d5.loss_mask: 0.1874  decode.d5.loss_dice: 0.2379  decode.d6.loss_cls: 0.1360  decode.d6.loss_mask: 0.1839  decode.d6.loss_dice: 0.2190  decode.d7.loss_cls: 0.1535  decode.d7.loss_mask: 0.1862  decode.d7.loss_dice: 0.2255  decode.d8.loss_cls: 0.1480  decode.d8.loss_mask: 0.1830  decode.d8.loss_dice: 0.2177
07/30 01:09:19 - mmengine - INFO - Iter(train) [14900/80000]  base_lr: 8.3070e-05 lr: 8.3070e-06  eta: 9:36:35  time: 0.5307  data_time: 0.0135  memory: 5900  grad_norm: 71.1078  loss: 7.6674  decode.loss_cls: 0.2011  decode.loss_mask: 0.2437  decode.loss_dice: 0.2566  decode.d0.loss_cls: 0.9084  decode.d0.loss_mask: 0.2547  decode.d0.loss_dice: 0.2581  decode.d1.loss_cls: 0.2411  decode.d1.loss_mask: 0.2502  decode.d1.loss_dice: 0.2764  decode.d2.loss_cls: 0.1717  decode.d2.loss_mask: 0.2472  decode.d2.loss_dice: 0.2659  decode.d3.loss_cls: 0.1684  decode.d3.loss_mask: 0.2463  decode.d3.loss_dice: 0.2694  decode.d4.loss_cls: 0.1594  decode.d4.loss_mask: 0.2514  decode.d4.loss_dice: 0.2487  decode.d5.loss_cls: 0.1641  decode.d5.loss_mask: 0.2489  decode.d5.loss_dice: 0.2663  decode.d6.loss_cls: 0.1843  decode.d6.loss_mask: 0.2468  decode.d6.loss_dice: 0.2482  decode.d7.loss_cls: 0.1729  decode.d7.loss_mask: 0.2463  decode.d7.loss_dice: 0.2585  decode.d8.loss_cls: 0.1698  decode.d8.loss_mask: 0.2494  decode.d8.loss_dice: 0.2933
07/30 01:09:46 - mmengine - INFO - Iter(train) [14950/80000]  base_lr: 8.3013e-05 lr: 8.3013e-06  eta: 9:36:08  time: 0.5243  data_time: 0.0133  memory: 5934  grad_norm: 114.7355  loss: 8.0073  decode.loss_cls: 0.1721  decode.loss_mask: 0.2535  decode.loss_dice: 0.3195  decode.d0.loss_cls: 0.8752  decode.d0.loss_mask: 0.2610  decode.d0.loss_dice: 0.3197  decode.d1.loss_cls: 0.1588  decode.d1.loss_mask: 0.2567  decode.d1.loss_dice: 0.3169  decode.d2.loss_cls: 0.1521  decode.d2.loss_mask: 0.2537  decode.d2.loss_dice: 0.3044  decode.d3.loss_cls: 0.2215  decode.d3.loss_mask: 0.2477  decode.d3.loss_dice: 0.2982  decode.d4.loss_cls: 0.1606  decode.d4.loss_mask: 0.2501  decode.d4.loss_dice: 0.3198  decode.d5.loss_cls: 0.1331  decode.d5.loss_mask: 0.2491  decode.d5.loss_dice: 0.3267  decode.d6.loss_cls: 0.1444  decode.d6.loss_mask: 0.2481  decode.d6.loss_dice: 0.3237  decode.d7.loss_cls: 0.1289  decode.d7.loss_mask: 0.2530  decode.d7.loss_dice: 0.3202  decode.d8.loss_cls: 0.1705  decode.d8.loss_mask: 0.2541  decode.d8.loss_dice: 0.3138
07/30 01:10:12 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/30 01:10:12 - mmengine - INFO - Iter(train) [15000/80000]  base_lr: 8.2956e-05 lr: 8.2956e-06  eta: 9:35:41  time: 0.5299  data_time: 0.0136  memory: 5933  grad_norm: 83.6047  loss: 8.0072  decode.loss_cls: 0.1962  decode.loss_mask: 0.2380  decode.loss_dice: 0.2940  decode.d0.loss_cls: 0.9915  decode.d0.loss_mask: 0.2521  decode.d0.loss_dice: 0.3294  decode.d1.loss_cls: 0.2612  decode.d1.loss_mask: 0.2607  decode.d1.loss_dice: 0.2938  decode.d2.loss_cls: 0.1424  decode.d2.loss_mask: 0.2498  decode.d2.loss_dice: 0.3039  decode.d3.loss_cls: 0.1759  decode.d3.loss_mask: 0.2394  decode.d3.loss_dice: 0.3125  decode.d4.loss_cls: 0.1645  decode.d4.loss_mask: 0.2364  decode.d4.loss_dice: 0.2835  decode.d5.loss_cls: 0.1773  decode.d5.loss_mask: 0.2351  decode.d5.loss_dice: 0.2836  decode.d6.loss_cls: 0.1585  decode.d6.loss_mask: 0.2351  decode.d6.loss_dice: 0.3038  decode.d7.loss_cls: 0.1669  decode.d7.loss_mask: 0.2396  decode.d7.loss_dice: 0.2927  decode.d8.loss_cls: 0.1507  decode.d8.loss_mask: 0.2415  decode.d8.loss_dice: 0.2974
07/30 01:10:12 - mmengine - INFO - Saving checkpoint at 15000 iterations
07/30 01:10:41 - mmengine - INFO - Iter(train) [15050/80000]  base_lr: 8.2898e-05 lr: 8.2898e-06  eta: 9:35:27  time: 0.5280  data_time: 0.0134  memory: 5918  grad_norm: 108.4997  loss: 7.8230  decode.loss_cls: 0.1070  decode.loss_mask: 0.2512  decode.loss_dice: 0.2823  decode.d0.loss_cls: 0.8702  decode.d0.loss_mask: 0.2514  decode.d0.loss_dice: 0.2954  decode.d1.loss_cls: 0.3444  decode.d1.loss_mask: 0.2441  decode.d1.loss_dice: 0.2824  decode.d2.loss_cls: 0.2116  decode.d2.loss_mask: 0.2486  decode.d2.loss_dice: 0.2774  decode.d3.loss_cls: 0.1800  decode.d3.loss_mask: 0.2475  decode.d3.loss_dice: 0.2808  decode.d4.loss_cls: 0.1783  decode.d4.loss_mask: 0.2475  decode.d4.loss_dice: 0.2863  decode.d5.loss_cls: 0.1735  decode.d5.loss_mask: 0.2502  decode.d5.loss_dice: 0.2856  decode.d6.loss_cls: 0.1669  decode.d6.loss_mask: 0.2504  decode.d6.loss_dice: 0.2735  decode.d7.loss_cls: 0.1151  decode.d7.loss_mask: 0.2504  decode.d7.loss_dice: 0.2815  decode.d8.loss_cls: 0.1487  decode.d8.loss_mask: 0.2464  decode.d8.loss_dice: 0.2945
07/30 01:11:08 - mmengine - INFO - Iter(train) [15100/80000]  base_lr: 8.2841e-05 lr: 8.2841e-06  eta: 9:34:59  time: 0.5264  data_time: 0.0134  memory: 5932  grad_norm: 70.7548  loss: 9.3155  decode.loss_cls: 0.1665  decode.loss_mask: 0.2934  decode.loss_dice: 0.3242  decode.d0.loss_cls: 1.0524  decode.d0.loss_mask: 0.3061  decode.d0.loss_dice: 0.3725  decode.d1.loss_cls: 0.2881  decode.d1.loss_mask: 0.3045  decode.d1.loss_dice: 0.3446  decode.d2.loss_cls: 0.2219  decode.d2.loss_mask: 0.2836  decode.d2.loss_dice: 0.3292  decode.d3.loss_cls: 0.2406  decode.d3.loss_mask: 0.2889  decode.d3.loss_dice: 0.3267  decode.d4.loss_cls: 0.2195  decode.d4.loss_mask: 0.2852  decode.d4.loss_dice: 0.3511  decode.d5.loss_cls: 0.2195  decode.d5.loss_mask: 0.2780  decode.d5.loss_dice: 0.3252  decode.d6.loss_cls: 0.1926  decode.d6.loss_mask: 0.2775  decode.d6.loss_dice: 0.3274  decode.d7.loss_cls: 0.2360  decode.d7.loss_mask: 0.2889  decode.d7.loss_dice: 0.3396  decode.d8.loss_cls: 0.2081  decode.d8.loss_mask: 0.2925  decode.d8.loss_dice: 0.3315
07/30 01:11:34 - mmengine - INFO - Iter(train) [15150/80000]  base_lr: 8.2783e-05 lr: 8.2783e-06  eta: 9:34:32  time: 0.5330  data_time: 0.0137  memory: 5920  grad_norm: 465.3528  loss: 8.8193  decode.loss_cls: 0.2100  decode.loss_mask: 0.2426  decode.loss_dice: 0.2819  decode.d0.loss_cls: 1.0204  decode.d0.loss_mask: 0.3127  decode.d0.loss_dice: 0.2970  decode.d1.loss_cls: 0.3401  decode.d1.loss_mask: 0.2871  decode.d1.loss_dice: 0.2901  decode.d2.loss_cls: 0.2695  decode.d2.loss_mask: 0.2765  decode.d2.loss_dice: 0.2831  decode.d3.loss_cls: 0.2572  decode.d3.loss_mask: 0.2652  decode.d3.loss_dice: 0.2736  decode.d4.loss_cls: 0.2272  decode.d4.loss_mask: 0.2743  decode.d4.loss_dice: 0.2738  decode.d5.loss_cls: 0.2266  decode.d5.loss_mask: 0.2668  decode.d5.loss_dice: 0.2759  decode.d6.loss_cls: 0.2220  decode.d6.loss_mask: 0.2827  decode.d6.loss_dice: 0.2868  decode.d7.loss_cls: 0.2045  decode.d7.loss_mask: 0.2648  decode.d7.loss_dice: 0.2672  decode.d8.loss_cls: 0.2888  decode.d8.loss_mask: 0.2560  decode.d8.loss_dice: 0.2948
07/30 01:12:01 - mmengine - INFO - Iter(train) [15200/80000]  base_lr: 8.2726e-05 lr: 8.2726e-06  eta: 9:34:06  time: 0.5294  data_time: 0.0133  memory: 5896  grad_norm: 163.9802  loss: 8.2012  decode.loss_cls: 0.1597  decode.loss_mask: 0.2542  decode.loss_dice: 0.2786  decode.d0.loss_cls: 1.1319  decode.d0.loss_mask: 0.2593  decode.d0.loss_dice: 0.2974  decode.d1.loss_cls: 0.1874  decode.d1.loss_mask: 0.2625  decode.d1.loss_dice: 0.2867  decode.d2.loss_cls: 0.1600  decode.d2.loss_mask: 0.2585  decode.d2.loss_dice: 0.2801  decode.d3.loss_cls: 0.1960  decode.d3.loss_mask: 0.2555  decode.d3.loss_dice: 0.2651  decode.d4.loss_cls: 0.2058  decode.d4.loss_mask: 0.2556  decode.d4.loss_dice: 0.2705  decode.d5.loss_cls: 0.1890  decode.d5.loss_mask: 0.2578  decode.d5.loss_dice: 0.2778  decode.d6.loss_cls: 0.2095  decode.d6.loss_mask: 0.2556  decode.d6.loss_dice: 0.2758  decode.d7.loss_cls: 0.2003  decode.d7.loss_mask: 0.2547  decode.d7.loss_dice: 0.2735  decode.d8.loss_cls: 0.2105  decode.d8.loss_mask: 0.2526  decode.d8.loss_dice: 0.2794
07/30 01:12:27 - mmengine - INFO - Iter(train) [15250/80000]  base_lr: 8.2668e-05 lr: 8.2668e-06  eta: 9:33:39  time: 0.5387  data_time: 0.0136  memory: 5918  grad_norm: 138.8422  loss: 7.6618  decode.loss_cls: 0.1497  decode.loss_mask: 0.2183  decode.loss_dice: 0.2731  decode.d0.loss_cls: 1.1136  decode.d0.loss_mask: 0.2259  decode.d0.loss_dice: 0.2685  decode.d1.loss_cls: 0.3328  decode.d1.loss_mask: 0.2226  decode.d1.loss_dice: 0.2713  decode.d2.loss_cls: 0.2729  decode.d2.loss_mask: 0.2146  decode.d2.loss_dice: 0.2421  decode.d3.loss_cls: 0.1597  decode.d3.loss_mask: 0.2197  decode.d3.loss_dice: 0.2628  decode.d4.loss_cls: 0.1612  decode.d4.loss_mask: 0.2185  decode.d4.loss_dice: 0.2665  decode.d5.loss_cls: 0.1611  decode.d5.loss_mask: 0.2202  decode.d5.loss_dice: 0.2709  decode.d6.loss_cls: 0.1302  decode.d6.loss_mask: 0.2220  decode.d6.loss_dice: 0.2669  decode.d7.loss_cls: 0.1649  decode.d7.loss_mask: 0.2268  decode.d7.loss_dice: 0.2800  decode.d8.loss_cls: 0.1334  decode.d8.loss_mask: 0.2188  decode.d8.loss_dice: 0.2728
07/30 01:12:54 - mmengine - INFO - Iter(train) [15300/80000]  base_lr: 8.2611e-05 lr: 8.2611e-06  eta: 9:33:13  time: 0.5321  data_time: 0.0132  memory: 5895  grad_norm: 56.8062  loss: 6.7660  decode.loss_cls: 0.1612  decode.loss_mask: 0.1904  decode.loss_dice: 0.2475  decode.d0.loss_cls: 0.9715  decode.d0.loss_mask: 0.1977  decode.d0.loss_dice: 0.2390  decode.d1.loss_cls: 0.1882  decode.d1.loss_mask: 0.1959  decode.d1.loss_dice: 0.2470  decode.d2.loss_cls: 0.1516  decode.d2.loss_mask: 0.1947  decode.d2.loss_dice: 0.2425  decode.d3.loss_cls: 0.1501  decode.d3.loss_mask: 0.1921  decode.d3.loss_dice: 0.2424  decode.d4.loss_cls: 0.1664  decode.d4.loss_mask: 0.1924  decode.d4.loss_dice: 0.2424  decode.d5.loss_cls: 0.1480  decode.d5.loss_mask: 0.1923  decode.d5.loss_dice: 0.2462  decode.d6.loss_cls: 0.1331  decode.d6.loss_mask: 0.1948  decode.d6.loss_dice: 0.2444  decode.d7.loss_cls: 0.1576  decode.d7.loss_mask: 0.1970  decode.d7.loss_dice: 0.2457  decode.d8.loss_cls: 0.1588  decode.d8.loss_mask: 0.1914  decode.d8.loss_dice: 0.2437
07/30 01:13:21 - mmengine - INFO - Iter(train) [15350/80000]  base_lr: 8.2554e-05 lr: 8.2554e-06  eta: 9:32:47  time: 0.5301  data_time: 0.0137  memory: 5918  grad_norm: 131.9212  loss: 9.2831  decode.loss_cls: 0.2010  decode.loss_mask: 0.2729  decode.loss_dice: 0.3170  decode.d0.loss_cls: 1.3816  decode.d0.loss_mask: 0.2872  decode.d0.loss_dice: 0.3476  decode.d1.loss_cls: 0.3158  decode.d1.loss_mask: 0.2819  decode.d1.loss_dice: 0.3310  decode.d2.loss_cls: 0.2275  decode.d2.loss_mask: 0.2778  decode.d2.loss_dice: 0.3273  decode.d3.loss_cls: 0.2248  decode.d3.loss_mask: 0.2736  decode.d3.loss_dice: 0.3020  decode.d4.loss_cls: 0.2046  decode.d4.loss_mask: 0.2733  decode.d4.loss_dice: 0.3004  decode.d5.loss_cls: 0.2159  decode.d5.loss_mask: 0.2742  decode.d5.loss_dice: 0.3044  decode.d6.loss_cls: 0.1865  decode.d6.loss_mask: 0.2679  decode.d6.loss_dice: 0.3170  decode.d7.loss_cls: 0.2210  decode.d7.loss_mask: 0.2703  decode.d7.loss_dice: 0.3094  decode.d8.loss_cls: 0.1744  decode.d8.loss_mask: 0.2746  decode.d8.loss_dice: 0.3203
07/30 01:13:47 - mmengine - INFO - Iter(train) [15400/80000]  base_lr: 8.2496e-05 lr: 8.2496e-06  eta: 9:32:20  time: 0.5277  data_time: 0.0131  memory: 5916  grad_norm: 149.0713  loss: 10.8919  decode.loss_cls: 0.4048  decode.loss_mask: 0.2834  decode.loss_dice: 0.3274  decode.d0.loss_cls: 1.1271  decode.d0.loss_mask: 0.2900  decode.d0.loss_dice: 0.3676  decode.d1.loss_cls: 0.4242  decode.d1.loss_mask: 0.2924  decode.d1.loss_dice: 0.3731  decode.d2.loss_cls: 0.3867  decode.d2.loss_mask: 0.2847  decode.d2.loss_dice: 0.3525  decode.d3.loss_cls: 0.3272  decode.d3.loss_mask: 0.2917  decode.d3.loss_dice: 0.3413  decode.d4.loss_cls: 0.3515  decode.d4.loss_mask: 0.2861  decode.d4.loss_dice: 0.3542  decode.d5.loss_cls: 0.3925  decode.d5.loss_mask: 0.2828  decode.d5.loss_dice: 0.3570  decode.d6.loss_cls: 0.4193  decode.d6.loss_mask: 0.2735  decode.d6.loss_dice: 0.3376  decode.d7.loss_cls: 0.3816  decode.d7.loss_mask: 0.2789  decode.d7.loss_dice: 0.3422  decode.d8.loss_cls: 0.3448  decode.d8.loss_mask: 0.2886  decode.d8.loss_dice: 0.3272
07/30 01:14:14 - mmengine - INFO - Iter(train) [15450/80000]  base_lr: 8.2439e-05 lr: 8.2439e-06  eta: 9:31:53  time: 0.5305  data_time: 0.0135  memory: 5896  grad_norm: 60.8742  loss: 6.6683  decode.loss_cls: 0.0833  decode.loss_mask: 0.2074  decode.loss_dice: 0.2606  decode.d0.loss_cls: 1.0031  decode.d0.loss_mask: 0.2150  decode.d0.loss_dice: 0.2888  decode.d1.loss_cls: 0.1731  decode.d1.loss_mask: 0.2153  decode.d1.loss_dice: 0.2847  decode.d2.loss_cls: 0.0966  decode.d2.loss_mask: 0.2119  decode.d2.loss_dice: 0.2815  decode.d3.loss_cls: 0.0758  decode.d3.loss_mask: 0.2119  decode.d3.loss_dice: 0.2687  decode.d4.loss_cls: 0.0676  decode.d4.loss_mask: 0.2086  decode.d4.loss_dice: 0.2726  decode.d5.loss_cls: 0.0724  decode.d5.loss_mask: 0.2114  decode.d5.loss_dice: 0.2742  decode.d6.loss_cls: 0.0767  decode.d6.loss_mask: 0.2082  decode.d6.loss_dice: 0.2538  decode.d7.loss_cls: 0.0899  decode.d7.loss_mask: 0.2099  decode.d7.loss_dice: 0.2706  decode.d8.loss_cls: 0.0978  decode.d8.loss_mask: 0.2070  decode.d8.loss_dice: 0.2700
07/30 01:14:41 - mmengine - INFO - Iter(train) [15500/80000]  base_lr: 8.2381e-05 lr: 8.2381e-06  eta: 9:31:27  time: 0.5272  data_time: 0.0131  memory: 5896  grad_norm: 101.0344  loss: 10.3118  decode.loss_cls: 0.1063  decode.loss_mask: 0.3580  decode.loss_dice: 0.3917  decode.d0.loss_cls: 0.9505  decode.d0.loss_mask: 0.3566  decode.d0.loss_dice: 0.4047  decode.d1.loss_cls: 0.2913  decode.d1.loss_mask: 0.3486  decode.d1.loss_dice: 0.3979  decode.d2.loss_cls: 0.2112  decode.d2.loss_mask: 0.3550  decode.d2.loss_dice: 0.4084  decode.d3.loss_cls: 0.2236  decode.d3.loss_mask: 0.3372  decode.d3.loss_dice: 0.3815  decode.d4.loss_cls: 0.2986  decode.d4.loss_mask: 0.3331  decode.d4.loss_dice: 0.3735  decode.d5.loss_cls: 0.2814  decode.d5.loss_mask: 0.3369  decode.d5.loss_dice: 0.3770  decode.d6.loss_cls: 0.2957  decode.d6.loss_mask: 0.3343  decode.d6.loss_dice: 0.3679  decode.d7.loss_cls: 0.2080  decode.d7.loss_mask: 0.3413  decode.d7.loss_dice: 0.3699  decode.d8.loss_cls: 0.1184  decode.d8.loss_mask: 0.3604  decode.d8.loss_dice: 0.3934
07/30 01:15:07 - mmengine - INFO - Iter(train) [15550/80000]  base_lr: 8.2324e-05 lr: 8.2324e-06  eta: 9:31:00  time: 0.5309  data_time: 0.0134  memory: 5975  grad_norm: 53.0021  loss: 5.3598  decode.loss_cls: 0.0133  decode.loss_mask: 0.2198  decode.loss_dice: 0.2097  decode.d0.loss_cls: 0.8192  decode.d0.loss_mask: 0.2259  decode.d0.loss_dice: 0.2200  decode.d1.loss_cls: 0.0840  decode.d1.loss_mask: 0.2253  decode.d1.loss_dice: 0.2139  decode.d2.loss_cls: 0.0263  decode.d2.loss_mask: 0.2163  decode.d2.loss_dice: 0.2152  decode.d3.loss_cls: 0.0254  decode.d3.loss_mask: 0.2146  decode.d3.loss_dice: 0.2085  decode.d4.loss_cls: 0.0151  decode.d4.loss_mask: 0.2175  decode.d4.loss_dice: 0.2066  decode.d5.loss_cls: 0.0201  decode.d5.loss_mask: 0.2199  decode.d5.loss_dice: 0.2143  decode.d6.loss_cls: 0.0155  decode.d6.loss_mask: 0.2159  decode.d6.loss_dice: 0.2075  decode.d7.loss_cls: 0.0150  decode.d7.loss_mask: 0.2158  decode.d7.loss_dice: 0.2084  decode.d8.loss_cls: 0.0130  decode.d8.loss_mask: 0.2194  decode.d8.loss_dice: 0.2182
07/30 01:15:34 - mmengine - INFO - Iter(train) [15600/80000]  base_lr: 8.2266e-05 lr: 8.2266e-06  eta: 9:30:33  time: 0.5287  data_time: 0.0136  memory: 5916  grad_norm: 169.9561  loss: 11.0490  decode.loss_cls: 0.3400  decode.loss_mask: 0.3245  decode.loss_dice: 0.3618  decode.d0.loss_cls: 1.1376  decode.d0.loss_mask: 0.3596  decode.d0.loss_dice: 0.4068  decode.d1.loss_cls: 0.4507  decode.d1.loss_mask: 0.3521  decode.d1.loss_dice: 0.3757  decode.d2.loss_cls: 0.3433  decode.d2.loss_mask: 0.3428  decode.d2.loss_dice: 0.3740  decode.d3.loss_cls: 0.2556  decode.d3.loss_mask: 0.3430  decode.d3.loss_dice: 0.3720  decode.d4.loss_cls: 0.2195  decode.d4.loss_mask: 0.3484  decode.d4.loss_dice: 0.3832  decode.d5.loss_cls: 0.2865  decode.d5.loss_mask: 0.3376  decode.d5.loss_dice: 0.3692  decode.d6.loss_cls: 0.2465  decode.d6.loss_mask: 0.3398  decode.d6.loss_dice: 0.3767  decode.d7.loss_cls: 0.2885  decode.d7.loss_mask: 0.3341  decode.d7.loss_dice: 0.3599  decode.d8.loss_cls: 0.3300  decode.d8.loss_mask: 0.3310  decode.d8.loss_dice: 0.3589
07/30 01:16:00 - mmengine - INFO - Iter(train) [15650/80000]  base_lr: 8.2209e-05 lr: 8.2209e-06  eta: 9:30:07  time: 0.5325  data_time: 0.0132  memory: 5899  grad_norm: 149.3406  loss: 8.5428  decode.loss_cls: 0.1663  decode.loss_mask: 0.2445  decode.loss_dice: 0.3102  decode.d0.loss_cls: 1.0232  decode.d0.loss_mask: 0.2600  decode.d0.loss_dice: 0.3535  decode.d1.loss_cls: 0.3559  decode.d1.loss_mask: 0.2490  decode.d1.loss_dice: 0.3132  decode.d2.loss_cls: 0.2370  decode.d2.loss_mask: 0.2452  decode.d2.loss_dice: 0.3157  decode.d3.loss_cls: 0.2029  decode.d3.loss_mask: 0.2451  decode.d3.loss_dice: 0.3131  decode.d4.loss_cls: 0.1569  decode.d4.loss_mask: 0.2479  decode.d4.loss_dice: 0.3315  decode.d5.loss_cls: 0.1821  decode.d5.loss_mask: 0.2462  decode.d5.loss_dice: 0.3209  decode.d6.loss_cls: 0.1733  decode.d6.loss_mask: 0.2485  decode.d6.loss_dice: 0.3040  decode.d7.loss_cls: 0.1945  decode.d7.loss_mask: 0.2491  decode.d7.loss_dice: 0.3033  decode.d8.loss_cls: 0.1722  decode.d8.loss_mask: 0.2486  decode.d8.loss_dice: 0.3290
07/30 01:16:27 - mmengine - INFO - Iter(train) [15700/80000]  base_lr: 8.2151e-05 lr: 8.2151e-06  eta: 9:29:40  time: 0.5297  data_time: 0.0137  memory: 5918  grad_norm: 102.5340  loss: 7.4054  decode.loss_cls: 0.1945  decode.loss_mask: 0.1851  decode.loss_dice: 0.2507  decode.d0.loss_cls: 1.1470  decode.d0.loss_mask: 0.1868  decode.d0.loss_dice: 0.2468  decode.d1.loss_cls: 0.2884  decode.d1.loss_mask: 0.1881  decode.d1.loss_dice: 0.2416  decode.d2.loss_cls: 0.1957  decode.d2.loss_mask: 0.1873  decode.d2.loss_dice: 0.2520  decode.d3.loss_cls: 0.1919  decode.d3.loss_mask: 0.1870  decode.d3.loss_dice: 0.2555  decode.d4.loss_cls: 0.2086  decode.d4.loss_mask: 0.1879  decode.d4.loss_dice: 0.2769  decode.d5.loss_cls: 0.1950  decode.d5.loss_mask: 0.1837  decode.d5.loss_dice: 0.2382  decode.d6.loss_cls: 0.2225  decode.d6.loss_mask: 0.1854  decode.d6.loss_dice: 0.2340  decode.d7.loss_cls: 0.2100  decode.d7.loss_mask: 0.1825  decode.d7.loss_dice: 0.2555  decode.d8.loss_cls: 0.2001  decode.d8.loss_mask: 0.1867  decode.d8.loss_dice: 0.2399
07/30 01:16:53 - mmengine - INFO - Iter(train) [15750/80000]  base_lr: 8.2094e-05 lr: 8.2094e-06  eta: 9:29:13  time: 0.5293  data_time: 0.0131  memory: 5920  grad_norm: 106.0174  loss: 7.6737  decode.loss_cls: 0.1157  decode.loss_mask: 0.2754  decode.loss_dice: 0.2740  decode.d0.loss_cls: 0.8820  decode.d0.loss_mask: 0.2950  decode.d0.loss_dice: 0.2872  decode.d1.loss_cls: 0.2254  decode.d1.loss_mask: 0.2817  decode.d1.loss_dice: 0.2972  decode.d2.loss_cls: 0.1213  decode.d2.loss_mask: 0.2835  decode.d2.loss_dice: 0.2806  decode.d3.loss_cls: 0.1263  decode.d3.loss_mask: 0.2788  decode.d3.loss_dice: 0.2791  decode.d4.loss_cls: 0.1435  decode.d4.loss_mask: 0.2774  decode.d4.loss_dice: 0.2808  decode.d5.loss_cls: 0.1159  decode.d5.loss_mask: 0.2766  decode.d5.loss_dice: 0.2773  decode.d6.loss_cls: 0.0849  decode.d6.loss_mask: 0.2824  decode.d6.loss_dice: 0.2791  decode.d7.loss_cls: 0.0979  decode.d7.loss_mask: 0.2766  decode.d7.loss_dice: 0.2914  decode.d8.loss_cls: 0.1151  decode.d8.loss_mask: 0.2789  decode.d8.loss_dice: 0.2928
07/30 01:17:20 - mmengine - INFO - Iter(train) [15800/80000]  base_lr: 8.2036e-05 lr: 8.2036e-06  eta: 9:28:46  time: 0.5303  data_time: 0.0133  memory: 5936  grad_norm: 96.7349  loss: 5.8974  decode.loss_cls: 0.0374  decode.loss_mask: 0.2052  decode.loss_dice: 0.2287  decode.d0.loss_cls: 0.9767  decode.d0.loss_mask: 0.2166  decode.d0.loss_dice: 0.2336  decode.d1.loss_cls: 0.0899  decode.d1.loss_mask: 0.2169  decode.d1.loss_dice: 0.2410  decode.d2.loss_cls: 0.0839  decode.d2.loss_mask: 0.2127  decode.d2.loss_dice: 0.2430  decode.d3.loss_cls: 0.0606  decode.d3.loss_mask: 0.2080  decode.d3.loss_dice: 0.2357  decode.d4.loss_cls: 0.0422  decode.d4.loss_mask: 0.2051  decode.d4.loss_dice: 0.2398  decode.d5.loss_cls: 0.0485  decode.d5.loss_mask: 0.2084  decode.d5.loss_dice: 0.2346  decode.d6.loss_cls: 0.0403  decode.d6.loss_mask: 0.2073  decode.d6.loss_dice: 0.2251  decode.d7.loss_cls: 0.0376  decode.d7.loss_mask: 0.2113  decode.d7.loss_dice: 0.2322  decode.d8.loss_cls: 0.0368  decode.d8.loss_mask: 0.2072  decode.d8.loss_dice: 0.2312
07/30 01:17:46 - mmengine - INFO - Iter(train) [15850/80000]  base_lr: 8.1979e-05 lr: 8.1979e-06  eta: 9:28:19  time: 0.5286  data_time: 0.0135  memory: 5916  grad_norm: 150.0949  loss: 8.1647  decode.loss_cls: 0.1501  decode.loss_mask: 0.2268  decode.loss_dice: 0.3053  decode.d0.loss_cls: 1.0434  decode.d0.loss_mask: 0.2420  decode.d0.loss_dice: 0.3710  decode.d1.loss_cls: 0.3292  decode.d1.loss_mask: 0.2311  decode.d1.loss_dice: 0.3269  decode.d2.loss_cls: 0.1847  decode.d2.loss_mask: 0.2304  decode.d2.loss_dice: 0.3227  decode.d3.loss_cls: 0.1901  decode.d3.loss_mask: 0.2356  decode.d3.loss_dice: 0.3183  decode.d4.loss_cls: 0.1661  decode.d4.loss_mask: 0.2347  decode.d4.loss_dice: 0.3189  decode.d5.loss_cls: 0.1509  decode.d5.loss_mask: 0.2348  decode.d5.loss_dice: 0.3106  decode.d6.loss_cls: 0.1440  decode.d6.loss_mask: 0.2266  decode.d6.loss_dice: 0.3063  decode.d7.loss_cls: 0.1583  decode.d7.loss_mask: 0.2276  decode.d7.loss_dice: 0.3086  decode.d8.loss_cls: 0.1369  decode.d8.loss_mask: 0.2270  decode.d8.loss_dice: 0.3057
07/30 01:18:13 - mmengine - INFO - Iter(train) [15900/80000]  base_lr: 8.1921e-05 lr: 8.1921e-06  eta: 9:27:52  time: 0.5304  data_time: 0.0130  memory: 5916  grad_norm: 208.7119  loss: 9.4651  decode.loss_cls: 0.3331  decode.loss_mask: 0.2564  decode.loss_dice: 0.3376  decode.d0.loss_cls: 1.0937  decode.d0.loss_mask: 0.2657  decode.d0.loss_dice: 0.3533  decode.d1.loss_cls: 0.3259  decode.d1.loss_mask: 0.2685  decode.d1.loss_dice: 0.3664  decode.d2.loss_cls: 0.2651  decode.d2.loss_mask: 0.2523  decode.d2.loss_dice: 0.3492  decode.d3.loss_cls: 0.2119  decode.d3.loss_mask: 0.2497  decode.d3.loss_dice: 0.3456  decode.d4.loss_cls: 0.2358  decode.d4.loss_mask: 0.2478  decode.d4.loss_dice: 0.3567  decode.d5.loss_cls: 0.1869  decode.d5.loss_mask: 0.2697  decode.d5.loss_dice: 0.3579  decode.d6.loss_cls: 0.1673  decode.d6.loss_mask: 0.2599  decode.d6.loss_dice: 0.3668  decode.d7.loss_cls: 0.1970  decode.d7.loss_mask: 0.2580  decode.d7.loss_dice: 0.3629  decode.d8.loss_cls: 0.3237  decode.d8.loss_mask: 0.2521  decode.d8.loss_dice: 0.3480
07/30 01:18:39 - mmengine - INFO - Iter(train) [15950/80000]  base_lr: 8.1864e-05 lr: 8.1864e-06  eta: 9:27:26  time: 0.5332  data_time: 0.0136  memory: 5916  grad_norm: 109.6409  loss: 9.7956  decode.loss_cls: 0.2927  decode.loss_mask: 0.2585  decode.loss_dice: 0.3416  decode.d0.loss_cls: 1.1114  decode.d0.loss_mask: 0.2686  decode.d0.loss_dice: 0.3583  decode.d1.loss_cls: 0.3451  decode.d1.loss_mask: 0.2665  decode.d1.loss_dice: 0.3485  decode.d2.loss_cls: 0.3017  decode.d2.loss_mask: 0.2639  decode.d2.loss_dice: 0.3421  decode.d3.loss_cls: 0.2608  decode.d3.loss_mask: 0.2640  decode.d3.loss_dice: 0.3564  decode.d4.loss_cls: 0.2496  decode.d4.loss_mask: 0.2639  decode.d4.loss_dice: 0.3301  decode.d5.loss_cls: 0.2933  decode.d5.loss_mask: 0.2634  decode.d5.loss_dice: 0.3585  decode.d6.loss_cls: 0.2509  decode.d6.loss_mask: 0.2602  decode.d6.loss_dice: 0.3141  decode.d7.loss_cls: 0.2985  decode.d7.loss_mask: 0.2610  decode.d7.loss_dice: 0.3565  decode.d8.loss_cls: 0.3263  decode.d8.loss_mask: 0.2644  decode.d8.loss_dice: 0.3245
07/30 01:19:06 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/30 01:19:06 - mmengine - INFO - Iter(train) [16000/80000]  base_lr: 8.1806e-05 lr: 8.1806e-06  eta: 9:26:59  time: 0.5328  data_time: 0.0133  memory: 5934  grad_norm: 85.7033  loss: 9.0189  decode.loss_cls: 0.1543  decode.loss_mask: 0.2802  decode.loss_dice: 0.3405  decode.d0.loss_cls: 0.9508  decode.d0.loss_mask: 0.2901  decode.d0.loss_dice: 0.3732  decode.d1.loss_cls: 0.3934  decode.d1.loss_mask: 0.2825  decode.d1.loss_dice: 0.3596  decode.d2.loss_cls: 0.2586  decode.d2.loss_mask: 0.2808  decode.d2.loss_dice: 0.3228  decode.d3.loss_cls: 0.1377  decode.d3.loss_mask: 0.2761  decode.d3.loss_dice: 0.3712  decode.d4.loss_cls: 0.2144  decode.d4.loss_mask: 0.2756  decode.d4.loss_dice: 0.3378  decode.d5.loss_cls: 0.1708  decode.d5.loss_mask: 0.2756  decode.d5.loss_dice: 0.3360  decode.d6.loss_cls: 0.1380  decode.d6.loss_mask: 0.2776  decode.d6.loss_dice: 0.3552  decode.d7.loss_cls: 0.1498  decode.d7.loss_mask: 0.2779  decode.d7.loss_dice: 0.3439  decode.d8.loss_cls: 0.1879  decode.d8.loss_mask: 0.2775  decode.d8.loss_dice: 0.3290
07/30 01:19:33 - mmengine - INFO - Iter(train) [16050/80000]  base_lr: 8.1749e-05 lr: 8.1749e-06  eta: 9:26:33  time: 0.5401  data_time: 0.0133  memory: 5896  grad_norm: 213.7269  loss: 8.5582  decode.loss_cls: 0.1569  decode.loss_mask: 0.2494  decode.loss_dice: 0.3029  decode.d0.loss_cls: 1.0825  decode.d0.loss_mask: 0.2780  decode.d0.loss_dice: 0.3321  decode.d1.loss_cls: 0.3406  decode.d1.loss_mask: 0.2646  decode.d1.loss_dice: 0.3229  decode.d2.loss_cls: 0.2392  decode.d2.loss_mask: 0.2623  decode.d2.loss_dice: 0.3284  decode.d3.loss_cls: 0.2375  decode.d3.loss_mask: 0.2547  decode.d3.loss_dice: 0.3072  decode.d4.loss_cls: 0.1456  decode.d4.loss_mask: 0.2598  decode.d4.loss_dice: 0.2924  decode.d5.loss_cls: 0.1504  decode.d5.loss_mask: 0.2585  decode.d5.loss_dice: 0.3077  decode.d6.loss_cls: 0.1814  decode.d6.loss_mask: 0.2525  decode.d6.loss_dice: 0.3085  decode.d7.loss_cls: 0.1704  decode.d7.loss_mask: 0.2515  decode.d7.loss_dice: 0.3299  decode.d8.loss_cls: 0.1189  decode.d8.loss_mask: 0.2548  decode.d8.loss_dice: 0.3164
07/30 01:19:59 - mmengine - INFO - Iter(train) [16100/80000]  base_lr: 8.1691e-05 lr: 8.1691e-06  eta: 9:26:07  time: 0.5320  data_time: 0.0139  memory: 5918  grad_norm: 99.4988  loss: 7.9246  decode.loss_cls: 0.0970  decode.loss_mask: 0.2785  decode.loss_dice: 0.2733  decode.d0.loss_cls: 0.9376  decode.d0.loss_mask: 0.2884  decode.d0.loss_dice: 0.2883  decode.d1.loss_cls: 0.2726  decode.d1.loss_mask: 0.2845  decode.d1.loss_dice: 0.2797  decode.d2.loss_cls: 0.2000  decode.d2.loss_mask: 0.2812  decode.d2.loss_dice: 0.2696  decode.d3.loss_cls: 0.1971  decode.d3.loss_mask: 0.2783  decode.d3.loss_dice: 0.2691  decode.d4.loss_cls: 0.1222  decode.d4.loss_mask: 0.2824  decode.d4.loss_dice: 0.2772  decode.d5.loss_cls: 0.1222  decode.d5.loss_mask: 0.2800  decode.d5.loss_dice: 0.2710  decode.d6.loss_cls: 0.1347  decode.d6.loss_mask: 0.2791  decode.d6.loss_dice: 0.2691  decode.d7.loss_cls: 0.1090  decode.d7.loss_mask: 0.2799  decode.d7.loss_dice: 0.2631  decode.d8.loss_cls: 0.1852  decode.d8.loss_mask: 0.2815  decode.d8.loss_dice: 0.2728
07/30 01:20:26 - mmengine - INFO - Iter(train) [16150/80000]  base_lr: 8.1634e-05 lr: 8.1634e-06  eta: 9:25:41  time: 0.5281  data_time: 0.0130  memory: 5916  grad_norm: 95.6743  loss: 6.5883  decode.loss_cls: 0.1155  decode.loss_mask: 0.1982  decode.loss_dice: 0.2401  decode.d0.loss_cls: 1.0707  decode.d0.loss_mask: 0.2048  decode.d0.loss_dice: 0.2785  decode.d1.loss_cls: 0.1398  decode.d1.loss_mask: 0.2018  decode.d1.loss_dice: 0.2627  decode.d2.loss_cls: 0.1221  decode.d2.loss_mask: 0.2037  decode.d2.loss_dice: 0.2499  decode.d3.loss_cls: 0.0938  decode.d3.loss_mask: 0.2002  decode.d3.loss_dice: 0.2374  decode.d4.loss_cls: 0.1182  decode.d4.loss_mask: 0.1988  decode.d4.loss_dice: 0.2422  decode.d5.loss_cls: 0.1386  decode.d5.loss_mask: 0.1981  decode.d5.loss_dice: 0.2513  decode.d6.loss_cls: 0.0907  decode.d6.loss_mask: 0.1984  decode.d6.loss_dice: 0.2477  decode.d7.loss_cls: 0.0944  decode.d7.loss_mask: 0.2005  decode.d7.loss_dice: 0.2415  decode.d8.loss_cls: 0.0679  decode.d8.loss_mask: 0.2112  decode.d8.loss_dice: 0.2695
07/30 01:20:53 - mmengine - INFO - Iter(train) [16200/80000]  base_lr: 8.1576e-05 lr: 8.1576e-06  eta: 9:25:14  time: 0.5303  data_time: 0.0134  memory: 5919  grad_norm: 132.2010  loss: 8.4421  decode.loss_cls: 0.2169  decode.loss_mask: 0.2699  decode.loss_dice: 0.2758  decode.d0.loss_cls: 1.0042  decode.d0.loss_mask: 0.2817  decode.d0.loss_dice: 0.3075  decode.d1.loss_cls: 0.2353  decode.d1.loss_mask: 0.2674  decode.d1.loss_dice: 0.2978  decode.d2.loss_cls: 0.2559  decode.d2.loss_mask: 0.2705  decode.d2.loss_dice: 0.2876  decode.d3.loss_cls: 0.2668  decode.d3.loss_mask: 0.2656  decode.d3.loss_dice: 0.2849  decode.d4.loss_cls: 0.2336  decode.d4.loss_mask: 0.2652  decode.d4.loss_dice: 0.2980  decode.d5.loss_cls: 0.1705  decode.d5.loss_mask: 0.2711  decode.d5.loss_dice: 0.2910  decode.d6.loss_cls: 0.1497  decode.d6.loss_mask: 0.2736  decode.d6.loss_dice: 0.2898  decode.d7.loss_cls: 0.1536  decode.d7.loss_mask: 0.2767  decode.d7.loss_dice: 0.2850  decode.d8.loss_cls: 0.1291  decode.d8.loss_mask: 0.2785  decode.d8.loss_dice: 0.2888
07/30 01:21:19 - mmengine - INFO - Iter(train) [16250/80000]  base_lr: 8.1518e-05 lr: 8.1518e-06  eta: 9:24:47  time: 0.5283  data_time: 0.0133  memory: 5883  grad_norm: 76.6496  loss: 8.5020  decode.loss_cls: 0.1680  decode.loss_mask: 0.2869  decode.loss_dice: 0.2596  decode.d0.loss_cls: 1.0296  decode.d0.loss_mask: 0.2999  decode.d0.loss_dice: 0.2880  decode.d1.loss_cls: 0.2207  decode.d1.loss_mask: 0.2906  decode.d1.loss_dice: 0.2695  decode.d2.loss_cls: 0.2696  decode.d2.loss_mask: 0.2889  decode.d2.loss_dice: 0.2626  decode.d3.loss_cls: 0.1712  decode.d3.loss_mask: 0.2848  decode.d3.loss_dice: 0.2656  decode.d4.loss_cls: 0.2282  decode.d4.loss_mask: 0.2854  decode.d4.loss_dice: 0.2514  decode.d5.loss_cls: 0.2619  decode.d5.loss_mask: 0.2894  decode.d5.loss_dice: 0.2599  decode.d6.loss_cls: 0.1902  decode.d6.loss_mask: 0.2887  decode.d6.loss_dice: 0.2681  decode.d7.loss_cls: 0.1734  decode.d7.loss_mask: 0.2902  decode.d7.loss_dice: 0.2591  decode.d8.loss_cls: 0.2290  decode.d8.loss_mask: 0.2893  decode.d8.loss_dice: 0.2822
07/30 01:21:46 - mmengine - INFO - Iter(train) [16300/80000]  base_lr: 8.1461e-05 lr: 8.1461e-06  eta: 9:24:21  time: 0.5325  data_time: 0.0131  memory: 5896  grad_norm: 95.3869  loss: 9.5812  decode.loss_cls: 0.1786  decode.loss_mask: 0.2297  decode.loss_dice: 0.3826  decode.d0.loss_cls: 1.2273  decode.d0.loss_mask: 0.2083  decode.d0.loss_dice: 0.3714  decode.d1.loss_cls: 0.4088  decode.d1.loss_mask: 0.2308  decode.d1.loss_dice: 0.3655  decode.d2.loss_cls: 0.3052  decode.d2.loss_mask: 0.2299  decode.d2.loss_dice: 0.3724  decode.d3.loss_cls: 0.3043  decode.d3.loss_mask: 0.2253  decode.d3.loss_dice: 0.3695  decode.d4.loss_cls: 0.2191  decode.d4.loss_mask: 0.2279  decode.d4.loss_dice: 0.3698  decode.d5.loss_cls: 0.2300  decode.d5.loss_mask: 0.2224  decode.d5.loss_dice: 0.3548  decode.d6.loss_cls: 0.2700  decode.d6.loss_mask: 0.2247  decode.d6.loss_dice: 0.3509  decode.d7.loss_cls: 0.2397  decode.d7.loss_mask: 0.2311  decode.d7.loss_dice: 0.3712  decode.d8.loss_cls: 0.2715  decode.d8.loss_mask: 0.2299  decode.d8.loss_dice: 0.3586
07/30 01:22:12 - mmengine - INFO - Iter(train) [16350/80000]  base_lr: 8.1403e-05 lr: 8.1403e-06  eta: 9:23:54  time: 0.5329  data_time: 0.0135  memory: 5898  grad_norm: 112.1136  loss: 7.7897  decode.loss_cls: 0.1188  decode.loss_mask: 0.2803  decode.loss_dice: 0.2785  decode.d0.loss_cls: 1.0972  decode.d0.loss_mask: 0.2882  decode.d0.loss_dice: 0.2923  decode.d1.loss_cls: 0.1707  decode.d1.loss_mask: 0.2878  decode.d1.loss_dice: 0.2969  decode.d2.loss_cls: 0.1047  decode.d2.loss_mask: 0.2837  decode.d2.loss_dice: 0.2866  decode.d3.loss_cls: 0.1225  decode.d3.loss_mask: 0.2790  decode.d3.loss_dice: 0.2835  decode.d4.loss_cls: 0.1070  decode.d4.loss_mask: 0.2827  decode.d4.loss_dice: 0.2754  decode.d5.loss_cls: 0.0743  decode.d5.loss_mask: 0.2795  decode.d5.loss_dice: 0.2740  decode.d6.loss_cls: 0.0862  decode.d6.loss_mask: 0.2829  decode.d6.loss_dice: 0.2771  decode.d7.loss_cls: 0.1147  decode.d7.loss_mask: 0.2822  decode.d7.loss_dice: 0.2834  decode.d8.loss_cls: 0.1445  decode.d8.loss_mask: 0.2840  decode.d8.loss_dice: 0.2712
07/30 01:22:39 - mmengine - INFO - Iter(train) [16400/80000]  base_lr: 8.1346e-05 lr: 8.1346e-06  eta: 9:23:28  time: 0.5298  data_time: 0.0131  memory: 5918  grad_norm: 145.5548  loss: 9.0648  decode.loss_cls: 0.1555  decode.loss_mask: 0.2776  decode.loss_dice: 0.3403  decode.d0.loss_cls: 1.0487  decode.d0.loss_mask: 0.2874  decode.d0.loss_dice: 0.3683  decode.d1.loss_cls: 0.3293  decode.d1.loss_mask: 0.2678  decode.d1.loss_dice: 0.3429  decode.d2.loss_cls: 0.2310  decode.d2.loss_mask: 0.2723  decode.d2.loss_dice: 0.3229  decode.d3.loss_cls: 0.2539  decode.d3.loss_mask: 0.2738  decode.d3.loss_dice: 0.3396  decode.d4.loss_cls: 0.1496  decode.d4.loss_mask: 0.2726  decode.d4.loss_dice: 0.3227  decode.d5.loss_cls: 0.2069  decode.d5.loss_mask: 0.2744  decode.d5.loss_dice: 0.3426  decode.d6.loss_cls: 0.1922  decode.d6.loss_mask: 0.2705  decode.d6.loss_dice: 0.3385  decode.d7.loss_cls: 0.1838  decode.d7.loss_mask: 0.2694  decode.d7.loss_dice: 0.3311  decode.d8.loss_cls: 0.1810  decode.d8.loss_mask: 0.2785  decode.d8.loss_dice: 0.3398
07/30 01:23:05 - mmengine - INFO - Iter(train) [16450/80000]  base_lr: 8.1288e-05 lr: 8.1288e-06  eta: 9:23:00  time: 0.5266  data_time: 0.0126  memory: 5931  grad_norm: 159.8363  loss: 9.5171  decode.loss_cls: 0.1978  decode.loss_mask: 0.2897  decode.loss_dice: 0.3680  decode.d0.loss_cls: 0.9475  decode.d0.loss_mask: 0.2935  decode.d0.loss_dice: 0.3679  decode.d1.loss_cls: 0.2781  decode.d1.loss_mask: 0.3005  decode.d1.loss_dice: 0.3439  decode.d2.loss_cls: 0.2123  decode.d2.loss_mask: 0.3093  decode.d2.loss_dice: 0.3452  decode.d3.loss_cls: 0.2450  decode.d3.loss_mask: 0.2984  decode.d3.loss_dice: 0.3440  decode.d4.loss_cls: 0.2101  decode.d4.loss_mask: 0.2935  decode.d4.loss_dice: 0.3567  decode.d5.loss_cls: 0.2018  decode.d5.loss_mask: 0.2999  decode.d5.loss_dice: 0.3665  decode.d6.loss_cls: 0.2655  decode.d6.loss_mask: 0.3047  decode.d6.loss_dice: 0.3425  decode.d7.loss_cls: 0.2303  decode.d7.loss_mask: 0.2908  decode.d7.loss_dice: 0.3364  decode.d8.loss_cls: 0.2371  decode.d8.loss_mask: 0.2949  decode.d8.loss_dice: 0.3455
07/30 01:23:32 - mmengine - INFO - Iter(train) [16500/80000]  base_lr: 8.1231e-05 lr: 8.1231e-06  eta: 9:22:33  time: 0.5323  data_time: 0.0137  memory: 5919  grad_norm: 164.7698  loss: 8.2909  decode.loss_cls: 0.1646  decode.loss_mask: 0.2729  decode.loss_dice: 0.3297  decode.d0.loss_cls: 1.0285  decode.d0.loss_mask: 0.2795  decode.d0.loss_dice: 0.3013  decode.d1.loss_cls: 0.2427  decode.d1.loss_mask: 0.2730  decode.d1.loss_dice: 0.2944  decode.d2.loss_cls: 0.2553  decode.d2.loss_mask: 0.2635  decode.d2.loss_dice: 0.2479  decode.d3.loss_cls: 0.2029  decode.d3.loss_mask: 0.2718  decode.d3.loss_dice: 0.2820  decode.d4.loss_cls: 0.1569  decode.d4.loss_mask: 0.2633  decode.d4.loss_dice: 0.2801  decode.d5.loss_cls: 0.1645  decode.d5.loss_mask: 0.2613  decode.d5.loss_dice: 0.2770  decode.d6.loss_cls: 0.1323  decode.d6.loss_mask: 0.2685  decode.d6.loss_dice: 0.2963  decode.d7.loss_cls: 0.1695  decode.d7.loss_mask: 0.2705  decode.d7.loss_dice: 0.3253  decode.d8.loss_cls: 0.1125  decode.d8.loss_mask: 0.2713  decode.d8.loss_dice: 0.3316
07/30 01:23:58 - mmengine - INFO - Iter(train) [16550/80000]  base_lr: 8.1173e-05 lr: 8.1173e-06  eta: 9:22:07  time: 0.5339  data_time: 0.0137  memory: 5932  grad_norm: 168.0813  loss: 10.3894  decode.loss_cls: 0.2905  decode.loss_mask: 0.3192  decode.loss_dice: 0.3318  decode.d0.loss_cls: 1.0946  decode.d0.loss_mask: 0.3191  decode.d0.loss_dice: 0.3776  decode.d1.loss_cls: 0.3820  decode.d1.loss_mask: 0.3205  decode.d1.loss_dice: 0.3488  decode.d2.loss_cls: 0.2965  decode.d2.loss_mask: 0.3133  decode.d2.loss_dice: 0.3554  decode.d3.loss_cls: 0.2934  decode.d3.loss_mask: 0.3139  decode.d3.loss_dice: 0.3286  decode.d4.loss_cls: 0.3066  decode.d4.loss_mask: 0.3166  decode.d4.loss_dice: 0.3480  decode.d5.loss_cls: 0.2554  decode.d5.loss_mask: 0.3117  decode.d5.loss_dice: 0.3447  decode.d6.loss_cls: 0.2688  decode.d6.loss_mask: 0.3111  decode.d6.loss_dice: 0.3432  decode.d7.loss_cls: 0.3108  decode.d7.loss_mask: 0.3125  decode.d7.loss_dice: 0.3404  decode.d8.loss_cls: 0.2768  decode.d8.loss_mask: 0.3142  decode.d8.loss_dice: 0.3433
07/30 01:24:25 - mmengine - INFO - Iter(train) [16600/80000]  base_lr: 8.1116e-05 lr: 8.1116e-06  eta: 9:21:41  time: 0.5276  data_time: 0.0132  memory: 5896  grad_norm: 75.9450  loss: 7.7526  decode.loss_cls: 0.1328  decode.loss_mask: 0.2415  decode.loss_dice: 0.2631  decode.d0.loss_cls: 0.9296  decode.d0.loss_mask: 0.2528  decode.d0.loss_dice: 0.3067  decode.d1.loss_cls: 0.2499  decode.d1.loss_mask: 0.2428  decode.d1.loss_dice: 0.2891  decode.d2.loss_cls: 0.1867  decode.d2.loss_mask: 0.2490  decode.d2.loss_dice: 0.3138  decode.d3.loss_cls: 0.1628  decode.d3.loss_mask: 0.2429  decode.d3.loss_dice: 0.2938  decode.d4.loss_cls: 0.1480  decode.d4.loss_mask: 0.2434  decode.d4.loss_dice: 0.2933  decode.d5.loss_cls: 0.1481  decode.d5.loss_mask: 0.2433  decode.d5.loss_dice: 0.2835  decode.d6.loss_cls: 0.1314  decode.d6.loss_mask: 0.2434  decode.d6.loss_dice: 0.2949  decode.d7.loss_cls: 0.1418  decode.d7.loss_mask: 0.2471  decode.d7.loss_dice: 0.2829  decode.d8.loss_cls: 0.1490  decode.d8.loss_mask: 0.2439  decode.d8.loss_dice: 0.3015
07/30 01:24:52 - mmengine - INFO - Iter(train) [16650/80000]  base_lr: 8.1058e-05 lr: 8.1058e-06  eta: 9:21:14  time: 0.5233  data_time: 0.0130  memory: 5882  grad_norm: 109.6146  loss: 10.1324  decode.loss_cls: 0.2426  decode.loss_mask: 0.3157  decode.loss_dice: 0.3449  decode.d0.loss_cls: 1.0340  decode.d0.loss_mask: 0.3204  decode.d0.loss_dice: 0.3356  decode.d1.loss_cls: 0.3843  decode.d1.loss_mask: 0.3251  decode.d1.loss_dice: 0.3739  decode.d2.loss_cls: 0.3161  decode.d2.loss_mask: 0.3122  decode.d2.loss_dice: 0.3542  decode.d3.loss_cls: 0.2385  decode.d3.loss_mask: 0.3144  decode.d3.loss_dice: 0.3663  decode.d4.loss_cls: 0.2400  decode.d4.loss_mask: 0.3142  decode.d4.loss_dice: 0.3417  decode.d5.loss_cls: 0.2506  decode.d5.loss_mask: 0.3114  decode.d5.loss_dice: 0.3443  decode.d6.loss_cls: 0.2606  decode.d6.loss_mask: 0.3125  decode.d6.loss_dice: 0.3490  decode.d7.loss_cls: 0.2626  decode.d7.loss_mask: 0.3122  decode.d7.loss_dice: 0.3458  decode.d8.loss_cls: 0.2473  decode.d8.loss_mask: 0.3140  decode.d8.loss_dice: 0.3480
07/30 01:25:18 - mmengine - INFO - Iter(train) [16700/80000]  base_lr: 8.1000e-05 lr: 8.1000e-06  eta: 9:20:47  time: 0.5235  data_time: 0.0134  memory: 5916  grad_norm: 361.3304  loss: 12.4420  decode.loss_cls: 0.2687  decode.loss_mask: 0.4479  decode.loss_dice: 0.4329  decode.d0.loss_cls: 1.1549  decode.d0.loss_mask: 0.3664  decode.d0.loss_dice: 0.4099  decode.d1.loss_cls: 0.4827  decode.d1.loss_mask: 0.4060  decode.d1.loss_dice: 0.3960  decode.d2.loss_cls: 0.4357  decode.d2.loss_mask: 0.3937  decode.d2.loss_dice: 0.3734  decode.d3.loss_cls: 0.3716  decode.d3.loss_mask: 0.3819  decode.d3.loss_dice: 0.4020  decode.d4.loss_cls: 0.3344  decode.d4.loss_mask: 0.3834  decode.d4.loss_dice: 0.3806  decode.d5.loss_cls: 0.3861  decode.d5.loss_mask: 0.3859  decode.d5.loss_dice: 0.3707  decode.d6.loss_cls: 0.4026  decode.d6.loss_mask: 0.3951  decode.d6.loss_dice: 0.3733  decode.d7.loss_cls: 0.3073  decode.d7.loss_mask: 0.4315  decode.d7.loss_dice: 0.4255  decode.d8.loss_cls: 0.3026  decode.d8.loss_mask: 0.4283  decode.d8.loss_dice: 0.4109
07/30 01:25:44 - mmengine - INFO - Iter(train) [16750/80000]  base_lr: 8.0943e-05 lr: 8.0943e-06  eta: 9:20:20  time: 0.5235  data_time: 0.0126  memory: 5895  grad_norm: 172.3430  loss: 12.8504  decode.loss_cls: 0.5060  decode.loss_mask: 0.3373  decode.loss_dice: 0.3355  decode.d0.loss_cls: 1.3034  decode.d0.loss_mask: 0.3222  decode.d0.loss_dice: 0.3412  decode.d1.loss_cls: 0.5375  decode.d1.loss_mask: 0.3296  decode.d1.loss_dice: 0.3236  decode.d2.loss_cls: 0.5258  decode.d2.loss_mask: 0.3167  decode.d2.loss_dice: 0.3286  decode.d3.loss_cls: 0.5717  decode.d3.loss_mask: 0.3379  decode.d3.loss_dice: 0.3281  decode.d4.loss_cls: 0.6094  decode.d4.loss_mask: 0.3682  decode.d4.loss_dice: 0.3335  decode.d5.loss_cls: 0.5458  decode.d5.loss_mask: 0.3428  decode.d5.loss_dice: 0.3220  decode.d6.loss_cls: 0.5638  decode.d6.loss_mask: 0.3550  decode.d6.loss_dice: 0.3392  decode.d7.loss_cls: 0.4890  decode.d7.loss_mask: 0.3179  decode.d7.loss_dice: 0.3346  decode.d8.loss_cls: 0.5229  decode.d8.loss_mask: 0.3341  decode.d8.loss_dice: 0.3272
07/30 01:26:11 - mmengine - INFO - Iter(train) [16800/80000]  base_lr: 8.0885e-05 lr: 8.0885e-06  eta: 9:19:53  time: 0.5342  data_time: 0.0133  memory: 5896  grad_norm: 204.0781  loss: 10.1346  decode.loss_cls: 0.3098  decode.loss_mask: 0.2739  decode.loss_dice: 0.3685  decode.d0.loss_cls: 1.1889  decode.d0.loss_mask: 0.2747  decode.d0.loss_dice: 0.3923  decode.d1.loss_cls: 0.3751  decode.d1.loss_mask: 0.2619  decode.d1.loss_dice: 0.3438  decode.d2.loss_cls: 0.2799  decode.d2.loss_mask: 0.2756  decode.d2.loss_dice: 0.3576  decode.d3.loss_cls: 0.1915  decode.d3.loss_mask: 0.2861  decode.d3.loss_dice: 0.3471  decode.d4.loss_cls: 0.1932  decode.d4.loss_mask: 0.2891  decode.d4.loss_dice: 0.3722  decode.d5.loss_cls: 0.1841  decode.d5.loss_mask: 0.2832  decode.d5.loss_dice: 0.3790  decode.d6.loss_cls: 0.2608  decode.d6.loss_mask: 0.2830  decode.d6.loss_dice: 0.4009  decode.d7.loss_cls: 0.2734  decode.d7.loss_mask: 0.2892  decode.d7.loss_dice: 0.4233  decode.d8.loss_cls: 0.3248  decode.d8.loss_mask: 0.2798  decode.d8.loss_dice: 0.3719
07/30 01:26:38 - mmengine - INFO - Iter(train) [16850/80000]  base_lr: 8.0828e-05 lr: 8.0828e-06  eta: 9:19:28  time: 0.5397  data_time: 0.0138  memory: 5918  grad_norm: 60.4734  loss: 6.7815  decode.loss_cls: 0.1045  decode.loss_mask: 0.2383  decode.loss_dice: 0.2577  decode.d0.loss_cls: 0.9772  decode.d0.loss_mask: 0.2472  decode.d0.loss_dice: 0.2613  decode.d1.loss_cls: 0.1101  decode.d1.loss_mask: 0.2389  decode.d1.loss_dice: 0.2607  decode.d2.loss_cls: 0.0778  decode.d2.loss_mask: 0.2364  decode.d2.loss_dice: 0.2533  decode.d3.loss_cls: 0.0776  decode.d3.loss_mask: 0.2370  decode.d3.loss_dice: 0.2477  decode.d4.loss_cls: 0.0961  decode.d4.loss_mask: 0.2339  decode.d4.loss_dice: 0.2527  decode.d5.loss_cls: 0.0999  decode.d5.loss_mask: 0.2346  decode.d5.loss_dice: 0.2541  decode.d6.loss_cls: 0.0992  decode.d6.loss_mask: 0.2395  decode.d6.loss_dice: 0.2531  decode.d7.loss_cls: 0.1059  decode.d7.loss_mask: 0.2378  decode.d7.loss_dice: 0.2552  decode.d8.loss_cls: 0.1087  decode.d8.loss_mask: 0.2356  decode.d8.loss_dice: 0.2496
07/30 01:27:05 - mmengine - INFO - Iter(train) [16900/80000]  base_lr: 8.0770e-05 lr: 8.0770e-06  eta: 9:19:04  time: 0.5377  data_time: 0.0137  memory: 5916  grad_norm: 169.4264  loss: 8.9783  decode.loss_cls: 0.2325  decode.loss_mask: 0.2537  decode.loss_dice: 0.3254  decode.d0.loss_cls: 0.9572  decode.d0.loss_mask: 0.2241  decode.d0.loss_dice: 0.3184  decode.d1.loss_cls: 0.3909  decode.d1.loss_mask: 0.2176  decode.d1.loss_dice: 0.2993  decode.d2.loss_cls: 0.3038  decode.d2.loss_mask: 0.2604  decode.d2.loss_dice: 0.3197  decode.d3.loss_cls: 0.2242  decode.d3.loss_mask: 0.2964  decode.d3.loss_dice: 0.3064  decode.d4.loss_cls: 0.2226  decode.d4.loss_mask: 0.2693  decode.d4.loss_dice: 0.3108  decode.d5.loss_cls: 0.2359  decode.d5.loss_mask: 0.2580  decode.d5.loss_dice: 0.3012  decode.d6.loss_cls: 0.2082  decode.d6.loss_mask: 0.2687  decode.d6.loss_dice: 0.3150  decode.d7.loss_cls: 0.2161  decode.d7.loss_mask: 0.2794  decode.d7.loss_dice: 0.3036  decode.d8.loss_cls: 0.2790  decode.d8.loss_mask: 0.2695  decode.d8.loss_dice: 0.3110
07/30 01:27:32 - mmengine - INFO - Iter(train) [16950/80000]  base_lr: 8.0712e-05 lr: 8.0712e-06  eta: 9:18:39  time: 0.5425  data_time: 0.0141  memory: 5933  grad_norm: 110.2460  loss: 9.8022  decode.loss_cls: 0.3803  decode.loss_mask: 0.2189  decode.loss_dice: 0.3370  decode.d0.loss_cls: 1.0415  decode.d0.loss_mask: 0.2260  decode.d0.loss_dice: 0.3477  decode.d1.loss_cls: 0.4271  decode.d1.loss_mask: 0.2219  decode.d1.loss_dice: 0.3477  decode.d2.loss_cls: 0.3750  decode.d2.loss_mask: 0.2212  decode.d2.loss_dice: 0.3434  decode.d3.loss_cls: 0.3443  decode.d3.loss_mask: 0.2166  decode.d3.loss_dice: 0.3234  decode.d4.loss_cls: 0.3493  decode.d4.loss_mask: 0.2154  decode.d4.loss_dice: 0.3287  decode.d5.loss_cls: 0.3153  decode.d5.loss_mask: 0.2133  decode.d5.loss_dice: 0.3139  decode.d6.loss_cls: 0.3742  decode.d6.loss_mask: 0.2218  decode.d6.loss_dice: 0.3528  decode.d7.loss_cls: 0.3253  decode.d7.loss_mask: 0.2231  decode.d7.loss_dice: 0.3178  decode.d8.loss_cls: 0.3073  decode.d8.loss_mask: 0.2276  decode.d8.loss_dice: 0.3443
07/30 01:27:59 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/30 01:27:59 - mmengine - INFO - Iter(train) [17000/80000]  base_lr: 8.0655e-05 lr: 8.0655e-06  eta: 9:18:14  time: 0.5392  data_time: 0.0141  memory: 5919  grad_norm: 153.6343  loss: 8.6556  decode.loss_cls: 0.3218  decode.loss_mask: 0.2118  decode.loss_dice: 0.3020  decode.d0.loss_cls: 1.1119  decode.d0.loss_mask: 0.2094  decode.d0.loss_dice: 0.2952  decode.d1.loss_cls: 0.3993  decode.d1.loss_mask: 0.2161  decode.d1.loss_dice: 0.2975  decode.d2.loss_cls: 0.2243  decode.d2.loss_mask: 0.2275  decode.d2.loss_dice: 0.3068  decode.d3.loss_cls: 0.2037  decode.d3.loss_mask: 0.2198  decode.d3.loss_dice: 0.3300  decode.d4.loss_cls: 0.2224  decode.d4.loss_mask: 0.2149  decode.d4.loss_dice: 0.3251  decode.d5.loss_cls: 0.2479  decode.d5.loss_mask: 0.2119  decode.d5.loss_dice: 0.3170  decode.d6.loss_cls: 0.2402  decode.d6.loss_mask: 0.2107  decode.d6.loss_dice: 0.2869  decode.d7.loss_cls: 0.2227  decode.d7.loss_mask: 0.2202  decode.d7.loss_dice: 0.3125  decode.d8.loss_cls: 0.2255  decode.d8.loss_mask: 0.2111  decode.d8.loss_dice: 0.3096
07/30 01:28:26 - mmengine - INFO - Iter(train) [17050/80000]  base_lr: 8.0597e-05 lr: 8.0597e-06  eta: 9:17:48  time: 0.5359  data_time: 0.0137  memory: 5916  grad_norm: 100.5181  loss: 7.2287  decode.loss_cls: 0.0920  decode.loss_mask: 0.2453  decode.loss_dice: 0.2694  decode.d0.loss_cls: 0.9758  decode.d0.loss_mask: 0.2502  decode.d0.loss_dice: 0.2933  decode.d1.loss_cls: 0.1650  decode.d1.loss_mask: 0.2417  decode.d1.loss_dice: 0.2737  decode.d2.loss_cls: 0.1995  decode.d2.loss_mask: 0.2427  decode.d2.loss_dice: 0.2737  decode.d3.loss_cls: 0.1588  decode.d3.loss_mask: 0.2494  decode.d3.loss_dice: 0.2786  decode.d4.loss_cls: 0.0780  decode.d4.loss_mask: 0.2471  decode.d4.loss_dice: 0.2722  decode.d5.loss_cls: 0.0799  decode.d5.loss_mask: 0.2457  decode.d5.loss_dice: 0.2823  decode.d6.loss_cls: 0.0783  decode.d6.loss_mask: 0.2476  decode.d6.loss_dice: 0.2669  decode.d7.loss_cls: 0.0736  decode.d7.loss_mask: 0.2478  decode.d7.loss_dice: 0.2690  decode.d8.loss_cls: 0.0954  decode.d8.loss_mask: 0.2496  decode.d8.loss_dice: 0.2861
07/30 01:28:53 - mmengine - INFO - Iter(train) [17100/80000]  base_lr: 8.0540e-05 lr: 8.0540e-06  eta: 9:17:22  time: 0.5356  data_time: 0.0134  memory: 5918  grad_norm: 76.5099  loss: 7.1076  decode.loss_cls: 0.0875  decode.loss_mask: 0.2667  decode.loss_dice: 0.2595  decode.d0.loss_cls: 0.9206  decode.d0.loss_mask: 0.2727  decode.d0.loss_dice: 0.2693  decode.d1.loss_cls: 0.1423  decode.d1.loss_mask: 0.2728  decode.d1.loss_dice: 0.2609  decode.d2.loss_cls: 0.1075  decode.d2.loss_mask: 0.2668  decode.d2.loss_dice: 0.2665  decode.d3.loss_cls: 0.1187  decode.d3.loss_mask: 0.2672  decode.d3.loss_dice: 0.2557  decode.d4.loss_cls: 0.0833  decode.d4.loss_mask: 0.2666  decode.d4.loss_dice: 0.2554  decode.d5.loss_cls: 0.0800  decode.d5.loss_mask: 0.2643  decode.d5.loss_dice: 0.2670  decode.d6.loss_cls: 0.0974  decode.d6.loss_mask: 0.2655  decode.d6.loss_dice: 0.2482  decode.d7.loss_cls: 0.0905  decode.d7.loss_mask: 0.2664  decode.d7.loss_dice: 0.2560  decode.d8.loss_cls: 0.1042  decode.d8.loss_mask: 0.2677  decode.d8.loss_dice: 0.2604
07/30 01:29:19 - mmengine - INFO - Iter(train) [17150/80000]  base_lr: 8.0482e-05 lr: 8.0482e-06  eta: 9:16:56  time: 0.5379  data_time: 0.0135  memory: 5897  grad_norm: 156.8694  loss: 7.1258  decode.loss_cls: 0.1481  decode.loss_mask: 0.1958  decode.loss_dice: 0.2539  decode.d0.loss_cls: 0.9236  decode.d0.loss_mask: 0.1967  decode.d0.loss_dice: 0.2674  decode.d1.loss_cls: 0.3393  decode.d1.loss_mask: 0.2028  decode.d1.loss_dice: 0.2580  decode.d2.loss_cls: 0.2196  decode.d2.loss_mask: 0.1965  decode.d2.loss_dice: 0.2485  decode.d3.loss_cls: 0.2042  decode.d3.loss_mask: 0.2006  decode.d3.loss_dice: 0.2460  decode.d4.loss_cls: 0.1912  decode.d4.loss_mask: 0.2034  decode.d4.loss_dice: 0.2477  decode.d5.loss_cls: 0.1663  decode.d5.loss_mask: 0.1991  decode.d5.loss_dice: 0.2483  decode.d6.loss_cls: 0.1400  decode.d6.loss_mask: 0.1991  decode.d6.loss_dice: 0.2541  decode.d7.loss_cls: 0.1415  decode.d7.loss_mask: 0.1989  decode.d7.loss_dice: 0.2479  decode.d8.loss_cls: 0.1369  decode.d8.loss_mask: 0.1969  decode.d8.loss_dice: 0.2536
07/30 01:29:46 - mmengine - INFO - Iter(train) [17200/80000]  base_lr: 8.0424e-05 lr: 8.0424e-06  eta: 9:16:29  time: 0.5337  data_time: 0.0134  memory: 5897  grad_norm: 117.6448  loss: 8.6697  decode.loss_cls: 0.1442  decode.loss_mask: 0.2754  decode.loss_dice: 0.3081  decode.d0.loss_cls: 0.9834  decode.d0.loss_mask: 0.2644  decode.d0.loss_dice: 0.3142  decode.d1.loss_cls: 0.2820  decode.d1.loss_mask: 0.2461  decode.d1.loss_dice: 0.2994  decode.d2.loss_cls: 0.2079  decode.d2.loss_mask: 0.2833  decode.d2.loss_dice: 0.3170  decode.d3.loss_cls: 0.3390  decode.d3.loss_mask: 0.2408  decode.d3.loss_dice: 0.3037  decode.d4.loss_cls: 0.2363  decode.d4.loss_mask: 0.2396  decode.d4.loss_dice: 0.2872  decode.d5.loss_cls: 0.2336  decode.d5.loss_mask: 0.2399  decode.d5.loss_dice: 0.2969  decode.d6.loss_cls: 0.2071  decode.d6.loss_mask: 0.2444  decode.d6.loss_dice: 0.3070  decode.d7.loss_cls: 0.2407  decode.d7.loss_mask: 0.2435  decode.d7.loss_dice: 0.2898  decode.d8.loss_cls: 0.2445  decode.d8.loss_mask: 0.2423  decode.d8.loss_dice: 0.3078
07/30 01:30:13 - mmengine - INFO - Iter(train) [17250/80000]  base_lr: 8.0367e-05 lr: 8.0367e-06  eta: 9:16:03  time: 0.5335  data_time: 0.0140  memory: 5896  grad_norm: 191.0748  loss: 8.4281  decode.loss_cls: 0.2300  decode.loss_mask: 0.2616  decode.loss_dice: 0.2620  decode.d0.loss_cls: 0.9975  decode.d0.loss_mask: 0.2671  decode.d0.loss_dice: 0.2740  decode.d1.loss_cls: 0.2836  decode.d1.loss_mask: 0.2660  decode.d1.loss_dice: 0.2752  decode.d2.loss_cls: 0.2871  decode.d2.loss_mask: 0.2797  decode.d2.loss_dice: 0.2785  decode.d3.loss_cls: 0.2764  decode.d3.loss_mask: 0.2639  decode.d3.loss_dice: 0.2542  decode.d4.loss_cls: 0.2184  decode.d4.loss_mask: 0.2677  decode.d4.loss_dice: 0.2860  decode.d5.loss_cls: 0.1946  decode.d5.loss_mask: 0.2627  decode.d5.loss_dice: 0.2642  decode.d6.loss_cls: 0.2060  decode.d6.loss_mask: 0.2614  decode.d6.loss_dice: 0.2698  decode.d7.loss_cls: 0.1852  decode.d7.loss_mask: 0.2591  decode.d7.loss_dice: 0.2704  decode.d8.loss_cls: 0.1879  decode.d8.loss_mask: 0.2639  decode.d8.loss_dice: 0.2739
07/30 01:30:39 - mmengine - INFO - Iter(train) [17300/80000]  base_lr: 8.0309e-05 lr: 8.0309e-06  eta: 9:15:37  time: 0.5390  data_time: 0.0136  memory: 5916  grad_norm: 264.3694  loss: 11.3841  decode.loss_cls: 0.2462  decode.loss_mask: 0.3779  decode.loss_dice: 0.3859  decode.d0.loss_cls: 1.0488  decode.d0.loss_mask: 0.3794  decode.d0.loss_dice: 0.4674  decode.d1.loss_cls: 0.2661  decode.d1.loss_mask: 0.3716  decode.d1.loss_dice: 0.4135  decode.d2.loss_cls: 0.3145  decode.d2.loss_mask: 0.3625  decode.d2.loss_dice: 0.4119  decode.d3.loss_cls: 0.2300  decode.d3.loss_mask: 0.3727  decode.d3.loss_dice: 0.4078  decode.d4.loss_cls: 0.2955  decode.d4.loss_mask: 0.3762  decode.d4.loss_dice: 0.4266  decode.d5.loss_cls: 0.2603  decode.d5.loss_mask: 0.4007  decode.d5.loss_dice: 0.4108  decode.d6.loss_cls: 0.2665  decode.d6.loss_mask: 0.3876  decode.d6.loss_dice: 0.3782  decode.d7.loss_cls: 0.2782  decode.d7.loss_mask: 0.3986  decode.d7.loss_dice: 0.3771  decode.d8.loss_cls: 0.2621  decode.d8.loss_mask: 0.3973  decode.d8.loss_dice: 0.4123
07/30 01:31:06 - mmengine - INFO - Iter(train) [17350/80000]  base_lr: 8.0251e-05 lr: 8.0251e-06  eta: 9:15:11  time: 0.5377  data_time: 0.0140  memory: 5918  grad_norm: 106.8787  loss: 8.3072  decode.loss_cls: 0.1677  decode.loss_mask: 0.2501  decode.loss_dice: 0.2666  decode.d0.loss_cls: 1.0778  decode.d0.loss_mask: 0.2616  decode.d0.loss_dice: 0.2806  decode.d1.loss_cls: 0.2571  decode.d1.loss_mask: 0.2511  decode.d1.loss_dice: 0.2585  decode.d2.loss_cls: 0.2539  decode.d2.loss_mask: 0.2486  decode.d2.loss_dice: 0.2725  decode.d3.loss_cls: 0.2094  decode.d3.loss_mask: 0.2504  decode.d3.loss_dice: 0.2697  decode.d4.loss_cls: 0.2186  decode.d4.loss_mask: 0.2512  decode.d4.loss_dice: 0.2716  decode.d5.loss_cls: 0.2159  decode.d5.loss_mask: 0.2485  decode.d5.loss_dice: 0.2614  decode.d6.loss_cls: 0.2695  decode.d6.loss_mask: 0.2459  decode.d6.loss_dice: 0.2528  decode.d7.loss_cls: 0.2242  decode.d7.loss_mask: 0.2499  decode.d7.loss_dice: 0.2715  decode.d8.loss_cls: 0.2000  decode.d8.loss_mask: 0.2573  decode.d8.loss_dice: 0.2936
07/30 01:31:33 - mmengine - INFO - Iter(train) [17400/80000]  base_lr: 8.0194e-05 lr: 8.0194e-06  eta: 9:14:45  time: 0.5344  data_time: 0.0138  memory: 5898  grad_norm: 139.2162  loss: 8.4308  decode.loss_cls: 0.2698  decode.loss_mask: 0.2266  decode.loss_dice: 0.2579  decode.d0.loss_cls: 1.0956  decode.d0.loss_mask: 0.2454  decode.d0.loss_dice: 0.3247  decode.d1.loss_cls: 0.3108  decode.d1.loss_mask: 0.2373  decode.d1.loss_dice: 0.2753  decode.d2.loss_cls: 0.3119  decode.d2.loss_mask: 0.2252  decode.d2.loss_dice: 0.2613  decode.d3.loss_cls: 0.3265  decode.d3.loss_mask: 0.2259  decode.d3.loss_dice: 0.2493  decode.d4.loss_cls: 0.2896  decode.d4.loss_mask: 0.2262  decode.d4.loss_dice: 0.2641  decode.d5.loss_cls: 0.2305  decode.d5.loss_mask: 0.2286  decode.d5.loss_dice: 0.2687  decode.d6.loss_cls: 0.1781  decode.d6.loss_mask: 0.2250  decode.d6.loss_dice: 0.2645  decode.d7.loss_cls: 0.2203  decode.d7.loss_mask: 0.2269  decode.d7.loss_dice: 0.2848  decode.d8.loss_cls: 0.1885  decode.d8.loss_mask: 0.2259  decode.d8.loss_dice: 0.2655
07/30 01:32:00 - mmengine - INFO - Iter(train) [17450/80000]  base_lr: 8.0136e-05 lr: 8.0136e-06  eta: 9:14:19  time: 0.5373  data_time: 0.0136  memory: 5899  grad_norm: 137.3274  loss: 11.9490  decode.loss_cls: 0.3833  decode.loss_mask: 0.4005  decode.loss_dice: 0.4286  decode.d0.loss_cls: 1.0848  decode.d0.loss_mask: 0.2829  decode.d0.loss_dice: 0.4497  decode.d1.loss_cls: 0.4833  decode.d1.loss_mask: 0.3121  decode.d1.loss_dice: 0.4488  decode.d2.loss_cls: 0.3891  decode.d2.loss_mask: 0.3183  decode.d2.loss_dice: 0.4562  decode.d3.loss_cls: 0.3628  decode.d3.loss_mask: 0.3569  decode.d3.loss_dice: 0.4422  decode.d4.loss_cls: 0.3412  decode.d4.loss_mask: 0.2960  decode.d4.loss_dice: 0.4115  decode.d5.loss_cls: 0.3205  decode.d5.loss_mask: 0.3338  decode.d5.loss_dice: 0.4222  decode.d6.loss_cls: 0.3169  decode.d6.loss_mask: 0.3909  decode.d6.loss_dice: 0.4095  decode.d7.loss_cls: 0.3588  decode.d7.loss_mask: 0.2794  decode.d7.loss_dice: 0.4202  decode.d8.loss_cls: 0.3478  decode.d8.loss_mask: 0.2861  decode.d8.loss_dice: 0.4147
07/30 01:32:26 - mmengine - INFO - Iter(train) [17500/80000]  base_lr: 8.0078e-05 lr: 8.0078e-06  eta: 9:13:53  time: 0.5331  data_time: 0.0134  memory: 5879  grad_norm: 75.5209  loss: 6.2010  decode.loss_cls: 0.0566  decode.loss_mask: 0.2341  decode.loss_dice: 0.2203  decode.d0.loss_cls: 0.9029  decode.d0.loss_mask: 0.2456  decode.d0.loss_dice: 0.2415  decode.d1.loss_cls: 0.1253  decode.d1.loss_mask: 0.2349  decode.d1.loss_dice: 0.2304  decode.d2.loss_cls: 0.1046  decode.d2.loss_mask: 0.2351  decode.d2.loss_dice: 0.2255  decode.d3.loss_cls: 0.0533  decode.d3.loss_mask: 0.2353  decode.d3.loss_dice: 0.2208  decode.d4.loss_cls: 0.0544  decode.d4.loss_mask: 0.2322  decode.d4.loss_dice: 0.2186  decode.d5.loss_cls: 0.0485  decode.d5.loss_mask: 0.2370  decode.d5.loss_dice: 0.2207  decode.d6.loss_cls: 0.0842  decode.d6.loss_mask: 0.2339  decode.d6.loss_dice: 0.2185  decode.d7.loss_cls: 0.0893  decode.d7.loss_mask: 0.2364  decode.d7.loss_dice: 0.2255  decode.d8.loss_cls: 0.0799  decode.d8.loss_mask: 0.2344  decode.d8.loss_dice: 0.2214
07/30 01:32:53 - mmengine - INFO - Iter(train) [17550/80000]  base_lr: 8.0021e-05 lr: 8.0021e-06  eta: 9:13:26  time: 0.5314  data_time: 0.0130  memory: 5971  grad_norm: 122.9020  loss: 8.6202  decode.loss_cls: 0.1929  decode.loss_mask: 0.2496  decode.loss_dice: 0.2781  decode.d0.loss_cls: 1.0857  decode.d0.loss_mask: 0.2568  decode.d0.loss_dice: 0.3453  decode.d1.loss_cls: 0.4173  decode.d1.loss_mask: 0.2526  decode.d1.loss_dice: 0.2843  decode.d2.loss_cls: 0.2811  decode.d2.loss_mask: 0.2498  decode.d2.loss_dice: 0.2794  decode.d3.loss_cls: 0.2071  decode.d3.loss_mask: 0.2500  decode.d3.loss_dice: 0.2924  decode.d4.loss_cls: 0.2045  decode.d4.loss_mask: 0.2483  decode.d4.loss_dice: 0.2809  decode.d5.loss_cls: 0.2300  decode.d5.loss_mask: 0.2489  decode.d5.loss_dice: 0.2878  decode.d6.loss_cls: 0.1921  decode.d6.loss_mask: 0.2533  decode.d6.loss_dice: 0.2833  decode.d7.loss_cls: 0.2047  decode.d7.loss_mask: 0.2488  decode.d7.loss_dice: 0.2818  decode.d8.loss_cls: 0.2098  decode.d8.loss_mask: 0.2498  decode.d8.loss_dice: 0.2740
07/30 01:33:20 - mmengine - INFO - Iter(train) [17600/80000]  base_lr: 7.9963e-05 lr: 7.9963e-06  eta: 9:13:00  time: 0.5287  data_time: 0.0131  memory: 5882  grad_norm: 101.9461  loss: 8.4322  decode.loss_cls: 0.2559  decode.loss_mask: 0.2448  decode.loss_dice: 0.2645  decode.d0.loss_cls: 1.1368  decode.d0.loss_mask: 0.2614  decode.d0.loss_dice: 0.2919  decode.d1.loss_cls: 0.2544  decode.d1.loss_mask: 0.2531  decode.d1.loss_dice: 0.2775  decode.d2.loss_cls: 0.2484  decode.d2.loss_mask: 0.2499  decode.d2.loss_dice: 0.2781  decode.d3.loss_cls: 0.1837  decode.d3.loss_mask: 0.2525  decode.d3.loss_dice: 0.2777  decode.d4.loss_cls: 0.2085  decode.d4.loss_mask: 0.2489  decode.d4.loss_dice: 0.2647  decode.d5.loss_cls: 0.2103  decode.d5.loss_mask: 0.2456  decode.d5.loss_dice: 0.2714  decode.d6.loss_cls: 0.2144  decode.d6.loss_mask: 0.2462  decode.d6.loss_dice: 0.2741  decode.d7.loss_cls: 0.2251  decode.d7.loss_mask: 0.2455  decode.d7.loss_dice: 0.2654  decode.d8.loss_cls: 0.2479  decode.d8.loss_mask: 0.2446  decode.d8.loss_dice: 0.2891
07/30 01:33:46 - mmengine - INFO - Iter(train) [17650/80000]  base_lr: 7.9906e-05 lr: 7.9906e-06  eta: 9:12:34  time: 0.5353  data_time: 0.0132  memory: 5919  grad_norm: 62.9699  loss: 5.8555  decode.loss_cls: 0.0572  decode.loss_mask: 0.2223  decode.loss_dice: 0.2198  decode.d0.loss_cls: 0.8002  decode.d0.loss_mask: 0.2335  decode.d0.loss_dice: 0.2489  decode.d1.loss_cls: 0.1307  decode.d1.loss_mask: 0.2235  decode.d1.loss_dice: 0.2295  decode.d2.loss_cls: 0.0867  decode.d2.loss_mask: 0.2231  decode.d2.loss_dice: 0.2262  decode.d3.loss_cls: 0.0673  decode.d3.loss_mask: 0.2251  decode.d3.loss_dice: 0.2273  decode.d4.loss_cls: 0.0394  decode.d4.loss_mask: 0.2246  decode.d4.loss_dice: 0.2227  decode.d5.loss_cls: 0.0466  decode.d5.loss_mask: 0.2223  decode.d5.loss_dice: 0.2183  decode.d6.loss_cls: 0.0479  decode.d6.loss_mask: 0.2172  decode.d6.loss_dice: 0.2163  decode.d7.loss_cls: 0.0446  decode.d7.loss_mask: 0.2223  decode.d7.loss_dice: 0.2210  decode.d8.loss_cls: 0.0469  decode.d8.loss_mask: 0.2200  decode.d8.loss_dice: 0.2238
07/30 01:34:13 - mmengine - INFO - Iter(train) [17700/80000]  base_lr: 7.9848e-05 lr: 7.9848e-06  eta: 9:12:08  time: 0.5283  data_time: 0.0131  memory: 5898  grad_norm: 90.5088  loss: 7.1721  decode.loss_cls: 0.0978  decode.loss_mask: 0.2451  decode.loss_dice: 0.2676  decode.d0.loss_cls: 0.9880  decode.d0.loss_mask: 0.2504  decode.d0.loss_dice: 0.2710  decode.d1.loss_cls: 0.2281  decode.d1.loss_mask: 0.2428  decode.d1.loss_dice: 0.2297  decode.d2.loss_cls: 0.1368  decode.d2.loss_mask: 0.2450  decode.d2.loss_dice: 0.2451  decode.d3.loss_cls: 0.1340  decode.d3.loss_mask: 0.2444  decode.d3.loss_dice: 0.2278  decode.d4.loss_cls: 0.1224  decode.d4.loss_mask: 0.2450  decode.d4.loss_dice: 0.2288  decode.d5.loss_cls: 0.1331  decode.d5.loss_mask: 0.2443  decode.d5.loss_dice: 0.2362  decode.d6.loss_cls: 0.1279  decode.d6.loss_mask: 0.2471  decode.d6.loss_dice: 0.2482  decode.d7.loss_cls: 0.1877  decode.d7.loss_mask: 0.2487  decode.d7.loss_dice: 0.2290  decode.d8.loss_cls: 0.1332  decode.d8.loss_mask: 0.2470  decode.d8.loss_dice: 0.2397
07/30 01:34:40 - mmengine - INFO - Iter(train) [17750/80000]  base_lr: 7.9790e-05 lr: 7.9790e-06  eta: 9:11:42  time: 0.5312  data_time: 0.0135  memory: 5936  grad_norm: 178.1724  loss: 8.8320  decode.loss_cls: 0.2408  decode.loss_mask: 0.2668  decode.loss_dice: 0.2919  decode.d0.loss_cls: 1.0857  decode.d0.loss_mask: 0.2492  decode.d0.loss_dice: 0.3003  decode.d1.loss_cls: 0.3007  decode.d1.loss_mask: 0.2601  decode.d1.loss_dice: 0.2869  decode.d2.loss_cls: 0.1998  decode.d2.loss_mask: 0.2791  decode.d2.loss_dice: 0.3048  decode.d3.loss_cls: 0.2470  decode.d3.loss_mask: 0.2803  decode.d3.loss_dice: 0.2855  decode.d4.loss_cls: 0.2307  decode.d4.loss_mask: 0.2772  decode.d4.loss_dice: 0.2863  decode.d5.loss_cls: 0.2036  decode.d5.loss_mask: 0.2669  decode.d5.loss_dice: 0.3007  decode.d6.loss_cls: 0.2216  decode.d6.loss_mask: 0.2622  decode.d6.loss_dice: 0.2785  decode.d7.loss_cls: 0.2798  decode.d7.loss_mask: 0.2679  decode.d7.loss_dice: 0.2792  decode.d8.loss_cls: 0.2207  decode.d8.loss_mask: 0.2668  decode.d8.loss_dice: 0.3107
07/30 01:35:06 - mmengine - INFO - Iter(train) [17800/80000]  base_lr: 7.9732e-05 lr: 7.9732e-06  eta: 9:11:15  time: 0.5272  data_time: 0.0133  memory: 5916  grad_norm: 158.9384  loss: 12.3682  decode.loss_cls: 0.4202  decode.loss_mask: 0.3405  decode.loss_dice: 0.4197  decode.d0.loss_cls: 1.1661  decode.d0.loss_mask: 0.3295  decode.d0.loss_dice: 0.4326  decode.d1.loss_cls: 0.5872  decode.d1.loss_mask: 0.2898  decode.d1.loss_dice: 0.3921  decode.d2.loss_cls: 0.5669  decode.d2.loss_mask: 0.2451  decode.d2.loss_dice: 0.3948  decode.d3.loss_cls: 0.4514  decode.d3.loss_mask: 0.3144  decode.d3.loss_dice: 0.4304  decode.d4.loss_cls: 0.3895  decode.d4.loss_mask: 0.2973  decode.d4.loss_dice: 0.4043  decode.d5.loss_cls: 0.4679  decode.d5.loss_mask: 0.2941  decode.d5.loss_dice: 0.4385  decode.d6.loss_cls: 0.3922  decode.d6.loss_mask: 0.2905  decode.d6.loss_dice: 0.4098  decode.d7.loss_cls: 0.3768  decode.d7.loss_mask: 0.2943  decode.d7.loss_dice: 0.3465  decode.d8.loss_cls: 0.4427  decode.d8.loss_mask: 0.3440  decode.d8.loss_dice: 0.3989
07/30 01:35:33 - mmengine - INFO - Iter(train) [17850/80000]  base_lr: 7.9675e-05 lr: 7.9675e-06  eta: 9:10:48  time: 0.5285  data_time: 0.0134  memory: 5931  grad_norm: 169.2731  loss: 9.5905  decode.loss_cls: 0.2348  decode.loss_mask: 0.3284  decode.loss_dice: 0.3319  decode.d0.loss_cls: 1.2166  decode.d0.loss_mask: 0.3380  decode.d0.loss_dice: 0.3790  decode.d1.loss_cls: 0.2301  decode.d1.loss_mask: 0.3309  decode.d1.loss_dice: 0.3357  decode.d2.loss_cls: 0.1963  decode.d2.loss_mask: 0.3251  decode.d2.loss_dice: 0.3196  decode.d3.loss_cls: 0.1451  decode.d3.loss_mask: 0.3219  decode.d3.loss_dice: 0.3608  decode.d4.loss_cls: 0.1900  decode.d4.loss_mask: 0.3196  decode.d4.loss_dice: 0.3526  decode.d5.loss_cls: 0.1641  decode.d5.loss_mask: 0.3222  decode.d5.loss_dice: 0.3479  decode.d6.loss_cls: 0.1472  decode.d6.loss_mask: 0.3247  decode.d6.loss_dice: 0.3524  decode.d7.loss_cls: 0.1733  decode.d7.loss_mask: 0.3305  decode.d7.loss_dice: 0.3475  decode.d8.loss_cls: 0.1699  decode.d8.loss_mask: 0.3267  decode.d8.loss_dice: 0.3277
07/30 01:35:59 - mmengine - INFO - Iter(train) [17900/80000]  base_lr: 7.9617e-05 lr: 7.9617e-06  eta: 9:10:20  time: 0.5283  data_time: 0.0131  memory: 5918  grad_norm: 88.5963  loss: 6.7635  decode.loss_cls: 0.0763  decode.loss_mask: 0.2260  decode.loss_dice: 0.2487  decode.d0.loss_cls: 1.0514  decode.d0.loss_mask: 0.2351  decode.d0.loss_dice: 0.2814  decode.d1.loss_cls: 0.2148  decode.d1.loss_mask: 0.2267  decode.d1.loss_dice: 0.2492  decode.d2.loss_cls: 0.1374  decode.d2.loss_mask: 0.2225  decode.d2.loss_dice: 0.2557  decode.d3.loss_cls: 0.0868  decode.d3.loss_mask: 0.2232  decode.d3.loss_dice: 0.2701  decode.d4.loss_cls: 0.0853  decode.d4.loss_mask: 0.2203  decode.d4.loss_dice: 0.2493  decode.d5.loss_cls: 0.0747  decode.d5.loss_mask: 0.2193  decode.d5.loss_dice: 0.2434  decode.d6.loss_cls: 0.0778  decode.d6.loss_mask: 0.2195  decode.d6.loss_dice: 0.2365  decode.d7.loss_cls: 0.0937  decode.d7.loss_mask: 0.2299  decode.d7.loss_dice: 0.2565  decode.d8.loss_cls: 0.0927  decode.d8.loss_mask: 0.2242  decode.d8.loss_dice: 0.2353
07/30 01:36:25 - mmengine - INFO - Iter(train) [17950/80000]  base_lr: 7.9559e-05 lr: 7.9559e-06  eta: 9:09:53  time: 0.5226  data_time: 0.0127  memory: 5918  grad_norm: 177.4430  loss: 7.1852  decode.loss_cls: 0.1105  decode.loss_mask: 0.2168  decode.loss_dice: 0.3027  decode.d0.loss_cls: 1.0377  decode.d0.loss_mask: 0.2187  decode.d0.loss_dice: 0.3074  decode.d1.loss_cls: 0.1989  decode.d1.loss_mask: 0.2220  decode.d1.loss_dice: 0.3125  decode.d2.loss_cls: 0.1172  decode.d2.loss_mask: 0.2143  decode.d2.loss_dice: 0.2926  decode.d3.loss_cls: 0.0795  decode.d3.loss_mask: 0.2168  decode.d3.loss_dice: 0.3093  decode.d4.loss_cls: 0.0588  decode.d4.loss_mask: 0.2132  decode.d4.loss_dice: 0.2885  decode.d5.loss_cls: 0.0748  decode.d5.loss_mask: 0.2144  decode.d5.loss_dice: 0.2978  decode.d6.loss_cls: 0.0812  decode.d6.loss_mask: 0.2168  decode.d6.loss_dice: 0.3165  decode.d7.loss_cls: 0.0734  decode.d7.loss_mask: 0.2362  decode.d7.loss_dice: 0.3257  decode.d8.loss_cls: 0.0401  decode.d8.loss_mask: 0.2627  decode.d8.loss_dice: 0.3280
07/30 01:36:52 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/30 01:36:52 - mmengine - INFO - Iter(train) [18000/80000]  base_lr: 7.9502e-05 lr: 7.9502e-06  eta: 9:09:26  time: 0.5393  data_time: 0.0135  memory: 5931  grad_norm: 83.0592  loss: 6.1105  decode.loss_cls: 0.1165  decode.loss_mask: 0.1641  decode.loss_dice: 0.2452  decode.d0.loss_cls: 0.9278  decode.d0.loss_mask: 0.1710  decode.d0.loss_dice: 0.2995  decode.d1.loss_cls: 0.2107  decode.d1.loss_mask: 0.1659  decode.d1.loss_dice: 0.2610  decode.d2.loss_cls: 0.0891  decode.d2.loss_mask: 0.1648  decode.d2.loss_dice: 0.2579  decode.d3.loss_cls: 0.0985  decode.d3.loss_mask: 0.1641  decode.d3.loss_dice: 0.2567  decode.d4.loss_cls: 0.0847  decode.d4.loss_mask: 0.1632  decode.d4.loss_dice: 0.2478  decode.d5.loss_cls: 0.1034  decode.d5.loss_mask: 0.1625  decode.d5.loss_dice: 0.2383  decode.d6.loss_cls: 0.0426  decode.d6.loss_mask: 0.1623  decode.d6.loss_dice: 0.2639  decode.d7.loss_cls: 0.0904  decode.d7.loss_mask: 0.1654  decode.d7.loss_dice: 0.2598  decode.d8.loss_cls: 0.1187  decode.d8.loss_mask: 0.1642  decode.d8.loss_dice: 0.2506
07/30 01:37:19 - mmengine - INFO - Iter(train) [18050/80000]  base_lr: 7.9444e-05 lr: 7.9444e-06  eta: 9:09:01  time: 0.5356  data_time: 0.0133  memory: 5882  grad_norm: 140.6812  loss: 6.9672  decode.loss_cls: 0.0365  decode.loss_mask: 0.3164  decode.loss_dice: 0.2562  decode.d0.loss_cls: 0.8073  decode.d0.loss_mask: 0.3473  decode.d0.loss_dice: 0.2735  decode.d1.loss_cls: 0.1020  decode.d1.loss_mask: 0.3069  decode.d1.loss_dice: 0.2561  decode.d2.loss_cls: 0.0693  decode.d2.loss_mask: 0.3092  decode.d2.loss_dice: 0.2477  decode.d3.loss_cls: 0.0264  decode.d3.loss_mask: 0.3168  decode.d3.loss_dice: 0.2589  decode.d4.loss_cls: 0.0313  decode.d4.loss_mask: 0.3143  decode.d4.loss_dice: 0.2566  decode.d5.loss_cls: 0.0357  decode.d5.loss_mask: 0.3175  decode.d5.loss_dice: 0.2583  decode.d6.loss_cls: 0.0275  decode.d6.loss_mask: 0.3197  decode.d6.loss_dice: 0.2574  decode.d7.loss_cls: 0.0345  decode.d7.loss_mask: 0.3124  decode.d7.loss_dice: 0.2563  decode.d8.loss_cls: 0.0340  decode.d8.loss_mask: 0.3187  decode.d8.loss_dice: 0.2624
07/30 01:37:46 - mmengine - INFO - Iter(train) [18100/80000]  base_lr: 7.9386e-05 lr: 7.9386e-06  eta: 9:08:34  time: 0.5369  data_time: 0.0140  memory: 5916  grad_norm: 172.0847  loss: 8.6561  decode.loss_cls: 0.1842  decode.loss_mask: 0.2903  decode.loss_dice: 0.3177  decode.d0.loss_cls: 0.9535  decode.d0.loss_mask: 0.3147  decode.d0.loss_dice: 0.3228  decode.d1.loss_cls: 0.3103  decode.d1.loss_mask: 0.2973  decode.d1.loss_dice: 0.3090  decode.d2.loss_cls: 0.1444  decode.d2.loss_mask: 0.2961  decode.d2.loss_dice: 0.3145  decode.d3.loss_cls: 0.1556  decode.d3.loss_mask: 0.2948  decode.d3.loss_dice: 0.3181  decode.d4.loss_cls: 0.1647  decode.d4.loss_mask: 0.2932  decode.d4.loss_dice: 0.2946  decode.d5.loss_cls: 0.1588  decode.d5.loss_mask: 0.2926  decode.d5.loss_dice: 0.3062  decode.d6.loss_cls: 0.1556  decode.d6.loss_mask: 0.2970  decode.d6.loss_dice: 0.3053  decode.d7.loss_cls: 0.1616  decode.d7.loss_mask: 0.2902  decode.d7.loss_dice: 0.3131  decode.d8.loss_cls: 0.1956  decode.d8.loss_mask: 0.2922  decode.d8.loss_dice: 0.3121
07/30 01:38:12 - mmengine - INFO - Iter(train) [18150/80000]  base_lr: 7.9329e-05 lr: 7.9329e-06  eta: 9:08:08  time: 0.5333  data_time: 0.0137  memory: 5896  grad_norm: 140.8126  loss: 8.9491  decode.loss_cls: 0.1707  decode.loss_mask: 0.3178  decode.loss_dice: 0.3605  decode.d0.loss_cls: 0.9114  decode.d0.loss_mask: 0.3228  decode.d0.loss_dice: 0.3528  decode.d1.loss_cls: 0.2070  decode.d1.loss_mask: 0.3194  decode.d1.loss_dice: 0.3902  decode.d2.loss_cls: 0.1444  decode.d2.loss_mask: 0.3162  decode.d2.loss_dice: 0.3823  decode.d3.loss_cls: 0.0843  decode.d3.loss_mask: 0.3125  decode.d3.loss_dice: 0.3690  decode.d4.loss_cls: 0.1603  decode.d4.loss_mask: 0.3209  decode.d4.loss_dice: 0.3836  decode.d5.loss_cls: 0.0960  decode.d5.loss_mask: 0.3141  decode.d5.loss_dice: 0.3505  decode.d6.loss_cls: 0.1097  decode.d6.loss_mask: 0.3160  decode.d6.loss_dice: 0.3511  decode.d7.loss_cls: 0.0987  decode.d7.loss_mask: 0.3141  decode.d7.loss_dice: 0.3585  decode.d8.loss_cls: 0.1302  decode.d8.loss_mask: 0.3179  decode.d8.loss_dice: 0.3661
07/30 01:38:39 - mmengine - INFO - Iter(train) [18200/80000]  base_lr: 7.9271e-05 lr: 7.9271e-06  eta: 9:07:41  time: 0.5341  data_time: 0.0136  memory: 5919  grad_norm: 138.1308  loss: 8.1035  decode.loss_cls: 0.1532  decode.loss_mask: 0.2350  decode.loss_dice: 0.3028  decode.d0.loss_cls: 1.1016  decode.d0.loss_mask: 0.2415  decode.d0.loss_dice: 0.3196  decode.d1.loss_cls: 0.1782  decode.d1.loss_mask: 0.2432  decode.d1.loss_dice: 0.3165  decode.d2.loss_cls: 0.2245  decode.d2.loss_mask: 0.2326  decode.d2.loss_dice: 0.2873  decode.d3.loss_cls: 0.1542  decode.d3.loss_mask: 0.2340  decode.d3.loss_dice: 0.2882  decode.d4.loss_cls: 0.1522  decode.d4.loss_mask: 0.2321  decode.d4.loss_dice: 0.3112  decode.d5.loss_cls: 0.1442  decode.d5.loss_mask: 0.2309  decode.d5.loss_dice: 0.2978  decode.d6.loss_cls: 0.1743  decode.d6.loss_mask: 0.2345  decode.d6.loss_dice: 0.3187  decode.d7.loss_cls: 0.1934  decode.d7.loss_mask: 0.2310  decode.d7.loss_dice: 0.3202  decode.d8.loss_cls: 0.2049  decode.d8.loss_mask: 0.2349  decode.d8.loss_dice: 0.3107
07/30 01:39:05 - mmengine - INFO - Iter(train) [18250/80000]  base_lr: 7.9213e-05 lr: 7.9213e-06  eta: 9:07:15  time: 0.5356  data_time: 0.0138  memory: 5933  grad_norm: 127.6235  loss: 9.9826  decode.loss_cls: 0.1532  decode.loss_mask: 0.3606  decode.loss_dice: 0.3877  decode.d0.loss_cls: 1.1208  decode.d0.loss_mask: 0.3215  decode.d0.loss_dice: 0.3986  decode.d1.loss_cls: 0.2615  decode.d1.loss_mask: 0.3444  decode.d1.loss_dice: 0.3793  decode.d2.loss_cls: 0.2201  decode.d2.loss_mask: 0.3658  decode.d2.loss_dice: 0.3597  decode.d3.loss_cls: 0.1304  decode.d3.loss_mask: 0.3566  decode.d3.loss_dice: 0.3778  decode.d4.loss_cls: 0.2088  decode.d4.loss_mask: 0.3344  decode.d4.loss_dice: 0.3658  decode.d5.loss_cls: 0.1761  decode.d5.loss_mask: 0.3296  decode.d5.loss_dice: 0.3615  decode.d6.loss_cls: 0.1909  decode.d6.loss_mask: 0.3264  decode.d6.loss_dice: 0.3599  decode.d7.loss_cls: 0.1873  decode.d7.loss_mask: 0.3368  decode.d7.loss_dice: 0.3610  decode.d8.loss_cls: 0.1678  decode.d8.loss_mask: 0.3668  decode.d8.loss_dice: 0.3716
07/30 01:39:32 - mmengine - INFO - Iter(train) [18300/80000]  base_lr: 7.9155e-05 lr: 7.9155e-06  eta: 9:06:48  time: 0.5333  data_time: 0.0138  memory: 5918  grad_norm: 71.7532  loss: 6.4110  decode.loss_cls: 0.0293  decode.loss_mask: 0.2240  decode.loss_dice: 0.2651  decode.d0.loss_cls: 0.9731  decode.d0.loss_mask: 0.2365  decode.d0.loss_dice: 0.2785  decode.d1.loss_cls: 0.1273  decode.d1.loss_mask: 0.2326  decode.d1.loss_dice: 0.2825  decode.d2.loss_cls: 0.0889  decode.d2.loss_mask: 0.2258  decode.d2.loss_dice: 0.2678  decode.d3.loss_cls: 0.0581  decode.d3.loss_mask: 0.2225  decode.d3.loss_dice: 0.2608  decode.d4.loss_cls: 0.0438  decode.d4.loss_mask: 0.2236  decode.d4.loss_dice: 0.2762  decode.d5.loss_cls: 0.0401  decode.d5.loss_mask: 0.2209  decode.d5.loss_dice: 0.2673  decode.d6.loss_cls: 0.0327  decode.d6.loss_mask: 0.2242  decode.d6.loss_dice: 0.2574  decode.d7.loss_cls: 0.0297  decode.d7.loss_mask: 0.2247  decode.d7.loss_dice: 0.2712  decode.d8.loss_cls: 0.0298  decode.d8.loss_mask: 0.2231  decode.d8.loss_dice: 0.2736
07/30 01:39:59 - mmengine - INFO - Iter(train) [18350/80000]  base_lr: 7.9098e-05 lr: 7.9098e-06  eta: 9:06:22  time: 0.5343  data_time: 0.0137  memory: 5933  grad_norm: 177.6240  loss: 9.3083  decode.loss_cls: 0.2585  decode.loss_mask: 0.2845  decode.loss_dice: 0.2864  decode.d0.loss_cls: 1.0430  decode.d0.loss_mask: 0.2959  decode.d0.loss_dice: 0.3460  decode.d1.loss_cls: 0.3000  decode.d1.loss_mask: 0.3006  decode.d1.loss_dice: 0.3147  decode.d2.loss_cls: 0.2611  decode.d2.loss_mask: 0.2844  decode.d2.loss_dice: 0.3046  decode.d3.loss_cls: 0.2381  decode.d3.loss_mask: 0.2886  decode.d3.loss_dice: 0.2933  decode.d4.loss_cls: 0.2382  decode.d4.loss_mask: 0.2944  decode.d4.loss_dice: 0.3023  decode.d5.loss_cls: 0.2552  decode.d5.loss_mask: 0.2896  decode.d5.loss_dice: 0.2936  decode.d6.loss_cls: 0.2612  decode.d6.loss_mask: 0.2895  decode.d6.loss_dice: 0.2890  decode.d7.loss_cls: 0.2522  decode.d7.loss_mask: 0.2860  decode.d7.loss_dice: 0.2982  decode.d8.loss_cls: 0.2777  decode.d8.loss_mask: 0.2893  decode.d8.loss_dice: 0.2921
07/30 01:40:25 - mmengine - INFO - Iter(train) [18400/80000]  base_lr: 7.9040e-05 lr: 7.9040e-06  eta: 9:05:56  time: 0.5309  data_time: 0.0133  memory: 5897  grad_norm: 52.3494  loss: 6.3803  decode.loss_cls: 0.0819  decode.loss_mask: 0.2230  decode.loss_dice: 0.2333  decode.d0.loss_cls: 0.8149  decode.d0.loss_mask: 0.2334  decode.d0.loss_dice: 0.2822  decode.d1.loss_cls: 0.1270  decode.d1.loss_mask: 0.2259  decode.d1.loss_dice: 0.2443  decode.d2.loss_cls: 0.0838  decode.d2.loss_mask: 0.2236  decode.d2.loss_dice: 0.2323  decode.d3.loss_cls: 0.0895  decode.d3.loss_mask: 0.2237  decode.d3.loss_dice: 0.2299  decode.d4.loss_cls: 0.1054  decode.d4.loss_mask: 0.2238  decode.d4.loss_dice: 0.2364  decode.d5.loss_cls: 0.1098  decode.d5.loss_mask: 0.2258  decode.d5.loss_dice: 0.2343  decode.d6.loss_cls: 0.1225  decode.d6.loss_mask: 0.2248  decode.d6.loss_dice: 0.2267  decode.d7.loss_cls: 0.0852  decode.d7.loss_mask: 0.2253  decode.d7.loss_dice: 0.2303  decode.d8.loss_cls: 0.1058  decode.d8.loss_mask: 0.2244  decode.d8.loss_dice: 0.2512
07/30 01:40:52 - mmengine - INFO - Iter(train) [18450/80000]  base_lr: 7.8982e-05 lr: 7.8982e-06  eta: 9:05:29  time: 0.5289  data_time: 0.0132  memory: 5920  grad_norm: 79.0404  loss: 7.7110  decode.loss_cls: 0.1476  decode.loss_mask: 0.2477  decode.loss_dice: 0.2675  decode.d0.loss_cls: 1.0272  decode.d0.loss_mask: 0.2633  decode.d0.loss_dice: 0.2710  decode.d1.loss_cls: 0.2903  decode.d1.loss_mask: 0.2556  decode.d1.loss_dice: 0.2793  decode.d2.loss_cls: 0.1412  decode.d2.loss_mask: 0.2612  decode.d2.loss_dice: 0.2861  decode.d3.loss_cls: 0.1439  decode.d3.loss_mask: 0.2527  decode.d3.loss_dice: 0.2715  decode.d4.loss_cls: 0.1282  decode.d4.loss_mask: 0.2507  decode.d4.loss_dice: 0.2696  decode.d5.loss_cls: 0.1008  decode.d5.loss_mask: 0.2536  decode.d5.loss_dice: 0.2720  decode.d6.loss_cls: 0.1383  decode.d6.loss_mask: 0.2487  decode.d6.loss_dice: 0.2664  decode.d7.loss_cls: 0.1820  decode.d7.loss_mask: 0.2476  decode.d7.loss_dice: 0.2577  decode.d8.loss_cls: 0.1781  decode.d8.loss_mask: 0.2481  decode.d8.loss_dice: 0.2634
07/30 01:41:19 - mmengine - INFO - Iter(train) [18500/80000]  base_lr: 7.8924e-05 lr: 7.8924e-06  eta: 9:05:02  time: 0.5304  data_time: 0.0132  memory: 5971  grad_norm: 97.9392  loss: 6.8646  decode.loss_cls: 0.1350  decode.loss_mask: 0.1824  decode.loss_dice: 0.2456  decode.d0.loss_cls: 0.9581  decode.d0.loss_mask: 0.2004  decode.d0.loss_dice: 0.2912  decode.d1.loss_cls: 0.3153  decode.d1.loss_mask: 0.1896  decode.d1.loss_dice: 0.2532  decode.d2.loss_cls: 0.1754  decode.d2.loss_mask: 0.1930  decode.d2.loss_dice: 0.2515  decode.d3.loss_cls: 0.1543  decode.d3.loss_mask: 0.1813  decode.d3.loss_dice: 0.2511  decode.d4.loss_cls: 0.1730  decode.d4.loss_mask: 0.1801  decode.d4.loss_dice: 0.2539  decode.d5.loss_cls: 0.1307  decode.d5.loss_mask: 0.1810  decode.d5.loss_dice: 0.2367  decode.d6.loss_cls: 0.1241  decode.d6.loss_mask: 0.1803  decode.d6.loss_dice: 0.2338  decode.d7.loss_cls: 0.1710  decode.d7.loss_mask: 0.1851  decode.d7.loss_dice: 0.2758  decode.d8.loss_cls: 0.1133  decode.d8.loss_mask: 0.1846  decode.d8.loss_dice: 0.2637
07/30 01:41:45 - mmengine - INFO - Iter(train) [18550/80000]  base_lr: 7.8867e-05 lr: 7.8867e-06  eta: 9:04:36  time: 0.5323  data_time: 0.0137  memory: 5934  grad_norm: 194.5838  loss: 9.3424  decode.loss_cls: 0.1974  decode.loss_mask: 0.3493  decode.loss_dice: 0.3500  decode.d0.loss_cls: 1.0468  decode.d0.loss_mask: 0.3141  decode.d0.loss_dice: 0.3612  decode.d1.loss_cls: 0.2234  decode.d1.loss_mask: 0.3146  decode.d1.loss_dice: 0.3379  decode.d2.loss_cls: 0.1248  decode.d2.loss_mask: 0.3460  decode.d2.loss_dice: 0.3610  decode.d3.loss_cls: 0.1074  decode.d3.loss_mask: 0.3623  decode.d3.loss_dice: 0.3626  decode.d4.loss_cls: 0.1347  decode.d4.loss_mask: 0.3517  decode.d4.loss_dice: 0.3516  decode.d5.loss_cls: 0.1545  decode.d5.loss_mask: 0.3410  decode.d5.loss_dice: 0.3353  decode.d6.loss_cls: 0.1437  decode.d6.loss_mask: 0.3274  decode.d6.loss_dice: 0.3316  decode.d7.loss_cls: 0.1803  decode.d7.loss_mask: 0.3299  decode.d7.loss_dice: 0.3307  decode.d8.loss_cls: 0.2052  decode.d8.loss_mask: 0.3345  decode.d8.loss_dice: 0.3317
07/30 01:42:12 - mmengine - INFO - Iter(train) [18600/80000]  base_lr: 7.8809e-05 lr: 7.8809e-06  eta: 9:04:09  time: 0.5316  data_time: 0.0136  memory: 6002  grad_norm: 75.8270  loss: 8.0911  decode.loss_cls: 0.2099  decode.loss_mask: 0.2338  decode.loss_dice: 0.2354  decode.d0.loss_cls: 1.2910  decode.d0.loss_mask: 0.2323  decode.d0.loss_dice: 0.2749  decode.d1.loss_cls: 0.2717  decode.d1.loss_mask: 0.2456  decode.d1.loss_dice: 0.2551  decode.d2.loss_cls: 0.2204  decode.d2.loss_mask: 0.2389  decode.d2.loss_dice: 0.2360  decode.d3.loss_cls: 0.2607  decode.d3.loss_mask: 0.2330  decode.d3.loss_dice: 0.2245  decode.d4.loss_cls: 0.2417  decode.d4.loss_mask: 0.2310  decode.d4.loss_dice: 0.2455  decode.d5.loss_cls: 0.2398  decode.d5.loss_mask: 0.2392  decode.d5.loss_dice: 0.2283  decode.d6.loss_cls: 0.2435  decode.d6.loss_mask: 0.2359  decode.d6.loss_dice: 0.2290  decode.d7.loss_cls: 0.1839  decode.d7.loss_mask: 0.2352  decode.d7.loss_dice: 0.2208  decode.d8.loss_cls: 0.1977  decode.d8.loss_mask: 0.2353  decode.d8.loss_dice: 0.2211
07/30 01:42:38 - mmengine - INFO - Iter(train) [18650/80000]  base_lr: 7.8751e-05 lr: 7.8751e-06  eta: 9:03:43  time: 0.5280  data_time: 0.0136  memory: 5918  grad_norm: 134.2433  loss: 9.2244  decode.loss_cls: 0.2478  decode.loss_mask: 0.2931  decode.loss_dice: 0.3125  decode.d0.loss_cls: 1.0773  decode.d0.loss_mask: 0.2822  decode.d0.loss_dice: 0.3318  decode.d1.loss_cls: 0.2511  decode.d1.loss_mask: 0.2785  decode.d1.loss_dice: 0.2963  decode.d2.loss_cls: 0.3527  decode.d2.loss_mask: 0.2718  decode.d2.loss_dice: 0.3020  decode.d3.loss_cls: 0.2718  decode.d3.loss_mask: 0.2765  decode.d3.loss_dice: 0.3049  decode.d4.loss_cls: 0.2227  decode.d4.loss_mask: 0.2886  decode.d4.loss_dice: 0.3217  decode.d5.loss_cls: 0.2117  decode.d5.loss_mask: 0.2892  decode.d5.loss_dice: 0.3152  decode.d6.loss_cls: 0.1998  decode.d6.loss_mask: 0.2889  decode.d6.loss_dice: 0.3182  decode.d7.loss_cls: 0.1984  decode.d7.loss_mask: 0.2909  decode.d7.loss_dice: 0.3192  decode.d8.loss_cls: 0.2151  decode.d8.loss_mask: 0.2865  decode.d8.loss_dice: 0.3080
07/30 01:43:05 - mmengine - INFO - Iter(train) [18700/80000]  base_lr: 7.8693e-05 lr: 7.8693e-06  eta: 9:03:16  time: 0.5323  data_time: 0.0140  memory: 5898  grad_norm: 139.4922  loss: 10.2421  decode.loss_cls: 0.1857  decode.loss_mask: 0.3705  decode.loss_dice: 0.3361  decode.d0.loss_cls: 1.1216  decode.d0.loss_mask: 0.3585  decode.d0.loss_dice: 0.3616  decode.d1.loss_cls: 0.3238  decode.d1.loss_mask: 0.3710  decode.d1.loss_dice: 0.3574  decode.d2.loss_cls: 0.3175  decode.d2.loss_mask: 0.3546  decode.d2.loss_dice: 0.3290  decode.d3.loss_cls: 0.2020  decode.d3.loss_mask: 0.3664  decode.d3.loss_dice: 0.3367  decode.d4.loss_cls: 0.2075  decode.d4.loss_mask: 0.3618  decode.d4.loss_dice: 0.3303  decode.d5.loss_cls: 0.2030  decode.d5.loss_mask: 0.3689  decode.d5.loss_dice: 0.3445  decode.d6.loss_cls: 0.1971  decode.d6.loss_mask: 0.3636  decode.d6.loss_dice: 0.3427  decode.d7.loss_cls: 0.2306  decode.d7.loss_mask: 0.3720  decode.d7.loss_dice: 0.3390  decode.d8.loss_cls: 0.1769  decode.d8.loss_mask: 0.3683  decode.d8.loss_dice: 0.3433
07/30 01:43:32 - mmengine - INFO - Iter(train) [18750/80000]  base_lr: 7.8636e-05 lr: 7.8636e-06  eta: 9:02:50  time: 0.5279  data_time: 0.0135  memory: 5916  grad_norm: 193.5660  loss: 8.3024  decode.loss_cls: 0.1774  decode.loss_mask: 0.2095  decode.loss_dice: 0.3245  decode.d0.loss_cls: 1.0288  decode.d0.loss_mask: 0.2127  decode.d0.loss_dice: 0.3470  decode.d1.loss_cls: 0.3757  decode.d1.loss_mask: 0.2108  decode.d1.loss_dice: 0.3111  decode.d2.loss_cls: 0.2512  decode.d2.loss_mask: 0.2105  decode.d2.loss_dice: 0.3067  decode.d3.loss_cls: 0.1801  decode.d3.loss_mask: 0.2169  decode.d3.loss_dice: 0.3195  decode.d4.loss_cls: 0.2024  decode.d4.loss_mask: 0.2085  decode.d4.loss_dice: 0.3169  decode.d5.loss_cls: 0.2063  decode.d5.loss_mask: 0.2078  decode.d5.loss_dice: 0.3232  decode.d6.loss_cls: 0.1626  decode.d6.loss_mask: 0.2100  decode.d6.loss_dice: 0.2944  decode.d7.loss_cls: 0.2303  decode.d7.loss_mask: 0.2145  decode.d7.loss_dice: 0.3195  decode.d8.loss_cls: 0.1877  decode.d8.loss_mask: 0.2114  decode.d8.loss_dice: 0.3245
07/30 01:43:58 - mmengine - INFO - Iter(train) [18800/80000]  base_lr: 7.8578e-05 lr: 7.8578e-06  eta: 9:02:24  time: 0.5317  data_time: 0.0139  memory: 5879  grad_norm: 117.1249  loss: 8.5426  decode.loss_cls: 0.1498  decode.loss_mask: 0.2609  decode.loss_dice: 0.3284  decode.d0.loss_cls: 0.9020  decode.d0.loss_mask: 0.2629  decode.d0.loss_dice: 0.3313  decode.d1.loss_cls: 0.2963  decode.d1.loss_mask: 0.2568  decode.d1.loss_dice: 0.3083  decode.d2.loss_cls: 0.2803  decode.d2.loss_mask: 0.2592  decode.d2.loss_dice: 0.3301  decode.d3.loss_cls: 0.2326  decode.d3.loss_mask: 0.2577  decode.d3.loss_dice: 0.3093  decode.d4.loss_cls: 0.2469  decode.d4.loss_mask: 0.2591  decode.d4.loss_dice: 0.3044  decode.d5.loss_cls: 0.1595  decode.d5.loss_mask: 0.2597  decode.d5.loss_dice: 0.3429  decode.d6.loss_cls: 0.1475  decode.d6.loss_mask: 0.2601  decode.d6.loss_dice: 0.3255  decode.d7.loss_cls: 0.1575  decode.d7.loss_mask: 0.2565  decode.d7.loss_dice: 0.3238  decode.d8.loss_cls: 0.1311  decode.d8.loss_mask: 0.2588  decode.d8.loss_dice: 0.3436
07/30 01:44:25 - mmengine - INFO - Iter(train) [18850/80000]  base_lr: 7.8520e-05 lr: 7.8520e-06  eta: 9:01:57  time: 0.5246  data_time: 0.0134  memory: 5932  grad_norm: 354.8011  loss: 8.9579  decode.loss_cls: 0.1981  decode.loss_mask: 0.2829  decode.loss_dice: 0.3110  decode.d0.loss_cls: 0.9823  decode.d0.loss_mask: 0.2884  decode.d0.loss_dice: 0.3398  decode.d1.loss_cls: 0.2649  decode.d1.loss_mask: 0.2851  decode.d1.loss_dice: 0.3131  decode.d2.loss_cls: 0.2051  decode.d2.loss_mask: 0.2819  decode.d2.loss_dice: 0.3232  decode.d3.loss_cls: 0.1783  decode.d3.loss_mask: 0.2824  decode.d3.loss_dice: 0.3136  decode.d4.loss_cls: 0.1862  decode.d4.loss_mask: 0.2902  decode.d4.loss_dice: 0.3597  decode.d5.loss_cls: 0.2494  decode.d5.loss_mask: 0.2878  decode.d5.loss_dice: 0.3370  decode.d6.loss_cls: 0.1798  decode.d6.loss_mask: 0.2853  decode.d6.loss_dice: 0.3250  decode.d7.loss_cls: 0.1919  decode.d7.loss_mask: 0.2873  decode.d7.loss_dice: 0.3197  decode.d8.loss_cls: 0.1949  decode.d8.loss_mask: 0.2839  decode.d8.loss_dice: 0.3298
07/30 01:44:51 - mmengine - INFO - Iter(train) [18900/80000]  base_lr: 7.8462e-05 lr: 7.8462e-06  eta: 9:01:30  time: 0.5306  data_time: 0.0137  memory: 5896  grad_norm: 83.1463  loss: 8.4132  decode.loss_cls: 0.1880  decode.loss_mask: 0.2217  decode.loss_dice: 0.3483  decode.d0.loss_cls: 1.0670  decode.d0.loss_mask: 0.2225  decode.d0.loss_dice: 0.3134  decode.d1.loss_cls: 0.1793  decode.d1.loss_mask: 0.2224  decode.d1.loss_dice: 0.3486  decode.d2.loss_cls: 0.1866  decode.d2.loss_mask: 0.2239  decode.d2.loss_dice: 0.3531  decode.d3.loss_cls: 0.2333  decode.d3.loss_mask: 0.2214  decode.d3.loss_dice: 0.3352  decode.d4.loss_cls: 0.1901  decode.d4.loss_mask: 0.2183  decode.d4.loss_dice: 0.3417  decode.d5.loss_cls: 0.2056  decode.d5.loss_mask: 0.2201  decode.d5.loss_dice: 0.3084  decode.d6.loss_cls: 0.2073  decode.d6.loss_mask: 0.2173  decode.d6.loss_dice: 0.3278  decode.d7.loss_cls: 0.1742  decode.d7.loss_mask: 0.2220  decode.d7.loss_dice: 0.3402  decode.d8.loss_cls: 0.2029  decode.d8.loss_mask: 0.2200  decode.d8.loss_dice: 0.3526
07/30 01:45:18 - mmengine - INFO - Iter(train) [18950/80000]  base_lr: 7.8405e-05 lr: 7.8405e-06  eta: 9:01:04  time: 0.5310  data_time: 0.0136  memory: 5971  grad_norm: 139.7202  loss: 9.8742  decode.loss_cls: 0.2643  decode.loss_mask: 0.3068  decode.loss_dice: 0.3247  decode.d0.loss_cls: 1.1083  decode.d0.loss_mask: 0.2759  decode.d0.loss_dice: 0.2873  decode.d1.loss_cls: 0.3965  decode.d1.loss_mask: 0.2975  decode.d1.loss_dice: 0.2984  decode.d2.loss_cls: 0.3711  decode.d2.loss_mask: 0.2961  decode.d2.loss_dice: 0.3172  decode.d3.loss_cls: 0.2859  decode.d3.loss_mask: 0.2925  decode.d3.loss_dice: 0.2855  decode.d4.loss_cls: 0.2836  decode.d4.loss_mask: 0.2985  decode.d4.loss_dice: 0.2787  decode.d5.loss_cls: 0.3278  decode.d5.loss_mask: 0.3003  decode.d5.loss_dice: 0.3264  decode.d6.loss_cls: 0.2628  decode.d6.loss_mask: 0.2990  decode.d6.loss_dice: 0.3196  decode.d7.loss_cls: 0.2028  decode.d7.loss_mask: 0.3249  decode.d7.loss_dice: 0.3430  decode.d8.loss_cls: 0.2770  decode.d8.loss_mask: 0.3022  decode.d8.loss_dice: 0.3196
07/30 01:45:45 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/30 01:45:45 - mmengine - INFO - Iter(train) [19000/80000]  base_lr: 7.8347e-05 lr: 7.8347e-06  eta: 9:00:37  time: 0.5281  data_time: 0.0132  memory: 5897  grad_norm: 129.5913  loss: 7.6188  decode.loss_cls: 0.1278  decode.loss_mask: 0.2934  decode.loss_dice: 0.2541  decode.d0.loss_cls: 1.0270  decode.d0.loss_mask: 0.2738  decode.d0.loss_dice: 0.2849  decode.d1.loss_cls: 0.1764  decode.d1.loss_mask: 0.2745  decode.d1.loss_dice: 0.2748  decode.d2.loss_cls: 0.1165  decode.d2.loss_mask: 0.2894  decode.d2.loss_dice: 0.2551  decode.d3.loss_cls: 0.1523  decode.d3.loss_mask: 0.2785  decode.d3.loss_dice: 0.2587  decode.d4.loss_cls: 0.0907  decode.d4.loss_mask: 0.2892  decode.d4.loss_dice: 0.2528  decode.d5.loss_cls: 0.1117  decode.d5.loss_mask: 0.2878  decode.d5.loss_dice: 0.2483  decode.d6.loss_cls: 0.1160  decode.d6.loss_mask: 0.2913  decode.d6.loss_dice: 0.2410  decode.d7.loss_cls: 0.1018  decode.d7.loss_mask: 0.2900  decode.d7.loss_dice: 0.2690  decode.d8.loss_cls: 0.1255  decode.d8.loss_mask: 0.2920  decode.d8.loss_dice: 0.2746
07/30 01:46:11 - mmengine - INFO - Iter(train) [19050/80000]  base_lr: 7.8289e-05 lr: 7.8289e-06  eta: 9:00:11  time: 0.5343  data_time: 0.0136  memory: 5931  grad_norm: 260.4800  loss: 10.4368  decode.loss_cls: 0.2782  decode.loss_mask: 0.2203  decode.loss_dice: 0.3428  decode.d0.loss_cls: 1.3107  decode.d0.loss_mask: 0.2388  decode.d0.loss_dice: 0.4138  decode.d1.loss_cls: 0.4868  decode.d1.loss_mask: 0.2312  decode.d1.loss_dice: 0.3609  decode.d2.loss_cls: 0.4934  decode.d2.loss_mask: 0.2212  decode.d2.loss_dice: 0.3601  decode.d3.loss_cls: 0.3251  decode.d3.loss_mask: 0.2303  decode.d3.loss_dice: 0.3389  decode.d4.loss_cls: 0.3659  decode.d4.loss_mask: 0.2330  decode.d4.loss_dice: 0.3649  decode.d5.loss_cls: 0.3246  decode.d5.loss_mask: 0.2198  decode.d5.loss_dice: 0.3510  decode.d6.loss_cls: 0.3837  decode.d6.loss_mask: 0.2163  decode.d6.loss_dice: 0.3354  decode.d7.loss_cls: 0.3263  decode.d7.loss_mask: 0.2229  decode.d7.loss_dice: 0.3646  decode.d8.loss_cls: 0.3245  decode.d8.loss_mask: 0.2212  decode.d8.loss_dice: 0.3301
07/30 01:46:38 - mmengine - INFO - Iter(train) [19100/80000]  base_lr: 7.8231e-05 lr: 7.8231e-06  eta: 8:59:45  time: 0.5307  data_time: 0.0135  memory: 5895  grad_norm: 75.1030  loss: 6.5710  decode.loss_cls: 0.0517  decode.loss_mask: 0.2389  decode.loss_dice: 0.2775  decode.d0.loss_cls: 0.8283  decode.d0.loss_mask: 0.2526  decode.d0.loss_dice: 0.2821  decode.d1.loss_cls: 0.1318  decode.d1.loss_mask: 0.2481  decode.d1.loss_dice: 0.2688  decode.d2.loss_cls: 0.0820  decode.d2.loss_mask: 0.2408  decode.d2.loss_dice: 0.2550  decode.d3.loss_cls: 0.0517  decode.d3.loss_mask: 0.2383  decode.d3.loss_dice: 0.2660  decode.d4.loss_cls: 0.0685  decode.d4.loss_mask: 0.2375  decode.d4.loss_dice: 0.2624  decode.d5.loss_cls: 0.0853  decode.d5.loss_mask: 0.2433  decode.d5.loss_dice: 0.2745  decode.d6.loss_cls: 0.0485  decode.d6.loss_mask: 0.2417  decode.d6.loss_dice: 0.2681  decode.d7.loss_cls: 0.0767  decode.d7.loss_mask: 0.2421  decode.d7.loss_dice: 0.2585  decode.d8.loss_cls: 0.0419  decode.d8.loss_mask: 0.2424  decode.d8.loss_dice: 0.2660
07/30 01:47:05 - mmengine - INFO - Iter(train) [19150/80000]  base_lr: 7.8173e-05 lr: 7.8173e-06  eta: 8:59:19  time: 0.5371  data_time: 0.0136  memory: 5916  grad_norm: 314.0803  loss: 7.4643  decode.loss_cls: 0.0215  decode.loss_mask: 0.3081  decode.loss_dice: 0.2972  decode.d0.loss_cls: 0.8764  decode.d0.loss_mask: 0.3173  decode.d0.loss_dice: 0.3219  decode.d1.loss_cls: 0.0425  decode.d1.loss_mask: 0.3206  decode.d1.loss_dice: 0.3109  decode.d2.loss_cls: 0.0323  decode.d2.loss_mask: 0.3137  decode.d2.loss_dice: 0.3119  decode.d3.loss_cls: 0.0338  decode.d3.loss_mask: 0.3093  decode.d3.loss_dice: 0.3169  decode.d4.loss_cls: 0.0380  decode.d4.loss_mask: 0.3348  decode.d4.loss_dice: 0.3191  decode.d5.loss_cls: 0.0423  decode.d5.loss_mask: 0.3123  decode.d5.loss_dice: 0.3165  decode.d6.loss_cls: 0.0491  decode.d6.loss_mask: 0.3117  decode.d6.loss_dice: 0.3019  decode.d7.loss_cls: 0.0514  decode.d7.loss_mask: 0.3068  decode.d7.loss_dice: 0.3039  decode.d8.loss_cls: 0.0329  decode.d8.loss_mask: 0.3084  decode.d8.loss_dice: 0.3009
07/30 01:47:32 - mmengine - INFO - Iter(train) [19200/80000]  base_lr: 7.8115e-05 lr: 7.8115e-06  eta: 8:58:52  time: 0.5373  data_time: 0.0135  memory: 5896  grad_norm: 80.2587  loss: 5.5611  decode.loss_cls: 0.0585  decode.loss_mask: 0.1689  decode.loss_dice: 0.2484  decode.d0.loss_cls: 0.8624  decode.d0.loss_mask: 0.1731  decode.d0.loss_dice: 0.2568  decode.d1.loss_cls: 0.1237  decode.d1.loss_mask: 0.1722  decode.d1.loss_dice: 0.2542  decode.d2.loss_cls: 0.0773  decode.d2.loss_mask: 0.1644  decode.d2.loss_dice: 0.2433  decode.d3.loss_cls: 0.0486  decode.d3.loss_mask: 0.1659  decode.d3.loss_dice: 0.2333  decode.d4.loss_cls: 0.0497  decode.d4.loss_mask: 0.1688  decode.d4.loss_dice: 0.2391  decode.d5.loss_cls: 0.0477  decode.d5.loss_mask: 0.1665  decode.d5.loss_dice: 0.2384  decode.d6.loss_cls: 0.0535  decode.d6.loss_mask: 0.1648  decode.d6.loss_dice: 0.2371  decode.d7.loss_cls: 0.0844  decode.d7.loss_mask: 0.1667  decode.d7.loss_dice: 0.2372  decode.d8.loss_cls: 0.0607  decode.d8.loss_mask: 0.1664  decode.d8.loss_dice: 0.2292
07/30 01:47:58 - mmengine - INFO - Iter(train) [19250/80000]  base_lr: 7.8058e-05 lr: 7.8058e-06  eta: 8:58:26  time: 0.5286  data_time: 0.0135  memory: 5916  grad_norm: 86.3788  loss: 6.7114  decode.loss_cls: 0.0589  decode.loss_mask: 0.2456  decode.loss_dice: 0.2726  decode.d0.loss_cls: 0.8832  decode.d0.loss_mask: 0.2574  decode.d0.loss_dice: 0.2899  decode.d1.loss_cls: 0.1112  decode.d1.loss_mask: 0.2534  decode.d1.loss_dice: 0.2859  decode.d2.loss_cls: 0.0683  decode.d2.loss_mask: 0.2569  decode.d2.loss_dice: 0.2851  decode.d3.loss_cls: 0.0429  decode.d3.loss_mask: 0.2447  decode.d3.loss_dice: 0.2657  decode.d4.loss_cls: 0.0500  decode.d4.loss_mask: 0.2473  decode.d4.loss_dice: 0.2677  decode.d5.loss_cls: 0.0610  decode.d5.loss_mask: 0.2456  decode.d5.loss_dice: 0.2691  decode.d6.loss_cls: 0.0911  decode.d6.loss_mask: 0.2456  decode.d6.loss_dice: 0.2635  decode.d7.loss_cls: 0.0733  decode.d7.loss_mask: 0.2453  decode.d7.loss_dice: 0.2679  decode.d8.loss_cls: 0.0556  decode.d8.loss_mask: 0.2416  decode.d8.loss_dice: 0.2647
07/30 01:48:25 - mmengine - INFO - Iter(train) [19300/80000]  base_lr: 7.8000e-05 lr: 7.8000e-06  eta: 8:58:00  time: 0.5357  data_time: 0.0135  memory: 5931  grad_norm: 257.0172  loss: 8.3204  decode.loss_cls: 0.1829  decode.loss_mask: 0.2719  decode.loss_dice: 0.2904  decode.d0.loss_cls: 1.1077  decode.d0.loss_mask: 0.2574  decode.d0.loss_dice: 0.2841  decode.d1.loss_cls: 0.3186  decode.d1.loss_mask: 0.2517  decode.d1.loss_dice: 0.2892  decode.d2.loss_cls: 0.2580  decode.d2.loss_mask: 0.2354  decode.d2.loss_dice: 0.2864  decode.d3.loss_cls: 0.2351  decode.d3.loss_mask: 0.2318  decode.d3.loss_dice: 0.2889  decode.d4.loss_cls: 0.1856  decode.d4.loss_mask: 0.2382  decode.d4.loss_dice: 0.2718  decode.d5.loss_cls: 0.1324  decode.d5.loss_mask: 0.2531  decode.d5.loss_dice: 0.2879  decode.d6.loss_cls: 0.1344  decode.d6.loss_mask: 0.2602  decode.d6.loss_dice: 0.2851  decode.d7.loss_cls: 0.1616  decode.d7.loss_mask: 0.2812  decode.d7.loss_dice: 0.2804  decode.d8.loss_cls: 0.2021  decode.d8.loss_mask: 0.2738  decode.d8.loss_dice: 0.2831
07/30 01:48:51 - mmengine - INFO - Iter(train) [19350/80000]  base_lr: 7.7942e-05 lr: 7.7942e-06  eta: 8:57:33  time: 0.5320  data_time: 0.0135  memory: 5897  grad_norm: 132.7783  loss: 8.5212  decode.loss_cls: 0.1745  decode.loss_mask: 0.2535  decode.loss_dice: 0.3233  decode.d0.loss_cls: 0.8913  decode.d0.loss_mask: 0.2578  decode.d0.loss_dice: 0.3463  decode.d1.loss_cls: 0.2684  decode.d1.loss_mask: 0.2474  decode.d1.loss_dice: 0.3171  decode.d2.loss_cls: 0.2047  decode.d2.loss_mask: 0.2502  decode.d2.loss_dice: 0.3214  decode.d3.loss_cls: 0.1741  decode.d3.loss_mask: 0.2473  decode.d3.loss_dice: 0.3173  decode.d4.loss_cls: 0.1977  decode.d4.loss_mask: 0.2486  decode.d4.loss_dice: 0.3155  decode.d5.loss_cls: 0.2445  decode.d5.loss_mask: 0.2499  decode.d5.loss_dice: 0.3171  decode.d6.loss_cls: 0.2132  decode.d6.loss_mask: 0.2487  decode.d6.loss_dice: 0.3187  decode.d7.loss_cls: 0.2236  decode.d7.loss_mask: 0.2486  decode.d7.loss_dice: 0.3309  decode.d8.loss_cls: 0.2069  decode.d8.loss_mask: 0.2478  decode.d8.loss_dice: 0.3148
07/30 01:49:18 - mmengine - INFO - Iter(train) [19400/80000]  base_lr: 7.7884e-05 lr: 7.7884e-06  eta: 8:57:06  time: 0.5264  data_time: 0.0132  memory: 5918  grad_norm: 78.7443  loss: 7.2423  decode.loss_cls: 0.1154  decode.loss_mask: 0.2292  decode.loss_dice: 0.2519  decode.d0.loss_cls: 0.9065  decode.d0.loss_mask: 0.2378  decode.d0.loss_dice: 0.2706  decode.d1.loss_cls: 0.2968  decode.d1.loss_mask: 0.2358  decode.d1.loss_dice: 0.2590  decode.d2.loss_cls: 0.1798  decode.d2.loss_mask: 0.2331  decode.d2.loss_dice: 0.2435  decode.d3.loss_cls: 0.1136  decode.d3.loss_mask: 0.2271  decode.d3.loss_dice: 0.2313  decode.d4.loss_cls: 0.1110  decode.d4.loss_mask: 0.2297  decode.d4.loss_dice: 0.2555  decode.d5.loss_cls: 0.1992  decode.d5.loss_mask: 0.2331  decode.d5.loss_dice: 0.2501  decode.d6.loss_cls: 0.1659  decode.d6.loss_mask: 0.2278  decode.d6.loss_dice: 0.2413  decode.d7.loss_cls: 0.1457  decode.d7.loss_mask: 0.2321  decode.d7.loss_dice: 0.2561  decode.d8.loss_cls: 0.1791  decode.d8.loss_mask: 0.2339  decode.d8.loss_dice: 0.2506
07/30 01:49:45 - mmengine - INFO - Iter(train) [19450/80000]  base_lr: 7.7826e-05 lr: 7.7826e-06  eta: 8:56:40  time: 0.5301  data_time: 0.0133  memory: 5934  grad_norm: 93.9208  loss: 8.0001  decode.loss_cls: 0.1526  decode.loss_mask: 0.2595  decode.loss_dice: 0.2878  decode.d0.loss_cls: 0.8521  decode.d0.loss_mask: 0.2636  decode.d0.loss_dice: 0.3666  decode.d1.loss_cls: 0.2754  decode.d1.loss_mask: 0.2643  decode.d1.loss_dice: 0.3119  decode.d2.loss_cls: 0.1245  decode.d2.loss_mask: 0.2628  decode.d2.loss_dice: 0.3167  decode.d3.loss_cls: 0.1231  decode.d3.loss_mask: 0.2585  decode.d3.loss_dice: 0.2829  decode.d4.loss_cls: 0.1578  decode.d4.loss_mask: 0.2548  decode.d4.loss_dice: 0.2970  decode.d5.loss_cls: 0.1924  decode.d5.loss_mask: 0.2581  decode.d5.loss_dice: 0.3027  decode.d6.loss_cls: 0.1075  decode.d6.loss_mask: 0.2570  decode.d6.loss_dice: 0.3083  decode.d7.loss_cls: 0.1322  decode.d7.loss_mask: 0.2619  decode.d7.loss_dice: 0.3135  decode.d8.loss_cls: 0.1889  decode.d8.loss_mask: 0.2572  decode.d8.loss_dice: 0.3086
07/30 01:50:11 - mmengine - INFO - Iter(train) [19500/80000]  base_lr: 7.7769e-05 lr: 7.7769e-06  eta: 8:56:14  time: 0.5367  data_time: 0.0135  memory: 5918  grad_norm: 72.0949  loss: 8.9843  decode.loss_cls: 0.1907  decode.loss_mask: 0.2801  decode.loss_dice: 0.3532  decode.d0.loss_cls: 1.0440  decode.d0.loss_mask: 0.2836  decode.d0.loss_dice: 0.3828  decode.d1.loss_cls: 0.2769  decode.d1.loss_mask: 0.2847  decode.d1.loss_dice: 0.3453  decode.d2.loss_cls: 0.1236  decode.d2.loss_mask: 0.2841  decode.d2.loss_dice: 0.3562  decode.d3.loss_cls: 0.1315  decode.d3.loss_mask: 0.2748  decode.d3.loss_dice: 0.3402  decode.d4.loss_cls: 0.1280  decode.d4.loss_mask: 0.2784  decode.d4.loss_dice: 0.3475  decode.d5.loss_cls: 0.1817  decode.d5.loss_mask: 0.2812  decode.d5.loss_dice: 0.3531  decode.d6.loss_cls: 0.2075  decode.d6.loss_mask: 0.2834  decode.d6.loss_dice: 0.3533  decode.d7.loss_cls: 0.1657  decode.d7.loss_mask: 0.2826  decode.d7.loss_dice: 0.3447  decode.d8.loss_cls: 0.1836  decode.d8.loss_mask: 0.2819  decode.d8.loss_dice: 0.3603
07/30 01:50:38 - mmengine - INFO - Iter(train) [19550/80000]  base_lr: 7.7711e-05 lr: 7.7711e-06  eta: 8:55:47  time: 0.5385  data_time: 0.0138  memory: 5881  grad_norm: 153.6421  loss: 9.5306  decode.loss_cls: 0.3001  decode.loss_mask: 0.2210  decode.loss_dice: 0.3273  decode.d0.loss_cls: 1.1552  decode.d0.loss_mask: 0.2326  decode.d0.loss_dice: 0.3351  decode.d1.loss_cls: 0.3445  decode.d1.loss_mask: 0.2326  decode.d1.loss_dice: 0.3258  decode.d2.loss_cls: 0.3164  decode.d2.loss_mask: 0.2272  decode.d2.loss_dice: 0.3160  decode.d3.loss_cls: 0.2594  decode.d3.loss_mask: 0.2203  decode.d3.loss_dice: 0.3168  decode.d4.loss_cls: 0.2856  decode.d4.loss_mask: 0.2190  decode.d4.loss_dice: 0.2883  decode.d5.loss_cls: 0.2676  decode.d5.loss_mask: 0.2224  decode.d5.loss_dice: 0.3350  decode.d6.loss_cls: 0.3743  decode.d6.loss_mask: 0.2213  decode.d6.loss_dice: 0.3303  decode.d7.loss_cls: 0.4590  decode.d7.loss_mask: 0.2245  decode.d7.loss_dice: 0.3271  decode.d8.loss_cls: 0.2988  decode.d8.loss_mask: 0.2209  decode.d8.loss_dice: 0.3262
07/30 01:51:05 - mmengine - INFO - Iter(train) [19600/80000]  base_lr: 7.7653e-05 lr: 7.7653e-06  eta: 8:55:21  time: 0.5381  data_time: 0.0139  memory: 5918  grad_norm: 198.8564  loss: 10.8192  decode.loss_cls: 0.2885  decode.loss_mask: 0.3076  decode.loss_dice: 0.4483  decode.d0.loss_cls: 1.1487  decode.d0.loss_mask: 0.3236  decode.d0.loss_dice: 0.4615  decode.d1.loss_cls: 0.3058  decode.d1.loss_mask: 0.3137  decode.d1.loss_dice: 0.4251  decode.d2.loss_cls: 0.3059  decode.d2.loss_mask: 0.3090  decode.d2.loss_dice: 0.3875  decode.d3.loss_cls: 0.1966  decode.d3.loss_mask: 0.3073  decode.d3.loss_dice: 0.4139  decode.d4.loss_cls: 0.2127  decode.d4.loss_mask: 0.3017  decode.d4.loss_dice: 0.4298  decode.d5.loss_cls: 0.2238  decode.d5.loss_mask: 0.3066  decode.d5.loss_dice: 0.4210  decode.d6.loss_cls: 0.2674  decode.d6.loss_mask: 0.3046  decode.d6.loss_dice: 0.3947  decode.d7.loss_cls: 0.2415  decode.d7.loss_mask: 0.3061  decode.d7.loss_dice: 0.4573  decode.d8.loss_cls: 0.2450  decode.d8.loss_mask: 0.3086  decode.d8.loss_dice: 0.4554
07/30 01:51:32 - mmengine - INFO - Iter(train) [19650/80000]  base_lr: 7.7595e-05 lr: 7.7595e-06  eta: 8:54:55  time: 0.5332  data_time: 0.0136  memory: 5899  grad_norm: 101.9755  loss: 6.9169  decode.loss_cls: 0.0675  decode.loss_mask: 0.2529  decode.loss_dice: 0.2538  decode.d0.loss_cls: 0.7990  decode.d0.loss_mask: 0.2624  decode.d0.loss_dice: 0.2800  decode.d1.loss_cls: 0.1999  decode.d1.loss_mask: 0.2572  decode.d1.loss_dice: 0.2635  decode.d2.loss_cls: 0.1278  decode.d2.loss_mask: 0.2552  decode.d2.loss_dice: 0.2533  decode.d3.loss_cls: 0.0993  decode.d3.loss_mask: 0.2531  decode.d3.loss_dice: 0.2581  decode.d4.loss_cls: 0.0900  decode.d4.loss_mask: 0.2585  decode.d4.loss_dice: 0.2488  decode.d5.loss_cls: 0.0912  decode.d5.loss_mask: 0.2609  decode.d5.loss_dice: 0.2681  decode.d6.loss_cls: 0.0971  decode.d6.loss_mask: 0.2578  decode.d6.loss_dice: 0.2567  decode.d7.loss_cls: 0.0864  decode.d7.loss_mask: 0.2531  decode.d7.loss_dice: 0.2651  decode.d8.loss_cls: 0.0888  decode.d8.loss_mask: 0.2534  decode.d8.loss_dice: 0.2580
07/30 01:51:58 - mmengine - INFO - Iter(train) [19700/80000]  base_lr: 7.7537e-05 lr: 7.7537e-06  eta: 8:54:29  time: 0.5305  data_time: 0.0132  memory: 5897  grad_norm: 72.8400  loss: 5.9156  decode.loss_cls: 0.0700  decode.loss_mask: 0.2017  decode.loss_dice: 0.2375  decode.d0.loss_cls: 0.8693  decode.d0.loss_mask: 0.2072  decode.d0.loss_dice: 0.2422  decode.d1.loss_cls: 0.0782  decode.d1.loss_mask: 0.2019  decode.d1.loss_dice: 0.2340  decode.d2.loss_cls: 0.0742  decode.d2.loss_mask: 0.2032  decode.d2.loss_dice: 0.2409  decode.d3.loss_cls: 0.0636  decode.d3.loss_mask: 0.2013  decode.d3.loss_dice: 0.2350  decode.d4.loss_cls: 0.0692  decode.d4.loss_mask: 0.2017  decode.d4.loss_dice: 0.2300  decode.d5.loss_cls: 0.1142  decode.d5.loss_mask: 0.1988  decode.d5.loss_dice: 0.2272  decode.d6.loss_cls: 0.0759  decode.d6.loss_mask: 0.1997  decode.d6.loss_dice: 0.2319  decode.d7.loss_cls: 0.0639  decode.d7.loss_mask: 0.2013  decode.d7.loss_dice: 0.2422  decode.d8.loss_cls: 0.0658  decode.d8.loss_mask: 0.2001  decode.d8.loss_dice: 0.2335
07/30 01:52:25 - mmengine - INFO - Iter(train) [19750/80000]  base_lr: 7.7479e-05 lr: 7.7479e-06  eta: 8:54:03  time: 0.5334  data_time: 0.0136  memory: 5895  grad_norm: 92.7620  loss: 7.7084  decode.loss_cls: 0.1511  decode.loss_mask: 0.2664  decode.loss_dice: 0.2714  decode.d0.loss_cls: 0.9670  decode.d0.loss_mask: 0.2791  decode.d0.loss_dice: 0.3126  decode.d1.loss_cls: 0.1981  decode.d1.loss_mask: 0.2644  decode.d1.loss_dice: 0.2758  decode.d2.loss_cls: 0.1637  decode.d2.loss_mask: 0.2654  decode.d2.loss_dice: 0.2716  decode.d3.loss_cls: 0.1401  decode.d3.loss_mask: 0.2687  decode.d3.loss_dice: 0.2610  decode.d4.loss_cls: 0.1379  decode.d4.loss_mask: 0.2666  decode.d4.loss_dice: 0.2595  decode.d5.loss_cls: 0.1318  decode.d5.loss_mask: 0.2632  decode.d5.loss_dice: 0.2800  decode.d6.loss_cls: 0.1490  decode.d6.loss_mask: 0.2658  decode.d6.loss_dice: 0.2776  decode.d7.loss_cls: 0.1257  decode.d7.loss_mask: 0.2647  decode.d7.loss_dice: 0.2625  decode.d8.loss_cls: 0.1420  decode.d8.loss_mask: 0.2655  decode.d8.loss_dice: 0.2604
07/30 01:52:52 - mmengine - INFO - Iter(train) [19800/80000]  base_lr: 7.7421e-05 lr: 7.7421e-06  eta: 8:53:37  time: 0.5370  data_time: 0.0136  memory: 5918  grad_norm: 91.9345  loss: 7.3789  decode.loss_cls: 0.1288  decode.loss_mask: 0.2279  decode.loss_dice: 0.2453  decode.d0.loss_cls: 1.0949  decode.d0.loss_mask: 0.2405  decode.d0.loss_dice: 0.2764  decode.d1.loss_cls: 0.1495  decode.d1.loss_mask: 0.2264  decode.d1.loss_dice: 0.2440  decode.d2.loss_cls: 0.1829  decode.d2.loss_mask: 0.2275  decode.d2.loss_dice: 0.2543  decode.d3.loss_cls: 0.1879  decode.d3.loss_mask: 0.2276  decode.d3.loss_dice: 0.2516  decode.d4.loss_cls: 0.2235  decode.d4.loss_mask: 0.2219  decode.d4.loss_dice: 0.2477  decode.d5.loss_cls: 0.1185  decode.d5.loss_mask: 0.2327  decode.d5.loss_dice: 0.2556  decode.d6.loss_cls: 0.1757  decode.d6.loss_mask: 0.2273  decode.d6.loss_dice: 0.2446  decode.d7.loss_cls: 0.1635  decode.d7.loss_mask: 0.2223  decode.d7.loss_dice: 0.2365  decode.d8.loss_cls: 0.1656  decode.d8.loss_mask: 0.2289  decode.d8.loss_dice: 0.2491
07/30 01:53:19 - mmengine - INFO - Iter(train) [19850/80000]  base_lr: 7.7363e-05 lr: 7.7363e-06  eta: 8:53:11  time: 0.5323  data_time: 0.0132  memory: 5918  grad_norm: 186.9742  loss: 8.0663  decode.loss_cls: 0.1731  decode.loss_mask: 0.2448  decode.loss_dice: 0.2509  decode.d0.loss_cls: 1.0169  decode.d0.loss_mask: 0.2586  decode.d0.loss_dice: 0.2780  decode.d1.loss_cls: 0.2326  decode.d1.loss_mask: 0.2491  decode.d1.loss_dice: 0.2529  decode.d2.loss_cls: 0.2457  decode.d2.loss_mask: 0.2498  decode.d2.loss_dice: 0.2552  decode.d3.loss_cls: 0.2464  decode.d3.loss_mask: 0.2460  decode.d3.loss_dice: 0.2574  decode.d4.loss_cls: 0.2146  decode.d4.loss_mask: 0.2490  decode.d4.loss_dice: 0.2647  decode.d5.loss_cls: 0.2175  decode.d5.loss_mask: 0.2467  decode.d5.loss_dice: 0.2549  decode.d6.loss_cls: 0.2094  decode.d6.loss_mask: 0.2484  decode.d6.loss_dice: 0.2551  decode.d7.loss_cls: 0.2441  decode.d7.loss_mask: 0.2432  decode.d7.loss_dice: 0.2550  decode.d8.loss_cls: 0.2028  decode.d8.loss_mask: 0.2456  decode.d8.loss_dice: 0.2581
07/30 01:53:45 - mmengine - INFO - Iter(train) [19900/80000]  base_lr: 7.7306e-05 lr: 7.7306e-06  eta: 8:52:44  time: 0.5343  data_time: 0.0132  memory: 5897  grad_norm: 87.7864  loss: 9.4191  decode.loss_cls: 0.2169  decode.loss_mask: 0.2477  decode.loss_dice: 0.3247  decode.d0.loss_cls: 0.9649  decode.d0.loss_mask: 0.2607  decode.d0.loss_dice: 0.3725  decode.d1.loss_cls: 0.3839  decode.d1.loss_mask: 0.2589  decode.d1.loss_dice: 0.3718  decode.d2.loss_cls: 0.3289  decode.d2.loss_mask: 0.2524  decode.d2.loss_dice: 0.3495  decode.d3.loss_cls: 0.3086  decode.d3.loss_mask: 0.2534  decode.d3.loss_dice: 0.3306  decode.d4.loss_cls: 0.3008  decode.d4.loss_mask: 0.2511  decode.d4.loss_dice: 0.3391  decode.d5.loss_cls: 0.2864  decode.d5.loss_mask: 0.2502  decode.d5.loss_dice: 0.3251  decode.d6.loss_cls: 0.2267  decode.d6.loss_mask: 0.2484  decode.d6.loss_dice: 0.3409  decode.d7.loss_cls: 0.2171  decode.d7.loss_mask: 0.2480  decode.d7.loss_dice: 0.3603  decode.d8.loss_cls: 0.2279  decode.d8.loss_mask: 0.2486  decode.d8.loss_dice: 0.3232
07/30 01:54:12 - mmengine - INFO - Iter(train) [19950/80000]  base_lr: 7.7248e-05 lr: 7.7248e-06  eta: 8:52:18  time: 0.5303  data_time: 0.0134  memory: 5919  grad_norm: 122.2570  loss: 6.5759  decode.loss_cls: 0.0525  decode.loss_mask: 0.2007  decode.loss_dice: 0.3085  decode.d0.loss_cls: 0.8891  decode.d0.loss_mask: 0.1981  decode.d0.loss_dice: 0.2951  decode.d1.loss_cls: 0.1361  decode.d1.loss_mask: 0.1984  decode.d1.loss_dice: 0.2906  decode.d2.loss_cls: 0.1586  decode.d2.loss_mask: 0.1919  decode.d2.loss_dice: 0.2789  decode.d3.loss_cls: 0.1329  decode.d3.loss_mask: 0.1942  decode.d3.loss_dice: 0.2747  decode.d4.loss_cls: 0.1190  decode.d4.loss_mask: 0.1918  decode.d4.loss_dice: 0.2732  decode.d5.loss_cls: 0.0518  decode.d5.loss_mask: 0.2001  decode.d5.loss_dice: 0.2857  decode.d6.loss_cls: 0.0708  decode.d6.loss_mask: 0.1968  decode.d6.loss_dice: 0.3062  decode.d7.loss_cls: 0.0408  decode.d7.loss_mask: 0.2008  decode.d7.loss_dice: 0.2986  decode.d8.loss_cls: 0.0425  decode.d8.loss_mask: 0.2010  decode.d8.loss_dice: 0.2963
07/30 01:54:38 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/30 01:54:38 - mmengine - INFO - Iter(train) [20000/80000]  base_lr: 7.7190e-05 lr: 7.7190e-06  eta: 8:51:51  time: 0.5301  data_time: 0.0135  memory: 5916  grad_norm: 62.6232  loss: 7.8385  decode.loss_cls: 0.1140  decode.loss_mask: 0.2923  decode.loss_dice: 0.2712  decode.d0.loss_cls: 0.9347  decode.d0.loss_mask: 0.3012  decode.d0.loss_dice: 0.2778  decode.d1.loss_cls: 0.2331  decode.d1.loss_mask: 0.2906  decode.d1.loss_dice: 0.2997  decode.d2.loss_cls: 0.1455  decode.d2.loss_mask: 0.2929  decode.d2.loss_dice: 0.2743  decode.d3.loss_cls: 0.1134  decode.d3.loss_mask: 0.2918  decode.d3.loss_dice: 0.2723  decode.d4.loss_cls: 0.1031  decode.d4.loss_mask: 0.2944  decode.d4.loss_dice: 0.2839  decode.d5.loss_cls: 0.1138  decode.d5.loss_mask: 0.2896  decode.d5.loss_dice: 0.2725  decode.d6.loss_cls: 0.1508  decode.d6.loss_mask: 0.2972  decode.d6.loss_dice: 0.2702  decode.d7.loss_cls: 0.1070  decode.d7.loss_mask: 0.2960  decode.d7.loss_dice: 0.2855  decode.d8.loss_cls: 0.1072  decode.d8.loss_mask: 0.2966  decode.d8.loss_dice: 0.2658
07/30 01:54:38 - mmengine - INFO - Saving checkpoint at 20000 iterations
07/30 01:55:08 - mmengine - INFO - Iter(train) [20050/80000]  base_lr: 7.7132e-05 lr: 7.7132e-06  eta: 8:51:34  time: 0.5379  data_time: 0.0143  memory: 5896  grad_norm: 77.1656  loss: 6.9234  decode.loss_cls: 0.0494  decode.loss_mask: 0.2468  decode.loss_dice: 0.3044  decode.d0.loss_cls: 0.9327  decode.d0.loss_mask: 0.2604  decode.d0.loss_dice: 0.3265  decode.d1.loss_cls: 0.1298  decode.d1.loss_mask: 0.2488  decode.d1.loss_dice: 0.3009  decode.d2.loss_cls: 0.0502  decode.d2.loss_mask: 0.2442  decode.d2.loss_dice: 0.3081  decode.d3.loss_cls: 0.0368  decode.d3.loss_mask: 0.2457  decode.d3.loss_dice: 0.3178  decode.d4.loss_cls: 0.0394  decode.d4.loss_mask: 0.2477  decode.d4.loss_dice: 0.2995  decode.d5.loss_cls: 0.0613  decode.d5.loss_mask: 0.2473  decode.d5.loss_dice: 0.2958  decode.d6.loss_cls: 0.0354  decode.d6.loss_mask: 0.2462  decode.d6.loss_dice: 0.2916  decode.d7.loss_cls: 0.0392  decode.d7.loss_mask: 0.2466  decode.d7.loss_dice: 0.2909  decode.d8.loss_cls: 0.0347  decode.d8.loss_mask: 0.2447  decode.d8.loss_dice: 0.3006
07/30 01:55:35 - mmengine - INFO - Iter(train) [20100/80000]  base_lr: 7.7074e-05 lr: 7.7074e-06  eta: 8:51:08  time: 0.5343  data_time: 0.0139  memory: 5916  grad_norm: 97.7907  loss: 7.2250  decode.loss_cls: 0.1422  decode.loss_mask: 0.1855  decode.loss_dice: 0.2934  decode.d0.loss_cls: 1.0126  decode.d0.loss_mask: 0.1897  decode.d0.loss_dice: 0.2856  decode.d1.loss_cls: 0.1090  decode.d1.loss_mask: 0.1880  decode.d1.loss_dice: 0.2888  decode.d2.loss_cls: 0.2010  decode.d2.loss_mask: 0.1861  decode.d2.loss_dice: 0.2903  decode.d3.loss_cls: 0.1400  decode.d3.loss_mask: 0.1869  decode.d3.loss_dice: 0.2978  decode.d4.loss_cls: 0.1718  decode.d4.loss_mask: 0.1850  decode.d4.loss_dice: 0.2848  decode.d5.loss_cls: 0.2023  decode.d5.loss_mask: 0.1848  decode.d5.loss_dice: 0.2875  decode.d6.loss_cls: 0.1732  decode.d6.loss_mask: 0.1829  decode.d6.loss_dice: 0.2857  decode.d7.loss_cls: 0.1834  decode.d7.loss_mask: 0.1830  decode.d7.loss_dice: 0.2821  decode.d8.loss_cls: 0.1503  decode.d8.loss_mask: 0.1859  decode.d8.loss_dice: 0.2854
07/30 01:56:02 - mmengine - INFO - Iter(train) [20150/80000]  base_lr: 7.7016e-05 lr: 7.7016e-06  eta: 8:50:42  time: 0.5374  data_time: 0.0138  memory: 5920  grad_norm: 79.8437  loss: 7.4326  decode.loss_cls: 0.2343  decode.loss_mask: 0.1856  decode.loss_dice: 0.2343  decode.d0.loss_cls: 0.9375  decode.d0.loss_mask: 0.1901  decode.d0.loss_dice: 0.2611  decode.d1.loss_cls: 0.2711  decode.d1.loss_mask: 0.1879  decode.d1.loss_dice: 0.2489  decode.d2.loss_cls: 0.2437  decode.d2.loss_mask: 0.1859  decode.d2.loss_dice: 0.2367  decode.d3.loss_cls: 0.2099  decode.d3.loss_mask: 0.1867  decode.d3.loss_dice: 0.2383  decode.d4.loss_cls: 0.2487  decode.d4.loss_mask: 0.1831  decode.d4.loss_dice: 0.2335  decode.d5.loss_cls: 0.2237  decode.d5.loss_mask: 0.1849  decode.d5.loss_dice: 0.2419  decode.d6.loss_cls: 0.2394  decode.d6.loss_mask: 0.1858  decode.d6.loss_dice: 0.2550  decode.d7.loss_cls: 0.2655  decode.d7.loss_mask: 0.1833  decode.d7.loss_dice: 0.2449  decode.d8.loss_cls: 0.2666  decode.d8.loss_mask: 0.1847  decode.d8.loss_dice: 0.2396
07/30 01:56:29 - mmengine - INFO - Iter(train) [20200/80000]  base_lr: 7.6958e-05 lr: 7.6958e-06  eta: 8:50:16  time: 0.5348  data_time: 0.0137  memory: 5933  grad_norm: 82.6079  loss: 8.2166  decode.loss_cls: 0.0955  decode.loss_mask: 0.2806  decode.loss_dice: 0.3183  decode.d0.loss_cls: 0.8827  decode.d0.loss_mask: 0.2814  decode.d0.loss_dice: 0.3418  decode.d1.loss_cls: 0.2224  decode.d1.loss_mask: 0.2746  decode.d1.loss_dice: 0.3366  decode.d2.loss_cls: 0.1714  decode.d2.loss_mask: 0.2808  decode.d2.loss_dice: 0.3516  decode.d3.loss_cls: 0.1692  decode.d3.loss_mask: 0.2756  decode.d3.loss_dice: 0.3199  decode.d4.loss_cls: 0.1868  decode.d4.loss_mask: 0.2715  decode.d4.loss_dice: 0.3283  decode.d5.loss_cls: 0.1309  decode.d5.loss_mask: 0.2752  decode.d5.loss_dice: 0.3318  decode.d6.loss_cls: 0.0938  decode.d6.loss_mask: 0.2801  decode.d6.loss_dice: 0.3297  decode.d7.loss_cls: 0.0979  decode.d7.loss_mask: 0.2871  decode.d7.loss_dice: 0.3060  decode.d8.loss_cls: 0.0922  decode.d8.loss_mask: 0.2841  decode.d8.loss_dice: 0.3189
07/30 01:56:55 - mmengine - INFO - Iter(train) [20250/80000]  base_lr: 7.6900e-05 lr: 7.6900e-06  eta: 8:49:49  time: 0.5301  data_time: 0.0133  memory: 5918  grad_norm: 87.6950  loss: 7.2249  decode.loss_cls: 0.1704  decode.loss_mask: 0.2293  decode.loss_dice: 0.2711  decode.d0.loss_cls: 0.8068  decode.d0.loss_mask: 0.2296  decode.d0.loss_dice: 0.2653  decode.d1.loss_cls: 0.2038  decode.d1.loss_mask: 0.2271  decode.d1.loss_dice: 0.2629  decode.d2.loss_cls: 0.1810  decode.d2.loss_mask: 0.2301  decode.d2.loss_dice: 0.2649  decode.d3.loss_cls: 0.1091  decode.d3.loss_mask: 0.2325  decode.d3.loss_dice: 0.2734  decode.d4.loss_cls: 0.1450  decode.d4.loss_mask: 0.2293  decode.d4.loss_dice: 0.2710  decode.d5.loss_cls: 0.1568  decode.d5.loss_mask: 0.2285  decode.d5.loss_dice: 0.2661  decode.d6.loss_cls: 0.1397  decode.d6.loss_mask: 0.2288  decode.d6.loss_dice: 0.2685  decode.d7.loss_cls: 0.1633  decode.d7.loss_mask: 0.2288  decode.d7.loss_dice: 0.2845  decode.d8.loss_cls: 0.1438  decode.d8.loss_mask: 0.2303  decode.d8.loss_dice: 0.2830
07/30 01:57:22 - mmengine - INFO - Iter(train) [20300/80000]  base_lr: 7.6842e-05 lr: 7.6842e-06  eta: 8:49:23  time: 0.5355  data_time: 0.0136  memory: 5918  grad_norm: 126.2751  loss: 9.0278  decode.loss_cls: 0.1822  decode.loss_mask: 0.3106  decode.loss_dice: 0.3303  decode.d0.loss_cls: 0.9886  decode.d0.loss_mask: 0.3063  decode.d0.loss_dice: 0.3388  decode.d1.loss_cls: 0.2064  decode.d1.loss_mask: 0.3045  decode.d1.loss_dice: 0.3358  decode.d2.loss_cls: 0.1904  decode.d2.loss_mask: 0.3164  decode.d2.loss_dice: 0.3362  decode.d3.loss_cls: 0.1801  decode.d3.loss_mask: 0.3097  decode.d3.loss_dice: 0.3346  decode.d4.loss_cls: 0.1922  decode.d4.loss_mask: 0.3050  decode.d4.loss_dice: 0.3496  decode.d5.loss_cls: 0.1603  decode.d5.loss_mask: 0.3082  decode.d5.loss_dice: 0.3264  decode.d6.loss_cls: 0.1853  decode.d6.loss_mask: 0.3057  decode.d6.loss_dice: 0.3220  decode.d7.loss_cls: 0.1684  decode.d7.loss_mask: 0.3017  decode.d7.loss_dice: 0.3076  decode.d8.loss_cls: 0.1752  decode.d8.loss_mask: 0.3058  decode.d8.loss_dice: 0.3433
07/30 01:57:49 - mmengine - INFO - Iter(train) [20350/80000]  base_lr: 7.6784e-05 lr: 7.6784e-06  eta: 8:48:57  time: 0.5337  data_time: 0.0135  memory: 5918  grad_norm: 116.6301  loss: 8.1572  decode.loss_cls: 0.1355  decode.loss_mask: 0.2546  decode.loss_dice: 0.2861  decode.d0.loss_cls: 0.9131  decode.d0.loss_mask: 0.2752  decode.d0.loss_dice: 0.3113  decode.d1.loss_cls: 0.2817  decode.d1.loss_mask: 0.2771  decode.d1.loss_dice: 0.3177  decode.d2.loss_cls: 0.2158  decode.d2.loss_mask: 0.2556  decode.d2.loss_dice: 0.2897  decode.d3.loss_cls: 0.1956  decode.d3.loss_mask: 0.2569  decode.d3.loss_dice: 0.3124  decode.d4.loss_cls: 0.1770  decode.d4.loss_mask: 0.2643  decode.d4.loss_dice: 0.3181  decode.d5.loss_cls: 0.1575  decode.d5.loss_mask: 0.2579  decode.d5.loss_dice: 0.2794  decode.d6.loss_cls: 0.1310  decode.d6.loss_mask: 0.2620  decode.d6.loss_dice: 0.3062  decode.d7.loss_cls: 0.1342  decode.d7.loss_mask: 0.2617  decode.d7.loss_dice: 0.3067  decode.d8.loss_cls: 0.1649  decode.d8.loss_mask: 0.2596  decode.d8.loss_dice: 0.2983
07/30 01:58:15 - mmengine - INFO - Iter(train) [20400/80000]  base_lr: 7.6727e-05 lr: 7.6727e-06  eta: 8:48:30  time: 0.5357  data_time: 0.0138  memory: 5932  grad_norm: 113.0992  loss: 8.0319  decode.loss_cls: 0.1832  decode.loss_mask: 0.2206  decode.loss_dice: 0.2651  decode.d0.loss_cls: 1.1795  decode.d0.loss_mask: 0.2268  decode.d0.loss_dice: 0.2886  decode.d1.loss_cls: 0.2437  decode.d1.loss_mask: 0.2358  decode.d1.loss_dice: 0.3168  decode.d2.loss_cls: 0.3363  decode.d2.loss_mask: 0.2280  decode.d2.loss_dice: 0.2613  decode.d3.loss_cls: 0.2592  decode.d3.loss_mask: 0.2197  decode.d3.loss_dice: 0.2543  decode.d4.loss_cls: 0.1934  decode.d4.loss_mask: 0.2185  decode.d4.loss_dice: 0.2556  decode.d5.loss_cls: 0.1700  decode.d5.loss_mask: 0.2183  decode.d5.loss_dice: 0.2581  decode.d6.loss_cls: 0.1689  decode.d6.loss_mask: 0.2198  decode.d6.loss_dice: 0.2524  decode.d7.loss_cls: 0.1899  decode.d7.loss_mask: 0.2265  decode.d7.loss_dice: 0.2730  decode.d8.loss_cls: 0.1805  decode.d8.loss_mask: 0.2208  decode.d8.loss_dice: 0.2673
07/30 01:58:42 - mmengine - INFO - Iter(train) [20450/80000]  base_lr: 7.6669e-05 lr: 7.6669e-06  eta: 8:48:04  time: 0.5294  data_time: 0.0136  memory: 5898  grad_norm: 97.9348  loss: 8.0082  decode.loss_cls: 0.1398  decode.loss_mask: 0.2561  decode.loss_dice: 0.3112  decode.d0.loss_cls: 0.9653  decode.d0.loss_mask: 0.2567  decode.d0.loss_dice: 0.3217  decode.d1.loss_cls: 0.1801  decode.d1.loss_mask: 0.2515  decode.d1.loss_dice: 0.3043  decode.d2.loss_cls: 0.1648  decode.d2.loss_mask: 0.2541  decode.d2.loss_dice: 0.2978  decode.d3.loss_cls: 0.1719  decode.d3.loss_mask: 0.2495  decode.d3.loss_dice: 0.3021  decode.d4.loss_cls: 0.1639  decode.d4.loss_mask: 0.2503  decode.d4.loss_dice: 0.3022  decode.d5.loss_cls: 0.1182  decode.d5.loss_mask: 0.2558  decode.d5.loss_dice: 0.3220  decode.d6.loss_cls: 0.1519  decode.d6.loss_mask: 0.2569  decode.d6.loss_dice: 0.3201  decode.d7.loss_cls: 0.1184  decode.d7.loss_mask: 0.2696  decode.d7.loss_dice: 0.3276  decode.d8.loss_cls: 0.1582  decode.d8.loss_mask: 0.2562  decode.d8.loss_dice: 0.3099
07/30 01:59:09 - mmengine - INFO - Iter(train) [20500/80000]  base_lr: 7.6611e-05 lr: 7.6611e-06  eta: 8:47:37  time: 0.5299  data_time: 0.0133  memory: 5896  grad_norm: 113.1753  loss: 7.9673  decode.loss_cls: 0.1519  decode.loss_mask: 0.2768  decode.loss_dice: 0.3017  decode.d0.loss_cls: 0.9210  decode.d0.loss_mask: 0.2768  decode.d0.loss_dice: 0.3140  decode.d1.loss_cls: 0.1872  decode.d1.loss_mask: 0.2830  decode.d1.loss_dice: 0.3034  decode.d2.loss_cls: 0.1468  decode.d2.loss_mask: 0.2765  decode.d2.loss_dice: 0.2910  decode.d3.loss_cls: 0.1616  decode.d3.loss_mask: 0.2756  decode.d3.loss_dice: 0.2875  decode.d4.loss_cls: 0.1181  decode.d4.loss_mask: 0.2770  decode.d4.loss_dice: 0.3033  decode.d5.loss_cls: 0.1362  decode.d5.loss_mask: 0.2797  decode.d5.loss_dice: 0.2983  decode.d6.loss_cls: 0.1110  decode.d6.loss_mask: 0.2715  decode.d6.loss_dice: 0.2942  decode.d7.loss_cls: 0.1154  decode.d7.loss_mask: 0.2731  decode.d7.loss_dice: 0.2942  decode.d8.loss_cls: 0.1617  decode.d8.loss_mask: 0.2752  decode.d8.loss_dice: 0.3036
07/30 01:59:35 - mmengine - INFO - Iter(train) [20550/80000]  base_lr: 7.6553e-05 lr: 7.6553e-06  eta: 8:47:11  time: 0.5328  data_time: 0.0130  memory: 5934  grad_norm: 121.7319  loss: 7.1705  decode.loss_cls: 0.0738  decode.loss_mask: 0.2602  decode.loss_dice: 0.2541  decode.d0.loss_cls: 1.0455  decode.d0.loss_mask: 0.2585  decode.d0.loss_dice: 0.2929  decode.d1.loss_cls: 0.1954  decode.d1.loss_mask: 0.2624  decode.d1.loss_dice: 0.2696  decode.d2.loss_cls: 0.1091  decode.d2.loss_mask: 0.2565  decode.d2.loss_dice: 0.2517  decode.d3.loss_cls: 0.1391  decode.d3.loss_mask: 0.2557  decode.d3.loss_dice: 0.2560  decode.d4.loss_cls: 0.0824  decode.d4.loss_mask: 0.2591  decode.d4.loss_dice: 0.2619  decode.d5.loss_cls: 0.0645  decode.d5.loss_mask: 0.2592  decode.d5.loss_dice: 0.2683  decode.d6.loss_cls: 0.0610  decode.d6.loss_mask: 0.2588  decode.d6.loss_dice: 0.2616  decode.d7.loss_cls: 0.0830  decode.d7.loss_mask: 0.2568  decode.d7.loss_dice: 0.2883  decode.d8.loss_cls: 0.0697  decode.d8.loss_mask: 0.2609  decode.d8.loss_dice: 0.2545
07/30 02:00:02 - mmengine - INFO - Iter(train) [20600/80000]  base_lr: 7.6495e-05 lr: 7.6495e-06  eta: 8:46:44  time: 0.5305  data_time: 0.0134  memory: 5971  grad_norm: 119.4672  loss: 7.6834  decode.loss_cls: 0.2144  decode.loss_mask: 0.2184  decode.loss_dice: 0.2314  decode.d0.loss_cls: 1.0831  decode.d0.loss_mask: 0.2237  decode.d0.loss_dice: 0.2714  decode.d1.loss_cls: 0.3376  decode.d1.loss_mask: 0.2230  decode.d1.loss_dice: 0.2392  decode.d2.loss_cls: 0.2804  decode.d2.loss_mask: 0.2237  decode.d2.loss_dice: 0.2470  decode.d3.loss_cls: 0.2391  decode.d3.loss_mask: 0.2199  decode.d3.loss_dice: 0.2516  decode.d4.loss_cls: 0.1659  decode.d4.loss_mask: 0.2202  decode.d4.loss_dice: 0.2396  decode.d5.loss_cls: 0.1685  decode.d5.loss_mask: 0.2221  decode.d5.loss_dice: 0.2487  decode.d6.loss_cls: 0.2006  decode.d6.loss_mask: 0.2178  decode.d6.loss_dice: 0.2355  decode.d7.loss_cls: 0.1825  decode.d7.loss_mask: 0.2154  decode.d7.loss_dice: 0.2600  decode.d8.loss_cls: 0.1334  decode.d8.loss_mask: 0.2188  decode.d8.loss_dice: 0.2506
07/30 02:00:28 - mmengine - INFO - Iter(train) [20650/80000]  base_lr: 7.6437e-05 lr: 7.6437e-06  eta: 8:46:17  time: 0.5329  data_time: 0.0136  memory: 5895  grad_norm: 103.2082  loss: 7.0379  decode.loss_cls: 0.1086  decode.loss_mask: 0.2385  decode.loss_dice: 0.2584  decode.d0.loss_cls: 1.0078  decode.d0.loss_mask: 0.2442  decode.d0.loss_dice: 0.2830  decode.d1.loss_cls: 0.1109  decode.d1.loss_mask: 0.2460  decode.d1.loss_dice: 0.2739  decode.d2.loss_cls: 0.1370  decode.d2.loss_mask: 0.2328  decode.d2.loss_dice: 0.2504  decode.d3.loss_cls: 0.1301  decode.d3.loss_mask: 0.2373  decode.d3.loss_dice: 0.2528  decode.d4.loss_cls: 0.1044  decode.d4.loss_mask: 0.2332  decode.d4.loss_dice: 0.2556  decode.d5.loss_cls: 0.1075  decode.d5.loss_mask: 0.2383  decode.d5.loss_dice: 0.2517  decode.d6.loss_cls: 0.1242  decode.d6.loss_mask: 0.2346  decode.d6.loss_dice: 0.2546  decode.d7.loss_cls: 0.1184  decode.d7.loss_mask: 0.2348  decode.d7.loss_dice: 0.2571  decode.d8.loss_cls: 0.1092  decode.d8.loss_mask: 0.2419  decode.d8.loss_dice: 0.2609
07/30 02:00:55 - mmengine - INFO - Iter(train) [20700/80000]  base_lr: 7.6379e-05 lr: 7.6379e-06  eta: 8:45:51  time: 0.5365  data_time: 0.0137  memory: 5918  grad_norm: 211.1122  loss: 8.2748  decode.loss_cls: 0.1891  decode.loss_mask: 0.2241  decode.loss_dice: 0.2916  decode.d0.loss_cls: 0.9527  decode.d0.loss_mask: 0.2257  decode.d0.loss_dice: 0.2871  decode.d1.loss_cls: 0.3588  decode.d1.loss_mask: 0.2243  decode.d1.loss_dice: 0.3058  decode.d2.loss_cls: 0.3185  decode.d2.loss_mask: 0.2249  decode.d2.loss_dice: 0.2771  decode.d3.loss_cls: 0.2180  decode.d3.loss_mask: 0.2206  decode.d3.loss_dice: 0.2783  decode.d4.loss_cls: 0.2429  decode.d4.loss_mask: 0.2271  decode.d4.loss_dice: 0.2729  decode.d5.loss_cls: 0.2274  decode.d5.loss_mask: 0.2266  decode.d5.loss_dice: 0.2924  decode.d6.loss_cls: 0.2007  decode.d6.loss_mask: 0.2238  decode.d6.loss_dice: 0.2986  decode.d7.loss_cls: 0.2302  decode.d7.loss_mask: 0.2237  decode.d7.loss_dice: 0.2757  decode.d8.loss_cls: 0.2194  decode.d8.loss_mask: 0.2206  decode.d8.loss_dice: 0.2961
07/30 02:01:22 - mmengine - INFO - Iter(train) [20750/80000]  base_lr: 7.6321e-05 lr: 7.6321e-06  eta: 8:45:24  time: 0.5357  data_time: 0.0136  memory: 5897  grad_norm: 61.6528  loss: 6.9709  decode.loss_cls: 0.1076  decode.loss_mask: 0.2450  decode.loss_dice: 0.2575  decode.d0.loss_cls: 0.9040  decode.d0.loss_mask: 0.2626  decode.d0.loss_dice: 0.2716  decode.d1.loss_cls: 0.1369  decode.d1.loss_mask: 0.2518  decode.d1.loss_dice: 0.2740  decode.d2.loss_cls: 0.1360  decode.d2.loss_mask: 0.2534  decode.d2.loss_dice: 0.2488  decode.d3.loss_cls: 0.1210  decode.d3.loss_mask: 0.2472  decode.d3.loss_dice: 0.2520  decode.d4.loss_cls: 0.1089  decode.d4.loss_mask: 0.2481  decode.d4.loss_dice: 0.2460  decode.d5.loss_cls: 0.1059  decode.d5.loss_mask: 0.2511  decode.d5.loss_dice: 0.2579  decode.d6.loss_cls: 0.0945  decode.d6.loss_mask: 0.2494  decode.d6.loss_dice: 0.2514  decode.d7.loss_cls: 0.0916  decode.d7.loss_mask: 0.2479  decode.d7.loss_dice: 0.2573  decode.d8.loss_cls: 0.0944  decode.d8.loss_mask: 0.2470  decode.d8.loss_dice: 0.2501
07/30 02:01:48 - mmengine - INFO - Iter(train) [20800/80000]  base_lr: 7.6263e-05 lr: 7.6263e-06  eta: 8:44:58  time: 0.5380  data_time: 0.0140  memory: 5918  grad_norm: 136.2522  loss: 7.4674  decode.loss_cls: 0.0668  decode.loss_mask: 0.2888  decode.loss_dice: 0.2681  decode.d0.loss_cls: 0.8719  decode.d0.loss_mask: 0.2912  decode.d0.loss_dice: 0.2626  decode.d1.loss_cls: 0.2375  decode.d1.loss_mask: 0.2865  decode.d1.loss_dice: 0.2650  decode.d2.loss_cls: 0.1504  decode.d2.loss_mask: 0.2842  decode.d2.loss_dice: 0.2767  decode.d3.loss_cls: 0.1214  decode.d3.loss_mask: 0.2853  decode.d3.loss_dice: 0.2742  decode.d4.loss_cls: 0.0718  decode.d4.loss_mask: 0.2879  decode.d4.loss_dice: 0.2678  decode.d5.loss_cls: 0.0875  decode.d5.loss_mask: 0.2905  decode.d5.loss_dice: 0.2728  decode.d6.loss_cls: 0.0934  decode.d6.loss_mask: 0.2910  decode.d6.loss_dice: 0.2774  decode.d7.loss_cls: 0.0813  decode.d7.loss_mask: 0.2893  decode.d7.loss_dice: 0.2804  decode.d8.loss_cls: 0.0768  decode.d8.loss_mask: 0.2902  decode.d8.loss_dice: 0.2788
07/30 02:02:15 - mmengine - INFO - Iter(train) [20850/80000]  base_lr: 7.6205e-05 lr: 7.6205e-06  eta: 8:44:32  time: 0.5365  data_time: 0.0137  memory: 5916  grad_norm: 320.6608  loss: 6.9990  decode.loss_cls: 0.1328  decode.loss_mask: 0.2412  decode.loss_dice: 0.2449  decode.d0.loss_cls: 0.9068  decode.d0.loss_mask: 0.2373  decode.d0.loss_dice: 0.2801  decode.d1.loss_cls: 0.2044  decode.d1.loss_mask: 0.2180  decode.d1.loss_dice: 0.2528  decode.d2.loss_cls: 0.1752  decode.d2.loss_mask: 0.2170  decode.d2.loss_dice: 0.2525  decode.d3.loss_cls: 0.1232  decode.d3.loss_mask: 0.2136  decode.d3.loss_dice: 0.2662  decode.d4.loss_cls: 0.1232  decode.d4.loss_mask: 0.2222  decode.d4.loss_dice: 0.2664  decode.d5.loss_cls: 0.1122  decode.d5.loss_mask: 0.2264  decode.d5.loss_dice: 0.2572  decode.d6.loss_cls: 0.1263  decode.d6.loss_mask: 0.2180  decode.d6.loss_dice: 0.2693  decode.d7.loss_cls: 0.1344  decode.d7.loss_mask: 0.2221  decode.d7.loss_dice: 0.2588  decode.d8.loss_cls: 0.1290  decode.d8.loss_mask: 0.2208  decode.d8.loss_dice: 0.2465
07/30 02:02:42 - mmengine - INFO - Iter(train) [20900/80000]  base_lr: 7.6147e-05 lr: 7.6147e-06  eta: 8:44:05  time: 0.5286  data_time: 0.0133  memory: 5882  grad_norm: 80.4532  loss: 7.6347  decode.loss_cls: 0.1383  decode.loss_mask: 0.2952  decode.loss_dice: 0.2574  decode.d0.loss_cls: 1.0014  decode.d0.loss_mask: 0.3084  decode.d0.loss_dice: 0.2726  decode.d1.loss_cls: 0.1599  decode.d1.loss_mask: 0.2997  decode.d1.loss_dice: 0.2556  decode.d2.loss_cls: 0.1280  decode.d2.loss_mask: 0.2941  decode.d2.loss_dice: 0.2439  decode.d3.loss_cls: 0.1294  decode.d3.loss_mask: 0.2929  decode.d3.loss_dice: 0.2582  decode.d4.loss_cls: 0.1327  decode.d4.loss_mask: 0.2928  decode.d4.loss_dice: 0.2602  decode.d5.loss_cls: 0.0898  decode.d5.loss_mask: 0.2934  decode.d5.loss_dice: 0.2541  decode.d6.loss_cls: 0.0953  decode.d6.loss_mask: 0.2926  decode.d6.loss_dice: 0.2475  decode.d7.loss_cls: 0.1488  decode.d7.loss_mask: 0.2896  decode.d7.loss_dice: 0.2452  decode.d8.loss_cls: 0.1204  decode.d8.loss_mask: 0.2948  decode.d8.loss_dice: 0.2428
07/30 02:03:08 - mmengine - INFO - Iter(train) [20950/80000]  base_lr: 7.6089e-05 lr: 7.6089e-06  eta: 8:43:39  time: 0.5394  data_time: 0.0139  memory: 5932  grad_norm: 77.4051  loss: 6.8923  decode.loss_cls: 0.0810  decode.loss_mask: 0.2667  decode.loss_dice: 0.2626  decode.d0.loss_cls: 0.8245  decode.d0.loss_mask: 0.2764  decode.d0.loss_dice: 0.2782  decode.d1.loss_cls: 0.1319  decode.d1.loss_mask: 0.2668  decode.d1.loss_dice: 0.2719  decode.d2.loss_cls: 0.0836  decode.d2.loss_mask: 0.2656  decode.d2.loss_dice: 0.2715  decode.d3.loss_cls: 0.0691  decode.d3.loss_mask: 0.2678  decode.d3.loss_dice: 0.2738  decode.d4.loss_cls: 0.0571  decode.d4.loss_mask: 0.2697  decode.d4.loss_dice: 0.2654  decode.d5.loss_cls: 0.0409  decode.d5.loss_mask: 0.2667  decode.d5.loss_dice: 0.2752  decode.d6.loss_cls: 0.0793  decode.d6.loss_mask: 0.2662  decode.d6.loss_dice: 0.2624  decode.d7.loss_cls: 0.0646  decode.d7.loss_mask: 0.2648  decode.d7.loss_dice: 0.2750  decode.d8.loss_cls: 0.0866  decode.d8.loss_mask: 0.2634  decode.d8.loss_dice: 0.2634
07/30 02:03:35 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/30 02:03:35 - mmengine - INFO - Iter(train) [21000/80000]  base_lr: 7.6031e-05 lr: 7.6031e-06  eta: 8:43:13  time: 0.5348  data_time: 0.0137  memory: 5934  grad_norm: 123.6991  loss: 7.0497  decode.loss_cls: 0.0448  decode.loss_mask: 0.2244  decode.loss_dice: 0.3144  decode.d0.loss_cls: 0.9720  decode.d0.loss_mask: 0.2260  decode.d0.loss_dice: 0.3407  decode.d1.loss_cls: 0.2135  decode.d1.loss_mask: 0.2251  decode.d1.loss_dice: 0.3004  decode.d2.loss_cls: 0.1067  decode.d2.loss_mask: 0.2252  decode.d2.loss_dice: 0.3062  decode.d3.loss_cls: 0.1080  decode.d3.loss_mask: 0.2217  decode.d3.loss_dice: 0.3045  decode.d4.loss_cls: 0.0403  decode.d4.loss_mask: 0.2258  decode.d4.loss_dice: 0.3046  decode.d5.loss_cls: 0.0601  decode.d5.loss_mask: 0.2247  decode.d5.loss_dice: 0.3147  decode.d6.loss_cls: 0.0325  decode.d6.loss_mask: 0.2251  decode.d6.loss_dice: 0.3123  decode.d7.loss_cls: 0.0376  decode.d7.loss_mask: 0.2259  decode.d7.loss_dice: 0.3055  decode.d8.loss_cls: 0.0473  decode.d8.loss_mask: 0.2302  decode.d8.loss_dice: 0.3293
07/30 02:04:02 - mmengine - INFO - Iter(train) [21050/80000]  base_lr: 7.5973e-05 lr: 7.5973e-06  eta: 8:42:46  time: 0.5326  data_time: 0.0138  memory: 5916  grad_norm: 82.0824  loss: 6.6979  decode.loss_cls: 0.0781  decode.loss_mask: 0.2718  decode.loss_dice: 0.2411  decode.d0.loss_cls: 0.8818  decode.d0.loss_mask: 0.2863  decode.d0.loss_dice: 0.2548  decode.d1.loss_cls: 0.1062  decode.d1.loss_mask: 0.2850  decode.d1.loss_dice: 0.2415  decode.d2.loss_cls: 0.0912  decode.d2.loss_mask: 0.2704  decode.d2.loss_dice: 0.2338  decode.d3.loss_cls: 0.0720  decode.d3.loss_mask: 0.2720  decode.d3.loss_dice: 0.2401  decode.d4.loss_cls: 0.0543  decode.d4.loss_mask: 0.2755  decode.d4.loss_dice: 0.2326  decode.d5.loss_cls: 0.0587  decode.d5.loss_mask: 0.2698  decode.d5.loss_dice: 0.2459  decode.d6.loss_cls: 0.0655  decode.d6.loss_mask: 0.2671  decode.d6.loss_dice: 0.2401  decode.d7.loss_cls: 0.0659  decode.d7.loss_mask: 0.2674  decode.d7.loss_dice: 0.2439  decode.d8.loss_cls: 0.0720  decode.d8.loss_mask: 0.2715  decode.d8.loss_dice: 0.2414
07/30 02:04:28 - mmengine - INFO - Iter(train) [21100/80000]  base_lr: 7.5915e-05 lr: 7.5915e-06  eta: 8:42:20  time: 0.5340  data_time: 0.0137  memory: 5918  grad_norm: 67.2962  loss: 6.9696  decode.loss_cls: 0.0909  decode.loss_mask: 0.2307  decode.loss_dice: 0.2847  decode.d0.loss_cls: 0.9724  decode.d0.loss_mask: 0.2323  decode.d0.loss_dice: 0.2850  decode.d1.loss_cls: 0.1721  decode.d1.loss_mask: 0.2288  decode.d1.loss_dice: 0.2727  decode.d2.loss_cls: 0.0874  decode.d2.loss_mask: 0.2316  decode.d2.loss_dice: 0.2884  decode.d3.loss_cls: 0.0824  decode.d3.loss_mask: 0.2316  decode.d3.loss_dice: 0.2927  decode.d4.loss_cls: 0.1109  decode.d4.loss_mask: 0.2284  decode.d4.loss_dice: 0.2898  decode.d5.loss_cls: 0.0801  decode.d5.loss_mask: 0.2267  decode.d5.loss_dice: 0.2904  decode.d6.loss_cls: 0.0994  decode.d6.loss_mask: 0.2276  decode.d6.loss_dice: 0.2795  decode.d7.loss_cls: 0.0810  decode.d7.loss_mask: 0.2289  decode.d7.loss_dice: 0.2616  decode.d8.loss_cls: 0.0799  decode.d8.loss_mask: 0.2287  decode.d8.loss_dice: 0.2729
07/30 02:04:55 - mmengine - INFO - Iter(train) [21150/80000]  base_lr: 7.5857e-05 lr: 7.5857e-06  eta: 8:41:53  time: 0.5369  data_time: 0.0143  memory: 5934  grad_norm: 138.6584  loss: 7.5901  decode.loss_cls: 0.2202  decode.loss_mask: 0.2340  decode.loss_dice: 0.2750  decode.d0.loss_cls: 0.9191  decode.d0.loss_mask: 0.2477  decode.d0.loss_dice: 0.2962  decode.d1.loss_cls: 0.2338  decode.d1.loss_mask: 0.2302  decode.d1.loss_dice: 0.2604  decode.d2.loss_cls: 0.1197  decode.d2.loss_mask: 0.2279  decode.d2.loss_dice: 0.2665  decode.d3.loss_cls: 0.1336  decode.d3.loss_mask: 0.2289  decode.d3.loss_dice: 0.2507  decode.d4.loss_cls: 0.2311  decode.d4.loss_mask: 0.2291  decode.d4.loss_dice: 0.2526  decode.d5.loss_cls: 0.1624  decode.d5.loss_mask: 0.2308  decode.d5.loss_dice: 0.2761  decode.d6.loss_cls: 0.1267  decode.d6.loss_mask: 0.2368  decode.d6.loss_dice: 0.2743  decode.d7.loss_cls: 0.1585  decode.d7.loss_mask: 0.2349  decode.d7.loss_dice: 0.2713  decode.d8.loss_cls: 0.2473  decode.d8.loss_mask: 0.2332  decode.d8.loss_dice: 0.2810
07/30 02:05:22 - mmengine - INFO - Iter(train) [21200/80000]  base_lr: 7.5799e-05 lr: 7.5799e-06  eta: 8:41:27  time: 0.5362  data_time: 0.0139  memory: 5894  grad_norm: 86.4553  loss: 7.3496  decode.loss_cls: 0.1330  decode.loss_mask: 0.2591  decode.loss_dice: 0.2533  decode.d0.loss_cls: 0.9441  decode.d0.loss_mask: 0.2654  decode.d0.loss_dice: 0.2677  decode.d1.loss_cls: 0.1854  decode.d1.loss_mask: 0.2598  decode.d1.loss_dice: 0.2768  decode.d2.loss_cls: 0.1749  decode.d2.loss_mask: 0.2590  decode.d2.loss_dice: 0.2698  decode.d3.loss_cls: 0.1482  decode.d3.loss_mask: 0.2599  decode.d3.loss_dice: 0.2397  decode.d4.loss_cls: 0.1526  decode.d4.loss_mask: 0.2600  decode.d4.loss_dice: 0.2432  decode.d5.loss_cls: 0.1273  decode.d5.loss_mask: 0.2589  decode.d5.loss_dice: 0.2664  decode.d6.loss_cls: 0.1171  decode.d6.loss_mask: 0.2603  decode.d6.loss_dice: 0.2433  decode.d7.loss_cls: 0.1052  decode.d7.loss_mask: 0.2619  decode.d7.loss_dice: 0.2405  decode.d8.loss_cls: 0.1151  decode.d8.loss_mask: 0.2587  decode.d8.loss_dice: 0.2431
07/30 02:05:48 - mmengine - INFO - Iter(train) [21250/80000]  base_lr: 7.5741e-05 lr: 7.5741e-06  eta: 8:41:00  time: 0.5341  data_time: 0.0136  memory: 5916  grad_norm: 107.8528  loss: 7.2473  decode.loss_cls: 0.1704  decode.loss_mask: 0.2826  decode.loss_dice: 0.2393  decode.d0.loss_cls: 0.7826  decode.d0.loss_mask: 0.2923  decode.d0.loss_dice: 0.2689  decode.d1.loss_cls: 0.1237  decode.d1.loss_mask: 0.2874  decode.d1.loss_dice: 0.2351  decode.d2.loss_cls: 0.0515  decode.d2.loss_mask: 0.2861  decode.d2.loss_dice: 0.2565  decode.d3.loss_cls: 0.1146  decode.d3.loss_mask: 0.2844  decode.d3.loss_dice: 0.2475  decode.d4.loss_cls: 0.1450  decode.d4.loss_mask: 0.2816  decode.d4.loss_dice: 0.2351  decode.d5.loss_cls: 0.1821  decode.d5.loss_mask: 0.2805  decode.d5.loss_dice: 0.2378  decode.d6.loss_cls: 0.1571  decode.d6.loss_mask: 0.2805  decode.d6.loss_dice: 0.2415  decode.d7.loss_cls: 0.1069  decode.d7.loss_mask: 0.2855  decode.d7.loss_dice: 0.2526  decode.d8.loss_cls: 0.1074  decode.d8.loss_mask: 0.2861  decode.d8.loss_dice: 0.2447
07/30 02:06:15 - mmengine - INFO - Iter(train) [21300/80000]  base_lr: 7.5683e-05 lr: 7.5683e-06  eta: 8:40:35  time: 0.5325  data_time: 0.0138  memory: 5918  grad_norm: 74.4846  loss: 9.0239  decode.loss_cls: 0.2321  decode.loss_mask: 0.2854  decode.loss_dice: 0.3452  decode.d0.loss_cls: 1.0153  decode.d0.loss_mask: 0.2922  decode.d0.loss_dice: 0.3677  decode.d1.loss_cls: 0.1751  decode.d1.loss_mask: 0.2911  decode.d1.loss_dice: 0.3610  decode.d2.loss_cls: 0.2134  decode.d2.loss_mask: 0.2853  decode.d2.loss_dice: 0.3478  decode.d3.loss_cls: 0.1133  decode.d3.loss_mask: 0.2834  decode.d3.loss_dice: 0.3467  decode.d4.loss_cls: 0.1477  decode.d4.loss_mask: 0.2846  decode.d4.loss_dice: 0.3382  decode.d5.loss_cls: 0.2197  decode.d5.loss_mask: 0.2815  decode.d5.loss_dice: 0.3516  decode.d6.loss_cls: 0.1725  decode.d6.loss_mask: 0.2844  decode.d6.loss_dice: 0.3214  decode.d7.loss_cls: 0.2072  decode.d7.loss_mask: 0.2796  decode.d7.loss_dice: 0.3364  decode.d8.loss_cls: 0.2503  decode.d8.loss_mask: 0.2811  decode.d8.loss_dice: 0.3129
07/30 02:06:42 - mmengine - INFO - Iter(train) [21350/80000]  base_lr: 7.5625e-05 lr: 7.5625e-06  eta: 8:40:08  time: 0.5317  data_time: 0.0135  memory: 5931  grad_norm: 63.0982  loss: 8.8216  decode.loss_cls: 0.1977  decode.loss_mask: 0.2619  decode.loss_dice: 0.3383  decode.d0.loss_cls: 0.9777  decode.d0.loss_mask: 0.2780  decode.d0.loss_dice: 0.3405  decode.d1.loss_cls: 0.3263  decode.d1.loss_mask: 0.2694  decode.d1.loss_dice: 0.3512  decode.d2.loss_cls: 0.2056  decode.d2.loss_mask: 0.2662  decode.d2.loss_dice: 0.3026  decode.d3.loss_cls: 0.1979  decode.d3.loss_mask: 0.2676  decode.d3.loss_dice: 0.3089  decode.d4.loss_cls: 0.2442  decode.d4.loss_mask: 0.2640  decode.d4.loss_dice: 0.3251  decode.d5.loss_cls: 0.1762  decode.d5.loss_mask: 0.2624  decode.d5.loss_dice: 0.3053  decode.d6.loss_cls: 0.2305  decode.d6.loss_mask: 0.2607  decode.d6.loss_dice: 0.3154  decode.d7.loss_cls: 0.1970  decode.d7.loss_mask: 0.2632  decode.d7.loss_dice: 0.3077  decode.d8.loss_cls: 0.1989  decode.d8.loss_mask: 0.2621  decode.d8.loss_dice: 0.3192
07/30 02:07:09 - mmengine - INFO - Iter(train) [21400/80000]  base_lr: 7.5567e-05 lr: 7.5567e-06  eta: 8:39:42  time: 0.5374  data_time: 0.0137  memory: 5918  grad_norm: 116.5749  loss: 7.6838  decode.loss_cls: 0.1855  decode.loss_mask: 0.2679  decode.loss_dice: 0.2669  decode.d0.loss_cls: 0.9268  decode.d0.loss_mask: 0.2786  decode.d0.loss_dice: 0.2793  decode.d1.loss_cls: 0.1520  decode.d1.loss_mask: 0.2635  decode.d1.loss_dice: 0.2516  decode.d2.loss_cls: 0.0768  decode.d2.loss_mask: 0.2666  decode.d2.loss_dice: 0.2463  decode.d3.loss_cls: 0.0939  decode.d3.loss_mask: 0.2672  decode.d3.loss_dice: 0.2486  decode.d4.loss_cls: 0.2151  decode.d4.loss_mask: 0.2704  decode.d4.loss_dice: 0.2650  decode.d5.loss_cls: 0.2140  decode.d5.loss_mask: 0.2661  decode.d5.loss_dice: 0.2435  decode.d6.loss_cls: 0.2216  decode.d6.loss_mask: 0.2643  decode.d6.loss_dice: 0.2396  decode.d7.loss_cls: 0.1853  decode.d7.loss_mask: 0.2623  decode.d7.loss_dice: 0.2522  decode.d8.loss_cls: 0.2136  decode.d8.loss_mask: 0.2651  decode.d8.loss_dice: 0.2341
07/30 02:07:36 - mmengine - INFO - Iter(train) [21450/80000]  base_lr: 7.5509e-05 lr: 7.5509e-06  eta: 8:39:16  time: 0.5403  data_time: 0.0148  memory: 5916  grad_norm: 95.4952  loss: 7.5669  decode.loss_cls: 0.1750  decode.loss_mask: 0.2506  decode.loss_dice: 0.2321  decode.d0.loss_cls: 0.9820  decode.d0.loss_mask: 0.2605  decode.d0.loss_dice: 0.2643  decode.d1.loss_cls: 0.2427  decode.d1.loss_mask: 0.2517  decode.d1.loss_dice: 0.2474  decode.d2.loss_cls: 0.2130  decode.d2.loss_mask: 0.2529  decode.d2.loss_dice: 0.2443  decode.d3.loss_cls: 0.1602  decode.d3.loss_mask: 0.2489  decode.d3.loss_dice: 0.2404  decode.d4.loss_cls: 0.1755  decode.d4.loss_mask: 0.2517  decode.d4.loss_dice: 0.2456  decode.d5.loss_cls: 0.1545  decode.d5.loss_mask: 0.2495  decode.d5.loss_dice: 0.2427  decode.d6.loss_cls: 0.1703  decode.d6.loss_mask: 0.2475  decode.d6.loss_dice: 0.2285  decode.d7.loss_cls: 0.1623  decode.d7.loss_mask: 0.2516  decode.d7.loss_dice: 0.2403  decode.d8.loss_cls: 0.1907  decode.d8.loss_mask: 0.2508  decode.d8.loss_dice: 0.2394
07/30 02:08:02 - mmengine - INFO - Iter(train) [21500/80000]  base_lr: 7.5451e-05 lr: 7.5451e-06  eta: 8:38:50  time: 0.5265  data_time: 0.0136  memory: 5897  grad_norm: 56.0609  loss: 6.1224  decode.loss_cls: 0.0427  decode.loss_mask: 0.2340  decode.loss_dice: 0.2533  decode.d0.loss_cls: 0.7757  decode.d0.loss_mask: 0.2405  decode.d0.loss_dice: 0.2826  decode.d1.loss_cls: 0.0951  decode.d1.loss_mask: 0.2328  decode.d1.loss_dice: 0.2482  decode.d2.loss_cls: 0.0391  decode.d2.loss_mask: 0.2343  decode.d2.loss_dice: 0.2466  decode.d3.loss_cls: 0.0390  decode.d3.loss_mask: 0.2361  decode.d3.loss_dice: 0.2458  decode.d4.loss_cls: 0.0381  decode.d4.loss_mask: 0.2348  decode.d4.loss_dice: 0.2466  decode.d5.loss_cls: 0.0313  decode.d5.loss_mask: 0.2378  decode.d5.loss_dice: 0.2555  decode.d6.loss_cls: 0.0780  decode.d6.loss_mask: 0.2372  decode.d6.loss_dice: 0.2478  decode.d7.loss_cls: 0.0549  decode.d7.loss_mask: 0.2345  decode.d7.loss_dice: 0.2619  decode.d8.loss_cls: 0.0328  decode.d8.loss_mask: 0.2347  decode.d8.loss_dice: 0.2509
07/30 02:08:29 - mmengine - INFO - Iter(train) [21550/80000]  base_lr: 7.5393e-05 lr: 7.5393e-06  eta: 8:38:23  time: 0.5291  data_time: 0.0138  memory: 5916  grad_norm: 86.7001  loss: 10.1247  decode.loss_cls: 0.3244  decode.loss_mask: 0.2631  decode.loss_dice: 0.3467  decode.d0.loss_cls: 0.9582  decode.d0.loss_mask: 0.2747  decode.d0.loss_dice: 0.3548  decode.d1.loss_cls: 0.2817  decode.d1.loss_mask: 0.2621  decode.d1.loss_dice: 0.3585  decode.d2.loss_cls: 0.3523  decode.d2.loss_mask: 0.2665  decode.d2.loss_dice: 0.3654  decode.d3.loss_cls: 0.3125  decode.d3.loss_mask: 0.2702  decode.d3.loss_dice: 0.3415  decode.d4.loss_cls: 0.3411  decode.d4.loss_mask: 0.2671  decode.d4.loss_dice: 0.3515  decode.d5.loss_cls: 0.3405  decode.d5.loss_mask: 0.2684  decode.d5.loss_dice: 0.3588  decode.d6.loss_cls: 0.3019  decode.d6.loss_mask: 0.2658  decode.d6.loss_dice: 0.3502  decode.d7.loss_cls: 0.3175  decode.d7.loss_mask: 0.2668  decode.d7.loss_dice: 0.3501  decode.d8.loss_cls: 0.3837  decode.d8.loss_mask: 0.2683  decode.d8.loss_dice: 0.3603
07/30 02:08:55 - mmengine - INFO - Iter(train) [21600/80000]  base_lr: 7.5335e-05 lr: 7.5335e-06  eta: 8:37:55  time: 0.5339  data_time: 0.0138  memory: 5916  grad_norm: 44.4074  loss: 7.5673  decode.loss_cls: 0.1310  decode.loss_mask: 0.2539  decode.loss_dice: 0.3054  decode.d0.loss_cls: 0.8165  decode.d0.loss_mask: 0.2606  decode.d0.loss_dice: 0.3090  decode.d1.loss_cls: 0.1502  decode.d1.loss_mask: 0.2513  decode.d1.loss_dice: 0.3090  decode.d2.loss_cls: 0.1348  decode.d2.loss_mask: 0.2515  decode.d2.loss_dice: 0.2898  decode.d3.loss_cls: 0.1264  decode.d3.loss_mask: 0.2555  decode.d3.loss_dice: 0.2928  decode.d4.loss_cls: 0.1330  decode.d4.loss_mask: 0.2565  decode.d4.loss_dice: 0.2929  decode.d5.loss_cls: 0.1325  decode.d5.loss_mask: 0.2524  decode.d5.loss_dice: 0.2861  decode.d6.loss_cls: 0.1174  decode.d6.loss_mask: 0.2480  decode.d6.loss_dice: 0.3038  decode.d7.loss_cls: 0.1510  decode.d7.loss_mask: 0.2516  decode.d7.loss_dice: 0.3045  decode.d8.loss_cls: 0.1436  decode.d8.loss_mask: 0.2491  decode.d8.loss_dice: 0.3072
07/30 02:09:22 - mmengine - INFO - Iter(train) [21650/80000]  base_lr: 7.5277e-05 lr: 7.5277e-06  eta: 8:37:29  time: 0.5302  data_time: 0.0135  memory: 5896  grad_norm: 166.4979  loss: 10.2479  decode.loss_cls: 0.3485  decode.loss_mask: 0.3131  decode.loss_dice: 0.3072  decode.d0.loss_cls: 1.0794  decode.d0.loss_mask: 0.3243  decode.d0.loss_dice: 0.3287  decode.d1.loss_cls: 0.3492  decode.d1.loss_mask: 0.3215  decode.d1.loss_dice: 0.3088  decode.d2.loss_cls: 0.2983  decode.d2.loss_mask: 0.3148  decode.d2.loss_dice: 0.2949  decode.d3.loss_cls: 0.2849  decode.d3.loss_mask: 0.3201  decode.d3.loss_dice: 0.3127  decode.d4.loss_cls: 0.3234  decode.d4.loss_mask: 0.3205  decode.d4.loss_dice: 0.2951  decode.d5.loss_cls: 0.3229  decode.d5.loss_mask: 0.3209  decode.d5.loss_dice: 0.3263  decode.d6.loss_cls: 0.3273  decode.d6.loss_mask: 0.3158  decode.d6.loss_dice: 0.3191  decode.d7.loss_cls: 0.2981  decode.d7.loss_mask: 0.3266  decode.d7.loss_dice: 0.3204  decode.d8.loss_cls: 0.2790  decode.d8.loss_mask: 0.3214  decode.d8.loss_dice: 0.3248
07/30 02:09:48 - mmengine - INFO - Iter(train) [21700/80000]  base_lr: 7.5219e-05 lr: 7.5219e-06  eta: 8:37:02  time: 0.5319  data_time: 0.0138  memory: 5916  grad_norm: 137.7412  loss: 7.3531  decode.loss_cls: 0.0802  decode.loss_mask: 0.3275  decode.loss_dice: 0.2381  decode.d0.loss_cls: 0.8208  decode.d0.loss_mask: 0.3381  decode.d0.loss_dice: 0.2667  decode.d1.loss_cls: 0.1488  decode.d1.loss_mask: 0.3346  decode.d1.loss_dice: 0.2483  decode.d2.loss_cls: 0.0929  decode.d2.loss_mask: 0.3279  decode.d2.loss_dice: 0.2473  decode.d3.loss_cls: 0.0743  decode.d3.loss_mask: 0.3259  decode.d3.loss_dice: 0.2427  decode.d4.loss_cls: 0.0789  decode.d4.loss_mask: 0.3260  decode.d4.loss_dice: 0.2404  decode.d5.loss_cls: 0.0903  decode.d5.loss_mask: 0.3262  decode.d5.loss_dice: 0.2344  decode.d6.loss_cls: 0.0855  decode.d6.loss_mask: 0.3272  decode.d6.loss_dice: 0.2379  decode.d7.loss_cls: 0.0761  decode.d7.loss_mask: 0.3269  decode.d7.loss_dice: 0.2538  decode.d8.loss_cls: 0.0683  decode.d8.loss_mask: 0.3315  decode.d8.loss_dice: 0.2356
07/30 02:10:15 - mmengine - INFO - Iter(train) [21750/80000]  base_lr: 7.5161e-05 lr: 7.5161e-06  eta: 8:36:36  time: 0.5426  data_time: 0.0144  memory: 5897  grad_norm: 85.1472  loss: 6.3367  decode.loss_cls: 0.0825  decode.loss_mask: 0.2073  decode.loss_dice: 0.2604  decode.d0.loss_cls: 0.8978  decode.d0.loss_mask: 0.2133  decode.d0.loss_dice: 0.2740  decode.d1.loss_cls: 0.1173  decode.d1.loss_mask: 0.2078  decode.d1.loss_dice: 0.2543  decode.d2.loss_cls: 0.0965  decode.d2.loss_mask: 0.2082  decode.d2.loss_dice: 0.2509  decode.d3.loss_cls: 0.0603  decode.d3.loss_mask: 0.2010  decode.d3.loss_dice: 0.2509  decode.d4.loss_cls: 0.0941  decode.d4.loss_mask: 0.2074  decode.d4.loss_dice: 0.2502  decode.d5.loss_cls: 0.0861  decode.d5.loss_mask: 0.2077  decode.d5.loss_dice: 0.2622  decode.d6.loss_cls: 0.0985  decode.d6.loss_mask: 0.2054  decode.d6.loss_dice: 0.2609  decode.d7.loss_cls: 0.1142  decode.d7.loss_mask: 0.2041  decode.d7.loss_dice: 0.2449  decode.d8.loss_cls: 0.0549  decode.d8.loss_mask: 0.2059  decode.d8.loss_dice: 0.2580
07/30 02:10:42 - mmengine - INFO - Iter(train) [21800/80000]  base_lr: 7.5103e-05 lr: 7.5103e-06  eta: 8:36:10  time: 0.5420  data_time: 0.0142  memory: 5919  grad_norm: 119.0284  loss: 7.9181  decode.loss_cls: 0.2389  decode.loss_mask: 0.2127  decode.loss_dice: 0.2754  decode.d0.loss_cls: 0.9479  decode.d0.loss_mask: 0.2181  decode.d0.loss_dice: 0.2844  decode.d1.loss_cls: 0.3258  decode.d1.loss_mask: 0.2137  decode.d1.loss_dice: 0.2778  decode.d2.loss_cls: 0.2652  decode.d2.loss_mask: 0.2164  decode.d2.loss_dice: 0.2597  decode.d3.loss_cls: 0.2270  decode.d3.loss_mask: 0.2158  decode.d3.loss_dice: 0.2613  decode.d4.loss_cls: 0.2193  decode.d4.loss_mask: 0.2120  decode.d4.loss_dice: 0.2662  decode.d5.loss_cls: 0.2071  decode.d5.loss_mask: 0.2218  decode.d5.loss_dice: 0.2782  decode.d6.loss_cls: 0.2368  decode.d6.loss_mask: 0.2166  decode.d6.loss_dice: 0.2729  decode.d7.loss_cls: 0.1549  decode.d7.loss_mask: 0.2177  decode.d7.loss_dice: 0.2700  decode.d8.loss_cls: 0.2162  decode.d8.loss_mask: 0.2145  decode.d8.loss_dice: 0.2738
07/30 02:11:09 - mmengine - INFO - Iter(train) [21850/80000]  base_lr: 7.5044e-05 lr: 7.5044e-06  eta: 8:35:45  time: 0.5418  data_time: 0.0137  memory: 5898  grad_norm: 68.4209  loss: 6.8165  decode.loss_cls: 0.0845  decode.loss_mask: 0.2440  decode.loss_dice: 0.2856  decode.d0.loss_cls: 0.8488  decode.d0.loss_mask: 0.2547  decode.d0.loss_dice: 0.2782  decode.d1.loss_cls: 0.0828  decode.d1.loss_mask: 0.2539  decode.d1.loss_dice: 0.2503  decode.d2.loss_cls: 0.1044  decode.d2.loss_mask: 0.2549  decode.d2.loss_dice: 0.2705  decode.d3.loss_cls: 0.1016  decode.d3.loss_mask: 0.2471  decode.d3.loss_dice: 0.2520  decode.d4.loss_cls: 0.0938  decode.d4.loss_mask: 0.2490  decode.d4.loss_dice: 0.2565  decode.d5.loss_cls: 0.1038  decode.d5.loss_mask: 0.2467  decode.d5.loss_dice: 0.2516  decode.d6.loss_cls: 0.1045  decode.d6.loss_mask: 0.2450  decode.d6.loss_dice: 0.2641  decode.d7.loss_cls: 0.0992  decode.d7.loss_mask: 0.2459  decode.d7.loss_dice: 0.2494  decode.d8.loss_cls: 0.0939  decode.d8.loss_mask: 0.2471  decode.d8.loss_dice: 0.2528
07/30 02:11:36 - mmengine - INFO - Iter(train) [21900/80000]  base_lr: 7.4986e-05 lr: 7.4986e-06  eta: 8:35:20  time: 0.5422  data_time: 0.0137  memory: 5916  grad_norm: 68.0579  loss: 6.7473  decode.loss_cls: 0.0801  decode.loss_mask: 0.2504  decode.loss_dice: 0.2247  decode.d0.loss_cls: 0.9564  decode.d0.loss_mask: 0.2337  decode.d0.loss_dice: 0.2417  decode.d1.loss_cls: 0.1692  decode.d1.loss_mask: 0.2358  decode.d1.loss_dice: 0.2226  decode.d2.loss_cls: 0.1132  decode.d2.loss_mask: 0.2344  decode.d2.loss_dice: 0.2182  decode.d3.loss_cls: 0.1013  decode.d3.loss_mask: 0.2390  decode.d3.loss_dice: 0.2273  decode.d4.loss_cls: 0.1108  decode.d4.loss_mask: 0.2267  decode.d4.loss_dice: 0.2242  decode.d5.loss_cls: 0.1537  decode.d5.loss_mask: 0.2381  decode.d5.loss_dice: 0.2283  decode.d6.loss_cls: 0.1505  decode.d6.loss_mask: 0.2438  decode.d6.loss_dice: 0.2193  decode.d7.loss_cls: 0.1560  decode.d7.loss_mask: 0.2417  decode.d7.loss_dice: 0.2316  decode.d8.loss_cls: 0.1030  decode.d8.loss_mask: 0.2391  decode.d8.loss_dice: 0.2324
07/30 02:12:03 - mmengine - INFO - Iter(train) [21950/80000]  base_lr: 7.4928e-05 lr: 7.4928e-06  eta: 8:34:54  time: 0.5274  data_time: 0.0122  memory: 5933  grad_norm: 90.5040  loss: 6.9621  decode.loss_cls: 0.0770  decode.loss_mask: 0.2353  decode.loss_dice: 0.2550  decode.d0.loss_cls: 1.0196  decode.d0.loss_mask: 0.2379  decode.d0.loss_dice: 0.2807  decode.d1.loss_cls: 0.2159  decode.d1.loss_mask: 0.2362  decode.d1.loss_dice: 0.2706  decode.d2.loss_cls: 0.1161  decode.d2.loss_mask: 0.2302  decode.d2.loss_dice: 0.2713  decode.d3.loss_cls: 0.0916  decode.d3.loss_mask: 0.2312  decode.d3.loss_dice: 0.2639  decode.d4.loss_cls: 0.0946  decode.d4.loss_mask: 0.2305  decode.d4.loss_dice: 0.2639  decode.d5.loss_cls: 0.0700  decode.d5.loss_mask: 0.2340  decode.d5.loss_dice: 0.2452  decode.d6.loss_cls: 0.1299  decode.d6.loss_mask: 0.2330  decode.d6.loss_dice: 0.2578  decode.d7.loss_cls: 0.0985  decode.d7.loss_mask: 0.2360  decode.d7.loss_dice: 0.2667  decode.d8.loss_cls: 0.0798  decode.d8.loss_mask: 0.2354  decode.d8.loss_dice: 0.2544
07/30 02:12:29 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/30 02:12:29 - mmengine - INFO - Iter(train) [22000/80000]  base_lr: 7.4870e-05 lr: 7.4870e-06  eta: 8:34:26  time: 0.5241  data_time: 0.0124  memory: 5898  grad_norm: 53.1031  loss: 7.8993  decode.loss_cls: 0.1681  decode.loss_mask: 0.2333  decode.loss_dice: 0.2930  decode.d0.loss_cls: 0.9293  decode.d0.loss_mask: 0.2350  decode.d0.loss_dice: 0.3237  decode.d1.loss_cls: 0.1885  decode.d1.loss_mask: 0.2357  decode.d1.loss_dice: 0.3225  decode.d2.loss_cls: 0.1927  decode.d2.loss_mask: 0.2252  decode.d2.loss_dice: 0.2986  decode.d3.loss_cls: 0.1929  decode.d3.loss_mask: 0.2318  decode.d3.loss_dice: 0.3050  decode.d4.loss_cls: 0.1739  decode.d4.loss_mask: 0.2272  decode.d4.loss_dice: 0.2921  decode.d5.loss_cls: 0.1675  decode.d5.loss_mask: 0.2404  decode.d5.loss_dice: 0.3013  decode.d6.loss_cls: 0.1818  decode.d6.loss_mask: 0.2275  decode.d6.loss_dice: 0.2916  decode.d7.loss_cls: 0.1786  decode.d7.loss_mask: 0.2268  decode.d7.loss_dice: 0.3058  decode.d8.loss_cls: 0.1801  decode.d8.loss_mask: 0.2325  decode.d8.loss_dice: 0.2969
07/30 02:12:56 - mmengine - INFO - Iter(train) [22050/80000]  base_lr: 7.4812e-05 lr: 7.4812e-06  eta: 8:33:59  time: 0.5403  data_time: 0.0139  memory: 5918  grad_norm: 70.3770  loss: 7.0590  decode.loss_cls: 0.1149  decode.loss_mask: 0.2388  decode.loss_dice: 0.2623  decode.d0.loss_cls: 0.9113  decode.d0.loss_mask: 0.2481  decode.d0.loss_dice: 0.2884  decode.d1.loss_cls: 0.1806  decode.d1.loss_mask: 0.2406  decode.d1.loss_dice: 0.2730  decode.d2.loss_cls: 0.1620  decode.d2.loss_mask: 0.2387  decode.d2.loss_dice: 0.2634  decode.d3.loss_cls: 0.1394  decode.d3.loss_mask: 0.2420  decode.d3.loss_dice: 0.2679  decode.d4.loss_cls: 0.1251  decode.d4.loss_mask: 0.2372  decode.d4.loss_dice: 0.2564  decode.d5.loss_cls: 0.1220  decode.d5.loss_mask: 0.2380  decode.d5.loss_dice: 0.2576  decode.d6.loss_cls: 0.0636  decode.d6.loss_mask: 0.2511  decode.d6.loss_dice: 0.2667  decode.d7.loss_cls: 0.0693  decode.d7.loss_mask: 0.2468  decode.d7.loss_dice: 0.2683  decode.d8.loss_cls: 0.0674  decode.d8.loss_mask: 0.2432  decode.d8.loss_dice: 0.2748
07/30 02:13:23 - mmengine - INFO - Iter(train) [22100/80000]  base_lr: 7.4754e-05 lr: 7.4754e-06  eta: 8:33:33  time: 0.5318  data_time: 0.0132  memory: 5931  grad_norm: 160.8620  loss: 8.8559  decode.loss_cls: 0.1867  decode.loss_mask: 0.2525  decode.loss_dice: 0.3208  decode.d0.loss_cls: 1.0631  decode.d0.loss_mask: 0.2695  decode.d0.loss_dice: 0.3731  decode.d1.loss_cls: 0.3100  decode.d1.loss_mask: 0.2547  decode.d1.loss_dice: 0.3315  decode.d2.loss_cls: 0.1911  decode.d2.loss_mask: 0.2545  decode.d2.loss_dice: 0.3240  decode.d3.loss_cls: 0.1887  decode.d3.loss_mask: 0.2559  decode.d3.loss_dice: 0.3223  decode.d4.loss_cls: 0.2336  decode.d4.loss_mask: 0.2531  decode.d4.loss_dice: 0.3119  decode.d5.loss_cls: 0.1728  decode.d5.loss_mask: 0.2562  decode.d5.loss_dice: 0.3331  decode.d6.loss_cls: 0.2498  decode.d6.loss_mask: 0.2547  decode.d6.loss_dice: 0.3439  decode.d7.loss_cls: 0.1923  decode.d7.loss_mask: 0.2558  decode.d7.loss_dice: 0.3277  decode.d8.loss_cls: 0.1893  decode.d8.loss_mask: 0.2553  decode.d8.loss_dice: 0.3280
07/30 02:13:49 - mmengine - INFO - Iter(train) [22150/80000]  base_lr: 7.4696e-05 lr: 7.4696e-06  eta: 8:33:07  time: 0.5383  data_time: 0.0137  memory: 5897  grad_norm: 121.3824  loss: 7.9761  decode.loss_cls: 0.1161  decode.loss_mask: 0.2566  decode.loss_dice: 0.2950  decode.d0.loss_cls: 0.9947  decode.d0.loss_mask: 0.2540  decode.d0.loss_dice: 0.3127  decode.d1.loss_cls: 0.2450  decode.d1.loss_mask: 0.2658  decode.d1.loss_dice: 0.3058  decode.d2.loss_cls: 0.2099  decode.d2.loss_mask: 0.2562  decode.d2.loss_dice: 0.3003  decode.d3.loss_cls: 0.1790  decode.d3.loss_mask: 0.2668  decode.d3.loss_dice: 0.2963  decode.d4.loss_cls: 0.1737  decode.d4.loss_mask: 0.2603  decode.d4.loss_dice: 0.3001  decode.d5.loss_cls: 0.1206  decode.d5.loss_mask: 0.2617  decode.d5.loss_dice: 0.3026  decode.d6.loss_cls: 0.1081  decode.d6.loss_mask: 0.2605  decode.d6.loss_dice: 0.2972  decode.d7.loss_cls: 0.1206  decode.d7.loss_mask: 0.2627  decode.d7.loss_dice: 0.2957  decode.d8.loss_cls: 0.1077  decode.d8.loss_mask: 0.2542  decode.d8.loss_dice: 0.2962
07/30 02:14:16 - mmengine - INFO - Iter(train) [22200/80000]  base_lr: 7.4638e-05 lr: 7.4638e-06  eta: 8:32:41  time: 0.5362  data_time: 0.0132  memory: 5881  grad_norm: 71.6719  loss: 6.5214  decode.loss_cls: 0.0679  decode.loss_mask: 0.2497  decode.loss_dice: 0.2469  decode.d0.loss_cls: 0.7782  decode.d0.loss_mask: 0.2586  decode.d0.loss_dice: 0.2743  decode.d1.loss_cls: 0.1243  decode.d1.loss_mask: 0.2486  decode.d1.loss_dice: 0.2557  decode.d2.loss_cls: 0.0855  decode.d2.loss_mask: 0.2494  decode.d2.loss_dice: 0.2628  decode.d3.loss_cls: 0.0808  decode.d3.loss_mask: 0.2463  decode.d3.loss_dice: 0.2613  decode.d4.loss_cls: 0.0708  decode.d4.loss_mask: 0.2465  decode.d4.loss_dice: 0.2554  decode.d5.loss_cls: 0.0670  decode.d5.loss_mask: 0.2493  decode.d5.loss_dice: 0.2558  decode.d6.loss_cls: 0.0648  decode.d6.loss_mask: 0.2440  decode.d6.loss_dice: 0.2486  decode.d7.loss_cls: 0.0714  decode.d7.loss_mask: 0.2474  decode.d7.loss_dice: 0.2525  decode.d8.loss_cls: 0.0671  decode.d8.loss_mask: 0.2442  decode.d8.loss_dice: 0.2463
07/30 02:14:43 - mmengine - INFO - Iter(train) [22250/80000]  base_lr: 7.4580e-05 lr: 7.4580e-06  eta: 8:32:15  time: 0.5198  data_time: 0.0121  memory: 5918  grad_norm: 113.5077  loss: 9.0682  decode.loss_cls: 0.2798  decode.loss_mask: 0.2468  decode.loss_dice: 0.3430  decode.d0.loss_cls: 1.0869  decode.d0.loss_mask: 0.2615  decode.d0.loss_dice: 0.3717  decode.d1.loss_cls: 0.2362  decode.d1.loss_mask: 0.2569  decode.d1.loss_dice: 0.3630  decode.d2.loss_cls: 0.2539  decode.d2.loss_mask: 0.2517  decode.d2.loss_dice: 0.3416  decode.d3.loss_cls: 0.1775  decode.d3.loss_mask: 0.2476  decode.d3.loss_dice: 0.3326  decode.d4.loss_cls: 0.2026  decode.d4.loss_mask: 0.2483  decode.d4.loss_dice: 0.3303  decode.d5.loss_cls: 0.2005  decode.d5.loss_mask: 0.2451  decode.d5.loss_dice: 0.3472  decode.d6.loss_cls: 0.2453  decode.d6.loss_mask: 0.2477  decode.d6.loss_dice: 0.3340  decode.d7.loss_cls: 0.2162  decode.d7.loss_mask: 0.2456  decode.d7.loss_dice: 0.3405  decode.d8.loss_cls: 0.2312  decode.d8.loss_mask: 0.2474  decode.d8.loss_dice: 0.3355
07/30 02:15:09 - mmengine - INFO - Iter(train) [22300/80000]  base_lr: 7.4522e-05 lr: 7.4522e-06  eta: 8:31:47  time: 0.5301  data_time: 0.0131  memory: 5895  grad_norm: 114.3854  loss: 7.7041  decode.loss_cls: 0.2130  decode.loss_mask: 0.2369  decode.loss_dice: 0.2986  decode.d0.loss_cls: 0.9198  decode.d0.loss_mask: 0.2405  decode.d0.loss_dice: 0.2771  decode.d1.loss_cls: 0.2378  decode.d1.loss_mask: 0.2269  decode.d1.loss_dice: 0.2526  decode.d2.loss_cls: 0.1271  decode.d2.loss_mask: 0.2239  decode.d2.loss_dice: 0.2559  decode.d3.loss_cls: 0.1246  decode.d3.loss_mask: 0.2231  decode.d3.loss_dice: 0.2535  decode.d4.loss_cls: 0.2025  decode.d4.loss_mask: 0.2270  decode.d4.loss_dice: 0.2834  decode.d5.loss_cls: 0.1548  decode.d5.loss_mask: 0.2287  decode.d5.loss_dice: 0.2632  decode.d6.loss_cls: 0.1801  decode.d6.loss_mask: 0.2468  decode.d6.loss_dice: 0.2924  decode.d7.loss_cls: 0.2373  decode.d7.loss_mask: 0.2339  decode.d7.loss_dice: 0.2953  decode.d8.loss_cls: 0.2258  decode.d8.loss_mask: 0.2276  decode.d8.loss_dice: 0.2939
07/30 02:15:36 - mmengine - INFO - Iter(train) [22350/80000]  base_lr: 7.4463e-05 lr: 7.4463e-06  eta: 8:31:20  time: 0.5219  data_time: 0.0122  memory: 5916  grad_norm: 186.7085  loss: 7.2047  decode.loss_cls: 0.1220  decode.loss_mask: 0.2394  decode.loss_dice: 0.2611  decode.d0.loss_cls: 1.1125  decode.d0.loss_mask: 0.2448  decode.d0.loss_dice: 0.2586  decode.d1.loss_cls: 0.1843  decode.d1.loss_mask: 0.2583  decode.d1.loss_dice: 0.2445  decode.d2.loss_cls: 0.1330  decode.d2.loss_mask: 0.2407  decode.d2.loss_dice: 0.2619  decode.d3.loss_cls: 0.1501  decode.d3.loss_mask: 0.2398  decode.d3.loss_dice: 0.2665  decode.d4.loss_cls: 0.1063  decode.d4.loss_mask: 0.2382  decode.d4.loss_dice: 0.2425  decode.d5.loss_cls: 0.1167  decode.d5.loss_mask: 0.2333  decode.d5.loss_dice: 0.2466  decode.d6.loss_cls: 0.1113  decode.d6.loss_mask: 0.2357  decode.d6.loss_dice: 0.2417  decode.d7.loss_cls: 0.1054  decode.d7.loss_mask: 0.2375  decode.d7.loss_dice: 0.2446  decode.d8.loss_cls: 0.1227  decode.d8.loss_mask: 0.2373  decode.d8.loss_dice: 0.2674
07/30 02:16:02 - mmengine - INFO - Iter(train) [22400/80000]  base_lr: 7.4405e-05 lr: 7.4405e-06  eta: 8:30:53  time: 0.5261  data_time: 0.0123  memory: 5971  grad_norm: 71.9981  loss: 6.4591  decode.loss_cls: 0.0338  decode.loss_mask: 0.2446  decode.loss_dice: 0.2605  decode.d0.loss_cls: 0.9880  decode.d0.loss_mask: 0.2538  decode.d0.loss_dice: 0.2825  decode.d1.loss_cls: 0.0405  decode.d1.loss_mask: 0.2476  decode.d1.loss_dice: 0.2837  decode.d2.loss_cls: 0.0379  decode.d2.loss_mask: 0.2494  decode.d2.loss_dice: 0.2708  decode.d3.loss_cls: 0.0306  decode.d3.loss_mask: 0.2478  decode.d3.loss_dice: 0.2588  decode.d4.loss_cls: 0.0324  decode.d4.loss_mask: 0.2500  decode.d4.loss_dice: 0.2690  decode.d5.loss_cls: 0.0276  decode.d5.loss_mask: 0.2466  decode.d5.loss_dice: 0.2693  decode.d6.loss_cls: 0.0288  decode.d6.loss_mask: 0.2442  decode.d6.loss_dice: 0.2698  decode.d7.loss_cls: 0.0391  decode.d7.loss_mask: 0.2465  decode.d7.loss_dice: 0.2598  decode.d8.loss_cls: 0.0373  decode.d8.loss_mask: 0.2434  decode.d8.loss_dice: 0.2652
07/30 02:16:28 - mmengine - INFO - Iter(train) [22450/80000]  base_lr: 7.4347e-05 lr: 7.4347e-06  eta: 8:30:26  time: 0.5322  data_time: 0.0128  memory: 5920  grad_norm: 123.8020  loss: 7.1943  decode.loss_cls: 0.0584  decode.loss_mask: 0.2271  decode.loss_dice: 0.3107  decode.d0.loss_cls: 1.0926  decode.d0.loss_mask: 0.2242  decode.d0.loss_dice: 0.3069  decode.d1.loss_cls: 0.2078  decode.d1.loss_mask: 0.2176  decode.d1.loss_dice: 0.3097  decode.d2.loss_cls: 0.1582  decode.d2.loss_mask: 0.2189  decode.d2.loss_dice: 0.2996  decode.d3.loss_cls: 0.0640  decode.d3.loss_mask: 0.2172  decode.d3.loss_dice: 0.2978  decode.d4.loss_cls: 0.0859  decode.d4.loss_mask: 0.2134  decode.d4.loss_dice: 0.2948  decode.d5.loss_cls: 0.0742  decode.d5.loss_mask: 0.2159  decode.d5.loss_dice: 0.3055  decode.d6.loss_cls: 0.0740  decode.d6.loss_mask: 0.2152  decode.d6.loss_dice: 0.3004  decode.d7.loss_cls: 0.0716  decode.d7.loss_mask: 0.2162  decode.d7.loss_dice: 0.3105  decode.d8.loss_cls: 0.0719  decode.d8.loss_mask: 0.2296  decode.d8.loss_dice: 0.3045
07/30 02:16:55 - mmengine - INFO - Iter(train) [22500/80000]  base_lr: 7.4289e-05 lr: 7.4289e-06  eta: 8:29:58  time: 0.5228  data_time: 0.0125  memory: 5880  grad_norm: 73.2138  loss: 6.6120  decode.loss_cls: 0.0665  decode.loss_mask: 0.2364  decode.loss_dice: 0.2660  decode.d0.loss_cls: 0.8780  decode.d0.loss_mask: 0.2422  decode.d0.loss_dice: 0.2926  decode.d1.loss_cls: 0.0869  decode.d1.loss_mask: 0.2365  decode.d1.loss_dice: 0.2664  decode.d2.loss_cls: 0.1030  decode.d2.loss_mask: 0.2359  decode.d2.loss_dice: 0.2682  decode.d3.loss_cls: 0.0655  decode.d3.loss_mask: 0.2377  decode.d3.loss_dice: 0.2640  decode.d4.loss_cls: 0.0734  decode.d4.loss_mask: 0.2390  decode.d4.loss_dice: 0.2733  decode.d5.loss_cls: 0.0970  decode.d5.loss_mask: 0.2366  decode.d5.loss_dice: 0.2459  decode.d6.loss_cls: 0.0655  decode.d6.loss_mask: 0.2376  decode.d6.loss_dice: 0.2548  decode.d7.loss_cls: 0.0816  decode.d7.loss_mask: 0.2378  decode.d7.loss_dice: 0.2607  decode.d8.loss_cls: 0.0696  decode.d8.loss_mask: 0.2377  decode.d8.loss_dice: 0.2557
07/30 02:17:21 - mmengine - INFO - Iter(train) [22550/80000]  base_lr: 7.4231e-05 lr: 7.4231e-06  eta: 8:29:30  time: 0.5198  data_time: 0.0125  memory: 5918  grad_norm: 202.3574  loss: 9.5471  decode.loss_cls: 0.3957  decode.loss_mask: 0.1990  decode.loss_dice: 0.3329  decode.d0.loss_cls: 1.0305  decode.d0.loss_mask: 0.1985  decode.d0.loss_dice: 0.3256  decode.d1.loss_cls: 0.4260  decode.d1.loss_mask: 0.1969  decode.d1.loss_dice: 0.2873  decode.d2.loss_cls: 0.4217  decode.d2.loss_mask: 0.1971  decode.d2.loss_dice: 0.3117  decode.d3.loss_cls: 0.2879  decode.d3.loss_mask: 0.1983  decode.d3.loss_dice: 0.3312  decode.d4.loss_cls: 0.2584  decode.d4.loss_mask: 0.1996  decode.d4.loss_dice: 0.3413  decode.d5.loss_cls: 0.3750  decode.d5.loss_mask: 0.1970  decode.d5.loss_dice: 0.3287  decode.d6.loss_cls: 0.3017  decode.d6.loss_mask: 0.1966  decode.d6.loss_dice: 0.3286  decode.d7.loss_cls: 0.4228  decode.d7.loss_mask: 0.1978  decode.d7.loss_dice: 0.3244  decode.d8.loss_cls: 0.4205  decode.d8.loss_mask: 0.1946  decode.d8.loss_dice: 0.3200
07/30 02:17:47 - mmengine - INFO - Iter(train) [22600/80000]  base_lr: 7.4173e-05 lr: 7.4173e-06  eta: 8:29:02  time: 0.5184  data_time: 0.0125  memory: 5918  grad_norm: 69.3053  loss: 7.5340  decode.loss_cls: 0.1089  decode.loss_mask: 0.2569  decode.loss_dice: 0.3216  decode.d0.loss_cls: 0.8721  decode.d0.loss_mask: 0.2758  decode.d0.loss_dice: 0.3182  decode.d1.loss_cls: 0.1519  decode.d1.loss_mask: 0.2599  decode.d1.loss_dice: 0.3095  decode.d2.loss_cls: 0.1032  decode.d2.loss_mask: 0.2584  decode.d2.loss_dice: 0.3200  decode.d3.loss_cls: 0.0996  decode.d3.loss_mask: 0.2568  decode.d3.loss_dice: 0.3118  decode.d4.loss_cls: 0.0737  decode.d4.loss_mask: 0.2548  decode.d4.loss_dice: 0.3234  decode.d5.loss_cls: 0.0981  decode.d5.loss_mask: 0.2578  decode.d5.loss_dice: 0.3203  decode.d6.loss_cls: 0.0947  decode.d6.loss_mask: 0.2599  decode.d6.loss_dice: 0.3068  decode.d7.loss_cls: 0.0961  decode.d7.loss_mask: 0.2607  decode.d7.loss_dice: 0.3045  decode.d8.loss_cls: 0.0987  decode.d8.loss_mask: 0.2579  decode.d8.loss_dice: 0.3019
07/30 02:18:13 - mmengine - INFO - Iter(train) [22650/80000]  base_lr: 7.4115e-05 lr: 7.4115e-06  eta: 8:28:35  time: 0.5354  data_time: 0.0134  memory: 5896  grad_norm: 84.5050  loss: 7.7876  decode.loss_cls: 0.1607  decode.loss_mask: 0.2493  decode.loss_dice: 0.2917  decode.d0.loss_cls: 0.8601  decode.d0.loss_mask: 0.2550  decode.d0.loss_dice: 0.3074  decode.d1.loss_cls: 0.1826  decode.d1.loss_mask: 0.2548  decode.d1.loss_dice: 0.2822  decode.d2.loss_cls: 0.2000  decode.d2.loss_mask: 0.2523  decode.d2.loss_dice: 0.2824  decode.d3.loss_cls: 0.1606  decode.d3.loss_mask: 0.2520  decode.d3.loss_dice: 0.2852  decode.d4.loss_cls: 0.1443  decode.d4.loss_mask: 0.2474  decode.d4.loss_dice: 0.2917  decode.d5.loss_cls: 0.1629  decode.d5.loss_mask: 0.2480  decode.d5.loss_dice: 0.2864  decode.d6.loss_cls: 0.1717  decode.d6.loss_mask: 0.2496  decode.d6.loss_dice: 0.2852  decode.d7.loss_cls: 0.1518  decode.d7.loss_mask: 0.2484  decode.d7.loss_dice: 0.2872  decode.d8.loss_cls: 0.1623  decode.d8.loss_mask: 0.2496  decode.d8.loss_dice: 0.3247
07/30 02:18:39 - mmengine - INFO - Iter(train) [22700/80000]  base_lr: 7.4056e-05 lr: 7.4056e-06  eta: 8:28:07  time: 0.5224  data_time: 0.0124  memory: 5936  grad_norm: 64.7312  loss: 6.6770  decode.loss_cls: 0.0805  decode.loss_mask: 0.2474  decode.loss_dice: 0.2387  decode.d0.loss_cls: 0.8288  decode.d0.loss_mask: 0.2501  decode.d0.loss_dice: 0.2710  decode.d1.loss_cls: 0.1423  decode.d1.loss_mask: 0.2383  decode.d1.loss_dice: 0.2348  decode.d2.loss_cls: 0.1479  decode.d2.loss_mask: 0.2422  decode.d2.loss_dice: 0.2375  decode.d3.loss_cls: 0.1107  decode.d3.loss_mask: 0.2417  decode.d3.loss_dice: 0.2500  decode.d4.loss_cls: 0.1100  decode.d4.loss_mask: 0.2434  decode.d4.loss_dice: 0.2396  decode.d5.loss_cls: 0.1032  decode.d5.loss_mask: 0.2425  decode.d5.loss_dice: 0.2498  decode.d6.loss_cls: 0.0774  decode.d6.loss_mask: 0.2440  decode.d6.loss_dice: 0.2455  decode.d7.loss_cls: 0.0722  decode.d7.loss_mask: 0.2421  decode.d7.loss_dice: 0.2343  decode.d8.loss_cls: 0.1200  decode.d8.loss_mask: 0.2445  decode.d8.loss_dice: 0.2467
07/30 02:19:06 - mmengine - INFO - Iter(train) [22750/80000]  base_lr: 7.3998e-05 lr: 7.3998e-06  eta: 8:27:41  time: 0.5328  data_time: 0.0131  memory: 5896  grad_norm: 89.7791  loss: 6.0609  decode.loss_cls: 0.0647  decode.loss_mask: 0.2207  decode.loss_dice: 0.2201  decode.d0.loss_cls: 0.9281  decode.d0.loss_mask: 0.2289  decode.d0.loss_dice: 0.2154  decode.d1.loss_cls: 0.1030  decode.d1.loss_mask: 0.2249  decode.d1.loss_dice: 0.2206  decode.d2.loss_cls: 0.0890  decode.d2.loss_mask: 0.2255  decode.d2.loss_dice: 0.2212  decode.d3.loss_cls: 0.0867  decode.d3.loss_mask: 0.2212  decode.d3.loss_dice: 0.2128  decode.d4.loss_cls: 0.0869  decode.d4.loss_mask: 0.2254  decode.d4.loss_dice: 0.2138  decode.d5.loss_cls: 0.0861  decode.d5.loss_mask: 0.2226  decode.d5.loss_dice: 0.2117  decode.d6.loss_cls: 0.0875  decode.d6.loss_mask: 0.2216  decode.d6.loss_dice: 0.2110  decode.d7.loss_cls: 0.0792  decode.d7.loss_mask: 0.2198  decode.d7.loss_dice: 0.2125  decode.d8.loss_cls: 0.0644  decode.d8.loss_mask: 0.2207  decode.d8.loss_dice: 0.2149
07/30 02:19:33 - mmengine - INFO - Iter(train) [22800/80000]  base_lr: 7.3940e-05 lr: 7.3940e-06  eta: 8:27:14  time: 0.5273  data_time: 0.0132  memory: 5895  grad_norm: 109.4133  loss: 7.5717  decode.loss_cls: 0.1591  decode.loss_mask: 0.2572  decode.loss_dice: 0.2324  decode.d0.loss_cls: 1.0178  decode.d0.loss_mask: 0.2821  decode.d0.loss_dice: 0.3030  decode.d1.loss_cls: 0.2550  decode.d1.loss_mask: 0.2531  decode.d1.loss_dice: 0.2461  decode.d2.loss_cls: 0.1743  decode.d2.loss_mask: 0.2583  decode.d2.loss_dice: 0.2429  decode.d3.loss_cls: 0.2087  decode.d3.loss_mask: 0.2558  decode.d3.loss_dice: 0.2529  decode.d4.loss_cls: 0.1649  decode.d4.loss_mask: 0.2527  decode.d4.loss_dice: 0.2412  decode.d5.loss_cls: 0.1395  decode.d5.loss_mask: 0.2534  decode.d5.loss_dice: 0.2478  decode.d6.loss_cls: 0.1375  decode.d6.loss_mask: 0.2530  decode.d6.loss_dice: 0.2469  decode.d7.loss_cls: 0.1242  decode.d7.loss_mask: 0.2559  decode.d7.loss_dice: 0.2380  decode.d8.loss_cls: 0.1297  decode.d8.loss_mask: 0.2533  decode.d8.loss_dice: 0.2351
07/30 02:19:59 - mmengine - INFO - Iter(train) [22850/80000]  base_lr: 7.3882e-05 lr: 7.3882e-06  eta: 8:26:48  time: 0.5424  data_time: 0.0140  memory: 5883  grad_norm: 205.7856  loss: 11.9899  decode.loss_cls: 0.2790  decode.loss_mask: 0.3762  decode.loss_dice: 0.3542  decode.d0.loss_cls: 1.0594  decode.d0.loss_mask: 0.3772  decode.d0.loss_dice: 0.4401  decode.d1.loss_cls: 0.4082  decode.d1.loss_mask: 0.4132  decode.d1.loss_dice: 0.4189  decode.d2.loss_cls: 0.3126  decode.d2.loss_mask: 0.4073  decode.d2.loss_dice: 0.4133  decode.d3.loss_cls: 0.3330  decode.d3.loss_mask: 0.4042  decode.d3.loss_dice: 0.4196  decode.d4.loss_cls: 0.3674  decode.d4.loss_mask: 0.3807  decode.d4.loss_dice: 0.3946  decode.d5.loss_cls: 0.3055  decode.d5.loss_mask: 0.3839  decode.d5.loss_dice: 0.4085  decode.d6.loss_cls: 0.3613  decode.d6.loss_mask: 0.3912  decode.d6.loss_dice: 0.3954  decode.d7.loss_cls: 0.3058  decode.d7.loss_mask: 0.3779  decode.d7.loss_dice: 0.3898  decode.d8.loss_cls: 0.3243  decode.d8.loss_mask: 0.3775  decode.d8.loss_dice: 0.4096
07/30 02:20:26 - mmengine - INFO - Iter(train) [22900/80000]  base_lr: 7.3824e-05 lr: 7.3824e-06  eta: 8:26:21  time: 0.5311  data_time: 0.0133  memory: 5936  grad_norm: 179.5985  loss: 10.5807  decode.loss_cls: 0.2805  decode.loss_mask: 0.3064  decode.loss_dice: 0.3336  decode.d0.loss_cls: 1.0800  decode.d0.loss_mask: 0.3190  decode.d0.loss_dice: 0.3789  decode.d1.loss_cls: 0.3881  decode.d1.loss_mask: 0.3102  decode.d1.loss_dice: 0.3619  decode.d2.loss_cls: 0.2709  decode.d2.loss_mask: 0.3045  decode.d2.loss_dice: 0.3466  decode.d3.loss_cls: 0.3751  decode.d3.loss_mask: 0.3028  decode.d3.loss_dice: 0.3214  decode.d4.loss_cls: 0.3396  decode.d4.loss_mask: 0.3053  decode.d4.loss_dice: 0.3399  decode.d5.loss_cls: 0.3419  decode.d5.loss_mask: 0.3057  decode.d5.loss_dice: 0.3299  decode.d6.loss_cls: 0.3466  decode.d6.loss_mask: 0.3011  decode.d6.loss_dice: 0.3276  decode.d7.loss_cls: 0.3253  decode.d7.loss_mask: 0.3092  decode.d7.loss_dice: 0.3688  decode.d8.loss_cls: 0.2984  decode.d8.loss_mask: 0.3039  decode.d8.loss_dice: 0.3576
07/30 02:20:52 - mmengine - INFO - Iter(train) [22950/80000]  base_lr: 7.3766e-05 lr: 7.3766e-06  eta: 8:25:53  time: 0.5216  data_time: 0.0125  memory: 5918  grad_norm: 103.2206  loss: 9.1461  decode.loss_cls: 0.2130  decode.loss_mask: 0.2888  decode.loss_dice: 0.3333  decode.d0.loss_cls: 0.9093  decode.d0.loss_mask: 0.2989  decode.d0.loss_dice: 0.3798  decode.d1.loss_cls: 0.1798  decode.d1.loss_mask: 0.2935  decode.d1.loss_dice: 0.3167  decode.d2.loss_cls: 0.1998  decode.d2.loss_mask: 0.2892  decode.d2.loss_dice: 0.3194  decode.d3.loss_cls: 0.2397  decode.d3.loss_mask: 0.2893  decode.d3.loss_dice: 0.3441  decode.d4.loss_cls: 0.2037  decode.d4.loss_mask: 0.2850  decode.d4.loss_dice: 0.3295  decode.d5.loss_cls: 0.1997  decode.d5.loss_mask: 0.2873  decode.d5.loss_dice: 0.3129  decode.d6.loss_cls: 0.2271  decode.d6.loss_mask: 0.2870  decode.d6.loss_dice: 0.3324  decode.d7.loss_cls: 0.2690  decode.d7.loss_mask: 0.2885  decode.d7.loss_dice: 0.3640  decode.d8.loss_cls: 0.2397  decode.d8.loss_mask: 0.2956  decode.d8.loss_dice: 0.3301
07/30 02:21:19 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250729_225710
07/30 02:21:19 - mmengine - INFO - Iter(train) [23000/80000]  base_lr: 7.3707e-05 lr: 7.3707e-06  eta: 8:25:27  time: 0.5275  data_time: 0.0126  memory: 5897  grad_norm: 143.5443  loss: 9.5425  decode.loss_cls: 0.3154  decode.loss_mask: 0.2449  decode.loss_dice: 0.3386  decode.d0.loss_cls: 0.9858  decode.d0.loss_mask: 0.2513  decode.d0.loss_dice: 0.3481  decode.d1.loss_cls: 0.2960  decode.d1.loss_mask: 0.2469  decode.d1.loss_dice: 0.3234  decode.d2.loss_cls: 0.3290  decode.d2.loss_mask: 0.2465  decode.d2.loss_dice: 0.3236  decode.d3.loss_cls: 0.2971  decode.d3.loss_mask: 0.2464  decode.d3.loss_dice: 0.3154  decode.d4.loss_cls: 0.2896  decode.d4.loss_mask: 0.2441  decode.d4.loss_dice: 0.3486  decode.d5.loss_cls: 0.3393  decode.d5.loss_mask: 0.2391  decode.d5.loss_dice: 0.3459  decode.d6.loss_cls: 0.3557  decode.d6.loss_mask: 0.2430  decode.d6.loss_dice: 0.3207  decode.d7.loss_cls: 0.2748  decode.d7.loss_mask: 0.2463  decode.d7.loss_dice: 0.3257  decode.d8.loss_cls: 0.2825  decode.d8.loss_mask: 0.2435  decode.d8.loss_dice: 0.3352
07/30 02:21:45 - mmengine - INFO - Iter(train) [23050/80000]  base_lr: 7.3649e-05 lr: 7.3649e-06  eta: 8:24:59  time: 0.5268  data_time: 0.0126  memory: 5933  grad_norm: 113.5235  loss: 7.1696  decode.loss_cls: 0.1895  decode.loss_mask: 0.2105  decode.loss_dice: 0.2790  decode.d0.loss_cls: 0.9556  decode.d0.loss_mask: 0.2155  decode.d0.loss_dice: 0.2510  decode.d1.loss_cls: 0.3360  decode.d1.loss_mask: 0.2102  decode.d1.loss_dice: 0.2536  decode.d2.loss_cls: 0.1883  decode.d2.loss_mask: 0.2106  decode.d2.loss_dice: 0.2699  decode.d3.loss_cls: 0.1098  decode.d3.loss_mask: 0.2049  decode.d3.loss_dice: 0.2502  decode.d4.loss_cls: 0.1341  decode.d4.loss_mask: 0.2102  decode.d4.loss_dice: 0.2627  decode.d5.loss_cls: 0.1349  decode.d5.loss_mask: 0.2040  decode.d5.loss_dice: 0.2658  decode.d6.loss_cls: 0.1368  decode.d6.loss_mask: 0.2078  decode.d6.loss_dice: 0.2714  decode.d7.loss_cls: 0.1289  decode.d7.loss_mask: 0.2088  decode.d7.loss_dice: 0.2637  decode.d8.loss_cls: 0.1184  decode.d8.loss_mask: 0.2078  decode.d8.loss_dice: 0.2796
07/30 02:22:11 - mmengine - INFO - Iter(train) [23100/80000]  base_lr: 7.3591e-05 lr: 7.3591e-06  eta: 8:24:32  time: 0.5323  data_time: 0.0135  memory: 5931  grad_norm: 183.5211  loss: 8.5701  decode.loss_cls: 0.2141  decode.loss_mask: 0.2644  decode.loss_dice: 0.2657  decode.d0.loss_cls: 1.0535  decode.d0.loss_mask: 0.2723  decode.d0.loss_dice: 0.2904  decode.d1.loss_cls: 0.2061  decode.d1.loss_mask: 0.2704  decode.d1.loss_dice: 0.2634  decode.d2.loss_cls: 0.2426  decode.d2.loss_mask: 0.2674  decode.d2.loss_dice: 0.2694  decode.d3.loss_cls: 0.2106  decode.d3.loss_mask: 0.2639  decode.d3.loss_dice: 0.2695  decode.d4.loss_cls: 0.2659  decode.d4.loss_mask: 0.2651  decode.d4.loss_dice: 0.2639  decode.d5.loss_cls: 0.2406  decode.d5.loss_mask: 0.2613  decode.d5.loss_dice: 0.2689  decode.d6.loss_cls: 0.2120  decode.d6.loss_mask: 0.2701  decode.d6.loss_dice: 0.2650  decode.d7.loss_cls: 0.2360  decode.d7.loss_mask: 0.2663  decode.d7.loss_dice: 0.2691  decode.d8.loss_cls: 0.3108  decode.d8.loss_mask: 0.2681  decode.d8.loss_dice: 0.2834
07/30 02:22:37 - mmengine - INFO - Iter(train) [23150/80000]  base_lr: 7.3533e-05 lr: 7.3533e-06  eta: 8:24:04  time: 0.5207  data_time: 0.0124  memory: 5918  grad_norm: 135.9754  loss: 8.5019  decode.loss_cls: 0.1316  decode.loss_mask: 0.3559  decode.loss_dice: 0.2976  decode.d0.loss_cls: 0.7796  decode.d0.loss_mask: 0.3686  decode.d0.loss_dice: 0.3155  decode.d1.loss_cls: 0.1955  decode.d1.loss_mask: 0.3667  decode.d1.loss_dice: 0.2877  decode.d2.loss_cls: 0.1278  decode.d2.loss_mask: 0.3585  decode.d2.loss_dice: 0.2814  decode.d3.loss_cls: 0.1260  decode.d3.loss_mask: 0.3560  decode.d3.loss_dice: 0.2792  decode.d4.loss_cls: 0.1445  decode.d4.loss_mask: 0.3604  decode.d4.loss_dice: 0.2903  decode.d5.loss_cls: 0.1754  decode.d5.loss_mask: 0.3595  decode.d5.loss_dice: 0.2937  decode.d6.loss_cls: 0.1312  decode.d6.loss_mask: 0.3528  decode.d6.loss_dice: 0.2751  decode.d7.loss_cls: 0.1168  decode.d7.loss_mask: 0.3552  decode.d7.loss_dice: 0.2812  decode.d8.loss_cls: 0.1022  decode.d8.loss_mask: 0.3538  decode.d8.loss_dice: 0.2823
07/30 02:23:03 - mmengine - INFO - Iter(train) [23200/80000]  base_lr: 7.3475e-05 lr: 7.3475e-06  eta: 8:23:36  time: 0.5237  data_time: 0.0128  memory: 5933  grad_norm: 147.6721  loss: 8.8187  decode.loss_cls: 0.2950  decode.loss_mask: 0.2473  decode.loss_dice: 0.2741  decode.d0.loss_cls: 0.9735  decode.d0.loss_mask: 0.2523  decode.d0.loss_dice: 0.3069  decode.d1.loss_cls: 0.2532  decode.d1.loss_mask: 0.2379  decode.d1.loss_dice: 0.2512  decode.d2.loss_cls: 0.2875  decode.d2.loss_mask: 0.2365  decode.d2.loss_dice: 0.2556  decode.d3.loss_cls: 0.2708  decode.d3.loss_mask: 0.2443  decode.d3.loss_dice: 0.2713  decode.d4.loss_cls: 0.2894  decode.d4.loss_mask: 0.2686  decode.d4.loss_dice: 0.2728  decode.d5.loss_cls: 0.2907  decode.d5.loss_mask: 0.2668  decode.d5.loss_dice: 0.2693  decode.d6.loss_cls: 0.2874  decode.d6.loss_mask: 0.2637  decode.d6.loss_dice: 0.2724  decode.d7.loss_cls: 0.3158  decode.d7.loss_mask: 0.2435  decode.d7.loss_dice: 0.2826  decode.d8.loss_cls: 0.3221  decode.d8.loss_mask: 0.2449  decode.d8.loss_dice: 0.2714
07/30 02:23:30 - mmengine - INFO - Iter(train) [23250/80000]  base_lr: 7.3416e-05 lr: 7.3416e-06  eta: 8:23:10  time: 0.5270  data_time: 0.0132  memory: 5932  grad_norm: 90.1583  loss: 8.0127  decode.loss_cls: 0.2209  decode.loss_mask: 0.2705  decode.loss_dice: 0.2534  decode.d0.loss_cls: 1.0119  decode.d0.loss_mask: 0.2767  decode.d0.loss_dice: 0.2691  decode.d1.loss_cls: 0.2158  decode.d1.loss_mask: 0.2709  decode.d1.loss_dice: 0.2655  decode.d2.loss_cls: 0.2299  decode.d2.loss_mask: 0.2666  decode.d2.loss_dice: 0.2627  decode.d3.loss_cls: 0.2000  decode.d3.loss_mask: 0.2698  decode.d3.loss_dice: 0.2448  decode.d4.loss_cls: 0.1715  decode.d4.loss_mask: 0.2665  decode.d4.loss_dice: 0.2395  decode.d5.loss_cls: 0.1307  decode.d5.loss_mask: 0.2694  decode.d5.loss_dice: 0.2704  decode.d6.loss_cls: 0.1762  decode.d6.loss_mask: 0.2703  decode.d6.loss_dice: 0.2516  decode.d7.loss_cls: 0.1887  decode.d7.loss_mask: 0.2700  decode.d7.loss_dice: 0.2484  decode.d8.loss_cls: 0.1971  decode.d8.loss_mask: 0.2736  decode.d8.loss_dice: 0.2601
07/30 02:23:56 - mmengine - INFO - Iter(train) [23300/80000]  base_lr: 7.3358e-05 lr: 7.3358e-06  eta: 8:22:41  time: 0.5229  data_time: 0.0127  memory: 5931  grad_norm: 80.0205  loss: 8.2627  decode.loss_cls: 0.1905  decode.loss_mask: 0.2654  decode.loss_dice: 0.3128  decode.d0.loss_cls: 0.9487  decode.d0.loss_mask: 0.2724  decode.d0.loss_dice: 0.3227  decode.d1.loss_cls: 0.2371  decode.d1.loss_mask: 0.2694  decode.d1.loss_dice: 0.3232  decode.d2.loss_cls: 0.1773  decode.d2.loss_mask: 0.2782  decode.d2.loss_dice: 0.3444  decode.d3.loss_cls: 0.1446  decode.d3.loss_mask: 0.2676  decode.d3.loss_dice: 0.3092  decode.d4.loss_cls: 0.0931  decode.d4.loss_mask: 0.2721  decode.d4.loss_dice: 0.3372  decode.d5.loss_cls: 0.1108  decode.d5.loss_mask: 0.2675  decode.d5.loss_dice: 0.3134  decode.d6.loss_cls: 0.1217  decode.d6.loss_mask: 0.2687  decode.d6.loss_dice: 0.3217  decode.d7.loss_cls: 0.1392  decode.d7.loss_mask: 0.2647  decode.d7.loss_dice: 0.3137  decode.d8.loss_cls: 0.1843  decode.d8.loss_mask: 0.2697  decode.d8.loss_dice: 0.3214
07/30 02:24:22 - mmengine - INFO - Iter(train) [23350/80000]  base_lr: 7.3300e-05 lr: 7.3300e-06  eta: 8:22:13  time: 0.5182  data_time: 0.0123  memory: 5918  grad_norm: 211.2794  loss: 8.6341  decode.loss_cls: 0.2179  decode.loss_mask: 0.2660  decode.loss_dice: 0.3302  decode.d0.loss_cls: 1.0184  decode.d0.loss_mask: 0.2462  decode.d0.loss_dice: 0.3280  decode.d1.loss_cls: 0.2378  decode.d1.loss_mask: 0.2628  decode.d1.loss_dice: 0.3171  decode.d2.loss_cls: 0.1452  decode.d2.loss_mask: 0.2701  decode.d2.loss_dice: 0.3346  decode.d3.loss_cls: 0.2203  decode.d3.loss_mask: 0.2612  decode.d3.loss_dice: 0.3136  decode.d4.loss_cls: 0.1404  decode.d4.loss_mask: 0.2829  decode.d4.loss_dice: 0.3240  decode.d5.loss_cls: 0.1812  decode.d5.loss_mask: 0.2644  decode.d5.loss_dice: 0.3161  decode.d6.loss_cls: 0.1879  decode.d6.loss_mask: 0.2814  decode.d6.loss_dice: 0.3217  decode.d7.loss_cls: 0.1878  decode.d7.loss_mask: 0.2743  decode.d7.loss_dice: 0.3158  decode.d8.loss_cls: 0.1877  decode.d8.loss_mask: 0.2850  decode.d8.loss_dice: 0.3141
07/30 02:24:48 - mmengine - INFO - Iter(train) [23400/80000]  base_lr: 7.3242e-05 lr: 7.3242e-06  eta: 8:21:45  time: 0.5184  data_time: 0.0120  memory: 5897  grad_norm: 92.6316  loss: 7.7517  decode.loss_cls: 0.1260  decode.loss_mask: 0.2372  decode.loss_dice: 0.3002  decode.d0.loss_cls: 1.0275  decode.d0.loss_mask: 0.2415  decode.d0.loss_dice: 0.3319  decode.d1.loss_cls: 0.1395  decode.d1.loss_mask: 0.2428  decode.d1.loss_dice: 0.3087  decode.d2.loss_cls: 0.1749  decode.d2.loss_mask: 0.2403  decode.d2.loss_dice: 0.3076  decode.d3.loss_cls: 0.1340  decode.d3.loss_mask: 0.2393  decode.d3.loss_dice: 0.3030  decode.d4.loss_cls: 0.1801  decode.d4.loss_mask: 0.2364  decode.d4.loss_dice: 0.2994  decode.d5.loss_cls: 0.1388  decode.d5.loss_mask: 0.2352  decode.d5.loss_dice: 0.3049  decode.d6.loss_cls: 0.1179  decode.d6.loss_mask: 0.2363  decode.d6.loss_dice: 0.3049  decode.d7.loss_cls: 0.1193  decode.d7.loss_mask: 0.2349  decode.d7.loss_dice: 0.3034  decode.d8.loss_cls: 0.1366  decode.d8.loss_mask: 0.2378  decode.d8.loss_dice: 0.3112
