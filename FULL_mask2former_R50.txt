==========================================
SLURM_JOB_ID = 2466249
SLURM_NODELIST = gnode070
SLURM_JOB_GPUS = 0
==========================================
07/25 19:15:40 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.23 (main, Jun  5 2025, 13:40:20) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 446836777
    GPU 0: NVIDIA GeForce RTX 2080 Ti
    CUDA_HOME: /opt/cuda-12.1/
    NVCC: Cuda compilation tools, release 12.1, V12.1.66
    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
    PyTorch: 2.1.2
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 446836777
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

07/25 19:15:40 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=16, enable=False)
crop_size = (
    512,
    1024,
)
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        512,
        1024,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    test_cfg=dict(size_divisor=32),
    type='SegDataPreProcessor')
data_root = '/scratch/seg_benchmark/seg_FULL/'
dataset_type = 'YourDataset_BIG'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False, interval=5000, save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'))
default_scope = 'mmseg'
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
img_suffix = '.jpg'
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        deep_stem=False,
        depth=50,
        frozen_stages=-1,
        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),
        norm_cfg=dict(requires_grad=False, type='SyncBN'),
        num_stages=4,
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        style='pytorch',
        type='ResNet'),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            1024,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        test_cfg=dict(size_divisor=32),
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            256,
            512,
            1024,
            2048,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=57,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 57
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict(
            backbone=dict(decay_mult=1.0, lr_mult=0.1),
            level_embed=dict(decay_mult=0.0, lr_mult=1.0),
            query_embed=dict(decay_mult=0.0, lr_mult=1.0),
            query_feat=dict(decay_mult=0.0, lr_mult=1.0)),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=80000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
resume = False
seg_map_suffix = '.png'
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/seg_benchmark/seg_FULL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2048,
        1024,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(
    max_iters=80000, type='IterBasedTrainLoop', val_interval=80000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        data_prefix=dict(img_path='train/images', seg_map_path='train/masks'),
        data_root='/scratch/seg_benchmark/seg_FULL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                max_size=4096,
                resize_type='ResizeShortestEdge',
                scales=[
                    512,
                    614,
                    716,
                    819,
                    921,
                    1024,
                    1126,
                    1228,
                    1331,
                    1433,
                    1536,
                    1638,
                    1740,
                    1843,
                    1945,
                    2048,
                ],
                type='RandomChoiceResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    512,
                    1024,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        max_size=4096,
        resize_type='ResizeShortestEdge',
        scales=[
            512,
            614,
            716,
            819,
            921,
            1024,
            1126,
            1228,
            1331,
            1433,
            1536,
            1638,
            1740,
            1843,
            1945,
            2048,
        ],
        type='RandomChoiceResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        1024,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/seg_benchmark/seg_FULL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '/scratch/seg_benchmark/FULL/mask2former_R50'

07/25 19:15:55 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
07/25 19:15:55 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.0.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.0.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.0.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.0.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.0.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.0.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.0.downsample.1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.0.downsample.1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.1.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.1.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.1.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.1.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.1.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.1.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.2.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.2.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.2.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.2.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.2.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.2.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.0.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.0.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.0.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.0.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.0.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.0.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.0.downsample.1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.0.downsample.1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.1.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.1.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.1.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.1.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.1.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.1.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.2.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.2.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.2.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.2.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.2.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.2.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.3.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.3.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.3.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.3.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.3.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.3.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.0.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.0.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.0.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.0.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.0.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.0.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.0.downsample.1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.0.downsample.1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.1.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.1.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.1.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.1.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.1.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.1.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.2.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.2.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.2.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.2.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.2.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.2.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.3.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.3.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.3.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.3.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.3.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.3.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.4.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.4.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.4.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.4.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.4.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.4.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.5.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.5.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.5.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.5.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.5.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.5.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.0.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.0.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.0.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.0.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.0.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.0.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.0.downsample.1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.0.downsample.1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.1.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.1.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.1.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.1.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.1.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.1.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.2.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.2.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.2.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.2.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.2.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.2.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
07/25 19:15:56 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
07/25 19:15:57 - mmengine - INFO - load model from: torchvision://resnet50
07/25 19:15:57 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet50
07/25 19:16:02 - mmengine - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

07/25 19:16:03 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
07/25 19:16:03 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
07/25 19:16:03 - mmengine - INFO - Checkpoints will be saved to /scratch/seg_benchmark/FULL/mask2former_R50.
/home2/yasharora120/miniconda3/envs/mmseg/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400441250/work/aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
07/25 19:16:43 - mmengine - INFO - Iter(train) [   50/80000]  base_lr: 9.9945e-05 lr: 9.9945e-06  eta: 17:38:17  time: 0.4503  data_time: 0.0101  memory: 10589  grad_norm: 158.2570  loss: 100.2073  decode.loss_cls: 4.3556  decode.loss_mask: 2.2592  decode.loss_dice: 4.2021  decode.d0.loss_cls: 8.0755  decode.d0.loss_mask: 1.7814  decode.d0.loss_dice: 3.5501  decode.d1.loss_cls: 3.8993  decode.d1.loss_mask: 1.7096  decode.d1.loss_dice: 3.3914  decode.d2.loss_cls: 3.8226  decode.d2.loss_mask: 1.7181  decode.d2.loss_dice: 3.4107  decode.d3.loss_cls: 3.8172  decode.d3.loss_mask: 1.7546  decode.d3.loss_dice: 3.4285  decode.d4.loss_cls: 3.8584  decode.d4.loss_mask: 1.7657  decode.d4.loss_dice: 3.4749  decode.d5.loss_cls: 3.8862  decode.d5.loss_mask: 1.8375  decode.d5.loss_dice: 3.6192  decode.d6.loss_cls: 4.0698  decode.d6.loss_mask: 1.9370  decode.d6.loss_dice: 3.7545  decode.d7.loss_cls: 4.1472  decode.d7.loss_mask: 2.2540  decode.d7.loss_dice: 3.8631  decode.d8.loss_cls: 4.2929  decode.d8.loss_mask: 2.2836  decode.d8.loss_dice: 3.9871
07/25 19:17:05 - mmengine - INFO - Iter(train) [  100/80000]  base_lr: 9.9889e-05 lr: 9.9889e-06  eta: 13:49:46  time: 0.4532  data_time: 0.0106  memory: 5265  grad_norm: 275.0222  loss: 78.2691  decode.loss_cls: 3.0738  decode.loss_mask: 1.7527  decode.loss_dice: 2.9162  decode.d0.loss_cls: 7.9707  decode.d0.loss_mask: 1.5226  decode.d0.loss_dice: 2.8258  decode.d1.loss_cls: 3.0076  decode.d1.loss_mask: 1.4789  decode.d1.loss_dice: 2.6281  decode.d2.loss_cls: 2.8909  decode.d2.loss_mask: 1.5149  decode.d2.loss_dice: 2.6242  decode.d3.loss_cls: 2.7494  decode.d3.loss_mask: 1.5655  decode.d3.loss_dice: 2.6885  decode.d4.loss_cls: 2.7805  decode.d4.loss_mask: 1.5869  decode.d4.loss_dice: 2.7381  decode.d5.loss_cls: 2.7930  decode.d5.loss_mask: 1.6037  decode.d5.loss_dice: 2.7718  decode.d6.loss_cls: 3.0335  decode.d6.loss_mask: 1.6157  decode.d6.loss_dice: 2.7711  decode.d7.loss_cls: 3.1664  decode.d7.loss_mask: 1.6348  decode.d7.loss_dice: 2.7859  decode.d8.loss_cls: 3.0945  decode.d8.loss_mask: 1.7564  decode.d8.loss_dice: 2.9268
07/25 19:17:28 - mmengine - INFO - Iter(train) [  150/80000]  base_lr: 9.9832e-05 lr: 9.9832e-06  eta: 12:33:57  time: 0.4523  data_time: 0.0100  memory: 5249  grad_norm: 211.1235  loss: 64.6201  decode.loss_cls: 2.6660  decode.loss_mask: 1.3280  decode.loss_dice: 2.1313  decode.d0.loss_cls: 7.8807  decode.d0.loss_mask: 1.2033  decode.d0.loss_dice: 2.3060  decode.d1.loss_cls: 2.8784  decode.d1.loss_mask: 1.1752  decode.d1.loss_dice: 2.0100  decode.d2.loss_cls: 2.6619  decode.d2.loss_mask: 1.1835  decode.d2.loss_dice: 1.9683  decode.d3.loss_cls: 2.5775  decode.d3.loss_mask: 1.2252  decode.d3.loss_dice: 1.9724  decode.d4.loss_cls: 2.5927  decode.d4.loss_mask: 1.2466  decode.d4.loss_dice: 1.9826  decode.d5.loss_cls: 2.5952  decode.d5.loss_mask: 1.2581  decode.d5.loss_dice: 1.9790  decode.d6.loss_cls: 2.5676  decode.d6.loss_mask: 1.2568  decode.d6.loss_dice: 2.0023  decode.d7.loss_cls: 2.5819  decode.d7.loss_mask: 1.2650  decode.d7.loss_dice: 2.0717  decode.d8.loss_cls: 2.6742  decode.d8.loss_mask: 1.3121  decode.d8.loss_dice: 2.0667
07/25 19:17:50 - mmengine - INFO - Iter(train) [  200/80000]  base_lr: 9.9776e-05 lr: 9.9776e-06  eta: 11:54:10  time: 0.4526  data_time: 0.0101  memory: 5249  grad_norm: 234.4230  loss: 59.7927  decode.loss_cls: 2.9385  decode.loss_mask: 0.9035  decode.loss_dice: 1.7875  decode.d0.loss_cls: 7.7872  decode.d0.loss_mask: 0.8998  decode.d0.loss_dice: 2.1333  decode.d1.loss_cls: 2.7943  decode.d1.loss_mask: 0.8621  decode.d1.loss_dice: 1.7828  decode.d2.loss_cls: 2.6939  decode.d2.loss_mask: 0.8402  decode.d2.loss_dice: 1.6505  decode.d3.loss_cls: 2.6789  decode.d3.loss_mask: 0.8361  decode.d3.loss_dice: 1.7275  decode.d4.loss_cls: 2.8367  decode.d4.loss_mask: 0.8388  decode.d4.loss_dice: 1.7146  decode.d5.loss_cls: 2.9036  decode.d5.loss_mask: 0.8566  decode.d5.loss_dice: 1.7211  decode.d6.loss_cls: 2.9192  decode.d6.loss_mask: 0.8849  decode.d6.loss_dice: 1.6770  decode.d7.loss_cls: 2.9612  decode.d7.loss_mask: 0.8881  decode.d7.loss_dice: 1.6945  decode.d8.loss_cls: 2.9004  decode.d8.loss_mask: 0.9361  decode.d8.loss_dice: 1.7434
07/25 19:18:13 - mmengine - INFO - Iter(train) [  250/80000]  base_lr: 9.9720e-05 lr: 9.9720e-06  eta: 11:31:38  time: 0.4522  data_time: 0.0101  memory: 5228  grad_norm: 284.4101  loss: 56.9332  decode.loss_cls: 3.0469  decode.loss_mask: 0.9980  decode.loss_dice: 1.3135  decode.d0.loss_cls: 7.6351  decode.d0.loss_mask: 1.0489  decode.d0.loss_dice: 1.8128  decode.d1.loss_cls: 2.8569  decode.d1.loss_mask: 0.9662  decode.d1.loss_dice: 1.4138  decode.d2.loss_cls: 2.7505  decode.d2.loss_mask: 0.9329  decode.d2.loss_dice: 1.3152  decode.d3.loss_cls: 2.7594  decode.d3.loss_mask: 0.9315  decode.d3.loss_dice: 1.2938  decode.d4.loss_cls: 2.8990  decode.d4.loss_mask: 0.9316  decode.d4.loss_dice: 1.2810  decode.d5.loss_cls: 2.9699  decode.d5.loss_mask: 0.9286  decode.d5.loss_dice: 1.2866  decode.d6.loss_cls: 2.9373  decode.d6.loss_mask: 0.9153  decode.d6.loss_dice: 1.2606  decode.d7.loss_cls: 2.9391  decode.d7.loss_mask: 0.9470  decode.d7.loss_dice: 1.2796  decode.d8.loss_cls: 3.0084  decode.d8.loss_mask: 0.9736  decode.d8.loss_dice: 1.2999
07/25 19:18:36 - mmengine - INFO - Iter(train) [  300/80000]  base_lr: 9.9664e-05 lr: 9.9664e-06  eta: 11:15:44  time: 0.4532  data_time: 0.0103  memory: 5227  grad_norm: 318.4766  loss: 51.0229  decode.loss_cls: 2.7485  decode.loss_mask: 0.8021  decode.loss_dice: 1.0084  decode.d0.loss_cls: 7.4972  decode.d0.loss_mask: 1.0229  decode.d0.loss_dice: 1.5616  decode.d1.loss_cls: 2.7515  decode.d1.loss_mask: 0.8339  decode.d1.loss_dice: 1.1829  decode.d2.loss_cls: 2.6651  decode.d2.loss_mask: 0.7977  decode.d2.loss_dice: 1.0820  decode.d3.loss_cls: 2.6617  decode.d3.loss_mask: 0.7658  decode.d3.loss_dice: 1.0054  decode.d4.loss_cls: 2.7448  decode.d4.loss_mask: 0.7375  decode.d4.loss_dice: 1.0011  decode.d5.loss_cls: 2.7779  decode.d5.loss_mask: 0.7932  decode.d5.loss_dice: 0.9800  decode.d6.loss_cls: 2.7783  decode.d6.loss_mask: 0.7674  decode.d6.loss_dice: 0.9837  decode.d7.loss_cls: 2.7843  decode.d7.loss_mask: 0.7782  decode.d7.loss_dice: 0.9914  decode.d8.loss_cls: 2.7421  decode.d8.loss_mask: 0.7744  decode.d8.loss_dice: 1.0018
07/25 19:18:58 - mmengine - INFO - Iter(train) [  350/80000]  base_lr: 9.9607e-05 lr: 9.9607e-06  eta: 11:05:10  time: 0.4565  data_time: 0.0103  memory: 5294  grad_norm: 234.8158  loss: 49.8826  decode.loss_cls: 2.7002  decode.loss_mask: 0.7023  decode.loss_dice: 1.0695  decode.d0.loss_cls: 7.3268  decode.d0.loss_mask: 0.7432  decode.d0.loss_dice: 1.5303  decode.d1.loss_cls: 2.6501  decode.d1.loss_mask: 0.6859  decode.d1.loss_dice: 1.1292  decode.d2.loss_cls: 2.5731  decode.d2.loss_mask: 0.6867  decode.d2.loss_dice: 1.1033  decode.d3.loss_cls: 2.6492  decode.d3.loss_mask: 0.6880  decode.d3.loss_dice: 1.0672  decode.d4.loss_cls: 2.7745  decode.d4.loss_mask: 0.6616  decode.d4.loss_dice: 1.0436  decode.d5.loss_cls: 2.7236  decode.d5.loss_mask: 0.6988  decode.d5.loss_dice: 1.0937  decode.d6.loss_cls: 2.7333  decode.d6.loss_mask: 0.7085  decode.d6.loss_dice: 1.0791  decode.d7.loss_cls: 2.7441  decode.d7.loss_mask: 0.7131  decode.d7.loss_dice: 1.0922  decode.d8.loss_cls: 2.7457  decode.d8.loss_mask: 0.6789  decode.d8.loss_dice: 1.0867
07/25 19:19:21 - mmengine - INFO - Iter(train) [  400/80000]  base_lr: 9.9551e-05 lr: 9.9551e-06  eta: 10:56:59  time: 0.4540  data_time: 0.0104  memory: 5215  grad_norm: 380.3828  loss: 48.2619  decode.loss_cls: 2.4038  decode.loss_mask: 0.9298  decode.loss_dice: 1.0419  decode.d0.loss_cls: 7.1823  decode.d0.loss_mask: 0.9581  decode.d0.loss_dice: 1.3789  decode.d1.loss_cls: 2.3559  decode.d1.loss_mask: 0.9519  decode.d1.loss_dice: 1.1088  decode.d2.loss_cls: 2.2907  decode.d2.loss_mask: 0.9391  decode.d2.loss_dice: 1.0219  decode.d3.loss_cls: 2.2634  decode.d3.loss_mask: 0.8875  decode.d3.loss_dice: 1.0106  decode.d4.loss_cls: 2.3130  decode.d4.loss_mask: 0.8896  decode.d4.loss_dice: 0.9853  decode.d5.loss_cls: 2.3768  decode.d5.loss_mask: 0.9055  decode.d5.loss_dice: 0.9770  decode.d6.loss_cls: 2.3784  decode.d6.loss_mask: 0.9738  decode.d6.loss_dice: 1.0084  decode.d7.loss_cls: 2.3631  decode.d7.loss_mask: 0.9784  decode.d7.loss_dice: 1.0262  decode.d8.loss_cls: 2.3776  decode.d8.loss_mask: 0.9488  decode.d8.loss_dice: 1.0354
07/25 19:19:44 - mmengine - INFO - Iter(train) [  450/80000]  base_lr: 9.9495e-05 lr: 9.9495e-06  eta: 10:51:47  time: 0.4556  data_time: 0.0103  memory: 5308  grad_norm: 313.1468  loss: 44.9564  decode.loss_cls: 2.3586  decode.loss_mask: 0.7892  decode.loss_dice: 0.9097  decode.d0.loss_cls: 7.0012  decode.d0.loss_mask: 0.8872  decode.d0.loss_dice: 1.3307  decode.d1.loss_cls: 2.3996  decode.d1.loss_mask: 0.7499  decode.d1.loss_dice: 0.9590  decode.d2.loss_cls: 2.1750  decode.d2.loss_mask: 0.7489  decode.d2.loss_dice: 0.9133  decode.d3.loss_cls: 2.1681  decode.d3.loss_mask: 0.7249  decode.d3.loss_dice: 0.8938  decode.d4.loss_cls: 2.2273  decode.d4.loss_mask: 0.7646  decode.d4.loss_dice: 0.8985  decode.d5.loss_cls: 2.2681  decode.d5.loss_mask: 0.7764  decode.d5.loss_dice: 0.9334  decode.d6.loss_cls: 2.3275  decode.d6.loss_mask: 0.8063  decode.d6.loss_dice: 0.9016  decode.d7.loss_cls: 2.3307  decode.d7.loss_mask: 0.7718  decode.d7.loss_dice: 0.8958  decode.d8.loss_cls: 2.3958  decode.d8.loss_mask: 0.7462  decode.d8.loss_dice: 0.9032
07/25 19:20:07 - mmengine - INFO - Iter(train) [  500/80000]  base_lr: 9.9438e-05 lr: 9.9438e-06  eta: 10:46:44  time: 0.4608  data_time: 0.0103  memory: 5265  grad_norm: 272.6005  loss: 48.0799  decode.loss_cls: 2.6366  decode.loss_mask: 0.8264  decode.loss_dice: 1.0068  decode.d0.loss_cls: 6.8417  decode.d0.loss_mask: 0.7664  decode.d0.loss_dice: 1.2913  decode.d1.loss_cls: 2.6029  decode.d1.loss_mask: 0.7949  decode.d1.loss_dice: 0.9654  decode.d2.loss_cls: 2.5559  decode.d2.loss_mask: 0.7701  decode.d2.loss_dice: 0.9470  decode.d3.loss_cls: 2.5846  decode.d3.loss_mask: 0.7794  decode.d3.loss_dice: 0.9327  decode.d4.loss_cls: 2.6326  decode.d4.loss_mask: 0.7676  decode.d4.loss_dice: 0.9620  decode.d5.loss_cls: 2.6265  decode.d5.loss_mask: 0.7365  decode.d5.loss_dice: 0.9553  decode.d6.loss_cls: 2.6371  decode.d6.loss_mask: 0.7407  decode.d6.loss_dice: 0.9995  decode.d7.loss_cls: 2.6428  decode.d7.loss_mask: 0.6951  decode.d7.loss_dice: 0.9279  decode.d8.loss_cls: 2.6740  decode.d8.loss_mask: 0.7656  decode.d8.loss_dice: 1.0146
07/25 19:20:30 - mmengine - INFO - Iter(train) [  550/80000]  base_lr: 9.9382e-05 lr: 9.9382e-06  eta: 10:42:08  time: 0.4434  data_time: 0.0096  memory: 5228  grad_norm: 235.5370  loss: 40.9569  decode.loss_cls: 2.3422  decode.loss_mask: 0.5890  decode.loss_dice: 0.6665  decode.d0.loss_cls: 6.6312  decode.d0.loss_mask: 0.7016  decode.d0.loss_dice: 1.0087  decode.d1.loss_cls: 2.3908  decode.d1.loss_mask: 0.5835  decode.d1.loss_dice: 0.7367  decode.d2.loss_cls: 2.3086  decode.d2.loss_mask: 0.6127  decode.d2.loss_dice: 0.7359  decode.d3.loss_cls: 2.2912  decode.d3.loss_mask: 0.6078  decode.d3.loss_dice: 0.7066  decode.d4.loss_cls: 2.3494  decode.d4.loss_mask: 0.5754  decode.d4.loss_dice: 0.6874  decode.d5.loss_cls: 2.2905  decode.d5.loss_mask: 0.6031  decode.d5.loss_dice: 0.6942  decode.d6.loss_cls: 2.2640  decode.d6.loss_mask: 0.6014  decode.d6.loss_dice: 0.6939  decode.d7.loss_cls: 2.2952  decode.d7.loss_mask: 0.5912  decode.d7.loss_dice: 0.6934  decode.d8.loss_cls: 2.3959  decode.d8.loss_mask: 0.6146  decode.d8.loss_dice: 0.6941
07/25 19:20:52 - mmengine - INFO - Iter(train) [  600/80000]  base_lr: 9.9326e-05 lr: 9.9326e-06  eta: 10:38:25  time: 0.4585  data_time: 0.0104  memory: 5249  grad_norm: 205.6876  loss: 39.2980  decode.loss_cls: 2.5021  decode.loss_mask: 0.4406  decode.loss_dice: 0.5965  decode.d0.loss_cls: 6.5363  decode.d0.loss_mask: 0.5464  decode.d0.loss_dice: 0.9543  decode.d1.loss_cls: 2.5265  decode.d1.loss_mask: 0.4360  decode.d1.loss_dice: 0.6015  decode.d2.loss_cls: 2.4708  decode.d2.loss_mask: 0.4308  decode.d2.loss_dice: 0.5693  decode.d3.loss_cls: 2.4213  decode.d3.loss_mask: 0.4146  decode.d3.loss_dice: 0.5227  decode.d4.loss_cls: 2.4526  decode.d4.loss_mask: 0.4131  decode.d4.loss_dice: 0.5411  decode.d5.loss_cls: 2.4822  decode.d5.loss_mask: 0.4291  decode.d5.loss_dice: 0.5390  decode.d6.loss_cls: 2.4704  decode.d6.loss_mask: 0.4320  decode.d6.loss_dice: 0.5336  decode.d7.loss_cls: 2.5012  decode.d7.loss_mask: 0.4449  decode.d7.loss_dice: 0.5400  decode.d8.loss_cls: 2.4941  decode.d8.loss_mask: 0.4545  decode.d8.loss_dice: 0.6005
07/25 19:21:15 - mmengine - INFO - Iter(train) [  650/80000]  base_lr: 9.9270e-05 lr: 9.9270e-06  eta: 10:35:01  time: 0.4577  data_time: 0.0105  memory: 5269  grad_norm: 336.1997  loss: 44.2682  decode.loss_cls: 2.4108  decode.loss_mask: 0.6675  decode.loss_dice: 0.8152  decode.d0.loss_cls: 6.4807  decode.d0.loss_mask: 0.7381  decode.d0.loss_dice: 1.1842  decode.d1.loss_cls: 2.4702  decode.d1.loss_mask: 0.7045  decode.d1.loss_dice: 0.8868  decode.d2.loss_cls: 2.3983  decode.d2.loss_mask: 0.7028  decode.d2.loss_dice: 0.8529  decode.d3.loss_cls: 2.4417  decode.d3.loss_mask: 0.6806  decode.d3.loss_dice: 0.8448  decode.d4.loss_cls: 2.3926  decode.d4.loss_mask: 0.6847  decode.d4.loss_dice: 0.8754  decode.d5.loss_cls: 2.4443  decode.d5.loss_mask: 0.6837  decode.d5.loss_dice: 0.8528  decode.d6.loss_cls: 2.4226  decode.d6.loss_mask: 0.7363  decode.d6.loss_dice: 0.8833  decode.d7.loss_cls: 2.4156  decode.d7.loss_mask: 0.7549  decode.d7.loss_dice: 0.8719  decode.d8.loss_cls: 2.4443  decode.d8.loss_mask: 0.6884  decode.d8.loss_dice: 0.8381
07/25 19:21:38 - mmengine - INFO - Iter(train) [  700/80000]  base_lr: 9.9213e-05 lr: 9.9213e-06  eta: 10:32:16  time: 0.4564  data_time: 0.0102  memory: 5231  grad_norm: 179.2129  loss: 37.4267  decode.loss_cls: 2.2476  decode.loss_mask: 0.4176  decode.loss_dice: 0.5594  decode.d0.loss_cls: 6.2133  decode.d0.loss_mask: 0.5088  decode.d0.loss_dice: 0.9357  decode.d1.loss_cls: 2.4222  decode.d1.loss_mask: 0.4477  decode.d1.loss_dice: 0.6178  decode.d2.loss_cls: 2.3141  decode.d2.loss_mask: 0.4112  decode.d2.loss_dice: 0.5739  decode.d3.loss_cls: 2.2195  decode.d3.loss_mask: 0.4299  decode.d3.loss_dice: 0.5803  decode.d4.loss_cls: 2.2849  decode.d4.loss_mask: 0.4111  decode.d4.loss_dice: 0.5847  decode.d5.loss_cls: 2.2976  decode.d5.loss_mask: 0.4345  decode.d5.loss_dice: 0.5637  decode.d6.loss_cls: 2.2712  decode.d6.loss_mask: 0.4322  decode.d6.loss_dice: 0.5792  decode.d7.loss_cls: 2.3314  decode.d7.loss_mask: 0.4398  decode.d7.loss_dice: 0.5784  decode.d8.loss_cls: 2.2787  decode.d8.loss_mask: 0.4584  decode.d8.loss_dice: 0.5822
07/25 19:22:01 - mmengine - INFO - Iter(train) [  750/80000]  base_lr: 9.9157e-05 lr: 9.9157e-06  eta: 10:29:51  time: 0.4556  data_time: 0.0102  memory: 5228  grad_norm: 210.4335  loss: 39.7792  decode.loss_cls: 2.1047  decode.loss_mask: 0.5857  decode.loss_dice: 0.7738  decode.d0.loss_cls: 6.0825  decode.d0.loss_mask: 0.6650  decode.d0.loss_dice: 1.1580  decode.d1.loss_cls: 2.2098  decode.d1.loss_mask: 0.5677  decode.d1.loss_dice: 0.8762  decode.d2.loss_cls: 2.1087  decode.d2.loss_mask: 0.5616  decode.d2.loss_dice: 0.8244  decode.d3.loss_cls: 2.0682  decode.d3.loss_mask: 0.5448  decode.d3.loss_dice: 0.8100  decode.d4.loss_cls: 2.1873  decode.d4.loss_mask: 0.5576  decode.d4.loss_dice: 0.8279  decode.d5.loss_cls: 2.1564  decode.d5.loss_mask: 0.5782  decode.d5.loss_dice: 0.8034  decode.d6.loss_cls: 2.1291  decode.d6.loss_mask: 0.5843  decode.d6.loss_dice: 0.8407  decode.d7.loss_cls: 2.1711  decode.d7.loss_mask: 0.5789  decode.d7.loss_dice: 0.8051  decode.d8.loss_cls: 2.2319  decode.d8.loss_mask: 0.5883  decode.d8.loss_dice: 0.7983
07/25 19:22:23 - mmengine - INFO - Iter(train) [  800/80000]  base_lr: 9.9101e-05 lr: 9.9101e-06  eta: 10:27:34  time: 0.4520  data_time: 0.0102  memory: 5231  grad_norm: 274.4051  loss: 35.3409  decode.loss_cls: 1.7641  decode.loss_mask: 0.7698  decode.loss_dice: 0.6039  decode.d0.loss_cls: 5.9536  decode.d0.loss_mask: 0.6508  decode.d0.loss_dice: 0.8096  decode.d1.loss_cls: 1.9063  decode.d1.loss_mask: 0.6670  decode.d1.loss_dice: 0.5981  decode.d2.loss_cls: 1.8198  decode.d2.loss_mask: 0.6717  decode.d2.loss_dice: 0.5784  decode.d3.loss_cls: 1.8234  decode.d3.loss_mask: 0.6676  decode.d3.loss_dice: 0.5624  decode.d4.loss_cls: 1.8267  decode.d4.loss_mask: 0.6997  decode.d4.loss_dice: 0.6036  decode.d5.loss_cls: 1.8106  decode.d5.loss_mask: 0.7010  decode.d5.loss_dice: 0.5777  decode.d6.loss_cls: 1.7605  decode.d6.loss_mask: 0.6852  decode.d6.loss_dice: 0.5918  decode.d7.loss_cls: 1.8259  decode.d7.loss_mask: 0.7033  decode.d7.loss_dice: 0.5908  decode.d8.loss_cls: 1.8057  decode.d8.loss_mask: 0.7168  decode.d8.loss_dice: 0.5951
07/25 19:22:46 - mmengine - INFO - Iter(train) [  850/80000]  base_lr: 9.9044e-05 lr: 9.9044e-06  eta: 10:25:32  time: 0.4550  data_time: 0.0101  memory: 5249  grad_norm: 204.4741  loss: 38.9778  decode.loss_cls: 2.2518  decode.loss_mask: 0.6429  decode.loss_dice: 0.6425  decode.d0.loss_cls: 5.8968  decode.d0.loss_mask: 0.5570  decode.d0.loss_dice: 0.9114  decode.d1.loss_cls: 2.4945  decode.d1.loss_mask: 0.5058  decode.d1.loss_dice: 0.5814  decode.d2.loss_cls: 2.4067  decode.d2.loss_mask: 0.5090  decode.d2.loss_dice: 0.5611  decode.d3.loss_cls: 2.3438  decode.d3.loss_mask: 0.5137  decode.d3.loss_dice: 0.5657  decode.d4.loss_cls: 2.3484  decode.d4.loss_mask: 0.5820  decode.d4.loss_dice: 0.5939  decode.d5.loss_cls: 2.3444  decode.d5.loss_mask: 0.5939  decode.d5.loss_dice: 0.6045  decode.d6.loss_cls: 2.3158  decode.d6.loss_mask: 0.5758  decode.d6.loss_dice: 0.5898  decode.d7.loss_cls: 2.3783  decode.d7.loss_mask: 0.5977  decode.d7.loss_dice: 0.5966  decode.d8.loss_cls: 2.3102  decode.d8.loss_mask: 0.5814  decode.d8.loss_dice: 0.5810
07/25 19:23:09 - mmengine - INFO - Iter(train) [  900/80000]  base_lr: 9.8988e-05 lr: 9.8988e-06  eta: 10:23:47  time: 0.4544  data_time: 0.0102  memory: 5249  grad_norm: 460.2592  loss: 38.6751  decode.loss_cls: 1.9828  decode.loss_mask: 0.8056  decode.loss_dice: 0.7479  decode.d0.loss_cls: 5.6676  decode.d0.loss_mask: 0.7730  decode.d0.loss_dice: 0.9314  decode.d1.loss_cls: 2.0960  decode.d1.loss_mask: 0.6801  decode.d1.loss_dice: 0.7202  decode.d2.loss_cls: 1.8686  decode.d2.loss_mask: 0.6833  decode.d2.loss_dice: 0.7073  decode.d3.loss_cls: 1.9134  decode.d3.loss_mask: 0.6883  decode.d3.loss_dice: 0.7255  decode.d4.loss_cls: 2.0628  decode.d4.loss_mask: 0.7316  decode.d4.loss_dice: 0.7346  decode.d5.loss_cls: 2.0384  decode.d5.loss_mask: 0.7073  decode.d5.loss_dice: 0.7050  decode.d6.loss_cls: 2.0802  decode.d6.loss_mask: 0.7270  decode.d6.loss_dice: 0.7663  decode.d7.loss_cls: 2.0822  decode.d7.loss_mask: 0.7628  decode.d7.loss_dice: 0.7949  decode.d8.loss_cls: 2.0360  decode.d8.loss_mask: 0.7117  decode.d8.loss_dice: 0.7431
07/25 19:23:31 - mmengine - INFO - Iter(train) [  950/80000]  base_lr: 9.8932e-05 lr: 9.8932e-06  eta: 10:21:52  time: 0.4562  data_time: 0.0100  memory: 5248  grad_norm: 200.6241  loss: 31.1275  decode.loss_cls: 1.6768  decode.loss_mask: 0.4974  decode.loss_dice: 0.5082  decode.d0.loss_cls: 5.4981  decode.d0.loss_mask: 0.5611  decode.d0.loss_dice: 0.7549  decode.d1.loss_cls: 1.7716  decode.d1.loss_mask: 0.4770  decode.d1.loss_dice: 0.5173  decode.d2.loss_cls: 1.6133  decode.d2.loss_mask: 0.5023  decode.d2.loss_dice: 0.5159  decode.d3.loss_cls: 1.6377  decode.d3.loss_mask: 0.5099  decode.d3.loss_dice: 0.5386  decode.d4.loss_cls: 1.6854  decode.d4.loss_mask: 0.5107  decode.d4.loss_dice: 0.5399  decode.d5.loss_cls: 1.6985  decode.d5.loss_mask: 0.4902  decode.d5.loss_dice: 0.5076  decode.d6.loss_cls: 1.6511  decode.d6.loss_mask: 0.5213  decode.d6.loss_dice: 0.5369  decode.d7.loss_cls: 1.7290  decode.d7.loss_mask: 0.4892  decode.d7.loss_dice: 0.5002  decode.d8.loss_cls: 1.6710  decode.d8.loss_mask: 0.4760  decode.d8.loss_dice: 0.5405
07/25 19:23:54 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250725_191538
07/25 19:23:54 - mmengine - INFO - Iter(train) [ 1000/80000]  base_lr: 9.8875e-05 lr: 9.8875e-06  eta: 10:20:21  time: 0.4463  data_time: 0.0096  memory: 5266  grad_norm: 322.7416  loss: 40.2635  decode.loss_cls: 2.2547  decode.loss_mask: 0.6874  decode.loss_dice: 0.7410  decode.d0.loss_cls: 5.4700  decode.d0.loss_mask: 0.7856  decode.d0.loss_dice: 1.0768  decode.d1.loss_cls: 2.2923  decode.d1.loss_mask: 0.6963  decode.d1.loss_dice: 0.7249  decode.d2.loss_cls: 2.2102  decode.d2.loss_mask: 0.7153  decode.d2.loss_dice: 0.7001  decode.d3.loss_cls: 2.2154  decode.d3.loss_mask: 0.6837  decode.d3.loss_dice: 0.6774  decode.d4.loss_cls: 2.1568  decode.d4.loss_mask: 0.6832  decode.d4.loss_dice: 0.7532  decode.d5.loss_cls: 2.2867  decode.d5.loss_mask: 0.6427  decode.d5.loss_dice: 0.6901  decode.d6.loss_cls: 2.2582  decode.d6.loss_mask: 0.7317  decode.d6.loss_dice: 0.7121  decode.d7.loss_cls: 2.2962  decode.d7.loss_mask: 0.7144  decode.d7.loss_dice: 0.7067  decode.d8.loss_cls: 2.2548  decode.d8.loss_mask: 0.6975  decode.d8.loss_dice: 0.7480
07/25 19:24:17 - mmengine - INFO - Iter(train) [ 1050/80000]  base_lr: 9.8819e-05 lr: 9.8819e-06  eta: 10:18:41  time: 0.4589  data_time: 0.0107  memory: 5265  grad_norm: 313.6147  loss: 36.3158  decode.loss_cls: 1.9165  decode.loss_mask: 0.6778  decode.loss_dice: 0.7379  decode.d0.loss_cls: 5.2323  decode.d0.loss_mask: 0.7493  decode.d0.loss_dice: 0.9136  decode.d1.loss_cls: 2.0714  decode.d1.loss_mask: 0.6951  decode.d1.loss_dice: 0.7738  decode.d2.loss_cls: 1.9233  decode.d2.loss_mask: 0.6331  decode.d2.loss_dice: 0.6764  decode.d3.loss_cls: 1.8845  decode.d3.loss_mask: 0.6250  decode.d3.loss_dice: 0.6950  decode.d4.loss_cls: 1.8535  decode.d4.loss_mask: 0.6816  decode.d4.loss_dice: 0.7025  decode.d5.loss_cls: 1.8323  decode.d5.loss_mask: 0.6943  decode.d5.loss_dice: 0.6796  decode.d6.loss_cls: 1.8585  decode.d6.loss_mask: 0.6456  decode.d6.loss_dice: 0.7252  decode.d7.loss_cls: 1.8874  decode.d7.loss_mask: 0.6455  decode.d7.loss_dice: 0.7006  decode.d8.loss_cls: 1.8676  decode.d8.loss_mask: 0.6147  decode.d8.loss_dice: 0.7220
07/25 19:24:40 - mmengine - INFO - Iter(train) [ 1100/80000]  base_lr: 9.8763e-05 lr: 9.8763e-06  eta: 10:17:32  time: 0.4551  data_time: 0.0103  memory: 5249  grad_norm: 186.8740  loss: 33.7724  decode.loss_cls: 1.9198  decode.loss_mask: 0.4981  decode.loss_dice: 0.6203  decode.d0.loss_cls: 5.0859  decode.d0.loss_mask: 0.5293  decode.d0.loss_dice: 0.7708  decode.d1.loss_cls: 2.0143  decode.d1.loss_mask: 0.4697  decode.d1.loss_dice: 0.5852  decode.d2.loss_cls: 1.8540  decode.d2.loss_mask: 0.4835  decode.d2.loss_dice: 0.5847  decode.d3.loss_cls: 1.9254  decode.d3.loss_mask: 0.5006  decode.d3.loss_dice: 0.5797  decode.d4.loss_cls: 1.8676  decode.d4.loss_mask: 0.5155  decode.d4.loss_dice: 0.6209  decode.d5.loss_cls: 1.9290  decode.d5.loss_mask: 0.5506  decode.d5.loss_dice: 0.6435  decode.d6.loss_cls: 1.8828  decode.d6.loss_mask: 0.5672  decode.d6.loss_dice: 0.6268  decode.d7.loss_cls: 1.9214  decode.d7.loss_mask: 0.5157  decode.d7.loss_dice: 0.6291  decode.d8.loss_cls: 1.8996  decode.d8.loss_mask: 0.5360  decode.d8.loss_dice: 0.6454
07/25 19:25:03 - mmengine - INFO - Iter(train) [ 1150/80000]  base_lr: 9.8706e-05 lr: 9.8706e-06  eta: 10:16:29  time: 0.4607  data_time: 0.0104  memory: 5266  grad_norm: 174.5467  loss: 32.2577  decode.loss_cls: 1.9363  decode.loss_mask: 0.4445  decode.loss_dice: 0.5064  decode.d0.loss_cls: 4.9159  decode.d0.loss_mask: 0.5362  decode.d0.loss_dice: 0.6813  decode.d1.loss_cls: 2.1882  decode.d1.loss_mask: 0.4450  decode.d1.loss_dice: 0.4898  decode.d2.loss_cls: 1.9636  decode.d2.loss_mask: 0.4359  decode.d2.loss_dice: 0.4575  decode.d3.loss_cls: 1.9593  decode.d3.loss_mask: 0.4144  decode.d3.loss_dice: 0.4355  decode.d4.loss_cls: 1.9597  decode.d4.loss_mask: 0.4207  decode.d4.loss_dice: 0.4593  decode.d5.loss_cls: 1.9951  decode.d5.loss_mask: 0.4421  decode.d5.loss_dice: 0.4580  decode.d6.loss_cls: 1.9449  decode.d6.loss_mask: 0.4497  decode.d6.loss_dice: 0.4783  decode.d7.loss_cls: 1.9940  decode.d7.loss_mask: 0.4395  decode.d7.loss_dice: 0.5004  decode.d8.loss_cls: 2.0072  decode.d8.loss_mask: 0.4621  decode.d8.loss_dice: 0.4370
07/25 19:25:25 - mmengine - INFO - Iter(train) [ 1200/80000]  base_lr: 9.8650e-05 lr: 9.8650e-06  eta: 10:15:26  time: 0.4584  data_time: 0.0100  memory: 5296  grad_norm: 222.8679  loss: 33.9731  decode.loss_cls: 2.0813  decode.loss_mask: 0.4981  decode.loss_dice: 0.5602  decode.d0.loss_cls: 4.8200  decode.d0.loss_mask: 0.4286  decode.d0.loss_dice: 0.7132  decode.d1.loss_cls: 2.1813  decode.d1.loss_mask: 0.3737  decode.d1.loss_dice: 0.5426  decode.d2.loss_cls: 2.1188  decode.d2.loss_mask: 0.4117  decode.d2.loss_dice: 0.5667  decode.d3.loss_cls: 2.1964  decode.d3.loss_mask: 0.4063  decode.d3.loss_dice: 0.5018  decode.d4.loss_cls: 2.1283  decode.d4.loss_mask: 0.4136  decode.d4.loss_dice: 0.5453  decode.d5.loss_cls: 2.1135  decode.d5.loss_mask: 0.4276  decode.d5.loss_dice: 0.5626  decode.d6.loss_cls: 2.0844  decode.d6.loss_mask: 0.4990  decode.d6.loss_dice: 0.5783  decode.d7.loss_cls: 2.1220  decode.d7.loss_mask: 0.4308  decode.d7.loss_dice: 0.5336  decode.d8.loss_cls: 2.0788  decode.d8.loss_mask: 0.5058  decode.d8.loss_dice: 0.5489
07/25 19:25:48 - mmengine - INFO - Iter(train) [ 1250/80000]  base_lr: 9.8594e-05 lr: 9.8594e-06  eta: 10:14:24  time: 0.4607  data_time: 0.0103  memory: 5231  grad_norm: 184.8894  loss: 31.9939  decode.loss_cls: 1.8354  decode.loss_mask: 0.4141  decode.loss_dice: 0.5030  decode.d0.loss_cls: 4.6805  decode.d0.loss_mask: 0.4496  decode.d0.loss_dice: 0.6510  decode.d1.loss_cls: 2.1794  decode.d1.loss_mask: 0.4402  decode.d1.loss_dice: 0.5306  decode.d2.loss_cls: 1.9914  decode.d2.loss_mask: 0.4417  decode.d2.loss_dice: 0.4621  decode.d3.loss_cls: 2.0566  decode.d3.loss_mask: 0.4321  decode.d3.loss_dice: 0.4645  decode.d4.loss_cls: 1.9824  decode.d4.loss_mask: 0.4780  decode.d4.loss_dice: 0.4686  decode.d5.loss_cls: 2.0625  decode.d5.loss_mask: 0.4430  decode.d5.loss_dice: 0.4805  decode.d6.loss_cls: 1.9028  decode.d6.loss_mask: 0.4280  decode.d6.loss_dice: 0.4832  decode.d7.loss_cls: 2.0122  decode.d7.loss_mask: 0.4228  decode.d7.loss_dice: 0.4731  decode.d8.loss_cls: 1.9124  decode.d8.loss_mask: 0.4179  decode.d8.loss_dice: 0.4944
07/25 19:26:11 - mmengine - INFO - Iter(train) [ 1300/80000]  base_lr: 9.8537e-05 lr: 9.8537e-06  eta: 10:13:09  time: 0.4355  data_time: 0.0085  memory: 5249  grad_norm: 191.1890  loss: 29.7760  decode.loss_cls: 1.8006  decode.loss_mask: 0.3640  decode.loss_dice: 0.5027  decode.d0.loss_cls: 4.4143  decode.d0.loss_mask: 0.4008  decode.d0.loss_dice: 0.6963  decode.d1.loss_cls: 2.0540  decode.d1.loss_mask: 0.3122  decode.d1.loss_dice: 0.4260  decode.d2.loss_cls: 1.9369  decode.d2.loss_mask: 0.3470  decode.d2.loss_dice: 0.4383  decode.d3.loss_cls: 1.9168  decode.d3.loss_mask: 0.3309  decode.d3.loss_dice: 0.4393  decode.d4.loss_cls: 2.0355  decode.d4.loss_mask: 0.3373  decode.d4.loss_dice: 0.4642  decode.d5.loss_cls: 1.8660  decode.d5.loss_mask: 0.3369  decode.d5.loss_dice: 0.4263  decode.d6.loss_cls: 1.7445  decode.d6.loss_mask: 0.3793  decode.d6.loss_dice: 0.4752  decode.d7.loss_cls: 1.8201  decode.d7.loss_mask: 0.3916  decode.d7.loss_dice: 0.4941  decode.d8.loss_cls: 1.8512  decode.d8.loss_mask: 0.3319  decode.d8.loss_dice: 0.4418
07/25 19:26:33 - mmengine - INFO - Iter(train) [ 1350/80000]  base_lr: 9.8481e-05 lr: 9.8481e-06  eta: 10:12:10  time: 0.4518  data_time: 0.0103  memory: 5229  grad_norm: 197.7708  loss: 27.6999  decode.loss_cls: 1.5182  decode.loss_mask: 0.5339  decode.loss_dice: 0.3998  decode.d0.loss_cls: 4.2326  decode.d0.loss_mask: 0.5553  decode.d0.loss_dice: 0.6216  decode.d1.loss_cls: 1.7216  decode.d1.loss_mask: 0.5266  decode.d1.loss_dice: 0.4439  decode.d2.loss_cls: 1.5834  decode.d2.loss_mask: 0.5170  decode.d2.loss_dice: 0.4519  decode.d3.loss_cls: 1.5635  decode.d3.loss_mask: 0.4939  decode.d3.loss_dice: 0.4024  decode.d4.loss_cls: 1.5440  decode.d4.loss_mask: 0.5281  decode.d4.loss_dice: 0.4181  decode.d5.loss_cls: 1.5284  decode.d5.loss_mask: 0.4867  decode.d5.loss_dice: 0.4123  decode.d6.loss_cls: 1.4970  decode.d6.loss_mask: 0.5229  decode.d6.loss_dice: 0.4147  decode.d7.loss_cls: 1.5088  decode.d7.loss_mask: 0.5163  decode.d7.loss_dice: 0.3909  decode.d8.loss_cls: 1.4854  decode.d8.loss_mask: 0.4928  decode.d8.loss_dice: 0.3879
07/25 19:26:56 - mmengine - INFO - Iter(train) [ 1400/80000]  base_lr: 9.8425e-05 lr: 9.8425e-06  eta: 10:11:01  time: 0.4549  data_time: 0.0098  memory: 5231  grad_norm: 224.8977  loss: 32.3877  decode.loss_cls: 2.0420  decode.loss_mask: 0.4307  decode.loss_dice: 0.5719  decode.d0.loss_cls: 4.2075  decode.d0.loss_mask: 0.4661  decode.d0.loss_dice: 0.7916  decode.d1.loss_cls: 2.1302  decode.d1.loss_mask: 0.3897  decode.d1.loss_dice: 0.5369  decode.d2.loss_cls: 1.9500  decode.d2.loss_mask: 0.3909  decode.d2.loss_dice: 0.5193  decode.d3.loss_cls: 2.0005  decode.d3.loss_mask: 0.3759  decode.d3.loss_dice: 0.5124  decode.d4.loss_cls: 2.1140  decode.d4.loss_mask: 0.3874  decode.d4.loss_dice: 0.5050  decode.d5.loss_cls: 2.0638  decode.d5.loss_mask: 0.3886  decode.d5.loss_dice: 0.5075  decode.d6.loss_cls: 2.0811  decode.d6.loss_mask: 0.4051  decode.d6.loss_dice: 0.5428  decode.d7.loss_cls: 2.1452  decode.d7.loss_mask: 0.3951  decode.d7.loss_dice: 0.5482  decode.d8.loss_cls: 2.1209  decode.d8.loss_mask: 0.3704  decode.d8.loss_dice: 0.4966
07/25 19:27:19 - mmengine - INFO - Iter(train) [ 1450/80000]  base_lr: 9.8368e-05 lr: 9.8368e-06  eta: 10:10:09  time: 0.4551  data_time: 0.0102  memory: 5231  grad_norm: 144.7683  loss: 25.7123  decode.loss_cls: 1.3896  decode.loss_mask: 0.3804  decode.loss_dice: 0.4579  decode.d0.loss_cls: 3.9397  decode.d0.loss_mask: 0.3869  decode.d0.loss_dice: 0.6129  decode.d1.loss_cls: 1.7234  decode.d1.loss_mask: 0.3523  decode.d1.loss_dice: 0.4294  decode.d2.loss_cls: 1.5785  decode.d2.loss_mask: 0.3475  decode.d2.loss_dice: 0.3916  decode.d3.loss_cls: 1.6200  decode.d3.loss_mask: 0.3410  decode.d3.loss_dice: 0.3764  decode.d4.loss_cls: 1.5607  decode.d4.loss_mask: 0.3367  decode.d4.loss_dice: 0.3933  decode.d5.loss_cls: 1.5268  decode.d5.loss_mask: 0.3338  decode.d5.loss_dice: 0.4069  decode.d6.loss_cls: 1.5104  decode.d6.loss_mask: 0.3281  decode.d6.loss_dice: 0.3888  decode.d7.loss_cls: 1.5896  decode.d7.loss_mask: 0.3239  decode.d7.loss_dice: 0.3799  decode.d8.loss_cls: 1.5493  decode.d8.loss_mask: 0.3377  decode.d8.loss_dice: 0.4187
07/25 19:27:42 - mmengine - INFO - Iter(train) [ 1500/80000]  base_lr: 9.8312e-05 lr: 9.8312e-06  eta: 10:09:19  time: 0.4582  data_time: 0.0099  memory: 5231  grad_norm: 161.6990  loss: 29.8936  decode.loss_cls: 1.8677  decode.loss_mask: 0.3674  decode.loss_dice: 0.5188  decode.d0.loss_cls: 4.0367  decode.d0.loss_mask: 0.4056  decode.d0.loss_dice: 0.7123  decode.d1.loss_cls: 2.0635  decode.d1.loss_mask: 0.3538  decode.d1.loss_dice: 0.4470  decode.d2.loss_cls: 1.8741  decode.d2.loss_mask: 0.3470  decode.d2.loss_dice: 0.4558  decode.d3.loss_cls: 1.9765  decode.d3.loss_mask: 0.3481  decode.d3.loss_dice: 0.4684  decode.d4.loss_cls: 1.9636  decode.d4.loss_mask: 0.3565  decode.d4.loss_dice: 0.4621  decode.d5.loss_cls: 1.9325  decode.d5.loss_mask: 0.3310  decode.d5.loss_dice: 0.4653  decode.d6.loss_cls: 1.9076  decode.d6.loss_mask: 0.3400  decode.d6.loss_dice: 0.4619  decode.d7.loss_cls: 1.9165  decode.d7.loss_mask: 0.3591  decode.d7.loss_dice: 0.4864  decode.d8.loss_cls: 1.8683  decode.d8.loss_mask: 0.3356  decode.d8.loss_dice: 0.4646
07/25 19:28:04 - mmengine - INFO - Iter(train) [ 1550/80000]  base_lr: 9.8256e-05 lr: 9.8256e-06  eta: 10:08:33  time: 0.4577  data_time: 0.0103  memory: 5249  grad_norm: 154.9704  loss: 29.9585  decode.loss_cls: 1.9193  decode.loss_mask: 0.3973  decode.loss_dice: 0.4969  decode.d0.loss_cls: 3.8605  decode.d0.loss_mask: 0.3892  decode.d0.loss_dice: 0.6927  decode.d1.loss_cls: 1.9572  decode.d1.loss_mask: 0.4318  decode.d1.loss_dice: 0.5082  decode.d2.loss_cls: 1.8479  decode.d2.loss_mask: 0.3778  decode.d2.loss_dice: 0.4852  decode.d3.loss_cls: 1.9019  decode.d3.loss_mask: 0.3590  decode.d3.loss_dice: 0.4737  decode.d4.loss_cls: 1.9548  decode.d4.loss_mask: 0.3795  decode.d4.loss_dice: 0.4747  decode.d5.loss_cls: 1.8973  decode.d5.loss_mask: 0.3638  decode.d5.loss_dice: 0.4728  decode.d6.loss_cls: 1.8312  decode.d6.loss_mask: 0.3621  decode.d6.loss_dice: 0.4734  decode.d7.loss_cls: 1.9526  decode.d7.loss_mask: 0.3748  decode.d7.loss_dice: 0.4582  decode.d8.loss_cls: 1.9689  decode.d8.loss_mask: 0.3981  decode.d8.loss_dice: 0.4977
