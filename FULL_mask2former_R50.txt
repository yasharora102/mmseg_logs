==========================================
SLURM_JOB_ID = 2466249
SLURM_NODELIST = gnode070
SLURM_JOB_GPUS = 0
==========================================
07/25 19:15:40 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.23 (main, Jun  5 2025, 13:40:20) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 446836777
    GPU 0: NVIDIA GeForce RTX 2080 Ti
    CUDA_HOME: /opt/cuda-12.1/
    NVCC: Cuda compilation tools, release 12.1, V12.1.66
    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
    PyTorch: 2.1.2
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 446836777
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

07/25 19:15:40 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=16, enable=False)
crop_size = (
    512,
    1024,
)
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        512,
        1024,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    test_cfg=dict(size_divisor=32),
    type='SegDataPreProcessor')
data_root = '/scratch/seg_benchmark/seg_FULL/'
dataset_type = 'YourDataset_BIG'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False, interval=5000, save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'))
default_scope = 'mmseg'
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
img_suffix = '.jpg'
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        deep_stem=False,
        depth=50,
        frozen_stages=-1,
        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),
        norm_cfg=dict(requires_grad=False, type='SyncBN'),
        num_stages=4,
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        style='pytorch',
        type='ResNet'),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            1024,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        test_cfg=dict(size_divisor=32),
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            256,
            512,
            1024,
            2048,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=57,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 57
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict(
            backbone=dict(decay_mult=1.0, lr_mult=0.1),
            level_embed=dict(decay_mult=0.0, lr_mult=1.0),
            query_embed=dict(decay_mult=0.0, lr_mult=1.0),
            query_feat=dict(decay_mult=0.0, lr_mult=1.0)),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=80000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
resume = False
seg_map_suffix = '.png'
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/seg_benchmark/seg_FULL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2048,
        1024,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(
    max_iters=80000, type='IterBasedTrainLoop', val_interval=80000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        data_prefix=dict(img_path='train/images', seg_map_path='train/masks'),
        data_root='/scratch/seg_benchmark/seg_FULL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                max_size=4096,
                resize_type='ResizeShortestEdge',
                scales=[
                    512,
                    614,
                    716,
                    819,
                    921,
                    1024,
                    1126,
                    1228,
                    1331,
                    1433,
                    1536,
                    1638,
                    1740,
                    1843,
                    1945,
                    2048,
                ],
                type='RandomChoiceResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    512,
                    1024,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        max_size=4096,
        resize_type='ResizeShortestEdge',
        scales=[
            512,
            614,
            716,
            819,
            921,
            1024,
            1126,
            1228,
            1331,
            1433,
            1536,
            1638,
            1740,
            1843,
            1945,
            2048,
        ],
        type='RandomChoiceResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        1024,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/seg_benchmark/seg_FULL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '/scratch/seg_benchmark/FULL/mask2former_R50'

07/25 19:15:55 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
07/25 19:15:55 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.0.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.0.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.0.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.0.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.0.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.0.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.0.downsample.1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.0.downsample.1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.1.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.1.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.1.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.1.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.1.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.1.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.2.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.2.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.2.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.2.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.2.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer1.2.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.0.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.0.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.0.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.0.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.0.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.0.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.0.downsample.1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.0.downsample.1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.1.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.1.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.1.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.1.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.1.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.1.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.2.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.2.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.2.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.2.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.2.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.2.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.3.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.3.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.3.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.3.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.3.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer2.3.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.0.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.0.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.0.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.0.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.0.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.0.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.0.downsample.1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.0.downsample.1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.1.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.1.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.1.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.1.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.1.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.1.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.2.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.2.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.2.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.2.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.2.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.2.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.3.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.3.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.3.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.3.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.3.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.3.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.4.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.4.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.4.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.4.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.4.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.4.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.5.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.5.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.5.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.5.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.5.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer3.5.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.0.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.0.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.0.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.0.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.0.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.0.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.0.downsample.1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.0.downsample.1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.1.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.1.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.1.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.1.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.1.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.1.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.2.bn1.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.2.bn1.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.2.bn2.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.2.bn2.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:lr=1e-05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:weight_decay=0.05
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:lr_mult=0.1
07/25 19:15:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:decay_mult=1.0
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.2.bn3.weight is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - WARNING - backbone.layer4.2.bn3.bias is skipped since its requires_grad=False
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
07/25 19:15:56 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
07/25 19:15:56 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
07/25 19:15:57 - mmengine - INFO - load model from: torchvision://resnet50
07/25 19:15:57 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet50
07/25 19:16:02 - mmengine - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

07/25 19:16:03 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
07/25 19:16:03 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
07/25 19:16:03 - mmengine - INFO - Checkpoints will be saved to /scratch/seg_benchmark/FULL/mask2former_R50.
/home2/yasharora120/miniconda3/envs/mmseg/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400441250/work/aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
07/25 19:16:43 - mmengine - INFO - Iter(train) [   50/80000]  base_lr: 9.9945e-05 lr: 9.9945e-06  eta: 17:38:17  time: 0.4503  data_time: 0.0101  memory: 10589  grad_norm: 158.2570  loss: 100.2073  decode.loss_cls: 4.3556  decode.loss_mask: 2.2592  decode.loss_dice: 4.2021  decode.d0.loss_cls: 8.0755  decode.d0.loss_mask: 1.7814  decode.d0.loss_dice: 3.5501  decode.d1.loss_cls: 3.8993  decode.d1.loss_mask: 1.7096  decode.d1.loss_dice: 3.3914  decode.d2.loss_cls: 3.8226  decode.d2.loss_mask: 1.7181  decode.d2.loss_dice: 3.4107  decode.d3.loss_cls: 3.8172  decode.d3.loss_mask: 1.7546  decode.d3.loss_dice: 3.4285  decode.d4.loss_cls: 3.8584  decode.d4.loss_mask: 1.7657  decode.d4.loss_dice: 3.4749  decode.d5.loss_cls: 3.8862  decode.d5.loss_mask: 1.8375  decode.d5.loss_dice: 3.6192  decode.d6.loss_cls: 4.0698  decode.d6.loss_mask: 1.9370  decode.d6.loss_dice: 3.7545  decode.d7.loss_cls: 4.1472  decode.d7.loss_mask: 2.2540  decode.d7.loss_dice: 3.8631  decode.d8.loss_cls: 4.2929  decode.d8.loss_mask: 2.2836  decode.d8.loss_dice: 3.9871
07/25 19:17:05 - mmengine - INFO - Iter(train) [  100/80000]  base_lr: 9.9889e-05 lr: 9.9889e-06  eta: 13:49:46  time: 0.4532  data_time: 0.0106  memory: 5265  grad_norm: 275.0222  loss: 78.2691  decode.loss_cls: 3.0738  decode.loss_mask: 1.7527  decode.loss_dice: 2.9162  decode.d0.loss_cls: 7.9707  decode.d0.loss_mask: 1.5226  decode.d0.loss_dice: 2.8258  decode.d1.loss_cls: 3.0076  decode.d1.loss_mask: 1.4789  decode.d1.loss_dice: 2.6281  decode.d2.loss_cls: 2.8909  decode.d2.loss_mask: 1.5149  decode.d2.loss_dice: 2.6242  decode.d3.loss_cls: 2.7494  decode.d3.loss_mask: 1.5655  decode.d3.loss_dice: 2.6885  decode.d4.loss_cls: 2.7805  decode.d4.loss_mask: 1.5869  decode.d4.loss_dice: 2.7381  decode.d5.loss_cls: 2.7930  decode.d5.loss_mask: 1.6037  decode.d5.loss_dice: 2.7718  decode.d6.loss_cls: 3.0335  decode.d6.loss_mask: 1.6157  decode.d6.loss_dice: 2.7711  decode.d7.loss_cls: 3.1664  decode.d7.loss_mask: 1.6348  decode.d7.loss_dice: 2.7859  decode.d8.loss_cls: 3.0945  decode.d8.loss_mask: 1.7564  decode.d8.loss_dice: 2.9268
07/25 19:17:28 - mmengine - INFO - Iter(train) [  150/80000]  base_lr: 9.9832e-05 lr: 9.9832e-06  eta: 12:33:57  time: 0.4523  data_time: 0.0100  memory: 5249  grad_norm: 211.1235  loss: 64.6201  decode.loss_cls: 2.6660  decode.loss_mask: 1.3280  decode.loss_dice: 2.1313  decode.d0.loss_cls: 7.8807  decode.d0.loss_mask: 1.2033  decode.d0.loss_dice: 2.3060  decode.d1.loss_cls: 2.8784  decode.d1.loss_mask: 1.1752  decode.d1.loss_dice: 2.0100  decode.d2.loss_cls: 2.6619  decode.d2.loss_mask: 1.1835  decode.d2.loss_dice: 1.9683  decode.d3.loss_cls: 2.5775  decode.d3.loss_mask: 1.2252  decode.d3.loss_dice: 1.9724  decode.d4.loss_cls: 2.5927  decode.d4.loss_mask: 1.2466  decode.d4.loss_dice: 1.9826  decode.d5.loss_cls: 2.5952  decode.d5.loss_mask: 1.2581  decode.d5.loss_dice: 1.9790  decode.d6.loss_cls: 2.5676  decode.d6.loss_mask: 1.2568  decode.d6.loss_dice: 2.0023  decode.d7.loss_cls: 2.5819  decode.d7.loss_mask: 1.2650  decode.d7.loss_dice: 2.0717  decode.d8.loss_cls: 2.6742  decode.d8.loss_mask: 1.3121  decode.d8.loss_dice: 2.0667
07/25 19:17:50 - mmengine - INFO - Iter(train) [  200/80000]  base_lr: 9.9776e-05 lr: 9.9776e-06  eta: 11:54:10  time: 0.4526  data_time: 0.0101  memory: 5249  grad_norm: 234.4230  loss: 59.7927  decode.loss_cls: 2.9385  decode.loss_mask: 0.9035  decode.loss_dice: 1.7875  decode.d0.loss_cls: 7.7872  decode.d0.loss_mask: 0.8998  decode.d0.loss_dice: 2.1333  decode.d1.loss_cls: 2.7943  decode.d1.loss_mask: 0.8621  decode.d1.loss_dice: 1.7828  decode.d2.loss_cls: 2.6939  decode.d2.loss_mask: 0.8402  decode.d2.loss_dice: 1.6505  decode.d3.loss_cls: 2.6789  decode.d3.loss_mask: 0.8361  decode.d3.loss_dice: 1.7275  decode.d4.loss_cls: 2.8367  decode.d4.loss_mask: 0.8388  decode.d4.loss_dice: 1.7146  decode.d5.loss_cls: 2.9036  decode.d5.loss_mask: 0.8566  decode.d5.loss_dice: 1.7211  decode.d6.loss_cls: 2.9192  decode.d6.loss_mask: 0.8849  decode.d6.loss_dice: 1.6770  decode.d7.loss_cls: 2.9612  decode.d7.loss_mask: 0.8881  decode.d7.loss_dice: 1.6945  decode.d8.loss_cls: 2.9004  decode.d8.loss_mask: 0.9361  decode.d8.loss_dice: 1.7434
07/25 19:18:13 - mmengine - INFO - Iter(train) [  250/80000]  base_lr: 9.9720e-05 lr: 9.9720e-06  eta: 11:31:38  time: 0.4522  data_time: 0.0101  memory: 5228  grad_norm: 284.4101  loss: 56.9332  decode.loss_cls: 3.0469  decode.loss_mask: 0.9980  decode.loss_dice: 1.3135  decode.d0.loss_cls: 7.6351  decode.d0.loss_mask: 1.0489  decode.d0.loss_dice: 1.8128  decode.d1.loss_cls: 2.8569  decode.d1.loss_mask: 0.9662  decode.d1.loss_dice: 1.4138  decode.d2.loss_cls: 2.7505  decode.d2.loss_mask: 0.9329  decode.d2.loss_dice: 1.3152  decode.d3.loss_cls: 2.7594  decode.d3.loss_mask: 0.9315  decode.d3.loss_dice: 1.2938  decode.d4.loss_cls: 2.8990  decode.d4.loss_mask: 0.9316  decode.d4.loss_dice: 1.2810  decode.d5.loss_cls: 2.9699  decode.d5.loss_mask: 0.9286  decode.d5.loss_dice: 1.2866  decode.d6.loss_cls: 2.9373  decode.d6.loss_mask: 0.9153  decode.d6.loss_dice: 1.2606  decode.d7.loss_cls: 2.9391  decode.d7.loss_mask: 0.9470  decode.d7.loss_dice: 1.2796  decode.d8.loss_cls: 3.0084  decode.d8.loss_mask: 0.9736  decode.d8.loss_dice: 1.2999
07/25 19:18:36 - mmengine - INFO - Iter(train) [  300/80000]  base_lr: 9.9664e-05 lr: 9.9664e-06  eta: 11:15:44  time: 0.4532  data_time: 0.0103  memory: 5227  grad_norm: 318.4766  loss: 51.0229  decode.loss_cls: 2.7485  decode.loss_mask: 0.8021  decode.loss_dice: 1.0084  decode.d0.loss_cls: 7.4972  decode.d0.loss_mask: 1.0229  decode.d0.loss_dice: 1.5616  decode.d1.loss_cls: 2.7515  decode.d1.loss_mask: 0.8339  decode.d1.loss_dice: 1.1829  decode.d2.loss_cls: 2.6651  decode.d2.loss_mask: 0.7977  decode.d2.loss_dice: 1.0820  decode.d3.loss_cls: 2.6617  decode.d3.loss_mask: 0.7658  decode.d3.loss_dice: 1.0054  decode.d4.loss_cls: 2.7448  decode.d4.loss_mask: 0.7375  decode.d4.loss_dice: 1.0011  decode.d5.loss_cls: 2.7779  decode.d5.loss_mask: 0.7932  decode.d5.loss_dice: 0.9800  decode.d6.loss_cls: 2.7783  decode.d6.loss_mask: 0.7674  decode.d6.loss_dice: 0.9837  decode.d7.loss_cls: 2.7843  decode.d7.loss_mask: 0.7782  decode.d7.loss_dice: 0.9914  decode.d8.loss_cls: 2.7421  decode.d8.loss_mask: 0.7744  decode.d8.loss_dice: 1.0018
07/25 19:18:58 - mmengine - INFO - Iter(train) [  350/80000]  base_lr: 9.9607e-05 lr: 9.9607e-06  eta: 11:05:10  time: 0.4565  data_time: 0.0103  memory: 5294  grad_norm: 234.8158  loss: 49.8826  decode.loss_cls: 2.7002  decode.loss_mask: 0.7023  decode.loss_dice: 1.0695  decode.d0.loss_cls: 7.3268  decode.d0.loss_mask: 0.7432  decode.d0.loss_dice: 1.5303  decode.d1.loss_cls: 2.6501  decode.d1.loss_mask: 0.6859  decode.d1.loss_dice: 1.1292  decode.d2.loss_cls: 2.5731  decode.d2.loss_mask: 0.6867  decode.d2.loss_dice: 1.1033  decode.d3.loss_cls: 2.6492  decode.d3.loss_mask: 0.6880  decode.d3.loss_dice: 1.0672  decode.d4.loss_cls: 2.7745  decode.d4.loss_mask: 0.6616  decode.d4.loss_dice: 1.0436  decode.d5.loss_cls: 2.7236  decode.d5.loss_mask: 0.6988  decode.d5.loss_dice: 1.0937  decode.d6.loss_cls: 2.7333  decode.d6.loss_mask: 0.7085  decode.d6.loss_dice: 1.0791  decode.d7.loss_cls: 2.7441  decode.d7.loss_mask: 0.7131  decode.d7.loss_dice: 1.0922  decode.d8.loss_cls: 2.7457  decode.d8.loss_mask: 0.6789  decode.d8.loss_dice: 1.0867
07/25 19:19:21 - mmengine - INFO - Iter(train) [  400/80000]  base_lr: 9.9551e-05 lr: 9.9551e-06  eta: 10:56:59  time: 0.4540  data_time: 0.0104  memory: 5215  grad_norm: 380.3828  loss: 48.2619  decode.loss_cls: 2.4038  decode.loss_mask: 0.9298  decode.loss_dice: 1.0419  decode.d0.loss_cls: 7.1823  decode.d0.loss_mask: 0.9581  decode.d0.loss_dice: 1.3789  decode.d1.loss_cls: 2.3559  decode.d1.loss_mask: 0.9519  decode.d1.loss_dice: 1.1088  decode.d2.loss_cls: 2.2907  decode.d2.loss_mask: 0.9391  decode.d2.loss_dice: 1.0219  decode.d3.loss_cls: 2.2634  decode.d3.loss_mask: 0.8875  decode.d3.loss_dice: 1.0106  decode.d4.loss_cls: 2.3130  decode.d4.loss_mask: 0.8896  decode.d4.loss_dice: 0.9853  decode.d5.loss_cls: 2.3768  decode.d5.loss_mask: 0.9055  decode.d5.loss_dice: 0.9770  decode.d6.loss_cls: 2.3784  decode.d6.loss_mask: 0.9738  decode.d6.loss_dice: 1.0084  decode.d7.loss_cls: 2.3631  decode.d7.loss_mask: 0.9784  decode.d7.loss_dice: 1.0262  decode.d8.loss_cls: 2.3776  decode.d8.loss_mask: 0.9488  decode.d8.loss_dice: 1.0354
07/25 19:19:44 - mmengine - INFO - Iter(train) [  450/80000]  base_lr: 9.9495e-05 lr: 9.9495e-06  eta: 10:51:47  time: 0.4556  data_time: 0.0103  memory: 5308  grad_norm: 313.1468  loss: 44.9564  decode.loss_cls: 2.3586  decode.loss_mask: 0.7892  decode.loss_dice: 0.9097  decode.d0.loss_cls: 7.0012  decode.d0.loss_mask: 0.8872  decode.d0.loss_dice: 1.3307  decode.d1.loss_cls: 2.3996  decode.d1.loss_mask: 0.7499  decode.d1.loss_dice: 0.9590  decode.d2.loss_cls: 2.1750  decode.d2.loss_mask: 0.7489  decode.d2.loss_dice: 0.9133  decode.d3.loss_cls: 2.1681  decode.d3.loss_mask: 0.7249  decode.d3.loss_dice: 0.8938  decode.d4.loss_cls: 2.2273  decode.d4.loss_mask: 0.7646  decode.d4.loss_dice: 0.8985  decode.d5.loss_cls: 2.2681  decode.d5.loss_mask: 0.7764  decode.d5.loss_dice: 0.9334  decode.d6.loss_cls: 2.3275  decode.d6.loss_mask: 0.8063  decode.d6.loss_dice: 0.9016  decode.d7.loss_cls: 2.3307  decode.d7.loss_mask: 0.7718  decode.d7.loss_dice: 0.8958  decode.d8.loss_cls: 2.3958  decode.d8.loss_mask: 0.7462  decode.d8.loss_dice: 0.9032
07/25 19:20:07 - mmengine - INFO - Iter(train) [  500/80000]  base_lr: 9.9438e-05 lr: 9.9438e-06  eta: 10:46:44  time: 0.4608  data_time: 0.0103  memory: 5265  grad_norm: 272.6005  loss: 48.0799  decode.loss_cls: 2.6366  decode.loss_mask: 0.8264  decode.loss_dice: 1.0068  decode.d0.loss_cls: 6.8417  decode.d0.loss_mask: 0.7664  decode.d0.loss_dice: 1.2913  decode.d1.loss_cls: 2.6029  decode.d1.loss_mask: 0.7949  decode.d1.loss_dice: 0.9654  decode.d2.loss_cls: 2.5559  decode.d2.loss_mask: 0.7701  decode.d2.loss_dice: 0.9470  decode.d3.loss_cls: 2.5846  decode.d3.loss_mask: 0.7794  decode.d3.loss_dice: 0.9327  decode.d4.loss_cls: 2.6326  decode.d4.loss_mask: 0.7676  decode.d4.loss_dice: 0.9620  decode.d5.loss_cls: 2.6265  decode.d5.loss_mask: 0.7365  decode.d5.loss_dice: 0.9553  decode.d6.loss_cls: 2.6371  decode.d6.loss_mask: 0.7407  decode.d6.loss_dice: 0.9995  decode.d7.loss_cls: 2.6428  decode.d7.loss_mask: 0.6951  decode.d7.loss_dice: 0.9279  decode.d8.loss_cls: 2.6740  decode.d8.loss_mask: 0.7656  decode.d8.loss_dice: 1.0146
07/25 19:20:30 - mmengine - INFO - Iter(train) [  550/80000]  base_lr: 9.9382e-05 lr: 9.9382e-06  eta: 10:42:08  time: 0.4434  data_time: 0.0096  memory: 5228  grad_norm: 235.5370  loss: 40.9569  decode.loss_cls: 2.3422  decode.loss_mask: 0.5890  decode.loss_dice: 0.6665  decode.d0.loss_cls: 6.6312  decode.d0.loss_mask: 0.7016  decode.d0.loss_dice: 1.0087  decode.d1.loss_cls: 2.3908  decode.d1.loss_mask: 0.5835  decode.d1.loss_dice: 0.7367  decode.d2.loss_cls: 2.3086  decode.d2.loss_mask: 0.6127  decode.d2.loss_dice: 0.7359  decode.d3.loss_cls: 2.2912  decode.d3.loss_mask: 0.6078  decode.d3.loss_dice: 0.7066  decode.d4.loss_cls: 2.3494  decode.d4.loss_mask: 0.5754  decode.d4.loss_dice: 0.6874  decode.d5.loss_cls: 2.2905  decode.d5.loss_mask: 0.6031  decode.d5.loss_dice: 0.6942  decode.d6.loss_cls: 2.2640  decode.d6.loss_mask: 0.6014  decode.d6.loss_dice: 0.6939  decode.d7.loss_cls: 2.2952  decode.d7.loss_mask: 0.5912  decode.d7.loss_dice: 0.6934  decode.d8.loss_cls: 2.3959  decode.d8.loss_mask: 0.6146  decode.d8.loss_dice: 0.6941
07/25 19:20:52 - mmengine - INFO - Iter(train) [  600/80000]  base_lr: 9.9326e-05 lr: 9.9326e-06  eta: 10:38:25  time: 0.4585  data_time: 0.0104  memory: 5249  grad_norm: 205.6876  loss: 39.2980  decode.loss_cls: 2.5021  decode.loss_mask: 0.4406  decode.loss_dice: 0.5965  decode.d0.loss_cls: 6.5363  decode.d0.loss_mask: 0.5464  decode.d0.loss_dice: 0.9543  decode.d1.loss_cls: 2.5265  decode.d1.loss_mask: 0.4360  decode.d1.loss_dice: 0.6015  decode.d2.loss_cls: 2.4708  decode.d2.loss_mask: 0.4308  decode.d2.loss_dice: 0.5693  decode.d3.loss_cls: 2.4213  decode.d3.loss_mask: 0.4146  decode.d3.loss_dice: 0.5227  decode.d4.loss_cls: 2.4526  decode.d4.loss_mask: 0.4131  decode.d4.loss_dice: 0.5411  decode.d5.loss_cls: 2.4822  decode.d5.loss_mask: 0.4291  decode.d5.loss_dice: 0.5390  decode.d6.loss_cls: 2.4704  decode.d6.loss_mask: 0.4320  decode.d6.loss_dice: 0.5336  decode.d7.loss_cls: 2.5012  decode.d7.loss_mask: 0.4449  decode.d7.loss_dice: 0.5400  decode.d8.loss_cls: 2.4941  decode.d8.loss_mask: 0.4545  decode.d8.loss_dice: 0.6005
07/25 19:21:15 - mmengine - INFO - Iter(train) [  650/80000]  base_lr: 9.9270e-05 lr: 9.9270e-06  eta: 10:35:01  time: 0.4577  data_time: 0.0105  memory: 5269  grad_norm: 336.1997  loss: 44.2682  decode.loss_cls: 2.4108  decode.loss_mask: 0.6675  decode.loss_dice: 0.8152  decode.d0.loss_cls: 6.4807  decode.d0.loss_mask: 0.7381  decode.d0.loss_dice: 1.1842  decode.d1.loss_cls: 2.4702  decode.d1.loss_mask: 0.7045  decode.d1.loss_dice: 0.8868  decode.d2.loss_cls: 2.3983  decode.d2.loss_mask: 0.7028  decode.d2.loss_dice: 0.8529  decode.d3.loss_cls: 2.4417  decode.d3.loss_mask: 0.6806  decode.d3.loss_dice: 0.8448  decode.d4.loss_cls: 2.3926  decode.d4.loss_mask: 0.6847  decode.d4.loss_dice: 0.8754  decode.d5.loss_cls: 2.4443  decode.d5.loss_mask: 0.6837  decode.d5.loss_dice: 0.8528  decode.d6.loss_cls: 2.4226  decode.d6.loss_mask: 0.7363  decode.d6.loss_dice: 0.8833  decode.d7.loss_cls: 2.4156  decode.d7.loss_mask: 0.7549  decode.d7.loss_dice: 0.8719  decode.d8.loss_cls: 2.4443  decode.d8.loss_mask: 0.6884  decode.d8.loss_dice: 0.8381
07/25 19:21:38 - mmengine - INFO - Iter(train) [  700/80000]  base_lr: 9.9213e-05 lr: 9.9213e-06  eta: 10:32:16  time: 0.4564  data_time: 0.0102  memory: 5231  grad_norm: 179.2129  loss: 37.4267  decode.loss_cls: 2.2476  decode.loss_mask: 0.4176  decode.loss_dice: 0.5594  decode.d0.loss_cls: 6.2133  decode.d0.loss_mask: 0.5088  decode.d0.loss_dice: 0.9357  decode.d1.loss_cls: 2.4222  decode.d1.loss_mask: 0.4477  decode.d1.loss_dice: 0.6178  decode.d2.loss_cls: 2.3141  decode.d2.loss_mask: 0.4112  decode.d2.loss_dice: 0.5739  decode.d3.loss_cls: 2.2195  decode.d3.loss_mask: 0.4299  decode.d3.loss_dice: 0.5803  decode.d4.loss_cls: 2.2849  decode.d4.loss_mask: 0.4111  decode.d4.loss_dice: 0.5847  decode.d5.loss_cls: 2.2976  decode.d5.loss_mask: 0.4345  decode.d5.loss_dice: 0.5637  decode.d6.loss_cls: 2.2712  decode.d6.loss_mask: 0.4322  decode.d6.loss_dice: 0.5792  decode.d7.loss_cls: 2.3314  decode.d7.loss_mask: 0.4398  decode.d7.loss_dice: 0.5784  decode.d8.loss_cls: 2.2787  decode.d8.loss_mask: 0.4584  decode.d8.loss_dice: 0.5822
07/25 19:22:01 - mmengine - INFO - Iter(train) [  750/80000]  base_lr: 9.9157e-05 lr: 9.9157e-06  eta: 10:29:51  time: 0.4556  data_time: 0.0102  memory: 5228  grad_norm: 210.4335  loss: 39.7792  decode.loss_cls: 2.1047  decode.loss_mask: 0.5857  decode.loss_dice: 0.7738  decode.d0.loss_cls: 6.0825  decode.d0.loss_mask: 0.6650  decode.d0.loss_dice: 1.1580  decode.d1.loss_cls: 2.2098  decode.d1.loss_mask: 0.5677  decode.d1.loss_dice: 0.8762  decode.d2.loss_cls: 2.1087  decode.d2.loss_mask: 0.5616  decode.d2.loss_dice: 0.8244  decode.d3.loss_cls: 2.0682  decode.d3.loss_mask: 0.5448  decode.d3.loss_dice: 0.8100  decode.d4.loss_cls: 2.1873  decode.d4.loss_mask: 0.5576  decode.d4.loss_dice: 0.8279  decode.d5.loss_cls: 2.1564  decode.d5.loss_mask: 0.5782  decode.d5.loss_dice: 0.8034  decode.d6.loss_cls: 2.1291  decode.d6.loss_mask: 0.5843  decode.d6.loss_dice: 0.8407  decode.d7.loss_cls: 2.1711  decode.d7.loss_mask: 0.5789  decode.d7.loss_dice: 0.8051  decode.d8.loss_cls: 2.2319  decode.d8.loss_mask: 0.5883  decode.d8.loss_dice: 0.7983
07/25 19:22:23 - mmengine - INFO - Iter(train) [  800/80000]  base_lr: 9.9101e-05 lr: 9.9101e-06  eta: 10:27:34  time: 0.4520  data_time: 0.0102  memory: 5231  grad_norm: 274.4051  loss: 35.3409  decode.loss_cls: 1.7641  decode.loss_mask: 0.7698  decode.loss_dice: 0.6039  decode.d0.loss_cls: 5.9536  decode.d0.loss_mask: 0.6508  decode.d0.loss_dice: 0.8096  decode.d1.loss_cls: 1.9063  decode.d1.loss_mask: 0.6670  decode.d1.loss_dice: 0.5981  decode.d2.loss_cls: 1.8198  decode.d2.loss_mask: 0.6717  decode.d2.loss_dice: 0.5784  decode.d3.loss_cls: 1.8234  decode.d3.loss_mask: 0.6676  decode.d3.loss_dice: 0.5624  decode.d4.loss_cls: 1.8267  decode.d4.loss_mask: 0.6997  decode.d4.loss_dice: 0.6036  decode.d5.loss_cls: 1.8106  decode.d5.loss_mask: 0.7010  decode.d5.loss_dice: 0.5777  decode.d6.loss_cls: 1.7605  decode.d6.loss_mask: 0.6852  decode.d6.loss_dice: 0.5918  decode.d7.loss_cls: 1.8259  decode.d7.loss_mask: 0.7033  decode.d7.loss_dice: 0.5908  decode.d8.loss_cls: 1.8057  decode.d8.loss_mask: 0.7168  decode.d8.loss_dice: 0.5951
07/25 19:22:46 - mmengine - INFO - Iter(train) [  850/80000]  base_lr: 9.9044e-05 lr: 9.9044e-06  eta: 10:25:32  time: 0.4550  data_time: 0.0101  memory: 5249  grad_norm: 204.4741  loss: 38.9778  decode.loss_cls: 2.2518  decode.loss_mask: 0.6429  decode.loss_dice: 0.6425  decode.d0.loss_cls: 5.8968  decode.d0.loss_mask: 0.5570  decode.d0.loss_dice: 0.9114  decode.d1.loss_cls: 2.4945  decode.d1.loss_mask: 0.5058  decode.d1.loss_dice: 0.5814  decode.d2.loss_cls: 2.4067  decode.d2.loss_mask: 0.5090  decode.d2.loss_dice: 0.5611  decode.d3.loss_cls: 2.3438  decode.d3.loss_mask: 0.5137  decode.d3.loss_dice: 0.5657  decode.d4.loss_cls: 2.3484  decode.d4.loss_mask: 0.5820  decode.d4.loss_dice: 0.5939  decode.d5.loss_cls: 2.3444  decode.d5.loss_mask: 0.5939  decode.d5.loss_dice: 0.6045  decode.d6.loss_cls: 2.3158  decode.d6.loss_mask: 0.5758  decode.d6.loss_dice: 0.5898  decode.d7.loss_cls: 2.3783  decode.d7.loss_mask: 0.5977  decode.d7.loss_dice: 0.5966  decode.d8.loss_cls: 2.3102  decode.d8.loss_mask: 0.5814  decode.d8.loss_dice: 0.5810
07/25 19:23:09 - mmengine - INFO - Iter(train) [  900/80000]  base_lr: 9.8988e-05 lr: 9.8988e-06  eta: 10:23:47  time: 0.4544  data_time: 0.0102  memory: 5249  grad_norm: 460.2592  loss: 38.6751  decode.loss_cls: 1.9828  decode.loss_mask: 0.8056  decode.loss_dice: 0.7479  decode.d0.loss_cls: 5.6676  decode.d0.loss_mask: 0.7730  decode.d0.loss_dice: 0.9314  decode.d1.loss_cls: 2.0960  decode.d1.loss_mask: 0.6801  decode.d1.loss_dice: 0.7202  decode.d2.loss_cls: 1.8686  decode.d2.loss_mask: 0.6833  decode.d2.loss_dice: 0.7073  decode.d3.loss_cls: 1.9134  decode.d3.loss_mask: 0.6883  decode.d3.loss_dice: 0.7255  decode.d4.loss_cls: 2.0628  decode.d4.loss_mask: 0.7316  decode.d4.loss_dice: 0.7346  decode.d5.loss_cls: 2.0384  decode.d5.loss_mask: 0.7073  decode.d5.loss_dice: 0.7050  decode.d6.loss_cls: 2.0802  decode.d6.loss_mask: 0.7270  decode.d6.loss_dice: 0.7663  decode.d7.loss_cls: 2.0822  decode.d7.loss_mask: 0.7628  decode.d7.loss_dice: 0.7949  decode.d8.loss_cls: 2.0360  decode.d8.loss_mask: 0.7117  decode.d8.loss_dice: 0.7431
07/25 19:23:31 - mmengine - INFO - Iter(train) [  950/80000]  base_lr: 9.8932e-05 lr: 9.8932e-06  eta: 10:21:52  time: 0.4562  data_time: 0.0100  memory: 5248  grad_norm: 200.6241  loss: 31.1275  decode.loss_cls: 1.6768  decode.loss_mask: 0.4974  decode.loss_dice: 0.5082  decode.d0.loss_cls: 5.4981  decode.d0.loss_mask: 0.5611  decode.d0.loss_dice: 0.7549  decode.d1.loss_cls: 1.7716  decode.d1.loss_mask: 0.4770  decode.d1.loss_dice: 0.5173  decode.d2.loss_cls: 1.6133  decode.d2.loss_mask: 0.5023  decode.d2.loss_dice: 0.5159  decode.d3.loss_cls: 1.6377  decode.d3.loss_mask: 0.5099  decode.d3.loss_dice: 0.5386  decode.d4.loss_cls: 1.6854  decode.d4.loss_mask: 0.5107  decode.d4.loss_dice: 0.5399  decode.d5.loss_cls: 1.6985  decode.d5.loss_mask: 0.4902  decode.d5.loss_dice: 0.5076  decode.d6.loss_cls: 1.6511  decode.d6.loss_mask: 0.5213  decode.d6.loss_dice: 0.5369  decode.d7.loss_cls: 1.7290  decode.d7.loss_mask: 0.4892  decode.d7.loss_dice: 0.5002  decode.d8.loss_cls: 1.6710  decode.d8.loss_mask: 0.4760  decode.d8.loss_dice: 0.5405
07/25 19:23:54 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250725_191538
07/25 19:23:54 - mmengine - INFO - Iter(train) [ 1000/80000]  base_lr: 9.8875e-05 lr: 9.8875e-06  eta: 10:20:21  time: 0.4463  data_time: 0.0096  memory: 5266  grad_norm: 322.7416  loss: 40.2635  decode.loss_cls: 2.2547  decode.loss_mask: 0.6874  decode.loss_dice: 0.7410  decode.d0.loss_cls: 5.4700  decode.d0.loss_mask: 0.7856  decode.d0.loss_dice: 1.0768  decode.d1.loss_cls: 2.2923  decode.d1.loss_mask: 0.6963  decode.d1.loss_dice: 0.7249  decode.d2.loss_cls: 2.2102  decode.d2.loss_mask: 0.7153  decode.d2.loss_dice: 0.7001  decode.d3.loss_cls: 2.2154  decode.d3.loss_mask: 0.6837  decode.d3.loss_dice: 0.6774  decode.d4.loss_cls: 2.1568  decode.d4.loss_mask: 0.6832  decode.d4.loss_dice: 0.7532  decode.d5.loss_cls: 2.2867  decode.d5.loss_mask: 0.6427  decode.d5.loss_dice: 0.6901  decode.d6.loss_cls: 2.2582  decode.d6.loss_mask: 0.7317  decode.d6.loss_dice: 0.7121  decode.d7.loss_cls: 2.2962  decode.d7.loss_mask: 0.7144  decode.d7.loss_dice: 0.7067  decode.d8.loss_cls: 2.2548  decode.d8.loss_mask: 0.6975  decode.d8.loss_dice: 0.7480
07/25 19:24:17 - mmengine - INFO - Iter(train) [ 1050/80000]  base_lr: 9.8819e-05 lr: 9.8819e-06  eta: 10:18:41  time: 0.4589  data_time: 0.0107  memory: 5265  grad_norm: 313.6147  loss: 36.3158  decode.loss_cls: 1.9165  decode.loss_mask: 0.6778  decode.loss_dice: 0.7379  decode.d0.loss_cls: 5.2323  decode.d0.loss_mask: 0.7493  decode.d0.loss_dice: 0.9136  decode.d1.loss_cls: 2.0714  decode.d1.loss_mask: 0.6951  decode.d1.loss_dice: 0.7738  decode.d2.loss_cls: 1.9233  decode.d2.loss_mask: 0.6331  decode.d2.loss_dice: 0.6764  decode.d3.loss_cls: 1.8845  decode.d3.loss_mask: 0.6250  decode.d3.loss_dice: 0.6950  decode.d4.loss_cls: 1.8535  decode.d4.loss_mask: 0.6816  decode.d4.loss_dice: 0.7025  decode.d5.loss_cls: 1.8323  decode.d5.loss_mask: 0.6943  decode.d5.loss_dice: 0.6796  decode.d6.loss_cls: 1.8585  decode.d6.loss_mask: 0.6456  decode.d6.loss_dice: 0.7252  decode.d7.loss_cls: 1.8874  decode.d7.loss_mask: 0.6455  decode.d7.loss_dice: 0.7006  decode.d8.loss_cls: 1.8676  decode.d8.loss_mask: 0.6147  decode.d8.loss_dice: 0.7220
07/25 19:24:40 - mmengine - INFO - Iter(train) [ 1100/80000]  base_lr: 9.8763e-05 lr: 9.8763e-06  eta: 10:17:32  time: 0.4551  data_time: 0.0103  memory: 5249  grad_norm: 186.8740  loss: 33.7724  decode.loss_cls: 1.9198  decode.loss_mask: 0.4981  decode.loss_dice: 0.6203  decode.d0.loss_cls: 5.0859  decode.d0.loss_mask: 0.5293  decode.d0.loss_dice: 0.7708  decode.d1.loss_cls: 2.0143  decode.d1.loss_mask: 0.4697  decode.d1.loss_dice: 0.5852  decode.d2.loss_cls: 1.8540  decode.d2.loss_mask: 0.4835  decode.d2.loss_dice: 0.5847  decode.d3.loss_cls: 1.9254  decode.d3.loss_mask: 0.5006  decode.d3.loss_dice: 0.5797  decode.d4.loss_cls: 1.8676  decode.d4.loss_mask: 0.5155  decode.d4.loss_dice: 0.6209  decode.d5.loss_cls: 1.9290  decode.d5.loss_mask: 0.5506  decode.d5.loss_dice: 0.6435  decode.d6.loss_cls: 1.8828  decode.d6.loss_mask: 0.5672  decode.d6.loss_dice: 0.6268  decode.d7.loss_cls: 1.9214  decode.d7.loss_mask: 0.5157  decode.d7.loss_dice: 0.6291  decode.d8.loss_cls: 1.8996  decode.d8.loss_mask: 0.5360  decode.d8.loss_dice: 0.6454
07/25 19:25:03 - mmengine - INFO - Iter(train) [ 1150/80000]  base_lr: 9.8706e-05 lr: 9.8706e-06  eta: 10:16:29  time: 0.4607  data_time: 0.0104  memory: 5266  grad_norm: 174.5467  loss: 32.2577  decode.loss_cls: 1.9363  decode.loss_mask: 0.4445  decode.loss_dice: 0.5064  decode.d0.loss_cls: 4.9159  decode.d0.loss_mask: 0.5362  decode.d0.loss_dice: 0.6813  decode.d1.loss_cls: 2.1882  decode.d1.loss_mask: 0.4450  decode.d1.loss_dice: 0.4898  decode.d2.loss_cls: 1.9636  decode.d2.loss_mask: 0.4359  decode.d2.loss_dice: 0.4575  decode.d3.loss_cls: 1.9593  decode.d3.loss_mask: 0.4144  decode.d3.loss_dice: 0.4355  decode.d4.loss_cls: 1.9597  decode.d4.loss_mask: 0.4207  decode.d4.loss_dice: 0.4593  decode.d5.loss_cls: 1.9951  decode.d5.loss_mask: 0.4421  decode.d5.loss_dice: 0.4580  decode.d6.loss_cls: 1.9449  decode.d6.loss_mask: 0.4497  decode.d6.loss_dice: 0.4783  decode.d7.loss_cls: 1.9940  decode.d7.loss_mask: 0.4395  decode.d7.loss_dice: 0.5004  decode.d8.loss_cls: 2.0072  decode.d8.loss_mask: 0.4621  decode.d8.loss_dice: 0.4370
07/25 19:25:25 - mmengine - INFO - Iter(train) [ 1200/80000]  base_lr: 9.8650e-05 lr: 9.8650e-06  eta: 10:15:26  time: 0.4584  data_time: 0.0100  memory: 5296  grad_norm: 222.8679  loss: 33.9731  decode.loss_cls: 2.0813  decode.loss_mask: 0.4981  decode.loss_dice: 0.5602  decode.d0.loss_cls: 4.8200  decode.d0.loss_mask: 0.4286  decode.d0.loss_dice: 0.7132  decode.d1.loss_cls: 2.1813  decode.d1.loss_mask: 0.3737  decode.d1.loss_dice: 0.5426  decode.d2.loss_cls: 2.1188  decode.d2.loss_mask: 0.4117  decode.d2.loss_dice: 0.5667  decode.d3.loss_cls: 2.1964  decode.d3.loss_mask: 0.4063  decode.d3.loss_dice: 0.5018  decode.d4.loss_cls: 2.1283  decode.d4.loss_mask: 0.4136  decode.d4.loss_dice: 0.5453  decode.d5.loss_cls: 2.1135  decode.d5.loss_mask: 0.4276  decode.d5.loss_dice: 0.5626  decode.d6.loss_cls: 2.0844  decode.d6.loss_mask: 0.4990  decode.d6.loss_dice: 0.5783  decode.d7.loss_cls: 2.1220  decode.d7.loss_mask: 0.4308  decode.d7.loss_dice: 0.5336  decode.d8.loss_cls: 2.0788  decode.d8.loss_mask: 0.5058  decode.d8.loss_dice: 0.5489
07/25 19:25:48 - mmengine - INFO - Iter(train) [ 1250/80000]  base_lr: 9.8594e-05 lr: 9.8594e-06  eta: 10:14:24  time: 0.4607  data_time: 0.0103  memory: 5231  grad_norm: 184.8894  loss: 31.9939  decode.loss_cls: 1.8354  decode.loss_mask: 0.4141  decode.loss_dice: 0.5030  decode.d0.loss_cls: 4.6805  decode.d0.loss_mask: 0.4496  decode.d0.loss_dice: 0.6510  decode.d1.loss_cls: 2.1794  decode.d1.loss_mask: 0.4402  decode.d1.loss_dice: 0.5306  decode.d2.loss_cls: 1.9914  decode.d2.loss_mask: 0.4417  decode.d2.loss_dice: 0.4621  decode.d3.loss_cls: 2.0566  decode.d3.loss_mask: 0.4321  decode.d3.loss_dice: 0.4645  decode.d4.loss_cls: 1.9824  decode.d4.loss_mask: 0.4780  decode.d4.loss_dice: 0.4686  decode.d5.loss_cls: 2.0625  decode.d5.loss_mask: 0.4430  decode.d5.loss_dice: 0.4805  decode.d6.loss_cls: 1.9028  decode.d6.loss_mask: 0.4280  decode.d6.loss_dice: 0.4832  decode.d7.loss_cls: 2.0122  decode.d7.loss_mask: 0.4228  decode.d7.loss_dice: 0.4731  decode.d8.loss_cls: 1.9124  decode.d8.loss_mask: 0.4179  decode.d8.loss_dice: 0.4944
07/25 19:26:11 - mmengine - INFO - Iter(train) [ 1300/80000]  base_lr: 9.8537e-05 lr: 9.8537e-06  eta: 10:13:09  time: 0.4355  data_time: 0.0085  memory: 5249  grad_norm: 191.1890  loss: 29.7760  decode.loss_cls: 1.8006  decode.loss_mask: 0.3640  decode.loss_dice: 0.5027  decode.d0.loss_cls: 4.4143  decode.d0.loss_mask: 0.4008  decode.d0.loss_dice: 0.6963  decode.d1.loss_cls: 2.0540  decode.d1.loss_mask: 0.3122  decode.d1.loss_dice: 0.4260  decode.d2.loss_cls: 1.9369  decode.d2.loss_mask: 0.3470  decode.d2.loss_dice: 0.4383  decode.d3.loss_cls: 1.9168  decode.d3.loss_mask: 0.3309  decode.d3.loss_dice: 0.4393  decode.d4.loss_cls: 2.0355  decode.d4.loss_mask: 0.3373  decode.d4.loss_dice: 0.4642  decode.d5.loss_cls: 1.8660  decode.d5.loss_mask: 0.3369  decode.d5.loss_dice: 0.4263  decode.d6.loss_cls: 1.7445  decode.d6.loss_mask: 0.3793  decode.d6.loss_dice: 0.4752  decode.d7.loss_cls: 1.8201  decode.d7.loss_mask: 0.3916  decode.d7.loss_dice: 0.4941  decode.d8.loss_cls: 1.8512  decode.d8.loss_mask: 0.3319  decode.d8.loss_dice: 0.4418
07/25 19:26:33 - mmengine - INFO - Iter(train) [ 1350/80000]  base_lr: 9.8481e-05 lr: 9.8481e-06  eta: 10:12:10  time: 0.4518  data_time: 0.0103  memory: 5229  grad_norm: 197.7708  loss: 27.6999  decode.loss_cls: 1.5182  decode.loss_mask: 0.5339  decode.loss_dice: 0.3998  decode.d0.loss_cls: 4.2326  decode.d0.loss_mask: 0.5553  decode.d0.loss_dice: 0.6216  decode.d1.loss_cls: 1.7216  decode.d1.loss_mask: 0.5266  decode.d1.loss_dice: 0.4439  decode.d2.loss_cls: 1.5834  decode.d2.loss_mask: 0.5170  decode.d2.loss_dice: 0.4519  decode.d3.loss_cls: 1.5635  decode.d3.loss_mask: 0.4939  decode.d3.loss_dice: 0.4024  decode.d4.loss_cls: 1.5440  decode.d4.loss_mask: 0.5281  decode.d4.loss_dice: 0.4181  decode.d5.loss_cls: 1.5284  decode.d5.loss_mask: 0.4867  decode.d5.loss_dice: 0.4123  decode.d6.loss_cls: 1.4970  decode.d6.loss_mask: 0.5229  decode.d6.loss_dice: 0.4147  decode.d7.loss_cls: 1.5088  decode.d7.loss_mask: 0.5163  decode.d7.loss_dice: 0.3909  decode.d8.loss_cls: 1.4854  decode.d8.loss_mask: 0.4928  decode.d8.loss_dice: 0.3879
07/25 19:26:56 - mmengine - INFO - Iter(train) [ 1400/80000]  base_lr: 9.8425e-05 lr: 9.8425e-06  eta: 10:11:01  time: 0.4549  data_time: 0.0098  memory: 5231  grad_norm: 224.8977  loss: 32.3877  decode.loss_cls: 2.0420  decode.loss_mask: 0.4307  decode.loss_dice: 0.5719  decode.d0.loss_cls: 4.2075  decode.d0.loss_mask: 0.4661  decode.d0.loss_dice: 0.7916  decode.d1.loss_cls: 2.1302  decode.d1.loss_mask: 0.3897  decode.d1.loss_dice: 0.5369  decode.d2.loss_cls: 1.9500  decode.d2.loss_mask: 0.3909  decode.d2.loss_dice: 0.5193  decode.d3.loss_cls: 2.0005  decode.d3.loss_mask: 0.3759  decode.d3.loss_dice: 0.5124  decode.d4.loss_cls: 2.1140  decode.d4.loss_mask: 0.3874  decode.d4.loss_dice: 0.5050  decode.d5.loss_cls: 2.0638  decode.d5.loss_mask: 0.3886  decode.d5.loss_dice: 0.5075  decode.d6.loss_cls: 2.0811  decode.d6.loss_mask: 0.4051  decode.d6.loss_dice: 0.5428  decode.d7.loss_cls: 2.1452  decode.d7.loss_mask: 0.3951  decode.d7.loss_dice: 0.5482  decode.d8.loss_cls: 2.1209  decode.d8.loss_mask: 0.3704  decode.d8.loss_dice: 0.4966
07/25 19:27:19 - mmengine - INFO - Iter(train) [ 1450/80000]  base_lr: 9.8368e-05 lr: 9.8368e-06  eta: 10:10:09  time: 0.4551  data_time: 0.0102  memory: 5231  grad_norm: 144.7683  loss: 25.7123  decode.loss_cls: 1.3896  decode.loss_mask: 0.3804  decode.loss_dice: 0.4579  decode.d0.loss_cls: 3.9397  decode.d0.loss_mask: 0.3869  decode.d0.loss_dice: 0.6129  decode.d1.loss_cls: 1.7234  decode.d1.loss_mask: 0.3523  decode.d1.loss_dice: 0.4294  decode.d2.loss_cls: 1.5785  decode.d2.loss_mask: 0.3475  decode.d2.loss_dice: 0.3916  decode.d3.loss_cls: 1.6200  decode.d3.loss_mask: 0.3410  decode.d3.loss_dice: 0.3764  decode.d4.loss_cls: 1.5607  decode.d4.loss_mask: 0.3367  decode.d4.loss_dice: 0.3933  decode.d5.loss_cls: 1.5268  decode.d5.loss_mask: 0.3338  decode.d5.loss_dice: 0.4069  decode.d6.loss_cls: 1.5104  decode.d6.loss_mask: 0.3281  decode.d6.loss_dice: 0.3888  decode.d7.loss_cls: 1.5896  decode.d7.loss_mask: 0.3239  decode.d7.loss_dice: 0.3799  decode.d8.loss_cls: 1.5493  decode.d8.loss_mask: 0.3377  decode.d8.loss_dice: 0.4187
07/25 19:27:42 - mmengine - INFO - Iter(train) [ 1500/80000]  base_lr: 9.8312e-05 lr: 9.8312e-06  eta: 10:09:19  time: 0.4582  data_time: 0.0099  memory: 5231  grad_norm: 161.6990  loss: 29.8936  decode.loss_cls: 1.8677  decode.loss_mask: 0.3674  decode.loss_dice: 0.5188  decode.d0.loss_cls: 4.0367  decode.d0.loss_mask: 0.4056  decode.d0.loss_dice: 0.7123  decode.d1.loss_cls: 2.0635  decode.d1.loss_mask: 0.3538  decode.d1.loss_dice: 0.4470  decode.d2.loss_cls: 1.8741  decode.d2.loss_mask: 0.3470  decode.d2.loss_dice: 0.4558  decode.d3.loss_cls: 1.9765  decode.d3.loss_mask: 0.3481  decode.d3.loss_dice: 0.4684  decode.d4.loss_cls: 1.9636  decode.d4.loss_mask: 0.3565  decode.d4.loss_dice: 0.4621  decode.d5.loss_cls: 1.9325  decode.d5.loss_mask: 0.3310  decode.d5.loss_dice: 0.4653  decode.d6.loss_cls: 1.9076  decode.d6.loss_mask: 0.3400  decode.d6.loss_dice: 0.4619  decode.d7.loss_cls: 1.9165  decode.d7.loss_mask: 0.3591  decode.d7.loss_dice: 0.4864  decode.d8.loss_cls: 1.8683  decode.d8.loss_mask: 0.3356  decode.d8.loss_dice: 0.4646
07/25 19:28:04 - mmengine - INFO - Iter(train) [ 1550/80000]  base_lr: 9.8256e-05 lr: 9.8256e-06  eta: 10:08:33  time: 0.4577  data_time: 0.0103  memory: 5249  grad_norm: 154.9704  loss: 29.9585  decode.loss_cls: 1.9193  decode.loss_mask: 0.3973  decode.loss_dice: 0.4969  decode.d0.loss_cls: 3.8605  decode.d0.loss_mask: 0.3892  decode.d0.loss_dice: 0.6927  decode.d1.loss_cls: 1.9572  decode.d1.loss_mask: 0.4318  decode.d1.loss_dice: 0.5082  decode.d2.loss_cls: 1.8479  decode.d2.loss_mask: 0.3778  decode.d2.loss_dice: 0.4852  decode.d3.loss_cls: 1.9019  decode.d3.loss_mask: 0.3590  decode.d3.loss_dice: 0.4737  decode.d4.loss_cls: 1.9548  decode.d4.loss_mask: 0.3795  decode.d4.loss_dice: 0.4747  decode.d5.loss_cls: 1.8973  decode.d5.loss_mask: 0.3638  decode.d5.loss_dice: 0.4728  decode.d6.loss_cls: 1.8312  decode.d6.loss_mask: 0.3621  decode.d6.loss_dice: 0.4734  decode.d7.loss_cls: 1.9526  decode.d7.loss_mask: 0.3748  decode.d7.loss_dice: 0.4582  decode.d8.loss_cls: 1.9689  decode.d8.loss_mask: 0.3981  decode.d8.loss_dice: 0.4977
07/25 19:28:27 - mmengine - INFO - Iter(train) [ 1600/80000]  base_lr: 9.8199e-05 lr: 9.8199e-06  eta: 10:07:43  time: 0.4524  data_time: 0.0103  memory: 5197  grad_norm: 169.6871  loss: 28.8244  decode.loss_cls: 1.6125  decode.loss_mask: 0.4825  decode.loss_dice: 0.5027  decode.d0.loss_cls: 3.5550  decode.d0.loss_mask: 0.4906  decode.d0.loss_dice: 0.6586  decode.d1.loss_cls: 1.8080  decode.d1.loss_mask: 0.4889  decode.d1.loss_dice: 0.5141  decode.d2.loss_cls: 1.6713  decode.d2.loss_mask: 0.4479  decode.d2.loss_dice: 0.5017  decode.d3.loss_cls: 1.6344  decode.d3.loss_mask: 0.4595  decode.d3.loss_dice: 0.4890  decode.d4.loss_cls: 1.6785  decode.d4.loss_mask: 0.4475  decode.d4.loss_dice: 0.4860  decode.d5.loss_cls: 1.7361  decode.d5.loss_mask: 0.4381  decode.d5.loss_dice: 0.5092  decode.d6.loss_cls: 1.7137  decode.d6.loss_mask: 0.4747  decode.d6.loss_dice: 0.5423  decode.d7.loss_cls: 1.8297  decode.d7.loss_mask: 0.4299  decode.d7.loss_dice: 0.5046  decode.d8.loss_cls: 1.7545  decode.d8.loss_mask: 0.4366  decode.d8.loss_dice: 0.5265
07/25 19:28:50 - mmengine - INFO - Iter(train) [ 1650/80000]  base_lr: 9.8143e-05 lr: 9.8143e-06  eta: 10:07:00  time: 0.4565  data_time: 0.0102  memory: 5231  grad_norm: 143.5672  loss: 25.8509  decode.loss_cls: 1.5978  decode.loss_mask: 0.3592  decode.loss_dice: 0.4448  decode.d0.loss_cls: 3.5840  decode.d0.loss_mask: 0.4111  decode.d0.loss_dice: 0.5827  decode.d1.loss_cls: 1.7275  decode.d1.loss_mask: 0.3540  decode.d1.loss_dice: 0.4106  decode.d2.loss_cls: 1.5726  decode.d2.loss_mask: 0.3408  decode.d2.loss_dice: 0.3753  decode.d3.loss_cls: 1.5467  decode.d3.loss_mask: 0.3807  decode.d3.loss_dice: 0.4117  decode.d4.loss_cls: 1.5926  decode.d4.loss_mask: 0.3509  decode.d4.loss_dice: 0.4181  decode.d5.loss_cls: 1.5300  decode.d5.loss_mask: 0.3583  decode.d5.loss_dice: 0.4180  decode.d6.loss_cls: 1.5064  decode.d6.loss_mask: 0.3459  decode.d6.loss_dice: 0.4103  decode.d7.loss_cls: 1.6734  decode.d7.loss_mask: 0.3444  decode.d7.loss_dice: 0.4002  decode.d8.loss_cls: 1.6302  decode.d8.loss_mask: 0.3464  decode.d8.loss_dice: 0.4265
07/25 19:29:13 - mmengine - INFO - Iter(train) [ 1700/80000]  base_lr: 9.8087e-05 lr: 9.8087e-06  eta: 10:06:09  time: 0.4568  data_time: 0.0104  memory: 5249  grad_norm: 164.3699  loss: 28.1661  decode.loss_cls: 1.7076  decode.loss_mask: 0.4117  decode.loss_dice: 0.4742  decode.d0.loss_cls: 3.4580  decode.d0.loss_mask: 0.4827  decode.d0.loss_dice: 0.5870  decode.d1.loss_cls: 1.8510  decode.d1.loss_mask: 0.4314  decode.d1.loss_dice: 0.4537  decode.d2.loss_cls: 1.6882  decode.d2.loss_mask: 0.4262  decode.d2.loss_dice: 0.4384  decode.d3.loss_cls: 1.7289  decode.d3.loss_mask: 0.4202  decode.d3.loss_dice: 0.4483  decode.d4.loss_cls: 1.7331  decode.d4.loss_mask: 0.4231  decode.d4.loss_dice: 0.4669  decode.d5.loss_cls: 1.6950  decode.d5.loss_mask: 0.4066  decode.d5.loss_dice: 0.4630  decode.d6.loss_cls: 1.7332  decode.d6.loss_mask: 0.4405  decode.d6.loss_dice: 0.4822  decode.d7.loss_cls: 1.7683  decode.d7.loss_mask: 0.4139  decode.d7.loss_dice: 0.4731  decode.d8.loss_cls: 1.7699  decode.d8.loss_mask: 0.4118  decode.d8.loss_dice: 0.4777
07/25 19:29:35 - mmengine - INFO - Iter(train) [ 1750/80000]  base_lr: 9.8030e-05 lr: 9.8030e-06  eta: 10:05:20  time: 0.4445  data_time: 0.0093  memory: 5249  grad_norm: 176.2786  loss: 29.5699  decode.loss_cls: 1.8494  decode.loss_mask: 0.3951  decode.loss_dice: 0.4865  decode.d0.loss_cls: 3.3193  decode.d0.loss_mask: 0.5215  decode.d0.loss_dice: 0.6714  decode.d1.loss_cls: 2.0232  decode.d1.loss_mask: 0.4106  decode.d1.loss_dice: 0.5045  decode.d2.loss_cls: 1.8641  decode.d2.loss_mask: 0.4320  decode.d2.loss_dice: 0.5396  decode.d3.loss_cls: 1.9238  decode.d3.loss_mask: 0.4106  decode.d3.loss_dice: 0.4813  decode.d4.loss_cls: 1.9096  decode.d4.loss_mask: 0.4211  decode.d4.loss_dice: 0.5027  decode.d5.loss_cls: 1.9206  decode.d5.loss_mask: 0.4033  decode.d5.loss_dice: 0.4780  decode.d6.loss_cls: 1.8443  decode.d6.loss_mask: 0.4149  decode.d6.loss_dice: 0.4772  decode.d7.loss_cls: 1.7789  decode.d7.loss_mask: 0.4005  decode.d7.loss_dice: 0.4857  decode.d8.loss_cls: 1.8305  decode.d8.loss_mask: 0.3944  decode.d8.loss_dice: 0.4755
07/25 19:29:58 - mmengine - INFO - Iter(train) [ 1800/80000]  base_lr: 9.7974e-05 lr: 9.7974e-06  eta: 10:04:45  time: 0.4599  data_time: 0.0106  memory: 5228  grad_norm: 111.6690  loss: 24.3778  decode.loss_cls: 1.5116  decode.loss_mask: 0.3481  decode.loss_dice: 0.3477  decode.d0.loss_cls: 3.1411  decode.d0.loss_mask: 0.3786  decode.d0.loss_dice: 0.5673  decode.d1.loss_cls: 1.6035  decode.d1.loss_mask: 0.3345  decode.d1.loss_dice: 0.3616  decode.d2.loss_cls: 1.5095  decode.d2.loss_mask: 0.3342  decode.d2.loss_dice: 0.3594  decode.d3.loss_cls: 1.5597  decode.d3.loss_mask: 0.3343  decode.d3.loss_dice: 0.3373  decode.d4.loss_cls: 1.5878  decode.d4.loss_mask: 0.3462  decode.d4.loss_dice: 0.3479  decode.d5.loss_cls: 1.5108  decode.d5.loss_mask: 0.3452  decode.d5.loss_dice: 0.3596  decode.d6.loss_cls: 1.5502  decode.d6.loss_mask: 0.3430  decode.d6.loss_dice: 0.3459  decode.d7.loss_cls: 1.6291  decode.d7.loss_mask: 0.3463  decode.d7.loss_dice: 0.3656  decode.d8.loss_cls: 1.5681  decode.d8.loss_mask: 0.3516  decode.d8.loss_dice: 0.3520
07/25 19:30:21 - mmengine - INFO - Iter(train) [ 1850/80000]  base_lr: 9.7917e-05 lr: 9.7917e-06  eta: 10:04:05  time: 0.4568  data_time: 0.0102  memory: 5214  grad_norm: 184.4611  loss: 30.7042  decode.loss_cls: 1.8463  decode.loss_mask: 0.5140  decode.loss_dice: 0.5158  decode.d0.loss_cls: 3.3292  decode.d0.loss_mask: 0.5796  decode.d0.loss_dice: 0.6500  decode.d1.loss_cls: 1.9718  decode.d1.loss_mask: 0.5275  decode.d1.loss_dice: 0.4730  decode.d2.loss_cls: 1.8339  decode.d2.loss_mask: 0.5645  decode.d2.loss_dice: 0.4848  decode.d3.loss_cls: 1.8609  decode.d3.loss_mask: 0.5809  decode.d3.loss_dice: 0.4642  decode.d4.loss_cls: 1.9269  decode.d4.loss_mask: 0.4853  decode.d4.loss_dice: 0.4696  decode.d5.loss_cls: 1.9563  decode.d5.loss_mask: 0.4971  decode.d5.loss_dice: 0.4562  decode.d6.loss_cls: 1.9026  decode.d6.loss_mask: 0.4795  decode.d6.loss_dice: 0.4753  decode.d7.loss_cls: 1.9623  decode.d7.loss_mask: 0.5605  decode.d7.loss_dice: 0.4645  decode.d8.loss_cls: 1.8262  decode.d8.loss_mask: 0.5585  decode.d8.loss_dice: 0.4870
07/25 19:30:44 - mmengine - INFO - Iter(train) [ 1900/80000]  base_lr: 9.7861e-05 lr: 9.7861e-06  eta: 10:03:31  time: 0.4555  data_time: 0.0099  memory: 5248  grad_norm: 142.2499  loss: 21.9290  decode.loss_cls: 1.2084  decode.loss_mask: 0.3854  decode.loss_dice: 0.4339  decode.d0.loss_cls: 2.7453  decode.d0.loss_mask: 0.4560  decode.d0.loss_dice: 0.5275  decode.d1.loss_cls: 1.2613  decode.d1.loss_mask: 0.3986  decode.d1.loss_dice: 0.3956  decode.d2.loss_cls: 1.1823  decode.d2.loss_mask: 0.3911  decode.d2.loss_dice: 0.4056  decode.d3.loss_cls: 1.1994  decode.d3.loss_mask: 0.3773  decode.d3.loss_dice: 0.4139  decode.d4.loss_cls: 1.1774  decode.d4.loss_mask: 0.4024  decode.d4.loss_dice: 0.4368  decode.d5.loss_cls: 1.2111  decode.d5.loss_mask: 0.3798  decode.d5.loss_dice: 0.4241  decode.d6.loss_cls: 1.1862  decode.d6.loss_mask: 0.3941  decode.d6.loss_dice: 0.4471  decode.d7.loss_cls: 1.1981  decode.d7.loss_mask: 0.4087  decode.d7.loss_dice: 0.4362  decode.d8.loss_cls: 1.2594  decode.d8.loss_mask: 0.3762  decode.d8.loss_dice: 0.4099
07/25 19:31:07 - mmengine - INFO - Iter(train) [ 1950/80000]  base_lr: 9.7805e-05 lr: 9.7805e-06  eta: 10:02:53  time: 0.4577  data_time: 0.0101  memory: 5231  grad_norm: 141.3271  loss: 25.6172  decode.loss_cls: 1.6516  decode.loss_mask: 0.2852  decode.loss_dice: 0.3829  decode.d0.loss_cls: 2.9906  decode.d0.loss_mask: 0.3759  decode.d0.loss_dice: 0.5425  decode.d1.loss_cls: 1.9105  decode.d1.loss_mask: 0.3045  decode.d1.loss_dice: 0.3858  decode.d2.loss_cls: 1.7146  decode.d2.loss_mask: 0.2884  decode.d2.loss_dice: 0.3692  decode.d3.loss_cls: 1.7744  decode.d3.loss_mask: 0.2966  decode.d3.loss_dice: 0.3846  decode.d4.loss_cls: 1.7052  decode.d4.loss_mask: 0.2943  decode.d4.loss_dice: 0.3982  decode.d5.loss_cls: 1.7562  decode.d5.loss_mask: 0.2898  decode.d5.loss_dice: 0.3831  decode.d6.loss_cls: 1.6920  decode.d6.loss_mask: 0.2812  decode.d6.loss_dice: 0.3674  decode.d7.loss_cls: 1.6792  decode.d7.loss_mask: 0.3017  decode.d7.loss_dice: 0.3968  decode.d8.loss_cls: 1.7263  decode.d8.loss_mask: 0.2904  decode.d8.loss_dice: 0.3982
07/25 19:31:30 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250725_191538
07/25 19:31:30 - mmengine - INFO - Iter(train) [ 2000/80000]  base_lr: 9.7748e-05 lr: 9.7748e-06  eta: 10:02:15  time: 0.4550  data_time: 0.0104  memory: 5249  grad_norm: 207.5631  loss: 26.4523  decode.loss_cls: 1.4521  decode.loss_mask: 0.5353  decode.loss_dice: 0.4834  decode.d0.loss_cls: 2.7682  decode.d0.loss_mask: 0.6310  decode.d0.loss_dice: 0.6815  decode.d1.loss_cls: 1.5342  decode.d1.loss_mask: 0.5433  decode.d1.loss_dice: 0.4759  decode.d2.loss_cls: 1.4518  decode.d2.loss_mask: 0.5440  decode.d2.loss_dice: 0.4484  decode.d3.loss_cls: 1.4449  decode.d3.loss_mask: 0.5377  decode.d3.loss_dice: 0.4705  decode.d4.loss_cls: 1.4708  decode.d4.loss_mask: 0.5435  decode.d4.loss_dice: 0.4773  decode.d5.loss_cls: 1.4815  decode.d5.loss_mask: 0.5072  decode.d5.loss_dice: 0.4879  decode.d6.loss_cls: 1.4058  decode.d6.loss_mask: 0.4916  decode.d6.loss_dice: 0.4809  decode.d7.loss_cls: 1.5050  decode.d7.loss_mask: 0.5124  decode.d7.loss_dice: 0.4951  decode.d8.loss_cls: 1.5654  decode.d8.loss_mask: 0.5464  decode.d8.loss_dice: 0.4795
07/25 19:31:52 - mmengine - INFO - Iter(train) [ 2050/80000]  base_lr: 9.7692e-05 lr: 9.7692e-06  eta: 10:01:33  time: 0.4571  data_time: 0.0106  memory: 5230  grad_norm: 205.5669  loss: 28.1118  decode.loss_cls: 1.7531  decode.loss_mask: 0.4108  decode.loss_dice: 0.4144  decode.d0.loss_cls: 2.7854  decode.d0.loss_mask: 0.5428  decode.d0.loss_dice: 0.6044  decode.d1.loss_cls: 1.8538  decode.d1.loss_mask: 0.4181  decode.d1.loss_dice: 0.4402  decode.d2.loss_cls: 1.7152  decode.d2.loss_mask: 0.4187  decode.d2.loss_dice: 0.4294  decode.d3.loss_cls: 1.8220  decode.d3.loss_mask: 0.4345  decode.d3.loss_dice: 0.4540  decode.d4.loss_cls: 1.7643  decode.d4.loss_mask: 0.4548  decode.d4.loss_dice: 0.4494  decode.d5.loss_cls: 1.7446  decode.d5.loss_mask: 0.4474  decode.d5.loss_dice: 0.4575  decode.d6.loss_cls: 1.7927  decode.d6.loss_mask: 0.4662  decode.d6.loss_dice: 0.4562  decode.d7.loss_cls: 1.8963  decode.d7.loss_mask: 0.4868  decode.d7.loss_dice: 0.4868  decode.d8.loss_cls: 1.8381  decode.d8.loss_mask: 0.4186  decode.d8.loss_dice: 0.4551
07/25 19:32:15 - mmengine - INFO - Iter(train) [ 2100/80000]  base_lr: 9.7635e-05 lr: 9.7635e-06  eta: 10:01:01  time: 0.4607  data_time: 0.0106  memory: 5231  grad_norm: 407.9556  loss: 24.9561  decode.loss_cls: 1.3967  decode.loss_mask: 0.4631  decode.loss_dice: 0.3898  decode.d0.loss_cls: 2.6332  decode.d0.loss_mask: 0.5102  decode.d0.loss_dice: 0.4860  decode.d1.loss_cls: 1.4808  decode.d1.loss_mask: 0.5678  decode.d1.loss_dice: 0.4228  decode.d2.loss_cls: 1.3197  decode.d2.loss_mask: 0.6352  decode.d2.loss_dice: 0.3960  decode.d3.loss_cls: 1.3647  decode.d3.loss_mask: 0.5425  decode.d3.loss_dice: 0.3855  decode.d4.loss_cls: 1.4047  decode.d4.loss_mask: 0.5485  decode.d4.loss_dice: 0.4083  decode.d5.loss_cls: 1.4202  decode.d5.loss_mask: 0.5492  decode.d5.loss_dice: 0.4053  decode.d6.loss_cls: 1.4220  decode.d6.loss_mask: 0.6096  decode.d6.loss_dice: 0.3958  decode.d7.loss_cls: 1.4568  decode.d7.loss_mask: 0.6016  decode.d7.loss_dice: 0.4055  decode.d8.loss_cls: 1.3806  decode.d8.loss_mask: 0.5329  decode.d8.loss_dice: 0.4209
07/25 19:32:38 - mmengine - INFO - Iter(train) [ 2150/80000]  base_lr: 9.7579e-05 lr: 9.7579e-06  eta: 10:00:16  time: 0.4565  data_time: 0.0102  memory: 5249  grad_norm: 163.0110  loss: 22.1632  decode.loss_cls: 1.3419  decode.loss_mask: 0.3678  decode.loss_dice: 0.3431  decode.d0.loss_cls: 2.4182  decode.d0.loss_mask: 0.4575  decode.d0.loss_dice: 0.5122  decode.d1.loss_cls: 1.4084  decode.d1.loss_mask: 0.4009  decode.d1.loss_dice: 0.3610  decode.d2.loss_cls: 1.1592  decode.d2.loss_mask: 0.3987  decode.d2.loss_dice: 0.3537  decode.d3.loss_cls: 1.2090  decode.d3.loss_mask: 0.3904  decode.d3.loss_dice: 0.3701  decode.d4.loss_cls: 1.2816  decode.d4.loss_mask: 0.3911  decode.d4.loss_dice: 0.3897  decode.d5.loss_cls: 1.3029  decode.d5.loss_mask: 0.3867  decode.d5.loss_dice: 0.4261  decode.d6.loss_cls: 1.3666  decode.d6.loss_mask: 0.3863  decode.d6.loss_dice: 0.3813  decode.d7.loss_cls: 1.3903  decode.d7.loss_mask: 0.3884  decode.d7.loss_dice: 0.4028  decode.d8.loss_cls: 1.4185  decode.d8.loss_mask: 0.3845  decode.d8.loss_dice: 0.3743
07/25 19:33:01 - mmengine - INFO - Iter(train) [ 2200/80000]  base_lr: 9.7523e-05 lr: 9.7523e-06  eta: 9:59:42  time: 0.4538  data_time: 0.0097  memory: 5231  grad_norm: 191.4784  loss: 20.7851  decode.loss_cls: 1.2034  decode.loss_mask: 0.3769  decode.loss_dice: 0.4547  decode.d0.loss_cls: 2.3129  decode.d0.loss_mask: 0.3674  decode.d0.loss_dice: 0.5070  decode.d1.loss_cls: 1.2949  decode.d1.loss_mask: 0.3410  decode.d1.loss_dice: 0.3794  decode.d2.loss_cls: 1.1654  decode.d2.loss_mask: 0.3352  decode.d2.loss_dice: 0.4044  decode.d3.loss_cls: 1.1775  decode.d3.loss_mask: 0.3298  decode.d3.loss_dice: 0.3943  decode.d4.loss_cls: 1.1889  decode.d4.loss_mask: 0.3380  decode.d4.loss_dice: 0.4072  decode.d5.loss_cls: 1.2128  decode.d5.loss_mask: 0.3173  decode.d5.loss_dice: 0.3867  decode.d6.loss_cls: 1.2248  decode.d6.loss_mask: 0.3309  decode.d6.loss_dice: 0.3765  decode.d7.loss_cls: 1.2204  decode.d7.loss_mask: 0.3402  decode.d7.loss_dice: 0.3948  decode.d8.loss_cls: 1.2192  decode.d8.loss_mask: 0.3607  decode.d8.loss_dice: 0.4221
07/25 19:33:23 - mmengine - INFO - Iter(train) [ 2250/80000]  base_lr: 9.7466e-05 lr: 9.7466e-06  eta: 9:59:05  time: 0.4577  data_time: 0.0104  memory: 5265  grad_norm: 122.9817  loss: 23.1966  decode.loss_cls: 1.5805  decode.loss_mask: 0.2695  decode.loss_dice: 0.3631  decode.d0.loss_cls: 2.4057  decode.d0.loss_mask: 0.3240  decode.d0.loss_dice: 0.4791  decode.d1.loss_cls: 1.5821  decode.d1.loss_mask: 0.2774  decode.d1.loss_dice: 0.3675  decode.d2.loss_cls: 1.4597  decode.d2.loss_mask: 0.2685  decode.d2.loss_dice: 0.3449  decode.d3.loss_cls: 1.5643  decode.d3.loss_mask: 0.2807  decode.d3.loss_dice: 0.3534  decode.d4.loss_cls: 1.6387  decode.d4.loss_mask: 0.2647  decode.d4.loss_dice: 0.3625  decode.d5.loss_cls: 1.5652  decode.d5.loss_mask: 0.2755  decode.d5.loss_dice: 0.3669  decode.d6.loss_cls: 1.6104  decode.d6.loss_mask: 0.2717  decode.d6.loss_dice: 0.3595  decode.d7.loss_cls: 1.6707  decode.d7.loss_mask: 0.2798  decode.d7.loss_dice: 0.3728  decode.d8.loss_cls: 1.6010  decode.d8.loss_mask: 0.2724  decode.d8.loss_dice: 0.3644
07/25 19:33:46 - mmengine - INFO - Iter(train) [ 2300/80000]  base_lr: 9.7410e-05 lr: 9.7410e-06  eta: 9:58:31  time: 0.4580  data_time: 0.0100  memory: 5265  grad_norm: 175.6696  loss: 24.9518  decode.loss_cls: 1.6581  decode.loss_mask: 0.3426  decode.loss_dice: 0.3952  decode.d0.loss_cls: 2.5274  decode.d0.loss_mask: 0.3761  decode.d0.loss_dice: 0.5830  decode.d1.loss_cls: 1.7713  decode.d1.loss_mask: 0.2940  decode.d1.loss_dice: 0.4188  decode.d2.loss_cls: 1.7333  decode.d2.loss_mask: 0.2844  decode.d2.loss_dice: 0.4180  decode.d3.loss_cls: 1.6551  decode.d3.loss_mask: 0.3238  decode.d3.loss_dice: 0.4367  decode.d4.loss_cls: 1.6808  decode.d4.loss_mask: 0.3359  decode.d4.loss_dice: 0.4377  decode.d5.loss_cls: 1.6220  decode.d5.loss_mask: 0.3211  decode.d5.loss_dice: 0.4135  decode.d6.loss_cls: 1.5671  decode.d6.loss_mask: 0.3184  decode.d6.loss_dice: 0.4483  decode.d7.loss_cls: 1.5460  decode.d7.loss_mask: 0.3470  decode.d7.loss_dice: 0.4043  decode.d8.loss_cls: 1.5287  decode.d8.loss_mask: 0.3480  decode.d8.loss_dice: 0.4148
07/25 19:34:09 - mmengine - INFO - Iter(train) [ 2350/80000]  base_lr: 9.7353e-05 lr: 9.7353e-06  eta: 9:57:57  time: 0.4526  data_time: 0.0101  memory: 5249  grad_norm: 511.5263  loss: 25.7894  decode.loss_cls: 1.5530  decode.loss_mask: 0.4791  decode.loss_dice: 0.4136  decode.d0.loss_cls: 2.4569  decode.d0.loss_mask: 0.5503  decode.d0.loss_dice: 0.5250  decode.d1.loss_cls: 1.6121  decode.d1.loss_mask: 0.5156  decode.d1.loss_dice: 0.3813  decode.d2.loss_cls: 1.5362  decode.d2.loss_mask: 0.5140  decode.d2.loss_dice: 0.4035  decode.d3.loss_cls: 1.5738  decode.d3.loss_mask: 0.5063  decode.d3.loss_dice: 0.3936  decode.d4.loss_cls: 1.6432  decode.d4.loss_mask: 0.4805  decode.d4.loss_dice: 0.3891  decode.d5.loss_cls: 1.4937  decode.d5.loss_mask: 0.5085  decode.d5.loss_dice: 0.4412  decode.d6.loss_cls: 1.6295  decode.d6.loss_mask: 0.4636  decode.d6.loss_dice: 0.3847  decode.d7.loss_cls: 1.5675  decode.d7.loss_mask: 0.4879  decode.d7.loss_dice: 0.4187  decode.d8.loss_cls: 1.5764  decode.d8.loss_mask: 0.4768  decode.d8.loss_dice: 0.4137
07/25 19:34:32 - mmengine - INFO - Iter(train) [ 2400/80000]  base_lr: 9.7297e-05 lr: 9.7297e-06  eta: 9:57:24  time: 0.4561  data_time: 0.0105  memory: 5249  grad_norm: 131.1525  loss: 22.1417  decode.loss_cls: 1.2922  decode.loss_mask: 0.3678  decode.loss_dice: 0.3678  decode.d0.loss_cls: 2.2980  decode.d0.loss_mask: 0.3954  decode.d0.loss_dice: 0.4958  decode.d1.loss_cls: 1.5721  decode.d1.loss_mask: 0.3245  decode.d1.loss_dice: 0.3246  decode.d2.loss_cls: 1.4374  decode.d2.loss_mask: 0.3328  decode.d2.loss_dice: 0.3461  decode.d3.loss_cls: 1.4858  decode.d3.loss_mask: 0.3193  decode.d3.loss_dice: 0.3287  decode.d4.loss_cls: 1.4328  decode.d4.loss_mask: 0.3282  decode.d4.loss_dice: 0.3399  decode.d5.loss_cls: 1.4158  decode.d5.loss_mask: 0.3478  decode.d5.loss_dice: 0.3529  decode.d6.loss_cls: 1.3426  decode.d6.loss_mask: 0.3323  decode.d6.loss_dice: 0.3541  decode.d7.loss_cls: 1.4011  decode.d7.loss_mask: 0.3204  decode.d7.loss_dice: 0.3474  decode.d8.loss_cls: 1.4490  decode.d8.loss_mask: 0.3340  decode.d8.loss_dice: 0.3548
07/25 19:34:54 - mmengine - INFO - Iter(train) [ 2450/80000]  base_lr: 9.7241e-05 lr: 9.7241e-06  eta: 9:56:48  time: 0.4590  data_time: 0.0102  memory: 5249  grad_norm: 207.8437  loss: 24.4528  decode.loss_cls: 1.4374  decode.loss_mask: 0.4140  decode.loss_dice: 0.4259  decode.d0.loss_cls: 2.2339  decode.d0.loss_mask: 0.4227  decode.d0.loss_dice: 0.5391  decode.d1.loss_cls: 1.5852  decode.d1.loss_mask: 0.4132  decode.d1.loss_dice: 0.4177  decode.d2.loss_cls: 1.5304  decode.d2.loss_mask: 0.3945  decode.d2.loss_dice: 0.3909  decode.d3.loss_cls: 1.5962  decode.d3.loss_mask: 0.4044  decode.d3.loss_dice: 0.3943  decode.d4.loss_cls: 1.5674  decode.d4.loss_mask: 0.3932  decode.d4.loss_dice: 0.4169  decode.d5.loss_cls: 1.6217  decode.d5.loss_mask: 0.3891  decode.d5.loss_dice: 0.4081  decode.d6.loss_cls: 1.5607  decode.d6.loss_mask: 0.3981  decode.d6.loss_dice: 0.3989  decode.d7.loss_cls: 1.5690  decode.d7.loss_mask: 0.3861  decode.d7.loss_dice: 0.4140  decode.d8.loss_cls: 1.5040  decode.d8.loss_mask: 0.3990  decode.d8.loss_dice: 0.4269
07/25 19:35:17 - mmengine - INFO - Iter(train) [ 2500/80000]  base_lr: 9.7184e-05 lr: 9.7184e-06  eta: 9:56:08  time: 0.4595  data_time: 0.0103  memory: 5249  grad_norm: 154.3571  loss: 25.4614  decode.loss_cls: 1.6392  decode.loss_mask: 0.4058  decode.loss_dice: 0.4054  decode.d0.loss_cls: 2.4174  decode.d0.loss_mask: 0.4116  decode.d0.loss_dice: 0.5481  decode.d1.loss_cls: 1.7739  decode.d1.loss_mask: 0.4275  decode.d1.loss_dice: 0.4358  decode.d2.loss_cls: 1.6194  decode.d2.loss_mask: 0.3812  decode.d2.loss_dice: 0.4422  decode.d3.loss_cls: 1.5714  decode.d3.loss_mask: 0.3816  decode.d3.loss_dice: 0.4258  decode.d4.loss_cls: 1.6065  decode.d4.loss_mask: 0.3867  decode.d4.loss_dice: 0.4135  decode.d5.loss_cls: 1.5813  decode.d5.loss_mask: 0.3748  decode.d5.loss_dice: 0.4088  decode.d6.loss_cls: 1.6506  decode.d6.loss_mask: 0.3982  decode.d6.loss_dice: 0.3951  decode.d7.loss_cls: 1.6360  decode.d7.loss_mask: 0.4015  decode.d7.loss_dice: 0.4224  decode.d8.loss_cls: 1.7036  decode.d8.loss_mask: 0.3787  decode.d8.loss_dice: 0.4177
07/25 19:35:40 - mmengine - INFO - Iter(train) [ 2550/80000]  base_lr: 9.7128e-05 lr: 9.7128e-06  eta: 9:55:37  time: 0.4548  data_time: 0.0100  memory: 5229  grad_norm: 124.4480  loss: 23.7046  decode.loss_cls: 1.4917  decode.loss_mask: 0.3330  decode.loss_dice: 0.4008  decode.d0.loss_cls: 2.2851  decode.d0.loss_mask: 0.3672  decode.d0.loss_dice: 0.5676  decode.d1.loss_cls: 1.6597  decode.d1.loss_mask: 0.3216  decode.d1.loss_dice: 0.4059  decode.d2.loss_cls: 1.4051  decode.d2.loss_mask: 0.3125  decode.d2.loss_dice: 0.4031  decode.d3.loss_cls: 1.6501  decode.d3.loss_mask: 0.3188  decode.d3.loss_dice: 0.3904  decode.d4.loss_cls: 1.6342  decode.d4.loss_mask: 0.3045  decode.d4.loss_dice: 0.3969  decode.d5.loss_cls: 1.5538  decode.d5.loss_mask: 0.3102  decode.d5.loss_dice: 0.3981  decode.d6.loss_cls: 1.5255  decode.d6.loss_mask: 0.3251  decode.d6.loss_dice: 0.4006  decode.d7.loss_cls: 1.4969  decode.d7.loss_mask: 0.3627  decode.d7.loss_dice: 0.4326  decode.d8.loss_cls: 1.5191  decode.d8.loss_mask: 0.3300  decode.d8.loss_dice: 0.4017
07/25 19:36:03 - mmengine - INFO - Iter(train) [ 2600/80000]  base_lr: 9.7071e-05 lr: 9.7071e-06  eta: 9:55:07  time: 0.4580  data_time: 0.0101  memory: 5292  grad_norm: 213.8656  loss: 26.4454  decode.loss_cls: 1.7169  decode.loss_mask: 0.3747  decode.loss_dice: 0.4571  decode.d0.loss_cls: 2.5118  decode.d0.loss_mask: 0.3942  decode.d0.loss_dice: 0.5731  decode.d1.loss_cls: 1.8571  decode.d1.loss_mask: 0.3855  decode.d1.loss_dice: 0.4584  decode.d2.loss_cls: 1.6990  decode.d2.loss_mask: 0.3661  decode.d2.loss_dice: 0.4376  decode.d3.loss_cls: 1.7485  decode.d3.loss_mask: 0.3500  decode.d3.loss_dice: 0.4540  decode.d4.loss_cls: 1.7631  decode.d4.loss_mask: 0.3517  decode.d4.loss_dice: 0.4476  decode.d5.loss_cls: 1.6844  decode.d5.loss_mask: 0.3757  decode.d5.loss_dice: 0.4574  decode.d6.loss_cls: 1.6599  decode.d6.loss_mask: 0.3664  decode.d6.loss_dice: 0.4530  decode.d7.loss_cls: 1.7505  decode.d7.loss_mask: 0.3748  decode.d7.loss_dice: 0.4725  decode.d8.loss_cls: 1.6792  decode.d8.loss_mask: 0.3787  decode.d8.loss_dice: 0.4467
07/25 19:36:25 - mmengine - INFO - Iter(train) [ 2650/80000]  base_lr: 9.7015e-05 lr: 9.7015e-06  eta: 9:54:36  time: 0.4591  data_time: 0.0103  memory: 5215  grad_norm: 191.6983  loss: 24.4619  decode.loss_cls: 1.5370  decode.loss_mask: 0.3745  decode.loss_dice: 0.4310  decode.d0.loss_cls: 2.0770  decode.d0.loss_mask: 0.4218  decode.d0.loss_dice: 0.5632  decode.d1.loss_cls: 1.6071  decode.d1.loss_mask: 0.4015  decode.d1.loss_dice: 0.4515  decode.d2.loss_cls: 1.5791  decode.d2.loss_mask: 0.3869  decode.d2.loss_dice: 0.4546  decode.d3.loss_cls: 1.4572  decode.d3.loss_mask: 0.4041  decode.d3.loss_dice: 0.4545  decode.d4.loss_cls: 1.4773  decode.d4.loss_mask: 0.3779  decode.d4.loss_dice: 0.4666  decode.d5.loss_cls: 1.5440  decode.d5.loss_mask: 0.3868  decode.d5.loss_dice: 0.4656  decode.d6.loss_cls: 1.5267  decode.d6.loss_mask: 0.3995  decode.d6.loss_dice: 0.4468  decode.d7.loss_cls: 1.5496  decode.d7.loss_mask: 0.4053  decode.d7.loss_dice: 0.4482  decode.d8.loss_cls: 1.5449  decode.d8.loss_mask: 0.3821  decode.d8.loss_dice: 0.4397
07/25 19:36:48 - mmengine - INFO - Iter(train) [ 2700/80000]  base_lr: 9.6958e-05 lr: 9.6958e-06  eta: 9:54:03  time: 0.4554  data_time: 0.0100  memory: 5229  grad_norm: 229.6679  loss: 20.7490  decode.loss_cls: 1.1991  decode.loss_mask: 0.3853  decode.loss_dice: 0.3577  decode.d0.loss_cls: 1.9849  decode.d0.loss_mask: 0.3868  decode.d0.loss_dice: 0.4307  decode.d1.loss_cls: 1.4598  decode.d1.loss_mask: 0.3291  decode.d1.loss_dice: 0.3694  decode.d2.loss_cls: 1.2589  decode.d2.loss_mask: 0.3384  decode.d2.loss_dice: 0.3767  decode.d3.loss_cls: 1.2364  decode.d3.loss_mask: 0.3623  decode.d3.loss_dice: 0.3513  decode.d4.loss_cls: 1.3459  decode.d4.loss_mask: 0.3504  decode.d4.loss_dice: 0.3437  decode.d5.loss_cls: 1.2496  decode.d5.loss_mask: 0.3560  decode.d5.loss_dice: 0.3561  decode.d6.loss_cls: 1.2371  decode.d6.loss_mask: 0.3394  decode.d6.loss_dice: 0.3522  decode.d7.loss_cls: 1.2427  decode.d7.loss_mask: 0.3741  decode.d7.loss_dice: 0.3793  decode.d8.loss_cls: 1.2619  decode.d8.loss_mask: 0.3662  decode.d8.loss_dice: 0.3676
07/25 19:37:11 - mmengine - INFO - Iter(train) [ 2750/80000]  base_lr: 9.6902e-05 lr: 9.6902e-06  eta: 9:53:32  time: 0.4495  data_time: 0.0095  memory: 5266  grad_norm: 178.8149  loss: 24.1609  decode.loss_cls: 1.3193  decode.loss_mask: 0.4419  decode.loss_dice: 0.4667  decode.d0.loss_cls: 2.1546  decode.d0.loss_mask: 0.4539  decode.d0.loss_dice: 0.5234  decode.d1.loss_cls: 1.6219  decode.d1.loss_mask: 0.3990  decode.d1.loss_dice: 0.4327  decode.d2.loss_cls: 1.4971  decode.d2.loss_mask: 0.4035  decode.d2.loss_dice: 0.4553  decode.d3.loss_cls: 1.4005  decode.d3.loss_mask: 0.4041  decode.d3.loss_dice: 0.4671  decode.d4.loss_cls: 1.5154  decode.d4.loss_mask: 0.4032  decode.d4.loss_dice: 0.4634  decode.d5.loss_cls: 1.4747  decode.d5.loss_mask: 0.4200  decode.d5.loss_dice: 0.4492  decode.d6.loss_cls: 1.4487  decode.d6.loss_mask: 0.4092  decode.d6.loss_dice: 0.4636  decode.d7.loss_cls: 1.4763  decode.d7.loss_mask: 0.3971  decode.d7.loss_dice: 0.4739  decode.d8.loss_cls: 1.4487  decode.d8.loss_mask: 0.4103  decode.d8.loss_dice: 0.4664
07/25 19:37:33 - mmengine - INFO - Iter(train) [ 2800/80000]  base_lr: 9.6846e-05 lr: 9.6846e-06  eta: 9:52:57  time: 0.4584  data_time: 0.0102  memory: 5249  grad_norm: 143.7784  loss: 22.3092  decode.loss_cls: 1.3921  decode.loss_mask: 0.3364  decode.loss_dice: 0.3993  decode.d0.loss_cls: 2.1120  decode.d0.loss_mask: 0.3373  decode.d0.loss_dice: 0.5331  decode.d1.loss_cls: 1.5820  decode.d1.loss_mask: 0.3372  decode.d1.loss_dice: 0.4097  decode.d2.loss_cls: 1.4128  decode.d2.loss_mask: 0.3466  decode.d2.loss_dice: 0.4049  decode.d3.loss_cls: 1.3707  decode.d3.loss_mask: 0.3316  decode.d3.loss_dice: 0.3930  decode.d4.loss_cls: 1.3863  decode.d4.loss_mask: 0.3152  decode.d4.loss_dice: 0.3901  decode.d5.loss_cls: 1.3811  decode.d5.loss_mask: 0.3030  decode.d5.loss_dice: 0.3806  decode.d6.loss_cls: 1.4752  decode.d6.loss_mask: 0.3233  decode.d6.loss_dice: 0.3921  decode.d7.loss_cls: 1.3887  decode.d7.loss_mask: 0.3254  decode.d7.loss_dice: 0.3986  decode.d8.loss_cls: 1.4506  decode.d8.loss_mask: 0.3120  decode.d8.loss_dice: 0.3883
07/25 19:37:56 - mmengine - INFO - Iter(train) [ 2850/80000]  base_lr: 9.6789e-05 lr: 9.6789e-06  eta: 9:52:26  time: 0.4555  data_time: 0.0102  memory: 5249  grad_norm: 203.2081  loss: 20.0939  decode.loss_cls: 1.1039  decode.loss_mask: 0.3367  decode.loss_dice: 0.3777  decode.d0.loss_cls: 2.0873  decode.d0.loss_mask: 0.3673  decode.d0.loss_dice: 0.4772  decode.d1.loss_cls: 1.3677  decode.d1.loss_mask: 0.3385  decode.d1.loss_dice: 0.3907  decode.d2.loss_cls: 1.1859  decode.d2.loss_mask: 0.3664  decode.d2.loss_dice: 0.4045  decode.d3.loss_cls: 1.0872  decode.d3.loss_mask: 0.3554  decode.d3.loss_dice: 0.3785  decode.d4.loss_cls: 1.1515  decode.d4.loss_mask: 0.3621  decode.d4.loss_dice: 0.3698  decode.d5.loss_cls: 1.1413  decode.d5.loss_mask: 0.3239  decode.d5.loss_dice: 0.3911  decode.d6.loss_cls: 1.1975  decode.d6.loss_mask: 0.3272  decode.d6.loss_dice: 0.4174  decode.d7.loss_cls: 1.1601  decode.d7.loss_mask: 0.3259  decode.d7.loss_dice: 0.3953  decode.d8.loss_cls: 1.1744  decode.d8.loss_mask: 0.3356  decode.d8.loss_dice: 0.3959
07/25 19:38:19 - mmengine - INFO - Iter(train) [ 2900/80000]  base_lr: 9.6733e-05 lr: 9.6733e-06  eta: 9:51:51  time: 0.4538  data_time: 0.0097  memory: 5231  grad_norm: 162.3742  loss: 20.9104  decode.loss_cls: 1.2239  decode.loss_mask: 0.3934  decode.loss_dice: 0.4023  decode.d0.loss_cls: 2.0386  decode.d0.loss_mask: 0.4103  decode.d0.loss_dice: 0.4638  decode.d1.loss_cls: 1.3779  decode.d1.loss_mask: 0.3560  decode.d1.loss_dice: 0.3926  decode.d2.loss_cls: 1.1654  decode.d2.loss_mask: 0.3826  decode.d2.loss_dice: 0.3807  decode.d3.loss_cls: 1.2486  decode.d3.loss_mask: 0.3634  decode.d3.loss_dice: 0.3883  decode.d4.loss_cls: 1.1084  decode.d4.loss_mask: 0.3926  decode.d4.loss_dice: 0.4165  decode.d5.loss_cls: 1.2055  decode.d5.loss_mask: 0.3809  decode.d5.loss_dice: 0.4125  decode.d6.loss_cls: 1.1905  decode.d6.loss_mask: 0.3793  decode.d6.loss_dice: 0.4057  decode.d7.loss_cls: 1.2153  decode.d7.loss_mask: 0.3944  decode.d7.loss_dice: 0.3836  decode.d8.loss_cls: 1.2758  decode.d8.loss_mask: 0.3763  decode.d8.loss_dice: 0.3855
07/25 19:38:41 - mmengine - INFO - Iter(train) [ 2950/80000]  base_lr: 9.6676e-05 lr: 9.6676e-06  eta: 9:51:19  time: 0.4553  data_time: 0.0104  memory: 5249  grad_norm: 185.3018  loss: 21.6670  decode.loss_cls: 1.2587  decode.loss_mask: 0.3417  decode.loss_dice: 0.4630  decode.d0.loss_cls: 1.8249  decode.d0.loss_mask: 0.3811  decode.d0.loss_dice: 0.5357  decode.d1.loss_cls: 1.3532  decode.d1.loss_mask: 0.3958  decode.d1.loss_dice: 0.4725  decode.d2.loss_cls: 1.2733  decode.d2.loss_mask: 0.4087  decode.d2.loss_dice: 0.5097  decode.d3.loss_cls: 1.2398  decode.d3.loss_mask: 0.3937  decode.d3.loss_dice: 0.4724  decode.d4.loss_cls: 1.2076  decode.d4.loss_mask: 0.3843  decode.d4.loss_dice: 0.4833  decode.d5.loss_cls: 1.1679  decode.d5.loss_mask: 0.3804  decode.d5.loss_dice: 0.4634  decode.d6.loss_cls: 1.1890  decode.d6.loss_mask: 0.3660  decode.d6.loss_dice: 0.4625  decode.d7.loss_cls: 1.2712  decode.d7.loss_mask: 0.3751  decode.d7.loss_dice: 0.4838  decode.d8.loss_cls: 1.2474  decode.d8.loss_mask: 0.3653  decode.d8.loss_dice: 0.4953
07/25 19:39:04 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250725_191538
07/25 19:39:04 - mmengine - INFO - Iter(train) [ 3000/80000]  base_lr: 9.6620e-05 lr: 9.6620e-06  eta: 9:50:48  time: 0.4548  data_time: 0.0098  memory: 5294  grad_norm: 301.4065  loss: 21.8771  decode.loss_cls: 1.1349  decode.loss_mask: 0.4441  decode.loss_dice: 0.4161  decode.d0.loss_cls: 1.9884  decode.d0.loss_mask: 0.4883  decode.d0.loss_dice: 0.5572  decode.d1.loss_cls: 1.3657  decode.d1.loss_mask: 0.5049  decode.d1.loss_dice: 0.4648  decode.d2.loss_cls: 1.2628  decode.d2.loss_mask: 0.4832  decode.d2.loss_dice: 0.4172  decode.d3.loss_cls: 1.1806  decode.d3.loss_mask: 0.4433  decode.d3.loss_dice: 0.3916  decode.d4.loss_cls: 1.1563  decode.d4.loss_mask: 0.4368  decode.d4.loss_dice: 0.3993  decode.d5.loss_cls: 1.2254  decode.d5.loss_mask: 0.4459  decode.d5.loss_dice: 0.3938  decode.d6.loss_cls: 1.2052  decode.d6.loss_mask: 0.4461  decode.d6.loss_dice: 0.4064  decode.d7.loss_cls: 1.2616  decode.d7.loss_mask: 0.4352  decode.d7.loss_dice: 0.4115  decode.d8.loss_cls: 1.2380  decode.d8.loss_mask: 0.4548  decode.d8.loss_dice: 0.4181
07/25 19:39:27 - mmengine - INFO - Iter(train) [ 3050/80000]  base_lr: 9.6563e-05 lr: 9.6563e-06  eta: 9:50:21  time: 0.4574  data_time: 0.0105  memory: 5269  grad_norm: 98.7483  loss: 17.7173  decode.loss_cls: 0.9889  decode.loss_mask: 0.2586  decode.loss_dice: 0.3865  decode.d0.loss_cls: 1.9065  decode.d0.loss_mask: 0.2551  decode.d0.loss_dice: 0.4039  decode.d1.loss_cls: 1.3830  decode.d1.loss_mask: 0.2571  decode.d1.loss_dice: 0.3612  decode.d2.loss_cls: 1.0664  decode.d2.loss_mask: 0.2532  decode.d2.loss_dice: 0.3574  decode.d3.loss_cls: 0.9709  decode.d3.loss_mask: 0.2533  decode.d3.loss_dice: 0.3512  decode.d4.loss_cls: 1.0406  decode.d4.loss_mask: 0.2502  decode.d4.loss_dice: 0.3462  decode.d5.loss_cls: 1.0861  decode.d5.loss_mask: 0.2480  decode.d5.loss_dice: 0.3491  decode.d6.loss_cls: 1.0465  decode.d6.loss_mask: 0.2404  decode.d6.loss_dice: 0.3495  decode.d7.loss_cls: 1.0425  decode.d7.loss_mask: 0.2485  decode.d7.loss_dice: 0.3670  decode.d8.loss_cls: 1.0300  decode.d8.loss_mask: 0.2523  decode.d8.loss_dice: 0.3676
07/25 19:39:50 - mmengine - INFO - Iter(train) [ 3100/80000]  base_lr: 9.6507e-05 lr: 9.6507e-06  eta: 9:49:52  time: 0.4568  data_time: 0.0097  memory: 5293  grad_norm: 208.3404  loss: 22.7096  decode.loss_cls: 1.3016  decode.loss_mask: 0.4336  decode.loss_dice: 0.4939  decode.d0.loss_cls: 1.9258  decode.d0.loss_mask: 0.4856  decode.d0.loss_dice: 0.5581  decode.d1.loss_cls: 1.5135  decode.d1.loss_mask: 0.3891  decode.d1.loss_dice: 0.4477  decode.d2.loss_cls: 1.2386  decode.d2.loss_mask: 0.4225  decode.d2.loss_dice: 0.4847  decode.d3.loss_cls: 1.2484  decode.d3.loss_mask: 0.4184  decode.d3.loss_dice: 0.4870  decode.d4.loss_cls: 1.2825  decode.d4.loss_mask: 0.4137  decode.d4.loss_dice: 0.4849  decode.d5.loss_cls: 1.2615  decode.d5.loss_mask: 0.4481  decode.d5.loss_dice: 0.5101  decode.d6.loss_cls: 1.2552  decode.d6.loss_mask: 0.4019  decode.d6.loss_dice: 0.4673  decode.d7.loss_cls: 1.2604  decode.d7.loss_mask: 0.4303  decode.d7.loss_dice: 0.4567  decode.d8.loss_cls: 1.2538  decode.d8.loss_mask: 0.4620  decode.d8.loss_dice: 0.4725
07/25 19:40:13 - mmengine - INFO - Iter(train) [ 3150/80000]  base_lr: 9.6450e-05 lr: 9.6450e-06  eta: 9:49:23  time: 0.4555  data_time: 0.0101  memory: 5249  grad_norm: 169.0989  loss: 19.5024  decode.loss_cls: 1.1176  decode.loss_mask: 0.3274  decode.loss_dice: 0.3949  decode.d0.loss_cls: 1.7679  decode.d0.loss_mask: 0.3867  decode.d0.loss_dice: 0.4734  decode.d1.loss_cls: 1.2093  decode.d1.loss_mask: 0.3343  decode.d1.loss_dice: 0.3962  decode.d2.loss_cls: 1.1705  decode.d2.loss_mask: 0.3592  decode.d2.loss_dice: 0.3892  decode.d3.loss_cls: 1.1143  decode.d3.loss_mask: 0.3370  decode.d3.loss_dice: 0.3956  decode.d4.loss_cls: 1.1912  decode.d4.loss_mask: 0.3340  decode.d4.loss_dice: 0.3699  decode.d5.loss_cls: 1.1644  decode.d5.loss_mask: 0.3140  decode.d5.loss_dice: 0.3667  decode.d6.loss_cls: 1.1366  decode.d6.loss_mask: 0.3177  decode.d6.loss_dice: 0.3784  decode.d7.loss_cls: 1.1502  decode.d7.loss_mask: 0.3237  decode.d7.loss_dice: 0.3732  decode.d8.loss_cls: 1.1558  decode.d8.loss_mask: 0.3507  decode.d8.loss_dice: 0.4025
07/25 19:40:35 - mmengine - INFO - Iter(train) [ 3200/80000]  base_lr: 9.6394e-05 lr: 9.6394e-06  eta: 9:48:48  time: 0.4593  data_time: 0.0105  memory: 5228  grad_norm: 128.9329  loss: 18.3001  decode.loss_cls: 0.8838  decode.loss_mask: 0.3883  decode.loss_dice: 0.4775  decode.d0.loss_cls: 1.5322  decode.d0.loss_mask: 0.4201  decode.d0.loss_dice: 0.5099  decode.d1.loss_cls: 1.0748  decode.d1.loss_mask: 0.4142  decode.d1.loss_dice: 0.5480  decode.d2.loss_cls: 0.8919  decode.d2.loss_mask: 0.3996  decode.d2.loss_dice: 0.4492  decode.d3.loss_cls: 0.8258  decode.d3.loss_mask: 0.3999  decode.d3.loss_dice: 0.4473  decode.d4.loss_cls: 0.9137  decode.d4.loss_mask: 0.4087  decode.d4.loss_dice: 0.4610  decode.d5.loss_cls: 0.9256  decode.d5.loss_mask: 0.3945  decode.d5.loss_dice: 0.4450  decode.d6.loss_cls: 0.8192  decode.d6.loss_mask: 0.3901  decode.d6.loss_dice: 0.4485  decode.d7.loss_cls: 0.8648  decode.d7.loss_mask: 0.3950  decode.d7.loss_dice: 0.4368  decode.d8.loss_cls: 0.8766  decode.d8.loss_mask: 0.3929  decode.d8.loss_dice: 0.4654
07/25 19:40:58 - mmengine - INFO - Iter(train) [ 3250/80000]  base_lr: 9.6337e-05 lr: 9.6337e-06  eta: 9:48:13  time: 0.4442  data_time: 0.0091  memory: 5293  grad_norm: 174.5867  loss: 20.1910  decode.loss_cls: 1.1234  decode.loss_mask: 0.3354  decode.loss_dice: 0.3998  decode.d0.loss_cls: 1.8391  decode.d0.loss_mask: 0.3817  decode.d0.loss_dice: 0.5150  decode.d1.loss_cls: 1.2010  decode.d1.loss_mask: 0.3556  decode.d1.loss_dice: 0.4406  decode.d2.loss_cls: 1.1345  decode.d2.loss_mask: 0.3308  decode.d2.loss_dice: 0.4246  decode.d3.loss_cls: 1.0852  decode.d3.loss_mask: 0.3765  decode.d3.loss_dice: 0.4257  decode.d4.loss_cls: 1.0948  decode.d4.loss_mask: 0.3832  decode.d4.loss_dice: 0.4283  decode.d5.loss_cls: 1.2257  decode.d5.loss_mask: 0.4177  decode.d5.loss_dice: 0.4782  decode.d6.loss_cls: 1.1703  decode.d6.loss_mask: 0.3545  decode.d6.loss_dice: 0.4457  decode.d7.loss_cls: 1.1235  decode.d7.loss_mask: 0.3559  decode.d7.loss_dice: 0.4481  decode.d8.loss_cls: 1.0901  decode.d8.loss_mask: 0.3672  decode.d8.loss_dice: 0.4389
07/25 19:41:20 - mmengine - INFO - Iter(train) [ 3300/80000]  base_lr: 9.6281e-05 lr: 9.6281e-06  eta: 9:47:44  time: 0.4528  data_time: 0.0099  memory: 5292  grad_norm: 133.4791  loss: 20.3283  decode.loss_cls: 1.3481  decode.loss_mask: 0.2460  decode.loss_dice: 0.3681  decode.d0.loss_cls: 1.9332  decode.d0.loss_mask: 0.2671  decode.d0.loss_dice: 0.4592  decode.d1.loss_cls: 1.4446  decode.d1.loss_mask: 0.2434  decode.d1.loss_dice: 0.3961  decode.d2.loss_cls: 1.2150  decode.d2.loss_mask: 0.2441  decode.d2.loss_dice: 0.4081  decode.d3.loss_cls: 1.2810  decode.d3.loss_mask: 0.2422  decode.d3.loss_dice: 0.3674  decode.d4.loss_cls: 1.4045  decode.d4.loss_mask: 0.2363  decode.d4.loss_dice: 0.4001  decode.d5.loss_cls: 1.2686  decode.d5.loss_mask: 0.2579  decode.d5.loss_dice: 0.3794  decode.d6.loss_cls: 1.3330  decode.d6.loss_mask: 0.2428  decode.d6.loss_dice: 0.3504  decode.d7.loss_cls: 1.3609  decode.d7.loss_mask: 0.2450  decode.d7.loss_dice: 0.3750  decode.d8.loss_cls: 1.4241  decode.d8.loss_mask: 0.2385  decode.d8.loss_dice: 0.3484
07/25 19:41:43 - mmengine - INFO - Iter(train) [ 3350/80000]  base_lr: 9.6224e-05 lr: 9.6224e-06  eta: 9:47:16  time: 0.4565  data_time: 0.0099  memory: 5249  grad_norm: 163.9814  loss: 18.5917  decode.loss_cls: 1.0737  decode.loss_mask: 0.3514  decode.loss_dice: 0.3234  decode.d0.loss_cls: 1.8813  decode.d0.loss_mask: 0.3393  decode.d0.loss_dice: 0.4266  decode.d1.loss_cls: 1.3120  decode.d1.loss_mask: 0.3309  decode.d1.loss_dice: 0.3361  decode.d2.loss_cls: 1.0962  decode.d2.loss_mask: 0.3313  decode.d2.loss_dice: 0.3377  decode.d3.loss_cls: 1.1203  decode.d3.loss_mask: 0.3207  decode.d3.loss_dice: 0.3178  decode.d4.loss_cls: 1.0676  decode.d4.loss_mask: 0.3399  decode.d4.loss_dice: 0.3323  decode.d5.loss_cls: 1.0741  decode.d5.loss_mask: 0.3675  decode.d5.loss_dice: 0.3488  decode.d6.loss_cls: 1.0342  decode.d6.loss_mask: 0.3390  decode.d6.loss_dice: 0.3413  decode.d7.loss_cls: 1.0364  decode.d7.loss_mask: 0.3174  decode.d7.loss_dice: 0.3284  decode.d8.loss_cls: 1.1124  decode.d8.loss_mask: 0.3254  decode.d8.loss_dice: 0.3283
07/25 19:42:06 - mmengine - INFO - Iter(train) [ 3400/80000]  base_lr: 9.6168e-05 lr: 9.6168e-06  eta: 9:46:50  time: 0.4550  data_time: 0.0103  memory: 5249  grad_norm: 126.8912  loss: 16.7008  decode.loss_cls: 0.8857  decode.loss_mask: 0.3184  decode.loss_dice: 0.3258  decode.d0.loss_cls: 1.7567  decode.d0.loss_mask: 0.4158  decode.d0.loss_dice: 0.4133  decode.d1.loss_cls: 1.0174  decode.d1.loss_mask: 0.3407  decode.d1.loss_dice: 0.3764  decode.d2.loss_cls: 0.9374  decode.d2.loss_mask: 0.3033  decode.d2.loss_dice: 0.3325  decode.d3.loss_cls: 0.8474  decode.d3.loss_mask: 0.3310  decode.d3.loss_dice: 0.3605  decode.d4.loss_cls: 0.8860  decode.d4.loss_mask: 0.3212  decode.d4.loss_dice: 0.3241  decode.d5.loss_cls: 0.9142  decode.d5.loss_mask: 0.3033  decode.d5.loss_dice: 0.3222  decode.d6.loss_cls: 0.8787  decode.d6.loss_mask: 0.3183  decode.d6.loss_dice: 0.3389  decode.d7.loss_cls: 0.9112  decode.d7.loss_mask: 0.3295  decode.d7.loss_dice: 0.3494  decode.d8.loss_cls: 0.9220  decode.d8.loss_mask: 0.3012  decode.d8.loss_dice: 0.3183
07/25 19:42:29 - mmengine - INFO - Iter(train) [ 3450/80000]  base_lr: 9.6111e-05 lr: 9.6111e-06  eta: 9:46:25  time: 0.4540  data_time: 0.0099  memory: 5293  grad_norm: 146.0204  loss: 21.6948  decode.loss_cls: 1.3630  decode.loss_mask: 0.2896  decode.loss_dice: 0.4089  decode.d0.loss_cls: 2.1151  decode.d0.loss_mask: 0.3020  decode.d0.loss_dice: 0.4921  decode.d1.loss_cls: 1.5914  decode.d1.loss_mask: 0.2867  decode.d1.loss_dice: 0.4449  decode.d2.loss_cls: 1.4335  decode.d2.loss_mask: 0.2722  decode.d2.loss_dice: 0.3669  decode.d3.loss_cls: 1.3252  decode.d3.loss_mask: 0.3224  decode.d3.loss_dice: 0.3822  decode.d4.loss_cls: 1.3665  decode.d4.loss_mask: 0.2634  decode.d4.loss_dice: 0.3943  decode.d5.loss_cls: 1.3106  decode.d5.loss_mask: 0.3063  decode.d5.loss_dice: 0.3802  decode.d6.loss_cls: 1.4479  decode.d6.loss_mask: 0.2632  decode.d6.loss_dice: 0.3912  decode.d7.loss_cls: 1.4822  decode.d7.loss_mask: 0.2635  decode.d7.loss_dice: 0.3996  decode.d8.loss_cls: 1.3673  decode.d8.loss_mask: 0.2712  decode.d8.loss_dice: 0.3915
07/25 19:42:42 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250725_191538
07/25 19:42:52 - mmengine - INFO - Iter(train) [ 3500/80000]  base_lr: 9.6055e-05 lr: 9.6055e-06  eta: 9:45:59  time: 0.4561  data_time: 0.0102  memory: 5265  grad_norm: 120.7190  loss: 17.7300  decode.loss_cls: 0.9505  decode.loss_mask: 0.3828  decode.loss_dice: 0.4191  decode.d0.loss_cls: 1.5277  decode.d0.loss_mask: 0.3514  decode.d0.loss_dice: 0.4343  decode.d1.loss_cls: 1.1569  decode.d1.loss_mask: 0.3397  decode.d1.loss_dice: 0.4208  decode.d2.loss_cls: 0.8443  decode.d2.loss_mask: 0.3421  decode.d2.loss_dice: 0.4248  decode.d3.loss_cls: 0.9264  decode.d3.loss_mask: 0.3379  decode.d3.loss_dice: 0.3971  decode.d4.loss_cls: 0.9454  decode.d4.loss_mask: 0.3361  decode.d4.loss_dice: 0.4184  decode.d5.loss_cls: 0.9647  decode.d5.loss_mask: 0.3244  decode.d5.loss_dice: 0.4132  decode.d6.loss_cls: 0.9454  decode.d6.loss_mask: 0.3434  decode.d6.loss_dice: 0.4071  decode.d7.loss_cls: 0.9068  decode.d7.loss_mask: 0.3390  decode.d7.loss_dice: 0.4182  decode.d8.loss_cls: 0.9631  decode.d8.loss_mask: 0.3379  decode.d8.loss_dice: 0.4110
07/25 19:43:14 - mmengine - INFO - Iter(train) [ 3550/80000]  base_lr: 9.5998e-05 lr: 9.5998e-06  eta: 9:45:27  time: 0.4455  data_time: 0.0094  memory: 5249  grad_norm: 222.6434  loss: 25.5377  decode.loss_cls: 1.4267  decode.loss_mask: 0.4170  decode.loss_dice: 0.5061  decode.d0.loss_cls: 2.3109  decode.d0.loss_mask: 0.5029  decode.d0.loss_dice: 0.6940  decode.d1.loss_cls: 1.6613  decode.d1.loss_mask: 0.4577  decode.d1.loss_dice: 0.5372  decode.d2.loss_cls: 1.4679  decode.d2.loss_mask: 0.4589  decode.d2.loss_dice: 0.5626  decode.d3.loss_cls: 1.3653  decode.d3.loss_mask: 0.4523  decode.d3.loss_dice: 0.5293  decode.d4.loss_cls: 1.5024  decode.d4.loss_mask: 0.4207  decode.d4.loss_dice: 0.5298  decode.d5.loss_cls: 1.4793  decode.d5.loss_mask: 0.4304  decode.d5.loss_dice: 0.5215  decode.d6.loss_cls: 1.4710  decode.d6.loss_mask: 0.4318  decode.d6.loss_dice: 0.5126  decode.d7.loss_cls: 1.5427  decode.d7.loss_mask: 0.4801  decode.d7.loss_dice: 0.5279  decode.d8.loss_cls: 1.4052  decode.d8.loss_mask: 0.4462  decode.d8.loss_dice: 0.4859
07/25 19:43:37 - mmengine - INFO - Iter(train) [ 3600/80000]  base_lr: 9.5942e-05 lr: 9.5942e-06  eta: 9:45:01  time: 0.4552  data_time: 0.0100  memory: 5249  grad_norm: 127.8471  loss: 19.5034  decode.loss_cls: 1.0622  decode.loss_mask: 0.3948  decode.loss_dice: 0.4397  decode.d0.loss_cls: 1.9076  decode.d0.loss_mask: 0.3867  decode.d0.loss_dice: 0.5399  decode.d1.loss_cls: 1.3604  decode.d1.loss_mask: 0.3605  decode.d1.loss_dice: 0.4082  decode.d2.loss_cls: 1.0120  decode.d2.loss_mask: 0.3602  decode.d2.loss_dice: 0.3971  decode.d3.loss_cls: 1.0159  decode.d3.loss_mask: 0.3762  decode.d3.loss_dice: 0.4244  decode.d4.loss_cls: 1.0595  decode.d4.loss_mask: 0.3851  decode.d4.loss_dice: 0.4511  decode.d5.loss_cls: 1.0291  decode.d5.loss_mask: 0.3540  decode.d5.loss_dice: 0.4045  decode.d6.loss_cls: 1.0211  decode.d6.loss_mask: 0.3460  decode.d6.loss_dice: 0.4146  decode.d7.loss_cls: 1.0057  decode.d7.loss_mask: 0.3659  decode.d7.loss_dice: 0.4228  decode.d8.loss_cls: 1.0170  decode.d8.loss_mask: 0.3766  decode.d8.loss_dice: 0.4045
07/25 19:44:00 - mmengine - INFO - Iter(train) [ 3650/80000]  base_lr: 9.5885e-05 lr: 9.5885e-06  eta: 9:44:29  time: 0.4539  data_time: 0.0102  memory: 5309  grad_norm: 95.8064  loss: 16.4148  decode.loss_cls: 0.8679  decode.loss_mask: 0.3120  decode.loss_dice: 0.3402  decode.d0.loss_cls: 1.6524  decode.d0.loss_mask: 0.3179  decode.d0.loss_dice: 0.4206  decode.d1.loss_cls: 1.0761  decode.d1.loss_mask: 0.3211  decode.d1.loss_dice: 0.3448  decode.d2.loss_cls: 0.8921  decode.d2.loss_mask: 0.3075  decode.d2.loss_dice: 0.3330  decode.d3.loss_cls: 0.8750  decode.d3.loss_mask: 0.2941  decode.d3.loss_dice: 0.3303  decode.d4.loss_cls: 0.9024  decode.d4.loss_mask: 0.2812  decode.d4.loss_dice: 0.3505  decode.d5.loss_cls: 0.9401  decode.d5.loss_mask: 0.3001  decode.d5.loss_dice: 0.3351  decode.d6.loss_cls: 0.8570  decode.d6.loss_mask: 0.3074  decode.d6.loss_dice: 0.3375  decode.d7.loss_cls: 0.8932  decode.d7.loss_mask: 0.3257  decode.d7.loss_dice: 0.3448  decode.d8.loss_cls: 0.9064  decode.d8.loss_mask: 0.3093  decode.d8.loss_dice: 0.3389
07/25 19:44:22 - mmengine - INFO - Iter(train) [ 3700/80000]  base_lr: 9.5829e-05 lr: 9.5829e-06  eta: 9:44:03  time: 0.4553  data_time: 0.0101  memory: 5265  grad_norm: 132.5997  loss: 18.4058  decode.loss_cls: 1.0413  decode.loss_mask: 0.2831  decode.loss_dice: 0.3983  decode.d0.loss_cls: 1.9716  decode.d0.loss_mask: 0.2929  decode.d0.loss_dice: 0.4443  decode.d1.loss_cls: 1.3208  decode.d1.loss_mask: 0.3155  decode.d1.loss_dice: 0.3677  decode.d2.loss_cls: 1.0957  decode.d2.loss_mask: 0.2871  decode.d2.loss_dice: 0.3678  decode.d3.loss_cls: 0.9794  decode.d3.loss_mask: 0.3172  decode.d3.loss_dice: 0.3759  decode.d4.loss_cls: 1.0538  decode.d4.loss_mask: 0.3170  decode.d4.loss_dice: 0.3850  decode.d5.loss_cls: 1.0350  decode.d5.loss_mask: 0.2965  decode.d5.loss_dice: 0.3651  decode.d6.loss_cls: 1.0248  decode.d6.loss_mask: 0.2814  decode.d6.loss_dice: 0.3852  decode.d7.loss_cls: 1.0511  decode.d7.loss_mask: 0.2832  decode.d7.loss_dice: 0.3524  decode.d8.loss_cls: 1.0687  decode.d8.loss_mask: 0.2860  decode.d8.loss_dice: 0.3620
07/25 19:44:45 - mmengine - INFO - Iter(train) [ 3750/80000]  base_lr: 9.5772e-05 lr: 9.5772e-06  eta: 9:43:37  time: 0.4577  data_time: 0.0099  memory: 5265  grad_norm: 141.1649  loss: 17.6876  decode.loss_cls: 0.9820  decode.loss_mask: 0.3127  decode.loss_dice: 0.3808  decode.d0.loss_cls: 1.7506  decode.d0.loss_mask: 0.3004  decode.d0.loss_dice: 0.4685  decode.d1.loss_cls: 1.2768  decode.d1.loss_mask: 0.2845  decode.d1.loss_dice: 0.3659  decode.d2.loss_cls: 1.0476  decode.d2.loss_mask: 0.2856  decode.d2.loss_dice: 0.3624  decode.d3.loss_cls: 0.9753  decode.d3.loss_mask: 0.2911  decode.d3.loss_dice: 0.3442  decode.d4.loss_cls: 1.0101  decode.d4.loss_mask: 0.2931  decode.d4.loss_dice: 0.3564  decode.d5.loss_cls: 0.9756  decode.d5.loss_mask: 0.2925  decode.d5.loss_dice: 0.3557  decode.d6.loss_cls: 0.9708  decode.d6.loss_mask: 0.2914  decode.d6.loss_dice: 0.3459  decode.d7.loss_cls: 0.9583  decode.d7.loss_mask: 0.3078  decode.d7.loss_dice: 0.3846  decode.d8.loss_cls: 0.9987  decode.d8.loss_mask: 0.3301  decode.d8.loss_dice: 0.3884
07/25 19:45:08 - mmengine - INFO - Iter(train) [ 3800/80000]  base_lr: 9.5716e-05 lr: 9.5716e-06  eta: 9:43:10  time: 0.4544  data_time: 0.0100  memory: 5229  grad_norm: 123.2878  loss: 18.2800  decode.loss_cls: 1.0950  decode.loss_mask: 0.3349  decode.loss_dice: 0.3173  decode.d0.loss_cls: 1.8113  decode.d0.loss_mask: 0.3418  decode.d0.loss_dice: 0.3967  decode.d1.loss_cls: 1.1634  decode.d1.loss_mask: 0.3407  decode.d1.loss_dice: 0.3685  decode.d2.loss_cls: 1.0060  decode.d2.loss_mask: 0.3258  decode.d2.loss_dice: 0.3513  decode.d3.loss_cls: 1.0612  decode.d3.loss_mask: 0.3217  decode.d3.loss_dice: 0.3313  decode.d4.loss_cls: 1.0275  decode.d4.loss_mask: 0.3212  decode.d4.loss_dice: 0.3352  decode.d5.loss_cls: 1.0312  decode.d5.loss_mask: 0.3257  decode.d5.loss_dice: 0.3356  decode.d6.loss_cls: 1.1151  decode.d6.loss_mask: 0.3423  decode.d6.loss_dice: 0.3318  decode.d7.loss_cls: 1.0738  decode.d7.loss_mask: 0.3416  decode.d7.loss_dice: 0.3378  decode.d8.loss_cls: 1.1091  decode.d8.loss_mask: 0.3405  decode.d8.loss_dice: 0.3445
07/25 19:45:31 - mmengine - INFO - Iter(train) [ 3850/80000]  base_lr: 9.5659e-05 lr: 9.5659e-06  eta: 9:42:44  time: 0.4551  data_time: 0.0099  memory: 5249  grad_norm: 103.8812  loss: 17.9587  decode.loss_cls: 0.8965  decode.loss_mask: 0.3786  decode.loss_dice: 0.3740  decode.d0.loss_cls: 1.8141  decode.d0.loss_mask: 0.3863  decode.d0.loss_dice: 0.4416  decode.d1.loss_cls: 1.0558  decode.d1.loss_mask: 0.3713  decode.d1.loss_dice: 0.3675  decode.d2.loss_cls: 0.8819  decode.d2.loss_mask: 0.3942  decode.d2.loss_dice: 0.3909  decode.d3.loss_cls: 0.9643  decode.d3.loss_mask: 0.3594  decode.d3.loss_dice: 0.3790  decode.d4.loss_cls: 0.9954  decode.d4.loss_mask: 0.3723  decode.d4.loss_dice: 0.3718  decode.d5.loss_cls: 0.9242  decode.d5.loss_mask: 0.3932  decode.d5.loss_dice: 0.3887  decode.d6.loss_cls: 0.8864  decode.d6.loss_mask: 0.3828  decode.d6.loss_dice: 0.3768  decode.d7.loss_cls: 0.9521  decode.d7.loss_mask: 0.3815  decode.d7.loss_dice: 0.3656  decode.d8.loss_cls: 0.9585  decode.d8.loss_mask: 0.3821  decode.d8.loss_dice: 0.3715
07/25 19:45:54 - mmengine - INFO - Iter(train) [ 3900/80000]  base_lr: 9.5603e-05 lr: 9.5603e-06  eta: 9:42:19  time: 0.4610  data_time: 0.0101  memory: 5249  grad_norm: 134.6453  loss: 18.4629  decode.loss_cls: 0.9992  decode.loss_mask: 0.3157  decode.loss_dice: 0.4212  decode.d0.loss_cls: 1.8379  decode.d0.loss_mask: 0.4120  decode.d0.loss_dice: 0.5240  decode.d1.loss_cls: 1.1096  decode.d1.loss_mask: 0.2831  decode.d1.loss_dice: 0.3912  decode.d2.loss_cls: 0.9979  decode.d2.loss_mask: 0.2829  decode.d2.loss_dice: 0.3714  decode.d3.loss_cls: 1.0733  decode.d3.loss_mask: 0.3095  decode.d3.loss_dice: 0.4015  decode.d4.loss_cls: 1.1134  decode.d4.loss_mask: 0.3060  decode.d4.loss_dice: 0.3706  decode.d5.loss_cls: 0.9882  decode.d5.loss_mask: 0.3416  decode.d5.loss_dice: 0.3933  decode.d6.loss_cls: 1.0190  decode.d6.loss_mask: 0.3146  decode.d6.loss_dice: 0.3718  decode.d7.loss_cls: 1.0016  decode.d7.loss_mask: 0.3786  decode.d7.loss_dice: 0.4114  decode.d8.loss_cls: 0.9822  decode.d8.loss_mask: 0.3330  decode.d8.loss_dice: 0.4071
07/25 19:46:16 - mmengine - INFO - Iter(train) [ 3950/80000]  base_lr: 9.5546e-05 lr: 9.5546e-06  eta: 9:41:50  time: 0.4576  data_time: 0.0101  memory: 5248  grad_norm: 171.8620  loss: 16.4804  decode.loss_cls: 0.9904  decode.loss_mask: 0.2072  decode.loss_dice: 0.3172  decode.d0.loss_cls: 1.8038  decode.d0.loss_mask: 0.2114  decode.d0.loss_dice: 0.3507  decode.d1.loss_cls: 1.1494  decode.d1.loss_mask: 0.2126  decode.d1.loss_dice: 0.3361  decode.d2.loss_cls: 1.0869  decode.d2.loss_mask: 0.1886  decode.d2.loss_dice: 0.2898  decode.d3.loss_cls: 1.0567  decode.d3.loss_mask: 0.1854  decode.d3.loss_dice: 0.2742  decode.d4.loss_cls: 1.1255  decode.d4.loss_mask: 0.1896  decode.d4.loss_dice: 0.2720  decode.d5.loss_cls: 1.0638  decode.d5.loss_mask: 0.1881  decode.d5.loss_dice: 0.2886  decode.d6.loss_cls: 1.0889  decode.d6.loss_mask: 0.2152  decode.d6.loss_dice: 0.2993  decode.d7.loss_cls: 1.0142  decode.d7.loss_mask: 0.2162  decode.d7.loss_dice: 0.3040  decode.d8.loss_cls: 1.0730  decode.d8.loss_mask: 0.1932  decode.d8.loss_dice: 0.2882
07/25 19:46:39 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250725_191538
07/25 19:46:39 - mmengine - INFO - Iter(train) [ 4000/80000]  base_lr: 9.5490e-05 lr: 9.5490e-06  eta: 9:41:20  time: 0.4369  data_time: 0.0091  memory: 5248  grad_norm: 238.9099  loss: 23.1565  decode.loss_cls: 1.1195  decode.loss_mask: 0.6149  decode.loss_dice: 0.5491  decode.d0.loss_cls: 1.8657  decode.d0.loss_mask: 0.5858  decode.d0.loss_dice: 0.6100  decode.d1.loss_cls: 1.3742  decode.d1.loss_mask: 0.5278  decode.d1.loss_dice: 0.5000  decode.d2.loss_cls: 1.1780  decode.d2.loss_mask: 0.6073  decode.d2.loss_dice: 0.4849  decode.d3.loss_cls: 1.0985  decode.d3.loss_mask: 0.6077  decode.d3.loss_dice: 0.5001  decode.d4.loss_cls: 1.1435  decode.d4.loss_mask: 0.5198  decode.d4.loss_dice: 0.4791  decode.d5.loss_cls: 1.1953  decode.d5.loss_mask: 0.5096  decode.d5.loss_dice: 0.4764  decode.d6.loss_cls: 1.1426  decode.d6.loss_mask: 0.5232  decode.d6.loss_dice: 0.4865  decode.d7.loss_cls: 1.1149  decode.d7.loss_mask: 0.5637  decode.d7.loss_dice: 0.5050  decode.d8.loss_cls: 1.1655  decode.d8.loss_mask: 0.5832  decode.d8.loss_dice: 0.5247
07/25 19:47:02 - mmengine - INFO - Iter(train) [ 4050/80000]  base_lr: 9.5433e-05 lr: 9.5433e-06  eta: 9:40:56  time: 0.4598  data_time: 0.0102  memory: 5265  grad_norm: 118.3499  loss: 17.1312  decode.loss_cls: 1.1549  decode.loss_mask: 0.2353  decode.loss_dice: 0.3176  decode.d0.loss_cls: 1.5928  decode.d0.loss_mask: 0.3134  decode.d0.loss_dice: 0.4148  decode.d1.loss_cls: 1.1488  decode.d1.loss_mask: 0.2699  decode.d1.loss_dice: 0.3359  decode.d2.loss_cls: 1.0050  decode.d2.loss_mask: 0.2752  decode.d2.loss_dice: 0.3353  decode.d3.loss_cls: 1.0192  decode.d3.loss_mask: 0.2385  decode.d3.loss_dice: 0.3232  decode.d4.loss_cls: 1.0054  decode.d4.loss_mask: 0.2424  decode.d4.loss_dice: 0.3338  decode.d5.loss_cls: 1.1352  decode.d5.loss_mask: 0.2323  decode.d5.loss_dice: 0.2961  decode.d6.loss_cls: 1.0045  decode.d6.loss_mask: 0.2430  decode.d6.loss_dice: 0.3285  decode.d7.loss_cls: 1.0777  decode.d7.loss_mask: 0.2515  decode.d7.loss_dice: 0.3339  decode.d8.loss_cls: 1.1318  decode.d8.loss_mask: 0.2359  decode.d8.loss_dice: 0.2993
07/25 19:47:25 - mmengine - INFO - Iter(train) [ 4100/80000]  base_lr: 9.5377e-05 lr: 9.5377e-06  eta: 9:40:32  time: 0.4592  data_time: 0.0101  memory: 5229  grad_norm: 101.5220  loss: 16.4817  decode.loss_cls: 0.8931  decode.loss_mask: 0.2863  decode.loss_dice: 0.3033  decode.d0.loss_cls: 1.6855  decode.d0.loss_mask: 0.2869  decode.d0.loss_dice: 0.3927  decode.d1.loss_cls: 1.0852  decode.d1.loss_mask: 0.3033  decode.d1.loss_dice: 0.3871  decode.d2.loss_cls: 0.9953  decode.d2.loss_mask: 0.3066  decode.d2.loss_dice: 0.3318  decode.d3.loss_cls: 0.8434  decode.d3.loss_mask: 0.2976  decode.d3.loss_dice: 0.3441  decode.d4.loss_cls: 1.0006  decode.d4.loss_mask: 0.2816  decode.d4.loss_dice: 0.3185  decode.d5.loss_cls: 0.9201  decode.d5.loss_mask: 0.2864  decode.d5.loss_dice: 0.3054  decode.d6.loss_cls: 0.8795  decode.d6.loss_mask: 0.2929  decode.d6.loss_dice: 0.3162  decode.d7.loss_cls: 0.9405  decode.d7.loss_mask: 0.3073  decode.d7.loss_dice: 0.3380  decode.d8.loss_cls: 0.9399  decode.d8.loss_mask: 0.2949  decode.d8.loss_dice: 0.3176
07/25 19:47:47 - mmengine - INFO - Iter(train) [ 4150/80000]  base_lr: 9.5320e-05 lr: 9.5320e-06  eta: 9:40:06  time: 0.4540  data_time: 0.0099  memory: 5265  grad_norm: 157.5535  loss: 18.3597  decode.loss_cls: 0.8633  decode.loss_mask: 0.4203  decode.loss_dice: 0.4750  decode.d0.loss_cls: 1.5260  decode.d0.loss_mask: 0.4544  decode.d0.loss_dice: 0.5500  decode.d1.loss_cls: 1.0138  decode.d1.loss_mask: 0.4362  decode.d1.loss_dice: 0.4411  decode.d2.loss_cls: 0.8619  decode.d2.loss_mask: 0.4156  decode.d2.loss_dice: 0.4348  decode.d3.loss_cls: 0.8279  decode.d3.loss_mask: 0.4169  decode.d3.loss_dice: 0.4382  decode.d4.loss_cls: 0.9530  decode.d4.loss_mask: 0.4065  decode.d4.loss_dice: 0.4357  decode.d5.loss_cls: 0.9396  decode.d5.loss_mask: 0.4036  decode.d5.loss_dice: 0.4595  decode.d6.loss_cls: 0.8182  decode.d6.loss_mask: 0.4192  decode.d6.loss_dice: 0.4529  decode.d7.loss_cls: 0.8322  decode.d7.loss_mask: 0.4200  decode.d7.loss_dice: 0.4604  decode.d8.loss_cls: 0.8700  decode.d8.loss_mask: 0.4330  decode.d8.loss_dice: 0.4807
07/25 19:48:10 - mmengine - INFO - Iter(train) [ 4200/80000]  base_lr: 9.5263e-05 lr: 9.5263e-06  eta: 9:39:41  time: 0.4587  data_time: 0.0101  memory: 5215  grad_norm: 127.3751  loss: 18.1493  decode.loss_cls: 0.8397  decode.loss_mask: 0.3342  decode.loss_dice: 0.4202  decode.d0.loss_cls: 1.5844  decode.d0.loss_mask: 0.4045  decode.d0.loss_dice: 0.4971  decode.d1.loss_cls: 1.1386  decode.d1.loss_mask: 0.3397  decode.d1.loss_dice: 0.4280  decode.d2.loss_cls: 0.9127  decode.d2.loss_mask: 0.3751  decode.d2.loss_dice: 0.4099  decode.d3.loss_cls: 1.0227  decode.d3.loss_mask: 0.3539  decode.d3.loss_dice: 0.3947  decode.d4.loss_cls: 0.9203  decode.d4.loss_mask: 0.3686  decode.d4.loss_dice: 0.4122  decode.d5.loss_cls: 0.9489  decode.d5.loss_mask: 0.3453  decode.d5.loss_dice: 0.4177  decode.d6.loss_cls: 1.0977  decode.d6.loss_mask: 0.3346  decode.d6.loss_dice: 0.4072  decode.d7.loss_cls: 1.0046  decode.d7.loss_mask: 0.3461  decode.d7.loss_dice: 0.3962  decode.d8.loss_cls: 0.9358  decode.d8.loss_mask: 0.3353  decode.d8.loss_dice: 0.4238
07/25 19:48:33 - mmengine - INFO - Iter(train) [ 4250/80000]  base_lr: 9.5207e-05 lr: 9.5207e-06  eta: 9:39:17  time: 0.4557  data_time: 0.0100  memory: 5249  grad_norm: 165.1013  loss: 17.8670  decode.loss_cls: 0.9663  decode.loss_mask: 0.3255  decode.loss_dice: 0.4375  decode.d0.loss_cls: 1.5090  decode.d0.loss_mask: 0.3561  decode.d0.loss_dice: 0.5370  decode.d1.loss_cls: 1.0935  decode.d1.loss_mask: 0.3493  decode.d1.loss_dice: 0.4411  decode.d2.loss_cls: 0.9155  decode.d2.loss_mask: 0.3279  decode.d2.loss_dice: 0.4739  decode.d3.loss_cls: 0.9470  decode.d3.loss_mask: 0.3242  decode.d3.loss_dice: 0.4301  decode.d4.loss_cls: 0.8799  decode.d4.loss_mask: 0.3270  decode.d4.loss_dice: 0.4126  decode.d5.loss_cls: 0.9067  decode.d5.loss_mask: 0.3235  decode.d5.loss_dice: 0.4762  decode.d6.loss_cls: 0.9667  decode.d6.loss_mask: 0.3342  decode.d6.loss_dice: 0.4305  decode.d7.loss_cls: 0.9537  decode.d7.loss_mask: 0.3292  decode.d7.loss_dice: 0.4141  decode.d8.loss_cls: 0.8995  decode.d8.loss_mask: 0.3340  decode.d8.loss_dice: 0.4455
07/25 19:48:56 - mmengine - INFO - Iter(train) [ 4300/80000]  base_lr: 9.5150e-05 lr: 9.5150e-06  eta: 9:38:49  time: 0.4584  data_time: 0.0102  memory: 5231  grad_norm: 133.6399  loss: 19.7873  decode.loss_cls: 0.9696  decode.loss_mask: 0.4472  decode.loss_dice: 0.4410  decode.d0.loss_cls: 1.8431  decode.d0.loss_mask: 0.4469  decode.d0.loss_dice: 0.5072  decode.d1.loss_cls: 1.3115  decode.d1.loss_mask: 0.4146  decode.d1.loss_dice: 0.4096  decode.d2.loss_cls: 0.9957  decode.d2.loss_mask: 0.4286  decode.d2.loss_dice: 0.4143  decode.d3.loss_cls: 0.9584  decode.d3.loss_mask: 0.4245  decode.d3.loss_dice: 0.4016  decode.d4.loss_cls: 1.0145  decode.d4.loss_mask: 0.4207  decode.d4.loss_dice: 0.4114  decode.d5.loss_cls: 1.0087  decode.d5.loss_mask: 0.4501  decode.d5.loss_dice: 0.4179  decode.d6.loss_cls: 0.9453  decode.d6.loss_mask: 0.4804  decode.d6.loss_dice: 0.4421  decode.d7.loss_cls: 1.0013  decode.d7.loss_mask: 0.4710  decode.d7.loss_dice: 0.4378  decode.d8.loss_cls: 1.0027  decode.d8.loss_mask: 0.4322  decode.d8.loss_dice: 0.4373
07/25 19:49:19 - mmengine - INFO - Iter(train) [ 4350/80000]  base_lr: 9.5094e-05 lr: 9.5094e-06  eta: 9:38:25  time: 0.4510  data_time: 0.0096  memory: 5266  grad_norm: 126.9499  loss: 17.5663  decode.loss_cls: 0.9177  decode.loss_mask: 0.3247  decode.loss_dice: 0.3627  decode.d0.loss_cls: 1.6837  decode.d0.loss_mask: 0.3451  decode.d0.loss_dice: 0.4429  decode.d1.loss_cls: 1.1962  decode.d1.loss_mask: 0.3605  decode.d1.loss_dice: 0.3723  decode.d2.loss_cls: 1.0175  decode.d2.loss_mask: 0.3155  decode.d2.loss_dice: 0.3574  decode.d3.loss_cls: 0.9589  decode.d3.loss_mask: 0.3283  decode.d3.loss_dice: 0.3495  decode.d4.loss_cls: 0.8999  decode.d4.loss_mask: 0.3336  decode.d4.loss_dice: 0.3629  decode.d5.loss_cls: 1.0372  decode.d5.loss_mask: 0.3090  decode.d5.loss_dice: 0.3546  decode.d6.loss_cls: 0.9943  decode.d6.loss_mask: 0.3219  decode.d6.loss_dice: 0.3586  decode.d7.loss_cls: 0.9257  decode.d7.loss_mask: 0.3373  decode.d7.loss_dice: 0.3612  decode.d8.loss_cls: 0.9230  decode.d8.loss_mask: 0.3402  decode.d8.loss_dice: 0.3739
07/25 19:49:41 - mmengine - INFO - Iter(train) [ 4400/80000]  base_lr: 9.5037e-05 lr: 9.5037e-06  eta: 9:37:57  time: 0.4564  data_time: 0.0101  memory: 5265  grad_norm: 124.9956  loss: 16.5978  decode.loss_cls: 0.8538  decode.loss_mask: 0.3429  decode.loss_dice: 0.4027  decode.d0.loss_cls: 1.6313  decode.d0.loss_mask: 0.3831  decode.d0.loss_dice: 0.4687  decode.d1.loss_cls: 0.9724  decode.d1.loss_mask: 0.3438  decode.d1.loss_dice: 0.3688  decode.d2.loss_cls: 0.7683  decode.d2.loss_mask: 0.3398  decode.d2.loss_dice: 0.4001  decode.d3.loss_cls: 0.7842  decode.d3.loss_mask: 0.3439  decode.d3.loss_dice: 0.4046  decode.d4.loss_cls: 0.8010  decode.d4.loss_mask: 0.3390  decode.d4.loss_dice: 0.4105  decode.d5.loss_cls: 0.8189  decode.d5.loss_mask: 0.3419  decode.d5.loss_dice: 0.4023  decode.d6.loss_cls: 0.8648  decode.d6.loss_mask: 0.3343  decode.d6.loss_dice: 0.3549  decode.d7.loss_cls: 0.8161  decode.d7.loss_mask: 0.3499  decode.d7.loss_dice: 0.3916  decode.d8.loss_cls: 0.8526  decode.d8.loss_mask: 0.3457  decode.d8.loss_dice: 0.3658
07/25 19:50:04 - mmengine - INFO - Iter(train) [ 4450/80000]  base_lr: 9.4981e-05 lr: 9.4981e-06  eta: 9:37:31  time: 0.4601  data_time: 0.0102  memory: 5215  grad_norm: 226.1704  loss: 17.6617  decode.loss_cls: 0.9320  decode.loss_mask: 0.3074  decode.loss_dice: 0.4296  decode.d0.loss_cls: 1.6745  decode.d0.loss_mask: 0.3240  decode.d0.loss_dice: 0.4932  decode.d1.loss_cls: 1.1140  decode.d1.loss_mask: 0.2920  decode.d1.loss_dice: 0.3986  decode.d2.loss_cls: 1.0360  decode.d2.loss_mask: 0.2794  decode.d2.loss_dice: 0.4156  decode.d3.loss_cls: 0.9502  decode.d3.loss_mask: 0.2936  decode.d3.loss_dice: 0.4333  decode.d4.loss_cls: 0.9131  decode.d4.loss_mask: 0.2975  decode.d4.loss_dice: 0.4178  decode.d5.loss_cls: 0.8994  decode.d5.loss_mask: 0.3113  decode.d5.loss_dice: 0.4364  decode.d6.loss_cls: 0.9057  decode.d6.loss_mask: 0.3132  decode.d6.loss_dice: 0.4351  decode.d7.loss_cls: 0.8688  decode.d7.loss_mask: 0.3467  decode.d7.loss_dice: 0.4503  decode.d8.loss_cls: 0.9335  decode.d8.loss_mask: 0.3315  decode.d8.loss_dice: 0.4281
07/25 19:50:27 - mmengine - INFO - Iter(train) [ 4500/80000]  base_lr: 9.4924e-05 lr: 9.4924e-06  eta: 9:37:07  time: 0.4619  data_time: 0.0102  memory: 5249  grad_norm: 129.3826  loss: 15.7598  decode.loss_cls: 0.7798  decode.loss_mask: 0.3400  decode.loss_dice: 0.4118  decode.d0.loss_cls: 1.4118  decode.d0.loss_mask: 0.3437  decode.d0.loss_dice: 0.4582  decode.d1.loss_cls: 0.8610  decode.d1.loss_mask: 0.3220  decode.d1.loss_dice: 0.3890  decode.d2.loss_cls: 0.7654  decode.d2.loss_mask: 0.3280  decode.d2.loss_dice: 0.3976  decode.d3.loss_cls: 0.7195  decode.d3.loss_mask: 0.3255  decode.d3.loss_dice: 0.3626  decode.d4.loss_cls: 0.7142  decode.d4.loss_mask: 0.3347  decode.d4.loss_dice: 0.4251  decode.d5.loss_cls: 0.7432  decode.d5.loss_mask: 0.3552  decode.d5.loss_dice: 0.4259  decode.d6.loss_cls: 0.7334  decode.d6.loss_mask: 0.3410  decode.d6.loss_dice: 0.4133  decode.d7.loss_cls: 0.7338  decode.d7.loss_mask: 0.3523  decode.d7.loss_dice: 0.4095  decode.d8.loss_cls: 0.7907  decode.d8.loss_mask: 0.3551  decode.d8.loss_dice: 0.4165
07/25 19:50:50 - mmengine - INFO - Iter(train) [ 4550/80000]  base_lr: 9.4867e-05 lr: 9.4867e-06  eta: 9:36:45  time: 0.4639  data_time: 0.0101  memory: 5249  grad_norm: 121.9512  loss: 17.7299  decode.loss_cls: 0.8549  decode.loss_mask: 0.3929  decode.loss_dice: 0.4050  decode.d0.loss_cls: 1.6827  decode.d0.loss_mask: 0.4112  decode.d0.loss_dice: 0.4871  decode.d1.loss_cls: 1.0343  decode.d1.loss_mask: 0.3862  decode.d1.loss_dice: 0.4250  decode.d2.loss_cls: 0.8428  decode.d2.loss_mask: 0.3942  decode.d2.loss_dice: 0.4063  decode.d3.loss_cls: 0.8056  decode.d3.loss_mask: 0.4006  decode.d3.loss_dice: 0.4390  decode.d4.loss_cls: 0.7305  decode.d4.loss_mask: 0.4453  decode.d4.loss_dice: 0.4414  decode.d5.loss_cls: 0.7930  decode.d5.loss_mask: 0.4452  decode.d5.loss_dice: 0.4269  decode.d6.loss_cls: 0.8637  decode.d6.loss_mask: 0.4122  decode.d6.loss_dice: 0.4281  decode.d7.loss_cls: 0.8350  decode.d7.loss_mask: 0.3905  decode.d7.loss_dice: 0.4598  decode.d8.loss_cls: 0.8392  decode.d8.loss_mask: 0.3977  decode.d8.loss_dice: 0.4536
07/25 19:51:13 - mmengine - INFO - Iter(train) [ 4600/80000]  base_lr: 9.4811e-05 lr: 9.4811e-06  eta: 9:36:20  time: 0.4565  data_time: 0.0103  memory: 5293  grad_norm: 120.0205  loss: 14.5562  decode.loss_cls: 0.6428  decode.loss_mask: 0.3264  decode.loss_dice: 0.3993  decode.d0.loss_cls: 1.4980  decode.d0.loss_mask: 0.3308  decode.d0.loss_dice: 0.4888  decode.d1.loss_cls: 0.7762  decode.d1.loss_mask: 0.3011  decode.d1.loss_dice: 0.4297  decode.d2.loss_cls: 0.7136  decode.d2.loss_mask: 0.2952  decode.d2.loss_dice: 0.4038  decode.d3.loss_cls: 0.6936  decode.d3.loss_mask: 0.2925  decode.d3.loss_dice: 0.3876  decode.d4.loss_cls: 0.6342  decode.d4.loss_mask: 0.2889  decode.d4.loss_dice: 0.3908  decode.d5.loss_cls: 0.5847  decode.d5.loss_mask: 0.3032  decode.d5.loss_dice: 0.4176  decode.d6.loss_cls: 0.6268  decode.d6.loss_mask: 0.2894  decode.d6.loss_dice: 0.3944  decode.d7.loss_cls: 0.5996  decode.d7.loss_mask: 0.2942  decode.d7.loss_dice: 0.4121  decode.d8.loss_cls: 0.6041  decode.d8.loss_mask: 0.3277  decode.d8.loss_dice: 0.4091
07/25 19:51:36 - mmengine - INFO - Iter(train) [ 4650/80000]  base_lr: 9.4754e-05 lr: 9.4754e-06  eta: 9:35:55  time: 0.4494  data_time: 0.0096  memory: 5249  grad_norm: 143.8974  loss: 17.6287  decode.loss_cls: 0.9370  decode.loss_mask: 0.4085  decode.loss_dice: 0.4033  decode.d0.loss_cls: 1.6483  decode.d0.loss_mask: 0.3569  decode.d0.loss_dice: 0.4767  decode.d1.loss_cls: 1.1369  decode.d1.loss_mask: 0.3573  decode.d1.loss_dice: 0.3832  decode.d2.loss_cls: 0.8704  decode.d2.loss_mask: 0.3766  decode.d2.loss_dice: 0.3753  decode.d3.loss_cls: 0.9876  decode.d3.loss_mask: 0.3514  decode.d3.loss_dice: 0.3526  decode.d4.loss_cls: 0.8877  decode.d4.loss_mask: 0.3484  decode.d4.loss_dice: 0.3535  decode.d5.loss_cls: 0.9082  decode.d5.loss_mask: 0.3574  decode.d5.loss_dice: 0.3824  decode.d6.loss_cls: 0.8689  decode.d6.loss_mask: 0.3750  decode.d6.loss_dice: 0.3771  decode.d7.loss_cls: 0.9112  decode.d7.loss_mask: 0.3639  decode.d7.loss_dice: 0.3630  decode.d8.loss_cls: 0.9272  decode.d8.loss_mask: 0.3935  decode.d8.loss_dice: 0.3893
07/25 19:51:58 - mmengine - INFO - Iter(train) [ 4700/80000]  base_lr: 9.4698e-05 lr: 9.4698e-06  eta: 9:35:29  time: 0.4555  data_time: 0.0096  memory: 5265  grad_norm: 173.3179  loss: 18.9583  decode.loss_cls: 1.0488  decode.loss_mask: 0.3004  decode.loss_dice: 0.4313  decode.d0.loss_cls: 1.7195  decode.d0.loss_mask: 0.3854  decode.d0.loss_dice: 0.5385  decode.d1.loss_cls: 1.2393  decode.d1.loss_mask: 0.3208  decode.d1.loss_dice: 0.4494  decode.d2.loss_cls: 1.1305  decode.d2.loss_mask: 0.3090  decode.d2.loss_dice: 0.4295  decode.d3.loss_cls: 1.1384  decode.d3.loss_mask: 0.3139  decode.d3.loss_dice: 0.4227  decode.d4.loss_cls: 1.0953  decode.d4.loss_mask: 0.3013  decode.d4.loss_dice: 0.4189  decode.d5.loss_cls: 1.1347  decode.d5.loss_mask: 0.2927  decode.d5.loss_dice: 0.3848  decode.d6.loss_cls: 1.0165  decode.d6.loss_mask: 0.2976  decode.d6.loss_dice: 0.4060  decode.d7.loss_cls: 0.9686  decode.d7.loss_mask: 0.3010  decode.d7.loss_dice: 0.4203  decode.d8.loss_cls: 0.9584  decode.d8.loss_mask: 0.3331  decode.d8.loss_dice: 0.4516
07/25 19:52:21 - mmengine - INFO - Iter(train) [ 4750/80000]  base_lr: 9.4641e-05 lr: 9.4641e-06  eta: 9:34:57  time: 0.4609  data_time: 0.0099  memory: 5249  grad_norm: 129.6185  loss: 17.0477  decode.loss_cls: 0.8342  decode.loss_mask: 0.3086  decode.loss_dice: 0.3727  decode.d0.loss_cls: 1.7565  decode.d0.loss_mask: 0.3230  decode.d0.loss_dice: 0.4437  decode.d1.loss_cls: 1.1171  decode.d1.loss_mask: 0.3246  decode.d1.loss_dice: 0.3915  decode.d2.loss_cls: 0.8944  decode.d2.loss_mask: 0.3039  decode.d2.loss_dice: 0.3768  decode.d3.loss_cls: 0.8431  decode.d3.loss_mask: 0.3005  decode.d3.loss_dice: 0.3647  decode.d4.loss_cls: 0.8860  decode.d4.loss_mask: 0.3264  decode.d4.loss_dice: 0.3883  decode.d5.loss_cls: 0.8926  decode.d5.loss_mask: 0.3751  decode.d5.loss_dice: 0.4202  decode.d6.loss_cls: 0.8955  decode.d6.loss_mask: 0.3631  decode.d6.loss_dice: 0.4348  decode.d7.loss_cls: 0.8323  decode.d7.loss_mask: 0.3079  decode.d7.loss_dice: 0.3841  decode.d8.loss_cls: 0.8933  decode.d8.loss_mask: 0.3158  decode.d8.loss_dice: 0.3770
07/25 19:52:44 - mmengine - INFO - Iter(train) [ 4800/80000]  base_lr: 9.4584e-05 lr: 9.4584e-06  eta: 9:34:34  time: 0.4584  data_time: 0.0100  memory: 5249  grad_norm: 137.6224  loss: 16.4946  decode.loss_cls: 0.8495  decode.loss_mask: 0.3313  decode.loss_dice: 0.4111  decode.d0.loss_cls: 1.5960  decode.d0.loss_mask: 0.3018  decode.d0.loss_dice: 0.4151  decode.d1.loss_cls: 1.0940  decode.d1.loss_mask: 0.3039  decode.d1.loss_dice: 0.3511  decode.d2.loss_cls: 0.8542  decode.d2.loss_mask: 0.2987  decode.d2.loss_dice: 0.3533  decode.d3.loss_cls: 0.8165  decode.d3.loss_mask: 0.3004  decode.d3.loss_dice: 0.3550  decode.d4.loss_cls: 0.8189  decode.d4.loss_mask: 0.2997  decode.d4.loss_dice: 0.3698  decode.d5.loss_cls: 0.8835  decode.d5.loss_mask: 0.3081  decode.d5.loss_dice: 0.3794  decode.d6.loss_cls: 0.8250  decode.d6.loss_mask: 0.3018  decode.d6.loss_dice: 0.3620  decode.d7.loss_cls: 0.9702  decode.d7.loss_mask: 0.3008  decode.d7.loss_dice: 0.4014  decode.d8.loss_cls: 0.8717  decode.d8.loss_mask: 0.3492  decode.d8.loss_dice: 0.4211
07/25 19:53:06 - mmengine - INFO - Iter(train) [ 4850/80000]  base_lr: 9.4528e-05 lr: 9.4528e-06  eta: 9:34:10  time: 0.4585  data_time: 0.0102  memory: 5228  grad_norm: 117.3069  loss: 15.0358  decode.loss_cls: 0.7537  decode.loss_mask: 0.3021  decode.loss_dice: 0.4044  decode.d0.loss_cls: 1.5805  decode.d0.loss_mask: 0.3168  decode.d0.loss_dice: 0.4401  decode.d1.loss_cls: 0.8974  decode.d1.loss_mask: 0.2451  decode.d1.loss_dice: 0.3634  decode.d2.loss_cls: 0.8621  decode.d2.loss_mask: 0.2407  decode.d2.loss_dice: 0.3417  decode.d3.loss_cls: 0.8054  decode.d3.loss_mask: 0.2410  decode.d3.loss_dice: 0.3573  decode.d4.loss_cls: 0.7119  decode.d4.loss_mask: 0.2409  decode.d4.loss_dice: 0.3552  decode.d5.loss_cls: 0.7292  decode.d5.loss_mask: 0.2380  decode.d5.loss_dice: 0.3714  decode.d6.loss_cls: 0.6917  decode.d6.loss_mask: 0.3096  decode.d6.loss_dice: 0.3798  decode.d7.loss_cls: 0.7145  decode.d7.loss_mask: 0.3208  decode.d7.loss_dice: 0.3679  decode.d8.loss_cls: 0.7599  decode.d8.loss_mask: 0.2972  decode.d8.loss_dice: 0.3958
07/25 19:53:29 - mmengine - INFO - Iter(train) [ 4900/80000]  base_lr: 9.4471e-05 lr: 9.4471e-06  eta: 9:33:45  time: 0.4543  data_time: 0.0101  memory: 5309  grad_norm: 146.5828  loss: 16.2515  decode.loss_cls: 0.6535  decode.loss_mask: 0.3988  decode.loss_dice: 0.3946  decode.d0.loss_cls: 1.6931  decode.d0.loss_mask: 0.3708  decode.d0.loss_dice: 0.4621  decode.d1.loss_cls: 1.0627  decode.d1.loss_mask: 0.3674  decode.d1.loss_dice: 0.3889  decode.d2.loss_cls: 0.8011  decode.d2.loss_mask: 0.3626  decode.d2.loss_dice: 0.3847  decode.d3.loss_cls: 0.7822  decode.d3.loss_mask: 0.3880  decode.d3.loss_dice: 0.3616  decode.d4.loss_cls: 0.7425  decode.d4.loss_mask: 0.3932  decode.d4.loss_dice: 0.3800  decode.d5.loss_cls: 0.7325  decode.d5.loss_mask: 0.3875  decode.d5.loss_dice: 0.3728  decode.d6.loss_cls: 0.6830  decode.d6.loss_mask: 0.3837  decode.d6.loss_dice: 0.3646  decode.d7.loss_cls: 0.7207  decode.d7.loss_mask: 0.3589  decode.d7.loss_dice: 0.3735  decode.d8.loss_cls: 0.6662  decode.d8.loss_mask: 0.4101  decode.d8.loss_dice: 0.4103
07/25 19:53:52 - mmengine - INFO - Iter(train) [ 4950/80000]  base_lr: 9.4415e-05 lr: 9.4415e-06  eta: 9:33:20  time: 0.4558  data_time: 0.0102  memory: 5231  grad_norm: 109.0070  loss: 16.3472  decode.loss_cls: 0.7160  decode.loss_mask: 0.3582  decode.loss_dice: 0.4089  decode.d0.loss_cls: 1.6146  decode.d0.loss_mask: 0.4120  decode.d0.loss_dice: 0.4973  decode.d1.loss_cls: 1.0456  decode.d1.loss_mask: 0.3721  decode.d1.loss_dice: 0.4258  decode.d2.loss_cls: 0.7359  decode.d2.loss_mask: 0.3682  decode.d2.loss_dice: 0.4398  decode.d3.loss_cls: 0.7628  decode.d3.loss_mask: 0.3581  decode.d3.loss_dice: 0.4333  decode.d4.loss_cls: 0.7553  decode.d4.loss_mask: 0.3620  decode.d4.loss_dice: 0.3916  decode.d5.loss_cls: 0.7693  decode.d5.loss_mask: 0.3545  decode.d5.loss_dice: 0.3836  decode.d6.loss_cls: 0.7442  decode.d6.loss_mask: 0.3661  decode.d6.loss_dice: 0.3677  decode.d7.loss_cls: 0.6902  decode.d7.loss_mask: 0.3639  decode.d7.loss_dice: 0.3636  decode.d8.loss_cls: 0.7139  decode.d8.loss_mask: 0.3671  decode.d8.loss_dice: 0.4055
07/25 19:54:15 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250725_191538
07/25 19:54:15 - mmengine - INFO - Iter(train) [ 5000/80000]  base_lr: 9.4358e-05 lr: 9.4358e-06  eta: 9:32:55  time: 0.4548  data_time: 0.0104  memory: 5249  grad_norm: 103.9981  loss: 17.2588  decode.loss_cls: 0.8499  decode.loss_mask: 0.3678  decode.loss_dice: 0.4327  decode.d0.loss_cls: 1.6922  decode.d0.loss_mask: 0.3594  decode.d0.loss_dice: 0.5049  decode.d1.loss_cls: 1.1525  decode.d1.loss_mask: 0.3392  decode.d1.loss_dice: 0.3945  decode.d2.loss_cls: 0.8693  decode.d2.loss_mask: 0.3366  decode.d2.loss_dice: 0.3995  decode.d3.loss_cls: 0.8205  decode.d3.loss_mask: 0.3439  decode.d3.loss_dice: 0.4268  decode.d4.loss_cls: 0.8132  decode.d4.loss_mask: 0.3455  decode.d4.loss_dice: 0.3997  decode.d5.loss_cls: 0.8349  decode.d5.loss_mask: 0.3420  decode.d5.loss_dice: 0.4060  decode.d6.loss_cls: 0.8829  decode.d6.loss_mask: 0.3329  decode.d6.loss_dice: 0.3977  decode.d7.loss_cls: 0.8468  decode.d7.loss_mask: 0.3423  decode.d7.loss_dice: 0.3882  decode.d8.loss_cls: 0.8833  decode.d8.loss_mask: 0.3546  decode.d8.loss_dice: 0.3988
07/25 19:54:15 - mmengine - INFO - Saving checkpoint at 5000 iterations
07/25 19:54:39 - mmengine - INFO - Iter(train) [ 5050/80000]  base_lr: 9.4301e-05 lr: 9.4301e-06  eta: 9:32:56  time: 0.4577  data_time: 0.0104  memory: 5231  grad_norm: 180.5768  loss: 16.1646  decode.loss_cls: 0.7287  decode.loss_mask: 0.3528  decode.loss_dice: 0.4069  decode.d0.loss_cls: 1.3888  decode.d0.loss_mask: 0.3966  decode.d0.loss_dice: 0.4444  decode.d1.loss_cls: 1.0756  decode.d1.loss_mask: 0.3485  decode.d1.loss_dice: 0.3711  decode.d2.loss_cls: 0.7624  decode.d2.loss_mask: 0.3175  decode.d2.loss_dice: 0.3863  decode.d3.loss_cls: 0.7414  decode.d3.loss_mask: 0.3513  decode.d3.loss_dice: 0.4031  decode.d4.loss_cls: 0.8730  decode.d4.loss_mask: 0.3254  decode.d4.loss_dice: 0.3830  decode.d5.loss_cls: 0.7990  decode.d5.loss_mask: 0.3304  decode.d5.loss_dice: 0.4023  decode.d6.loss_cls: 0.7704  decode.d6.loss_mask: 0.3419  decode.d6.loss_dice: 0.3986  decode.d7.loss_cls: 0.8146  decode.d7.loss_mask: 0.3362  decode.d7.loss_dice: 0.3885  decode.d8.loss_cls: 0.7726  decode.d8.loss_mask: 0.3540  decode.d8.loss_dice: 0.3991
07/25 19:55:02 - mmengine - INFO - Iter(train) [ 5100/80000]  base_lr: 9.4245e-05 lr: 9.4245e-06  eta: 9:32:32  time: 0.4501  data_time: 0.0097  memory: 5266  grad_norm: 173.7532  loss: 17.8074  decode.loss_cls: 0.8725  decode.loss_mask: 0.4000  decode.loss_dice: 0.3802  decode.d0.loss_cls: 1.6975  decode.d0.loss_mask: 0.4151  decode.d0.loss_dice: 0.4255  decode.d1.loss_cls: 1.1213  decode.d1.loss_mask: 0.3594  decode.d1.loss_dice: 0.3670  decode.d2.loss_cls: 0.9202  decode.d2.loss_mask: 0.3404  decode.d2.loss_dice: 0.3549  decode.d3.loss_cls: 0.9469  decode.d3.loss_mask: 0.3249  decode.d3.loss_dice: 0.3286  decode.d4.loss_cls: 0.9274  decode.d4.loss_mask: 0.3633  decode.d4.loss_dice: 0.3709  decode.d5.loss_cls: 0.8991  decode.d5.loss_mask: 0.3832  decode.d5.loss_dice: 0.3722  decode.d6.loss_cls: 0.9333  decode.d6.loss_mask: 0.4023  decode.d6.loss_dice: 0.4105  decode.d7.loss_cls: 0.9547  decode.d7.loss_mask: 0.3763  decode.d7.loss_dice: 0.4139  decode.d8.loss_cls: 0.9058  decode.d8.loss_mask: 0.4350  decode.d8.loss_dice: 0.4049
07/25 19:55:25 - mmengine - INFO - Iter(train) [ 5150/80000]  base_lr: 9.4188e-05 lr: 9.4188e-06  eta: 9:32:06  time: 0.4544  data_time: 0.0102  memory: 5249  grad_norm: 163.6156  loss: 12.7962  decode.loss_cls: 0.5841  decode.loss_mask: 0.2960  decode.loss_dice: 0.3329  decode.d0.loss_cls: 1.5052  decode.d0.loss_mask: 0.3004  decode.d0.loss_dice: 0.3832  decode.d1.loss_cls: 0.7097  decode.d1.loss_mask: 0.2589  decode.d1.loss_dice: 0.3220  decode.d2.loss_cls: 0.5718  decode.d2.loss_mask: 0.2724  decode.d2.loss_dice: 0.3330  decode.d3.loss_cls: 0.5645  decode.d3.loss_mask: 0.2627  decode.d3.loss_dice: 0.3232  decode.d4.loss_cls: 0.5438  decode.d4.loss_mask: 0.2626  decode.d4.loss_dice: 0.3155  decode.d5.loss_cls: 0.5791  decode.d5.loss_mask: 0.2530  decode.d5.loss_dice: 0.3201  decode.d6.loss_cls: 0.5995  decode.d6.loss_mask: 0.2488  decode.d6.loss_dice: 0.2894  decode.d7.loss_cls: 0.6500  decode.d7.loss_mask: 0.2536  decode.d7.loss_dice: 0.3079  decode.d8.loss_cls: 0.5465  decode.d8.loss_mask: 0.2865  decode.d8.loss_dice: 0.3201
07/25 19:55:48 - mmengine - INFO - Iter(train) [ 5200/80000]  base_lr: 9.4132e-05 lr: 9.4132e-06  eta: 9:31:42  time: 0.4564  data_time: 0.0099  memory: 5265  grad_norm: 118.0432  loss: 13.4091  decode.loss_cls: 0.6080  decode.loss_mask: 0.2759  decode.loss_dice: 0.2930  decode.d0.loss_cls: 1.6484  decode.d0.loss_mask: 0.2625  decode.d0.loss_dice: 0.3798  decode.d1.loss_cls: 0.8526  decode.d1.loss_mask: 0.2598  decode.d1.loss_dice: 0.3129  decode.d2.loss_cls: 0.6717  decode.d2.loss_mask: 0.2896  decode.d2.loss_dice: 0.3044  decode.d3.loss_cls: 0.6178  decode.d3.loss_mask: 0.2707  decode.d3.loss_dice: 0.3052  decode.d4.loss_cls: 0.6323  decode.d4.loss_mask: 0.2455  decode.d4.loss_dice: 0.3072  decode.d5.loss_cls: 0.6780  decode.d5.loss_mask: 0.2657  decode.d5.loss_dice: 0.3031  decode.d6.loss_cls: 0.6420  decode.d6.loss_mask: 0.2650  decode.d6.loss_dice: 0.2931  decode.d7.loss_cls: 0.6327  decode.d7.loss_mask: 0.2811  decode.d7.loss_dice: 0.3111  decode.d8.loss_cls: 0.6148  decode.d8.loss_mask: 0.2768  decode.d8.loss_dice: 0.3083
07/25 19:56:11 - mmengine - INFO - Iter(train) [ 5250/80000]  base_lr: 9.4075e-05 lr: 9.4075e-06  eta: 9:31:18  time: 0.4551  data_time: 0.0100  memory: 5231  grad_norm: 115.2730  loss: 16.3871  decode.loss_cls: 0.9851  decode.loss_mask: 0.2211  decode.loss_dice: 0.3178  decode.d0.loss_cls: 1.9506  decode.d0.loss_mask: 0.2400  decode.d0.loss_dice: 0.3924  decode.d1.loss_cls: 1.1105  decode.d1.loss_mask: 0.2327  decode.d1.loss_dice: 0.3343  decode.d2.loss_cls: 0.9840  decode.d2.loss_mask: 0.2297  decode.d2.loss_dice: 0.3061  decode.d3.loss_cls: 0.9615  decode.d3.loss_mask: 0.2410  decode.d3.loss_dice: 0.3356  decode.d4.loss_cls: 0.8520  decode.d4.loss_mask: 0.2798  decode.d4.loss_dice: 0.3481  decode.d5.loss_cls: 1.0136  decode.d5.loss_mask: 0.2396  decode.d5.loss_dice: 0.3417  decode.d6.loss_cls: 0.9141  decode.d6.loss_mask: 0.2192  decode.d6.loss_dice: 0.3194  decode.d7.loss_cls: 0.9265  decode.d7.loss_mask: 0.2321  decode.d7.loss_dice: 0.3258  decode.d8.loss_cls: 0.9653  decode.d8.loss_mask: 0.2334  decode.d8.loss_dice: 0.3342
07/25 19:56:33 - mmengine - INFO - Iter(train) [ 5300/80000]  base_lr: 9.4018e-05 lr: 9.4018e-06  eta: 9:30:53  time: 0.4553  data_time: 0.0101  memory: 5249  grad_norm: 107.7891  loss: 14.1225  decode.loss_cls: 0.6759  decode.loss_mask: 0.3038  decode.loss_dice: 0.3368  decode.d0.loss_cls: 1.5819  decode.d0.loss_mask: 0.3039  decode.d0.loss_dice: 0.3786  decode.d1.loss_cls: 0.7588  decode.d1.loss_mask: 0.3079  decode.d1.loss_dice: 0.3506  decode.d2.loss_cls: 0.6732  decode.d2.loss_mask: 0.3024  decode.d2.loss_dice: 0.3410  decode.d3.loss_cls: 0.6610  decode.d3.loss_mask: 0.2995  decode.d3.loss_dice: 0.3370  decode.d4.loss_cls: 0.6951  decode.d4.loss_mask: 0.3031  decode.d4.loss_dice: 0.3394  decode.d5.loss_cls: 0.6812  decode.d5.loss_mask: 0.3074  decode.d5.loss_dice: 0.3477  decode.d6.loss_cls: 0.6267  decode.d6.loss_mask: 0.2979  decode.d6.loss_dice: 0.3422  decode.d7.loss_cls: 0.6320  decode.d7.loss_mask: 0.3132  decode.d7.loss_dice: 0.3425  decode.d8.loss_cls: 0.6392  decode.d8.loss_mask: 0.3085  decode.d8.loss_dice: 0.3343
07/25 19:56:56 - mmengine - INFO - Iter(train) [ 5350/80000]  base_lr: 9.3962e-05 lr: 9.3962e-06  eta: 9:30:28  time: 0.4548  data_time: 0.0101  memory: 5249  grad_norm: 137.7578  loss: 13.4566  decode.loss_cls: 0.6196  decode.loss_mask: 0.3015  decode.loss_dice: 0.3052  decode.d0.loss_cls: 1.6186  decode.d0.loss_mask: 0.2873  decode.d0.loss_dice: 0.3466  decode.d1.loss_cls: 0.7089  decode.d1.loss_mask: 0.3195  decode.d1.loss_dice: 0.3331  decode.d2.loss_cls: 0.5711  decode.d2.loss_mask: 0.3144  decode.d2.loss_dice: 0.2877  decode.d3.loss_cls: 0.5612  decode.d3.loss_mask: 0.3312  decode.d3.loss_dice: 0.3078  decode.d4.loss_cls: 0.6128  decode.d4.loss_mask: 0.3160  decode.d4.loss_dice: 0.3026  decode.d5.loss_cls: 0.5818  decode.d5.loss_mask: 0.3111  decode.d5.loss_dice: 0.3312  decode.d6.loss_cls: 0.6060  decode.d6.loss_mask: 0.3187  decode.d6.loss_dice: 0.3007  decode.d7.loss_cls: 0.6063  decode.d7.loss_mask: 0.3335  decode.d7.loss_dice: 0.3276  decode.d8.loss_cls: 0.6434  decode.d8.loss_mask: 0.3206  decode.d8.loss_dice: 0.3306
07/25 19:57:19 - mmengine - INFO - Iter(train) [ 5400/80000]  base_lr: 9.3905e-05 lr: 9.3905e-06  eta: 9:30:02  time: 0.4354  data_time: 0.0085  memory: 5249  grad_norm: 116.3233  loss: 16.2808  decode.loss_cls: 0.9045  decode.loss_mask: 0.3245  decode.loss_dice: 0.4007  decode.d0.loss_cls: 1.7277  decode.d0.loss_mask: 0.2756  decode.d0.loss_dice: 0.4056  decode.d1.loss_cls: 0.9399  decode.d1.loss_mask: 0.2888  decode.d1.loss_dice: 0.4108  decode.d2.loss_cls: 0.8520  decode.d2.loss_mask: 0.2957  decode.d2.loss_dice: 0.3613  decode.d3.loss_cls: 0.8916  decode.d3.loss_mask: 0.2917  decode.d3.loss_dice: 0.3580  decode.d4.loss_cls: 0.8499  decode.d4.loss_mask: 0.2898  decode.d4.loss_dice: 0.3640  decode.d5.loss_cls: 0.7907  decode.d5.loss_mask: 0.2933  decode.d5.loss_dice: 0.3716  decode.d6.loss_cls: 0.7768  decode.d6.loss_mask: 0.3072  decode.d6.loss_dice: 0.4103  decode.d7.loss_cls: 0.8557  decode.d7.loss_mask: 0.2959  decode.d7.loss_dice: 0.3961  decode.d8.loss_cls: 0.8207  decode.d8.loss_mask: 0.3063  decode.d8.loss_dice: 0.4240
07/25 19:57:42 - mmengine - INFO - Iter(train) [ 5450/80000]  base_lr: 9.3848e-05 lr: 9.3848e-06  eta: 9:29:39  time: 0.4566  data_time: 0.0099  memory: 5307  grad_norm: 161.8180  loss: 17.9777  decode.loss_cls: 0.9538  decode.loss_mask: 0.3646  decode.loss_dice: 0.4185  decode.d0.loss_cls: 1.7075  decode.d0.loss_mask: 0.4097  decode.d0.loss_dice: 0.5137  decode.d1.loss_cls: 1.0521  decode.d1.loss_mask: 0.3241  decode.d1.loss_dice: 0.3964  decode.d2.loss_cls: 0.8946  decode.d2.loss_mask: 0.3241  decode.d2.loss_dice: 0.3825  decode.d3.loss_cls: 0.9317  decode.d3.loss_mask: 0.3296  decode.d3.loss_dice: 0.3809  decode.d4.loss_cls: 0.9173  decode.d4.loss_mask: 0.3278  decode.d4.loss_dice: 0.3991  decode.d5.loss_cls: 0.9477  decode.d5.loss_mask: 0.3401  decode.d5.loss_dice: 0.3815  decode.d6.loss_cls: 1.0221  decode.d6.loss_mask: 0.3534  decode.d6.loss_dice: 0.3737  decode.d7.loss_cls: 0.9923  decode.d7.loss_mask: 0.3561  decode.d7.loss_dice: 0.3822  decode.d8.loss_cls: 0.9883  decode.d8.loss_mask: 0.3938  decode.d8.loss_dice: 0.4185
07/25 19:58:05 - mmengine - INFO - Iter(train) [ 5500/80000]  base_lr: 9.3792e-05 lr: 9.3792e-06  eta: 9:29:14  time: 0.4603  data_time: 0.0099  memory: 5249  grad_norm: 120.1302  loss: 15.0740  decode.loss_cls: 0.7274  decode.loss_mask: 0.3658  decode.loss_dice: 0.3318  decode.d0.loss_cls: 1.5047  decode.d0.loss_mask: 0.3387  decode.d0.loss_dice: 0.3834  decode.d1.loss_cls: 0.8990  decode.d1.loss_mask: 0.3196  decode.d1.loss_dice: 0.3279  decode.d2.loss_cls: 0.7323  decode.d2.loss_mask: 0.3578  decode.d2.loss_dice: 0.3362  decode.d3.loss_cls: 0.7804  decode.d3.loss_mask: 0.3170  decode.d3.loss_dice: 0.3168  decode.d4.loss_cls: 0.7985  decode.d4.loss_mask: 0.3228  decode.d4.loss_dice: 0.3255  decode.d5.loss_cls: 0.7421  decode.d5.loss_mask: 0.3448  decode.d5.loss_dice: 0.3177  decode.d6.loss_cls: 0.7135  decode.d6.loss_mask: 0.3681  decode.d6.loss_dice: 0.3217  decode.d7.loss_cls: 0.6718  decode.d7.loss_mask: 0.3584  decode.d7.loss_dice: 0.3272  decode.d8.loss_cls: 0.7317  decode.d8.loss_mask: 0.3496  decode.d8.loss_dice: 0.3420
07/25 19:58:27 - mmengine - INFO - Iter(train) [ 5550/80000]  base_lr: 9.3735e-05 lr: 9.3735e-06  eta: 9:28:49  time: 0.4616  data_time: 0.0106  memory: 5231  grad_norm: 94.7624  loss: 14.1704  decode.loss_cls: 0.7800  decode.loss_mask: 0.2489  decode.loss_dice: 0.3263  decode.d0.loss_cls: 1.6232  decode.d0.loss_mask: 0.2566  decode.d0.loss_dice: 0.3818  decode.d1.loss_cls: 0.9233  decode.d1.loss_mask: 0.2491  decode.d1.loss_dice: 0.3457  decode.d2.loss_cls: 0.7289  decode.d2.loss_mask: 0.2484  decode.d2.loss_dice: 0.3331  decode.d3.loss_cls: 0.7088  decode.d3.loss_mask: 0.2456  decode.d3.loss_dice: 0.3099  decode.d4.loss_cls: 0.7105  decode.d4.loss_mask: 0.2480  decode.d4.loss_dice: 0.3194  decode.d5.loss_cls: 0.7137  decode.d5.loss_mask: 0.2462  decode.d5.loss_dice: 0.3143  decode.d6.loss_cls: 0.7105  decode.d6.loss_mask: 0.2453  decode.d6.loss_dice: 0.3167  decode.d7.loss_cls: 0.7680  decode.d7.loss_mask: 0.2486  decode.d7.loss_dice: 0.3138  decode.d8.loss_cls: 0.7344  decode.d8.loss_mask: 0.2529  decode.d8.loss_dice: 0.3185
07/25 19:58:50 - mmengine - INFO - Iter(train) [ 5600/80000]  base_lr: 9.3678e-05 lr: 9.3678e-06  eta: 9:28:25  time: 0.4590  data_time: 0.0104  memory: 5249  grad_norm: 145.6273  loss: 14.0591  decode.loss_cls: 0.5788  decode.loss_mask: 0.3482  decode.loss_dice: 0.3821  decode.d0.loss_cls: 1.6181  decode.d0.loss_mask: 0.3507  decode.d0.loss_dice: 0.4236  decode.d1.loss_cls: 0.7152  decode.d1.loss_mask: 0.3233  decode.d1.loss_dice: 0.3579  decode.d2.loss_cls: 0.5530  decode.d2.loss_mask: 0.3355  decode.d2.loss_dice: 0.3505  decode.d3.loss_cls: 0.5953  decode.d3.loss_mask: 0.3265  decode.d3.loss_dice: 0.3536  decode.d4.loss_cls: 0.6166  decode.d4.loss_mask: 0.3459  decode.d4.loss_dice: 0.3548  decode.d5.loss_cls: 0.5855  decode.d5.loss_mask: 0.3557  decode.d5.loss_dice: 0.3397  decode.d6.loss_cls: 0.6142  decode.d6.loss_mask: 0.3301  decode.d6.loss_dice: 0.3232  decode.d7.loss_cls: 0.6100  decode.d7.loss_mask: 0.3520  decode.d7.loss_dice: 0.3282  decode.d8.loss_cls: 0.5934  decode.d8.loss_mask: 0.3434  decode.d8.loss_dice: 0.3541
07/25 19:59:13 - mmengine - INFO - Iter(train) [ 5650/80000]  base_lr: 9.3622e-05 lr: 9.3622e-06  eta: 9:28:01  time: 0.4579  data_time: 0.0103  memory: 5249  grad_norm: 123.5123  loss: 13.8275  decode.loss_cls: 0.4881  decode.loss_mask: 0.3408  decode.loss_dice: 0.3612  decode.d0.loss_cls: 1.7761  decode.d0.loss_mask: 0.3530  decode.d0.loss_dice: 0.4327  decode.d1.loss_cls: 0.7991  decode.d1.loss_mask: 0.3348  decode.d1.loss_dice: 0.3378  decode.d2.loss_cls: 0.5399  decode.d2.loss_mask: 0.3259  decode.d2.loss_dice: 0.3467  decode.d3.loss_cls: 0.5252  decode.d3.loss_mask: 0.3492  decode.d3.loss_dice: 0.3702  decode.d4.loss_cls: 0.5329  decode.d4.loss_mask: 0.3338  decode.d4.loss_dice: 0.3485  decode.d5.loss_cls: 0.5758  decode.d5.loss_mask: 0.3463  decode.d5.loss_dice: 0.3460  decode.d6.loss_cls: 0.5315  decode.d6.loss_mask: 0.3330  decode.d6.loss_dice: 0.3606  decode.d7.loss_cls: 0.5405  decode.d7.loss_mask: 0.3311  decode.d7.loss_dice: 0.3631  decode.d8.loss_cls: 0.5210  decode.d8.loss_mask: 0.3425  decode.d8.loss_dice: 0.3401
07/25 19:59:36 - mmengine - INFO - Iter(train) [ 5700/80000]  base_lr: 9.3565e-05 lr: 9.3565e-06  eta: 9:27:36  time: 0.4522  data_time: 0.0101  memory: 5249  grad_norm: 119.7527  loss: 13.1102  decode.loss_cls: 0.6222  decode.loss_mask: 0.3000  decode.loss_dice: 0.2998  decode.d0.loss_cls: 1.4689  decode.d0.loss_mask: 0.3081  decode.d0.loss_dice: 0.3665  decode.d1.loss_cls: 0.7636  decode.d1.loss_mask: 0.2973  decode.d1.loss_dice: 0.3027  decode.d2.loss_cls: 0.6026  decode.d2.loss_mask: 0.2881  decode.d2.loss_dice: 0.2997  decode.d3.loss_cls: 0.5316  decode.d3.loss_mask: 0.2948  decode.d3.loss_dice: 0.3035  decode.d4.loss_cls: 0.6001  decode.d4.loss_mask: 0.3421  decode.d4.loss_dice: 0.3184  decode.d5.loss_cls: 0.6097  decode.d5.loss_mask: 0.2874  decode.d5.loss_dice: 0.2917  decode.d6.loss_cls: 0.6449  decode.d6.loss_mask: 0.2883  decode.d6.loss_dice: 0.2969  decode.d7.loss_cls: 0.6137  decode.d7.loss_mask: 0.2913  decode.d7.loss_dice: 0.2766  decode.d8.loss_cls: 0.6275  decode.d8.loss_mask: 0.2898  decode.d8.loss_dice: 0.2821
07/25 19:59:59 - mmengine - INFO - Iter(train) [ 5750/80000]  base_lr: 9.3508e-05 lr: 9.3508e-06  eta: 9:27:14  time: 0.4573  data_time: 0.0100  memory: 5249  grad_norm: 148.9296  loss: 15.1136  decode.loss_cls: 0.7103  decode.loss_mask: 0.3254  decode.loss_dice: 0.3937  decode.d0.loss_cls: 1.5180  decode.d0.loss_mask: 0.3415  decode.d0.loss_dice: 0.4767  decode.d1.loss_cls: 0.8212  decode.d1.loss_mask: 0.3260  decode.d1.loss_dice: 0.4187  decode.d2.loss_cls: 0.6887  decode.d2.loss_mask: 0.3258  decode.d2.loss_dice: 0.4145  decode.d3.loss_cls: 0.6620  decode.d3.loss_mask: 0.3123  decode.d3.loss_dice: 0.4087  decode.d4.loss_cls: 0.6017  decode.d4.loss_mask: 0.3409  decode.d4.loss_dice: 0.4438  decode.d5.loss_cls: 0.7075  decode.d5.loss_mask: 0.3317  decode.d5.loss_dice: 0.4205  decode.d6.loss_cls: 0.6606  decode.d6.loss_mask: 0.3332  decode.d6.loss_dice: 0.3978  decode.d7.loss_cls: 0.6386  decode.d7.loss_mask: 0.3305  decode.d7.loss_dice: 0.3779  decode.d8.loss_cls: 0.6435  decode.d8.loss_mask: 0.3218  decode.d8.loss_dice: 0.4200
07/25 20:00:21 - mmengine - INFO - Iter(train) [ 5800/80000]  base_lr: 9.3452e-05 lr: 9.3452e-06  eta: 9:26:47  time: 0.4542  data_time: 0.0099  memory: 5249  grad_norm: 147.0836  loss: 17.9460  decode.loss_cls: 0.8400  decode.loss_mask: 0.4306  decode.loss_dice: 0.4800  decode.d0.loss_cls: 1.6242  decode.d0.loss_mask: 0.3873  decode.d0.loss_dice: 0.5418  decode.d1.loss_cls: 0.8774  decode.d1.loss_mask: 0.3854  decode.d1.loss_dice: 0.4841  decode.d2.loss_cls: 0.8066  decode.d2.loss_mask: 0.3632  decode.d2.loss_dice: 0.4768  decode.d3.loss_cls: 0.7669  decode.d3.loss_mask: 0.3901  decode.d3.loss_dice: 0.4693  decode.d4.loss_cls: 0.7819  decode.d4.loss_mask: 0.4116  decode.d4.loss_dice: 0.4851  decode.d5.loss_cls: 0.7933  decode.d5.loss_mask: 0.3831  decode.d5.loss_dice: 0.4601  decode.d6.loss_cls: 0.8510  decode.d6.loss_mask: 0.4210  decode.d6.loss_dice: 0.4532  decode.d7.loss_cls: 0.8568  decode.d7.loss_mask: 0.4546  decode.d7.loss_dice: 0.4727  decode.d8.loss_cls: 0.8264  decode.d8.loss_mask: 0.4712  decode.d8.loss_dice: 0.5003
07/25 20:00:44 - mmengine - INFO - Iter(train) [ 5850/80000]  base_lr: 9.3395e-05 lr: 9.3395e-06  eta: 9:26:18  time: 0.4330  data_time: 0.0085  memory: 5265  grad_norm: 213.3975  loss: 17.8620  decode.loss_cls: 0.8528  decode.loss_mask: 0.3765  decode.loss_dice: 0.4895  decode.d0.loss_cls: 1.5092  decode.d0.loss_mask: 0.3593  decode.d0.loss_dice: 0.5267  decode.d1.loss_cls: 0.9664  decode.d1.loss_mask: 0.3600  decode.d1.loss_dice: 0.4870  decode.d2.loss_cls: 0.8975  decode.d2.loss_mask: 0.3146  decode.d2.loss_dice: 0.4733  decode.d3.loss_cls: 0.9077  decode.d3.loss_mask: 0.3327  decode.d3.loss_dice: 0.4744  decode.d4.loss_cls: 0.8476  decode.d4.loss_mask: 0.3663  decode.d4.loss_dice: 0.4852  decode.d5.loss_cls: 0.8801  decode.d5.loss_mask: 0.3714  decode.d5.loss_dice: 0.4896  decode.d6.loss_cls: 0.9413  decode.d6.loss_mask: 0.3700  decode.d6.loss_dice: 0.4759  decode.d7.loss_cls: 0.8502  decode.d7.loss_mask: 0.3746  decode.d7.loss_dice: 0.4781  decode.d8.loss_cls: 0.7783  decode.d8.loss_mask: 0.3596  decode.d8.loss_dice: 0.4662
07/25 20:01:07 - mmengine - INFO - Iter(train) [ 5900/80000]  base_lr: 9.3338e-05 lr: 9.3338e-06  eta: 9:25:53  time: 0.4511  data_time: 0.0099  memory: 5249  grad_norm: 157.2615  loss: 18.5020  decode.loss_cls: 0.9500  decode.loss_mask: 0.3518  decode.loss_dice: 0.4149  decode.d0.loss_cls: 1.7243  decode.d0.loss_mask: 0.3801  decode.d0.loss_dice: 0.4291  decode.d1.loss_cls: 1.1264  decode.d1.loss_mask: 0.3644  decode.d1.loss_dice: 0.3686  decode.d2.loss_cls: 0.9335  decode.d2.loss_mask: 0.3587  decode.d2.loss_dice: 0.4008  decode.d3.loss_cls: 1.0056  decode.d3.loss_mask: 0.3574  decode.d3.loss_dice: 0.4059  decode.d4.loss_cls: 1.0193  decode.d4.loss_mask: 0.3545  decode.d4.loss_dice: 0.4176  decode.d5.loss_cls: 0.9723  decode.d5.loss_mask: 0.3601  decode.d5.loss_dice: 0.4219  decode.d6.loss_cls: 1.0608  decode.d6.loss_mask: 0.3631  decode.d6.loss_dice: 0.4320  decode.d7.loss_cls: 1.0063  decode.d7.loss_mask: 0.3595  decode.d7.loss_dice: 0.3890  decode.d8.loss_cls: 0.9983  decode.d8.loss_mask: 0.3594  decode.d8.loss_dice: 0.4166
07/25 20:01:29 - mmengine - INFO - Iter(train) [ 5950/80000]  base_lr: 9.3282e-05 lr: 9.3282e-06  eta: 9:25:29  time: 0.4537  data_time: 0.0098  memory: 5249  grad_norm: 109.1381  loss: 13.5721  decode.loss_cls: 0.6379  decode.loss_mask: 0.2895  decode.loss_dice: 0.3426  decode.d0.loss_cls: 1.4495  decode.d0.loss_mask: 0.3060  decode.d0.loss_dice: 0.4024  decode.d1.loss_cls: 0.7219  decode.d1.loss_mask: 0.2905  decode.d1.loss_dice: 0.3658  decode.d2.loss_cls: 0.6097  decode.d2.loss_mask: 0.2847  decode.d2.loss_dice: 0.3611  decode.d3.loss_cls: 0.6211  decode.d3.loss_mask: 0.2850  decode.d3.loss_dice: 0.3570  decode.d4.loss_cls: 0.6311  decode.d4.loss_mask: 0.2808  decode.d4.loss_dice: 0.3416  decode.d5.loss_cls: 0.6408  decode.d5.loss_mask: 0.2828  decode.d5.loss_dice: 0.3518  decode.d6.loss_cls: 0.6063  decode.d6.loss_mask: 0.2850  decode.d6.loss_dice: 0.3434  decode.d7.loss_cls: 0.5730  decode.d7.loss_mask: 0.2872  decode.d7.loss_dice: 0.3467  decode.d8.loss_cls: 0.6284  decode.d8.loss_mask: 0.2917  decode.d8.loss_dice: 0.3569
07/25 20:01:52 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250725_191538
07/25 20:01:52 - mmengine - INFO - Iter(train) [ 6000/80000]  base_lr: 9.3225e-05 lr: 9.3225e-06  eta: 9:25:06  time: 0.4558  data_time: 0.0101  memory: 5249  grad_norm: 88.4910  loss: 15.2862  decode.loss_cls: 0.7468  decode.loss_mask: 0.3077  decode.loss_dice: 0.3910  decode.d0.loss_cls: 1.6698  decode.d0.loss_mask: 0.3041  decode.d0.loss_dice: 0.4273  decode.d1.loss_cls: 0.8672  decode.d1.loss_mask: 0.3183  decode.d1.loss_dice: 0.3908  decode.d2.loss_cls: 0.6204  decode.d2.loss_mask: 0.3173  decode.d2.loss_dice: 0.3893  decode.d3.loss_cls: 0.7270  decode.d3.loss_mask: 0.2964  decode.d3.loss_dice: 0.3695  decode.d4.loss_cls: 0.7727  decode.d4.loss_mask: 0.2940  decode.d4.loss_dice: 0.3580  decode.d5.loss_cls: 0.8085  decode.d5.loss_mask: 0.2981  decode.d5.loss_dice: 0.3719  decode.d6.loss_cls: 0.7794  decode.d6.loss_mask: 0.2998  decode.d6.loss_dice: 0.3723  decode.d7.loss_cls: 0.7053  decode.d7.loss_mask: 0.2999  decode.d7.loss_dice: 0.3651  decode.d8.loss_cls: 0.7436  decode.d8.loss_mask: 0.3033  decode.d8.loss_dice: 0.3716
07/25 20:02:15 - mmengine - INFO - Iter(train) [ 6050/80000]  base_lr: 9.3168e-05 lr: 9.3168e-06  eta: 9:24:43  time: 0.4562  data_time: 0.0103  memory: 5231  grad_norm: 108.0866  loss: 11.4095  decode.loss_cls: 0.3956  decode.loss_mask: 0.2537  decode.loss_dice: 0.3394  decode.d0.loss_cls: 1.4195  decode.d0.loss_mask: 0.2527  decode.d0.loss_dice: 0.3451  decode.d1.loss_cls: 0.6104  decode.d1.loss_mask: 0.2395  decode.d1.loss_dice: 0.2998  decode.d2.loss_cls: 0.5014  decode.d2.loss_mask: 0.2377  decode.d2.loss_dice: 0.3261  decode.d3.loss_cls: 0.4583  decode.d3.loss_mask: 0.2507  decode.d3.loss_dice: 0.3453  decode.d4.loss_cls: 0.5720  decode.d4.loss_mask: 0.2422  decode.d4.loss_dice: 0.3433  decode.d5.loss_cls: 0.4647  decode.d5.loss_mask: 0.2478  decode.d5.loss_dice: 0.3464  decode.d6.loss_cls: 0.3850  decode.d6.loss_mask: 0.2576  decode.d6.loss_dice: 0.3253  decode.d7.loss_cls: 0.3871  decode.d7.loss_mask: 0.2610  decode.d7.loss_dice: 0.3346  decode.d8.loss_cls: 0.3888  decode.d8.loss_mask: 0.2542  decode.d8.loss_dice: 0.3245
07/25 20:02:38 - mmengine - INFO - Iter(train) [ 6100/80000]  base_lr: 9.3112e-05 lr: 9.3112e-06  eta: 9:24:19  time: 0.4558  data_time: 0.0105  memory: 5266  grad_norm: 87.0636  loss: 12.7549  decode.loss_cls: 0.6247  decode.loss_mask: 0.2503  decode.loss_dice: 0.3369  decode.d0.loss_cls: 1.2087  decode.d0.loss_mask: 0.2510  decode.d0.loss_dice: 0.3630  decode.d1.loss_cls: 0.7249  decode.d1.loss_mask: 0.2442  decode.d1.loss_dice: 0.3193  decode.d2.loss_cls: 0.6654  decode.d2.loss_mask: 0.2445  decode.d2.loss_dice: 0.3163  decode.d3.loss_cls: 0.6463  decode.d3.loss_mask: 0.2458  decode.d3.loss_dice: 0.3278  decode.d4.loss_cls: 0.6197  decode.d4.loss_mask: 0.2463  decode.d4.loss_dice: 0.3004  decode.d5.loss_cls: 0.6159  decode.d5.loss_mask: 0.2527  decode.d5.loss_dice: 0.3262  decode.d6.loss_cls: 0.6146  decode.d6.loss_mask: 0.2557  decode.d6.loss_dice: 0.3436  decode.d7.loss_cls: 0.6431  decode.d7.loss_mask: 0.2518  decode.d7.loss_dice: 0.3161  decode.d8.loss_cls: 0.6190  decode.d8.loss_mask: 0.2509  decode.d8.loss_dice: 0.3297
07/25 20:03:01 - mmengine - INFO - Iter(train) [ 6150/80000]  base_lr: 9.3055e-05 lr: 9.3055e-06  eta: 9:23:54  time: 0.4597  data_time: 0.0104  memory: 5292  grad_norm: 170.4741  loss: 13.1121  decode.loss_cls: 0.5369  decode.loss_mask: 0.3020  decode.loss_dice: 0.3755  decode.d0.loss_cls: 1.5204  decode.d0.loss_mask: 0.2403  decode.d0.loss_dice: 0.4024  decode.d1.loss_cls: 0.7209  decode.d1.loss_mask: 0.2481  decode.d1.loss_dice: 0.3551  decode.d2.loss_cls: 0.5545  decode.d2.loss_mask: 0.2502  decode.d2.loss_dice: 0.3427  decode.d3.loss_cls: 0.5559  decode.d3.loss_mask: 0.2509  decode.d3.loss_dice: 0.3620  decode.d4.loss_cls: 0.6303  decode.d4.loss_mask: 0.2487  decode.d4.loss_dice: 0.3529  decode.d5.loss_cls: 0.5883  decode.d5.loss_mask: 0.2643  decode.d5.loss_dice: 0.3751  decode.d6.loss_cls: 0.6078  decode.d6.loss_mask: 0.2681  decode.d6.loss_dice: 0.3713  decode.d7.loss_cls: 0.5455  decode.d7.loss_mask: 0.2752  decode.d7.loss_dice: 0.3642  decode.d8.loss_cls: 0.5431  decode.d8.loss_mask: 0.2977  decode.d8.loss_dice: 0.3615
07/25 20:03:24 - mmengine - INFO - Iter(train) [ 6200/80000]  base_lr: 9.2998e-05 lr: 9.2998e-06  eta: 9:23:32  time: 0.4605  data_time: 0.0102  memory: 5248  grad_norm: 135.7146  loss: 15.7464  decode.loss_cls: 0.5123  decode.loss_mask: 0.5481  decode.loss_dice: 0.4183  decode.d0.loss_cls: 1.3450  decode.d0.loss_mask: 0.4141  decode.d0.loss_dice: 0.5030  decode.d1.loss_cls: 0.7216  decode.d1.loss_mask: 0.4238  decode.d1.loss_dice: 0.4396  decode.d2.loss_cls: 0.6162  decode.d2.loss_mask: 0.4849  decode.d2.loss_dice: 0.4084  decode.d3.loss_cls: 0.6004  decode.d3.loss_mask: 0.4168  decode.d3.loss_dice: 0.4062  decode.d4.loss_cls: 0.5646  decode.d4.loss_mask: 0.4556  decode.d4.loss_dice: 0.4499  decode.d5.loss_cls: 0.5891  decode.d5.loss_mask: 0.5215  decode.d5.loss_dice: 0.4291  decode.d6.loss_cls: 0.5451  decode.d6.loss_mask: 0.4617  decode.d6.loss_dice: 0.4296  decode.d7.loss_cls: 0.5689  decode.d7.loss_mask: 0.5345  decode.d7.loss_dice: 0.4518  decode.d8.loss_cls: 0.5603  decode.d8.loss_mask: 0.4809  decode.d8.loss_dice: 0.4454
07/25 20:03:47 - mmengine - INFO - Iter(train) [ 6250/80000]  base_lr: 9.2942e-05 lr: 9.2942e-06  eta: 9:23:08  time: 0.4561  data_time: 0.0104  memory: 5248  grad_norm: 157.6532  loss: 16.3081  decode.loss_cls: 0.7068  decode.loss_mask: 0.3606  decode.loss_dice: 0.4799  decode.d0.loss_cls: 1.4181  decode.d0.loss_mask: 0.4421  decode.d0.loss_dice: 0.5090  decode.d1.loss_cls: 0.9349  decode.d1.loss_mask: 0.3703  decode.d1.loss_dice: 0.4216  decode.d2.loss_cls: 0.7023  decode.d2.loss_mask: 0.3885  decode.d2.loss_dice: 0.4318  decode.d3.loss_cls: 0.6895  decode.d3.loss_mask: 0.3818  decode.d3.loss_dice: 0.4522  decode.d4.loss_cls: 0.6840  decode.d4.loss_mask: 0.3820  decode.d4.loss_dice: 0.4524  decode.d5.loss_cls: 0.6648  decode.d5.loss_mask: 0.3834  decode.d5.loss_dice: 0.4893  decode.d6.loss_cls: 0.7564  decode.d6.loss_mask: 0.3588  decode.d6.loss_dice: 0.4247  decode.d7.loss_cls: 0.7031  decode.d7.loss_mask: 0.3555  decode.d7.loss_dice: 0.4654  decode.d8.loss_cls: 0.6550  decode.d8.loss_mask: 0.3606  decode.d8.loss_dice: 0.4835
07/25 20:04:09 - mmengine - INFO - Iter(train) [ 6300/80000]  base_lr: 9.2885e-05 lr: 9.2885e-06  eta: 9:22:44  time: 0.4569  data_time: 0.0102  memory: 5249  grad_norm: 100.6622  loss: 11.3510  decode.loss_cls: 0.4117  decode.loss_mask: 0.2796  decode.loss_dice: 0.2789  decode.d0.loss_cls: 1.4804  decode.d0.loss_mask: 0.3041  decode.d0.loss_dice: 0.3389  decode.d1.loss_cls: 0.6131  decode.d1.loss_mask: 0.2844  decode.d1.loss_dice: 0.2870  decode.d2.loss_cls: 0.4734  decode.d2.loss_mask: 0.2763  decode.d2.loss_dice: 0.2842  decode.d3.loss_cls: 0.4719  decode.d3.loss_mask: 0.2810  decode.d3.loss_dice: 0.2838  decode.d4.loss_cls: 0.4628  decode.d4.loss_mask: 0.2896  decode.d4.loss_dice: 0.2985  decode.d5.loss_cls: 0.4395  decode.d5.loss_mask: 0.2802  decode.d5.loss_dice: 0.2831  decode.d6.loss_cls: 0.4307  decode.d6.loss_mask: 0.2804  decode.d6.loss_dice: 0.2744  decode.d7.loss_cls: 0.4497  decode.d7.loss_mask: 0.2759  decode.d7.loss_dice: 0.2790  decode.d8.loss_cls: 0.3865  decode.d8.loss_mask: 0.2798  decode.d8.loss_dice: 0.2920
07/25 20:04:32 - mmengine - INFO - Iter(train) [ 6350/80000]  base_lr: 9.2828e-05 lr: 9.2828e-06  eta: 9:22:20  time: 0.4572  data_time: 0.0103  memory: 5231  grad_norm: 298.1817  loss: 12.3115  decode.loss_cls: 0.4794  decode.loss_mask: 0.2658  decode.loss_dice: 0.2844  decode.d0.loss_cls: 1.4781  decode.d0.loss_mask: 0.3186  decode.d0.loss_dice: 0.3529  decode.d1.loss_cls: 0.7157  decode.d1.loss_mask: 0.2898  decode.d1.loss_dice: 0.3260  decode.d2.loss_cls: 0.4912  decode.d2.loss_mask: 0.2846  decode.d2.loss_dice: 0.3227  decode.d3.loss_cls: 0.5232  decode.d3.loss_mask: 0.2760  decode.d3.loss_dice: 0.3313  decode.d4.loss_cls: 0.5056  decode.d4.loss_mask: 0.2762  decode.d4.loss_dice: 0.3307  decode.d5.loss_cls: 0.5471  decode.d5.loss_mask: 0.2753  decode.d5.loss_dice: 0.3399  decode.d6.loss_cls: 0.5209  decode.d6.loss_mask: 0.2666  decode.d6.loss_dice: 0.3014  decode.d7.loss_cls: 0.5067  decode.d7.loss_mask: 0.3127  decode.d7.loss_dice: 0.3003  decode.d8.loss_cls: 0.5080  decode.d8.loss_mask: 0.2895  decode.d8.loss_dice: 0.2909
07/25 20:04:55 - mmengine - INFO - Iter(train) [ 6400/80000]  base_lr: 9.2771e-05 lr: 9.2771e-06  eta: 9:21:56  time: 0.4528  data_time: 0.0101  memory: 5248  grad_norm: 165.6250  loss: 17.7652  decode.loss_cls: 0.9393  decode.loss_mask: 0.3240  decode.loss_dice: 0.4653  decode.d0.loss_cls: 1.6802  decode.d0.loss_mask: 0.3712  decode.d0.loss_dice: 0.5320  decode.d1.loss_cls: 1.1043  decode.d1.loss_mask: 0.3231  decode.d1.loss_dice: 0.4602  decode.d2.loss_cls: 0.9899  decode.d2.loss_mask: 0.3182  decode.d2.loss_dice: 0.4496  decode.d3.loss_cls: 0.8565  decode.d3.loss_mask: 0.3117  decode.d3.loss_dice: 0.4516  decode.d4.loss_cls: 0.8683  decode.d4.loss_mask: 0.3114  decode.d4.loss_dice: 0.4369  decode.d5.loss_cls: 0.9241  decode.d5.loss_mask: 0.3141  decode.d5.loss_dice: 0.4186  decode.d6.loss_cls: 0.8774  decode.d6.loss_mask: 0.3390  decode.d6.loss_dice: 0.4308  decode.d7.loss_cls: 0.8315  decode.d7.loss_mask: 0.3294  decode.d7.loss_dice: 0.4356  decode.d8.loss_cls: 0.9159  decode.d8.loss_mask: 0.3251  decode.d8.loss_dice: 0.4303
07/25 20:05:18 - mmengine - INFO - Iter(train) [ 6450/80000]  base_lr: 9.2715e-05 lr: 9.2715e-06  eta: 9:21:32  time: 0.4600  data_time: 0.0105  memory: 5249  grad_norm: 114.6207  loss: 13.0986  decode.loss_cls: 0.4371  decode.loss_mask: 0.3457  decode.loss_dice: 0.3937  decode.d0.loss_cls: 1.2791  decode.d0.loss_mask: 0.4400  decode.d0.loss_dice: 0.4750  decode.d1.loss_cls: 0.5789  decode.d1.loss_mask: 0.3475  decode.d1.loss_dice: 0.4074  decode.d2.loss_cls: 0.4185  decode.d2.loss_mask: 0.3528  decode.d2.loss_dice: 0.4166  decode.d3.loss_cls: 0.4547  decode.d3.loss_mask: 0.3502  decode.d3.loss_dice: 0.4050  decode.d4.loss_cls: 0.4343  decode.d4.loss_mask: 0.3591  decode.d4.loss_dice: 0.4312  decode.d5.loss_cls: 0.4128  decode.d5.loss_mask: 0.3512  decode.d5.loss_dice: 0.4232  decode.d6.loss_cls: 0.4608  decode.d6.loss_mask: 0.3448  decode.d6.loss_dice: 0.3991  decode.d7.loss_cls: 0.4565  decode.d7.loss_mask: 0.3444  decode.d7.loss_dice: 0.3845  decode.d8.loss_cls: 0.4700  decode.d8.loss_mask: 0.3475  decode.d8.loss_dice: 0.3771
07/25 20:05:41 - mmengine - INFO - Iter(train) [ 6500/80000]  base_lr: 9.2658e-05 lr: 9.2658e-06  eta: 9:21:08  time: 0.4489  data_time: 0.0100  memory: 5231  grad_norm: 102.4606  loss: 14.0273  decode.loss_cls: 0.6781  decode.loss_mask: 0.2792  decode.loss_dice: 0.3044  decode.d0.loss_cls: 1.5268  decode.d0.loss_mask: 0.3065  decode.d0.loss_dice: 0.4026  decode.d1.loss_cls: 0.8057  decode.d1.loss_mask: 0.2906  decode.d1.loss_dice: 0.3149  decode.d2.loss_cls: 0.7200  decode.d2.loss_mask: 0.2977  decode.d2.loss_dice: 0.3262  decode.d3.loss_cls: 0.6362  decode.d3.loss_mask: 0.2864  decode.d3.loss_dice: 0.3325  decode.d4.loss_cls: 0.6550  decode.d4.loss_mask: 0.2998  decode.d4.loss_dice: 0.3410  decode.d5.loss_cls: 0.7030  decode.d5.loss_mask: 0.2971  decode.d5.loss_dice: 0.3558  decode.d6.loss_cls: 0.6718  decode.d6.loss_mask: 0.2857  decode.d6.loss_dice: 0.3189  decode.d7.loss_cls: 0.6532  decode.d7.loss_mask: 0.2926  decode.d7.loss_dice: 0.3229  decode.d8.loss_cls: 0.7226  decode.d8.loss_mask: 0.2815  decode.d8.loss_dice: 0.3183
07/25 20:06:03 - mmengine - INFO - Iter(train) [ 6550/80000]  base_lr: 9.2601e-05 lr: 9.2601e-06  eta: 9:20:43  time: 0.4548  data_time: 0.0101  memory: 5231  grad_norm: 116.0046  loss: 12.4908  decode.loss_cls: 0.4737  decode.loss_mask: 0.2786  decode.loss_dice: 0.3466  decode.d0.loss_cls: 1.4477  decode.d0.loss_mask: 0.2903  decode.d0.loss_dice: 0.4290  decode.d1.loss_cls: 0.6580  decode.d1.loss_mask: 0.2822  decode.d1.loss_dice: 0.3473  decode.d2.loss_cls: 0.4648  decode.d2.loss_mask: 0.2868  decode.d2.loss_dice: 0.3481  decode.d3.loss_cls: 0.4786  decode.d3.loss_mask: 0.2794  decode.d3.loss_dice: 0.3440  decode.d4.loss_cls: 0.5488  decode.d4.loss_mask: 0.2799  decode.d4.loss_dice: 0.3331  decode.d5.loss_cls: 0.4823  decode.d5.loss_mask: 0.2874  decode.d5.loss_dice: 0.3474  decode.d6.loss_cls: 0.5009  decode.d6.loss_mask: 0.2900  decode.d6.loss_dice: 0.3412  decode.d7.loss_cls: 0.5233  decode.d7.loss_mask: 0.2942  decode.d7.loss_dice: 0.3521  decode.d8.loss_cls: 0.5118  decode.d8.loss_mask: 0.2886  decode.d8.loss_dice: 0.3546
07/25 20:06:26 - mmengine - INFO - Iter(train) [ 6600/80000]  base_lr: 9.2544e-05 lr: 9.2544e-06  eta: 9:20:18  time: 0.4587  data_time: 0.0106  memory: 5249  grad_norm: 103.9186  loss: 13.3663  decode.loss_cls: 0.5467  decode.loss_mask: 0.3719  decode.loss_dice: 0.3580  decode.d0.loss_cls: 1.4825  decode.d0.loss_mask: 0.3122  decode.d0.loss_dice: 0.3711  decode.d1.loss_cls: 0.6171  decode.d1.loss_mask: 0.3139  decode.d1.loss_dice: 0.3451  decode.d2.loss_cls: 0.5077  decode.d2.loss_mask: 0.3058  decode.d2.loss_dice: 0.3523  decode.d3.loss_cls: 0.5265  decode.d3.loss_mask: 0.2983  decode.d3.loss_dice: 0.3632  decode.d4.loss_cls: 0.6267  decode.d4.loss_mask: 0.3150  decode.d4.loss_dice: 0.3796  decode.d5.loss_cls: 0.5701  decode.d5.loss_mask: 0.3111  decode.d5.loss_dice: 0.3609  decode.d6.loss_cls: 0.5586  decode.d6.loss_mask: 0.3400  decode.d6.loss_dice: 0.3493  decode.d7.loss_cls: 0.5435  decode.d7.loss_mask: 0.3208  decode.d7.loss_dice: 0.3548  decode.d8.loss_cls: 0.5167  decode.d8.loss_mask: 0.3482  decode.d8.loss_dice: 0.3989
07/25 20:06:49 - mmengine - INFO - Iter(train) [ 6650/80000]  base_lr: 9.2488e-05 lr: 9.2488e-06  eta: 9:19:55  time: 0.4598  data_time: 0.0105  memory: 5249  grad_norm: 108.2641  loss: 10.9393  decode.loss_cls: 0.4039  decode.loss_mask: 0.2809  decode.loss_dice: 0.3374  decode.d0.loss_cls: 1.2193  decode.d0.loss_mask: 0.2592  decode.d0.loss_dice: 0.3563  decode.d1.loss_cls: 0.4919  decode.d1.loss_mask: 0.2654  decode.d1.loss_dice: 0.3261  decode.d2.loss_cls: 0.3571  decode.d2.loss_mask: 0.2854  decode.d2.loss_dice: 0.3376  decode.d3.loss_cls: 0.3888  decode.d3.loss_mask: 0.2813  decode.d3.loss_dice: 0.3358  decode.d4.loss_cls: 0.3626  decode.d4.loss_mask: 0.2753  decode.d4.loss_dice: 0.3379  decode.d5.loss_cls: 0.3829  decode.d5.loss_mask: 0.2641  decode.d5.loss_dice: 0.3323  decode.d6.loss_cls: 0.4429  decode.d6.loss_mask: 0.2813  decode.d6.loss_dice: 0.3363  decode.d7.loss_cls: 0.3606  decode.d7.loss_mask: 0.2837  decode.d7.loss_dice: 0.3492  decode.d8.loss_cls: 0.3793  decode.d8.loss_mask: 0.2816  decode.d8.loss_dice: 0.3429
07/25 20:07:12 - mmengine - INFO - Iter(train) [ 6700/80000]  base_lr: 9.2431e-05 lr: 9.2431e-06  eta: 9:19:32  time: 0.4582  data_time: 0.0104  memory: 5266  grad_norm: 124.5919  loss: 11.2056  decode.loss_cls: 0.4992  decode.loss_mask: 0.2633  decode.loss_dice: 0.2821  decode.d0.loss_cls: 1.3225  decode.d0.loss_mask: 0.2657  decode.d0.loss_dice: 0.3210  decode.d1.loss_cls: 0.5968  decode.d1.loss_mask: 0.2594  decode.d1.loss_dice: 0.2863  decode.d2.loss_cls: 0.5026  decode.d2.loss_mask: 0.2655  decode.d2.loss_dice: 0.2746  decode.d3.loss_cls: 0.4880  decode.d3.loss_mask: 0.2611  decode.d3.loss_dice: 0.2800  decode.d4.loss_cls: 0.4770  decode.d4.loss_mask: 0.2669  decode.d4.loss_dice: 0.2745  decode.d5.loss_cls: 0.4366  decode.d5.loss_mask: 0.2702  decode.d5.loss_dice: 0.2784  decode.d6.loss_cls: 0.4555  decode.d6.loss_mask: 0.2674  decode.d6.loss_dice: 0.2692  decode.d7.loss_cls: 0.4619  decode.d7.loss_mask: 0.2656  decode.d7.loss_dice: 0.2852  decode.d8.loss_cls: 0.4745  decode.d8.loss_mask: 0.2723  decode.d8.loss_dice: 0.2826
07/25 20:07:35 - mmengine - INFO - Iter(train) [ 6750/80000]  base_lr: 9.2374e-05 lr: 9.2374e-06  eta: 9:19:08  time: 0.4576  data_time: 0.0103  memory: 5265  grad_norm: 149.5168  loss: 15.4952  decode.loss_cls: 0.5271  decode.loss_mask: 0.4909  decode.loss_dice: 0.4471  decode.d0.loss_cls: 1.4179  decode.d0.loss_mask: 0.5090  decode.d0.loss_dice: 0.4425  decode.d1.loss_cls: 0.6513  decode.d1.loss_mask: 0.5019  decode.d1.loss_dice: 0.4289  decode.d2.loss_cls: 0.5347  decode.d2.loss_mask: 0.5044  decode.d2.loss_dice: 0.4103  decode.d3.loss_cls: 0.5678  decode.d3.loss_mask: 0.4921  decode.d3.loss_dice: 0.4160  decode.d4.loss_cls: 0.5292  decode.d4.loss_mask: 0.4986  decode.d4.loss_dice: 0.4451  decode.d5.loss_cls: 0.5473  decode.d5.loss_mask: 0.4953  decode.d5.loss_dice: 0.4297  decode.d6.loss_cls: 0.4625  decode.d6.loss_mask: 0.5052  decode.d6.loss_dice: 0.4253  decode.d7.loss_cls: 0.5037  decode.d7.loss_mask: 0.4898  decode.d7.loss_dice: 0.4215  decode.d8.loss_cls: 0.4559  decode.d8.loss_mask: 0.5021  decode.d8.loss_dice: 0.4420
07/25 20:07:57 - mmengine - INFO - Iter(train) [ 6800/80000]  base_lr: 9.2317e-05 lr: 9.2317e-06  eta: 9:18:45  time: 0.4553  data_time: 0.0102  memory: 5265  grad_norm: 156.2084  loss: 14.7738  decode.loss_cls: 0.6331  decode.loss_mask: 0.3294  decode.loss_dice: 0.4027  decode.d0.loss_cls: 1.3317  decode.d0.loss_mask: 0.3204  decode.d0.loss_dice: 0.4627  decode.d1.loss_cls: 0.7458  decode.d1.loss_mask: 0.2965  decode.d1.loss_dice: 0.3824  decode.d2.loss_cls: 0.5989  decode.d2.loss_mask: 0.3204  decode.d2.loss_dice: 0.4022  decode.d3.loss_cls: 0.6941  decode.d3.loss_mask: 0.3122  decode.d3.loss_dice: 0.4112  decode.d4.loss_cls: 0.6725  decode.d4.loss_mask: 0.3643  decode.d4.loss_dice: 0.4134  decode.d5.loss_cls: 0.6204  decode.d5.loss_mask: 0.3295  decode.d5.loss_dice: 0.4136  decode.d6.loss_cls: 0.6940  decode.d6.loss_mask: 0.3328  decode.d6.loss_dice: 0.4268  decode.d7.loss_cls: 0.7262  decode.d7.loss_mask: 0.3337  decode.d7.loss_dice: 0.4231  decode.d8.loss_cls: 0.6848  decode.d8.loss_mask: 0.3098  decode.d8.loss_dice: 0.3854
07/25 20:08:20 - mmengine - INFO - Iter(train) [ 6850/80000]  base_lr: 9.2261e-05 lr: 9.2261e-06  eta: 9:18:22  time: 0.4606  data_time: 0.0106  memory: 5265  grad_norm: 100.7093  loss: 11.3850  decode.loss_cls: 0.3916  decode.loss_mask: 0.2679  decode.loss_dice: 0.3699  decode.d0.loss_cls: 1.2950  decode.d0.loss_mask: 0.2833  decode.d0.loss_dice: 0.4075  decode.d1.loss_cls: 0.4188  decode.d1.loss_mask: 0.2713  decode.d1.loss_dice: 0.3826  decode.d2.loss_cls: 0.3966  decode.d2.loss_mask: 0.2650  decode.d2.loss_dice: 0.3612  decode.d3.loss_cls: 0.3644  decode.d3.loss_mask: 0.2700  decode.d3.loss_dice: 0.3656  decode.d4.loss_cls: 0.4201  decode.d4.loss_mask: 0.2680  decode.d4.loss_dice: 0.3618  decode.d5.loss_cls: 0.4093  decode.d5.loss_mask: 0.2809  decode.d5.loss_dice: 0.3778  decode.d6.loss_cls: 0.4039  decode.d6.loss_mask: 0.2651  decode.d6.loss_dice: 0.3720  decode.d7.loss_cls: 0.4447  decode.d7.loss_mask: 0.2660  decode.d7.loss_dice: 0.3567  decode.d8.loss_cls: 0.4055  decode.d8.loss_mask: 0.2649  decode.d8.loss_dice: 0.3775
07/25 20:08:43 - mmengine - INFO - Iter(train) [ 6900/80000]  base_lr: 9.2204e-05 lr: 9.2204e-06  eta: 9:17:55  time: 0.4599  data_time: 0.0103  memory: 5249  grad_norm: 141.0367  loss: 15.2741  decode.loss_cls: 0.6987  decode.loss_mask: 0.2909  decode.loss_dice: 0.3786  decode.d0.loss_cls: 1.6377  decode.d0.loss_mask: 0.3246  decode.d0.loss_dice: 0.4415  decode.d1.loss_cls: 0.8133  decode.d1.loss_mask: 0.2942  decode.d1.loss_dice: 0.3698  decode.d2.loss_cls: 0.7604  decode.d2.loss_mask: 0.3181  decode.d2.loss_dice: 0.3532  decode.d3.loss_cls: 0.7425  decode.d3.loss_mask: 0.3111  decode.d3.loss_dice: 0.4083  decode.d4.loss_cls: 0.7616  decode.d4.loss_mask: 0.2849  decode.d4.loss_dice: 0.3759  decode.d5.loss_cls: 0.6988  decode.d5.loss_mask: 0.3091  decode.d5.loss_dice: 0.3840  decode.d6.loss_cls: 0.7661  decode.d6.loss_mask: 0.2976  decode.d6.loss_dice: 0.3923  decode.d7.loss_cls: 0.7713  decode.d7.loss_mask: 0.2858  decode.d7.loss_dice: 0.3573  decode.d8.loss_cls: 0.7870  decode.d8.loss_mask: 0.2827  decode.d8.loss_dice: 0.3769
07/25 20:09:06 - mmengine - INFO - Iter(train) [ 6950/80000]  base_lr: 9.2147e-05 lr: 9.2147e-06  eta: 9:17:29  time: 0.4393  data_time: 0.0090  memory: 5249  grad_norm: 79.0003  loss: 11.0764  decode.loss_cls: 0.4010  decode.loss_mask: 0.2451  decode.loss_dice: 0.3480  decode.d0.loss_cls: 1.0929  decode.d0.loss_mask: 0.2555  decode.d0.loss_dice: 0.4122  decode.d1.loss_cls: 0.5584  decode.d1.loss_mask: 0.2448  decode.d1.loss_dice: 0.3644  decode.d2.loss_cls: 0.4286  decode.d2.loss_mask: 0.2444  decode.d2.loss_dice: 0.3634  decode.d3.loss_cls: 0.4794  decode.d3.loss_mask: 0.2419  decode.d3.loss_dice: 0.3126  decode.d4.loss_cls: 0.4310  decode.d4.loss_mask: 0.2428  decode.d4.loss_dice: 0.3237  decode.d5.loss_cls: 0.4198  decode.d5.loss_mask: 0.2477  decode.d5.loss_dice: 0.3321  decode.d6.loss_cls: 0.4433  decode.d6.loss_mask: 0.2552  decode.d6.loss_dice: 0.3684  decode.d7.loss_cls: 0.4461  decode.d7.loss_mask: 0.2459  decode.d7.loss_dice: 0.3408  decode.d8.loss_cls: 0.4127  decode.d8.loss_mask: 0.2468  decode.d8.loss_dice: 0.3274
07/25 20:09:29 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250725_191538
07/25 20:09:29 - mmengine - INFO - Iter(train) [ 7000/80000]  base_lr: 9.2090e-05 lr: 9.2090e-06  eta: 9:17:07  time: 0.4620  data_time: 0.0103  memory: 5249  grad_norm: 116.5093  loss: 11.9057  decode.loss_cls: 0.4759  decode.loss_mask: 0.2833  decode.loss_dice: 0.3208  decode.d0.loss_cls: 1.2436  decode.d0.loss_mask: 0.2895  decode.d0.loss_dice: 0.3464  decode.d1.loss_cls: 0.5184  decode.d1.loss_mask: 0.2947  decode.d1.loss_dice: 0.3021  decode.d2.loss_cls: 0.4819  decode.d2.loss_mask: 0.2925  decode.d2.loss_dice: 0.3286  decode.d3.loss_cls: 0.5458  decode.d3.loss_mask: 0.2900  decode.d3.loss_dice: 0.3150  decode.d4.loss_cls: 0.4910  decode.d4.loss_mask: 0.2857  decode.d4.loss_dice: 0.3105  decode.d5.loss_cls: 0.4607  decode.d5.loss_mask: 0.2799  decode.d5.loss_dice: 0.3129  decode.d6.loss_cls: 0.5205  decode.d6.loss_mask: 0.2839  decode.d6.loss_dice: 0.3132  decode.d7.loss_cls: 0.5898  decode.d7.loss_mask: 0.2866  decode.d7.loss_dice: 0.3239  decode.d8.loss_cls: 0.5194  decode.d8.loss_mask: 0.2856  decode.d8.loss_dice: 0.3136
07/25 20:09:51 - mmengine - INFO - Iter(train) [ 7050/80000]  base_lr: 9.2034e-05 lr: 9.2034e-06  eta: 9:16:44  time: 0.4535  data_time: 0.0104  memory: 5307  grad_norm: 104.3749  loss: 11.6599  decode.loss_cls: 0.4687  decode.loss_mask: 0.2944  decode.loss_dice: 0.2812  decode.d0.loss_cls: 1.3624  decode.d0.loss_mask: 0.3377  decode.d0.loss_dice: 0.3241  decode.d1.loss_cls: 0.5328  decode.d1.loss_mask: 0.3193  decode.d1.loss_dice: 0.2908  decode.d2.loss_cls: 0.4966  decode.d2.loss_mask: 0.3098  decode.d2.loss_dice: 0.3142  decode.d3.loss_cls: 0.4135  decode.d3.loss_mask: 0.3128  decode.d3.loss_dice: 0.3059  decode.d4.loss_cls: 0.4486  decode.d4.loss_mask: 0.2951  decode.d4.loss_dice: 0.3115  decode.d5.loss_cls: 0.4574  decode.d5.loss_mask: 0.3022  decode.d5.loss_dice: 0.3268  decode.d6.loss_cls: 0.4618  decode.d6.loss_mask: 0.3026  decode.d6.loss_dice: 0.3070  decode.d7.loss_cls: 0.4153  decode.d7.loss_mask: 0.3051  decode.d7.loss_dice: 0.3062  decode.d8.loss_cls: 0.4556  decode.d8.loss_mask: 0.2995  decode.d8.loss_dice: 0.3009
07/25 20:10:14 - mmengine - INFO - Iter(train) [ 7100/80000]  base_lr: 9.1977e-05 lr: 9.1977e-06  eta: 9:16:21  time: 0.4583  data_time: 0.0103  memory: 5231  grad_norm: 94.9455  loss: 12.1124  decode.loss_cls: 0.4708  decode.loss_mask: 0.3248  decode.loss_dice: 0.3372  decode.d0.loss_cls: 1.4324  decode.d0.loss_mask: 0.3397  decode.d0.loss_dice: 0.3568  decode.d1.loss_cls: 0.6008  decode.d1.loss_mask: 0.3228  decode.d1.loss_dice: 0.3287  decode.d2.loss_cls: 0.4694  decode.d2.loss_mask: 0.3225  decode.d2.loss_dice: 0.3230  decode.d3.loss_cls: 0.4140  decode.d3.loss_mask: 0.3320  decode.d3.loss_dice: 0.3438  decode.d4.loss_cls: 0.3907  decode.d4.loss_mask: 0.3295  decode.d4.loss_dice: 0.3241  decode.d5.loss_cls: 0.4145  decode.d5.loss_mask: 0.3288  decode.d5.loss_dice: 0.3201  decode.d6.loss_cls: 0.4631  decode.d6.loss_mask: 0.3214  decode.d6.loss_dice: 0.3360  decode.d7.loss_cls: 0.4404  decode.d7.loss_mask: 0.3216  decode.d7.loss_dice: 0.3147  decode.d8.loss_cls: 0.4421  decode.d8.loss_mask: 0.3168  decode.d8.loss_dice: 0.3299
07/25 20:10:37 - mmengine - INFO - Iter(train) [ 7150/80000]  base_lr: 9.1920e-05 lr: 9.1920e-06  eta: 9:15:58  time: 0.4567  data_time: 0.0103  memory: 5251  grad_norm: 281.7275  loss: 17.1612  decode.loss_cls: 0.5859  decode.loss_mask: 0.6544  decode.loss_dice: 0.5624  decode.d0.loss_cls: 1.3793  decode.d0.loss_mask: 0.5027  decode.d0.loss_dice: 0.4778  decode.d1.loss_cls: 0.6965  decode.d1.loss_mask: 0.4970  decode.d1.loss_dice: 0.4627  decode.d2.loss_cls: 0.6118  decode.d2.loss_mask: 0.5358  decode.d2.loss_dice: 0.4344  decode.d3.loss_cls: 0.5431  decode.d3.loss_mask: 0.4854  decode.d3.loss_dice: 0.4807  decode.d4.loss_cls: 0.5109  decode.d4.loss_mask: 0.5789  decode.d4.loss_dice: 0.4922  decode.d5.loss_cls: 0.6032  decode.d5.loss_mask: 0.6020  decode.d5.loss_dice: 0.4733  decode.d6.loss_cls: 0.5750  decode.d6.loss_mask: 0.5287  decode.d6.loss_dice: 0.4984  decode.d7.loss_cls: 0.6039  decode.d7.loss_mask: 0.5369  decode.d7.loss_dice: 0.4989  decode.d8.loss_cls: 0.5869  decode.d8.loss_mask: 0.6359  decode.d8.loss_dice: 0.5260
07/25 20:11:00 - mmengine - INFO - Iter(train) [ 7200/80000]  base_lr: 9.1863e-05 lr: 9.1863e-06  eta: 9:15:35  time: 0.4564  data_time: 0.0102  memory: 5214  grad_norm: 86.9535  loss: 10.1850  decode.loss_cls: 0.3189  decode.loss_mask: 0.2588  decode.loss_dice: 0.2776  decode.d0.loss_cls: 1.3089  decode.d0.loss_mask: 0.2749  decode.d0.loss_dice: 0.3114  decode.d1.loss_cls: 0.5829  decode.d1.loss_mask: 0.3097  decode.d1.loss_dice: 0.3024  decode.d2.loss_cls: 0.4014  decode.d2.loss_mask: 0.2705  decode.d2.loss_dice: 0.2735  decode.d3.loss_cls: 0.3768  decode.d3.loss_mask: 0.2648  decode.d3.loss_dice: 0.2702  decode.d4.loss_cls: 0.3369  decode.d4.loss_mask: 0.2646  decode.d4.loss_dice: 0.2914  decode.d5.loss_cls: 0.3380  decode.d5.loss_mask: 0.2622  decode.d5.loss_dice: 0.2774  decode.d6.loss_cls: 0.3228  decode.d6.loss_mask: 0.2642  decode.d6.loss_dice: 0.2664  decode.d7.loss_cls: 0.3438  decode.d7.loss_mask: 0.2641  decode.d7.loss_dice: 0.2728  decode.d8.loss_cls: 0.3336  decode.d8.loss_mask: 0.2672  decode.d8.loss_dice: 0.2769
07/25 20:11:23 - mmengine - INFO - Iter(train) [ 7250/80000]  base_lr: 9.1807e-05 lr: 9.1807e-06  eta: 9:15:11  time: 0.4631  data_time: 0.0106  memory: 5249  grad_norm: 184.8900  loss: 15.1198  decode.loss_cls: 0.6766  decode.loss_mask: 0.3122  decode.loss_dice: 0.4124  decode.d0.loss_cls: 1.4971  decode.d0.loss_mask: 0.3157  decode.d0.loss_dice: 0.5196  decode.d1.loss_cls: 0.7518  decode.d1.loss_mask: 0.3109  decode.d1.loss_dice: 0.3853  decode.d2.loss_cls: 0.7389  decode.d2.loss_mask: 0.2968  decode.d2.loss_dice: 0.3902  decode.d3.loss_cls: 0.6662  decode.d3.loss_mask: 0.3202  decode.d3.loss_dice: 0.4388  decode.d4.loss_cls: 0.7279  decode.d4.loss_mask: 0.2973  decode.d4.loss_dice: 0.3933  decode.d5.loss_cls: 0.7199  decode.d5.loss_mask: 0.3073  decode.d5.loss_dice: 0.3892  decode.d6.loss_cls: 0.7420  decode.d6.loss_mask: 0.3140  decode.d6.loss_dice: 0.4047  decode.d7.loss_cls: 0.6757  decode.d7.loss_mask: 0.3240  decode.d7.loss_dice: 0.4193  decode.d8.loss_cls: 0.6623  decode.d8.loss_mask: 0.3067  decode.d8.loss_dice: 0.4035
07/25 20:11:46 - mmengine - INFO - Iter(train) [ 7300/80000]  base_lr: 9.1750e-05 lr: 9.1750e-06  eta: 9:14:47  time: 0.4439  data_time: 0.0095  memory: 5265  grad_norm: 124.6263  loss: 12.6163  decode.loss_cls: 0.4968  decode.loss_mask: 0.3719  decode.loss_dice: 0.3538  decode.d0.loss_cls: 1.1420  decode.d0.loss_mask: 0.3546  decode.d0.loss_dice: 0.3547  decode.d1.loss_cls: 0.5086  decode.d1.loss_mask: 0.3342  decode.d1.loss_dice: 0.3709  decode.d2.loss_cls: 0.4511  decode.d2.loss_mask: 0.3376  decode.d2.loss_dice: 0.3640  decode.d3.loss_cls: 0.4569  decode.d3.loss_mask: 0.3675  decode.d3.loss_dice: 0.3534  decode.d4.loss_cls: 0.4537  decode.d4.loss_mask: 0.3507  decode.d4.loss_dice: 0.3718  decode.d5.loss_cls: 0.4491  decode.d5.loss_mask: 0.3783  decode.d5.loss_dice: 0.3801  decode.d6.loss_cls: 0.4751  decode.d6.loss_mask: 0.3630  decode.d6.loss_dice: 0.3745  decode.d7.loss_cls: 0.4762  decode.d7.loss_mask: 0.3497  decode.d7.loss_dice: 0.3545  decode.d8.loss_cls: 0.5226  decode.d8.loss_mask: 0.3338  decode.d8.loss_dice: 0.3655
07/25 20:12:09 - mmengine - INFO - Iter(train) [ 7350/80000]  base_lr: 9.1693e-05 lr: 9.1693e-06  eta: 9:14:27  time: 0.4770  data_time: 0.0101  memory: 5249  grad_norm: 134.7471  loss: 10.9405  decode.loss_cls: 0.3751  decode.loss_mask: 0.2508  decode.loss_dice: 0.3129  decode.d0.loss_cls: 1.3519  decode.d0.loss_mask: 0.2674  decode.d0.loss_dice: 0.3737  decode.d1.loss_cls: 0.4988  decode.d1.loss_mask: 0.2661  decode.d1.loss_dice: 0.3100  decode.d2.loss_cls: 0.3769  decode.d2.loss_mask: 0.2590  decode.d2.loss_dice: 0.3057  decode.d3.loss_cls: 0.4322  decode.d3.loss_mask: 0.2706  decode.d3.loss_dice: 0.3316  decode.d4.loss_cls: 0.4696  decode.d4.loss_mask: 0.2537  decode.d4.loss_dice: 0.3201  decode.d5.loss_cls: 0.3903  decode.d5.loss_mask: 0.2563  decode.d5.loss_dice: 0.3196  decode.d6.loss_cls: 0.4122  decode.d6.loss_mask: 0.2580  decode.d6.loss_dice: 0.3296  decode.d7.loss_cls: 0.4091  decode.d7.loss_mask: 0.2603  decode.d7.loss_dice: 0.3128  decode.d8.loss_cls: 0.3950  decode.d8.loss_mask: 0.2646  decode.d8.loss_dice: 0.3067
07/25 20:12:32 - mmengine - INFO - Iter(train) [ 7400/80000]  base_lr: 9.1636e-05 lr: 9.1636e-06  eta: 9:14:04  time: 0.4575  data_time: 0.0102  memory: 5231  grad_norm: 289.0346  loss: 17.3791  decode.loss_cls: 0.7289  decode.loss_mask: 0.4226  decode.loss_dice: 0.4749  decode.d0.loss_cls: 1.5615  decode.d0.loss_mask: 0.4386  decode.d0.loss_dice: 0.5106  decode.d1.loss_cls: 0.9653  decode.d1.loss_mask: 0.4236  decode.d1.loss_dice: 0.4281  decode.d2.loss_cls: 0.8139  decode.d2.loss_mask: 0.4220  decode.d2.loss_dice: 0.4844  decode.d3.loss_cls: 0.7468  decode.d3.loss_mask: 0.4441  decode.d3.loss_dice: 0.4817  decode.d4.loss_cls: 0.6954  decode.d4.loss_mask: 0.4559  decode.d4.loss_dice: 0.4435  decode.d5.loss_cls: 0.7066  decode.d5.loss_mask: 0.4336  decode.d5.loss_dice: 0.4536  decode.d6.loss_cls: 0.7264  decode.d6.loss_mask: 0.4332  decode.d6.loss_dice: 0.4646  decode.d7.loss_cls: 0.7168  decode.d7.loss_mask: 0.4176  decode.d7.loss_dice: 0.4712  decode.d8.loss_cls: 0.7583  decode.d8.loss_mask: 0.4057  decode.d8.loss_dice: 0.4499
07/25 20:12:55 - mmengine - INFO - Iter(train) [ 7450/80000]  base_lr: 9.1579e-05 lr: 9.1579e-06  eta: 9:13:42  time: 0.4571  data_time: 0.0102  memory: 5293  grad_norm: 109.0029  loss: 14.2044  decode.loss_cls: 0.4800  decode.loss_mask: 0.3509  decode.loss_dice: 0.4626  decode.d0.loss_cls: 1.4809  decode.d0.loss_mask: 0.4057  decode.d0.loss_dice: 0.5679  decode.d1.loss_cls: 0.6301  decode.d1.loss_mask: 0.3713  decode.d1.loss_dice: 0.4791  decode.d2.loss_cls: 0.5103  decode.d2.loss_mask: 0.3685  decode.d2.loss_dice: 0.4606  decode.d3.loss_cls: 0.4501  decode.d3.loss_mask: 0.3758  decode.d3.loss_dice: 0.4837  decode.d4.loss_cls: 0.4069  decode.d4.loss_mask: 0.3651  decode.d4.loss_dice: 0.5077  decode.d5.loss_cls: 0.4229  decode.d5.loss_mask: 0.3675  decode.d5.loss_dice: 0.5070  decode.d6.loss_cls: 0.4427  decode.d6.loss_mask: 0.3640  decode.d6.loss_dice: 0.4801  decode.d7.loss_cls: 0.3992  decode.d7.loss_mask: 0.3513  decode.d7.loss_dice: 0.4657  decode.d8.loss_cls: 0.4215  decode.d8.loss_mask: 0.3508  decode.d8.loss_dice: 0.4745
07/25 20:13:18 - mmengine - INFO - Iter(train) [ 7500/80000]  base_lr: 9.1523e-05 lr: 9.1523e-06  eta: 9:13:19  time: 0.4564  data_time: 0.0100  memory: 5265  grad_norm: 139.9567  loss: 12.4723  decode.loss_cls: 0.5111  decode.loss_mask: 0.3061  decode.loss_dice: 0.3343  decode.d0.loss_cls: 1.2132  decode.d0.loss_mask: 0.3189  decode.d0.loss_dice: 0.4110  decode.d1.loss_cls: 0.5576  decode.d1.loss_mask: 0.3181  decode.d1.loss_dice: 0.3553  decode.d2.loss_cls: 0.5149  decode.d2.loss_mask: 0.3110  decode.d2.loss_dice: 0.3074  decode.d3.loss_cls: 0.5453  decode.d3.loss_mask: 0.3080  decode.d3.loss_dice: 0.3350  decode.d4.loss_cls: 0.5251  decode.d4.loss_mask: 0.3233  decode.d4.loss_dice: 0.3571  decode.d5.loss_cls: 0.5738  decode.d5.loss_mask: 0.3069  decode.d5.loss_dice: 0.3516  decode.d6.loss_cls: 0.4667  decode.d6.loss_mask: 0.3118  decode.d6.loss_dice: 0.3238  decode.d7.loss_cls: 0.4957  decode.d7.loss_mask: 0.3124  decode.d7.loss_dice: 0.3406  decode.d8.loss_cls: 0.4918  decode.d8.loss_mask: 0.3097  decode.d8.loss_dice: 0.3352
07/25 20:13:40 - mmengine - INFO - Iter(train) [ 7550/80000]  base_lr: 9.1466e-05 lr: 9.1466e-06  eta: 9:12:56  time: 0.4584  data_time: 0.0101  memory: 5249  grad_norm: 134.3623  loss: 11.5152  decode.loss_cls: 0.4088  decode.loss_mask: 0.3061  decode.loss_dice: 0.3323  decode.d0.loss_cls: 1.1688  decode.d0.loss_mask: 0.3226  decode.d0.loss_dice: 0.4038  decode.d1.loss_cls: 0.5776  decode.d1.loss_mask: 0.3060  decode.d1.loss_dice: 0.3441  decode.d2.loss_cls: 0.4227  decode.d2.loss_mask: 0.2902  decode.d2.loss_dice: 0.3349  decode.d3.loss_cls: 0.4092  decode.d3.loss_mask: 0.2959  decode.d3.loss_dice: 0.3321  decode.d4.loss_cls: 0.4922  decode.d4.loss_mask: 0.2943  decode.d4.loss_dice: 0.3184  decode.d5.loss_cls: 0.3886  decode.d5.loss_mask: 0.3009  decode.d5.loss_dice: 0.3293  decode.d6.loss_cls: 0.3923  decode.d6.loss_mask: 0.2940  decode.d6.loss_dice: 0.3361  decode.d7.loss_cls: 0.4101  decode.d7.loss_mask: 0.3021  decode.d7.loss_dice: 0.3430  decode.d8.loss_cls: 0.4103  decode.d8.loss_mask: 0.3029  decode.d8.loss_dice: 0.3457
07/25 20:14:03 - mmengine - INFO - Iter(train) [ 7600/80000]  base_lr: 9.1409e-05 lr: 9.1409e-06  eta: 9:12:31  time: 0.4603  data_time: 0.0104  memory: 5215  grad_norm: 144.2463  loss: 13.2741  decode.loss_cls: 0.4642  decode.loss_mask: 0.3572  decode.loss_dice: 0.3947  decode.d0.loss_cls: 1.4273  decode.d0.loss_mask: 0.3237  decode.d0.loss_dice: 0.4292  decode.d1.loss_cls: 0.6250  decode.d1.loss_mask: 0.2914  decode.d1.loss_dice: 0.3610  decode.d2.loss_cls: 0.5939  decode.d2.loss_mask: 0.3030  decode.d2.loss_dice: 0.3660  decode.d3.loss_cls: 0.5334  decode.d3.loss_mask: 0.3176  decode.d3.loss_dice: 0.3847  decode.d4.loss_cls: 0.5277  decode.d4.loss_mask: 0.3051  decode.d4.loss_dice: 0.3468  decode.d5.loss_cls: 0.5302  decode.d5.loss_mask: 0.3168  decode.d5.loss_dice: 0.3680  decode.d6.loss_cls: 0.4923  decode.d6.loss_mask: 0.3363  decode.d6.loss_dice: 0.3641  decode.d7.loss_cls: 0.5199  decode.d7.loss_mask: 0.3676  decode.d7.loss_dice: 0.3853  decode.d8.loss_cls: 0.4985  decode.d8.loss_mask: 0.3449  decode.d8.loss_dice: 0.3982
07/25 20:14:26 - mmengine - INFO - Iter(train) [ 7650/80000]  base_lr: 9.1352e-05 lr: 9.1352e-06  eta: 9:12:07  time: 0.4412  data_time: 0.0093  memory: 5228  grad_norm: 61.3215  loss: 10.7723  decode.loss_cls: 0.3160  decode.loss_mask: 0.3047  decode.loss_dice: 0.3382  decode.d0.loss_cls: 1.2001  decode.d0.loss_mask: 0.3145  decode.d0.loss_dice: 0.3754  decode.d1.loss_cls: 0.3925  decode.d1.loss_mask: 0.3170  decode.d1.loss_dice: 0.3371  decode.d2.loss_cls: 0.3689  decode.d2.loss_mask: 0.3189  decode.d2.loss_dice: 0.3466  decode.d3.loss_cls: 0.3515  decode.d3.loss_mask: 0.3143  decode.d3.loss_dice: 0.3230  decode.d4.loss_cls: 0.2925  decode.d4.loss_mask: 0.3087  decode.d4.loss_dice: 0.3311  decode.d5.loss_cls: 0.3426  decode.d5.loss_mask: 0.3021  decode.d5.loss_dice: 0.3210  decode.d6.loss_cls: 0.3290  decode.d6.loss_mask: 0.3095  decode.d6.loss_dice: 0.3385  decode.d7.loss_cls: 0.3578  decode.d7.loss_mask: 0.3036  decode.d7.loss_dice: 0.3301  decode.d8.loss_cls: 0.3615  decode.d8.loss_mask: 0.3033  decode.d8.loss_dice: 0.3224
07/25 20:14:49 - mmengine - INFO - Iter(train) [ 7700/80000]  base_lr: 9.1295e-05 lr: 9.1295e-06  eta: 9:11:42  time: 0.4545  data_time: 0.0102  memory: 5265  grad_norm: 180.6606  loss: 14.3589  decode.loss_cls: 0.6838  decode.loss_mask: 0.2690  decode.loss_dice: 0.4020  decode.d0.loss_cls: 1.6859  decode.d0.loss_mask: 0.2902  decode.d0.loss_dice: 0.4557  decode.d1.loss_cls: 0.8705  decode.d1.loss_mask: 0.2651  decode.d1.loss_dice: 0.3729  decode.d2.loss_cls: 0.6512  decode.d2.loss_mask: 0.2739  decode.d2.loss_dice: 0.4149  decode.d3.loss_cls: 0.6237  decode.d3.loss_mask: 0.2560  decode.d3.loss_dice: 0.3811  decode.d4.loss_cls: 0.6693  decode.d4.loss_mask: 0.2588  decode.d4.loss_dice: 0.3780  decode.d5.loss_cls: 0.5942  decode.d5.loss_mask: 0.2763  decode.d5.loss_dice: 0.4005  decode.d6.loss_cls: 0.6159  decode.d6.loss_mask: 0.2728  decode.d6.loss_dice: 0.3900  decode.d7.loss_cls: 0.6908  decode.d7.loss_mask: 0.2624  decode.d7.loss_dice: 0.3910  decode.d8.loss_cls: 0.5914  decode.d8.loss_mask: 0.2738  decode.d8.loss_dice: 0.3978
07/25 20:15:11 - mmengine - INFO - Iter(train) [ 7750/80000]  base_lr: 9.1238e-05 lr: 9.1238e-06  eta: 9:11:18  time: 0.4548  data_time: 0.0098  memory: 5249  grad_norm: 98.8363  loss: 10.3135  decode.loss_cls: 0.3613  decode.loss_mask: 0.2363  decode.loss_dice: 0.2712  decode.d0.loss_cls: 1.3021  decode.d0.loss_mask: 0.2149  decode.d0.loss_dice: 0.3303  decode.d1.loss_cls: 0.5326  decode.d1.loss_mask: 0.2326  decode.d1.loss_dice: 0.2984  decode.d2.loss_cls: 0.4018  decode.d2.loss_mask: 0.2231  decode.d2.loss_dice: 0.3011  decode.d3.loss_cls: 0.4134  decode.d3.loss_mask: 0.2186  decode.d3.loss_dice: 0.2907  decode.d4.loss_cls: 0.4327  decode.d4.loss_mask: 0.2381  decode.d4.loss_dice: 0.3214  decode.d5.loss_cls: 0.3930  decode.d5.loss_mask: 0.2399  decode.d5.loss_dice: 0.3368  decode.d6.loss_cls: 0.3816  decode.d6.loss_mask: 0.2438  decode.d6.loss_dice: 0.3113  decode.d7.loss_cls: 0.3500  decode.d7.loss_mask: 0.2453  decode.d7.loss_dice: 0.2969  decode.d8.loss_cls: 0.3494  decode.d8.loss_mask: 0.2360  decode.d8.loss_dice: 0.3090
07/25 20:15:34 - mmengine - INFO - Iter(train) [ 7800/80000]  base_lr: 9.1182e-05 lr: 9.1182e-06  eta: 9:10:55  time: 0.4571  data_time: 0.0102  memory: 5265  grad_norm: 116.9345  loss: 10.7480  decode.loss_cls: 0.2904  decode.loss_mask: 0.3564  decode.loss_dice: 0.2961  decode.d0.loss_cls: 1.2148  decode.d0.loss_mask: 0.3668  decode.d0.loss_dice: 0.3186  decode.d1.loss_cls: 0.4118  decode.d1.loss_mask: 0.3569  decode.d1.loss_dice: 0.3219  decode.d2.loss_cls: 0.3181  decode.d2.loss_mask: 0.3599  decode.d2.loss_dice: 0.3113  decode.d3.loss_cls: 0.3064  decode.d3.loss_mask: 0.3479  decode.d3.loss_dice: 0.2978  decode.d4.loss_cls: 0.3109  decode.d4.loss_mask: 0.3407  decode.d4.loss_dice: 0.3024  decode.d5.loss_cls: 0.3246  decode.d5.loss_mask: 0.3492  decode.d5.loss_dice: 0.3121  decode.d6.loss_cls: 0.3039  decode.d6.loss_mask: 0.3523  decode.d6.loss_dice: 0.2931  decode.d7.loss_cls: 0.3520  decode.d7.loss_mask: 0.3511  decode.d7.loss_dice: 0.2863  decode.d8.loss_cls: 0.3564  decode.d8.loss_mask: 0.3491  decode.d8.loss_dice: 0.2888
07/25 20:15:57 - mmengine - INFO - Iter(train) [ 7850/80000]  base_lr: 9.1125e-05 lr: 9.1125e-06  eta: 9:10:32  time: 0.4641  data_time: 0.0104  memory: 5248  grad_norm: 138.6520  loss: 10.1559  decode.loss_cls: 0.3948  decode.loss_mask: 0.2329  decode.loss_dice: 0.2702  decode.d0.loss_cls: 1.3185  decode.d0.loss_mask: 0.2913  decode.d0.loss_dice: 0.3539  decode.d1.loss_cls: 0.4593  decode.d1.loss_mask: 0.2590  decode.d1.loss_dice: 0.3071  decode.d2.loss_cls: 0.3622  decode.d2.loss_mask: 0.2427  decode.d2.loss_dice: 0.2914  decode.d3.loss_cls: 0.3566  decode.d3.loss_mask: 0.2437  decode.d3.loss_dice: 0.2878  decode.d4.loss_cls: 0.3621  decode.d4.loss_mask: 0.2430  decode.d4.loss_dice: 0.2843  decode.d5.loss_cls: 0.3863  decode.d5.loss_mask: 0.2352  decode.d5.loss_dice: 0.2908  decode.d6.loss_cls: 0.3995  decode.d6.loss_mask: 0.2292  decode.d6.loss_dice: 0.2815  decode.d7.loss_cls: 0.3641  decode.d7.loss_mask: 0.2311  decode.d7.loss_dice: 0.2741  decode.d8.loss_cls: 0.3949  decode.d8.loss_mask: 0.2353  decode.d8.loss_dice: 0.2730
07/25 20:16:20 - mmengine - INFO - Iter(train) [ 7900/80000]  base_lr: 9.1068e-05 lr: 9.1068e-06  eta: 9:10:09  time: 0.4560  data_time: 0.0101  memory: 5249  grad_norm: 123.0808  loss: 12.7122  decode.loss_cls: 0.5113  decode.loss_mask: 0.2540  decode.loss_dice: 0.3768  decode.d0.loss_cls: 1.5146  decode.d0.loss_mask: 0.3100  decode.d0.loss_dice: 0.4520  decode.d1.loss_cls: 0.5585  decode.d1.loss_mask: 0.2731  decode.d1.loss_dice: 0.3928  decode.d2.loss_cls: 0.5142  decode.d2.loss_mask: 0.2611  decode.d2.loss_dice: 0.3822  decode.d3.loss_cls: 0.4499  decode.d3.loss_mask: 0.2614  decode.d3.loss_dice: 0.3811  decode.d4.loss_cls: 0.5698  decode.d4.loss_mask: 0.2610  decode.d4.loss_dice: 0.3648  decode.d5.loss_cls: 0.5139  decode.d5.loss_mask: 0.2592  decode.d5.loss_dice: 0.3963  decode.d6.loss_cls: 0.5128  decode.d6.loss_mask: 0.2565  decode.d6.loss_dice: 0.3711  decode.d7.loss_cls: 0.5052  decode.d7.loss_mask: 0.2629  decode.d7.loss_dice: 0.3875  decode.d8.loss_cls: 0.5068  decode.d8.loss_mask: 0.2627  decode.d8.loss_dice: 0.3887
07/25 20:16:43 - mmengine - INFO - Iter(train) [ 7950/80000]  base_lr: 9.1011e-05 lr: 9.1011e-06  eta: 9:09:45  time: 0.4414  data_time: 0.0091  memory: 5249  grad_norm: 98.9687  loss: 13.5050  decode.loss_cls: 0.6155  decode.loss_mask: 0.3150  decode.loss_dice: 0.3179  decode.d0.loss_cls: 1.4903  decode.d0.loss_mask: 0.3115  decode.d0.loss_dice: 0.3822  decode.d1.loss_cls: 0.7413  decode.d1.loss_mask: 0.3139  decode.d1.loss_dice: 0.3421  decode.d2.loss_cls: 0.6093  decode.d2.loss_mask: 0.3369  decode.d2.loss_dice: 0.3370  decode.d3.loss_cls: 0.6034  decode.d3.loss_mask: 0.2958  decode.d3.loss_dice: 0.3271  decode.d4.loss_cls: 0.5603  decode.d4.loss_mask: 0.3034  decode.d4.loss_dice: 0.3347  decode.d5.loss_cls: 0.5785  decode.d5.loss_mask: 0.3121  decode.d5.loss_dice: 0.3314  decode.d6.loss_cls: 0.6236  decode.d6.loss_mask: 0.3092  decode.d6.loss_dice: 0.3079  decode.d7.loss_cls: 0.6096  decode.d7.loss_mask: 0.3057  decode.d7.loss_dice: 0.3345  decode.d8.loss_cls: 0.5979  decode.d8.loss_mask: 0.3151  decode.d8.loss_dice: 0.3420
07/25 20:17:06 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250725_191538
07/25 20:17:06 - mmengine - INFO - Iter(train) [ 8000/80000]  base_lr: 9.0954e-05 lr: 9.0954e-06  eta: 9:09:21  time: 0.4527  data_time: 0.0100  memory: 5249  grad_norm: 169.4008  loss: 14.9505  decode.loss_cls: 0.6156  decode.loss_mask: 0.3921  decode.loss_dice: 0.3721  decode.d0.loss_cls: 1.6655  decode.d0.loss_mask: 0.3978  decode.d0.loss_dice: 0.4445  decode.d1.loss_cls: 0.7539  decode.d1.loss_mask: 0.3421  decode.d1.loss_dice: 0.3786  decode.d2.loss_cls: 0.6692  decode.d2.loss_mask: 0.3965  decode.d2.loss_dice: 0.3634  decode.d3.loss_cls: 0.6925  decode.d3.loss_mask: 0.3802  decode.d3.loss_dice: 0.3624  decode.d4.loss_cls: 0.6339  decode.d4.loss_mask: 0.3953  decode.d4.loss_dice: 0.3593  decode.d5.loss_cls: 0.6733  decode.d5.loss_mask: 0.3303  decode.d5.loss_dice: 0.3508  decode.d6.loss_cls: 0.6635  decode.d6.loss_mask: 0.3498  decode.d6.loss_dice: 0.3307  decode.d7.loss_cls: 0.5780  decode.d7.loss_mask: 0.3944  decode.d7.loss_dice: 0.3428  decode.d8.loss_cls: 0.5946  decode.d8.loss_mask: 0.3907  decode.d8.loss_dice: 0.3366
07/25 20:17:28 - mmengine - INFO - Iter(train) [ 8050/80000]  base_lr: 9.0897e-05 lr: 9.0897e-06  eta: 9:08:55  time: 0.4583  data_time: 0.0102  memory: 5248  grad_norm: 93.9931  loss: 13.6095  decode.loss_cls: 0.5093  decode.loss_mask: 0.2908  decode.loss_dice: 0.4447  decode.d0.loss_cls: 1.5874  decode.d0.loss_mask: 0.3029  decode.d0.loss_dice: 0.4977  decode.d1.loss_cls: 0.5483  decode.d1.loss_mask: 0.3066  decode.d1.loss_dice: 0.4462  decode.d2.loss_cls: 0.4971  decode.d2.loss_mask: 0.2974  decode.d2.loss_dice: 0.4244  decode.d3.loss_cls: 0.5089  decode.d3.loss_mask: 0.2966  decode.d3.loss_dice: 0.4392  decode.d4.loss_cls: 0.4925  decode.d4.loss_mask: 0.2995  decode.d4.loss_dice: 0.4413  decode.d5.loss_cls: 0.5368  decode.d5.loss_mask: 0.2952  decode.d5.loss_dice: 0.4123  decode.d6.loss_cls: 0.5529  decode.d6.loss_mask: 0.2932  decode.d6.loss_dice: 0.4120  decode.d7.loss_cls: 0.5202  decode.d7.loss_mask: 0.2965  decode.d7.loss_dice: 0.4431  decode.d8.loss_cls: 0.4799  decode.d8.loss_mask: 0.2890  decode.d8.loss_dice: 0.4476
07/25 20:17:51 - mmengine - INFO - Iter(train) [ 8100/80000]  base_lr: 9.0841e-05 lr: 9.0841e-06  eta: 9:08:32  time: 0.4580  data_time: 0.0107  memory: 5266  grad_norm: 82.7023  loss: 11.2501  decode.loss_cls: 0.3680  decode.loss_mask: 0.2704  decode.loss_dice: 0.3521  decode.d0.loss_cls: 1.2304  decode.d0.loss_mask: 0.2786  decode.d0.loss_dice: 0.4152  decode.d1.loss_cls: 0.5709  decode.d1.loss_mask: 0.2756  decode.d1.loss_dice: 0.3149  decode.d2.loss_cls: 0.4487  decode.d2.loss_mask: 0.2696  decode.d2.loss_dice: 0.3247  decode.d3.loss_cls: 0.4176  decode.d3.loss_mask: 0.2618  decode.d3.loss_dice: 0.3299  decode.d4.loss_cls: 0.4010  decode.d4.loss_mask: 0.2718  decode.d4.loss_dice: 0.3596  decode.d5.loss_cls: 0.3384  decode.d5.loss_mask: 0.2737  decode.d5.loss_dice: 0.3561  decode.d6.loss_cls: 0.4306  decode.d6.loss_mask: 0.2670  decode.d6.loss_dice: 0.3489  decode.d7.loss_cls: 0.4548  decode.d7.loss_mask: 0.2652  decode.d7.loss_dice: 0.3435  decode.d8.loss_cls: 0.3915  decode.d8.loss_mask: 0.2725  decode.d8.loss_dice: 0.3471
07/25 20:18:14 - mmengine - INFO - Iter(train) [ 8150/80000]  base_lr: 9.0784e-05 lr: 9.0784e-06  eta: 9:08:09  time: 0.4568  data_time: 0.0103  memory: 5293  grad_norm: 178.3595  loss: 12.6944  decode.loss_cls: 0.4846  decode.loss_mask: 0.3384  decode.loss_dice: 0.3091  decode.d0.loss_cls: 1.4577  decode.d0.loss_mask: 0.3502  decode.d0.loss_dice: 0.3661  decode.d1.loss_cls: 0.6636  decode.d1.loss_mask: 0.3426  decode.d1.loss_dice: 0.3098  decode.d2.loss_cls: 0.4712  decode.d2.loss_mask: 0.3392  decode.d2.loss_dice: 0.3154  decode.d3.loss_cls: 0.5109  decode.d3.loss_mask: 0.3319  decode.d3.loss_dice: 0.3271  decode.d4.loss_cls: 0.5278  decode.d4.loss_mask: 0.3410  decode.d4.loss_dice: 0.3286  decode.d5.loss_cls: 0.5517  decode.d5.loss_mask: 0.3320  decode.d5.loss_dice: 0.3049  decode.d6.loss_cls: 0.5250  decode.d6.loss_mask: 0.3296  decode.d6.loss_dice: 0.3035  decode.d7.loss_cls: 0.4789  decode.d7.loss_mask: 0.3261  decode.d7.loss_dice: 0.3076  decode.d8.loss_cls: 0.4813  decode.d8.loss_mask: 0.3295  decode.d8.loss_dice: 0.3086
07/25 20:18:37 - mmengine - INFO - Iter(train) [ 8200/80000]  base_lr: 9.0727e-05 lr: 9.0727e-06  eta: 9:07:46  time: 0.4563  data_time: 0.0103  memory: 5231  grad_norm: 80.2997  loss: 10.1444  decode.loss_cls: 0.2868  decode.loss_mask: 0.2618  decode.loss_dice: 0.3055  decode.d0.loss_cls: 1.3184  decode.d0.loss_mask: 0.2697  decode.d0.loss_dice: 0.3557  decode.d1.loss_cls: 0.4358  decode.d1.loss_mask: 0.2661  decode.d1.loss_dice: 0.3233  decode.d2.loss_cls: 0.3957  decode.d2.loss_mask: 0.2647  decode.d2.loss_dice: 0.3071  decode.d3.loss_cls: 0.3204  decode.d3.loss_mask: 0.2671  decode.d3.loss_dice: 0.3083  decode.d4.loss_cls: 0.2859  decode.d4.loss_mask: 0.2601  decode.d4.loss_dice: 0.3109  decode.d5.loss_cls: 0.2953  decode.d5.loss_mask: 0.2652  decode.d5.loss_dice: 0.3007  decode.d6.loss_cls: 0.3827  decode.d6.loss_mask: 0.2589  decode.d6.loss_dice: 0.3022  decode.d7.loss_cls: 0.3421  decode.d7.loss_mask: 0.2682  decode.d7.loss_dice: 0.3202  decode.d8.loss_cls: 0.3099  decode.d8.loss_mask: 0.2573  decode.d8.loss_dice: 0.2985
07/25 20:19:00 - mmengine - INFO - Iter(train) [ 8250/80000]  base_lr: 9.0670e-05 lr: 9.0670e-06  eta: 9:07:23  time: 0.4595  data_time: 0.0106  memory: 5248  grad_norm: 184.5394  loss: 14.4646  decode.loss_cls: 0.5434  decode.loss_mask: 0.3650  decode.loss_dice: 0.4259  decode.d0.loss_cls: 1.7301  decode.d0.loss_mask: 0.3580  decode.d0.loss_dice: 0.4526  decode.d1.loss_cls: 0.6559  decode.d1.loss_mask: 0.3570  decode.d1.loss_dice: 0.4031  decode.d2.loss_cls: 0.6741  decode.d2.loss_mask: 0.3373  decode.d2.loss_dice: 0.3797  decode.d3.loss_cls: 0.5690  decode.d3.loss_mask: 0.3374  decode.d3.loss_dice: 0.3785  decode.d4.loss_cls: 0.5824  decode.d4.loss_mask: 0.3497  decode.d4.loss_dice: 0.3838  decode.d5.loss_cls: 0.5446  decode.d5.loss_mask: 0.3660  decode.d5.loss_dice: 0.4047  decode.d6.loss_cls: 0.5163  decode.d6.loss_mask: 0.3720  decode.d6.loss_dice: 0.4178  decode.d7.loss_cls: 0.4792  decode.d7.loss_mask: 0.3796  decode.d7.loss_dice: 0.4255  decode.d8.loss_cls: 0.5009  decode.d8.loss_mask: 0.3631  decode.d8.loss_dice: 0.4118
07/25 20:19:22 - mmengine - INFO - Iter(train) [ 8300/80000]  base_lr: 9.0613e-05 lr: 9.0613e-06  eta: 9:07:00  time: 0.4520  data_time: 0.0100  memory: 5265  grad_norm: 108.1433  loss: 10.8335  decode.loss_cls: 0.3566  decode.loss_mask: 0.3185  decode.loss_dice: 0.2743  decode.d0.loss_cls: 1.3062  decode.d0.loss_mask: 0.3491  decode.d0.loss_dice: 0.3338  decode.d1.loss_cls: 0.3855  decode.d1.loss_mask: 0.3217  decode.d1.loss_dice: 0.2913  decode.d2.loss_cls: 0.4316  decode.d2.loss_mask: 0.3178  decode.d2.loss_dice: 0.2676  decode.d3.loss_cls: 0.3945  decode.d3.loss_mask: 0.3185  decode.d3.loss_dice: 0.2636  decode.d4.loss_cls: 0.3719  decode.d4.loss_mask: 0.3219  decode.d4.loss_dice: 0.2767  decode.d5.loss_cls: 0.4148  decode.d5.loss_mask: 0.3158  decode.d5.loss_dice: 0.2688  decode.d6.loss_cls: 0.3578  decode.d6.loss_mask: 0.3179  decode.d6.loss_dice: 0.2760  decode.d7.loss_cls: 0.3920  decode.d7.loss_mask: 0.3336  decode.d7.loss_dice: 0.2743  decode.d8.loss_cls: 0.3950  decode.d8.loss_mask: 0.3199  decode.d8.loss_dice: 0.2665
07/25 20:19:45 - mmengine - INFO - Iter(train) [ 8350/80000]  base_lr: 9.0556e-05 lr: 9.0556e-06  eta: 9:06:34  time: 0.4587  data_time: 0.0105  memory: 5231  grad_norm: 108.1100  loss: 13.0412  decode.loss_cls: 0.4669  decode.loss_mask: 0.2914  decode.loss_dice: 0.3896  decode.d0.loss_cls: 1.4668  decode.d0.loss_mask: 0.2756  decode.d0.loss_dice: 0.3956  decode.d1.loss_cls: 0.6699  decode.d1.loss_mask: 0.2809  decode.d1.loss_dice: 0.3602  decode.d2.loss_cls: 0.5690  decode.d2.loss_mask: 0.2732  decode.d2.loss_dice: 0.3813  decode.d3.loss_cls: 0.5463  decode.d3.loss_mask: 0.2806  decode.d3.loss_dice: 0.3778  decode.d4.loss_cls: 0.6679  decode.d4.loss_mask: 0.2761  decode.d4.loss_dice: 0.3734  decode.d5.loss_cls: 0.5891  decode.d5.loss_mask: 0.2785  decode.d5.loss_dice: 0.3973  decode.d6.loss_cls: 0.4981  decode.d6.loss_mask: 0.2939  decode.d6.loss_dice: 0.3771  decode.d7.loss_cls: 0.4755  decode.d7.loss_mask: 0.2899  decode.d7.loss_dice: 0.3779  decode.d8.loss_cls: 0.4713  decode.d8.loss_mask: 0.2823  decode.d8.loss_dice: 0.3675
07/25 20:20:08 - mmengine - INFO - Iter(train) [ 8400/80000]  base_lr: 9.0499e-05 lr: 9.0499e-06  eta: 9:06:10  time: 0.4482  data_time: 0.0102  memory: 5265  grad_norm: 139.5305  loss: 12.5831  decode.loss_cls: 0.3913  decode.loss_mask: 0.2905  decode.loss_dice: 0.3557  decode.d0.loss_cls: 1.5872  decode.d0.loss_mask: 0.2387  decode.d0.loss_dice: 0.4001  decode.d1.loss_cls: 0.8224  decode.d1.loss_mask: 0.2444  decode.d1.loss_dice: 0.3585  decode.d2.loss_cls: 0.6228  decode.d2.loss_mask: 0.2513  decode.d2.loss_dice: 0.3502  decode.d3.loss_cls: 0.5873  decode.d3.loss_mask: 0.2561  decode.d3.loss_dice: 0.3558  decode.d4.loss_cls: 0.5508  decode.d4.loss_mask: 0.2577  decode.d4.loss_dice: 0.3497  decode.d5.loss_cls: 0.5151  decode.d5.loss_mask: 0.2551  decode.d5.loss_dice: 0.3552  decode.d6.loss_cls: 0.5228  decode.d6.loss_mask: 0.2830  decode.d6.loss_dice: 0.3424  decode.d7.loss_cls: 0.3907  decode.d7.loss_mask: 0.2637  decode.d7.loss_dice: 0.3365  decode.d8.loss_cls: 0.4211  decode.d8.loss_mask: 0.2698  decode.d8.loss_dice: 0.3575
07/25 20:20:31 - mmengine - INFO - Iter(train) [ 8450/80000]  base_lr: 9.0443e-05 lr: 9.0443e-06  eta: 9:05:46  time: 0.4532  data_time: 0.0098  memory: 5265  grad_norm: 148.9548  loss: 12.8692  decode.loss_cls: 0.5425  decode.loss_mask: 0.2271  decode.loss_dice: 0.3474  decode.d0.loss_cls: 1.4303  decode.d0.loss_mask: 0.2293  decode.d0.loss_dice: 0.3796  decode.d1.loss_cls: 0.7378  decode.d1.loss_mask: 0.2316  decode.d1.loss_dice: 0.3594  decode.d2.loss_cls: 0.5353  decode.d2.loss_mask: 0.2293  decode.d2.loss_dice: 0.3439  decode.d3.loss_cls: 0.5968  decode.d3.loss_mask: 0.2230  decode.d3.loss_dice: 0.3534  decode.d4.loss_cls: 0.6612  decode.d4.loss_mask: 0.2327  decode.d4.loss_dice: 0.3448  decode.d5.loss_cls: 0.5659  decode.d5.loss_mask: 0.2243  decode.d5.loss_dice: 0.3840  decode.d6.loss_cls: 0.5766  decode.d6.loss_mask: 0.2272  decode.d6.loss_dice: 0.3861  decode.d7.loss_cls: 0.6803  decode.d7.loss_mask: 0.2309  decode.d7.loss_dice: 0.3617  decode.d8.loss_cls: 0.6122  decode.d8.loss_mask: 0.2339  decode.d8.loss_dice: 0.3808
07/25 20:20:53 - mmengine - INFO - Iter(train) [ 8500/80000]  base_lr: 9.0386e-05 lr: 9.0386e-06  eta: 9:05:22  time: 0.4587  data_time: 0.0105  memory: 5231  grad_norm: 106.7563  loss: 11.6422  decode.loss_cls: 0.3456  decode.loss_mask: 0.2708  decode.loss_dice: 0.4070  decode.d0.loss_cls: 1.3917  decode.d0.loss_mask: 0.3356  decode.d0.loss_dice: 0.4620  decode.d1.loss_cls: 0.4966  decode.d1.loss_mask: 0.2726  decode.d1.loss_dice: 0.3643  decode.d2.loss_cls: 0.3949  decode.d2.loss_mask: 0.2737  decode.d2.loss_dice: 0.3862  decode.d3.loss_cls: 0.3516  decode.d3.loss_mask: 0.2742  decode.d3.loss_dice: 0.3923  decode.d4.loss_cls: 0.3957  decode.d4.loss_mask: 0.2801  decode.d4.loss_dice: 0.3983  decode.d5.loss_cls: 0.3874  decode.d5.loss_mask: 0.2720  decode.d5.loss_dice: 0.3281  decode.d6.loss_cls: 0.3870  decode.d6.loss_mask: 0.2654  decode.d6.loss_dice: 0.4016  decode.d7.loss_cls: 0.3620  decode.d7.loss_mask: 0.2692  decode.d7.loss_dice: 0.4000  decode.d8.loss_cls: 0.3806  decode.d8.loss_mask: 0.2697  decode.d8.loss_dice: 0.4263
07/25 20:21:16 - mmengine - INFO - Iter(train) [ 8550/80000]  base_lr: 9.0329e-05 lr: 9.0329e-06  eta: 9:04:59  time: 0.4519  data_time: 0.0101  memory: 5265  grad_norm: 91.1320  loss: 12.4319  decode.loss_cls: 0.4691  decode.loss_mask: 0.2794  decode.loss_dice: 0.3407  decode.d0.loss_cls: 1.3308  decode.d0.loss_mask: 0.2868  decode.d0.loss_dice: 0.4622  decode.d1.loss_cls: 0.6883  decode.d1.loss_mask: 0.2976  decode.d1.loss_dice: 0.3534  decode.d2.loss_cls: 0.5479  decode.d2.loss_mask: 0.2954  decode.d2.loss_dice: 0.3442  decode.d3.loss_cls: 0.5610  decode.d3.loss_mask: 0.2776  decode.d3.loss_dice: 0.3457  decode.d4.loss_cls: 0.5064  decode.d4.loss_mask: 0.2974  decode.d4.loss_dice: 0.3667  decode.d5.loss_cls: 0.4989  decode.d5.loss_mask: 0.2967  decode.d5.loss_dice: 0.3485  decode.d6.loss_cls: 0.4885  decode.d6.loss_mask: 0.2853  decode.d6.loss_dice: 0.3430  decode.d7.loss_cls: 0.4556  decode.d7.loss_mask: 0.2844  decode.d7.loss_dice: 0.3407  decode.d8.loss_cls: 0.4000  decode.d8.loss_mask: 0.2815  decode.d8.loss_dice: 0.3582
07/25 20:21:39 - mmengine - INFO - Iter(train) [ 8600/80000]  base_lr: 9.0272e-05 lr: 9.0272e-06  eta: 9:04:36  time: 0.4589  data_time: 0.0105  memory: 5228  grad_norm: 137.0618  loss: 11.0148  decode.loss_cls: 0.2845  decode.loss_mask: 0.3335  decode.loss_dice: 0.3717  decode.d0.loss_cls: 1.2757  decode.d0.loss_mask: 0.3481  decode.d0.loss_dice: 0.4343  decode.d1.loss_cls: 0.3717  decode.d1.loss_mask: 0.3170  decode.d1.loss_dice: 0.3484  decode.d2.loss_cls: 0.2780  decode.d2.loss_mask: 0.3248  decode.d2.loss_dice: 0.3914  decode.d3.loss_cls: 0.3075  decode.d3.loss_mask: 0.3329  decode.d3.loss_dice: 0.3747  decode.d4.loss_cls: 0.2355  decode.d4.loss_mask: 0.3237  decode.d4.loss_dice: 0.3758  decode.d5.loss_cls: 0.2343  decode.d5.loss_mask: 0.3266  decode.d5.loss_dice: 0.4008  decode.d6.loss_cls: 0.2868  decode.d6.loss_mask: 0.3288  decode.d6.loss_dice: 0.3634  decode.d7.loss_cls: 0.3375  decode.d7.loss_mask: 0.3256  decode.d7.loss_dice: 0.3530  decode.d8.loss_cls: 0.3045  decode.d8.loss_mask: 0.3445  decode.d8.loss_dice: 0.3799
07/25 20:22:02 - mmengine - INFO - Iter(train) [ 8650/80000]  base_lr: 9.0215e-05 lr: 9.0215e-06  eta: 9:04:14  time: 0.4580  data_time: 0.0108  memory: 5249  grad_norm: 138.2836  loss: 13.8137  decode.loss_cls: 0.5772  decode.loss_mask: 0.3673  decode.loss_dice: 0.3818  decode.d0.loss_cls: 1.3849  decode.d0.loss_mask: 0.3643  decode.d0.loss_dice: 0.4145  decode.d1.loss_cls: 0.5811  decode.d1.loss_mask: 0.3811  decode.d1.loss_dice: 0.3887  decode.d2.loss_cls: 0.4931  decode.d2.loss_mask: 0.3683  decode.d2.loss_dice: 0.3626  decode.d3.loss_cls: 0.5038  decode.d3.loss_mask: 0.3662  decode.d3.loss_dice: 0.3673  decode.d4.loss_cls: 0.5124  decode.d4.loss_mask: 0.3663  decode.d4.loss_dice: 0.3823  decode.d5.loss_cls: 0.4997  decode.d5.loss_mask: 0.3621  decode.d5.loss_dice: 0.3792  decode.d6.loss_cls: 0.6614  decode.d6.loss_mask: 0.3533  decode.d6.loss_dice: 0.3721  decode.d7.loss_cls: 0.5544  decode.d7.loss_mask: 0.3621  decode.d7.loss_dice: 0.3958  decode.d8.loss_cls: 0.5550  decode.d8.loss_mask: 0.3633  decode.d8.loss_dice: 0.3919
07/25 20:22:25 - mmengine - INFO - Iter(train) [ 8700/80000]  base_lr: 9.0158e-05 lr: 9.0158e-06  eta: 9:03:50  time: 0.4540  data_time: 0.0102  memory: 5249  grad_norm: 122.8239  loss: 12.3441  decode.loss_cls: 0.5040  decode.loss_mask: 0.3330  decode.loss_dice: 0.3364  decode.d0.loss_cls: 1.3579  decode.d0.loss_mask: 0.3479  decode.d0.loss_dice: 0.3537  decode.d1.loss_cls: 0.5754  decode.d1.loss_mask: 0.3358  decode.d1.loss_dice: 0.3335  decode.d2.loss_cls: 0.3763  decode.d2.loss_mask: 0.3478  decode.d2.loss_dice: 0.3485  decode.d3.loss_cls: 0.4187  decode.d3.loss_mask: 0.3498  decode.d3.loss_dice: 0.3429  decode.d4.loss_cls: 0.4230  decode.d4.loss_mask: 0.3415  decode.d4.loss_dice: 0.3350  decode.d5.loss_cls: 0.4326  decode.d5.loss_mask: 0.3299  decode.d5.loss_dice: 0.3309  decode.d6.loss_cls: 0.4584  decode.d6.loss_mask: 0.3465  decode.d6.loss_dice: 0.3354  decode.d7.loss_cls: 0.5417  decode.d7.loss_mask: 0.3387  decode.d7.loss_dice: 0.3323  decode.d8.loss_cls: 0.4742  decode.d8.loss_mask: 0.3311  decode.d8.loss_dice: 0.3313
07/25 20:22:48 - mmengine - INFO - Iter(train) [ 8750/80000]  base_lr: 9.0101e-05 lr: 9.0101e-06  eta: 9:03:27  time: 0.4557  data_time: 0.0103  memory: 5266  grad_norm: 185.2691  loss: 13.4780  decode.loss_cls: 0.6435  decode.loss_mask: 0.2600  decode.loss_dice: 0.3396  decode.d0.loss_cls: 1.4811  decode.d0.loss_mask: 0.2742  decode.d0.loss_dice: 0.4002  decode.d1.loss_cls: 0.7808  decode.d1.loss_mask: 0.2616  decode.d1.loss_dice: 0.3317  decode.d2.loss_cls: 0.7173  decode.d2.loss_mask: 0.2654  decode.d2.loss_dice: 0.3255  decode.d3.loss_cls: 0.7086  decode.d3.loss_mask: 0.2552  decode.d3.loss_dice: 0.3079  decode.d4.loss_cls: 0.6694  decode.d4.loss_mask: 0.2610  decode.d4.loss_dice: 0.3044  decode.d5.loss_cls: 0.6614  decode.d5.loss_mask: 0.2573  decode.d5.loss_dice: 0.3292  decode.d6.loss_cls: 0.6085  decode.d6.loss_mask: 0.2544  decode.d6.loss_dice: 0.3358  decode.d7.loss_cls: 0.6086  decode.d7.loss_mask: 0.2589  decode.d7.loss_dice: 0.3495  decode.d8.loss_cls: 0.6326  decode.d8.loss_mask: 0.2599  decode.d8.loss_dice: 0.3343
07/25 20:23:10 - mmengine - INFO - Iter(train) [ 8800/80000]  base_lr: 9.0044e-05 lr: 9.0044e-06  eta: 9:03:02  time: 0.4589  data_time: 0.0106  memory: 5266  grad_norm: 139.5420  loss: 12.4092  decode.loss_cls: 0.3878  decode.loss_mask: 0.3840  decode.loss_dice: 0.3783  decode.d0.loss_cls: 1.4672  decode.d0.loss_mask: 0.3866  decode.d0.loss_dice: 0.4524  decode.d1.loss_cls: 0.3835  decode.d1.loss_mask: 0.3631  decode.d1.loss_dice: 0.3854  decode.d2.loss_cls: 0.3544  decode.d2.loss_mask: 0.3529  decode.d2.loss_dice: 0.3708  decode.d3.loss_cls: 0.3380  decode.d3.loss_mask: 0.3455  decode.d3.loss_dice: 0.3608  decode.d4.loss_cls: 0.4182  decode.d4.loss_mask: 0.3621  decode.d4.loss_dice: 0.3647  decode.d5.loss_cls: 0.3578  decode.d5.loss_mask: 0.3798  decode.d5.loss_dice: 0.3684  decode.d6.loss_cls: 0.3873  decode.d6.loss_mask: 0.3872  decode.d6.loss_dice: 0.3884  decode.d7.loss_cls: 0.3917  decode.d7.loss_mask: 0.3691  decode.d7.loss_dice: 0.3694  decode.d8.loss_cls: 0.3938  decode.d8.loss_mask: 0.3770  decode.d8.loss_dice: 0.3837
07/25 20:23:33 - mmengine - INFO - Iter(train) [ 8850/80000]  base_lr: 8.9987e-05 lr: 8.9987e-06  eta: 9:02:40  time: 0.4583  data_time: 0.0103  memory: 5292  grad_norm: 135.6199  loss: 13.9493  decode.loss_cls: 0.5945  decode.loss_mask: 0.2922  decode.loss_dice: 0.4073  decode.d0.loss_cls: 1.5165  decode.d0.loss_mask: 0.2798  decode.d0.loss_dice: 0.4499  decode.d1.loss_cls: 0.6893  decode.d1.loss_mask: 0.2754  decode.d1.loss_dice: 0.4119  decode.d2.loss_cls: 0.6456  decode.d2.loss_mask: 0.2699  decode.d2.loss_dice: 0.3966  decode.d3.loss_cls: 0.5988  decode.d3.loss_mask: 0.2808  decode.d3.loss_dice: 0.4154  decode.d4.loss_cls: 0.6367  decode.d4.loss_mask: 0.2802  decode.d4.loss_dice: 0.4131  decode.d5.loss_cls: 0.6358  decode.d5.loss_mask: 0.2831  decode.d5.loss_dice: 0.4106  decode.d6.loss_cls: 0.5516  decode.d6.loss_mask: 0.2706  decode.d6.loss_dice: 0.4047  decode.d7.loss_cls: 0.5638  decode.d7.loss_mask: 0.2724  decode.d7.loss_dice: 0.3973  decode.d8.loss_cls: 0.6252  decode.d8.loss_mask: 0.2750  decode.d8.loss_dice: 0.4053
07/25 20:23:56 - mmengine - INFO - Iter(train) [ 8900/80000]  base_lr: 8.9930e-05 lr: 8.9930e-06  eta: 9:02:17  time: 0.4539  data_time: 0.0100  memory: 5229  grad_norm: 134.2062  loss: 13.0209  decode.loss_cls: 0.6897  decode.loss_mask: 0.2579  decode.loss_dice: 0.3564  decode.d0.loss_cls: 1.4251  decode.d0.loss_mask: 0.2677  decode.d0.loss_dice: 0.3640  decode.d1.loss_cls: 0.6838  decode.d1.loss_mask: 0.2723  decode.d1.loss_dice: 0.3677  decode.d2.loss_cls: 0.6376  decode.d2.loss_mask: 0.2597  decode.d2.loss_dice: 0.3169  decode.d3.loss_cls: 0.5596  decode.d3.loss_mask: 0.2603  decode.d3.loss_dice: 0.3388  decode.d4.loss_cls: 0.5391  decode.d4.loss_mask: 0.2568  decode.d4.loss_dice: 0.3152  decode.d5.loss_cls: 0.5993  decode.d5.loss_mask: 0.2489  decode.d5.loss_dice: 0.3027  decode.d6.loss_cls: 0.6097  decode.d6.loss_mask: 0.2492  decode.d6.loss_dice: 0.3085  decode.d7.loss_cls: 0.6519  decode.d7.loss_mask: 0.2571  decode.d7.loss_dice: 0.3610  decode.d8.loss_cls: 0.6712  decode.d8.loss_mask: 0.2571  decode.d8.loss_dice: 0.3357
07/25 20:24:19 - mmengine - INFO - Iter(train) [ 8950/80000]  base_lr: 8.9873e-05 lr: 8.9873e-06  eta: 9:01:54  time: 0.4554  data_time: 0.0104  memory: 5266  grad_norm: 98.5099  loss: 11.7979  decode.loss_cls: 0.5495  decode.loss_mask: 0.2350  decode.loss_dice: 0.2780  decode.d0.loss_cls: 1.4655  decode.d0.loss_mask: 0.2590  decode.d0.loss_dice: 0.3363  decode.d1.loss_cls: 0.7064  decode.d1.loss_mask: 0.2373  decode.d1.loss_dice: 0.2739  decode.d2.loss_cls: 0.6052  decode.d2.loss_mask: 0.2372  decode.d2.loss_dice: 0.2869  decode.d3.loss_cls: 0.5302  decode.d3.loss_mask: 0.2413  decode.d3.loss_dice: 0.2822  decode.d4.loss_cls: 0.5569  decode.d4.loss_mask: 0.2419  decode.d4.loss_dice: 0.2739  decode.d5.loss_cls: 0.5423  decode.d5.loss_mask: 0.2380  decode.d5.loss_dice: 0.2817  decode.d6.loss_cls: 0.5405  decode.d6.loss_mask: 0.2378  decode.d6.loss_dice: 0.2692  decode.d7.loss_cls: 0.5456  decode.d7.loss_mask: 0.2410  decode.d7.loss_dice: 0.2662  decode.d8.loss_cls: 0.5291  decode.d8.loss_mask: 0.2379  decode.d8.loss_dice: 0.2720
07/25 20:24:42 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250725_191538
07/25 20:24:42 - mmengine - INFO - Iter(train) [ 9000/80000]  base_lr: 8.9817e-05 lr: 8.9817e-06  eta: 9:01:33  time: 0.4584  data_time: 0.0103  memory: 5249  grad_norm: 144.5001  loss: 16.7412  decode.loss_cls: 0.8254  decode.loss_mask: 0.3188  decode.loss_dice: 0.4190  decode.d0.loss_cls: 1.7986  decode.d0.loss_mask: 0.3005  decode.d0.loss_dice: 0.4656  decode.d1.loss_cls: 0.9319  decode.d1.loss_mask: 0.3038  decode.d1.loss_dice: 0.4061  decode.d2.loss_cls: 0.8484  decode.d2.loss_mask: 0.3287  decode.d2.loss_dice: 0.4238  decode.d3.loss_cls: 0.7723  decode.d3.loss_mask: 0.3245  decode.d3.loss_dice: 0.4044  decode.d4.loss_cls: 0.8616  decode.d4.loss_mask: 0.3341  decode.d4.loss_dice: 0.4115  decode.d5.loss_cls: 0.8052  decode.d5.loss_mask: 0.3311  decode.d5.loss_dice: 0.4105  decode.d6.loss_cls: 0.8240  decode.d6.loss_mask: 0.3200  decode.d6.loss_dice: 0.4221  decode.d7.loss_cls: 0.8240  decode.d7.loss_mask: 0.3168  decode.d7.loss_dice: 0.4131  decode.d8.loss_cls: 0.8545  decode.d8.loss_mask: 0.3283  decode.d8.loss_dice: 0.4127
07/25 20:25:05 - mmengine - INFO - Iter(train) [ 9050/80000]  base_lr: 8.9760e-05 lr: 8.9760e-06  eta: 9:01:09  time: 0.4513  data_time: 0.0098  memory: 5249  grad_norm: 193.0011  loss: 13.4785  decode.loss_cls: 0.5099  decode.loss_mask: 0.2869  decode.loss_dice: 0.4559  decode.d0.loss_cls: 1.2181  decode.d0.loss_mask: 0.3282  decode.d0.loss_dice: 0.4948  decode.d1.loss_cls: 0.5787  decode.d1.loss_mask: 0.2897  decode.d1.loss_dice: 0.4177  decode.d2.loss_cls: 0.5257  decode.d2.loss_mask: 0.2808  decode.d2.loss_dice: 0.4164  decode.d3.loss_cls: 0.5202  decode.d3.loss_mask: 0.2786  decode.d3.loss_dice: 0.4210  decode.d4.loss_cls: 0.5554  decode.d4.loss_mask: 0.2911  decode.d4.loss_dice: 0.4587  decode.d5.loss_cls: 0.4788  decode.d5.loss_mask: 0.2879  decode.d5.loss_dice: 0.4501  decode.d6.loss_cls: 0.5457  decode.d6.loss_mask: 0.2948  decode.d6.loss_dice: 0.4589  decode.d7.loss_cls: 0.5828  decode.d7.loss_mask: 0.2900  decode.d7.loss_dice: 0.4568  decode.d8.loss_cls: 0.5655  decode.d8.loss_mask: 0.2862  decode.d8.loss_dice: 0.4529
07/25 20:25:28 - mmengine - INFO - Iter(train) [ 9100/80000]  base_lr: 8.9703e-05 lr: 8.9703e-06  eta: 9:00:45  time: 0.4572  data_time: 0.0103  memory: 5249  grad_norm: 71.8810  loss: 8.5904  decode.loss_cls: 0.2680  decode.loss_mask: 0.2544  decode.loss_dice: 0.2635  decode.d0.loss_cls: 1.0951  decode.d0.loss_mask: 0.2605  decode.d0.loss_dice: 0.2783  decode.d1.loss_cls: 0.3488  decode.d1.loss_mask: 0.2488  decode.d1.loss_dice: 0.2360  decode.d2.loss_cls: 0.2968  decode.d2.loss_mask: 0.2421  decode.d2.loss_dice: 0.2380  decode.d3.loss_cls: 0.2456  decode.d3.loss_mask: 0.2488  decode.d3.loss_dice: 0.2357  decode.d4.loss_cls: 0.2733  decode.d4.loss_mask: 0.2526  decode.d4.loss_dice: 0.2416  decode.d5.loss_cls: 0.2707  decode.d5.loss_mask: 0.2452  decode.d5.loss_dice: 0.2340  decode.d6.loss_cls: 0.2964  decode.d6.loss_mask: 0.2454  decode.d6.loss_dice: 0.2322  decode.d7.loss_cls: 0.2881  decode.d7.loss_mask: 0.2554  decode.d7.loss_dice: 0.2283  decode.d8.loss_cls: 0.2733  decode.d8.loss_mask: 0.2515  decode.d8.loss_dice: 0.2421
07/25 20:25:50 - mmengine - INFO - Iter(train) [ 9150/80000]  base_lr: 8.9646e-05 lr: 8.9646e-06  eta: 9:00:21  time: 0.4568  data_time: 0.0106  memory: 5249  grad_norm: 161.9039  loss: 11.6506  decode.loss_cls: 0.4949  decode.loss_mask: 0.3084  decode.loss_dice: 0.2934  decode.d0.loss_cls: 1.2879  decode.d0.loss_mask: 0.3247  decode.d0.loss_dice: 0.3475  decode.d1.loss_cls: 0.5392  decode.d1.loss_mask: 0.3143  decode.d1.loss_dice: 0.3040  decode.d2.loss_cls: 0.4687  decode.d2.loss_mask: 0.3160  decode.d2.loss_dice: 0.3074  decode.d3.loss_cls: 0.4264  decode.d3.loss_mask: 0.3104  decode.d3.loss_dice: 0.3020  decode.d4.loss_cls: 0.4264  decode.d4.loss_mask: 0.3146  decode.d4.loss_dice: 0.3053  decode.d5.loss_cls: 0.4303  decode.d5.loss_mask: 0.3151  decode.d5.loss_dice: 0.2997  decode.d6.loss_cls: 0.4444  decode.d6.loss_mask: 0.3097  decode.d6.loss_dice: 0.2977  decode.d7.loss_cls: 0.4780  decode.d7.loss_mask: 0.3128  decode.d7.loss_dice: 0.3042  decode.d8.loss_cls: 0.4569  decode.d8.loss_mask: 0.3103  decode.d8.loss_dice: 0.3002
07/25 20:26:13 - mmengine - INFO - Iter(train) [ 9200/80000]  base_lr: 8.9589e-05 lr: 8.9589e-06  eta: 8:59:59  time: 0.4595  data_time: 0.0107  memory: 5249  grad_norm: 134.8553  loss: 12.8501  decode.loss_cls: 0.4509  decode.loss_mask: 0.3754  decode.loss_dice: 0.2890  decode.d0.loss_cls: 1.3019  decode.d0.loss_mask: 0.4095  decode.d0.loss_dice: 0.3704  decode.d1.loss_cls: 0.5189  decode.d1.loss_mask: 0.3793  decode.d1.loss_dice: 0.3237  decode.d2.loss_cls: 0.5037  decode.d2.loss_mask: 0.3886  decode.d2.loss_dice: 0.3130  decode.d3.loss_cls: 0.4801  decode.d3.loss_mask: 0.3690  decode.d3.loss_dice: 0.3366  decode.d4.loss_cls: 0.5410  decode.d4.loss_mask: 0.4038  decode.d4.loss_dice: 0.3368  decode.d5.loss_cls: 0.4590  decode.d5.loss_mask: 0.3984  decode.d5.loss_dice: 0.3232  decode.d6.loss_cls: 0.4634  decode.d6.loss_mask: 0.4189  decode.d6.loss_dice: 0.3164  decode.d7.loss_cls: 0.4763  decode.d7.loss_mask: 0.4306  decode.d7.loss_dice: 0.3168  decode.d8.loss_cls: 0.4454  decode.d8.loss_mask: 0.3867  decode.d8.loss_dice: 0.3232
07/25 20:26:36 - mmengine - INFO - Iter(train) [ 9250/80000]  base_lr: 8.9532e-05 lr: 8.9532e-06  eta: 8:59:36  time: 0.4592  data_time: 0.0105  memory: 5248  grad_norm: 58.5198  loss: 8.4672  decode.loss_cls: 0.2655  decode.loss_mask: 0.2264  decode.loss_dice: 0.2343  decode.d0.loss_cls: 1.2954  decode.d0.loss_mask: 0.2355  decode.d0.loss_dice: 0.2674  decode.d1.loss_cls: 0.3513  decode.d1.loss_mask: 0.2347  decode.d1.loss_dice: 0.2475  decode.d2.loss_cls: 0.2344  decode.d2.loss_mask: 0.2335  decode.d2.loss_dice: 0.2383  decode.d3.loss_cls: 0.2680  decode.d3.loss_mask: 0.2289  decode.d3.loss_dice: 0.2340  decode.d4.loss_cls: 0.2812  decode.d4.loss_mask: 0.2316  decode.d4.loss_dice: 0.2377  decode.d5.loss_cls: 0.2769  decode.d5.loss_mask: 0.2328  decode.d5.loss_dice: 0.2363  decode.d6.loss_cls: 0.2641  decode.d6.loss_mask: 0.2300  decode.d6.loss_dice: 0.2351  decode.d7.loss_cls: 0.2741  decode.d7.loss_mask: 0.2271  decode.d7.loss_dice: 0.2322  decode.d8.loss_cls: 0.2594  decode.d8.loss_mask: 0.2285  decode.d8.loss_dice: 0.2251
07/25 20:26:59 - mmengine - INFO - Iter(train) [ 9300/80000]  base_lr: 8.9475e-05 lr: 8.9475e-06  eta: 8:59:13  time: 0.4567  data_time: 0.0105  memory: 5229  grad_norm: 151.5219  loss: 9.5218  decode.loss_cls: 0.2647  decode.loss_mask: 0.2839  decode.loss_dice: 0.3427  decode.d0.loss_cls: 1.1713  decode.d0.loss_mask: 0.2811  decode.d0.loss_dice: 0.3562  decode.d1.loss_cls: 0.2527  decode.d1.loss_mask: 0.2832  decode.d1.loss_dice: 0.3736  decode.d2.loss_cls: 0.2169  decode.d2.loss_mask: 0.2834  decode.d2.loss_dice: 0.3402  decode.d3.loss_cls: 0.2141  decode.d3.loss_mask: 0.2829  decode.d3.loss_dice: 0.3416  decode.d4.loss_cls: 0.2120  decode.d4.loss_mask: 0.2764  decode.d4.loss_dice: 0.3371  decode.d5.loss_cls: 0.1867  decode.d5.loss_mask: 0.2824  decode.d5.loss_dice: 0.3284  decode.d6.loss_cls: 0.2140  decode.d6.loss_mask: 0.2780  decode.d6.loss_dice: 0.3529  decode.d7.loss_cls: 0.2655  decode.d7.loss_mask: 0.2800  decode.d7.loss_dice: 0.3498  decode.d8.loss_cls: 0.2533  decode.d8.loss_mask: 0.2756  decode.d8.loss_dice: 0.3413
07/25 20:27:22 - mmengine - INFO - Iter(train) [ 9350/80000]  base_lr: 8.9418e-05 lr: 8.9418e-06  eta: 8:58:51  time: 0.4567  data_time: 0.0100  memory: 5228  grad_norm: 57.0646  loss: 9.7001  decode.loss_cls: 0.3596  decode.loss_mask: 0.1946  decode.loss_dice: 0.3261  decode.d0.loss_cls: 1.2128  decode.d0.loss_mask: 0.1958  decode.d0.loss_dice: 0.3074  decode.d1.loss_cls: 0.4580  decode.d1.loss_mask: 0.1937  decode.d1.loss_dice: 0.3011  decode.d2.loss_cls: 0.3778  decode.d2.loss_mask: 0.1924  decode.d2.loss_dice: 0.2866  decode.d3.loss_cls: 0.3862  decode.d3.loss_mask: 0.1908  decode.d3.loss_dice: 0.2894  decode.d4.loss_cls: 0.3461  decode.d4.loss_mask: 0.1920  decode.d4.loss_dice: 0.2880  decode.d5.loss_cls: 0.4203  decode.d5.loss_mask: 0.1889  decode.d5.loss_dice: 0.2913  decode.d6.loss_cls: 0.3403  decode.d6.loss_mask: 0.2081  decode.d6.loss_dice: 0.3236  decode.d7.loss_cls: 0.4090  decode.d7.loss_mask: 0.1890  decode.d7.loss_dice: 0.3309  decode.d8.loss_cls: 0.3797  decode.d8.loss_mask: 0.1901  decode.d8.loss_dice: 0.3304
07/25 20:27:45 - mmengine - INFO - Iter(train) [ 9400/80000]  base_lr: 8.9361e-05 lr: 8.9361e-06  eta: 8:58:27  time: 0.4551  data_time: 0.0103  memory: 5249  grad_norm: 213.0836  loss: 12.7424  decode.loss_cls: 0.4712  decode.loss_mask: 0.3822  decode.loss_dice: 0.3220  decode.d0.loss_cls: 1.0869  decode.d0.loss_mask: 0.3954  decode.d0.loss_dice: 0.3880  decode.d1.loss_cls: 0.5583  decode.d1.loss_mask: 0.4440  decode.d1.loss_dice: 0.3659  decode.d2.loss_cls: 0.4569  decode.d2.loss_mask: 0.4104  decode.d2.loss_dice: 0.3272  decode.d3.loss_cls: 0.4330  decode.d3.loss_mask: 0.3956  decode.d3.loss_dice: 0.3495  decode.d4.loss_cls: 0.4793  decode.d4.loss_mask: 0.3906  decode.d4.loss_dice: 0.3465  decode.d5.loss_cls: 0.4760  decode.d5.loss_mask: 0.3896  decode.d5.loss_dice: 0.3341  decode.d6.loss_cls: 0.4580  decode.d6.loss_mask: 0.3829  decode.d6.loss_dice: 0.3436  decode.d7.loss_cls: 0.4834  decode.d7.loss_mask: 0.3769  decode.d7.loss_dice: 0.3199  decode.d8.loss_cls: 0.4754  decode.d8.loss_mask: 0.3811  decode.d8.loss_dice: 0.3186
07/25 20:28:07 - mmengine - INFO - Iter(train) [ 9450/80000]  base_lr: 8.9304e-05 lr: 8.9304e-06  eta: 8:58:02  time: 0.4564  data_time: 0.0103  memory: 5249  grad_norm: 120.8304  loss: 11.4332  decode.loss_cls: 0.4279  decode.loss_mask: 0.2639  decode.loss_dice: 0.2858  decode.d0.loss_cls: 1.2562  decode.d0.loss_mask: 0.2724  decode.d0.loss_dice: 0.3768  decode.d1.loss_cls: 0.5917  decode.d1.loss_mask: 0.2594  decode.d1.loss_dice: 0.2969  decode.d2.loss_cls: 0.5804  decode.d2.loss_mask: 0.2615  decode.d2.loss_dice: 0.2914  decode.d3.loss_cls: 0.4937  decode.d3.loss_mask: 0.2645  decode.d3.loss_dice: 0.2935  decode.d4.loss_cls: 0.5721  decode.d4.loss_mask: 0.2766  decode.d4.loss_dice: 0.3131  decode.d5.loss_cls: 0.4573  decode.d5.loss_mask: 0.2683  decode.d5.loss_dice: 0.3071  decode.d6.loss_cls: 0.4650  decode.d6.loss_mask: 0.2583  decode.d6.loss_dice: 0.2927  decode.d7.loss_cls: 0.4542  decode.d7.loss_mask: 0.2658  decode.d7.loss_dice: 0.2858  decode.d8.loss_cls: 0.4551  decode.d8.loss_mask: 0.2621  decode.d8.loss_dice: 0.2838
07/25 20:28:30 - mmengine - INFO - Iter(train) [ 9500/80000]  base_lr: 8.9247e-05 lr: 8.9247e-06  eta: 8:57:38  time: 0.4615  data_time: 0.0104  memory: 5249  grad_norm: 117.4185  loss: 12.3519  decode.loss_cls: 0.3579  decode.loss_mask: 0.3471  decode.loss_dice: 0.3544  decode.d0.loss_cls: 1.4459  decode.d0.loss_mask: 0.3811  decode.d0.loss_dice: 0.4285  decode.d1.loss_cls: 0.5151  decode.d1.loss_mask: 0.3630  decode.d1.loss_dice: 0.3619  decode.d2.loss_cls: 0.4292  decode.d2.loss_mask: 0.3605  decode.d2.loss_dice: 0.3601  decode.d3.loss_cls: 0.3319  decode.d3.loss_mask: 0.3617  decode.d3.loss_dice: 0.3711  decode.d4.loss_cls: 0.3786  decode.d4.loss_mask: 0.3600  decode.d4.loss_dice: 0.3597  decode.d5.loss_cls: 0.4112  decode.d5.loss_mask: 0.3470  decode.d5.loss_dice: 0.3655  decode.d6.loss_cls: 0.4481  decode.d6.loss_mask: 0.3474  decode.d6.loss_dice: 0.3521  decode.d7.loss_cls: 0.4065  decode.d7.loss_mask: 0.3526  decode.d7.loss_dice: 0.3560  decode.d8.loss_cls: 0.3949  decode.d8.loss_mask: 0.3442  decode.d8.loss_dice: 0.3588
07/25 20:28:53 - mmengine - INFO - Iter(train) [ 9550/80000]  base_lr: 8.9190e-05 lr: 8.9190e-06  eta: 8:57:16  time: 0.4558  data_time: 0.0106  memory: 5231  grad_norm: 106.7480  loss: 10.3225  decode.loss_cls: 0.3653  decode.loss_mask: 0.2639  decode.loss_dice: 0.2628  decode.d0.loss_cls: 1.2642  decode.d0.loss_mask: 0.2784  decode.d0.loss_dice: 0.3160  decode.d1.loss_cls: 0.4042  decode.d1.loss_mask: 0.2678  decode.d1.loss_dice: 0.2955  decode.d2.loss_cls: 0.3940  decode.d2.loss_mask: 0.2682  decode.d2.loss_dice: 0.2983  decode.d3.loss_cls: 0.3939  decode.d3.loss_mask: 0.2805  decode.d3.loss_dice: 0.3022  decode.d4.loss_cls: 0.3793  decode.d4.loss_mask: 0.2670  decode.d4.loss_dice: 0.2890  decode.d5.loss_cls: 0.3538  decode.d5.loss_mask: 0.2703  decode.d5.loss_dice: 0.2926  decode.d6.loss_cls: 0.3950  decode.d6.loss_mask: 0.2678  decode.d6.loss_dice: 0.3169  decode.d7.loss_cls: 0.3668  decode.d7.loss_mask: 0.2688  decode.d7.loss_dice: 0.2887  decode.d8.loss_cls: 0.3784  decode.d8.loss_mask: 0.2664  decode.d8.loss_dice: 0.2663
07/25 20:29:16 - mmengine - INFO - Iter(train) [ 9600/80000]  base_lr: 8.9133e-05 lr: 8.9133e-06  eta: 8:56:53  time: 0.4610  data_time: 0.0105  memory: 5265  grad_norm: 92.4735  loss: 11.9434  decode.loss_cls: 0.4856  decode.loss_mask: 0.2223  decode.loss_dice: 0.3722  decode.d0.loss_cls: 1.2493  decode.d0.loss_mask: 0.2268  decode.d0.loss_dice: 0.3853  decode.d1.loss_cls: 0.6226  decode.d1.loss_mask: 0.2319  decode.d1.loss_dice: 0.3805  decode.d2.loss_cls: 0.5819  decode.d2.loss_mask: 0.2369  decode.d2.loss_dice: 0.3758  decode.d3.loss_cls: 0.4953  decode.d3.loss_mask: 0.2244  decode.d3.loss_dice: 0.3584  decode.d4.loss_cls: 0.5183  decode.d4.loss_mask: 0.2338  decode.d4.loss_dice: 0.3679  decode.d5.loss_cls: 0.4613  decode.d5.loss_mask: 0.2247  decode.d5.loss_dice: 0.3668  decode.d6.loss_cls: 0.5015  decode.d6.loss_mask: 0.2259  decode.d6.loss_dice: 0.3858  decode.d7.loss_cls: 0.4743  decode.d7.loss_mask: 0.2254  decode.d7.loss_dice: 0.3657  decode.d8.loss_cls: 0.5513  decode.d8.loss_mask: 0.2198  decode.d8.loss_dice: 0.3719
07/25 20:29:39 - mmengine - INFO - Iter(train) [ 9650/80000]  base_lr: 8.9076e-05 lr: 8.9076e-06  eta: 8:56:31  time: 0.4602  data_time: 0.0105  memory: 5231  grad_norm: 74.2704  loss: 9.4386  decode.loss_cls: 0.2509  decode.loss_mask: 0.2590  decode.loss_dice: 0.3018  decode.d0.loss_cls: 1.3316  decode.d0.loss_mask: 0.2371  decode.d0.loss_dice: 0.3464  decode.d1.loss_cls: 0.4444  decode.d1.loss_mask: 0.2836  decode.d1.loss_dice: 0.2792  decode.d2.loss_cls: 0.3037  decode.d2.loss_mask: 0.2526  decode.d2.loss_dice: 0.2659  decode.d3.loss_cls: 0.2375  decode.d3.loss_mask: 0.2570  decode.d3.loss_dice: 0.2960  decode.d4.loss_cls: 0.2633  decode.d4.loss_mask: 0.2693  decode.d4.loss_dice: 0.2886  decode.d5.loss_cls: 0.2741  decode.d5.loss_mask: 0.2462  decode.d5.loss_dice: 0.2570  decode.d6.loss_cls: 0.2466  decode.d6.loss_mask: 0.2814  decode.d6.loss_dice: 0.2960  decode.d7.loss_cls: 0.2727  decode.d7.loss_mask: 0.2713  decode.d7.loss_dice: 0.2676  decode.d8.loss_cls: 0.2827  decode.d8.loss_mask: 0.2777  decode.d8.loss_dice: 0.2975
07/25 20:30:02 - mmengine - INFO - Iter(train) [ 9700/80000]  base_lr: 8.9019e-05 lr: 8.9019e-06  eta: 8:56:08  time: 0.4607  data_time: 0.0105  memory: 5249  grad_norm: 104.6848  loss: 9.6680  decode.loss_cls: 0.2725  decode.loss_mask: 0.3048  decode.loss_dice: 0.2568  decode.d0.loss_cls: 1.2077  decode.d0.loss_mask: 0.3335  decode.d0.loss_dice: 0.2866  decode.d1.loss_cls: 0.4446  decode.d1.loss_mask: 0.3083  decode.d1.loss_dice: 0.2590  decode.d2.loss_cls: 0.3143  decode.d2.loss_mask: 0.3031  decode.d2.loss_dice: 0.2498  decode.d3.loss_cls: 0.2887  decode.d3.loss_mask: 0.3067  decode.d3.loss_dice: 0.2466  decode.d4.loss_cls: 0.3050  decode.d4.loss_mask: 0.3036  decode.d4.loss_dice: 0.2495  decode.d5.loss_cls: 0.3388  decode.d5.loss_mask: 0.2999  decode.d5.loss_dice: 0.2509  decode.d6.loss_cls: 0.2875  decode.d6.loss_mask: 0.3048  decode.d6.loss_dice: 0.2468  decode.d7.loss_cls: 0.2959  decode.d7.loss_mask: 0.3091  decode.d7.loss_dice: 0.2517  decode.d8.loss_cls: 0.2853  decode.d8.loss_mask: 0.3111  decode.d8.loss_dice: 0.2448
07/25 20:30:25 - mmengine - INFO - Iter(train) [ 9750/80000]  base_lr: 8.8962e-05 lr: 8.8962e-06  eta: 8:55:46  time: 0.4564  data_time: 0.0105  memory: 5248  grad_norm: 107.6092  loss: 10.8406  decode.loss_cls: 0.3798  decode.loss_mask: 0.2610  decode.loss_dice: 0.3410  decode.d0.loss_cls: 1.3031  decode.d0.loss_mask: 0.2863  decode.d0.loss_dice: 0.3864  decode.d1.loss_cls: 0.4888  decode.d1.loss_mask: 0.2663  decode.d1.loss_dice: 0.3268  decode.d2.loss_cls: 0.3933  decode.d2.loss_mask: 0.2570  decode.d2.loss_dice: 0.3140  decode.d3.loss_cls: 0.3762  decode.d3.loss_mask: 0.2693  decode.d3.loss_dice: 0.3158  decode.d4.loss_cls: 0.3296  decode.d4.loss_mask: 0.2610  decode.d4.loss_dice: 0.3089  decode.d5.loss_cls: 0.4071  decode.d5.loss_mask: 0.2638  decode.d5.loss_dice: 0.3228  decode.d6.loss_cls: 0.4445  decode.d6.loss_mask: 0.2586  decode.d6.loss_dice: 0.3013  decode.d7.loss_cls: 0.3819  decode.d7.loss_mask: 0.2612  decode.d7.loss_dice: 0.3122  decode.d8.loss_cls: 0.4236  decode.d8.loss_mask: 0.2597  decode.d8.loss_dice: 0.3396
07/25 20:30:47 - mmengine - INFO - Iter(train) [ 9800/80000]  base_lr: 8.8905e-05 lr: 8.8905e-06  eta: 8:55:21  time: 0.4543  data_time: 0.0099  memory: 5249  grad_norm: 86.6954  loss: 10.8477  decode.loss_cls: 0.4997  decode.loss_mask: 0.2229  decode.loss_dice: 0.2567  decode.d0.loss_cls: 1.3837  decode.d0.loss_mask: 0.2290  decode.d0.loss_dice: 0.3354  decode.d1.loss_cls: 0.5402  decode.d1.loss_mask: 0.2227  decode.d1.loss_dice: 0.2837  decode.d2.loss_cls: 0.4492  decode.d2.loss_mask: 0.2162  decode.d2.loss_dice: 0.2806  decode.d3.loss_cls: 0.4262  decode.d3.loss_mask: 0.2219  decode.d3.loss_dice: 0.2743  decode.d4.loss_cls: 0.5176  decode.d4.loss_mask: 0.2224  decode.d4.loss_dice: 0.2642  decode.d5.loss_cls: 0.5106  decode.d5.loss_mask: 0.2236  decode.d5.loss_dice: 0.2818  decode.d6.loss_cls: 0.5035  decode.d6.loss_mask: 0.2182  decode.d6.loss_dice: 0.2656  decode.d7.loss_cls: 0.4796  decode.d7.loss_mask: 0.2225  decode.d7.loss_dice: 0.2888  decode.d8.loss_cls: 0.4920  decode.d8.loss_mask: 0.2211  decode.d8.loss_dice: 0.2941
07/25 20:31:10 - mmengine - INFO - Iter(train) [ 9850/80000]  base_lr: 8.8848e-05 lr: 8.8848e-06  eta: 8:54:57  time: 0.4460  data_time: 0.0094  memory: 5293  grad_norm: 60.5122  loss: 9.0049  decode.loss_cls: 0.2842  decode.loss_mask: 0.2328  decode.loss_dice: 0.2525  decode.d0.loss_cls: 1.1339  decode.d0.loss_mask: 0.2584  decode.d0.loss_dice: 0.3098  decode.d1.loss_cls: 0.4128  decode.d1.loss_mask: 0.2412  decode.d1.loss_dice: 0.2705  decode.d2.loss_cls: 0.3149  decode.d2.loss_mask: 0.2311  decode.d2.loss_dice: 0.2685  decode.d3.loss_cls: 0.2828  decode.d3.loss_mask: 0.2309  decode.d3.loss_dice: 0.2512  decode.d4.loss_cls: 0.2725  decode.d4.loss_mask: 0.2330  decode.d4.loss_dice: 0.2677  decode.d5.loss_cls: 0.2965  decode.d5.loss_mask: 0.2344  decode.d5.loss_dice: 0.2656  decode.d6.loss_cls: 0.3161  decode.d6.loss_mask: 0.2327  decode.d6.loss_dice: 0.2722  decode.d7.loss_cls: 0.3290  decode.d7.loss_mask: 0.2315  decode.d7.loss_dice: 0.2574  decode.d8.loss_cls: 0.3325  decode.d8.loss_mask: 0.2329  decode.d8.loss_dice: 0.2553
07/25 20:31:33 - mmengine - INFO - Iter(train) [ 9900/80000]  base_lr: 8.8791e-05 lr: 8.8791e-06  eta: 8:54:34  time: 0.4534  data_time: 0.0101  memory: 5248  grad_norm: 120.8553  loss: 10.5458  decode.loss_cls: 0.2680  decode.loss_mask: 0.3254  decode.loss_dice: 0.3516  decode.d0.loss_cls: 1.4923  decode.d0.loss_mask: 0.3302  decode.d0.loss_dice: 0.3766  decode.d1.loss_cls: 0.3190  decode.d1.loss_mask: 0.3313  decode.d1.loss_dice: 0.3513  decode.d2.loss_cls: 0.2444  decode.d2.loss_mask: 0.3278  decode.d2.loss_dice: 0.3512  decode.d3.loss_cls: 0.2590  decode.d3.loss_mask: 0.3258  decode.d3.loss_dice: 0.3646  decode.d4.loss_cls: 0.2017  decode.d4.loss_mask: 0.3202  decode.d4.loss_dice: 0.3519  decode.d5.loss_cls: 0.2328  decode.d5.loss_mask: 0.3221  decode.d5.loss_dice: 0.3500  decode.d6.loss_cls: 0.2420  decode.d6.loss_mask: 0.3263  decode.d6.loss_dice: 0.3600  decode.d7.loss_cls: 0.2138  decode.d7.loss_mask: 0.3323  decode.d7.loss_dice: 0.3572  decode.d8.loss_cls: 0.2446  decode.d8.loss_mask: 0.3243  decode.d8.loss_dice: 0.3481
07/25 20:31:56 - mmengine - INFO - Iter(train) [ 9950/80000]  base_lr: 8.8734e-05 lr: 8.8734e-06  eta: 8:54:11  time: 0.4579  data_time: 0.0101  memory: 5265  grad_norm: 148.8581  loss: 15.3733  decode.loss_cls: 0.5607  decode.loss_mask: 0.3681  decode.loss_dice: 0.4598  decode.d0.loss_cls: 1.5963  decode.d0.loss_mask: 0.3937  decode.d0.loss_dice: 0.5258  decode.d1.loss_cls: 0.7511  decode.d1.loss_mask: 0.3740  decode.d1.loss_dice: 0.4936  decode.d2.loss_cls: 0.5772  decode.d2.loss_mask: 0.3991  decode.d2.loss_dice: 0.5051  decode.d3.loss_cls: 0.4786  decode.d3.loss_mask: 0.3779  decode.d3.loss_dice: 0.4328  decode.d4.loss_cls: 0.5925  decode.d4.loss_mask: 0.3758  decode.d4.loss_dice: 0.4773  decode.d5.loss_cls: 0.6219  decode.d5.loss_mask: 0.3916  decode.d5.loss_dice: 0.4497  decode.d6.loss_cls: 0.5276  decode.d6.loss_mask: 0.3727  decode.d6.loss_dice: 0.4479  decode.d7.loss_cls: 0.5497  decode.d7.loss_mask: 0.3852  decode.d7.loss_dice: 0.4882  decode.d8.loss_cls: 0.5271  decode.d8.loss_mask: 0.4067  decode.d8.loss_dice: 0.4658
07/25 20:32:19 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250725_191538
07/25 20:32:19 - mmengine - INFO - Iter(train) [10000/80000]  base_lr: 8.8677e-05 lr: 8.8677e-06  eta: 8:53:48  time: 0.4596  data_time: 0.0102  memory: 5249  grad_norm: 141.9134  loss: 10.9679  decode.loss_cls: 0.2902  decode.loss_mask: 0.3326  decode.loss_dice: 0.3315  decode.d0.loss_cls: 1.4162  decode.d0.loss_mask: 0.3318  decode.d0.loss_dice: 0.3739  decode.d1.loss_cls: 0.3900  decode.d1.loss_mask: 0.3321  decode.d1.loss_dice: 0.3379  decode.d2.loss_cls: 0.3119  decode.d2.loss_mask: 0.3252  decode.d2.loss_dice: 0.3251  decode.d3.loss_cls: 0.2805  decode.d3.loss_mask: 0.3253  decode.d3.loss_dice: 0.3432  decode.d4.loss_cls: 0.3023  decode.d4.loss_mask: 0.3256  decode.d4.loss_dice: 0.3343  decode.d5.loss_cls: 0.3256  decode.d5.loss_mask: 0.3191  decode.d5.loss_dice: 0.3487  decode.d6.loss_cls: 0.3411  decode.d6.loss_mask: 0.3201  decode.d6.loss_dice: 0.3056  decode.d7.loss_cls: 0.3576  decode.d7.loss_mask: 0.3394  decode.d7.loss_dice: 0.3376  decode.d8.loss_cls: 0.2671  decode.d8.loss_mask: 0.3406  decode.d8.loss_dice: 0.3558
07/25 20:32:19 - mmengine - INFO - Saving checkpoint at 10000 iterations
07/25 20:32:44 - mmengine - INFO - Iter(train) [10050/80000]  base_lr: 8.8620e-05 lr: 8.8620e-06  eta: 8:53:38  time: 0.4546  data_time: 0.0102  memory: 5214  grad_norm: 123.3168  loss: 11.6283  decode.loss_cls: 0.4019  decode.loss_mask: 0.3470  decode.loss_dice: 0.3315  decode.d0.loss_cls: 1.2544  decode.d0.loss_mask: 0.3172  decode.d0.loss_dice: 0.3411  decode.d1.loss_cls: 0.4584  decode.d1.loss_mask: 0.2907  decode.d1.loss_dice: 0.3093  decode.d2.loss_cls: 0.4669  decode.d2.loss_mask: 0.2867  decode.d2.loss_dice: 0.3068  decode.d3.loss_cls: 0.5611  decode.d3.loss_mask: 0.2825  decode.d3.loss_dice: 0.3044  decode.d4.loss_cls: 0.5370  decode.d4.loss_mask: 0.2841  decode.d4.loss_dice: 0.3084  decode.d5.loss_cls: 0.5027  decode.d5.loss_mask: 0.2910  decode.d5.loss_dice: 0.3016  decode.d6.loss_cls: 0.4650  decode.d6.loss_mask: 0.2904  decode.d6.loss_dice: 0.2978  decode.d7.loss_cls: 0.4388  decode.d7.loss_mask: 0.2865  decode.d7.loss_dice: 0.3109  decode.d8.loss_cls: 0.3992  decode.d8.loss_mask: 0.3277  decode.d8.loss_dice: 0.3269
07/25 20:33:07 - mmengine - INFO - Iter(train) [10100/80000]  base_lr: 8.8563e-05 lr: 8.8563e-06  eta: 8:53:16  time: 0.4589  data_time: 0.0107  memory: 5249  grad_norm: 120.2152  loss: 10.1470  decode.loss_cls: 0.3390  decode.loss_mask: 0.2558  decode.loss_dice: 0.2927  decode.d0.loss_cls: 1.3151  decode.d0.loss_mask: 0.2583  decode.d0.loss_dice: 0.3437  decode.d1.loss_cls: 0.4738  decode.d1.loss_mask: 0.2646  decode.d1.loss_dice: 0.3043  decode.d2.loss_cls: 0.3982  decode.d2.loss_mask: 0.2623  decode.d2.loss_dice: 0.3071  decode.d3.loss_cls: 0.4083  decode.d3.loss_mask: 0.2735  decode.d3.loss_dice: 0.2862  decode.d4.loss_cls: 0.3519  decode.d4.loss_mask: 0.2576  decode.d4.loss_dice: 0.2807  decode.d5.loss_cls: 0.3485  decode.d5.loss_mask: 0.2493  decode.d5.loss_dice: 0.2916  decode.d6.loss_cls: 0.3324  decode.d6.loss_mask: 0.2450  decode.d6.loss_dice: 0.2743  decode.d7.loss_cls: 0.3432  decode.d7.loss_mask: 0.2488  decode.d7.loss_dice: 0.2761  decode.d8.loss_cls: 0.3399  decode.d8.loss_mask: 0.2500  decode.d8.loss_dice: 0.2748
07/25 20:33:29 - mmengine - INFO - Iter(train) [10150/80000]  base_lr: 8.8506e-05 lr: 8.8506e-06  eta: 8:52:52  time: 0.4602  data_time: 0.0103  memory: 5231  grad_norm: 77.7233  loss: 9.3105  decode.loss_cls: 0.3405  decode.loss_mask: 0.1926  decode.loss_dice: 0.2849  decode.d0.loss_cls: 1.3266  decode.d0.loss_mask: 0.1936  decode.d0.loss_dice: 0.3414  decode.d1.loss_cls: 0.4601  decode.d1.loss_mask: 0.1952  decode.d1.loss_dice: 0.3034  decode.d2.loss_cls: 0.3762  decode.d2.loss_mask: 0.1912  decode.d2.loss_dice: 0.2844  decode.d3.loss_cls: 0.3144  decode.d3.loss_mask: 0.1936  decode.d3.loss_dice: 0.2924  decode.d4.loss_cls: 0.2953  decode.d4.loss_mask: 0.1918  decode.d4.loss_dice: 0.2724  decode.d5.loss_cls: 0.3273  decode.d5.loss_mask: 0.1917  decode.d5.loss_dice: 0.2822  decode.d6.loss_cls: 0.3035  decode.d6.loss_mask: 0.1932  decode.d6.loss_dice: 0.2830  decode.d7.loss_cls: 0.3885  decode.d7.loss_mask: 0.1942  decode.d7.loss_dice: 0.2904  decode.d8.loss_cls: 0.3228  decode.d8.loss_mask: 0.1978  decode.d8.loss_dice: 0.2860
07/25 20:33:52 - mmengine - INFO - Iter(train) [10200/80000]  base_lr: 8.8449e-05 lr: 8.8449e-06  eta: 8:52:29  time: 0.4420  data_time: 0.0092  memory: 5266  grad_norm: 86.8691  loss: 9.7025  decode.loss_cls: 0.2706  decode.loss_mask: 0.2952  decode.loss_dice: 0.2847  decode.d0.loss_cls: 1.2881  decode.d0.loss_mask: 0.3164  decode.d0.loss_dice: 0.3358  decode.d1.loss_cls: 0.3516  decode.d1.loss_mask: 0.2976  decode.d1.loss_dice: 0.2872  decode.d2.loss_cls: 0.2495  decode.d2.loss_mask: 0.3008  decode.d2.loss_dice: 0.2969  decode.d3.loss_cls: 0.2688  decode.d3.loss_mask: 0.2856  decode.d3.loss_dice: 0.2897  decode.d4.loss_cls: 0.2745  decode.d4.loss_mask: 0.2948  decode.d4.loss_dice: 0.2891  decode.d5.loss_cls: 0.2942  decode.d5.loss_mask: 0.2917  decode.d5.loss_dice: 0.2769  decode.d6.loss_cls: 0.2698  decode.d6.loss_mask: 0.3098  decode.d6.loss_dice: 0.2796  decode.d7.loss_cls: 0.2893  decode.d7.loss_mask: 0.2960  decode.d7.loss_dice: 0.2748  decode.d8.loss_cls: 0.2660  decode.d8.loss_mask: 0.2968  decode.d8.loss_dice: 0.2810
07/25 20:34:15 - mmengine - INFO - Iter(train) [10250/80000]  base_lr: 8.8392e-05 lr: 8.8392e-06  eta: 8:52:08  time: 0.4543  data_time: 0.0103  memory: 5293  grad_norm: 134.1742  loss: 12.1979  decode.loss_cls: 0.4115  decode.loss_mask: 0.3240  decode.loss_dice: 0.3547  decode.d0.loss_cls: 1.1903  decode.d0.loss_mask: 0.3351  decode.d0.loss_dice: 0.4182  decode.d1.loss_cls: 0.4851  decode.d1.loss_mask: 0.3143  decode.d1.loss_dice: 0.3637  decode.d2.loss_cls: 0.4596  decode.d2.loss_mask: 0.3135  decode.d2.loss_dice: 0.3890  decode.d3.loss_cls: 0.5540  decode.d3.loss_mask: 0.3194  decode.d3.loss_dice: 0.3441  decode.d4.loss_cls: 0.5112  decode.d4.loss_mask: 0.3222  decode.d4.loss_dice: 0.3607  decode.d5.loss_cls: 0.4650  decode.d5.loss_mask: 0.3272  decode.d5.loss_dice: 0.3718  decode.d6.loss_cls: 0.4628  decode.d6.loss_mask: 0.3174  decode.d6.loss_dice: 0.3374  decode.d7.loss_cls: 0.4160  decode.d7.loss_mask: 0.3108  decode.d7.loss_dice: 0.3338  decode.d8.loss_cls: 0.4291  decode.d8.loss_mask: 0.3157  decode.d8.loss_dice: 0.3406
07/25 20:34:38 - mmengine - INFO - Iter(train) [10300/80000]  base_lr: 8.8335e-05 lr: 8.8335e-06  eta: 8:51:44  time: 0.4606  data_time: 0.0105  memory: 5249  grad_norm: 223.8005  loss: 13.1277  decode.loss_cls: 0.3961  decode.loss_mask: 0.3264  decode.loss_dice: 0.4924  decode.d0.loss_cls: 1.2752  decode.d0.loss_mask: 0.3276  decode.d0.loss_dice: 0.5023  decode.d1.loss_cls: 0.6856  decode.d1.loss_mask: 0.3218  decode.d1.loss_dice: 0.4484  decode.d2.loss_cls: 0.4543  decode.d2.loss_mask: 0.3261  decode.d2.loss_dice: 0.5081  decode.d3.loss_cls: 0.4475  decode.d3.loss_mask: 0.3197  decode.d3.loss_dice: 0.4113  decode.d4.loss_cls: 0.3651  decode.d4.loss_mask: 0.3208  decode.d4.loss_dice: 0.4439  decode.d5.loss_cls: 0.4246  decode.d5.loss_mask: 0.3220  decode.d5.loss_dice: 0.4789  decode.d6.loss_cls: 0.3864  decode.d6.loss_mask: 0.3187  decode.d6.loss_dice: 0.4579  decode.d7.loss_cls: 0.4549  decode.d7.loss_mask: 0.3222  decode.d7.loss_dice: 0.4694  decode.d8.loss_cls: 0.3142  decode.d8.loss_mask: 0.3296  decode.d8.loss_dice: 0.4764
07/25 20:35:01 - mmengine - INFO - Iter(train) [10350/80000]  base_lr: 8.8278e-05 lr: 8.8278e-06  eta: 8:51:21  time: 0.4593  data_time: 0.0106  memory: 5294  grad_norm: 293.6114  loss: 10.6115  decode.loss_cls: 0.2809  decode.loss_mask: 0.3241  decode.loss_dice: 0.3320  decode.d0.loss_cls: 1.2386  decode.d0.loss_mask: 0.3330  decode.d0.loss_dice: 0.3747  decode.d1.loss_cls: 0.4345  decode.d1.loss_mask: 0.3374  decode.d1.loss_dice: 0.3593  decode.d2.loss_cls: 0.3187  decode.d2.loss_mask: 0.3305  decode.d2.loss_dice: 0.3277  decode.d3.loss_cls: 0.3073  decode.d3.loss_mask: 0.3264  decode.d3.loss_dice: 0.3288  decode.d4.loss_cls: 0.3038  decode.d4.loss_mask: 0.3258  decode.d4.loss_dice: 0.3355  decode.d5.loss_cls: 0.2858  decode.d5.loss_mask: 0.3146  decode.d5.loss_dice: 0.3300  decode.d6.loss_cls: 0.2561  decode.d6.loss_mask: 0.3236  decode.d6.loss_dice: 0.3268  decode.d7.loss_cls: 0.2632  decode.d7.loss_mask: 0.3292  decode.d7.loss_dice: 0.3304  decode.d8.loss_cls: 0.2622  decode.d8.loss_mask: 0.3275  decode.d8.loss_dice: 0.3431
07/25 20:35:24 - mmengine - INFO - Iter(train) [10400/80000]  base_lr: 8.8221e-05 lr: 8.8221e-06  eta: 8:50:59  time: 0.4572  data_time: 0.0105  memory: 5296  grad_norm: 154.5777  loss: 11.1090  decode.loss_cls: 0.4429  decode.loss_mask: 0.2933  decode.loss_dice: 0.3098  decode.d0.loss_cls: 1.2177  decode.d0.loss_mask: 0.3029  decode.d0.loss_dice: 0.3654  decode.d1.loss_cls: 0.5326  decode.d1.loss_mask: 0.3003  decode.d1.loss_dice: 0.3175  decode.d2.loss_cls: 0.4073  decode.d2.loss_mask: 0.2936  decode.d2.loss_dice: 0.3117  decode.d3.loss_cls: 0.3159  decode.d3.loss_mask: 0.2931  decode.d3.loss_dice: 0.3263  decode.d4.loss_cls: 0.3522  decode.d4.loss_mask: 0.2895  decode.d4.loss_dice: 0.2959  decode.d5.loss_cls: 0.4094  decode.d5.loss_mask: 0.2868  decode.d5.loss_dice: 0.3085  decode.d6.loss_cls: 0.4492  decode.d6.loss_mask: 0.2900  decode.d6.loss_dice: 0.3077  decode.d7.loss_cls: 0.4199  decode.d7.loss_mask: 0.2946  decode.d7.loss_dice: 0.3261  decode.d8.loss_cls: 0.4428  decode.d8.loss_mask: 0.2928  decode.d8.loss_dice: 0.3133
07/25 20:35:47 - mmengine - INFO - Iter(train) [10450/80000]  base_lr: 8.8164e-05 lr: 8.8164e-06  eta: 8:50:36  time: 0.4638  data_time: 0.0109  memory: 5227  grad_norm: 112.9688  loss: 11.0232  decode.loss_cls: 0.4401  decode.loss_mask: 0.2255  decode.loss_dice: 0.3138  decode.d0.loss_cls: 1.1685  decode.d0.loss_mask: 0.2362  decode.d0.loss_dice: 0.3938  decode.d1.loss_cls: 0.4930  decode.d1.loss_mask: 0.2294  decode.d1.loss_dice: 0.3434  decode.d2.loss_cls: 0.4837  decode.d2.loss_mask: 0.2294  decode.d2.loss_dice: 0.3056  decode.d3.loss_cls: 0.4471  decode.d3.loss_mask: 0.2216  decode.d3.loss_dice: 0.2967  decode.d4.loss_cls: 0.4492  decode.d4.loss_mask: 0.2265  decode.d4.loss_dice: 0.3105  decode.d5.loss_cls: 0.5058  decode.d5.loss_mask: 0.2274  decode.d5.loss_dice: 0.3318  decode.d6.loss_cls: 0.4421  decode.d6.loss_mask: 0.2295  decode.d6.loss_dice: 0.3373  decode.d7.loss_cls: 0.4900  decode.d7.loss_mask: 0.2416  decode.d7.loss_dice: 0.3387  decode.d8.loss_cls: 0.5040  decode.d8.loss_mask: 0.2320  decode.d8.loss_dice: 0.3292
07/25 20:36:09 - mmengine - INFO - Iter(train) [10500/80000]  base_lr: 8.8107e-05 lr: 8.8107e-06  eta: 8:50:11  time: 0.4446  data_time: 0.0094  memory: 5248  grad_norm: 70.1701  loss: 9.9121  decode.loss_cls: 0.3624  decode.loss_mask: 0.2052  decode.loss_dice: 0.3039  decode.d0.loss_cls: 1.2354  decode.d0.loss_mask: 0.2173  decode.d0.loss_dice: 0.3611  decode.d1.loss_cls: 0.4925  decode.d1.loss_mask: 0.2086  decode.d1.loss_dice: 0.3332  decode.d2.loss_cls: 0.3828  decode.d2.loss_mask: 0.2094  decode.d2.loss_dice: 0.3164  decode.d3.loss_cls: 0.3391  decode.d3.loss_mask: 0.2060  decode.d3.loss_dice: 0.3168  decode.d4.loss_cls: 0.3976  decode.d4.loss_mask: 0.2071  decode.d4.loss_dice: 0.3085  decode.d5.loss_cls: 0.3613  decode.d5.loss_mask: 0.2045  decode.d5.loss_dice: 0.3113  decode.d6.loss_cls: 0.3458  decode.d6.loss_mask: 0.2047  decode.d6.loss_dice: 0.3116  decode.d7.loss_cls: 0.3673  decode.d7.loss_mask: 0.2096  decode.d7.loss_dice: 0.3178  decode.d8.loss_cls: 0.3712  decode.d8.loss_mask: 0.2092  decode.d8.loss_dice: 0.2945
07/25 20:36:32 - mmengine - INFO - Iter(train) [10550/80000]  base_lr: 8.8050e-05 lr: 8.8050e-06  eta: 8:49:48  time: 0.4646  data_time: 0.0108  memory: 5229  grad_norm: 136.1299  loss: 14.6576  decode.loss_cls: 0.7051  decode.loss_mask: 0.3277  decode.loss_dice: 0.3683  decode.d0.loss_cls: 1.3598  decode.d0.loss_mask: 0.3556  decode.d0.loss_dice: 0.4312  decode.d1.loss_cls: 0.7813  decode.d1.loss_mask: 0.3276  decode.d1.loss_dice: 0.3532  decode.d2.loss_cls: 0.7566  decode.d2.loss_mask: 0.3499  decode.d2.loss_dice: 0.3784  decode.d3.loss_cls: 0.7062  decode.d3.loss_mask: 0.3257  decode.d3.loss_dice: 0.3701  decode.d4.loss_cls: 0.6388  decode.d4.loss_mask: 0.3299  decode.d4.loss_dice: 0.3718  decode.d5.loss_cls: 0.5869  decode.d5.loss_mask: 0.3508  decode.d5.loss_dice: 0.4021  decode.d6.loss_cls: 0.5936  decode.d6.loss_mask: 0.3673  decode.d6.loss_dice: 0.4038  decode.d7.loss_cls: 0.6482  decode.d7.loss_mask: 0.3273  decode.d7.loss_dice: 0.4187  decode.d8.loss_cls: 0.6399  decode.d8.loss_mask: 0.3256  decode.d8.loss_dice: 0.3565
07/25 20:36:55 - mmengine - INFO - Iter(train) [10600/80000]  base_lr: 8.7993e-05 lr: 8.7993e-06  eta: 8:49:24  time: 0.4588  data_time: 0.0105  memory: 5227  grad_norm: 158.6326  loss: 10.9779  decode.loss_cls: 0.3503  decode.loss_mask: 0.3113  decode.loss_dice: 0.3119  decode.d0.loss_cls: 1.3188  decode.d0.loss_mask: 0.3448  decode.d0.loss_dice: 0.3972  decode.d1.loss_cls: 0.4722  decode.d1.loss_mask: 0.3214  decode.d1.loss_dice: 0.3336  decode.d2.loss_cls: 0.3318  decode.d2.loss_mask: 0.3036  decode.d2.loss_dice: 0.3332  decode.d3.loss_cls: 0.3612  decode.d3.loss_mask: 0.3010  decode.d3.loss_dice: 0.3289  decode.d4.loss_cls: 0.4179  decode.d4.loss_mask: 0.2925  decode.d4.loss_dice: 0.3103  decode.d5.loss_cls: 0.3068  decode.d5.loss_mask: 0.3038  decode.d5.loss_dice: 0.3233  decode.d6.loss_cls: 0.3034  decode.d6.loss_mask: 0.3079  decode.d6.loss_dice: 0.3150  decode.d7.loss_cls: 0.3533  decode.d7.loss_mask: 0.3148  decode.d7.loss_dice: 0.3176  decode.d8.loss_cls: 0.3494  decode.d8.loss_mask: 0.3178  decode.d8.loss_dice: 0.3229
07/25 20:37:18 - mmengine - INFO - Iter(train) [10650/80000]  base_lr: 8.7936e-05 lr: 8.7936e-06  eta: 8:49:00  time: 0.4543  data_time: 0.0103  memory: 5228  grad_norm: 135.3914  loss: 10.5367  decode.loss_cls: 0.4010  decode.loss_mask: 0.2303  decode.loss_dice: 0.2818  decode.d0.loss_cls: 1.1300  decode.d0.loss_mask: 0.2430  decode.d0.loss_dice: 0.3155  decode.d1.loss_cls: 0.5447  decode.d1.loss_mask: 0.2353  decode.d1.loss_dice: 0.2872  decode.d2.loss_cls: 0.5328  decode.d2.loss_mask: 0.2304  decode.d2.loss_dice: 0.2875  decode.d3.loss_cls: 0.4716  decode.d3.loss_mask: 0.2301  decode.d3.loss_dice: 0.2844  decode.d4.loss_cls: 0.4713  decode.d4.loss_mask: 0.2301  decode.d4.loss_dice: 0.2829  decode.d5.loss_cls: 0.4892  decode.d5.loss_mask: 0.2300  decode.d5.loss_dice: 0.2932  decode.d6.loss_cls: 0.4663  decode.d6.loss_mask: 0.2276  decode.d6.loss_dice: 0.2994  decode.d7.loss_cls: 0.3943  decode.d7.loss_mask: 0.2271  decode.d7.loss_dice: 0.2957  decode.d8.loss_cls: 0.4035  decode.d8.loss_mask: 0.2332  decode.d8.loss_dice: 0.2872
07/25 20:37:41 - mmengine - INFO - Iter(train) [10700/80000]  base_lr: 8.7879e-05 lr: 8.7879e-06  eta: 8:48:38  time: 0.4606  data_time: 0.0102  memory: 5265  grad_norm: 93.7171  loss: 8.8054  decode.loss_cls: 0.2547  decode.loss_mask: 0.2275  decode.loss_dice: 0.2527  decode.d0.loss_cls: 1.3879  decode.d0.loss_mask: 0.2342  decode.d0.loss_dice: 0.3293  decode.d1.loss_cls: 0.3914  decode.d1.loss_mask: 0.2292  decode.d1.loss_dice: 0.2555  decode.d2.loss_cls: 0.2949  decode.d2.loss_mask: 0.2266  decode.d2.loss_dice: 0.2753  decode.d3.loss_cls: 0.3005  decode.d3.loss_mask: 0.2246  decode.d3.loss_dice: 0.2548  decode.d4.loss_cls: 0.2733  decode.d4.loss_mask: 0.2272  decode.d4.loss_dice: 0.2662  decode.d5.loss_cls: 0.2432  decode.d5.loss_mask: 0.2235  decode.d5.loss_dice: 0.2553  decode.d6.loss_cls: 0.2357  decode.d6.loss_mask: 0.2225  decode.d6.loss_dice: 0.2511  decode.d7.loss_cls: 0.2085  decode.d7.loss_mask: 0.2281  decode.d7.loss_dice: 0.2787  decode.d8.loss_cls: 0.2550  decode.d8.loss_mask: 0.2274  decode.d8.loss_dice: 0.2706
07/25 20:38:03 - mmengine - INFO - Iter(train) [10750/80000]  base_lr: 8.7822e-05 lr: 8.7822e-06  eta: 8:48:14  time: 0.4550  data_time: 0.0104  memory: 5230  grad_norm: 90.8598  loss: 9.8031  decode.loss_cls: 0.2710  decode.loss_mask: 0.2528  decode.loss_dice: 0.3344  decode.d0.loss_cls: 1.1719  decode.d0.loss_mask: 0.3101  decode.d0.loss_dice: 0.4070  decode.d1.loss_cls: 0.3626  decode.d1.loss_mask: 0.2894  decode.d1.loss_dice: 0.3538  decode.d2.loss_cls: 0.3229  decode.d2.loss_mask: 0.2598  decode.d2.loss_dice: 0.3034  decode.d3.loss_cls: 0.2906  decode.d3.loss_mask: 0.2532  decode.d3.loss_dice: 0.3197  decode.d4.loss_cls: 0.2794  decode.d4.loss_mask: 0.2533  decode.d4.loss_dice: 0.3230  decode.d5.loss_cls: 0.2794  decode.d5.loss_mask: 0.2454  decode.d5.loss_dice: 0.3279  decode.d6.loss_cls: 0.3227  decode.d6.loss_mask: 0.2482  decode.d6.loss_dice: 0.3097  decode.d7.loss_cls: 0.3105  decode.d7.loss_mask: 0.2508  decode.d7.loss_dice: 0.3145  decode.d8.loss_cls: 0.2520  decode.d8.loss_mask: 0.2527  decode.d8.loss_dice: 0.3308
07/25 20:38:26 - mmengine - INFO - Iter(train) [10800/80000]  base_lr: 8.7765e-05 lr: 8.7765e-06  eta: 8:47:52  time: 0.4581  data_time: 0.0102  memory: 5228  grad_norm: 151.3877  loss: 10.9996  decode.loss_cls: 0.4378  decode.loss_mask: 0.2739  decode.loss_dice: 0.3252  decode.d0.loss_cls: 1.1087  decode.d0.loss_mask: 0.2778  decode.d0.loss_dice: 0.3537  decode.d1.loss_cls: 0.5233  decode.d1.loss_mask: 0.2651  decode.d1.loss_dice: 0.3197  decode.d2.loss_cls: 0.4045  decode.d2.loss_mask: 0.2645  decode.d2.loss_dice: 0.3029  decode.d3.loss_cls: 0.4298  decode.d3.loss_mask: 0.2594  decode.d3.loss_dice: 0.3014  decode.d4.loss_cls: 0.4417  decode.d4.loss_mask: 0.2674  decode.d4.loss_dice: 0.3079  decode.d5.loss_cls: 0.4311  decode.d5.loss_mask: 0.2629  decode.d5.loss_dice: 0.3144  decode.d6.loss_cls: 0.4814  decode.d6.loss_mask: 0.2711  decode.d6.loss_dice: 0.3149  decode.d7.loss_cls: 0.4366  decode.d7.loss_mask: 0.2764  decode.d7.loss_dice: 0.3132  decode.d8.loss_cls: 0.4481  decode.d8.loss_mask: 0.2754  decode.d8.loss_dice: 0.3092
07/25 20:38:49 - mmengine - INFO - Iter(train) [10850/80000]  base_lr: 8.7708e-05 lr: 8.7708e-06  eta: 8:47:30  time: 0.4640  data_time: 0.0102  memory: 5228  grad_norm: 102.5942  loss: 9.4495  decode.loss_cls: 0.3133  decode.loss_mask: 0.2333  decode.loss_dice: 0.2610  decode.d0.loss_cls: 1.0230  decode.d0.loss_mask: 0.2365  decode.d0.loss_dice: 0.3068  decode.d1.loss_cls: 0.3806  decode.d1.loss_mask: 0.2392  decode.d1.loss_dice: 0.2776  decode.d2.loss_cls: 0.3486  decode.d2.loss_mask: 0.2396  decode.d2.loss_dice: 0.2694  decode.d3.loss_cls: 0.3901  decode.d3.loss_mask: 0.2321  decode.d3.loss_dice: 0.2525  decode.d4.loss_cls: 0.3755  decode.d4.loss_mask: 0.2371  decode.d4.loss_dice: 0.2517  decode.d5.loss_cls: 0.3947  decode.d5.loss_mask: 0.2359  decode.d5.loss_dice: 0.2486  decode.d6.loss_cls: 0.4052  decode.d6.loss_mask: 0.2270  decode.d6.loss_dice: 0.2563  decode.d7.loss_cls: 0.4515  decode.d7.loss_mask: 0.2389  decode.d7.loss_dice: 0.2655  decode.d8.loss_cls: 0.3299  decode.d8.loss_mask: 0.2445  decode.d8.loss_dice: 0.2836
07/25 20:39:12 - mmengine - INFO - Iter(train) [10900/80000]  base_lr: 8.7650e-05 lr: 8.7650e-06  eta: 8:47:06  time: 0.4576  data_time: 0.0101  memory: 5249  grad_norm: 106.8961  loss: 13.0930  decode.loss_cls: 0.5005  decode.loss_mask: 0.2568  decode.loss_dice: 0.3899  decode.d0.loss_cls: 1.5290  decode.d0.loss_mask: 0.2676  decode.d0.loss_dice: 0.4008  decode.d1.loss_cls: 0.8487  decode.d1.loss_mask: 0.2610  decode.d1.loss_dice: 0.3497  decode.d2.loss_cls: 0.6017  decode.d2.loss_mask: 0.2589  decode.d2.loss_dice: 0.3386  decode.d3.loss_cls: 0.5738  decode.d3.loss_mask: 0.2562  decode.d3.loss_dice: 0.3552  decode.d4.loss_cls: 0.5547  decode.d4.loss_mask: 0.2606  decode.d4.loss_dice: 0.3784  decode.d5.loss_cls: 0.5646  decode.d5.loss_mask: 0.2581  decode.d5.loss_dice: 0.3858  decode.d6.loss_cls: 0.5694  decode.d6.loss_mask: 0.2597  decode.d6.loss_dice: 0.3903  decode.d7.loss_cls: 0.5100  decode.d7.loss_mask: 0.2569  decode.d7.loss_dice: 0.3723  decode.d8.loss_cls: 0.5288  decode.d8.loss_mask: 0.2594  decode.d8.loss_dice: 0.3557
07/25 20:39:35 - mmengine - INFO - Iter(train) [10950/80000]  base_lr: 8.7593e-05 lr: 8.7593e-06  eta: 8:46:42  time: 0.4440  data_time: 0.0096  memory: 5249  grad_norm: 55.4017  loss: 8.8713  decode.loss_cls: 0.1262  decode.loss_mask: 0.3226  decode.loss_dice: 0.3207  decode.d0.loss_cls: 1.1134  decode.d0.loss_mask: 0.3353  decode.d0.loss_dice: 0.3539  decode.d1.loss_cls: 0.2501  decode.d1.loss_mask: 0.3177  decode.d1.loss_dice: 0.3199  decode.d2.loss_cls: 0.1411  decode.d2.loss_mask: 0.3161  decode.d2.loss_dice: 0.3207  decode.d3.loss_cls: 0.1296  decode.d3.loss_mask: 0.3165  decode.d3.loss_dice: 0.3169  decode.d4.loss_cls: 0.1280  decode.d4.loss_mask: 0.3158  decode.d4.loss_dice: 0.3169  decode.d5.loss_cls: 0.1339  decode.d5.loss_mask: 0.3136  decode.d5.loss_dice: 0.3248  decode.d6.loss_cls: 0.1392  decode.d6.loss_mask: 0.3135  decode.d6.loss_dice: 0.3265  decode.d7.loss_cls: 0.1407  decode.d7.loss_mask: 0.3180  decode.d7.loss_dice: 0.3281  decode.d8.loss_cls: 0.1279  decode.d8.loss_mask: 0.3231  decode.d8.loss_dice: 0.3204
07/25 20:39:58 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250725_191538
07/25 20:39:58 - mmengine - INFO - Iter(train) [11000/80000]  base_lr: 8.7536e-05 lr: 8.7536e-06  eta: 8:46:19  time: 0.4564  data_time: 0.0102  memory: 5228  grad_norm: 107.0095  loss: 12.8754  decode.loss_cls: 0.4388  decode.loss_mask: 0.3362  decode.loss_dice: 0.4171  decode.d0.loss_cls: 1.2434  decode.d0.loss_mask: 0.3503  decode.d0.loss_dice: 0.4409  decode.d1.loss_cls: 0.5445  decode.d1.loss_mask: 0.3412  decode.d1.loss_dice: 0.4113  decode.d2.loss_cls: 0.4824  decode.d2.loss_mask: 0.3323  decode.d2.loss_dice: 0.4168  decode.d3.loss_cls: 0.4197  decode.d3.loss_mask: 0.3352  decode.d3.loss_dice: 0.4230  decode.d4.loss_cls: 0.4598  decode.d4.loss_mask: 0.3347  decode.d4.loss_dice: 0.3936  decode.d5.loss_cls: 0.4362  decode.d5.loss_mask: 0.3350  decode.d5.loss_dice: 0.3925  decode.d6.loss_cls: 0.4718  decode.d6.loss_mask: 0.3396  decode.d6.loss_dice: 0.4036  decode.d7.loss_cls: 0.4239  decode.d7.loss_mask: 0.3359  decode.d7.loss_dice: 0.3917  decode.d8.loss_cls: 0.4614  decode.d8.loss_mask: 0.3416  decode.d8.loss_dice: 0.4211
07/25 20:40:21 - mmengine - INFO - Iter(train) [11050/80000]  base_lr: 8.7479e-05 lr: 8.7479e-06  eta: 8:45:56  time: 0.4586  data_time: 0.0108  memory: 5266  grad_norm: 88.3581  loss: 9.0600  decode.loss_cls: 0.2793  decode.loss_mask: 0.2379  decode.loss_dice: 0.2552  decode.d0.loss_cls: 1.2447  decode.d0.loss_mask: 0.2466  decode.d0.loss_dice: 0.2881  decode.d1.loss_cls: 0.4085  decode.d1.loss_mask: 0.2410  decode.d1.loss_dice: 0.2527  decode.d2.loss_cls: 0.3244  decode.d2.loss_mask: 0.2362  decode.d2.loss_dice: 0.2439  decode.d3.loss_cls: 0.2957  decode.d3.loss_mask: 0.2352  decode.d3.loss_dice: 0.2357  decode.d4.loss_cls: 0.3505  decode.d4.loss_mask: 0.2346  decode.d4.loss_dice: 0.2398  decode.d5.loss_cls: 0.3660  decode.d5.loss_mask: 0.2384  decode.d5.loss_dice: 0.2479  decode.d6.loss_cls: 0.3137  decode.d6.loss_mask: 0.2390  decode.d6.loss_dice: 0.2526  decode.d7.loss_cls: 0.2855  decode.d7.loss_mask: 0.2407  decode.d7.loss_dice: 0.2533  decode.d8.loss_cls: 0.2762  decode.d8.loss_mask: 0.2400  decode.d8.loss_dice: 0.2564
07/25 20:40:44 - mmengine - INFO - Iter(train) [11100/80000]  base_lr: 8.7422e-05 lr: 8.7422e-06  eta: 8:45:34  time: 0.4638  data_time: 0.0105  memory: 5229  grad_norm: 66.0323  loss: 8.1913  decode.loss_cls: 0.1557  decode.loss_mask: 0.2576  decode.loss_dice: 0.2748  decode.d0.loss_cls: 1.0593  decode.d0.loss_mask: 0.2658  decode.d0.loss_dice: 0.3148  decode.d1.loss_cls: 0.2648  decode.d1.loss_mask: 0.2561  decode.d1.loss_dice: 0.2678  decode.d2.loss_cls: 0.2355  decode.d2.loss_mask: 0.2515  decode.d2.loss_dice: 0.2679  decode.d3.loss_cls: 0.2186  decode.d3.loss_mask: 0.2515  decode.d3.loss_dice: 0.2788  decode.d4.loss_cls: 0.2056  decode.d4.loss_mask: 0.2524  decode.d4.loss_dice: 0.2749  decode.d5.loss_cls: 0.2012  decode.d5.loss_mask: 0.2525  decode.d5.loss_dice: 0.2825  decode.d6.loss_cls: 0.1508  decode.d6.loss_mask: 0.2543  decode.d6.loss_dice: 0.2811  decode.d7.loss_cls: 0.1637  decode.d7.loss_mask: 0.2557  decode.d7.loss_dice: 0.2553  decode.d8.loss_cls: 0.2044  decode.d8.loss_mask: 0.2566  decode.d8.loss_dice: 0.2796
07/25 20:41:06 - mmengine - INFO - Iter(train) [11150/80000]  base_lr: 8.7365e-05 lr: 8.7365e-06  eta: 8:45:11  time: 0.4521  data_time: 0.0101  memory: 5249  grad_norm: 108.6609  loss: 10.7513  decode.loss_cls: 0.4104  decode.loss_mask: 0.3074  decode.loss_dice: 0.3053  decode.d0.loss_cls: 1.1271  decode.d0.loss_mask: 0.3409  decode.d0.loss_dice: 0.3568  decode.d1.loss_cls: 0.5210  decode.d1.loss_mask: 0.3334  decode.d1.loss_dice: 0.3368  decode.d2.loss_cls: 0.3692  decode.d2.loss_mask: 0.3092  decode.d2.loss_dice: 0.2986  decode.d3.loss_cls: 0.3324  decode.d3.loss_mask: 0.3051  decode.d3.loss_dice: 0.2855  decode.d4.loss_cls: 0.3592  decode.d4.loss_mask: 0.3103  decode.d4.loss_dice: 0.2918  decode.d5.loss_cls: 0.3722  decode.d5.loss_mask: 0.3051  decode.d5.loss_dice: 0.3088  decode.d6.loss_cls: 0.3612  decode.d6.loss_mask: 0.3012  decode.d6.loss_dice: 0.3067  decode.d7.loss_cls: 0.3620  decode.d7.loss_mask: 0.3078  decode.d7.loss_dice: 0.3031  decode.d8.loss_cls: 0.3211  decode.d8.loss_mask: 0.2995  decode.d8.loss_dice: 0.3022
07/25 20:41:29 - mmengine - INFO - Iter(train) [11200/80000]  base_lr: 8.7308e-05 lr: 8.7308e-06  eta: 8:44:48  time: 0.4592  data_time: 0.0104  memory: 5265  grad_norm: 97.8973  loss: 10.9402  decode.loss_cls: 0.3499  decode.loss_mask: 0.2879  decode.loss_dice: 0.3689  decode.d0.loss_cls: 1.2342  decode.d0.loss_mask: 0.2988  decode.d0.loss_dice: 0.4257  decode.d1.loss_cls: 0.4579  decode.d1.loss_mask: 0.2915  decode.d1.loss_dice: 0.3774  decode.d2.loss_cls: 0.3210  decode.d2.loss_mask: 0.2933  decode.d2.loss_dice: 0.3556  decode.d3.loss_cls: 0.2600  decode.d3.loss_mask: 0.2959  decode.d3.loss_dice: 0.3877  decode.d4.loss_cls: 0.2994  decode.d4.loss_mask: 0.2833  decode.d4.loss_dice: 0.3529  decode.d5.loss_cls: 0.2993  decode.d5.loss_mask: 0.2960  decode.d5.loss_dice: 0.3777  decode.d6.loss_cls: 0.3705  decode.d6.loss_mask: 0.2917  decode.d6.loss_dice: 0.3676  decode.d7.loss_cls: 0.3636  decode.d7.loss_mask: 0.2871  decode.d7.loss_dice: 0.3549  decode.d8.loss_cls: 0.3089  decode.d8.loss_mask: 0.2918  decode.d8.loss_dice: 0.3898
07/25 20:41:52 - mmengine - INFO - Iter(train) [11250/80000]  base_lr: 8.7251e-05 lr: 8.7251e-06  eta: 8:44:24  time: 0.4604  data_time: 0.0106  memory: 5307  grad_norm: 87.7355  loss: 9.4598  decode.loss_cls: 0.2554  decode.loss_mask: 0.2398  decode.loss_dice: 0.2787  decode.d0.loss_cls: 1.4150  decode.d0.loss_mask: 0.2660  decode.d0.loss_dice: 0.3349  decode.d1.loss_cls: 0.4679  decode.d1.loss_mask: 0.2462  decode.d1.loss_dice: 0.3228  decode.d2.loss_cls: 0.2574  decode.d2.loss_mask: 0.2458  decode.d2.loss_dice: 0.3083  decode.d3.loss_cls: 0.2479  decode.d3.loss_mask: 0.2427  decode.d3.loss_dice: 0.2917  decode.d4.loss_cls: 0.3001  decode.d4.loss_mask: 0.2415  decode.d4.loss_dice: 0.2931  decode.d5.loss_cls: 0.2842  decode.d5.loss_mask: 0.2371  decode.d5.loss_dice: 0.2994  decode.d6.loss_cls: 0.2722  decode.d6.loss_mask: 0.2378  decode.d6.loss_dice: 0.2926  decode.d7.loss_cls: 0.2511  decode.d7.loss_mask: 0.2384  decode.d7.loss_dice: 0.2862  decode.d8.loss_cls: 0.2726  decode.d8.loss_mask: 0.2439  decode.d8.loss_dice: 0.2891
07/25 20:42:15 - mmengine - INFO - Iter(train) [11300/80000]  base_lr: 8.7194e-05 lr: 8.7194e-06  eta: 8:44:02  time: 0.4629  data_time: 0.0104  memory: 5229  grad_norm: 173.8811  loss: 11.8071  decode.loss_cls: 0.3467  decode.loss_mask: 0.3620  decode.loss_dice: 0.3792  decode.d0.loss_cls: 1.1011  decode.d0.loss_mask: 0.3297  decode.d0.loss_dice: 0.4392  decode.d1.loss_cls: 0.5623  decode.d1.loss_mask: 0.3353  decode.d1.loss_dice: 0.4303  decode.d2.loss_cls: 0.4310  decode.d2.loss_mask: 0.2479  decode.d2.loss_dice: 0.4001  decode.d3.loss_cls: 0.3574  decode.d3.loss_mask: 0.3375  decode.d3.loss_dice: 0.4332  decode.d4.loss_cls: 0.4563  decode.d4.loss_mask: 0.2990  decode.d4.loss_dice: 0.4132  decode.d5.loss_cls: 0.3980  decode.d5.loss_mask: 0.2711  decode.d5.loss_dice: 0.3752  decode.d6.loss_cls: 0.3438  decode.d6.loss_mask: 0.3538  decode.d6.loss_dice: 0.3849  decode.d7.loss_cls: 0.2804  decode.d7.loss_mask: 0.3428  decode.d7.loss_dice: 0.3899  decode.d8.loss_cls: 0.2730  decode.d8.loss_mask: 0.3255  decode.d8.loss_dice: 0.4075
07/25 20:42:38 - mmengine - INFO - Iter(train) [11350/80000]  base_lr: 8.7137e-05 lr: 8.7137e-06  eta: 8:43:38  time: 0.4527  data_time: 0.0099  memory: 5249  grad_norm: 122.5141  loss: 13.1271  decode.loss_cls: 0.5758  decode.loss_mask: 0.2884  decode.loss_dice: 0.3183  decode.d0.loss_cls: 1.5038  decode.d0.loss_mask: 0.2929  decode.d0.loss_dice: 0.3733  decode.d1.loss_cls: 0.7873  decode.d1.loss_mask: 0.2853  decode.d1.loss_dice: 0.3396  decode.d2.loss_cls: 0.6045  decode.d2.loss_mask: 0.2893  decode.d2.loss_dice: 0.3223  decode.d3.loss_cls: 0.6303  decode.d3.loss_mask: 0.2956  decode.d3.loss_dice: 0.3258  decode.d4.loss_cls: 0.5899  decode.d4.loss_mask: 0.2912  decode.d4.loss_dice: 0.3287  decode.d5.loss_cls: 0.5472  decode.d5.loss_mask: 0.2902  decode.d5.loss_dice: 0.3243  decode.d6.loss_cls: 0.5217  decode.d6.loss_mask: 0.2954  decode.d6.loss_dice: 0.3137  decode.d7.loss_cls: 0.6053  decode.d7.loss_mask: 0.2841  decode.d7.loss_dice: 0.3231  decode.d8.loss_cls: 0.5771  decode.d8.loss_mask: 0.2853  decode.d8.loss_dice: 0.3173
07/25 20:43:01 - mmengine - INFO - Iter(train) [11400/80000]  base_lr: 8.7079e-05 lr: 8.7079e-06  eta: 8:43:15  time: 0.4621  data_time: 0.0103  memory: 5249  grad_norm: 148.1303  loss: 11.3390  decode.loss_cls: 0.4407  decode.loss_mask: 0.2161  decode.loss_dice: 0.4063  decode.d0.loss_cls: 1.3308  decode.d0.loss_mask: 0.2316  decode.d0.loss_dice: 0.4527  decode.d1.loss_cls: 0.5026  decode.d1.loss_mask: 0.2211  decode.d1.loss_dice: 0.3984  decode.d2.loss_cls: 0.4227  decode.d2.loss_mask: 0.2229  decode.d2.loss_dice: 0.3922  decode.d3.loss_cls: 0.3872  decode.d3.loss_mask: 0.2139  decode.d3.loss_dice: 0.3894  decode.d4.loss_cls: 0.3923  decode.d4.loss_mask: 0.2209  decode.d4.loss_dice: 0.3894  decode.d5.loss_cls: 0.3869  decode.d5.loss_mask: 0.2222  decode.d5.loss_dice: 0.4059  decode.d6.loss_cls: 0.4148  decode.d6.loss_mask: 0.2135  decode.d6.loss_dice: 0.3998  decode.d7.loss_cls: 0.4243  decode.d7.loss_mask: 0.2153  decode.d7.loss_dice: 0.3870  decode.d8.loss_cls: 0.4201  decode.d8.loss_mask: 0.2179  decode.d8.loss_dice: 0.4001
07/25 20:43:24 - mmengine - INFO - Iter(train) [11450/80000]  base_lr: 8.7022e-05 lr: 8.7022e-06  eta: 8:42:53  time: 0.4580  data_time: 0.0102  memory: 5298  grad_norm: 98.3028  loss: 11.3830  decode.loss_cls: 0.4130  decode.loss_mask: 0.2701  decode.loss_dice: 0.3632  decode.d0.loss_cls: 1.3519  decode.d0.loss_mask: 0.2876  decode.d0.loss_dice: 0.3905  decode.d1.loss_cls: 0.6100  decode.d1.loss_mask: 0.2776  decode.d1.loss_dice: 0.3618  decode.d2.loss_cls: 0.3843  decode.d2.loss_mask: 0.2747  decode.d2.loss_dice: 0.3957  decode.d3.loss_cls: 0.2775  decode.d3.loss_mask: 0.2717  decode.d3.loss_dice: 0.3747  decode.d4.loss_cls: 0.3126  decode.d4.loss_mask: 0.2711  decode.d4.loss_dice: 0.3721  decode.d5.loss_cls: 0.3685  decode.d5.loss_mask: 0.2726  decode.d5.loss_dice: 0.3658  decode.d6.loss_cls: 0.3672  decode.d6.loss_mask: 0.2764  decode.d6.loss_dice: 0.3686  decode.d7.loss_cls: 0.3960  decode.d7.loss_mask: 0.2713  decode.d7.loss_dice: 0.3704  decode.d8.loss_cls: 0.4199  decode.d8.loss_mask: 0.2770  decode.d8.loss_dice: 0.3690
07/25 20:43:47 - mmengine - INFO - Iter(train) [11500/80000]  base_lr: 8.6965e-05 lr: 8.6965e-06  eta: 8:42:31  time: 0.4586  data_time: 0.0101  memory: 5248  grad_norm: 111.1273  loss: 10.4675  decode.loss_cls: 0.2794  decode.loss_mask: 0.3064  decode.loss_dice: 0.3534  decode.d0.loss_cls: 1.0597  decode.d0.loss_mask: 0.3233  decode.d0.loss_dice: 0.3968  decode.d1.loss_cls: 0.4486  decode.d1.loss_mask: 0.3161  decode.d1.loss_dice: 0.3463  decode.d2.loss_cls: 0.3100  decode.d2.loss_mask: 0.3091  decode.d2.loss_dice: 0.3243  decode.d3.loss_cls: 0.2873  decode.d3.loss_mask: 0.3113  decode.d3.loss_dice: 0.3352  decode.d4.loss_cls: 0.3097  decode.d4.loss_mask: 0.3051  decode.d4.loss_dice: 0.3515  decode.d5.loss_cls: 0.2731  decode.d5.loss_mask: 0.3075  decode.d5.loss_dice: 0.3337  decode.d6.loss_cls: 0.3020  decode.d6.loss_mask: 0.3068  decode.d6.loss_dice: 0.3412  decode.d7.loss_cls: 0.3132  decode.d7.loss_mask: 0.3056  decode.d7.loss_dice: 0.3496  decode.d8.loss_cls: 0.2971  decode.d8.loss_mask: 0.3104  decode.d8.loss_dice: 0.3537
07/25 20:44:10 - mmengine - INFO - Iter(train) [11550/80000]  base_lr: 8.6908e-05 lr: 8.6908e-06  eta: 8:42:08  time: 0.4584  data_time: 0.0108  memory: 5249  grad_norm: 110.1790  loss: 12.6226  decode.loss_cls: 0.4398  decode.loss_mask: 0.3159  decode.loss_dice: 0.3608  decode.d0.loss_cls: 1.3695  decode.d0.loss_mask: 0.3403  decode.d0.loss_dice: 0.4140  decode.d1.loss_cls: 0.5725  decode.d1.loss_mask: 0.2892  decode.d1.loss_dice: 0.3677  decode.d2.loss_cls: 0.5296  decode.d2.loss_mask: 0.3452  decode.d2.loss_dice: 0.3809  decode.d3.loss_cls: 0.4545  decode.d3.loss_mask: 0.3254  decode.d3.loss_dice: 0.3763  decode.d4.loss_cls: 0.4635  decode.d4.loss_mask: 0.3235  decode.d4.loss_dice: 0.3732  decode.d5.loss_cls: 0.4888  decode.d5.loss_mask: 0.3028  decode.d5.loss_dice: 0.3604  decode.d6.loss_cls: 0.5154  decode.d6.loss_mask: 0.3380  decode.d6.loss_dice: 0.3650  decode.d7.loss_cls: 0.4272  decode.d7.loss_mask: 0.3041  decode.d7.loss_dice: 0.3868  decode.d8.loss_cls: 0.4410  decode.d8.loss_mask: 0.2952  decode.d8.loss_dice: 0.3562
07/25 20:44:32 - mmengine - INFO - Iter(train) [11600/80000]  base_lr: 8.6851e-05 lr: 8.6851e-06  eta: 8:41:43  time: 0.4355  data_time: 0.0092  memory: 5229  grad_norm: 231.4708  loss: 10.6572  decode.loss_cls: 0.2081  decode.loss_mask: 0.3406  decode.loss_dice: 0.3507  decode.d0.loss_cls: 1.1278  decode.d0.loss_mask: 0.3676  decode.d0.loss_dice: 0.3654  decode.d1.loss_cls: 0.4709  decode.d1.loss_mask: 0.3528  decode.d1.loss_dice: 0.3496  decode.d2.loss_cls: 0.3633  decode.d2.loss_mask: 0.3538  decode.d2.loss_dice: 0.3294  decode.d3.loss_cls: 0.3055  decode.d3.loss_mask: 0.3488  decode.d3.loss_dice: 0.3240  decode.d4.loss_cls: 0.2633  decode.d4.loss_mask: 0.3414  decode.d4.loss_dice: 0.3270  decode.d5.loss_cls: 0.2840  decode.d5.loss_mask: 0.3492  decode.d5.loss_dice: 0.3360  decode.d6.loss_cls: 0.3269  decode.d6.loss_mask: 0.3415  decode.d6.loss_dice: 0.3560  decode.d7.loss_cls: 0.2124  decode.d7.loss_mask: 0.3292  decode.d7.loss_dice: 0.3428  decode.d8.loss_cls: 0.1980  decode.d8.loss_mask: 0.3424  decode.d8.loss_dice: 0.3487
07/25 20:44:55 - mmengine - INFO - Iter(train) [11650/80000]  base_lr: 8.6794e-05 lr: 8.6794e-06  eta: 8:41:21  time: 0.4574  data_time: 0.0107  memory: 5231  grad_norm: 97.8513  loss: 11.0669  decode.loss_cls: 0.3443  decode.loss_mask: 0.2827  decode.loss_dice: 0.3809  decode.d0.loss_cls: 1.1978  decode.d0.loss_mask: 0.2888  decode.d0.loss_dice: 0.3605  decode.d1.loss_cls: 0.4796  decode.d1.loss_mask: 0.2775  decode.d1.loss_dice: 0.3513  decode.d2.loss_cls: 0.4457  decode.d2.loss_mask: 0.2736  decode.d2.loss_dice: 0.3450  decode.d3.loss_cls: 0.4116  decode.d3.loss_mask: 0.2718  decode.d3.loss_dice: 0.3524  decode.d4.loss_cls: 0.3592  decode.d4.loss_mask: 0.2739  decode.d4.loss_dice: 0.3569  decode.d5.loss_cls: 0.4089  decode.d5.loss_mask: 0.2721  decode.d5.loss_dice: 0.3464  decode.d6.loss_cls: 0.4083  decode.d6.loss_mask: 0.2727  decode.d6.loss_dice: 0.3415  decode.d7.loss_cls: 0.3533  decode.d7.loss_mask: 0.2797  decode.d7.loss_dice: 0.3637  decode.d8.loss_cls: 0.3321  decode.d8.loss_mask: 0.2797  decode.d8.loss_dice: 0.3549
07/25 20:45:18 - mmengine - INFO - Iter(train) [11700/80000]  base_lr: 8.6737e-05 lr: 8.6737e-06  eta: 8:40:57  time: 0.4627  data_time: 0.0105  memory: 5292  grad_norm: 146.5431  loss: 10.1474  decode.loss_cls: 0.4780  decode.loss_mask: 0.2341  decode.loss_dice: 0.2691  decode.d0.loss_cls: 1.3007  decode.d0.loss_mask: 0.2500  decode.d0.loss_dice: 0.2883  decode.d1.loss_cls: 0.4827  decode.d1.loss_mask: 0.2277  decode.d1.loss_dice: 0.2596  decode.d2.loss_cls: 0.3634  decode.d2.loss_mask: 0.2337  decode.d2.loss_dice: 0.2476  decode.d3.loss_cls: 0.4005  decode.d3.loss_mask: 0.2355  decode.d3.loss_dice: 0.2416  decode.d4.loss_cls: 0.4253  decode.d4.loss_mask: 0.2259  decode.d4.loss_dice: 0.2412  decode.d5.loss_cls: 0.4851  decode.d5.loss_mask: 0.2233  decode.d5.loss_dice: 0.2515  decode.d6.loss_cls: 0.4673  decode.d6.loss_mask: 0.2183  decode.d6.loss_dice: 0.2390  decode.d7.loss_cls: 0.4170  decode.d7.loss_mask: 0.2279  decode.d7.loss_dice: 0.2465  decode.d8.loss_cls: 0.4859  decode.d8.loss_mask: 0.2264  decode.d8.loss_dice: 0.2543
07/25 20:45:41 - mmengine - INFO - Iter(train) [11750/80000]  base_lr: 8.6679e-05 lr: 8.6679e-06  eta: 8:40:35  time: 0.4615  data_time: 0.0106  memory: 5265  grad_norm: 90.2785  loss: 12.5858  decode.loss_cls: 0.5232  decode.loss_mask: 0.2763  decode.loss_dice: 0.3537  decode.d0.loss_cls: 1.1953  decode.d0.loss_mask: 0.2949  decode.d0.loss_dice: 0.3922  decode.d1.loss_cls: 0.6246  decode.d1.loss_mask: 0.2892  decode.d1.loss_dice: 0.3659  decode.d2.loss_cls: 0.5721  decode.d2.loss_mask: 0.2734  decode.d2.loss_dice: 0.3660  decode.d3.loss_cls: 0.5263  decode.d3.loss_mask: 0.2809  decode.d3.loss_dice: 0.3653  decode.d4.loss_cls: 0.5313  decode.d4.loss_mask: 0.2790  decode.d4.loss_dice: 0.3699  decode.d5.loss_cls: 0.5270  decode.d5.loss_mask: 0.2807  decode.d5.loss_dice: 0.3629  decode.d6.loss_cls: 0.5722  decode.d6.loss_mask: 0.2773  decode.d6.loss_dice: 0.3550  decode.d7.loss_cls: 0.5614  decode.d7.loss_mask: 0.2798  decode.d7.loss_dice: 0.3415  decode.d8.loss_cls: 0.5139  decode.d8.loss_mask: 0.2766  decode.d8.loss_dice: 0.3579
07/25 20:46:04 - mmengine - INFO - Iter(train) [11800/80000]  base_lr: 8.6622e-05 lr: 8.6622e-06  eta: 8:40:12  time: 0.4534  data_time: 0.0101  memory: 5231  grad_norm: 135.7098  loss: 9.8587  decode.loss_cls: 0.2927  decode.loss_mask: 0.3130  decode.loss_dice: 0.3056  decode.d0.loss_cls: 1.1610  decode.d0.loss_mask: 0.3316  decode.d0.loss_dice: 0.3446  decode.d1.loss_cls: 0.3005  decode.d1.loss_mask: 0.3300  decode.d1.loss_dice: 0.3278  decode.d2.loss_cls: 0.2405  decode.d2.loss_mask: 0.3226  decode.d2.loss_dice: 0.3360  decode.d3.loss_cls: 0.2567  decode.d3.loss_mask: 0.3219  decode.d3.loss_dice: 0.3114  decode.d4.loss_cls: 0.2217  decode.d4.loss_mask: 0.3288  decode.d4.loss_dice: 0.3189  decode.d5.loss_cls: 0.2770  decode.d5.loss_mask: 0.3193  decode.d5.loss_dice: 0.2955  decode.d6.loss_cls: 0.2359  decode.d6.loss_mask: 0.3206  decode.d6.loss_dice: 0.2972  decode.d7.loss_cls: 0.2277  decode.d7.loss_mask: 0.3203  decode.d7.loss_dice: 0.2947  decode.d8.loss_cls: 0.2614  decode.d8.loss_mask: 0.3235  decode.d8.loss_dice: 0.3206
07/25 20:46:27 - mmengine - INFO - Iter(train) [11850/80000]  base_lr: 8.6565e-05 lr: 8.6565e-06  eta: 8:39:50  time: 0.4612  data_time: 0.0106  memory: 5249  grad_norm: 105.7111  loss: 12.7498  decode.loss_cls: 0.5591  decode.loss_mask: 0.2179  decode.loss_dice: 0.3314  decode.d0.loss_cls: 1.5141  decode.d0.loss_mask: 0.2105  decode.d0.loss_dice: 0.3682  decode.d1.loss_cls: 0.7950  decode.d1.loss_mask: 0.2057  decode.d1.loss_dice: 0.3572  decode.d2.loss_cls: 0.6763  decode.d2.loss_mask: 0.2042  decode.d2.loss_dice: 0.3410  decode.d3.loss_cls: 0.5433  decode.d3.loss_mask: 0.2091  decode.d3.loss_dice: 0.3538  decode.d4.loss_cls: 0.6010  decode.d4.loss_mask: 0.2085  decode.d4.loss_dice: 0.3630  decode.d5.loss_cls: 0.6280  decode.d5.loss_mask: 0.2139  decode.d5.loss_dice: 0.3610  decode.d6.loss_cls: 0.6417  decode.d6.loss_mask: 0.2067  decode.d6.loss_dice: 0.3373  decode.d7.loss_cls: 0.5721  decode.d7.loss_mask: 0.2198  decode.d7.loss_dice: 0.3736  decode.d8.loss_cls: 0.5735  decode.d8.loss_mask: 0.2129  decode.d8.loss_dice: 0.3501
07/25 20:46:50 - mmengine - INFO - Iter(train) [11900/80000]  base_lr: 8.6508e-05 lr: 8.6508e-06  eta: 8:39:27  time: 0.4550  data_time: 0.0099  memory: 5266  grad_norm: 100.1261  loss: 11.3350  decode.loss_cls: 0.3600  decode.loss_mask: 0.2834  decode.loss_dice: 0.3616  decode.d0.loss_cls: 1.3164  decode.d0.loss_mask: 0.2840  decode.d0.loss_dice: 0.4125  decode.d1.loss_cls: 0.4419  decode.d1.loss_mask: 0.2784  decode.d1.loss_dice: 0.3722  decode.d2.loss_cls: 0.3695  decode.d2.loss_mask: 0.2845  decode.d2.loss_dice: 0.3606  decode.d3.loss_cls: 0.4098  decode.d3.loss_mask: 0.2786  decode.d3.loss_dice: 0.3524  decode.d4.loss_cls: 0.3230  decode.d4.loss_mask: 0.2866  decode.d4.loss_dice: 0.3833  decode.d5.loss_cls: 0.3743  decode.d5.loss_mask: 0.2882  decode.d5.loss_dice: 0.3839  decode.d6.loss_cls: 0.4330  decode.d6.loss_mask: 0.2804  decode.d6.loss_dice: 0.3521  decode.d7.loss_cls: 0.3637  decode.d7.loss_mask: 0.2916  decode.d7.loss_dice: 0.3428  decode.d8.loss_cls: 0.4181  decode.d8.loss_mask: 0.2839  decode.d8.loss_dice: 0.3643
07/25 20:47:13 - mmengine - INFO - Iter(train) [11950/80000]  base_lr: 8.6451e-05 lr: 8.6451e-06  eta: 8:39:05  time: 0.4593  data_time: 0.0103  memory: 5215  grad_norm: 101.3947  loss: 10.1268  decode.loss_cls: 0.3151  decode.loss_mask: 0.2667  decode.loss_dice: 0.3323  decode.d0.loss_cls: 1.1333  decode.d0.loss_mask: 0.2810  decode.d0.loss_dice: 0.3416  decode.d1.loss_cls: 0.3184  decode.d1.loss_mask: 0.3140  decode.d1.loss_dice: 0.3569  decode.d2.loss_cls: 0.2655  decode.d2.loss_mask: 0.2864  decode.d2.loss_dice: 0.3355  decode.d3.loss_cls: 0.2961  decode.d3.loss_mask: 0.2981  decode.d3.loss_dice: 0.3415  decode.d4.loss_cls: 0.3236  decode.d4.loss_mask: 0.2710  decode.d4.loss_dice: 0.3305  decode.d5.loss_cls: 0.2745  decode.d5.loss_mask: 0.3103  decode.d5.loss_dice: 0.3312  decode.d6.loss_cls: 0.2680  decode.d6.loss_mask: 0.2962  decode.d6.loss_dice: 0.3437  decode.d7.loss_cls: 0.3046  decode.d7.loss_mask: 0.2923  decode.d7.loss_dice: 0.3594  decode.d8.loss_cls: 0.3108  decode.d8.loss_mask: 0.3014  decode.d8.loss_dice: 0.3270
07/25 20:47:35 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250725_191538
07/25 20:47:35 - mmengine - INFO - Iter(train) [12000/80000]  base_lr: 8.6394e-05 lr: 8.6394e-06  eta: 8:38:41  time: 0.4619  data_time: 0.0110  memory: 5214  grad_norm: 65.7035  loss: 8.2599  decode.loss_cls: 0.1814  decode.loss_mask: 0.3040  decode.loss_dice: 0.2545  decode.d0.loss_cls: 1.0782  decode.d0.loss_mask: 0.3261  decode.d0.loss_dice: 0.2747  decode.d1.loss_cls: 0.2311  decode.d1.loss_mask: 0.3081  decode.d1.loss_dice: 0.2610  decode.d2.loss_cls: 0.1590  decode.d2.loss_mask: 0.3018  decode.d2.loss_dice: 0.2600  decode.d3.loss_cls: 0.1302  decode.d3.loss_mask: 0.2971  decode.d3.loss_dice: 0.2532  decode.d4.loss_cls: 0.1643  decode.d4.loss_mask: 0.3007  decode.d4.loss_dice: 0.2523  decode.d5.loss_cls: 0.1888  decode.d5.loss_mask: 0.3007  decode.d5.loss_dice: 0.2501  decode.d6.loss_cls: 0.1834  decode.d6.loss_mask: 0.3024  decode.d6.loss_dice: 0.2494  decode.d7.loss_cls: 0.1680  decode.d7.loss_mask: 0.3049  decode.d7.loss_dice: 0.2481  decode.d8.loss_cls: 0.1719  decode.d8.loss_mask: 0.3031  decode.d8.loss_dice: 0.2516
07/25 20:47:58 - mmengine - INFO - Iter(train) [12050/80000]  base_lr: 8.6336e-05 lr: 8.6336e-06  eta: 8:38:17  time: 0.4509  data_time: 0.0098  memory: 5249  grad_norm: 87.9826  loss: 10.2954  decode.loss_cls: 0.2520  decode.loss_mask: 0.2888  decode.loss_dice: 0.3585  decode.d0.loss_cls: 1.2225  decode.d0.loss_mask: 0.3027  decode.d0.loss_dice: 0.4353  decode.d1.loss_cls: 0.3890  decode.d1.loss_mask: 0.2924  decode.d1.loss_dice: 0.3521  decode.d2.loss_cls: 0.2942  decode.d2.loss_mask: 0.2869  decode.d2.loss_dice: 0.3621  decode.d3.loss_cls: 0.2901  decode.d3.loss_mask: 0.2899  decode.d3.loss_dice: 0.3584  decode.d4.loss_cls: 0.2518  decode.d4.loss_mask: 0.2910  decode.d4.loss_dice: 0.3621  decode.d5.loss_cls: 0.2255  decode.d5.loss_mask: 0.2867  decode.d5.loss_dice: 0.3660  decode.d6.loss_cls: 0.2797  decode.d6.loss_mask: 0.2877  decode.d6.loss_dice: 0.3481  decode.d7.loss_cls: 0.2847  decode.d7.loss_mask: 0.2866  decode.d7.loss_dice: 0.3798  decode.d8.loss_cls: 0.2241  decode.d8.loss_mask: 0.2842  decode.d8.loss_dice: 0.3627
07/25 20:48:21 - mmengine - INFO - Iter(train) [12100/80000]  base_lr: 8.6279e-05 lr: 8.6279e-06  eta: 8:37:55  time: 0.4597  data_time: 0.0105  memory: 5230  grad_norm: 72.4686  loss: 10.3029  decode.loss_cls: 0.3461  decode.loss_mask: 0.2693  decode.loss_dice: 0.3175  decode.d0.loss_cls: 1.3453  decode.d0.loss_mask: 0.2806  decode.d0.loss_dice: 0.3139  decode.d1.loss_cls: 0.4953  decode.d1.loss_mask: 0.2683  decode.d1.loss_dice: 0.2701  decode.d2.loss_cls: 0.3449  decode.d2.loss_mask: 0.2730  decode.d2.loss_dice: 0.3077  decode.d3.loss_cls: 0.3164  decode.d3.loss_mask: 0.2688  decode.d3.loss_dice: 0.2816  decode.d4.loss_cls: 0.3530  decode.d4.loss_mask: 0.2686  decode.d4.loss_dice: 0.3350  decode.d5.loss_cls: 0.2946  decode.d5.loss_mask: 0.2708  decode.d5.loss_dice: 0.3231  decode.d6.loss_cls: 0.3133  decode.d6.loss_mask: 0.2701  decode.d6.loss_dice: 0.2915  decode.d7.loss_cls: 0.3369  decode.d7.loss_mask: 0.2672  decode.d7.loss_dice: 0.2982  decode.d8.loss_cls: 0.3961  decode.d8.loss_mask: 0.2706  decode.d8.loss_dice: 0.3149
07/25 20:48:44 - mmengine - INFO - Iter(train) [12150/80000]  base_lr: 8.6222e-05 lr: 8.6222e-06  eta: 8:37:33  time: 0.4606  data_time: 0.0105  memory: 5266  grad_norm: 74.3812  loss: 9.5701  decode.loss_cls: 0.2332  decode.loss_mask: 0.2814  decode.loss_dice: 0.2733  decode.d0.loss_cls: 1.5050  decode.d0.loss_mask: 0.2734  decode.d0.loss_dice: 0.3711  decode.d1.loss_cls: 0.3029  decode.d1.loss_mask: 0.2861  decode.d1.loss_dice: 0.3197  decode.d2.loss_cls: 0.2418  decode.d2.loss_mask: 0.2757  decode.d2.loss_dice: 0.2819  decode.d3.loss_cls: 0.2554  decode.d3.loss_mask: 0.2822  decode.d3.loss_dice: 0.2788  decode.d4.loss_cls: 0.2893  decode.d4.loss_mask: 0.2731  decode.d4.loss_dice: 0.3235  decode.d5.loss_cls: 0.2443  decode.d5.loss_mask: 0.2746  decode.d5.loss_dice: 0.2838  decode.d6.loss_cls: 0.2363  decode.d6.loss_mask: 0.2691  decode.d6.loss_dice: 0.2826  decode.d7.loss_cls: 0.2512  decode.d7.loss_mask: 0.2741  decode.d7.loss_dice: 0.2827  decode.d8.loss_cls: 0.2545  decode.d8.loss_mask: 0.2795  decode.d8.loss_dice: 0.2893
07/25 20:49:07 - mmengine - INFO - Iter(train) [12200/80000]  base_lr: 8.6165e-05 lr: 8.6165e-06  eta: 8:37:11  time: 0.4617  data_time: 0.0105  memory: 5215  grad_norm: 156.0460  loss: 11.5658  decode.loss_cls: 0.4177  decode.loss_mask: 0.3139  decode.loss_dice: 0.3853  decode.d0.loss_cls: 1.2910  decode.d0.loss_mask: 0.2517  decode.d0.loss_dice: 0.4110  decode.d1.loss_cls: 0.4747  decode.d1.loss_mask: 0.2483  decode.d1.loss_dice: 0.3643  decode.d2.loss_cls: 0.4265  decode.d2.loss_mask: 0.2580  decode.d2.loss_dice: 0.3680  decode.d3.loss_cls: 0.4183  decode.d3.loss_mask: 0.2528  decode.d3.loss_dice: 0.3645  decode.d4.loss_cls: 0.4704  decode.d4.loss_mask: 0.2866  decode.d4.loss_dice: 0.4013  decode.d5.loss_cls: 0.4260  decode.d5.loss_mask: 0.2928  decode.d5.loss_dice: 0.3823  decode.d6.loss_cls: 0.3525  decode.d6.loss_mask: 0.2836  decode.d6.loss_dice: 0.3723  decode.d7.loss_cls: 0.3748  decode.d7.loss_mask: 0.2798  decode.d7.loss_dice: 0.3755  decode.d8.loss_cls: 0.3678  decode.d8.loss_mask: 0.2943  decode.d8.loss_dice: 0.3598
07/25 20:49:30 - mmengine - INFO - Iter(train) [12250/80000]  base_lr: 8.6108e-05 lr: 8.6108e-06  eta: 8:36:48  time: 0.4608  data_time: 0.0105  memory: 5228  grad_norm: 78.9470  loss: 9.6156  decode.loss_cls: 0.2783  decode.loss_mask: 0.2929  decode.loss_dice: 0.3136  decode.d0.loss_cls: 1.2459  decode.d0.loss_mask: 0.3101  decode.d0.loss_dice: 0.3796  decode.d1.loss_cls: 0.2929  decode.d1.loss_mask: 0.2842  decode.d1.loss_dice: 0.3030  decode.d2.loss_cls: 0.2809  decode.d2.loss_mask: 0.2822  decode.d2.loss_dice: 0.3076  decode.d3.loss_cls: 0.2228  decode.d3.loss_mask: 0.2895  decode.d3.loss_dice: 0.3133  decode.d4.loss_cls: 0.2229  decode.d4.loss_mask: 0.2929  decode.d4.loss_dice: 0.3262  decode.d5.loss_cls: 0.1978  decode.d5.loss_mask: 0.2948  decode.d5.loss_dice: 0.3218  decode.d6.loss_cls: 0.1898  decode.d6.loss_mask: 0.3065  decode.d6.loss_dice: 0.3415  decode.d7.loss_cls: 0.2511  decode.d7.loss_mask: 0.2917  decode.d7.loss_dice: 0.3084  decode.d8.loss_cls: 0.2568  decode.d8.loss_mask: 0.2973  decode.d8.loss_dice: 0.3189
07/25 20:49:53 - mmengine - INFO - Iter(train) [12300/80000]  base_lr: 8.6051e-05 lr: 8.6051e-06  eta: 8:36:26  time: 0.4559  data_time: 0.0104  memory: 5265  grad_norm: 164.0583  loss: 11.5678  decode.loss_cls: 0.4014  decode.loss_mask: 0.3117  decode.loss_dice: 0.2974  decode.d0.loss_cls: 1.0806  decode.d0.loss_mask: 0.3313  decode.d0.loss_dice: 0.3764  decode.d1.loss_cls: 0.6376  decode.d1.loss_mask: 0.2987  decode.d1.loss_dice: 0.3172  decode.d2.loss_cls: 0.4255  decode.d2.loss_mask: 0.3065  decode.d2.loss_dice: 0.2982  decode.d3.loss_cls: 0.4909  decode.d3.loss_mask: 0.2922  decode.d3.loss_dice: 0.2916  decode.d4.loss_cls: 0.4663  decode.d4.loss_mask: 0.2908  decode.d4.loss_dice: 0.3049  decode.d5.loss_cls: 0.4713  decode.d5.loss_mask: 0.2972  decode.d5.loss_dice: 0.3048  decode.d6.loss_cls: 0.5023  decode.d6.loss_mask: 0.3045  decode.d6.loss_dice: 0.3090  decode.d7.loss_cls: 0.4360  decode.d7.loss_mask: 0.3051  decode.d7.loss_dice: 0.3131  decode.d8.loss_cls: 0.4704  decode.d8.loss_mask: 0.3161  decode.d8.loss_dice: 0.3187
07/25 20:50:16 - mmengine - INFO - Iter(train) [12350/80000]  base_lr: 8.5993e-05 lr: 8.5993e-06  eta: 8:36:01  time: 0.4551  data_time: 0.0103  memory: 5249  grad_norm: 60.5610  loss: 8.0480  decode.loss_cls: 0.1952  decode.loss_mask: 0.2666  decode.loss_dice: 0.2555  decode.d0.loss_cls: 1.0362  decode.d0.loss_mask: 0.2699  decode.d0.loss_dice: 0.2764  decode.d1.loss_cls: 0.2881  decode.d1.loss_mask: 0.2665  decode.d1.loss_dice: 0.2500  decode.d2.loss_cls: 0.2265  decode.d2.loss_mask: 0.2621  decode.d2.loss_dice: 0.2454  decode.d3.loss_cls: 0.2113  decode.d3.loss_mask: 0.2641  decode.d3.loss_dice: 0.2577  decode.d4.loss_cls: 0.1668  decode.d4.loss_mask: 0.2639  decode.d4.loss_dice: 0.2627  decode.d5.loss_cls: 0.1667  decode.d5.loss_mask: 0.2674  decode.d5.loss_dice: 0.2606  decode.d6.loss_cls: 0.1959  decode.d6.loss_mask: 0.2651  decode.d6.loss_dice: 0.2522  decode.d7.loss_cls: 0.1558  decode.d7.loss_mask: 0.2643  decode.d7.loss_dice: 0.2542  decode.d8.loss_cls: 0.1824  decode.d8.loss_mask: 0.2643  decode.d8.loss_dice: 0.2542
07/25 20:50:38 - mmengine - INFO - Iter(train) [12400/80000]  base_lr: 8.5936e-05 lr: 8.5936e-06  eta: 8:35:38  time: 0.4457  data_time: 0.0098  memory: 5249  grad_norm: 82.6219  loss: 10.4977  decode.loss_cls: 0.2982  decode.loss_mask: 0.2895  decode.loss_dice: 0.3126  decode.d0.loss_cls: 1.2487  decode.d0.loss_mask: 0.3082  decode.d0.loss_dice: 0.3498  decode.d1.loss_cls: 0.3962  decode.d1.loss_mask: 0.2997  decode.d1.loss_dice: 0.3175  decode.d2.loss_cls: 0.3284  decode.d2.loss_mask: 0.2919  decode.d2.loss_dice: 0.3342  decode.d3.loss_cls: 0.3462  decode.d3.loss_mask: 0.2940  decode.d3.loss_dice: 0.3085  decode.d4.loss_cls: 0.3576  decode.d4.loss_mask: 0.2944  decode.d4.loss_dice: 0.3080  decode.d5.loss_cls: 0.3436  decode.d5.loss_mask: 0.2935  decode.d5.loss_dice: 0.3144  decode.d6.loss_cls: 0.3284  decode.d6.loss_mask: 0.2910  decode.d6.loss_dice: 0.3296  decode.d7.loss_cls: 0.3509  decode.d7.loss_mask: 0.2893  decode.d7.loss_dice: 0.3329  decode.d8.loss_cls: 0.3218  decode.d8.loss_mask: 0.2909  decode.d8.loss_dice: 0.3279
07/25 20:51:01 - mmengine - INFO - Iter(train) [12450/80000]  base_lr: 8.5879e-05 lr: 8.5879e-06  eta: 8:35:13  time: 0.4572  data_time: 0.0103  memory: 5265  grad_norm: 59.5054  loss: 9.1564  decode.loss_cls: 0.2530  decode.loss_mask: 0.2349  decode.loss_dice: 0.2527  decode.d0.loss_cls: 1.3120  decode.d0.loss_mask: 0.2440  decode.d0.loss_dice: 0.3603  decode.d1.loss_cls: 0.3757  decode.d1.loss_mask: 0.2379  decode.d1.loss_dice: 0.3030  decode.d2.loss_cls: 0.2967  decode.d2.loss_mask: 0.2413  decode.d2.loss_dice: 0.2800  decode.d3.loss_cls: 0.2957  decode.d3.loss_mask: 0.2322  decode.d3.loss_dice: 0.2563  decode.d4.loss_cls: 0.2831  decode.d4.loss_mask: 0.2376  decode.d4.loss_dice: 0.2644  decode.d5.loss_cls: 0.2579  decode.d5.loss_mask: 0.2416  decode.d5.loss_dice: 0.2855  decode.d6.loss_cls: 0.2623  decode.d6.loss_mask: 0.2388  decode.d6.loss_dice: 0.2829  decode.d7.loss_cls: 0.2918  decode.d7.loss_mask: 0.2404  decode.d7.loss_dice: 0.2903  decode.d8.loss_cls: 0.2722  decode.d8.loss_mask: 0.2396  decode.d8.loss_dice: 0.2923
07/25 20:51:24 - mmengine - INFO - Iter(train) [12500/80000]  base_lr: 8.5822e-05 lr: 8.5822e-06  eta: 8:34:51  time: 0.4572  data_time: 0.0105  memory: 5229  grad_norm: 138.0255  loss: 9.5677  decode.loss_cls: 0.2967  decode.loss_mask: 0.2363  decode.loss_dice: 0.3396  decode.d0.loss_cls: 1.2299  decode.d0.loss_mask: 0.2604  decode.d0.loss_dice: 0.3249  decode.d1.loss_cls: 0.3460  decode.d1.loss_mask: 0.2455  decode.d1.loss_dice: 0.3072  decode.d2.loss_cls: 0.2979  decode.d2.loss_mask: 0.2354  decode.d2.loss_dice: 0.2884  decode.d3.loss_cls: 0.3078  decode.d3.loss_mask: 0.2357  decode.d3.loss_dice: 0.3177  decode.d4.loss_cls: 0.3546  decode.d4.loss_mask: 0.2337  decode.d4.loss_dice: 0.2852  decode.d5.loss_cls: 0.3532  decode.d5.loss_mask: 0.2355  decode.d5.loss_dice: 0.3140  decode.d6.loss_cls: 0.3281  decode.d6.loss_mask: 0.2377  decode.d6.loss_dice: 0.2996  decode.d7.loss_cls: 0.3158  decode.d7.loss_mask: 0.2329  decode.d7.loss_dice: 0.3098  decode.d8.loss_cls: 0.2339  decode.d8.loss_mask: 0.2454  decode.d8.loss_dice: 0.3187
07/25 20:51:47 - mmengine - INFO - Iter(train) [12550/80000]  base_lr: 8.5765e-05 lr: 8.5765e-06  eta: 8:34:28  time: 0.4565  data_time: 0.0100  memory: 5265  grad_norm: 158.7926  loss: 12.4914  decode.loss_cls: 0.4966  decode.loss_mask: 0.2788  decode.loss_dice: 0.4040  decode.d0.loss_cls: 1.5329  decode.d0.loss_mask: 0.3132  decode.d0.loss_dice: 0.4045  decode.d1.loss_cls: 0.4719  decode.d1.loss_mask: 0.2884  decode.d1.loss_dice: 0.3552  decode.d2.loss_cls: 0.4650  decode.d2.loss_mask: 0.2761  decode.d2.loss_dice: 0.3945  decode.d3.loss_cls: 0.5133  decode.d3.loss_mask: 0.2795  decode.d3.loss_dice: 0.4039  decode.d4.loss_cls: 0.4584  decode.d4.loss_mask: 0.2772  decode.d4.loss_dice: 0.3744  decode.d5.loss_cls: 0.4155  decode.d5.loss_mask: 0.2758  decode.d5.loss_dice: 0.3763  decode.d6.loss_cls: 0.4621  decode.d6.loss_mask: 0.2767  decode.d6.loss_dice: 0.4097  decode.d7.loss_cls: 0.4374  decode.d7.loss_mask: 0.2771  decode.d7.loss_dice: 0.4016  decode.d8.loss_cls: 0.5185  decode.d8.loss_mask: 0.2783  decode.d8.loss_dice: 0.3748
07/25 20:52:10 - mmengine - INFO - Iter(train) [12600/80000]  base_lr: 8.5707e-05 lr: 8.5707e-06  eta: 8:34:04  time: 0.4553  data_time: 0.0107  memory: 5265  grad_norm: 86.4672  loss: 9.2300  decode.loss_cls: 0.1310  decode.loss_mask: 0.2716  decode.loss_dice: 0.3393  decode.d0.loss_cls: 1.2225  decode.d0.loss_mask: 0.2851  decode.d0.loss_dice: 0.3817  decode.d1.loss_cls: 0.3373  decode.d1.loss_mask: 0.2746  decode.d1.loss_dice: 0.3551  decode.d2.loss_cls: 0.2215  decode.d2.loss_mask: 0.2690  decode.d2.loss_dice: 0.3330  decode.d3.loss_cls: 0.1832  decode.d3.loss_mask: 0.2682  decode.d3.loss_dice: 0.3332  decode.d4.loss_cls: 0.2384  decode.d4.loss_mask: 0.2630  decode.d4.loss_dice: 0.3241  decode.d5.loss_cls: 0.2291  decode.d5.loss_mask: 0.2726  decode.d5.loss_dice: 0.3336  decode.d6.loss_cls: 0.1710  decode.d6.loss_mask: 0.2661  decode.d6.loss_dice: 0.3476  decode.d7.loss_cls: 0.1938  decode.d7.loss_mask: 0.2712  decode.d7.loss_dice: 0.3259  decode.d8.loss_cls: 0.1840  decode.d8.loss_mask: 0.2697  decode.d8.loss_dice: 0.3337
07/25 20:52:32 - mmengine - INFO - Iter(train) [12650/80000]  base_lr: 8.5650e-05 lr: 8.5650e-06  eta: 8:33:41  time: 0.4538  data_time: 0.0103  memory: 5215  grad_norm: 92.1448  loss: 8.5647  decode.loss_cls: 0.1628  decode.loss_mask: 0.2672  decode.loss_dice: 0.3034  decode.d0.loss_cls: 1.1116  decode.d0.loss_mask: 0.2736  decode.d0.loss_dice: 0.3505  decode.d1.loss_cls: 0.2115  decode.d1.loss_mask: 0.2684  decode.d1.loss_dice: 0.3124  decode.d2.loss_cls: 0.1766  decode.d2.loss_mask: 0.2632  decode.d2.loss_dice: 0.3065  decode.d3.loss_cls: 0.1762  decode.d3.loss_mask: 0.2641  decode.d3.loss_dice: 0.3121  decode.d4.loss_cls: 0.1821  decode.d4.loss_mask: 0.2685  decode.d4.loss_dice: 0.3091  decode.d5.loss_cls: 0.1730  decode.d5.loss_mask: 0.2669  decode.d5.loss_dice: 0.3005  decode.d6.loss_cls: 0.1897  decode.d6.loss_mask: 0.2663  decode.d6.loss_dice: 0.3068  decode.d7.loss_cls: 0.1882  decode.d7.loss_mask: 0.2697  decode.d7.loss_dice: 0.3037  decode.d8.loss_cls: 0.2031  decode.d8.loss_mask: 0.2674  decode.d8.loss_dice: 0.3094
07/25 20:52:55 - mmengine - INFO - Iter(train) [12700/80000]  base_lr: 8.5593e-05 lr: 8.5593e-06  eta: 8:33:18  time: 0.4526  data_time: 0.0098  memory: 5248  grad_norm: 120.1023  loss: 11.2929  decode.loss_cls: 0.2668  decode.loss_mask: 0.3487  decode.loss_dice: 0.3852  decode.d0.loss_cls: 1.2250  decode.d0.loss_mask: 0.3496  decode.d0.loss_dice: 0.3915  decode.d1.loss_cls: 0.4291  decode.d1.loss_mask: 0.3407  decode.d1.loss_dice: 0.3653  decode.d2.loss_cls: 0.3550  decode.d2.loss_mask: 0.3408  decode.d2.loss_dice: 0.3681  decode.d3.loss_cls: 0.2857  decode.d3.loss_mask: 0.3322  decode.d3.loss_dice: 0.3647  decode.d4.loss_cls: 0.3155  decode.d4.loss_mask: 0.3339  decode.d4.loss_dice: 0.3723  decode.d5.loss_cls: 0.3040  decode.d5.loss_mask: 0.3513  decode.d5.loss_dice: 0.3736  decode.d6.loss_cls: 0.3154  decode.d6.loss_mask: 0.3455  decode.d6.loss_dice: 0.3589  decode.d7.loss_cls: 0.3314  decode.d7.loss_mask: 0.3557  decode.d7.loss_dice: 0.3834  decode.d8.loss_cls: 0.2792  decode.d8.loss_mask: 0.3529  decode.d8.loss_dice: 0.3713
07/25 20:53:18 - mmengine - INFO - Iter(train) [12750/80000]  base_lr: 8.5536e-05 lr: 8.5536e-06  eta: 8:32:55  time: 0.4528  data_time: 0.0099  memory: 5229  grad_norm: 232.7053  loss: 9.9154  decode.loss_cls: 0.2481  decode.loss_mask: 0.2940  decode.loss_dice: 0.3135  decode.d0.loss_cls: 1.2164  decode.d0.loss_mask: 0.3158  decode.d0.loss_dice: 0.3172  decode.d1.loss_cls: 0.3887  decode.d1.loss_mask: 0.3010  decode.d1.loss_dice: 0.3363  decode.d2.loss_cls: 0.2710  decode.d2.loss_mask: 0.2934  decode.d2.loss_dice: 0.3251  decode.d3.loss_cls: 0.3060  decode.d3.loss_mask: 0.2972  decode.d3.loss_dice: 0.3160  decode.d4.loss_cls: 0.2752  decode.d4.loss_mask: 0.3021  decode.d4.loss_dice: 0.3119  decode.d5.loss_cls: 0.2559  decode.d5.loss_mask: 0.3033  decode.d5.loss_dice: 0.3162  decode.d6.loss_cls: 0.2681  decode.d6.loss_mask: 0.2998  decode.d6.loss_dice: 0.3282  decode.d7.loss_cls: 0.2385  decode.d7.loss_mask: 0.2912  decode.d7.loss_dice: 0.3090  decode.d8.loss_cls: 0.2616  decode.d8.loss_mask: 0.2969  decode.d8.loss_dice: 0.3179
07/25 20:53:41 - mmengine - INFO - Iter(train) [12800/80000]  base_lr: 8.5478e-05 lr: 8.5478e-06  eta: 8:32:32  time: 0.4578  data_time: 0.0107  memory: 5231  grad_norm: 141.1632  loss: 10.0849  decode.loss_cls: 0.2256  decode.loss_mask: 0.3224  decode.loss_dice: 0.2796  decode.d0.loss_cls: 1.1132  decode.d0.loss_mask: 0.3506  decode.d0.loss_dice: 0.3285  decode.d1.loss_cls: 0.3839  decode.d1.loss_mask: 0.3518  decode.d1.loss_dice: 0.3036  decode.d2.loss_cls: 0.2731  decode.d2.loss_mask: 0.3353  decode.d2.loss_dice: 0.2883  decode.d3.loss_cls: 0.3087  decode.d3.loss_mask: 0.3226  decode.d3.loss_dice: 0.2785  decode.d4.loss_cls: 0.3062  decode.d4.loss_mask: 0.3281  decode.d4.loss_dice: 0.2809  decode.d5.loss_cls: 0.2967  decode.d5.loss_mask: 0.3286  decode.d5.loss_dice: 0.2871  decode.d6.loss_cls: 0.2844  decode.d6.loss_mask: 0.3202  decode.d6.loss_dice: 0.2801  decode.d7.loss_cls: 0.3366  decode.d7.loss_mask: 0.3634  decode.d7.loss_dice: 0.3015  decode.d8.loss_cls: 0.2932  decode.d8.loss_mask: 0.3266  decode.d8.loss_dice: 0.2855
07/25 20:54:04 - mmengine - INFO - Iter(train) [12850/80000]  base_lr: 8.5421e-05 lr: 8.5421e-06  eta: 8:32:09  time: 0.4568  data_time: 0.0103  memory: 5292  grad_norm: 101.4826  loss: 9.7362  decode.loss_cls: 0.3279  decode.loss_mask: 0.2293  decode.loss_dice: 0.3128  decode.d0.loss_cls: 1.1825  decode.d0.loss_mask: 0.2342  decode.d0.loss_dice: 0.3248  decode.d1.loss_cls: 0.4138  decode.d1.loss_mask: 0.2371  decode.d1.loss_dice: 0.3210  decode.d2.loss_cls: 0.3533  decode.d2.loss_mask: 0.2306  decode.d2.loss_dice: 0.3293  decode.d3.loss_cls: 0.3161  decode.d3.loss_mask: 0.2330  decode.d3.loss_dice: 0.3209  decode.d4.loss_cls: 0.3112  decode.d4.loss_mask: 0.2312  decode.d4.loss_dice: 0.3069  decode.d5.loss_cls: 0.3378  decode.d5.loss_mask: 0.2325  decode.d5.loss_dice: 0.3172  decode.d6.loss_cls: 0.3187  decode.d6.loss_mask: 0.2308  decode.d6.loss_dice: 0.3043  decode.d7.loss_cls: 0.3727  decode.d7.loss_mask: 0.2284  decode.d7.loss_dice: 0.3105  decode.d8.loss_cls: 0.3215  decode.d8.loss_mask: 0.2331  decode.d8.loss_dice: 0.3126
07/25 20:54:27 - mmengine - INFO - Iter(train) [12900/80000]  base_lr: 8.5364e-05 lr: 8.5364e-06  eta: 8:31:46  time: 0.4564  data_time: 0.0105  memory: 5265  grad_norm: 127.9162  loss: 10.0779  decode.loss_cls: 0.2983  decode.loss_mask: 0.2482  decode.loss_dice: 0.3329  decode.d0.loss_cls: 1.3349  decode.d0.loss_mask: 0.2645  decode.d0.loss_dice: 0.3707  decode.d1.loss_cls: 0.4420  decode.d1.loss_mask: 0.2623  decode.d1.loss_dice: 0.3583  decode.d2.loss_cls: 0.3698  decode.d2.loss_mask: 0.2477  decode.d2.loss_dice: 0.3325  decode.d3.loss_cls: 0.3218  decode.d3.loss_mask: 0.2494  decode.d3.loss_dice: 0.3326  decode.d4.loss_cls: 0.2655  decode.d4.loss_mask: 0.2482  decode.d4.loss_dice: 0.3290  decode.d5.loss_cls: 0.2862  decode.d5.loss_mask: 0.2459  decode.d5.loss_dice: 0.3314  decode.d6.loss_cls: 0.2880  decode.d6.loss_mask: 0.2523  decode.d6.loss_dice: 0.3139  decode.d7.loss_cls: 0.2678  decode.d7.loss_mask: 0.2528  decode.d7.loss_dice: 0.3205  decode.d8.loss_cls: 0.3004  decode.d8.loss_mask: 0.2615  decode.d8.loss_dice: 0.3489
07/25 20:54:50 - mmengine - INFO - Iter(train) [12950/80000]  base_lr: 8.5307e-05 lr: 8.5307e-06  eta: 8:31:23  time: 0.4553  data_time: 0.0104  memory: 5265  grad_norm: 111.2183  loss: 8.3115  decode.loss_cls: 0.1443  decode.loss_mask: 0.3143  decode.loss_dice: 0.2520  decode.d0.loss_cls: 0.9649  decode.d0.loss_mask: 0.3402  decode.d0.loss_dice: 0.2585  decode.d1.loss_cls: 0.2253  decode.d1.loss_mask: 0.3226  decode.d1.loss_dice: 0.2570  decode.d2.loss_cls: 0.1989  decode.d2.loss_mask: 0.3319  decode.d2.loss_dice: 0.2500  decode.d3.loss_cls: 0.1796  decode.d3.loss_mask: 0.3171  decode.d3.loss_dice: 0.2613  decode.d4.loss_cls: 0.1673  decode.d4.loss_mask: 0.3186  decode.d4.loss_dice: 0.2619  decode.d5.loss_cls: 0.1818  decode.d5.loss_mask: 0.3157  decode.d5.loss_dice: 0.2628  decode.d6.loss_cls: 0.1563  decode.d6.loss_mask: 0.3130  decode.d6.loss_dice: 0.2639  decode.d7.loss_cls: 0.1280  decode.d7.loss_mask: 0.3161  decode.d7.loss_dice: 0.2764  decode.d8.loss_cls: 0.1445  decode.d8.loss_mask: 0.3185  decode.d8.loss_dice: 0.2688
07/25 20:55:13 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250725_191538
07/25 20:55:13 - mmengine - INFO - Iter(train) [13000/80000]  base_lr: 8.5249e-05 lr: 8.5249e-06  eta: 8:31:01  time: 0.4569  data_time: 0.0104  memory: 5249  grad_norm: 127.8830  loss: 12.9831  decode.loss_cls: 0.4043  decode.loss_mask: 0.3350  decode.loss_dice: 0.4126  decode.d0.loss_cls: 1.2471  decode.d0.loss_mask: 0.3169  decode.d0.loss_dice: 0.4692  decode.d1.loss_cls: 0.6070  decode.d1.loss_mask: 0.4353  decode.d1.loss_dice: 0.4635  decode.d2.loss_cls: 0.4409  decode.d2.loss_mask: 0.3731  decode.d2.loss_dice: 0.4209  decode.d3.loss_cls: 0.4052  decode.d3.loss_mask: 0.3756  decode.d3.loss_dice: 0.4028  decode.d4.loss_cls: 0.4304  decode.d4.loss_mask: 0.3551  decode.d4.loss_dice: 0.4074  decode.d5.loss_cls: 0.4208  decode.d5.loss_mask: 0.3672  decode.d5.loss_dice: 0.3810  decode.d6.loss_cls: 0.3875  decode.d6.loss_mask: 0.3773  decode.d6.loss_dice: 0.4093  decode.d7.loss_cls: 0.4006  decode.d7.loss_mask: 0.3396  decode.d7.loss_dice: 0.4119  decode.d8.loss_cls: 0.4046  decode.d8.loss_mask: 0.3470  decode.d8.loss_dice: 0.4341
07/25 20:55:35 - mmengine - INFO - Iter(train) [13050/80000]  base_lr: 8.5192e-05 lr: 8.5192e-06  eta: 8:30:38  time: 0.4606  data_time: 0.0105  memory: 5249  grad_norm: 130.4045  loss: 8.7884  decode.loss_cls: 0.2939  decode.loss_mask: 0.2256  decode.loss_dice: 0.2672  decode.d0.loss_cls: 1.2723  decode.d0.loss_mask: 0.2583  decode.d0.loss_dice: 0.3309  decode.d1.loss_cls: 0.3112  decode.d1.loss_mask: 0.2293  decode.d1.loss_dice: 0.2839  decode.d2.loss_cls: 0.2485  decode.d2.loss_mask: 0.2250  decode.d2.loss_dice: 0.2770  decode.d3.loss_cls: 0.2570  decode.d3.loss_mask: 0.2218  decode.d3.loss_dice: 0.2694  decode.d4.loss_cls: 0.2958  decode.d4.loss_mask: 0.2212  decode.d4.loss_dice: 0.2603  decode.d5.loss_cls: 0.2805  decode.d5.loss_mask: 0.2194  decode.d5.loss_dice: 0.2641  decode.d6.loss_cls: 0.2965  decode.d6.loss_mask: 0.2238  decode.d6.loss_dice: 0.2564  decode.d7.loss_cls: 0.2572  decode.d7.loss_mask: 0.2221  decode.d7.loss_dice: 0.2491  decode.d8.loss_cls: 0.2646  decode.d8.loss_mask: 0.2281  decode.d8.loss_dice: 0.2784
07/25 20:55:58 - mmengine - INFO - Iter(train) [13100/80000]  base_lr: 8.5135e-05 lr: 8.5135e-06  eta: 8:30:14  time: 0.4569  data_time: 0.0106  memory: 5251  grad_norm: 188.5461  loss: 10.4640  decode.loss_cls: 0.3352  decode.loss_mask: 0.3381  decode.loss_dice: 0.2937  decode.d0.loss_cls: 1.3870  decode.d0.loss_mask: 0.3531  decode.d0.loss_dice: 0.3351  decode.d1.loss_cls: 0.4141  decode.d1.loss_mask: 0.3306  decode.d1.loss_dice: 0.2788  decode.d2.loss_cls: 0.2791  decode.d2.loss_mask: 0.3148  decode.d2.loss_dice: 0.2795  decode.d3.loss_cls: 0.2492  decode.d3.loss_mask: 0.3211  decode.d3.loss_dice: 0.2819  decode.d4.loss_cls: 0.3436  decode.d4.loss_mask: 0.3231  decode.d4.loss_dice: 0.2833  decode.d5.loss_cls: 0.2579  decode.d5.loss_mask: 0.3294  decode.d5.loss_dice: 0.2860  decode.d6.loss_cls: 0.3442  decode.d6.loss_mask: 0.3199  decode.d6.loss_dice: 0.2719  decode.d7.loss_cls: 0.3090  decode.d7.loss_mask: 0.3573  decode.d7.loss_dice: 0.3014  decode.d8.loss_cls: 0.3188  decode.d8.loss_mask: 0.3419  decode.d8.loss_dice: 0.2849
07/25 20:56:21 - mmengine - INFO - Iter(train) [13150/80000]  base_lr: 8.5078e-05 lr: 8.5078e-06  eta: 8:29:50  time: 0.4397  data_time: 0.0095  memory: 5249  grad_norm: 78.9090  loss: 9.4983  decode.loss_cls: 0.2735  decode.loss_mask: 0.2372  decode.loss_dice: 0.2812  decode.d0.loss_cls: 1.2451  decode.d0.loss_mask: 0.2423  decode.d0.loss_dice: 0.3339  decode.d1.loss_cls: 0.4661  decode.d1.loss_mask: 0.2368  decode.d1.loss_dice: 0.2972  decode.d2.loss_cls: 0.3576  decode.d2.loss_mask: 0.2358  decode.d2.loss_dice: 0.2998  decode.d3.loss_cls: 0.2725  decode.d3.loss_mask: 0.2361  decode.d3.loss_dice: 0.2844  decode.d4.loss_cls: 0.3338  decode.d4.loss_mask: 0.2298  decode.d4.loss_dice: 0.2870  decode.d5.loss_cls: 0.3169  decode.d5.loss_mask: 0.2286  decode.d5.loss_dice: 0.2763  decode.d6.loss_cls: 0.3424  decode.d6.loss_mask: 0.2318  decode.d6.loss_dice: 0.2748  decode.d7.loss_cls: 0.3220  decode.d7.loss_mask: 0.2338  decode.d7.loss_dice: 0.2905  decode.d8.loss_cls: 0.3062  decode.d8.loss_mask: 0.2320  decode.d8.loss_dice: 0.2929
07/25 20:56:44 - mmengine - INFO - Iter(train) [13200/80000]  base_lr: 8.5020e-05 lr: 8.5020e-06  eta: 8:29:27  time: 0.4572  data_time: 0.0102  memory: 5265  grad_norm: 109.4918  loss: 9.3315  decode.loss_cls: 0.2855  decode.loss_mask: 0.2551  decode.loss_dice: 0.2947  decode.d0.loss_cls: 1.1330  decode.d0.loss_mask: 0.2713  decode.d0.loss_dice: 0.3080  decode.d1.loss_cls: 0.3819  decode.d1.loss_mask: 0.2650  decode.d1.loss_dice: 0.3049  decode.d2.loss_cls: 0.3219  decode.d2.loss_mask: 0.2574  decode.d2.loss_dice: 0.3008  decode.d3.loss_cls: 0.2949  decode.d3.loss_mask: 0.2572  decode.d3.loss_dice: 0.2943  decode.d4.loss_cls: 0.2972  decode.d4.loss_mask: 0.2536  decode.d4.loss_dice: 0.3069  decode.d5.loss_cls: 0.2635  decode.d5.loss_mask: 0.2587  decode.d5.loss_dice: 0.2937  decode.d6.loss_cls: 0.2793  decode.d6.loss_mask: 0.2589  decode.d6.loss_dice: 0.3081  decode.d7.loss_cls: 0.1970  decode.d7.loss_mask: 0.2692  decode.d7.loss_dice: 0.3041  decode.d8.loss_cls: 0.2487  decode.d8.loss_mask: 0.2639  decode.d8.loss_dice: 0.3026
07/25 20:57:07 - mmengine - INFO - Iter(train) [13250/80000]  base_lr: 8.4963e-05 lr: 8.4963e-06  eta: 8:29:05  time: 0.4564  data_time: 0.0102  memory: 5248  grad_norm: 87.9171  loss: 9.1993  decode.loss_cls: 0.3091  decode.loss_mask: 0.2375  decode.loss_dice: 0.3068  decode.d0.loss_cls: 1.1887  decode.d0.loss_mask: 0.2439  decode.d0.loss_dice: 0.3365  decode.d1.loss_cls: 0.4923  decode.d1.loss_mask: 0.2360  decode.d1.loss_dice: 0.2913  decode.d2.loss_cls: 0.2778  decode.d2.loss_mask: 0.2383  decode.d2.loss_dice: 0.3099  decode.d3.loss_cls: 0.2521  decode.d3.loss_mask: 0.2325  decode.d3.loss_dice: 0.3068  decode.d4.loss_cls: 0.2426  decode.d4.loss_mask: 0.2304  decode.d4.loss_dice: 0.3064  decode.d5.loss_cls: 0.2591  decode.d5.loss_mask: 0.2379  decode.d5.loss_dice: 0.3123  decode.d6.loss_cls: 0.2454  decode.d6.loss_mask: 0.2352  decode.d6.loss_dice: 0.2941  decode.d7.loss_cls: 0.2445  decode.d7.loss_mask: 0.2354  decode.d7.loss_dice: 0.3039  decode.d8.loss_cls: 0.2430  decode.d8.loss_mask: 0.2363  decode.d8.loss_dice: 0.3132
07/25 20:57:30 - mmengine - INFO - Iter(train) [13300/80000]  base_lr: 8.4906e-05 lr: 8.4906e-06  eta: 8:28:42  time: 0.4589  data_time: 0.0105  memory: 5231  grad_norm: 90.3344  loss: 9.9065  decode.loss_cls: 0.2770  decode.loss_mask: 0.3056  decode.loss_dice: 0.3375  decode.d0.loss_cls: 1.1291  decode.d0.loss_mask: 0.3213  decode.d0.loss_dice: 0.3685  decode.d1.loss_cls: 0.3583  decode.d1.loss_mask: 0.3146  decode.d1.loss_dice: 0.3367  decode.d2.loss_cls: 0.2415  decode.d2.loss_mask: 0.3075  decode.d2.loss_dice: 0.3274  decode.d3.loss_cls: 0.2241  decode.d3.loss_mask: 0.3157  decode.d3.loss_dice: 0.3180  decode.d4.loss_cls: 0.2471  decode.d4.loss_mask: 0.3072  decode.d4.loss_dice: 0.3292  decode.d5.loss_cls: 0.2250  decode.d5.loss_mask: 0.3069  decode.d5.loss_dice: 0.3298  decode.d6.loss_cls: 0.2569  decode.d6.loss_mask: 0.3160  decode.d6.loss_dice: 0.3291  decode.d7.loss_cls: 0.2588  decode.d7.loss_mask: 0.3118  decode.d7.loss_dice: 0.3298  decode.d8.loss_cls: 0.2491  decode.d8.loss_mask: 0.3091  decode.d8.loss_dice: 0.3179
07/25 20:57:53 - mmengine - INFO - Iter(train) [13350/80000]  base_lr: 8.4848e-05 lr: 8.4848e-06  eta: 8:28:19  time: 0.4582  data_time: 0.0103  memory: 5265  grad_norm: 61.0686  loss: 7.9627  decode.loss_cls: 0.1500  decode.loss_mask: 0.2434  decode.loss_dice: 0.2422  decode.d0.loss_cls: 1.2532  decode.d0.loss_mask: 0.2533  decode.d0.loss_dice: 0.2823  decode.d1.loss_cls: 0.2809  decode.d1.loss_mask: 0.2484  decode.d1.loss_dice: 0.2605  decode.d2.loss_cls: 0.2268  decode.d2.loss_mask: 0.2511  decode.d2.loss_dice: 0.2540  decode.d3.loss_cls: 0.1958  decode.d3.loss_mask: 0.2440  decode.d3.loss_dice: 0.2413  decode.d4.loss_cls: 0.1908  decode.d4.loss_mask: 0.2490  decode.d4.loss_dice: 0.2560  decode.d5.loss_cls: 0.1844  decode.d5.loss_mask: 0.2445  decode.d5.loss_dice: 0.2516  decode.d6.loss_cls: 0.1577  decode.d6.loss_mask: 0.2424  decode.d6.loss_dice: 0.2469  decode.d7.loss_cls: 0.1611  decode.d7.loss_mask: 0.2429  decode.d7.loss_dice: 0.2467  decode.d8.loss_cls: 0.1731  decode.d8.loss_mask: 0.2445  decode.d8.loss_dice: 0.2436
07/25 20:58:16 - mmengine - INFO - Iter(train) [13400/80000]  base_lr: 8.4791e-05 lr: 8.4791e-06  eta: 8:27:57  time: 0.4607  data_time: 0.0104  memory: 5249  grad_norm: 98.9530  loss: 9.5123  decode.loss_cls: 0.3396  decode.loss_mask: 0.2450  decode.loss_dice: 0.2892  decode.d0.loss_cls: 1.1180  decode.d0.loss_mask: 0.2434  decode.d0.loss_dice: 0.3239  decode.d1.loss_cls: 0.4060  decode.d1.loss_mask: 0.2335  decode.d1.loss_dice: 0.2776  decode.d2.loss_cls: 0.3462  decode.d2.loss_mask: 0.2366  decode.d2.loss_dice: 0.2856  decode.d3.loss_cls: 0.3095  decode.d3.loss_mask: 0.2332  decode.d3.loss_dice: 0.2944  decode.d4.loss_cls: 0.4363  decode.d4.loss_mask: 0.2320  decode.d4.loss_dice: 0.2855  decode.d5.loss_cls: 0.3424  decode.d5.loss_mask: 0.2376  decode.d5.loss_dice: 0.2880  decode.d6.loss_cls: 0.3424  decode.d6.loss_mask: 0.2364  decode.d6.loss_dice: 0.2984  decode.d7.loss_cls: 0.3057  decode.d7.loss_mask: 0.2366  decode.d7.loss_dice: 0.2903  decode.d8.loss_cls: 0.2862  decode.d8.loss_mask: 0.2337  decode.d8.loss_dice: 0.2791
07/25 20:58:38 - mmengine - INFO - Iter(train) [13450/80000]  base_lr: 8.4734e-05 lr: 8.4734e-06  eta: 8:27:33  time: 0.4561  data_time: 0.0102  memory: 5229  grad_norm: 116.6040  loss: 8.9873  decode.loss_cls: 0.2340  decode.loss_mask: 0.2646  decode.loss_dice: 0.2707  decode.d0.loss_cls: 1.2051  decode.d0.loss_mask: 0.2928  decode.d0.loss_dice: 0.2801  decode.d1.loss_cls: 0.2331  decode.d1.loss_mask: 0.2757  decode.d1.loss_dice: 0.2946  decode.d2.loss_cls: 0.2357  decode.d2.loss_mask: 0.2753  decode.d2.loss_dice: 0.2929  decode.d3.loss_cls: 0.2444  decode.d3.loss_mask: 0.2814  decode.d3.loss_dice: 0.2937  decode.d4.loss_cls: 0.2490  decode.d4.loss_mask: 0.2790  decode.d4.loss_dice: 0.2965  decode.d5.loss_cls: 0.2580  decode.d5.loss_mask: 0.2666  decode.d5.loss_dice: 0.2782  decode.d6.loss_cls: 0.2593  decode.d6.loss_mask: 0.2648  decode.d6.loss_dice: 0.2756  decode.d7.loss_cls: 0.2635  decode.d7.loss_mask: 0.2597  decode.d7.loss_dice: 0.2778  decode.d8.loss_cls: 0.2326  decode.d8.loss_mask: 0.2630  decode.d8.loss_dice: 0.2895
07/25 20:59:01 - mmengine - INFO - Iter(train) [13500/80000]  base_lr: 8.4677e-05 lr: 8.4677e-06  eta: 8:27:10  time: 0.4532  data_time: 0.0099  memory: 5249  grad_norm: 79.8962  loss: 7.8117  decode.loss_cls: 0.1933  decode.loss_mask: 0.2418  decode.loss_dice: 0.2708  decode.d0.loss_cls: 0.9830  decode.d0.loss_mask: 0.2465  decode.d0.loss_dice: 0.2949  decode.d1.loss_cls: 0.2306  decode.d1.loss_mask: 0.2370  decode.d1.loss_dice: 0.2804  decode.d2.loss_cls: 0.1877  decode.d2.loss_mask: 0.2431  decode.d2.loss_dice: 0.2847  decode.d3.loss_cls: 0.1379  decode.d3.loss_mask: 0.2379  decode.d3.loss_dice: 0.2810  decode.d4.loss_cls: 0.1645  decode.d4.loss_mask: 0.2361  decode.d4.loss_dice: 0.2909  decode.d5.loss_cls: 0.1555  decode.d5.loss_mask: 0.2415  decode.d5.loss_dice: 0.2913  decode.d6.loss_cls: 0.1590  decode.d6.loss_mask: 0.2414  decode.d6.loss_dice: 0.2848  decode.d7.loss_cls: 0.1737  decode.d7.loss_mask: 0.2376  decode.d7.loss_dice: 0.2797  decode.d8.loss_cls: 0.1844  decode.d8.loss_mask: 0.2421  decode.d8.loss_dice: 0.2787
07/25 20:59:24 - mmengine - INFO - Iter(train) [13550/80000]  base_lr: 8.4619e-05 lr: 8.4619e-06  eta: 8:26:46  time: 0.4593  data_time: 0.0106  memory: 5249  grad_norm: 203.6184  loss: 12.1477  decode.loss_cls: 0.3536  decode.loss_mask: 0.3527  decode.loss_dice: 0.4017  decode.d0.loss_cls: 1.2049  decode.d0.loss_mask: 0.2679  decode.d0.loss_dice: 0.4158  decode.d1.loss_cls: 0.5517  decode.d1.loss_mask: 0.2808  decode.d1.loss_dice: 0.3951  decode.d2.loss_cls: 0.4847  decode.d2.loss_mask: 0.2637  decode.d2.loss_dice: 0.3594  decode.d3.loss_cls: 0.4046  decode.d3.loss_mask: 0.2824  decode.d3.loss_dice: 0.3654  decode.d4.loss_cls: 0.4049  decode.d4.loss_mask: 0.3471  decode.d4.loss_dice: 0.4187  decode.d5.loss_cls: 0.4199  decode.d5.loss_mask: 0.3790  decode.d5.loss_dice: 0.3534  decode.d6.loss_cls: 0.3794  decode.d6.loss_mask: 0.3442  decode.d6.loss_dice: 0.3949  decode.d7.loss_cls: 0.4002  decode.d7.loss_mask: 0.3753  decode.d7.loss_dice: 0.3853  decode.d8.loss_cls: 0.3693  decode.d8.loss_mask: 0.3694  decode.d8.loss_dice: 0.4226
07/25 20:59:47 - mmengine - INFO - Iter(train) [13600/80000]  base_lr: 8.4562e-05 lr: 8.4562e-06  eta: 8:26:25  time: 0.4602  data_time: 0.0103  memory: 5265  grad_norm: 122.9017  loss: 8.9296  decode.loss_cls: 0.2249  decode.loss_mask: 0.2321  decode.loss_dice: 0.2998  decode.d0.loss_cls: 1.1069  decode.d0.loss_mask: 0.2319  decode.d0.loss_dice: 0.3236  decode.d1.loss_cls: 0.3691  decode.d1.loss_mask: 0.2241  decode.d1.loss_dice: 0.3320  decode.d2.loss_cls: 0.3282  decode.d2.loss_mask: 0.2240  decode.d2.loss_dice: 0.3186  decode.d3.loss_cls: 0.2776  decode.d3.loss_mask: 0.2290  decode.d3.loss_dice: 0.3164  decode.d4.loss_cls: 0.2549  decode.d4.loss_mask: 0.2226  decode.d4.loss_dice: 0.3167  decode.d5.loss_cls: 0.2153  decode.d5.loss_mask: 0.2244  decode.d5.loss_dice: 0.3112  decode.d6.loss_cls: 0.2621  decode.d6.loss_mask: 0.2304  decode.d6.loss_dice: 0.3041  decode.d7.loss_cls: 0.2328  decode.d7.loss_mask: 0.2289  decode.d7.loss_dice: 0.3117  decode.d8.loss_cls: 0.2192  decode.d8.loss_mask: 0.2345  decode.d8.loss_dice: 0.3227
07/25 21:00:10 - mmengine - INFO - Iter(train) [13650/80000]  base_lr: 8.4505e-05 lr: 8.4505e-06  eta: 8:26:03  time: 0.4596  data_time: 0.0104  memory: 5249  grad_norm: 104.2106  loss: 10.0409  decode.loss_cls: 0.3349  decode.loss_mask: 0.2586  decode.loss_dice: 0.2763  decode.d0.loss_cls: 1.2111  decode.d0.loss_mask: 0.2663  decode.d0.loss_dice: 0.3199  decode.d1.loss_cls: 0.5545  decode.d1.loss_mask: 0.2635  decode.d1.loss_dice: 0.2787  decode.d2.loss_cls: 0.4062  decode.d2.loss_mask: 0.2695  decode.d2.loss_dice: 0.2614  decode.d3.loss_cls: 0.3295  decode.d3.loss_mask: 0.2621  decode.d3.loss_dice: 0.2949  decode.d4.loss_cls: 0.3344  decode.d4.loss_mask: 0.2575  decode.d4.loss_dice: 0.2927  decode.d5.loss_cls: 0.3456  decode.d5.loss_mask: 0.2692  decode.d5.loss_dice: 0.2885  decode.d6.loss_cls: 0.3342  decode.d6.loss_mask: 0.2601  decode.d6.loss_dice: 0.2991  decode.d7.loss_cls: 0.3219  decode.d7.loss_mask: 0.2526  decode.d7.loss_dice: 0.2906  decode.d8.loss_cls: 0.3290  decode.d8.loss_mask: 0.2726  decode.d8.loss_dice: 0.3056
07/25 21:00:33 - mmengine - INFO - Iter(train) [13700/80000]  base_lr: 8.4447e-05 lr: 8.4447e-06  eta: 8:25:40  time: 0.4575  data_time: 0.0105  memory: 5230  grad_norm: 111.1966  loss: 10.2231  decode.loss_cls: 0.3272  decode.loss_mask: 0.2692  decode.loss_dice: 0.3423  decode.d0.loss_cls: 1.2612  decode.d0.loss_mask: 0.2300  decode.d0.loss_dice: 0.3441  decode.d1.loss_cls: 0.4881  decode.d1.loss_mask: 0.2192  decode.d1.loss_dice: 0.3173  decode.d2.loss_cls: 0.3159  decode.d2.loss_mask: 0.2195  decode.d2.loss_dice: 0.3120  decode.d3.loss_cls: 0.3128  decode.d3.loss_mask: 0.2205  decode.d3.loss_dice: 0.3252  decode.d4.loss_cls: 0.3691  decode.d4.loss_mask: 0.2262  decode.d4.loss_dice: 0.3255  decode.d5.loss_cls: 0.3669  decode.d5.loss_mask: 0.2521  decode.d5.loss_dice: 0.3392  decode.d6.loss_cls: 0.3100  decode.d6.loss_mask: 0.2955  decode.d6.loss_dice: 0.3478  decode.d7.loss_cls: 0.3095  decode.d7.loss_mask: 0.3112  decode.d7.loss_dice: 0.3442  decode.d8.loss_cls: 0.2945  decode.d8.loss_mask: 0.2733  decode.d8.loss_dice: 0.3535
07/25 21:00:56 - mmengine - INFO - Iter(train) [13750/80000]  base_lr: 8.4390e-05 lr: 8.4390e-06  eta: 8:25:17  time: 0.4591  data_time: 0.0105  memory: 5249  grad_norm: 152.8026  loss: 10.9869  decode.loss_cls: 0.4410  decode.loss_mask: 0.2742  decode.loss_dice: 0.3043  decode.d0.loss_cls: 1.3212  decode.d0.loss_mask: 0.2873  decode.d0.loss_dice: 0.3475  decode.d1.loss_cls: 0.4469  decode.d1.loss_mask: 0.2835  decode.d1.loss_dice: 0.3277  decode.d2.loss_cls: 0.3224  decode.d2.loss_mask: 0.2771  decode.d2.loss_dice: 0.3209  decode.d3.loss_cls: 0.3742  decode.d3.loss_mask: 0.2768  decode.d3.loss_dice: 0.3238  decode.d4.loss_cls: 0.4175  decode.d4.loss_mask: 0.2765  decode.d4.loss_dice: 0.3269  decode.d5.loss_cls: 0.3736  decode.d5.loss_mask: 0.2753  decode.d5.loss_dice: 0.3289  decode.d6.loss_cls: 0.4444  decode.d6.loss_mask: 0.2823  decode.d6.loss_dice: 0.3254  decode.d7.loss_cls: 0.3230  decode.d7.loss_mask: 0.2766  decode.d7.loss_dice: 0.3566  decode.d8.loss_cls: 0.4041  decode.d8.loss_mask: 0.2785  decode.d8.loss_dice: 0.3686
07/25 21:01:19 - mmengine - INFO - Iter(train) [13800/80000]  base_lr: 8.4333e-05 lr: 8.4333e-06  eta: 8:24:54  time: 0.4521  data_time: 0.0100  memory: 5249  grad_norm: 111.8253  loss: 10.6255  decode.loss_cls: 0.3684  decode.loss_mask: 0.2777  decode.loss_dice: 0.3290  decode.d0.loss_cls: 1.2562  decode.d0.loss_mask: 0.2907  decode.d0.loss_dice: 0.3405  decode.d1.loss_cls: 0.4627  decode.d1.loss_mask: 0.2829  decode.d1.loss_dice: 0.3167  decode.d2.loss_cls: 0.3410  decode.d2.loss_mask: 0.2801  decode.d2.loss_dice: 0.3365  decode.d3.loss_cls: 0.3365  decode.d3.loss_mask: 0.2760  decode.d3.loss_dice: 0.3023  decode.d4.loss_cls: 0.3729  decode.d4.loss_mask: 0.2789  decode.d4.loss_dice: 0.3202  decode.d5.loss_cls: 0.3857  decode.d5.loss_mask: 0.2791  decode.d5.loss_dice: 0.3402  decode.d6.loss_cls: 0.3700  decode.d6.loss_mask: 0.2764  decode.d6.loss_dice: 0.3083  decode.d7.loss_cls: 0.3619  decode.d7.loss_mask: 0.2784  decode.d7.loss_dice: 0.3101  decode.d8.loss_cls: 0.3653  decode.d8.loss_mask: 0.2750  decode.d8.loss_dice: 0.3061
07/25 21:01:41 - mmengine - INFO - Iter(train) [13850/80000]  base_lr: 8.4275e-05 lr: 8.4275e-06  eta: 8:24:31  time: 0.4597  data_time: 0.0105  memory: 5231  grad_norm: 90.7496  loss: 9.5699  decode.loss_cls: 0.2502  decode.loss_mask: 0.2997  decode.loss_dice: 0.3082  decode.d0.loss_cls: 1.1066  decode.d0.loss_mask: 0.2843  decode.d0.loss_dice: 0.3426  decode.d1.loss_cls: 0.2914  decode.d1.loss_mask: 0.2929  decode.d1.loss_dice: 0.3153  decode.d2.loss_cls: 0.2413  decode.d2.loss_mask: 0.3015  decode.d2.loss_dice: 0.3068  decode.d3.loss_cls: 0.2452  decode.d3.loss_mask: 0.3059  decode.d3.loss_dice: 0.3081  decode.d4.loss_cls: 0.2198  decode.d4.loss_mask: 0.3127  decode.d4.loss_dice: 0.3010  decode.d5.loss_cls: 0.2430  decode.d5.loss_mask: 0.2929  decode.d5.loss_dice: 0.2897  decode.d6.loss_cls: 0.2866  decode.d6.loss_mask: 0.2987  decode.d6.loss_dice: 0.2992  decode.d7.loss_cls: 0.2883  decode.d7.loss_mask: 0.2979  decode.d7.loss_dice: 0.3053  decode.d8.loss_cls: 0.3140  decode.d8.loss_mask: 0.3069  decode.d8.loss_dice: 0.3139
07/25 21:02:04 - mmengine - INFO - Iter(train) [13900/80000]  base_lr: 8.4218e-05 lr: 8.4218e-06  eta: 8:24:07  time: 0.4553  data_time: 0.0102  memory: 5231  grad_norm: 131.7149  loss: 10.2328  decode.loss_cls: 0.1420  decode.loss_mask: 0.3181  decode.loss_dice: 0.3722  decode.d0.loss_cls: 1.0539  decode.d0.loss_mask: 0.3606  decode.d0.loss_dice: 0.4132  decode.d1.loss_cls: 0.3526  decode.d1.loss_mask: 0.3239  decode.d1.loss_dice: 0.3576  decode.d2.loss_cls: 0.3676  decode.d2.loss_mask: 0.3258  decode.d2.loss_dice: 0.3823  decode.d3.loss_cls: 0.2590  decode.d3.loss_mask: 0.3235  decode.d3.loss_dice: 0.3850  decode.d4.loss_cls: 0.2135  decode.d4.loss_mask: 0.3240  decode.d4.loss_dice: 0.3761  decode.d5.loss_cls: 0.2029  decode.d5.loss_mask: 0.3367  decode.d5.loss_dice: 0.3926  decode.d6.loss_cls: 0.2076  decode.d6.loss_mask: 0.3099  decode.d6.loss_dice: 0.3978  decode.d7.loss_cls: 0.1663  decode.d7.loss_mask: 0.3095  decode.d7.loss_dice: 0.3773  decode.d8.loss_cls: 0.1930  decode.d8.loss_mask: 0.3145  decode.d8.loss_dice: 0.3738
07/25 21:02:27 - mmengine - INFO - Iter(train) [13950/80000]  base_lr: 8.4161e-05 lr: 8.4161e-06  eta: 8:23:44  time: 0.4600  data_time: 0.0102  memory: 5248  grad_norm: 106.9643  loss: 9.0297  decode.loss_cls: 0.2180  decode.loss_mask: 0.2765  decode.loss_dice: 0.3047  decode.d0.loss_cls: 1.1604  decode.d0.loss_mask: 0.2919  decode.d0.loss_dice: 0.3426  decode.d1.loss_cls: 0.3574  decode.d1.loss_mask: 0.2776  decode.d1.loss_dice: 0.2961  decode.d2.loss_cls: 0.2161  decode.d2.loss_mask: 0.2813  decode.d2.loss_dice: 0.2863  decode.d3.loss_cls: 0.2373  decode.d3.loss_mask: 0.2809  decode.d3.loss_dice: 0.2828  decode.d4.loss_cls: 0.2185  decode.d4.loss_mask: 0.2799  decode.d4.loss_dice: 0.2885  decode.d5.loss_cls: 0.2140  decode.d5.loss_mask: 0.2833  decode.d5.loss_dice: 0.3141  decode.d6.loss_cls: 0.1772  decode.d6.loss_mask: 0.2743  decode.d6.loss_dice: 0.2994  decode.d7.loss_cls: 0.1724  decode.d7.loss_mask: 0.2740  decode.d7.loss_dice: 0.3125  decode.d8.loss_cls: 0.2548  decode.d8.loss_mask: 0.2716  decode.d8.loss_dice: 0.2851
07/25 21:02:50 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250725_191538
07/25 21:02:50 - mmengine - INFO - Iter(train) [14000/80000]  base_lr: 8.4103e-05 lr: 8.4103e-06  eta: 8:23:22  time: 0.4530  data_time: 0.0103  memory: 5231  grad_norm: 118.5612  loss: 15.1614  decode.loss_cls: 0.6918  decode.loss_mask: 0.3334  decode.loss_dice: 0.4160  decode.d0.loss_cls: 1.3986  decode.d0.loss_mask: 0.3665  decode.d0.loss_dice: 0.4436  decode.d1.loss_cls: 0.7698  decode.d1.loss_mask: 0.3570  decode.d1.loss_dice: 0.4227  decode.d2.loss_cls: 0.7828  decode.d2.loss_mask: 0.3469  decode.d2.loss_dice: 0.4465  decode.d3.loss_cls: 0.6885  decode.d3.loss_mask: 0.3388  decode.d3.loss_dice: 0.3996  decode.d4.loss_cls: 0.5935  decode.d4.loss_mask: 0.3410  decode.d4.loss_dice: 0.4207  decode.d5.loss_cls: 0.6391  decode.d5.loss_mask: 0.3414  decode.d5.loss_dice: 0.4134  decode.d6.loss_cls: 0.6460  decode.d6.loss_mask: 0.3338  decode.d6.loss_dice: 0.3944  decode.d7.loss_cls: 0.6273  decode.d7.loss_mask: 0.3465  decode.d7.loss_dice: 0.4117  decode.d8.loss_cls: 0.7061  decode.d8.loss_mask: 0.3405  decode.d8.loss_dice: 0.4037
07/25 21:03:13 - mmengine - INFO - Iter(train) [14050/80000]  base_lr: 8.4046e-05 lr: 8.4046e-06  eta: 8:22:59  time: 0.4564  data_time: 0.0102  memory: 5265  grad_norm: 113.3635  loss: 10.3467  decode.loss_cls: 0.2285  decode.loss_mask: 0.3446  decode.loss_dice: 0.3507  decode.d0.loss_cls: 1.1362  decode.d0.loss_mask: 0.3108  decode.d0.loss_dice: 0.3782  decode.d1.loss_cls: 0.3940  decode.d1.loss_mask: 0.3071  decode.d1.loss_dice: 0.3349  decode.d2.loss_cls: 0.2914  decode.d2.loss_mask: 0.3432  decode.d2.loss_dice: 0.3204  decode.d3.loss_cls: 0.2303  decode.d3.loss_mask: 0.3011  decode.d3.loss_dice: 0.3194  decode.d4.loss_cls: 0.3029  decode.d4.loss_mask: 0.3073  decode.d4.loss_dice: 0.3269  decode.d5.loss_cls: 0.3127  decode.d5.loss_mask: 0.3282  decode.d5.loss_dice: 0.3314  decode.d6.loss_cls: 0.3082  decode.d6.loss_mask: 0.3035  decode.d6.loss_dice: 0.3356  decode.d7.loss_cls: 0.2634  decode.d7.loss_mask: 0.3300  decode.d7.loss_dice: 0.3376  decode.d8.loss_cls: 0.2745  decode.d8.loss_mask: 0.3472  decode.d8.loss_dice: 0.3464
07/25 21:03:36 - mmengine - INFO - Iter(train) [14100/80000]  base_lr: 8.3989e-05 lr: 8.3989e-06  eta: 8:22:36  time: 0.4588  data_time: 0.0104  memory: 5265  grad_norm: 101.8042  loss: 8.3543  decode.loss_cls: 0.2855  decode.loss_mask: 0.2303  decode.loss_dice: 0.2641  decode.d0.loss_cls: 1.1058  decode.d0.loss_mask: 0.2463  decode.d0.loss_dice: 0.2892  decode.d1.loss_cls: 0.2919  decode.d1.loss_mask: 0.2356  decode.d1.loss_dice: 0.2537  decode.d2.loss_cls: 0.2382  decode.d2.loss_mask: 0.2394  decode.d2.loss_dice: 0.2722  decode.d3.loss_cls: 0.2239  decode.d3.loss_mask: 0.2353  decode.d3.loss_dice: 0.2749  decode.d4.loss_cls: 0.2037  decode.d4.loss_mask: 0.2296  decode.d4.loss_dice: 0.2567  decode.d5.loss_cls: 0.2279  decode.d5.loss_mask: 0.2325  decode.d5.loss_dice: 0.2732  decode.d6.loss_cls: 0.2460  decode.d6.loss_mask: 0.2291  decode.d6.loss_dice: 0.2743  decode.d7.loss_cls: 0.2056  decode.d7.loss_mask: 0.2343  decode.d7.loss_dice: 0.2754  decode.d8.loss_cls: 0.2731  decode.d8.loss_mask: 0.2337  decode.d8.loss_dice: 0.2730
07/25 21:03:59 - mmengine - INFO - Iter(train) [14150/80000]  base_lr: 8.3931e-05 lr: 8.3931e-06  eta: 8:22:13  time: 0.4461  data_time: 0.0099  memory: 5249  grad_norm: 96.9551  loss: 9.6783  decode.loss_cls: 0.2771  decode.loss_mask: 0.2515  decode.loss_dice: 0.3418  decode.d0.loss_cls: 1.0683  decode.d0.loss_mask: 0.2593  decode.d0.loss_dice: 0.3791  decode.d1.loss_cls: 0.4422  decode.d1.loss_mask: 0.2468  decode.d1.loss_dice: 0.3116  decode.d2.loss_cls: 0.3396  decode.d2.loss_mask: 0.2456  decode.d2.loss_dice: 0.2894  decode.d3.loss_cls: 0.3392  decode.d3.loss_mask: 0.2427  decode.d3.loss_dice: 0.2906  decode.d4.loss_cls: 0.2997  decode.d4.loss_mask: 0.2386  decode.d4.loss_dice: 0.3186  decode.d5.loss_cls: 0.3049  decode.d5.loss_mask: 0.2398  decode.d5.loss_dice: 0.3057  decode.d6.loss_cls: 0.3078  decode.d6.loss_mask: 0.2396  decode.d6.loss_dice: 0.3150  decode.d7.loss_cls: 0.3522  decode.d7.loss_mask: 0.2481  decode.d7.loss_dice: 0.3046  decode.d8.loss_cls: 0.3099  decode.d8.loss_mask: 0.2496  decode.d8.loss_dice: 0.3194
07/25 21:04:21 - mmengine - INFO - Iter(train) [14200/80000]  base_lr: 8.3874e-05 lr: 8.3874e-06  eta: 8:21:49  time: 0.4542  data_time: 0.0102  memory: 5265  grad_norm: 98.8577  loss: 10.1266  decode.loss_cls: 0.2991  decode.loss_mask: 0.2758  decode.loss_dice: 0.3403  decode.d0.loss_cls: 1.0418  decode.d0.loss_mask: 0.2947  decode.d0.loss_dice: 0.3495  decode.d1.loss_cls: 0.3815  decode.d1.loss_mask: 0.2833  decode.d1.loss_dice: 0.3405  decode.d2.loss_cls: 0.3593  decode.d2.loss_mask: 0.2771  decode.d2.loss_dice: 0.3061  decode.d3.loss_cls: 0.3584  decode.d3.loss_mask: 0.2739  decode.d3.loss_dice: 0.3216  decode.d4.loss_cls: 0.4317  decode.d4.loss_mask: 0.2750  decode.d4.loss_dice: 0.3282  decode.d5.loss_cls: 0.3378  decode.d5.loss_mask: 0.2789  decode.d5.loss_dice: 0.3344  decode.d6.loss_cls: 0.2968  decode.d6.loss_mask: 0.2730  decode.d6.loss_dice: 0.3387  decode.d7.loss_cls: 0.2564  decode.d7.loss_mask: 0.2732  decode.d7.loss_dice: 0.3406  decode.d8.loss_cls: 0.2591  decode.d8.loss_mask: 0.2754  decode.d8.loss_dice: 0.3244
07/25 21:04:44 - mmengine - INFO - Iter(train) [14250/80000]  base_lr: 8.3817e-05 lr: 8.3817e-06  eta: 8:21:26  time: 0.4598  data_time: 0.0109  memory: 5265  grad_norm: 56.4269  loss: 8.9954  decode.loss_cls: 0.1405  decode.loss_mask: 0.3120  decode.loss_dice: 0.3292  decode.d0.loss_cls: 1.0636  decode.d0.loss_mask: 0.3413  decode.d0.loss_dice: 0.3467  decode.d1.loss_cls: 0.2856  decode.d1.loss_mask: 0.3141  decode.d1.loss_dice: 0.3236  decode.d2.loss_cls: 0.1520  decode.d2.loss_mask: 0.3138  decode.d2.loss_dice: 0.3260  decode.d3.loss_cls: 0.1576  decode.d3.loss_mask: 0.3150  decode.d3.loss_dice: 0.3141  decode.d4.loss_cls: 0.1253  decode.d4.loss_mask: 0.3186  decode.d4.loss_dice: 0.3215  decode.d5.loss_cls: 0.1483  decode.d5.loss_mask: 0.3180  decode.d5.loss_dice: 0.3336  decode.d6.loss_cls: 0.1797  decode.d6.loss_mask: 0.3125  decode.d6.loss_dice: 0.3345  decode.d7.loss_cls: 0.1418  decode.d7.loss_mask: 0.3141  decode.d7.loss_dice: 0.3467  decode.d8.loss_cls: 0.1424  decode.d8.loss_mask: 0.3122  decode.d8.loss_dice: 0.3112
07/25 21:05:07 - mmengine - INFO - Iter(train) [14300/80000]  base_lr: 8.3759e-05 lr: 8.3759e-06  eta: 8:21:02  time: 0.4575  data_time: 0.0103  memory: 5231  grad_norm: 117.9262  loss: 9.9197  decode.loss_cls: 0.3626  decode.loss_mask: 0.2160  decode.loss_dice: 0.3328  decode.d0.loss_cls: 1.1471  decode.d0.loss_mask: 0.2277  decode.d0.loss_dice: 0.3635  decode.d1.loss_cls: 0.4305  decode.d1.loss_mask: 0.2201  decode.d1.loss_dice: 0.3428  decode.d2.loss_cls: 0.4192  decode.d2.loss_mask: 0.2200  decode.d2.loss_dice: 0.3148  decode.d3.loss_cls: 0.3127  decode.d3.loss_mask: 0.2165  decode.d3.loss_dice: 0.3502  decode.d4.loss_cls: 0.2859  decode.d4.loss_mask: 0.2220  decode.d4.loss_dice: 0.3481  decode.d5.loss_cls: 0.3634  decode.d5.loss_mask: 0.2191  decode.d5.loss_dice: 0.3016  decode.d6.loss_cls: 0.3489  decode.d6.loss_mask: 0.2176  decode.d6.loss_dice: 0.3154  decode.d7.loss_cls: 0.3799  decode.d7.loss_mask: 0.2164  decode.d7.loss_dice: 0.3127  decode.d8.loss_cls: 0.3724  decode.d8.loss_mask: 0.2168  decode.d8.loss_dice: 0.3229
07/25 21:05:30 - mmengine - INFO - Iter(train) [14350/80000]  base_lr: 8.3702e-05 lr: 8.3702e-06  eta: 8:20:40  time: 0.4577  data_time: 0.0103  memory: 5231  grad_norm: 122.5752  loss: 8.5817  decode.loss_cls: 0.2222  decode.loss_mask: 0.2448  decode.loss_dice: 0.2823  decode.d0.loss_cls: 1.1387  decode.d0.loss_mask: 0.2467  decode.d0.loss_dice: 0.2993  decode.d1.loss_cls: 0.3563  decode.d1.loss_mask: 0.2432  decode.d1.loss_dice: 0.3035  decode.d2.loss_cls: 0.2597  decode.d2.loss_mask: 0.2373  decode.d2.loss_dice: 0.2846  decode.d3.loss_cls: 0.2335  decode.d3.loss_mask: 0.2412  decode.d3.loss_dice: 0.2771  decode.d4.loss_cls: 0.2448  decode.d4.loss_mask: 0.2437  decode.d4.loss_dice: 0.2851  decode.d5.loss_cls: 0.2432  decode.d5.loss_mask: 0.2423  decode.d5.loss_dice: 0.2798  decode.d6.loss_cls: 0.1877  decode.d6.loss_mask: 0.2426  decode.d6.loss_dice: 0.2790  decode.d7.loss_cls: 0.2014  decode.d7.loss_mask: 0.2415  decode.d7.loss_dice: 0.2784  decode.d8.loss_cls: 0.2002  decode.d8.loss_mask: 0.2491  decode.d8.loss_dice: 0.2925
07/25 21:05:53 - mmengine - INFO - Iter(train) [14400/80000]  base_lr: 8.3644e-05 lr: 8.3644e-06  eta: 8:20:18  time: 0.4606  data_time: 0.0106  memory: 5249  grad_norm: 84.3461  loss: 9.4485  decode.loss_cls: 0.2576  decode.loss_mask: 0.2616  decode.loss_dice: 0.2825  decode.d0.loss_cls: 1.2544  decode.d0.loss_mask: 0.2587  decode.d0.loss_dice: 0.3171  decode.d1.loss_cls: 0.2931  decode.d1.loss_mask: 0.2956  decode.d1.loss_dice: 0.2915  decode.d2.loss_cls: 0.3075  decode.d2.loss_mask: 0.2901  decode.d2.loss_dice: 0.2921  decode.d3.loss_cls: 0.2971  decode.d3.loss_mask: 0.2680  decode.d3.loss_dice: 0.2833  decode.d4.loss_cls: 0.3070  decode.d4.loss_mask: 0.2682  decode.d4.loss_dice: 0.2807  decode.d5.loss_cls: 0.3063  decode.d5.loss_mask: 0.2669  decode.d5.loss_dice: 0.2788  decode.d6.loss_cls: 0.2916  decode.d6.loss_mask: 0.2678  decode.d6.loss_dice: 0.2768  decode.d7.loss_cls: 0.2769  decode.d7.loss_mask: 0.2656  decode.d7.loss_dice: 0.2824  decode.d8.loss_cls: 0.2901  decode.d8.loss_mask: 0.2618  decode.d8.loss_dice: 0.2773
07/25 21:06:16 - mmengine - INFO - Iter(train) [14450/80000]  base_lr: 8.3587e-05 lr: 8.3587e-06  eta: 8:19:56  time: 0.4604  data_time: 0.0106  memory: 5249  grad_norm: 135.4185  loss: 12.2370  decode.loss_cls: 0.3945  decode.loss_mask: 0.3051  decode.loss_dice: 0.3741  decode.d0.loss_cls: 1.3413  decode.d0.loss_mask: 0.3512  decode.d0.loss_dice: 0.4532  decode.d1.loss_cls: 0.5459  decode.d1.loss_mask: 0.3049  decode.d1.loss_dice: 0.3865  decode.d2.loss_cls: 0.4341  decode.d2.loss_mask: 0.3119  decode.d2.loss_dice: 0.4107  decode.d3.loss_cls: 0.3899  decode.d3.loss_mask: 0.3027  decode.d3.loss_dice: 0.3793  decode.d4.loss_cls: 0.4135  decode.d4.loss_mask: 0.3095  decode.d4.loss_dice: 0.4047  decode.d5.loss_cls: 0.4238  decode.d5.loss_mask: 0.3108  decode.d5.loss_dice: 0.4109  decode.d6.loss_cls: 0.3885  decode.d6.loss_mask: 0.3034  decode.d6.loss_dice: 0.3946  decode.d7.loss_cls: 0.3943  decode.d7.loss_mask: 0.3021  decode.d7.loss_dice: 0.4024  decode.d8.loss_cls: 0.3932  decode.d8.loss_mask: 0.3035  decode.d8.loss_dice: 0.3961
07/25 21:06:39 - mmengine - INFO - Iter(train) [14500/80000]  base_lr: 8.3530e-05 lr: 8.3530e-06  eta: 8:19:33  time: 0.4592  data_time: 0.0104  memory: 5266  grad_norm: 113.1998  loss: 12.9908  decode.loss_cls: 0.5767  decode.loss_mask: 0.2346  decode.loss_dice: 0.4121  decode.d0.loss_cls: 1.3993  decode.d0.loss_mask: 0.2400  decode.d0.loss_dice: 0.4174  decode.d1.loss_cls: 0.7793  decode.d1.loss_mask: 0.2263  decode.d1.loss_dice: 0.3747  decode.d2.loss_cls: 0.5392  decode.d2.loss_mask: 0.2347  decode.d2.loss_dice: 0.3858  decode.d3.loss_cls: 0.5389  decode.d3.loss_mask: 0.2248  decode.d3.loss_dice: 0.3524  decode.d4.loss_cls: 0.5632  decode.d4.loss_mask: 0.2184  decode.d4.loss_dice: 0.3710  decode.d5.loss_cls: 0.5786  decode.d5.loss_mask: 0.2376  decode.d5.loss_dice: 0.3715  decode.d6.loss_cls: 0.6723  decode.d6.loss_mask: 0.2196  decode.d6.loss_dice: 0.3875  decode.d7.loss_cls: 0.5662  decode.d7.loss_mask: 0.2424  decode.d7.loss_dice: 0.3921  decode.d8.loss_cls: 0.6081  decode.d8.loss_mask: 0.2335  decode.d8.loss_dice: 0.3925
07/25 21:07:02 - mmengine - INFO - Iter(train) [14550/80000]  base_lr: 8.3472e-05 lr: 8.3472e-06  eta: 8:19:09  time: 0.4616  data_time: 0.0105  memory: 5249  grad_norm: 76.3793  loss: 7.5324  decode.loss_cls: 0.1567  decode.loss_mask: 0.2076  decode.loss_dice: 0.2950  decode.d0.loss_cls: 1.0525  decode.d0.loss_mask: 0.2120  decode.d0.loss_dice: 0.2993  decode.d1.loss_cls: 0.2503  decode.d1.loss_mask: 0.2084  decode.d1.loss_dice: 0.2765  decode.d2.loss_cls: 0.2036  decode.d2.loss_mask: 0.2037  decode.d2.loss_dice: 0.2839  decode.d3.loss_cls: 0.1620  decode.d3.loss_mask: 0.2039  decode.d3.loss_dice: 0.2660  decode.d4.loss_cls: 0.1576  decode.d4.loss_mask: 0.2016  decode.d4.loss_dice: 0.2719  decode.d5.loss_cls: 0.1513  decode.d5.loss_mask: 0.2073  decode.d5.loss_dice: 0.2760  decode.d6.loss_cls: 0.1661  decode.d6.loss_mask: 0.2061  decode.d6.loss_dice: 0.2890  decode.d7.loss_cls: 0.1650  decode.d7.loss_mask: 0.2046  decode.d7.loss_dice: 0.2812  decode.d8.loss_cls: 0.1848  decode.d8.loss_mask: 0.2048  decode.d8.loss_dice: 0.2839
07/25 21:07:24 - mmengine - INFO - Iter(train) [14600/80000]  base_lr: 8.3415e-05 lr: 8.3415e-06  eta: 8:18:46  time: 0.4611  data_time: 0.0106  memory: 5231  grad_norm: 121.3202  loss: 10.1274  decode.loss_cls: 0.2521  decode.loss_mask: 0.2742  decode.loss_dice: 0.3267  decode.d0.loss_cls: 1.0634  decode.d0.loss_mask: 0.2787  decode.d0.loss_dice: 0.4160  decode.d1.loss_cls: 0.4212  decode.d1.loss_mask: 0.2739  decode.d1.loss_dice: 0.3398  decode.d2.loss_cls: 0.3094  decode.d2.loss_mask: 0.2775  decode.d2.loss_dice: 0.3409  decode.d3.loss_cls: 0.2524  decode.d3.loss_mask: 0.2785  decode.d3.loss_dice: 0.3354  decode.d4.loss_cls: 0.3265  decode.d4.loss_mask: 0.2743  decode.d4.loss_dice: 0.3396  decode.d5.loss_cls: 0.3441  decode.d5.loss_mask: 0.2800  decode.d5.loss_dice: 0.3282  decode.d6.loss_cls: 0.3348  decode.d6.loss_mask: 0.2769  decode.d6.loss_dice: 0.3280  decode.d7.loss_cls: 0.3216  decode.d7.loss_mask: 0.2792  decode.d7.loss_dice: 0.3220  decode.d8.loss_cls: 0.3459  decode.d8.loss_mask: 0.2820  decode.d8.loss_dice: 0.3045
07/25 21:07:47 - mmengine - INFO - Iter(train) [14650/80000]  base_lr: 8.3358e-05 lr: 8.3358e-06  eta: 8:18:23  time: 0.4570  data_time: 0.0103  memory: 5231  grad_norm: 66.2911  loss: 6.9890  decode.loss_cls: 0.1827  decode.loss_mask: 0.2131  decode.loss_dice: 0.2175  decode.d0.loss_cls: 0.9326  decode.d0.loss_mask: 0.2247  decode.d0.loss_dice: 0.2408  decode.d1.loss_cls: 0.1927  decode.d1.loss_mask: 0.2232  decode.d1.loss_dice: 0.2287  decode.d2.loss_cls: 0.1356  decode.d2.loss_mask: 0.2208  decode.d2.loss_dice: 0.2350  decode.d3.loss_cls: 0.2109  decode.d3.loss_mask: 0.2146  decode.d3.loss_dice: 0.2234  decode.d4.loss_cls: 0.1912  decode.d4.loss_mask: 0.2130  decode.d4.loss_dice: 0.2185  decode.d5.loss_cls: 0.1658  decode.d5.loss_mask: 0.2186  decode.d5.loss_dice: 0.2194  decode.d6.loss_cls: 0.1867  decode.d6.loss_mask: 0.2152  decode.d6.loss_dice: 0.2224  decode.d7.loss_cls: 0.1677  decode.d7.loss_mask: 0.2160  decode.d7.loss_dice: 0.2182  decode.d8.loss_cls: 0.2024  decode.d8.loss_mask: 0.2118  decode.d8.loss_dice: 0.2257
07/25 21:08:10 - mmengine - INFO - Iter(train) [14700/80000]  base_lr: 8.3300e-05 lr: 8.3300e-06  eta: 8:18:00  time: 0.4534  data_time: 0.0102  memory: 5231  grad_norm: 110.1856  loss: 9.2412  decode.loss_cls: 0.2575  decode.loss_mask: 0.2806  decode.loss_dice: 0.2749  decode.d0.loss_cls: 1.1201  decode.d0.loss_mask: 0.2979  decode.d0.loss_dice: 0.3142  decode.d1.loss_cls: 0.3266  decode.d1.loss_mask: 0.2715  decode.d1.loss_dice: 0.2981  decode.d2.loss_cls: 0.2853  decode.d2.loss_mask: 0.2655  decode.d2.loss_dice: 0.2849  decode.d3.loss_cls: 0.2405  decode.d3.loss_mask: 0.2800  decode.d3.loss_dice: 0.2773  decode.d4.loss_cls: 0.2333  decode.d4.loss_mask: 0.2819  decode.d4.loss_dice: 0.2719  decode.d5.loss_cls: 0.2763  decode.d5.loss_mask: 0.2792  decode.d5.loss_dice: 0.2770  decode.d6.loss_cls: 0.2913  decode.d6.loss_mask: 0.2783  decode.d6.loss_dice: 0.2718  decode.d7.loss_cls: 0.3314  decode.d7.loss_mask: 0.2818  decode.d7.loss_dice: 0.2747  decode.d8.loss_cls: 0.2604  decode.d8.loss_mask: 0.2847  decode.d8.loss_dice: 0.2723
07/25 21:08:33 - mmengine - INFO - Iter(train) [14750/80000]  base_lr: 8.3243e-05 lr: 8.3243e-06  eta: 8:17:37  time: 0.4618  data_time: 0.0106  memory: 5266  grad_norm: 122.0575  loss: 11.2234  decode.loss_cls: 0.4054  decode.loss_mask: 0.3080  decode.loss_dice: 0.3044  decode.d0.loss_cls: 1.3748  decode.d0.loss_mask: 0.3270  decode.d0.loss_dice: 0.3590  decode.d1.loss_cls: 0.3876  decode.d1.loss_mask: 0.3224  decode.d1.loss_dice: 0.3179  decode.d2.loss_cls: 0.3858  decode.d2.loss_mask: 0.3149  decode.d2.loss_dice: 0.3109  decode.d3.loss_cls: 0.3589  decode.d3.loss_mask: 0.3131  decode.d3.loss_dice: 0.3121  decode.d4.loss_cls: 0.3927  decode.d4.loss_mask: 0.3157  decode.d4.loss_dice: 0.3115  decode.d5.loss_cls: 0.3622  decode.d5.loss_mask: 0.3155  decode.d5.loss_dice: 0.3092  decode.d6.loss_cls: 0.4679  decode.d6.loss_mask: 0.3160  decode.d6.loss_dice: 0.3021  decode.d7.loss_cls: 0.4080  decode.d7.loss_mask: 0.3071  decode.d7.loss_dice: 0.3011  decode.d8.loss_cls: 0.3952  decode.d8.loss_mask: 0.3124  decode.d8.loss_dice: 0.3049
07/25 21:08:56 - mmengine - INFO - Iter(train) [14800/80000]  base_lr: 8.3185e-05 lr: 8.3185e-06  eta: 8:17:15  time: 0.4595  data_time: 0.0107  memory: 5265  grad_norm: 68.4346  loss: 8.2345  decode.loss_cls: 0.1524  decode.loss_mask: 0.2314  decode.loss_dice: 0.2873  decode.d0.loss_cls: 1.2330  decode.d0.loss_mask: 0.2458  decode.d0.loss_dice: 0.2840  decode.d1.loss_cls: 0.2961  decode.d1.loss_mask: 0.2285  decode.d1.loss_dice: 0.2947  decode.d2.loss_cls: 0.2122  decode.d2.loss_mask: 0.2329  decode.d2.loss_dice: 0.3096  decode.d3.loss_cls: 0.1932  decode.d3.loss_mask: 0.2294  decode.d3.loss_dice: 0.2854  decode.d4.loss_cls: 0.2066  decode.d4.loss_mask: 0.2322  decode.d4.loss_dice: 0.2815  decode.d5.loss_cls: 0.1767  decode.d5.loss_mask: 0.2321  decode.d5.loss_dice: 0.3057  decode.d6.loss_cls: 0.1878  decode.d6.loss_mask: 0.2345  decode.d6.loss_dice: 0.2820  decode.d7.loss_cls: 0.1705  decode.d7.loss_mask: 0.2381  decode.d7.loss_dice: 0.2828  decode.d8.loss_cls: 0.1637  decode.d8.loss_mask: 0.2334  decode.d8.loss_dice: 0.2908
07/25 21:09:19 - mmengine - INFO - Iter(train) [14850/80000]  base_lr: 8.3128e-05 lr: 8.3128e-06  eta: 8:16:53  time: 0.4583  data_time: 0.0107  memory: 5228  grad_norm: 146.4019  loss: 9.9041  decode.loss_cls: 0.3517  decode.loss_mask: 0.2715  decode.loss_dice: 0.3024  decode.d0.loss_cls: 0.9643  decode.d0.loss_mask: 0.2942  decode.d0.loss_dice: 0.3962  decode.d1.loss_cls: 0.4774  decode.d1.loss_mask: 0.2838  decode.d1.loss_dice: 0.3199  decode.d2.loss_cls: 0.3327  decode.d2.loss_mask: 0.2780  decode.d2.loss_dice: 0.3052  decode.d3.loss_cls: 0.3064  decode.d3.loss_mask: 0.2585  decode.d3.loss_dice: 0.2919  decode.d4.loss_cls: 0.3223  decode.d4.loss_mask: 0.2527  decode.d4.loss_dice: 0.2877  decode.d5.loss_cls: 0.2967  decode.d5.loss_mask: 0.2560  decode.d5.loss_dice: 0.3000  decode.d6.loss_cls: 0.3503  decode.d6.loss_mask: 0.2527  decode.d6.loss_dice: 0.3106  decode.d7.loss_cls: 0.3484  decode.d7.loss_mask: 0.2583  decode.d7.loss_dice: 0.3024  decode.d8.loss_cls: 0.3841  decode.d8.loss_mask: 0.2598  decode.d8.loss_dice: 0.2879
07/25 21:09:42 - mmengine - INFO - Iter(train) [14900/80000]  base_lr: 8.3070e-05 lr: 8.3070e-06  eta: 8:16:29  time: 0.4582  data_time: 0.0107  memory: 5248  grad_norm: 187.2612  loss: 9.5010  decode.loss_cls: 0.3670  decode.loss_mask: 0.2300  decode.loss_dice: 0.2961  decode.d0.loss_cls: 1.1989  decode.d0.loss_mask: 0.2125  decode.d0.loss_dice: 0.3390  decode.d1.loss_cls: 0.4098  decode.d1.loss_mask: 0.2252  decode.d1.loss_dice: 0.2822  decode.d2.loss_cls: 0.2393  decode.d2.loss_mask: 0.2296  decode.d2.loss_dice: 0.2886  decode.d3.loss_cls: 0.3297  decode.d3.loss_mask: 0.2220  decode.d3.loss_dice: 0.2689  decode.d4.loss_cls: 0.3045  decode.d4.loss_mask: 0.2272  decode.d4.loss_dice: 0.2844  decode.d5.loss_cls: 0.3875  decode.d5.loss_mask: 0.2254  decode.d5.loss_dice: 0.2940  decode.d6.loss_cls: 0.3742  decode.d6.loss_mask: 0.2220  decode.d6.loss_dice: 0.2855  decode.d7.loss_cls: 0.3287  decode.d7.loss_mask: 0.2356  decode.d7.loss_dice: 0.2953  decode.d8.loss_cls: 0.3534  decode.d8.loss_mask: 0.2372  decode.d8.loss_dice: 0.3073
07/25 21:10:04 - mmengine - INFO - Iter(train) [14950/80000]  base_lr: 8.3013e-05 lr: 8.3013e-06  eta: 8:16:05  time: 0.4447  data_time: 0.0092  memory: 5249  grad_norm: 178.7424  loss: 10.6421  decode.loss_cls: 0.2280  decode.loss_mask: 0.2873  decode.loss_dice: 0.3887  decode.d0.loss_cls: 1.2915  decode.d0.loss_mask: 0.2738  decode.d0.loss_dice: 0.4594  decode.d1.loss_cls: 0.4317  decode.d1.loss_mask: 0.2835  decode.d1.loss_dice: 0.4397  decode.d2.loss_cls: 0.3153  decode.d2.loss_mask: 0.2773  decode.d2.loss_dice: 0.4126  decode.d3.loss_cls: 0.2920  decode.d3.loss_mask: 0.2699  decode.d3.loss_dice: 0.3698  decode.d4.loss_cls: 0.2702  decode.d4.loss_mask: 0.2688  decode.d4.loss_dice: 0.3909  decode.d5.loss_cls: 0.1798  decode.d5.loss_mask: 0.2923  decode.d5.loss_dice: 0.3988  decode.d6.loss_cls: 0.2430  decode.d6.loss_mask: 0.2827  decode.d6.loss_dice: 0.3998  decode.d7.loss_cls: 0.2528  decode.d7.loss_mask: 0.2956  decode.d7.loss_dice: 0.4087  decode.d8.loss_cls: 0.2201  decode.d8.loss_mask: 0.2965  decode.d8.loss_dice: 0.4216
07/25 21:10:27 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250725_191538
07/25 21:10:27 - mmengine - INFO - Iter(train) [15000/80000]  base_lr: 8.2956e-05 lr: 8.2956e-06  eta: 8:15:42  time: 0.4626  data_time: 0.0103  memory: 5252  grad_norm: 78.2391  loss: 9.3244  decode.loss_cls: 0.2258  decode.loss_mask: 0.2911  decode.loss_dice: 0.3325  decode.d0.loss_cls: 0.9740  decode.d0.loss_mask: 0.2896  decode.d0.loss_dice: 0.3960  decode.d1.loss_cls: 0.2200  decode.d1.loss_mask: 0.2878  decode.d1.loss_dice: 0.3337  decode.d2.loss_cls: 0.2442  decode.d2.loss_mask: 0.2904  decode.d2.loss_dice: 0.3456  decode.d3.loss_cls: 0.2584  decode.d3.loss_mask: 0.2839  decode.d3.loss_dice: 0.3406  decode.d4.loss_cls: 0.1869  decode.d4.loss_mask: 0.2881  decode.d4.loss_dice: 0.3619  decode.d5.loss_cls: 0.2252  decode.d5.loss_mask: 0.2855  decode.d5.loss_dice: 0.3244  decode.d6.loss_cls: 0.2124  decode.d6.loss_mask: 0.2836  decode.d6.loss_dice: 0.3276  decode.d7.loss_cls: 0.2540  decode.d7.loss_mask: 0.3050  decode.d7.loss_dice: 0.3302  decode.d8.loss_cls: 0.2129  decode.d8.loss_mask: 0.2937  decode.d8.loss_dice: 0.3197
07/25 21:10:27 - mmengine - INFO - Saving checkpoint at 15000 iterations
07/25 21:10:52 - mmengine - INFO - Iter(train) [15050/80000]  base_lr: 8.2898e-05 lr: 8.2898e-06  eta: 8:15:28  time: 0.4584  data_time: 0.0107  memory: 5231  grad_norm: 99.7509  loss: 10.3585  decode.loss_cls: 0.2977  decode.loss_mask: 0.3012  decode.loss_dice: 0.3765  decode.d0.loss_cls: 1.1154  decode.d0.loss_mask: 0.3084  decode.d0.loss_dice: 0.3699  decode.d1.loss_cls: 0.2969  decode.d1.loss_mask: 0.3054  decode.d1.loss_dice: 0.3266  decode.d2.loss_cls: 0.3038  decode.d2.loss_mask: 0.3011  decode.d2.loss_dice: 0.3255  decode.d3.loss_cls: 0.2967  decode.d3.loss_mask: 0.2987  decode.d3.loss_dice: 0.3346  decode.d4.loss_cls: 0.3017  decode.d4.loss_mask: 0.3015  decode.d4.loss_dice: 0.3441  decode.d5.loss_cls: 0.3033  decode.d5.loss_mask: 0.2989  decode.d5.loss_dice: 0.3312  decode.d6.loss_cls: 0.3211  decode.d6.loss_mask: 0.3000  decode.d6.loss_dice: 0.3724  decode.d7.loss_cls: 0.3191  decode.d7.loss_mask: 0.2949  decode.d7.loss_dice: 0.3334  decode.d8.loss_cls: 0.2853  decode.d8.loss_mask: 0.3092  decode.d8.loss_dice: 0.3840
07/25 21:11:15 - mmengine - INFO - Iter(train) [15100/80000]  base_lr: 8.2841e-05 lr: 8.2841e-06  eta: 8:15:05  time: 0.4583  data_time: 0.0113  memory: 5231  grad_norm: 96.6971  loss: 9.0942  decode.loss_cls: 0.2599  decode.loss_mask: 0.2979  decode.loss_dice: 0.2930  decode.d0.loss_cls: 0.9374  decode.d0.loss_mask: 0.3289  decode.d0.loss_dice: 0.3392  decode.d1.loss_cls: 0.3114  decode.d1.loss_mask: 0.2863  decode.d1.loss_dice: 0.2934  decode.d2.loss_cls: 0.2502  decode.d2.loss_mask: 0.2993  decode.d2.loss_dice: 0.3036  decode.d3.loss_cls: 0.1847  decode.d3.loss_mask: 0.2989  decode.d3.loss_dice: 0.3183  decode.d4.loss_cls: 0.1752  decode.d4.loss_mask: 0.2951  decode.d4.loss_dice: 0.3244  decode.d5.loss_cls: 0.1924  decode.d5.loss_mask: 0.3052  decode.d5.loss_dice: 0.3170  decode.d6.loss_cls: 0.2329  decode.d6.loss_mask: 0.2837  decode.d6.loss_dice: 0.3110  decode.d7.loss_cls: 0.2499  decode.d7.loss_mask: 0.3016  decode.d7.loss_dice: 0.3055  decode.d8.loss_cls: 0.1989  decode.d8.loss_mask: 0.3007  decode.d8.loss_dice: 0.2983
07/25 21:11:38 - mmengine - INFO - Iter(train) [15150/80000]  base_lr: 8.2783e-05 lr: 8.2783e-06  eta: 8:14:42  time: 0.4556  data_time: 0.0107  memory: 5248  grad_norm: 79.5653  loss: 7.2568  decode.loss_cls: 0.1244  decode.loss_mask: 0.2234  decode.loss_dice: 0.2581  decode.d0.loss_cls: 1.0327  decode.d0.loss_mask: 0.2256  decode.d0.loss_dice: 0.3050  decode.d1.loss_cls: 0.2734  decode.d1.loss_mask: 0.2259  decode.d1.loss_dice: 0.2780  decode.d2.loss_cls: 0.1371  decode.d2.loss_mask: 0.2221  decode.d2.loss_dice: 0.2613  decode.d3.loss_cls: 0.1414  decode.d3.loss_mask: 0.2188  decode.d3.loss_dice: 0.2678  decode.d4.loss_cls: 0.1376  decode.d4.loss_mask: 0.2219  decode.d4.loss_dice: 0.2546  decode.d5.loss_cls: 0.1350  decode.d5.loss_mask: 0.2185  decode.d5.loss_dice: 0.2548  decode.d6.loss_cls: 0.1273  decode.d6.loss_mask: 0.2224  decode.d6.loss_dice: 0.2763  decode.d7.loss_cls: 0.1291  decode.d7.loss_mask: 0.2239  decode.d7.loss_dice: 0.2478  decode.d8.loss_cls: 0.1377  decode.d8.loss_mask: 0.2215  decode.d8.loss_dice: 0.2532
07/25 21:12:01 - mmengine - INFO - Iter(train) [15200/80000]  base_lr: 8.2726e-05 lr: 8.2726e-06  eta: 8:14:20  time: 0.4574  data_time: 0.0105  memory: 5248  grad_norm: 154.8797  loss: 9.7868  decode.loss_cls: 0.2820  decode.loss_mask: 0.2763  decode.loss_dice: 0.3032  decode.d0.loss_cls: 1.2108  decode.d0.loss_mask: 0.2914  decode.d0.loss_dice: 0.3452  decode.d1.loss_cls: 0.4171  decode.d1.loss_mask: 0.2795  decode.d1.loss_dice: 0.3259  decode.d2.loss_cls: 0.3061  decode.d2.loss_mask: 0.2791  decode.d2.loss_dice: 0.3063  decode.d3.loss_cls: 0.2872  decode.d3.loss_mask: 0.2772  decode.d3.loss_dice: 0.3093  decode.d4.loss_cls: 0.3076  decode.d4.loss_mask: 0.2806  decode.d4.loss_dice: 0.3289  decode.d5.loss_cls: 0.2742  decode.d5.loss_mask: 0.2773  decode.d5.loss_dice: 0.3082  decode.d6.loss_cls: 0.2367  decode.d6.loss_mask: 0.2745  decode.d6.loss_dice: 0.3151  decode.d7.loss_cls: 0.2799  decode.d7.loss_mask: 0.2760  decode.d7.loss_dice: 0.3085  decode.d8.loss_cls: 0.2337  decode.d8.loss_mask: 0.2821  decode.d8.loss_dice: 0.3068
07/25 21:12:24 - mmengine - INFO - Iter(train) [15250/80000]  base_lr: 8.2668e-05 lr: 8.2668e-06  eta: 8:13:56  time: 0.4569  data_time: 0.0109  memory: 5249  grad_norm: 66.2411  loss: 9.1879  decode.loss_cls: 0.2707  decode.loss_mask: 0.2823  decode.loss_dice: 0.2903  decode.d0.loss_cls: 1.1783  decode.d0.loss_mask: 0.2922  decode.d0.loss_dice: 0.3016  decode.d1.loss_cls: 0.3209  decode.d1.loss_mask: 0.2836  decode.d1.loss_dice: 0.2891  decode.d2.loss_cls: 0.2336  decode.d2.loss_mask: 0.2807  decode.d2.loss_dice: 0.2861  decode.d3.loss_cls: 0.2372  decode.d3.loss_mask: 0.2809  decode.d3.loss_dice: 0.2888  decode.d4.loss_cls: 0.2623  decode.d4.loss_mask: 0.2784  decode.d4.loss_dice: 0.2795  decode.d5.loss_cls: 0.2292  decode.d5.loss_mask: 0.2779  decode.d5.loss_dice: 0.2761  decode.d6.loss_cls: 0.2246  decode.d6.loss_mask: 0.2800  decode.d6.loss_dice: 0.2876  decode.d7.loss_cls: 0.2392  decode.d7.loss_mask: 0.2767  decode.d7.loss_dice: 0.2730  decode.d8.loss_cls: 0.3313  decode.d8.loss_mask: 0.2790  decode.d8.loss_dice: 0.2769
07/25 21:12:46 - mmengine - INFO - Iter(train) [15300/80000]  base_lr: 8.2611e-05 lr: 8.2611e-06  eta: 8:13:33  time: 0.4603  data_time: 0.0107  memory: 5231  grad_norm: 117.5526  loss: 9.1311  decode.loss_cls: 0.1678  decode.loss_mask: 0.3863  decode.loss_dice: 0.2776  decode.d0.loss_cls: 1.1038  decode.d0.loss_mask: 0.3910  decode.d0.loss_dice: 0.2775  decode.d1.loss_cls: 0.2511  decode.d1.loss_mask: 0.3957  decode.d1.loss_dice: 0.2696  decode.d2.loss_cls: 0.1789  decode.d2.loss_mask: 0.3681  decode.d2.loss_dice: 0.2718  decode.d3.loss_cls: 0.1669  decode.d3.loss_mask: 0.3787  decode.d3.loss_dice: 0.2785  decode.d4.loss_cls: 0.1803  decode.d4.loss_mask: 0.3752  decode.d4.loss_dice: 0.2702  decode.d5.loss_cls: 0.1315  decode.d5.loss_mask: 0.3727  decode.d5.loss_dice: 0.2616  decode.d6.loss_cls: 0.1313  decode.d6.loss_mask: 0.3841  decode.d6.loss_dice: 0.2659  decode.d7.loss_cls: 0.1585  decode.d7.loss_mask: 0.3867  decode.d7.loss_dice: 0.2708  decode.d8.loss_cls: 0.1192  decode.d8.loss_mask: 0.3866  decode.d8.loss_dice: 0.2734
07/25 21:13:09 - mmengine - INFO - Iter(train) [15350/80000]  base_lr: 8.2554e-05 lr: 8.2554e-06  eta: 8:13:10  time: 0.4553  data_time: 0.0104  memory: 5265  grad_norm: 91.0500  loss: 8.6501  decode.loss_cls: 0.2629  decode.loss_mask: 0.2611  decode.loss_dice: 0.2830  decode.d0.loss_cls: 1.0814  decode.d0.loss_mask: 0.2558  decode.d0.loss_dice: 0.3346  decode.d1.loss_cls: 0.2757  decode.d1.loss_mask: 0.2671  decode.d1.loss_dice: 0.2980  decode.d2.loss_cls: 0.1982  decode.d2.loss_mask: 0.2618  decode.d2.loss_dice: 0.3138  decode.d3.loss_cls: 0.1925  decode.d3.loss_mask: 0.2583  decode.d3.loss_dice: 0.2952  decode.d4.loss_cls: 0.2363  decode.d4.loss_mask: 0.2569  decode.d4.loss_dice: 0.2882  decode.d5.loss_cls: 0.1879  decode.d5.loss_mask: 0.2599  decode.d5.loss_dice: 0.2892  decode.d6.loss_cls: 0.1840  decode.d6.loss_mask: 0.2600  decode.d6.loss_dice: 0.2933  decode.d7.loss_cls: 0.2298  decode.d7.loss_mask: 0.2616  decode.d7.loss_dice: 0.3001  decode.d8.loss_cls: 0.2215  decode.d8.loss_mask: 0.2604  decode.d8.loss_dice: 0.2815
07/25 21:13:32 - mmengine - INFO - Iter(train) [15400/80000]  base_lr: 8.2496e-05 lr: 8.2496e-06  eta: 8:12:46  time: 0.4595  data_time: 0.0105  memory: 5248  grad_norm: 95.1109  loss: 9.2306  decode.loss_cls: 0.2319  decode.loss_mask: 0.2471  decode.loss_dice: 0.3512  decode.d0.loss_cls: 1.0321  decode.d0.loss_mask: 0.2406  decode.d0.loss_dice: 0.3719  decode.d1.loss_cls: 0.2730  decode.d1.loss_mask: 0.2440  decode.d1.loss_dice: 0.3515  decode.d2.loss_cls: 0.2557  decode.d2.loss_mask: 0.2472  decode.d2.loss_dice: 0.3558  decode.d3.loss_cls: 0.2075  decode.d3.loss_mask: 0.2462  decode.d3.loss_dice: 0.3451  decode.d4.loss_cls: 0.2287  decode.d4.loss_mask: 0.2461  decode.d4.loss_dice: 0.3387  decode.d5.loss_cls: 0.2533  decode.d5.loss_mask: 0.2462  decode.d5.loss_dice: 0.3550  decode.d6.loss_cls: 0.2835  decode.d6.loss_mask: 0.2373  decode.d6.loss_dice: 0.3532  decode.d7.loss_cls: 0.2558  decode.d7.loss_mask: 0.2510  decode.d7.loss_dice: 0.3563  decode.d8.loss_cls: 0.2214  decode.d8.loss_mask: 0.2485  decode.d8.loss_dice: 0.3544
07/25 21:13:55 - mmengine - INFO - Iter(train) [15450/80000]  base_lr: 8.2439e-05 lr: 8.2439e-06  eta: 8:12:24  time: 0.4622  data_time: 0.0107  memory: 5265  grad_norm: 91.8467  loss: 8.3013  decode.loss_cls: 0.1820  decode.loss_mask: 0.2451  decode.loss_dice: 0.2884  decode.d0.loss_cls: 0.9711  decode.d0.loss_mask: 0.2597  decode.d0.loss_dice: 0.3397  decode.d1.loss_cls: 0.2854  decode.d1.loss_mask: 0.2502  decode.d1.loss_dice: 0.3023  decode.d2.loss_cls: 0.2187  decode.d2.loss_mask: 0.2470  decode.d2.loss_dice: 0.2926  decode.d3.loss_cls: 0.2043  decode.d3.loss_mask: 0.2470  decode.d3.loss_dice: 0.2873  decode.d4.loss_cls: 0.2027  decode.d4.loss_mask: 0.2459  decode.d4.loss_dice: 0.2916  decode.d5.loss_cls: 0.1873  decode.d5.loss_mask: 0.2448  decode.d5.loss_dice: 0.2913  decode.d6.loss_cls: 0.1986  decode.d6.loss_mask: 0.2447  decode.d6.loss_dice: 0.2899  decode.d7.loss_cls: 0.2222  decode.d7.loss_mask: 0.2443  decode.d7.loss_dice: 0.3150  decode.d8.loss_cls: 0.1793  decode.d8.loss_mask: 0.2416  decode.d8.loss_dice: 0.2813
07/25 21:14:18 - mmengine - INFO - Iter(train) [15500/80000]  base_lr: 8.2381e-05 lr: 8.2381e-06  eta: 8:12:02  time: 0.4639  data_time: 0.0112  memory: 5249  grad_norm: 68.1428  loss: 8.4547  decode.loss_cls: 0.3111  decode.loss_mask: 0.1870  decode.loss_dice: 0.2678  decode.d0.loss_cls: 1.2354  decode.d0.loss_mask: 0.1986  decode.d0.loss_dice: 0.2897  decode.d1.loss_cls: 0.3825  decode.d1.loss_mask: 0.1911  decode.d1.loss_dice: 0.2753  decode.d2.loss_cls: 0.2989  decode.d2.loss_mask: 0.1960  decode.d2.loss_dice: 0.2799  decode.d3.loss_cls: 0.2921  decode.d3.loss_mask: 0.1911  decode.d3.loss_dice: 0.2719  decode.d4.loss_cls: 0.2675  decode.d4.loss_mask: 0.1887  decode.d4.loss_dice: 0.2628  decode.d5.loss_cls: 0.2656  decode.d5.loss_mask: 0.1891  decode.d5.loss_dice: 0.2743  decode.d6.loss_cls: 0.2074  decode.d6.loss_mask: 0.1895  decode.d6.loss_dice: 0.2683  decode.d7.loss_cls: 0.2406  decode.d7.loss_mask: 0.1896  decode.d7.loss_dice: 0.2728  decode.d8.loss_cls: 0.3077  decode.d8.loss_mask: 0.1885  decode.d8.loss_dice: 0.2739
07/25 21:14:41 - mmengine - INFO - Iter(train) [15550/80000]  base_lr: 8.2324e-05 lr: 8.2324e-06  eta: 8:11:41  time: 0.4629  data_time: 0.0106  memory: 5248  grad_norm: 100.8946  loss: 9.7880  decode.loss_cls: 0.2860  decode.loss_mask: 0.2496  decode.loss_dice: 0.3321  decode.d0.loss_cls: 1.0675  decode.d0.loss_mask: 0.2678  decode.d0.loss_dice: 0.4019  decode.d1.loss_cls: 0.4212  decode.d1.loss_mask: 0.2512  decode.d1.loss_dice: 0.3540  decode.d2.loss_cls: 0.3179  decode.d2.loss_mask: 0.2527  decode.d2.loss_dice: 0.3297  decode.d3.loss_cls: 0.2664  decode.d3.loss_mask: 0.2492  decode.d3.loss_dice: 0.3303  decode.d4.loss_cls: 0.2411  decode.d4.loss_mask: 0.2465  decode.d4.loss_dice: 0.3296  decode.d5.loss_cls: 0.3127  decode.d5.loss_mask: 0.2495  decode.d5.loss_dice: 0.3343  decode.d6.loss_cls: 0.2870  decode.d6.loss_mask: 0.2542  decode.d6.loss_dice: 0.3400  decode.d7.loss_cls: 0.3176  decode.d7.loss_mask: 0.2507  decode.d7.loss_dice: 0.3385  decode.d8.loss_cls: 0.3152  decode.d8.loss_mask: 0.2518  decode.d8.loss_dice: 0.3419
07/25 21:15:04 - mmengine - INFO - Iter(train) [15600/80000]  base_lr: 8.2266e-05 lr: 8.2266e-06  eta: 8:11:18  time: 0.4473  data_time: 0.0100  memory: 5265  grad_norm: 95.8290  loss: 9.1945  decode.loss_cls: 0.2219  decode.loss_mask: 0.2975  decode.loss_dice: 0.2869  decode.d0.loss_cls: 1.2079  decode.d0.loss_mask: 0.2990  decode.d0.loss_dice: 0.3264  decode.d1.loss_cls: 0.3313  decode.d1.loss_mask: 0.3077  decode.d1.loss_dice: 0.2874  decode.d2.loss_cls: 0.2175  decode.d2.loss_mask: 0.2984  decode.d2.loss_dice: 0.3084  decode.d3.loss_cls: 0.2189  decode.d3.loss_mask: 0.2988  decode.d3.loss_dice: 0.2924  decode.d4.loss_cls: 0.2311  decode.d4.loss_mask: 0.2966  decode.d4.loss_dice: 0.2806  decode.d5.loss_cls: 0.1992  decode.d5.loss_mask: 0.2967  decode.d5.loss_dice: 0.2822  decode.d6.loss_cls: 0.2333  decode.d6.loss_mask: 0.2912  decode.d6.loss_dice: 0.2816  decode.d7.loss_cls: 0.2352  decode.d7.loss_mask: 0.2949  decode.d7.loss_dice: 0.2816  decode.d8.loss_cls: 0.2087  decode.d8.loss_mask: 0.2965  decode.d8.loss_dice: 0.2848
07/25 21:15:27 - mmengine - INFO - Iter(train) [15650/80000]  base_lr: 8.2209e-05 lr: 8.2209e-06  eta: 8:10:55  time: 0.4572  data_time: 0.0105  memory: 5230  grad_norm: 125.9008  loss: 9.2260  decode.loss_cls: 0.2107  decode.loss_mask: 0.2829  decode.loss_dice: 0.3275  decode.d0.loss_cls: 0.9917  decode.d0.loss_mask: 0.3101  decode.d0.loss_dice: 0.3731  decode.d1.loss_cls: 0.2496  decode.d1.loss_mask: 0.2840  decode.d1.loss_dice: 0.3279  decode.d2.loss_cls: 0.2421  decode.d2.loss_mask: 0.2809  decode.d2.loss_dice: 0.3372  decode.d3.loss_cls: 0.2745  decode.d3.loss_mask: 0.2775  decode.d3.loss_dice: 0.3318  decode.d4.loss_cls: 0.2471  decode.d4.loss_mask: 0.2785  decode.d4.loss_dice: 0.3272  decode.d5.loss_cls: 0.2520  decode.d5.loss_mask: 0.2810  decode.d5.loss_dice: 0.3327  decode.d6.loss_cls: 0.1525  decode.d6.loss_mask: 0.2859  decode.d6.loss_dice: 0.3323  decode.d7.loss_cls: 0.2348  decode.d7.loss_mask: 0.2793  decode.d7.loss_dice: 0.3144  decode.d8.loss_cls: 0.2146  decode.d8.loss_mask: 0.2815  decode.d8.loss_dice: 0.3108
07/25 21:15:50 - mmengine - INFO - Iter(train) [15700/80000]  base_lr: 8.2151e-05 lr: 8.2151e-06  eta: 8:10:32  time: 0.4634  data_time: 0.0108  memory: 5249  grad_norm: 53.3194  loss: 7.9271  decode.loss_cls: 0.2540  decode.loss_mask: 0.2254  decode.loss_dice: 0.2416  decode.d0.loss_cls: 1.0681  decode.d0.loss_mask: 0.2379  decode.d0.loss_dice: 0.2708  decode.d1.loss_cls: 0.2917  decode.d1.loss_mask: 0.2373  decode.d1.loss_dice: 0.2653  decode.d2.loss_cls: 0.3125  decode.d2.loss_mask: 0.2250  decode.d2.loss_dice: 0.2341  decode.d3.loss_cls: 0.2446  decode.d3.loss_mask: 0.2295  decode.d3.loss_dice: 0.2538  decode.d4.loss_cls: 0.2467  decode.d4.loss_mask: 0.2287  decode.d4.loss_dice: 0.2466  decode.d5.loss_cls: 0.1931  decode.d5.loss_mask: 0.2300  decode.d5.loss_dice: 0.2586  decode.d6.loss_cls: 0.1606  decode.d6.loss_mask: 0.2312  decode.d6.loss_dice: 0.2500  decode.d7.loss_cls: 0.2036  decode.d7.loss_mask: 0.2266  decode.d7.loss_dice: 0.2318  decode.d8.loss_cls: 0.1623  decode.d8.loss_mask: 0.2281  decode.d8.loss_dice: 0.2376
07/25 21:16:13 - mmengine - INFO - Iter(train) [15750/80000]  base_lr: 8.2094e-05 lr: 8.2094e-06  eta: 8:10:09  time: 0.4587  data_time: 0.0106  memory: 5249  grad_norm: 134.2116  loss: 7.1724  decode.loss_cls: 0.1178  decode.loss_mask: 0.2483  decode.loss_dice: 0.2326  decode.d0.loss_cls: 1.0829  decode.d0.loss_mask: 0.2688  decode.d0.loss_dice: 0.2640  decode.d1.loss_cls: 0.1329  decode.d1.loss_mask: 0.2558  decode.d1.loss_dice: 0.2638  decode.d2.loss_cls: 0.1068  decode.d2.loss_mask: 0.2565  decode.d2.loss_dice: 0.2667  decode.d3.loss_cls: 0.1048  decode.d3.loss_mask: 0.2494  decode.d3.loss_dice: 0.2559  decode.d4.loss_cls: 0.0943  decode.d4.loss_mask: 0.2567  decode.d4.loss_dice: 0.2579  decode.d5.loss_cls: 0.0841  decode.d5.loss_mask: 0.2499  decode.d5.loss_dice: 0.2427  decode.d6.loss_cls: 0.1134  decode.d6.loss_mask: 0.2629  decode.d6.loss_dice: 0.2649  decode.d7.loss_cls: 0.1403  decode.d7.loss_mask: 0.2527  decode.d7.loss_dice: 0.2405  decode.d8.loss_cls: 0.1124  decode.d8.loss_mask: 0.2500  decode.d8.loss_dice: 0.2427
07/25 21:16:36 - mmengine - INFO - Iter(train) [15800/80000]  base_lr: 8.2036e-05 lr: 8.2036e-06  eta: 8:09:47  time: 0.4589  data_time: 0.0106  memory: 5231  grad_norm: 105.1567  loss: 8.5668  decode.loss_cls: 0.1562  decode.loss_mask: 0.2587  decode.loss_dice: 0.3030  decode.d0.loss_cls: 1.1549  decode.d0.loss_mask: 0.2647  decode.d0.loss_dice: 0.3292  decode.d1.loss_cls: 0.3024  decode.d1.loss_mask: 0.2543  decode.d1.loss_dice: 0.3265  decode.d2.loss_cls: 0.2524  decode.d2.loss_mask: 0.2566  decode.d2.loss_dice: 0.2995  decode.d3.loss_cls: 0.2180  decode.d3.loss_mask: 0.2498  decode.d3.loss_dice: 0.2889  decode.d4.loss_cls: 0.2144  decode.d4.loss_mask: 0.2593  decode.d4.loss_dice: 0.2975  decode.d5.loss_cls: 0.1818  decode.d5.loss_mask: 0.2536  decode.d5.loss_dice: 0.2918  decode.d6.loss_cls: 0.1786  decode.d6.loss_mask: 0.2526  decode.d6.loss_dice: 0.2878  decode.d7.loss_cls: 0.1489  decode.d7.loss_mask: 0.2559  decode.d7.loss_dice: 0.3124  decode.d8.loss_cls: 0.1572  decode.d8.loss_mask: 0.2536  decode.d8.loss_dice: 0.3064
07/25 21:16:59 - mmengine - INFO - Iter(train) [15850/80000]  base_lr: 8.1979e-05 lr: 8.1979e-06  eta: 8:09:24  time: 0.4646  data_time: 0.0108  memory: 5265  grad_norm: 130.6803  loss: 10.4674  decode.loss_cls: 0.2763  decode.loss_mask: 0.3175  decode.loss_dice: 0.3452  decode.d0.loss_cls: 1.1320  decode.d0.loss_mask: 0.3510  decode.d0.loss_dice: 0.3799  decode.d1.loss_cls: 0.3698  decode.d1.loss_mask: 0.3168  decode.d1.loss_dice: 0.3392  decode.d2.loss_cls: 0.2952  decode.d2.loss_mask: 0.3171  decode.d2.loss_dice: 0.3289  decode.d3.loss_cls: 0.2809  decode.d3.loss_mask: 0.3149  decode.d3.loss_dice: 0.3373  decode.d4.loss_cls: 0.2897  decode.d4.loss_mask: 0.3104  decode.d4.loss_dice: 0.3385  decode.d5.loss_cls: 0.3027  decode.d5.loss_mask: 0.3156  decode.d5.loss_dice: 0.3438  decode.d6.loss_cls: 0.2771  decode.d6.loss_mask: 0.3129  decode.d6.loss_dice: 0.3330  decode.d7.loss_cls: 0.3611  decode.d7.loss_mask: 0.3145  decode.d7.loss_dice: 0.3293  decode.d8.loss_cls: 0.2800  decode.d8.loss_mask: 0.3163  decode.d8.loss_dice: 0.3405
07/25 21:17:22 - mmengine - INFO - Iter(train) [15900/80000]  base_lr: 8.1921e-05 lr: 8.1921e-06  eta: 8:09:02  time: 0.4627  data_time: 0.0108  memory: 5248  grad_norm: 95.0839  loss: 9.0402  decode.loss_cls: 0.2422  decode.loss_mask: 0.2324  decode.loss_dice: 0.2732  decode.d0.loss_cls: 1.2903  decode.d0.loss_mask: 0.2474  decode.d0.loss_dice: 0.3136  decode.d1.loss_cls: 0.2897  decode.d1.loss_mask: 0.2451  decode.d1.loss_dice: 0.2961  decode.d2.loss_cls: 0.2480  decode.d2.loss_mask: 0.2388  decode.d2.loss_dice: 0.2870  decode.d3.loss_cls: 0.2722  decode.d3.loss_mask: 0.2374  decode.d3.loss_dice: 0.2907  decode.d4.loss_cls: 0.2778  decode.d4.loss_mask: 0.2339  decode.d4.loss_dice: 0.2824  decode.d5.loss_cls: 0.2922  decode.d5.loss_mask: 0.2333  decode.d5.loss_dice: 0.2756  decode.d6.loss_cls: 0.3536  decode.d6.loss_mask: 0.2419  decode.d6.loss_dice: 0.2963  decode.d7.loss_cls: 0.2825  decode.d7.loss_mask: 0.2400  decode.d7.loss_dice: 0.2814  decode.d8.loss_cls: 0.2359  decode.d8.loss_mask: 0.2346  decode.d8.loss_dice: 0.2747
07/25 21:17:45 - mmengine - INFO - Iter(train) [15950/80000]  base_lr: 8.1864e-05 lr: 8.1864e-06  eta: 8:08:39  time: 0.4359  data_time: 0.0088  memory: 5231  grad_norm: 95.3429  loss: 8.3868  decode.loss_cls: 0.1457  decode.loss_mask: 0.2655  decode.loss_dice: 0.2730  decode.d0.loss_cls: 1.1069  decode.d0.loss_mask: 0.2721  decode.d0.loss_dice: 0.2946  decode.d1.loss_cls: 0.4258  decode.d1.loss_mask: 0.2700  decode.d1.loss_dice: 0.2919  decode.d2.loss_cls: 0.1687  decode.d2.loss_mask: 0.2673  decode.d2.loss_dice: 0.3034  decode.d3.loss_cls: 0.1771  decode.d3.loss_mask: 0.2664  decode.d3.loss_dice: 0.2835  decode.d4.loss_cls: 0.1287  decode.d4.loss_mask: 0.2652  decode.d4.loss_dice: 0.2873  decode.d5.loss_cls: 0.1449  decode.d5.loss_mask: 0.2648  decode.d5.loss_dice: 0.2837  decode.d6.loss_cls: 0.1850  decode.d6.loss_mask: 0.2688  decode.d6.loss_dice: 0.2682  decode.d7.loss_cls: 0.1785  decode.d7.loss_mask: 0.2676  decode.d7.loss_dice: 0.2718  decode.d8.loss_cls: 0.2229  decode.d8.loss_mask: 0.2646  decode.d8.loss_dice: 0.2728
07/25 21:18:08 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250725_191538
07/25 21:18:08 - mmengine - INFO - Iter(train) [16000/80000]  base_lr: 8.1806e-05 lr: 8.1806e-06  eta: 8:08:16  time: 0.4529  data_time: 0.0106  memory: 5292  grad_norm: 128.8175  loss: 12.7838  decode.loss_cls: 0.4488  decode.loss_mask: 0.3833  decode.loss_dice: 0.3370  decode.d0.loss_cls: 1.2981  decode.d0.loss_mask: 0.3918  decode.d0.loss_dice: 0.3924  decode.d1.loss_cls: 0.5901  decode.d1.loss_mask: 0.3924  decode.d1.loss_dice: 0.3641  decode.d2.loss_cls: 0.5373  decode.d2.loss_mask: 0.3847  decode.d2.loss_dice: 0.3371  decode.d3.loss_cls: 0.4753  decode.d3.loss_mask: 0.3826  decode.d3.loss_dice: 0.3500  decode.d4.loss_cls: 0.4101  decode.d4.loss_mask: 0.3783  decode.d4.loss_dice: 0.3389  decode.d5.loss_cls: 0.3897  decode.d5.loss_mask: 0.3781  decode.d5.loss_dice: 0.3600  decode.d6.loss_cls: 0.4727  decode.d6.loss_mask: 0.3792  decode.d6.loss_dice: 0.3441  decode.d7.loss_cls: 0.4154  decode.d7.loss_mask: 0.3802  decode.d7.loss_dice: 0.3418  decode.d8.loss_cls: 0.4038  decode.d8.loss_mask: 0.3766  decode.d8.loss_dice: 0.3498
07/25 21:18:30 - mmengine - INFO - Iter(train) [16050/80000]  base_lr: 8.1749e-05 lr: 8.1749e-06  eta: 8:07:52  time: 0.4600  data_time: 0.0105  memory: 5266  grad_norm: 113.3538  loss: 10.0119  decode.loss_cls: 0.3030  decode.loss_mask: 0.2614  decode.loss_dice: 0.3568  decode.d0.loss_cls: 0.9997  decode.d0.loss_mask: 0.2611  decode.d0.loss_dice: 0.3592  decode.d1.loss_cls: 0.3558  decode.d1.loss_mask: 0.2623  decode.d1.loss_dice: 0.3228  decode.d2.loss_cls: 0.3556  decode.d2.loss_mask: 0.2585  decode.d2.loss_dice: 0.3150  decode.d3.loss_cls: 0.3250  decode.d3.loss_mask: 0.2592  decode.d3.loss_dice: 0.3355  decode.d4.loss_cls: 0.3547  decode.d4.loss_mask: 0.2598  decode.d4.loss_dice: 0.3232  decode.d5.loss_cls: 0.3085  decode.d5.loss_mask: 0.2600  decode.d5.loss_dice: 0.3496  decode.d6.loss_cls: 0.3330  decode.d6.loss_mask: 0.2579  decode.d6.loss_dice: 0.3420  decode.d7.loss_cls: 0.3831  decode.d7.loss_mask: 0.2587  decode.d7.loss_dice: 0.3319  decode.d8.loss_cls: 0.3301  decode.d8.loss_mask: 0.2584  decode.d8.loss_dice: 0.3301
07/25 21:18:53 - mmengine - INFO - Iter(train) [16100/80000]  base_lr: 8.1691e-05 lr: 8.1691e-06  eta: 8:07:29  time: 0.4537  data_time: 0.0100  memory: 5266  grad_norm: 77.9209  loss: 9.6776  decode.loss_cls: 0.3050  decode.loss_mask: 0.2519  decode.loss_dice: 0.3189  decode.d0.loss_cls: 1.1401  decode.d0.loss_mask: 0.3008  decode.d0.loss_dice: 0.3418  decode.d1.loss_cls: 0.4475  decode.d1.loss_mask: 0.2580  decode.d1.loss_dice: 0.2812  decode.d2.loss_cls: 0.3249  decode.d2.loss_mask: 0.2547  decode.d2.loss_dice: 0.3063  decode.d3.loss_cls: 0.3313  decode.d3.loss_mask: 0.2530  decode.d3.loss_dice: 0.3163  decode.d4.loss_cls: 0.2886  decode.d4.loss_mask: 0.2591  decode.d4.loss_dice: 0.3093  decode.d5.loss_cls: 0.2898  decode.d5.loss_mask: 0.2531  decode.d5.loss_dice: 0.3154  decode.d6.loss_cls: 0.2557  decode.d6.loss_mask: 0.2511  decode.d6.loss_dice: 0.3105  decode.d7.loss_cls: 0.3012  decode.d7.loss_mask: 0.2555  decode.d7.loss_dice: 0.3282  decode.d8.loss_cls: 0.2524  decode.d8.loss_mask: 0.2551  decode.d8.loss_dice: 0.3209
