==========================================
SLURM_JOB_ID = 2468346
SLURM_NODELIST = gnode070
SLURM_JOB_GPUS = 0
==========================================
07/30 16:40:03 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.23 (main, Jun  5 2025, 13:40:20) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 268722126
    GPU 0: NVIDIA GeForce RTX 2080 Ti
    CUDA_HOME: /opt/cuda-12.1/
    NVCC: Cuda compilation tools, release 12.1, V12.1.66
    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
    PyTorch: 2.1.2
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 268722126
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

07/30 16:40:04 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=16, enable=False)
crop_size = (
    512,
    1024,
)
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        512,
        1024,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    test_cfg=dict(size_divisor=32),
    type='SegDataPreProcessor')
data_root = '/scratch/seg_benchmark/seg_full_redone_FINAL/'
dataset_type = 'YourDataset_BIG'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False, interval=5000, save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'))
default_scope = 'mmseg'
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
img_suffix = '.jpg'
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        deep_stem=False,
        depth=50,
        frozen_stages=-1,
        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),
        norm_cfg=dict(requires_grad=False, type='SyncBN'),
        num_stages=4,
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        style='pytorch',
        type='ResNet'),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            1024,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        test_cfg=dict(size_divisor=32),
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            256,
            512,
            1024,
            2048,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=57,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 57
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict(
            backbone=dict(decay_mult=1.0, lr_mult=0.1),
            level_embed=dict(decay_mult=0.0, lr_mult=1.0),
            query_embed=dict(decay_mult=0.0, lr_mult=1.0),
            query_feat=dict(decay_mult=0.0, lr_mult=1.0)),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=80000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
randomness = dict(seed=268722126)
resume = False
seg_map_suffix = '.png'
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/seg_benchmark/seg_full_redone_FINAL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    classwise=True, iou_metrics=[
        'mIoU',
    ], type='IoUNanAbsent')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2048,
        1024,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(
    max_iters=80000, type='IterBasedTrainLoop', val_interval=80000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        data_prefix=dict(img_path='train/images', seg_map_path='train/masks'),
        data_root='/scratch/seg_benchmark/seg_full_redone_FINAL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                max_size=4096,
                resize_type='ResizeShortestEdge',
                scales=[
                    512,
                    614,
                    716,
                    819,
                    921,
                    1024,
                    1126,
                    1228,
                    1331,
                    1433,
                    1536,
                    1638,
                    1740,
                    1843,
                    1945,
                    2048,
                ],
                type='RandomChoiceResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    512,
                    1024,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        max_size=4096,
        resize_type='ResizeShortestEdge',
        scales=[
            512,
            614,
            716,
            819,
            921,
            1024,
            1126,
            1228,
            1331,
            1433,
            1536,
            1638,
            1740,
            1843,
            1945,
            2048,
        ],
        type='RandomChoiceResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        1024,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/seg_benchmark/seg_full_redone_FINAL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '/scratch/seg_benchmark/FINAL_seg_full_redone_redo_SEED/mask2former_R50'

07/30 16:40:14 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
07/30 16:40:14 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.bn1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.bn1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer1.0.bn1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer1.0.bn1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer1.0.bn2.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer1.0.bn2.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer1.0.bn3.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer1.0.bn3.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer1.0.downsample.1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer1.0.downsample.1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer1.1.bn1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer1.1.bn1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer1.1.bn2.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer1.1.bn2.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer1.1.bn3.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer1.1.bn3.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer1.2.bn1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer1.2.bn1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer1.2.bn2.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer1.2.bn2.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer1.2.bn3.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer1.2.bn3.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.0.bn1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.0.bn1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.0.bn2.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.0.bn2.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.0.bn3.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.0.bn3.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.0.downsample.1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.0.downsample.1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.1.bn1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.1.bn1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.1.bn2.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.1.bn2.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.1.bn3.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.1.bn3.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.2.bn1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.2.bn1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.2.bn2.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.2.bn2.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.2.bn3.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.2.bn3.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.3.bn1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.3.bn1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.3.bn2.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.3.bn2.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.3.bn3.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer2.3.bn3.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.0.bn1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.0.bn1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.0.bn2.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.0.bn2.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.0.bn3.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.0.bn3.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.0.downsample.1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.0.downsample.1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.1.bn1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.1.bn1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.1.bn2.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.1.bn2.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.1.bn3.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.1.bn3.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.2.bn1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.2.bn1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.2.bn2.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.2.bn2.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.2.bn3.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.2.bn3.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.3.bn1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.3.bn1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.3.bn2.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.3.bn2.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.3.bn3.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.3.bn3.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.4.bn1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.4.bn1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.4.bn2.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.4.bn2.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.4.bn3.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.4.bn3.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.5.bn1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.5.bn1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.5.bn2.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.5.bn2.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.5.bn3.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer3.5.bn3.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer4.0.bn1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer4.0.bn1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer4.0.bn2.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer4.0.bn2.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer4.0.bn3.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer4.0.bn3.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer4.0.downsample.1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer4.0.downsample.1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer4.1.bn1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer4.1.bn1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer4.1.bn2.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer4.1.bn2.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer4.1.bn3.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer4.1.bn3.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer4.2.bn1.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer4.2.bn1.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer4.2.bn2.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer4.2.bn2.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:lr=1e-05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:weight_decay=0.05
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:lr_mult=0.1
07/30 16:40:15 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:decay_mult=1.0
07/30 16:40:15 - mmengine - WARNING - backbone.layer4.2.bn3.weight is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - WARNING - backbone.layer4.2.bn3.bias is skipped since its requires_grad=False
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
07/30 16:40:15 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
07/30 16:40:15 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
07/30 16:40:16 - mmengine - INFO - load model from: torchvision://resnet50
07/30 16:40:16 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet50
07/30 16:40:16 - mmengine - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

07/30 16:40:16 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
07/30 16:40:16 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
07/30 16:40:16 - mmengine - INFO - Checkpoints will be saved to /scratch/seg_benchmark/FINAL_seg_full_redone_redo_SEED/mask2former_R50.
/home2/yasharora120/miniconda3/envs/mmseg/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400441250/work/aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
07/30 16:40:44 - mmengine - INFO - Iter(train) [   50/80000]  base_lr: 9.9945e-05 lr: 9.9945e-06  eta: 12:29:14  time: 0.4221  data_time: 0.0077  memory: 10587  grad_norm: 148.8318  loss: 98.0694  decode.loss_cls: 4.1104  decode.loss_mask: 2.2955  decode.loss_dice: 4.1903  decode.d0.loss_cls: 8.2725  decode.d0.loss_mask: 1.8595  decode.d0.loss_dice: 3.5204  decode.d1.loss_cls: 3.7203  decode.d1.loss_mask: 1.7803  decode.d1.loss_dice: 3.5003  decode.d2.loss_cls: 3.4006  decode.d2.loss_mask: 1.7984  decode.d2.loss_dice: 3.4207  decode.d3.loss_cls: 3.4341  decode.d3.loss_mask: 1.8286  decode.d3.loss_dice: 3.4785  decode.d4.loss_cls: 3.5175  decode.d4.loss_mask: 1.8694  decode.d4.loss_dice: 3.5342  decode.d5.loss_cls: 3.6018  decode.d5.loss_mask: 1.9093  decode.d5.loss_dice: 3.5708  decode.d6.loss_cls: 3.7040  decode.d6.loss_mask: 1.9600  decode.d6.loss_dice: 3.7339  decode.d7.loss_cls: 3.8259  decode.d7.loss_mask: 2.0957  decode.d7.loss_dice: 3.8138  decode.d8.loss_cls: 4.0161  decode.d8.loss_mask: 2.3208  decode.d8.loss_dice: 3.9860
07/30 16:41:05 - mmengine - INFO - Iter(train) [  100/80000]  base_lr: 9.9889e-05 lr: 9.9889e-06  eta: 10:55:54  time: 0.4235  data_time: 0.0078  memory: 5246  grad_norm: 239.9117  loss: 80.6174  decode.loss_cls: 3.3245  decode.loss_mask: 1.5852  decode.loss_dice: 3.0779  decode.d0.loss_cls: 8.2525  decode.d0.loss_mask: 1.3702  decode.d0.loss_dice: 3.0132  decode.d1.loss_cls: 3.3136  decode.d1.loss_mask: 1.3716  decode.d1.loss_dice: 2.8129  decode.d2.loss_cls: 2.9328  decode.d2.loss_mask: 1.4094  decode.d2.loss_dice: 2.7814  decode.d3.loss_cls: 2.9605  decode.d3.loss_mask: 1.4368  decode.d3.loss_dice: 2.8312  decode.d4.loss_cls: 2.9788  decode.d4.loss_mask: 1.5172  decode.d4.loss_dice: 2.8788  decode.d5.loss_cls: 3.0724  decode.d5.loss_mask: 1.5378  decode.d5.loss_dice: 2.8961  decode.d6.loss_cls: 3.1119  decode.d6.loss_mask: 1.5677  decode.d6.loss_dice: 2.9490  decode.d7.loss_cls: 3.1698  decode.d7.loss_mask: 1.5856  decode.d7.loss_dice: 2.9930  decode.d8.loss_cls: 3.3123  decode.d8.loss_mask: 1.5943  decode.d8.loss_dice: 2.9790
07/30 16:41:27 - mmengine - INFO - Iter(train) [  150/80000]  base_lr: 9.9832e-05 lr: 9.9832e-06  eta: 10:24:57  time: 0.4242  data_time: 0.0076  memory: 5265  grad_norm: 253.2759  loss: 70.2548  decode.loss_cls: 3.0135  decode.loss_mask: 1.3016  decode.loss_dice: 2.3884  decode.d0.loss_cls: 8.0868  decode.d0.loss_mask: 1.1588  decode.d0.loss_dice: 2.4803  decode.d1.loss_cls: 2.9036  decode.d1.loss_mask: 1.1890  decode.d1.loss_dice: 2.2981  decode.d2.loss_cls: 2.7574  decode.d2.loss_mask: 1.2158  decode.d2.loss_dice: 2.2274  decode.d3.loss_cls: 2.7690  decode.d3.loss_mask: 1.2808  decode.d3.loss_dice: 2.2366  decode.d4.loss_cls: 2.9537  decode.d4.loss_mask: 1.2959  decode.d4.loss_dice: 2.3285  decode.d5.loss_cls: 3.0680  decode.d5.loss_mask: 1.2936  decode.d5.loss_dice: 2.3070  decode.d6.loss_cls: 3.0140  decode.d6.loss_mask: 1.2983  decode.d6.loss_dice: 2.3071  decode.d7.loss_cls: 2.9260  decode.d7.loss_mask: 1.2908  decode.d7.loss_dice: 2.3090  decode.d8.loss_cls: 2.9708  decode.d8.loss_mask: 1.2818  decode.d8.loss_dice: 2.3031
07/30 16:41:48 - mmengine - INFO - Iter(train) [  200/80000]  base_lr: 9.9776e-05 lr: 9.9776e-06  eta: 10:09:38  time: 0.4246  data_time: 0.0077  memory: 5265  grad_norm: 254.1080  loss: 59.8407  decode.loss_cls: 2.9554  decode.loss_mask: 1.1255  decode.loss_dice: 1.6838  decode.d0.loss_cls: 7.9007  decode.d0.loss_mask: 1.0891  decode.d0.loss_dice: 1.9222  decode.d1.loss_cls: 2.6132  decode.d1.loss_mask: 1.1048  decode.d1.loss_dice: 1.6114  decode.d2.loss_cls: 2.7318  decode.d2.loss_mask: 1.1164  decode.d2.loss_dice: 1.4962  decode.d3.loss_cls: 2.7382  decode.d3.loss_mask: 1.0511  decode.d3.loss_dice: 1.4840  decode.d4.loss_cls: 2.6894  decode.d4.loss_mask: 1.0349  decode.d4.loss_dice: 1.4822  decode.d5.loss_cls: 2.6480  decode.d5.loss_mask: 1.0951  decode.d5.loss_dice: 1.5035  decode.d6.loss_cls: 2.7272  decode.d6.loss_mask: 1.1048  decode.d6.loss_dice: 1.5418  decode.d7.loss_cls: 2.8443  decode.d7.loss_mask: 1.1756  decode.d7.loss_dice: 1.6005  decode.d8.loss_cls: 2.9618  decode.d8.loss_mask: 1.1875  decode.d8.loss_dice: 1.6202
07/30 16:42:09 - mmengine - INFO - Iter(train) [  250/80000]  base_lr: 9.9720e-05 lr: 9.9720e-06  eta: 10:00:48  time: 0.4259  data_time: 0.0079  memory: 5279  grad_norm: 281.1287  loss: 51.8201  decode.loss_cls: 2.6013  decode.loss_mask: 0.8746  decode.loss_dice: 1.1735  decode.d0.loss_cls: 7.7875  decode.d0.loss_mask: 1.0136  decode.d0.loss_dice: 1.6232  decode.d1.loss_cls: 2.4580  decode.d1.loss_mask: 0.9438  decode.d1.loss_dice: 1.2883  decode.d2.loss_cls: 2.4166  decode.d2.loss_mask: 0.9455  decode.d2.loss_dice: 1.2153  decode.d3.loss_cls: 2.4000  decode.d3.loss_mask: 0.8832  decode.d3.loss_dice: 1.1553  decode.d4.loss_cls: 2.6255  decode.d4.loss_mask: 0.8536  decode.d4.loss_dice: 1.1540  decode.d5.loss_cls: 2.5574  decode.d5.loss_mask: 0.8889  decode.d5.loss_dice: 1.1859  decode.d6.loss_cls: 2.5123  decode.d6.loss_mask: 0.8763  decode.d6.loss_dice: 1.1562  decode.d7.loss_cls: 2.5167  decode.d7.loss_mask: 0.8979  decode.d7.loss_dice: 1.2229  decode.d8.loss_cls: 2.5423  decode.d8.loss_mask: 0.8902  decode.d8.loss_dice: 1.1603
07/30 16:42:30 - mmengine - INFO - Iter(train) [  300/80000]  base_lr: 9.9664e-05 lr: 9.9664e-06  eta: 9:54:39  time: 0.4264  data_time: 0.0079  memory: 5246  grad_norm: 362.1981  loss: 51.3095  decode.loss_cls: 2.6214  decode.loss_mask: 1.0003  decode.loss_dice: 1.0785  decode.d0.loss_cls: 7.5857  decode.d0.loss_mask: 0.9980  decode.d0.loss_dice: 1.4419  decode.d1.loss_cls: 2.5978  decode.d1.loss_mask: 0.9314  decode.d1.loss_dice: 1.1180  decode.d2.loss_cls: 2.5455  decode.d2.loss_mask: 0.9011  decode.d2.loss_dice: 1.0297  decode.d3.loss_cls: 2.5925  decode.d3.loss_mask: 0.9450  decode.d3.loss_dice: 1.0445  decode.d4.loss_cls: 2.6783  decode.d4.loss_mask: 0.8656  decode.d4.loss_dice: 0.9797  decode.d5.loss_cls: 2.6360  decode.d5.loss_mask: 0.8994  decode.d5.loss_dice: 0.9692  decode.d6.loss_cls: 2.7026  decode.d6.loss_mask: 0.9043  decode.d6.loss_dice: 0.9853  decode.d7.loss_cls: 2.6880  decode.d7.loss_mask: 0.9188  decode.d7.loss_dice: 0.9957  decode.d8.loss_cls: 2.6586  decode.d8.loss_mask: 0.9559  decode.d8.loss_dice: 1.0407
07/30 16:42:52 - mmengine - INFO - Iter(train) [  350/80000]  base_lr: 9.9607e-05 lr: 9.9607e-06  eta: 9:50:15  time: 0.4270  data_time: 0.0079  memory: 5246  grad_norm: 280.9033  loss: 50.5941  decode.loss_cls: 2.6627  decode.loss_mask: 0.7725  decode.loss_dice: 1.0672  decode.d0.loss_cls: 7.4082  decode.d0.loss_mask: 0.8484  decode.d0.loss_dice: 1.3956  decode.d1.loss_cls: 2.7835  decode.d1.loss_mask: 0.7320  decode.d1.loss_dice: 1.1389  decode.d2.loss_cls: 2.7596  decode.d2.loss_mask: 0.7477  decode.d2.loss_dice: 1.0384  decode.d3.loss_cls: 2.7657  decode.d3.loss_mask: 0.7150  decode.d3.loss_dice: 1.0446  decode.d4.loss_cls: 2.8106  decode.d4.loss_mask: 0.7517  decode.d4.loss_dice: 1.0325  decode.d5.loss_cls: 2.7618  decode.d5.loss_mask: 0.7655  decode.d5.loss_dice: 1.0188  decode.d6.loss_cls: 2.6751  decode.d6.loss_mask: 0.7968  decode.d6.loss_dice: 1.0348  decode.d7.loss_cls: 2.7078  decode.d7.loss_mask: 0.8096  decode.d7.loss_dice: 1.0431  decode.d8.loss_cls: 2.6808  decode.d8.loss_mask: 0.8036  decode.d8.loss_dice: 1.0215
07/30 16:43:13 - mmengine - INFO - Iter(train) [  400/80000]  base_lr: 9.9551e-05 lr: 9.9551e-06  eta: 9:47:34  time: 0.4463  data_time: 0.0079  memory: 5265  grad_norm: 282.8290  loss: 48.1193  decode.loss_cls: 2.6582  decode.loss_mask: 0.7194  decode.loss_dice: 0.9113  decode.d0.loss_cls: 7.2840  decode.d0.loss_mask: 0.8126  decode.d0.loss_dice: 1.2772  decode.d1.loss_cls: 2.5661  decode.d1.loss_mask: 0.7760  decode.d1.loss_dice: 1.0041  decode.d2.loss_cls: 2.5760  decode.d2.loss_mask: 0.7375  decode.d2.loss_dice: 0.9126  decode.d3.loss_cls: 2.7048  decode.d3.loss_mask: 0.6704  decode.d3.loss_dice: 0.8624  decode.d4.loss_cls: 2.8388  decode.d4.loss_mask: 0.6754  decode.d4.loss_dice: 0.8798  decode.d5.loss_cls: 2.7985  decode.d5.loss_mask: 0.6820  decode.d5.loss_dice: 0.8823  decode.d6.loss_cls: 2.7726  decode.d6.loss_mask: 0.6902  decode.d6.loss_dice: 0.8612  decode.d7.loss_cls: 2.7287  decode.d7.loss_mask: 0.6791  decode.d7.loss_dice: 0.8700  decode.d8.loss_cls: 2.7047  decode.d8.loss_mask: 0.7014  decode.d8.loss_dice: 0.8821
07/30 16:43:35 - mmengine - INFO - Iter(train) [  450/80000]  base_lr: 9.9495e-05 lr: 9.9495e-06  eta: 9:44:54  time: 0.4288  data_time: 0.0081  memory: 5278  grad_norm: 291.7968  loss: 45.7651  decode.loss_cls: 2.5158  decode.loss_mask: 0.6722  decode.loss_dice: 0.8973  decode.d0.loss_cls: 7.1768  decode.d0.loss_mask: 0.8215  decode.d0.loss_dice: 1.1621  decode.d1.loss_cls: 2.5443  decode.d1.loss_mask: 0.7154  decode.d1.loss_dice: 0.8062  decode.d2.loss_cls: 2.5483  decode.d2.loss_mask: 0.6584  decode.d2.loss_dice: 0.7990  decode.d3.loss_cls: 2.5925  decode.d3.loss_mask: 0.6942  decode.d3.loss_dice: 0.7987  decode.d4.loss_cls: 2.6680  decode.d4.loss_mask: 0.6597  decode.d4.loss_dice: 0.7976  decode.d5.loss_cls: 2.6940  decode.d5.loss_mask: 0.6488  decode.d5.loss_dice: 0.7175  decode.d6.loss_cls: 2.6303  decode.d6.loss_mask: 0.6537  decode.d6.loss_dice: 0.7761  decode.d7.loss_cls: 2.6420  decode.d7.loss_mask: 0.7034  decode.d7.loss_dice: 0.7977  decode.d8.loss_cls: 2.5593  decode.d8.loss_mask: 0.6629  decode.d8.loss_dice: 0.7513
07/30 16:43:56 - mmengine - INFO - Iter(train) [  500/80000]  base_lr: 9.9438e-05 lr: 9.9438e-06  eta: 9:42:44  time: 0.4286  data_time: 0.0080  memory: 5265  grad_norm: 224.9936  loss: 43.3307  decode.loss_cls: 2.5496  decode.loss_mask: 0.5198  decode.loss_dice: 0.7385  decode.d0.loss_cls: 7.0475  decode.d0.loss_mask: 0.6568  decode.d0.loss_dice: 1.0330  decode.d1.loss_cls: 2.5726  decode.d1.loss_mask: 0.6186  decode.d1.loss_dice: 0.8291  decode.d2.loss_cls: 2.6208  decode.d2.loss_mask: 0.5255  decode.d2.loss_dice: 0.7064  decode.d3.loss_cls: 2.5675  decode.d3.loss_mask: 0.5278  decode.d3.loss_dice: 0.6998  decode.d4.loss_cls: 2.5982  decode.d4.loss_mask: 0.5208  decode.d4.loss_dice: 0.6880  decode.d5.loss_cls: 2.6054  decode.d5.loss_mask: 0.5262  decode.d5.loss_dice: 0.7041  decode.d6.loss_cls: 2.5337  decode.d6.loss_mask: 0.5333  decode.d6.loss_dice: 0.7080  decode.d7.loss_cls: 2.6723  decode.d7.loss_mask: 0.5221  decode.d7.loss_dice: 0.7154  decode.d8.loss_cls: 2.5275  decode.d8.loss_mask: 0.5361  decode.d8.loss_dice: 0.7261
07/30 16:44:17 - mmengine - INFO - Iter(train) [  550/80000]  base_lr: 9.9382e-05 lr: 9.9382e-06  eta: 9:40:55  time: 0.4274  data_time: 0.0079  memory: 5227  grad_norm: 251.4347  loss: 39.9031  decode.loss_cls: 2.2705  decode.loss_mask: 0.6051  decode.loss_dice: 0.6562  decode.d0.loss_cls: 6.8479  decode.d0.loss_mask: 0.6804  decode.d0.loss_dice: 0.9847  decode.d1.loss_cls: 2.2236  decode.d1.loss_mask: 0.6340  decode.d1.loss_dice: 0.7775  decode.d2.loss_cls: 2.2697  decode.d2.loss_mask: 0.5868  decode.d2.loss_dice: 0.6377  decode.d3.loss_cls: 2.1922  decode.d3.loss_mask: 0.5669  decode.d3.loss_dice: 0.6493  decode.d4.loss_cls: 2.1859  decode.d4.loss_mask: 0.5885  decode.d4.loss_dice: 0.6564  decode.d5.loss_cls: 2.2106  decode.d5.loss_mask: 0.5952  decode.d5.loss_dice: 0.6333  decode.d6.loss_cls: 2.2312  decode.d6.loss_mask: 0.6031  decode.d6.loss_dice: 0.6220  decode.d7.loss_cls: 2.2837  decode.d7.loss_mask: 0.5785  decode.d7.loss_dice: 0.6518  decode.d8.loss_cls: 2.2760  decode.d8.loss_mask: 0.5742  decode.d8.loss_dice: 0.6306
07/30 16:44:39 - mmengine - INFO - Iter(train) [  600/80000]  base_lr: 9.9326e-05 lr: 9.9326e-06  eta: 9:39:24  time: 0.4310  data_time: 0.0083  memory: 5265  grad_norm: 243.8695  loss: 41.8288  decode.loss_cls: 2.3474  decode.loss_mask: 0.6195  decode.loss_dice: 0.7734  decode.d0.loss_cls: 6.7924  decode.d0.loss_mask: 0.6417  decode.d0.loss_dice: 1.0057  decode.d1.loss_cls: 2.3838  decode.d1.loss_mask: 0.6096  decode.d1.loss_dice: 0.7691  decode.d2.loss_cls: 2.2352  decode.d2.loss_mask: 0.5921  decode.d2.loss_dice: 0.7355  decode.d3.loss_cls: 2.2834  decode.d3.loss_mask: 0.5992  decode.d3.loss_dice: 0.7204  decode.d4.loss_cls: 2.3190  decode.d4.loss_mask: 0.6181  decode.d4.loss_dice: 0.7262  decode.d5.loss_cls: 2.3303  decode.d5.loss_mask: 0.5967  decode.d5.loss_dice: 0.7420  decode.d6.loss_cls: 2.3797  decode.d6.loss_mask: 0.6213  decode.d6.loss_dice: 0.7442  decode.d7.loss_cls: 2.4162  decode.d7.loss_mask: 0.6154  decode.d7.loss_dice: 0.8135  decode.d8.loss_cls: 2.3822  decode.d8.loss_mask: 0.6519  decode.d8.loss_dice: 0.7636
07/30 16:45:01 - mmengine - INFO - Iter(train) [  650/80000]  base_lr: 9.9270e-05 lr: 9.9270e-06  eta: 9:38:48  time: 0.4309  data_time: 0.0083  memory: 5246  grad_norm: 176.5365  loss: 35.0055  decode.loss_cls: 2.0117  decode.loss_mask: 0.5025  decode.loss_dice: 0.5243  decode.d0.loss_cls: 6.6487  decode.d0.loss_mask: 0.4975  decode.d0.loss_dice: 0.7883  decode.d1.loss_cls: 2.0936  decode.d1.loss_mask: 0.4367  decode.d1.loss_dice: 0.5347  decode.d2.loss_cls: 2.0727  decode.d2.loss_mask: 0.4591  decode.d2.loss_dice: 0.5305  decode.d3.loss_cls: 2.0658  decode.d3.loss_mask: 0.4420  decode.d3.loss_dice: 0.5153  decode.d4.loss_cls: 2.0562  decode.d4.loss_mask: 0.4318  decode.d4.loss_dice: 0.4963  decode.d5.loss_cls: 1.9967  decode.d5.loss_mask: 0.4548  decode.d5.loss_dice: 0.5175  decode.d6.loss_cls: 2.0403  decode.d6.loss_mask: 0.4434  decode.d6.loss_dice: 0.5019  decode.d7.loss_cls: 2.0465  decode.d7.loss_mask: 0.4472  decode.d7.loss_dice: 0.4969  decode.d8.loss_cls: 1.9846  decode.d8.loss_mask: 0.4503  decode.d8.loss_dice: 0.5178
07/30 16:45:22 - mmengine - INFO - Iter(train) [  700/80000]  base_lr: 9.9213e-05 lr: 9.9213e-06  eta: 9:37:53  time: 0.4345  data_time: 0.0085  memory: 5227  grad_norm: 244.7263  loss: 41.8554  decode.loss_cls: 2.4912  decode.loss_mask: 0.6532  decode.loss_dice: 0.7548  decode.d0.loss_cls: 6.5019  decode.d0.loss_mask: 0.6680  decode.d0.loss_dice: 0.9816  decode.d1.loss_cls: 2.3941  decode.d1.loss_mask: 0.6426  decode.d1.loss_dice: 0.7416  decode.d2.loss_cls: 2.4026  decode.d2.loss_mask: 0.6058  decode.d2.loss_dice: 0.6883  decode.d3.loss_cls: 2.3940  decode.d3.loss_mask: 0.6003  decode.d3.loss_dice: 0.6996  decode.d4.loss_cls: 2.4052  decode.d4.loss_mask: 0.6165  decode.d4.loss_dice: 0.6821  decode.d5.loss_cls: 2.4484  decode.d5.loss_mask: 0.6072  decode.d5.loss_dice: 0.6680  decode.d6.loss_cls: 2.4180  decode.d6.loss_mask: 0.6300  decode.d6.loss_dice: 0.7481  decode.d7.loss_cls: 2.3999  decode.d7.loss_mask: 0.5873  decode.d7.loss_dice: 0.6824  decode.d8.loss_cls: 2.3685  decode.d8.loss_mask: 0.6487  decode.d8.loss_dice: 0.7254
07/30 16:45:44 - mmengine - INFO - Iter(train) [  750/80000]  base_lr: 9.9157e-05 lr: 9.9157e-06  eta: 9:37:14  time: 0.4340  data_time: 0.0084  memory: 5277  grad_norm: 219.3145  loss: 38.7342  decode.loss_cls: 2.2707  decode.loss_mask: 0.5409  decode.loss_dice: 0.6230  decode.d0.loss_cls: 6.4010  decode.d0.loss_mask: 0.5795  decode.d0.loss_dice: 1.0392  decode.d1.loss_cls: 2.3382  decode.d1.loss_mask: 0.5058  decode.d1.loss_dice: 0.7043  decode.d2.loss_cls: 2.2712  decode.d2.loss_mask: 0.4842  decode.d2.loss_dice: 0.6194  decode.d3.loss_cls: 2.2190  decode.d3.loss_mask: 0.5218  decode.d3.loss_dice: 0.6671  decode.d4.loss_cls: 2.2998  decode.d4.loss_mask: 0.4803  decode.d4.loss_dice: 0.6450  decode.d5.loss_cls: 2.2398  decode.d5.loss_mask: 0.4806  decode.d5.loss_dice: 0.6620  decode.d6.loss_cls: 2.1885  decode.d6.loss_mask: 0.5293  decode.d6.loss_dice: 0.6492  decode.d7.loss_cls: 2.2340  decode.d7.loss_mask: 0.5116  decode.d7.loss_dice: 0.6259  decode.d8.loss_cls: 2.2362  decode.d8.loss_mask: 0.5140  decode.d8.loss_dice: 0.6527
07/30 16:46:06 - mmengine - INFO - Iter(train) [  800/80000]  base_lr: 9.9101e-05 lr: 9.9101e-06  eta: 9:36:37  time: 0.4336  data_time: 0.0083  memory: 5261  grad_norm: 163.0568  loss: 37.1823  decode.loss_cls: 2.2691  decode.loss_mask: 0.4583  decode.loss_dice: 0.6410  decode.d0.loss_cls: 6.2941  decode.d0.loss_mask: 0.5080  decode.d0.loss_dice: 0.9028  decode.d1.loss_cls: 2.2241  decode.d1.loss_mask: 0.4872  decode.d1.loss_dice: 0.6298  decode.d2.loss_cls: 2.2368  decode.d2.loss_mask: 0.4558  decode.d2.loss_dice: 0.5733  decode.d3.loss_cls: 2.2650  decode.d3.loss_mask: 0.4160  decode.d3.loss_dice: 0.5860  decode.d4.loss_cls: 2.2967  decode.d4.loss_mask: 0.4292  decode.d4.loss_dice: 0.6009  decode.d5.loss_cls: 2.2553  decode.d5.loss_mask: 0.4128  decode.d5.loss_dice: 0.5578  decode.d6.loss_cls: 2.1999  decode.d6.loss_mask: 0.4368  decode.d6.loss_dice: 0.5881  decode.d7.loss_cls: 2.1991  decode.d7.loss_mask: 0.4101  decode.d7.loss_dice: 0.5734  decode.d8.loss_cls: 2.2129  decode.d8.loss_mask: 0.4433  decode.d8.loss_dice: 0.6186
07/30 16:46:27 - mmengine - INFO - Iter(train) [  850/80000]  base_lr: 9.9044e-05 lr: 9.9044e-06  eta: 9:35:58  time: 0.4333  data_time: 0.0084  memory: 5279  grad_norm: 300.2624  loss: 37.1165  decode.loss_cls: 2.0903  decode.loss_mask: 0.5095  decode.loss_dice: 0.7014  decode.d0.loss_cls: 6.1216  decode.d0.loss_mask: 0.5890  decode.d0.loss_dice: 0.9608  decode.d1.loss_cls: 2.1443  decode.d1.loss_mask: 0.5717  decode.d1.loss_dice: 0.6617  decode.d2.loss_cls: 2.0958  decode.d2.loss_mask: 0.5149  decode.d2.loss_dice: 0.6272  decode.d3.loss_cls: 2.0537  decode.d3.loss_mask: 0.5212  decode.d3.loss_dice: 0.6537  decode.d4.loss_cls: 2.0855  decode.d4.loss_mask: 0.5200  decode.d4.loss_dice: 0.6757  decode.d5.loss_cls: 2.0628  decode.d5.loss_mask: 0.5142  decode.d5.loss_dice: 0.6712  decode.d6.loss_cls: 2.0040  decode.d6.loss_mask: 0.4983  decode.d6.loss_dice: 0.6623  decode.d7.loss_cls: 2.0628  decode.d7.loss_mask: 0.5003  decode.d7.loss_dice: 0.7015  decode.d8.loss_cls: 2.0947  decode.d8.loss_mask: 0.5123  decode.d8.loss_dice: 0.7339
07/30 16:46:49 - mmengine - INFO - Iter(train) [  900/80000]  base_lr: 9.8988e-05 lr: 9.8988e-06  eta: 9:35:26  time: 0.4348  data_time: 0.0085  memory: 5265  grad_norm: 209.2493  loss: 36.6007  decode.loss_cls: 2.1480  decode.loss_mask: 0.5387  decode.loss_dice: 0.5732  decode.d0.loss_cls: 5.8760  decode.d0.loss_mask: 0.5626  decode.d0.loss_dice: 0.7749  decode.d1.loss_cls: 2.1515  decode.d1.loss_mask: 0.4961  decode.d1.loss_dice: 0.5566  decode.d2.loss_cls: 2.0751  decode.d2.loss_mask: 0.5145  decode.d2.loss_dice: 0.5455  decode.d3.loss_cls: 2.1602  decode.d3.loss_mask: 0.5004  decode.d3.loss_dice: 0.5644  decode.d4.loss_cls: 2.2300  decode.d4.loss_mask: 0.5472  decode.d4.loss_dice: 0.5841  decode.d5.loss_cls: 2.2607  decode.d5.loss_mask: 0.5254  decode.d5.loss_dice: 0.5535  decode.d6.loss_cls: 2.1454  decode.d6.loss_mask: 0.5538  decode.d6.loss_dice: 0.5888  decode.d7.loss_cls: 2.2551  decode.d7.loss_mask: 0.5244  decode.d7.loss_dice: 0.5436  decode.d8.loss_cls: 2.1257  decode.d8.loss_mask: 0.5570  decode.d8.loss_dice: 0.5683
07/30 16:47:11 - mmengine - INFO - Iter(train) [  950/80000]  base_lr: 9.8932e-05 lr: 9.8932e-06  eta: 9:34:56  time: 0.4340  data_time: 0.0085  memory: 5246  grad_norm: 173.9467  loss: 32.4908  decode.loss_cls: 1.8372  decode.loss_mask: 0.4537  decode.loss_dice: 0.5129  decode.d0.loss_cls: 5.8775  decode.d0.loss_mask: 0.4989  decode.d0.loss_dice: 0.6775  decode.d1.loss_cls: 1.9529  decode.d1.loss_mask: 0.4971  decode.d1.loss_dice: 0.5399  decode.d2.loss_cls: 1.7847  decode.d2.loss_mask: 0.4860  decode.d2.loss_dice: 0.5384  decode.d3.loss_cls: 1.9269  decode.d3.loss_mask: 0.4757  decode.d3.loss_dice: 0.5104  decode.d4.loss_cls: 1.7381  decode.d4.loss_mask: 0.4893  decode.d4.loss_dice: 0.5393  decode.d5.loss_cls: 1.7605  decode.d5.loss_mask: 0.4807  decode.d5.loss_dice: 0.5264  decode.d6.loss_cls: 1.7231  decode.d6.loss_mask: 0.4756  decode.d6.loss_dice: 0.5250  decode.d7.loss_cls: 1.8450  decode.d7.loss_mask: 0.4681  decode.d7.loss_dice: 0.5335  decode.d8.loss_cls: 1.8113  decode.d8.loss_mask: 0.4739  decode.d8.loss_dice: 0.5319
07/30 16:47:32 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 16:47:32 - mmengine - INFO - Iter(train) [ 1000/80000]  base_lr: 9.8875e-05 lr: 9.8875e-06  eta: 9:34:27  time: 0.4343  data_time: 0.0086  memory: 5265  grad_norm: 147.4448  loss: 31.0227  decode.loss_cls: 1.7119  decode.loss_mask: 0.4397  decode.loss_dice: 0.5094  decode.d0.loss_cls: 5.6211  decode.d0.loss_mask: 0.4714  decode.d0.loss_dice: 0.7020  decode.d1.loss_cls: 1.7760  decode.d1.loss_mask: 0.4291  decode.d1.loss_dice: 0.5708  decode.d2.loss_cls: 1.7178  decode.d2.loss_mask: 0.4146  decode.d2.loss_dice: 0.5283  decode.d3.loss_cls: 1.7053  decode.d3.loss_mask: 0.4307  decode.d3.loss_dice: 0.5111  decode.d4.loss_cls: 1.7297  decode.d4.loss_mask: 0.4228  decode.d4.loss_dice: 0.5074  decode.d5.loss_cls: 1.7106  decode.d5.loss_mask: 0.4408  decode.d5.loss_dice: 0.5088  decode.d6.loss_cls: 1.7558  decode.d6.loss_mask: 0.4398  decode.d6.loss_dice: 0.5388  decode.d7.loss_cls: 1.7667  decode.d7.loss_mask: 0.4314  decode.d7.loss_dice: 0.5086  decode.d8.loss_cls: 1.7318  decode.d8.loss_mask: 0.4457  decode.d8.loss_dice: 0.5449
07/30 16:47:54 - mmengine - INFO - Iter(train) [ 1050/80000]  base_lr: 9.8819e-05 lr: 9.8819e-06  eta: 9:33:58  time: 0.4353  data_time: 0.0086  memory: 5265  grad_norm: 241.4757  loss: 33.9876  decode.loss_cls: 2.1434  decode.loss_mask: 0.4503  decode.loss_dice: 0.5436  decode.d0.loss_cls: 5.5528  decode.d0.loss_mask: 0.4969  decode.d0.loss_dice: 0.6830  decode.d1.loss_cls: 2.2907  decode.d1.loss_mask: 0.4843  decode.d1.loss_dice: 0.5374  decode.d2.loss_cls: 2.1843  decode.d2.loss_mask: 0.4356  decode.d2.loss_dice: 0.4789  decode.d3.loss_cls: 2.0167  decode.d3.loss_mask: 0.4223  decode.d3.loss_dice: 0.4961  decode.d4.loss_cls: 2.0151  decode.d4.loss_mask: 0.4160  decode.d4.loss_dice: 0.4888  decode.d5.loss_cls: 1.9790  decode.d5.loss_mask: 0.4486  decode.d5.loss_dice: 0.4996  decode.d6.loss_cls: 2.0028  decode.d6.loss_mask: 0.4237  decode.d6.loss_dice: 0.4684  decode.d7.loss_cls: 2.0552  decode.d7.loss_mask: 0.4424  decode.d7.loss_dice: 0.5022  decode.d8.loss_cls: 2.1038  decode.d8.loss_mask: 0.4375  decode.d8.loss_dice: 0.4882
07/30 16:48:16 - mmengine - INFO - Iter(train) [ 1100/80000]  base_lr: 9.8763e-05 lr: 9.8763e-06  eta: 9:33:30  time: 0.4353  data_time: 0.0087  memory: 5277  grad_norm: 273.1386  loss: 34.9038  decode.loss_cls: 2.0046  decode.loss_mask: 0.4843  decode.loss_dice: 0.5524  decode.d0.loss_cls: 5.3970  decode.d0.loss_mask: 0.5726  decode.d0.loss_dice: 0.8117  decode.d1.loss_cls: 2.0321  decode.d1.loss_mask: 0.4925  decode.d1.loss_dice: 0.6426  decode.d2.loss_cls: 2.0030  decode.d2.loss_mask: 0.5009  decode.d2.loss_dice: 0.5804  decode.d3.loss_cls: 2.0330  decode.d3.loss_mask: 0.4819  decode.d3.loss_dice: 0.5706  decode.d4.loss_cls: 2.1067  decode.d4.loss_mask: 0.5211  decode.d4.loss_dice: 0.6359  decode.d5.loss_cls: 2.0374  decode.d5.loss_mask: 0.5166  decode.d5.loss_dice: 0.5840  decode.d6.loss_cls: 1.9862  decode.d6.loss_mask: 0.5088  decode.d6.loss_dice: 0.6072  decode.d7.loss_cls: 1.9872  decode.d7.loss_mask: 0.5014  decode.d7.loss_dice: 0.6444  decode.d8.loss_cls: 2.0002  decode.d8.loss_mask: 0.5310  decode.d8.loss_dice: 0.5760
07/30 16:48:38 - mmengine - INFO - Iter(train) [ 1150/80000]  base_lr: 9.8706e-05 lr: 9.8706e-06  eta: 9:33:03  time: 0.4345  data_time: 0.0087  memory: 5246  grad_norm: 279.3321  loss: 36.5418  decode.loss_cls: 2.1345  decode.loss_mask: 0.5470  decode.loss_dice: 0.6654  decode.d0.loss_cls: 5.4771  decode.d0.loss_mask: 0.5765  decode.d0.loss_dice: 0.7286  decode.d1.loss_cls: 2.1278  decode.d1.loss_mask: 0.5409  decode.d1.loss_dice: 0.6246  decode.d2.loss_cls: 2.1170  decode.d2.loss_mask: 0.4797  decode.d2.loss_dice: 0.5545  decode.d3.loss_cls: 2.1937  decode.d3.loss_mask: 0.4997  decode.d3.loss_dice: 0.5410  decode.d4.loss_cls: 2.1780  decode.d4.loss_mask: 0.5297  decode.d4.loss_dice: 0.5745  decode.d5.loss_cls: 2.1376  decode.d5.loss_mask: 0.5925  decode.d5.loss_dice: 0.5998  decode.d6.loss_cls: 2.0989  decode.d6.loss_mask: 0.6495  decode.d6.loss_dice: 0.6512  decode.d7.loss_cls: 2.0915  decode.d7.loss_mask: 0.5747  decode.d7.loss_dice: 0.6618  decode.d8.loss_cls: 2.2005  decode.d8.loss_mask: 0.5507  decode.d8.loss_dice: 0.6432
07/30 16:48:59 - mmengine - INFO - Iter(train) [ 1200/80000]  base_lr: 9.8650e-05 lr: 9.8650e-06  eta: 9:32:36  time: 0.4345  data_time: 0.0087  memory: 5305  grad_norm: 224.4113  loss: 32.7327  decode.loss_cls: 1.9853  decode.loss_mask: 0.4776  decode.loss_dice: 0.4712  decode.d0.loss_cls: 5.2309  decode.d0.loss_mask: 0.5052  decode.d0.loss_dice: 0.5834  decode.d1.loss_cls: 2.0886  decode.d1.loss_mask: 0.4451  decode.d1.loss_dice: 0.4823  decode.d2.loss_cls: 1.9230  decode.d2.loss_mask: 0.4472  decode.d2.loss_dice: 0.4554  decode.d3.loss_cls: 1.9722  decode.d3.loss_mask: 0.4511  decode.d3.loss_dice: 0.4686  decode.d4.loss_cls: 2.0372  decode.d4.loss_mask: 0.4334  decode.d4.loss_dice: 0.4623  decode.d5.loss_cls: 2.0094  decode.d5.loss_mask: 0.4748  decode.d5.loss_dice: 0.4684  decode.d6.loss_cls: 2.0469  decode.d6.loss_mask: 0.4559  decode.d6.loss_dice: 0.4927  decode.d7.loss_cls: 2.0400  decode.d7.loss_mask: 0.4441  decode.d7.loss_dice: 0.4632  decode.d8.loss_cls: 1.9391  decode.d8.loss_mask: 0.4908  decode.d8.loss_dice: 0.4874
07/30 16:49:21 - mmengine - INFO - Iter(train) [ 1250/80000]  base_lr: 9.8594e-05 lr: 9.8594e-06  eta: 9:32:09  time: 0.4344  data_time: 0.0086  memory: 5261  grad_norm: 254.7697  loss: 33.5446  decode.loss_cls: 1.9192  decode.loss_mask: 0.5132  decode.loss_dice: 0.5899  decode.d0.loss_cls: 5.0773  decode.d0.loss_mask: 0.6119  decode.d0.loss_dice: 0.8510  decode.d1.loss_cls: 1.9625  decode.d1.loss_mask: 0.4871  decode.d1.loss_dice: 0.6085  decode.d2.loss_cls: 1.8619  decode.d2.loss_mask: 0.5413  decode.d2.loss_dice: 0.6038  decode.d3.loss_cls: 1.8758  decode.d3.loss_mask: 0.4990  decode.d3.loss_dice: 0.5738  decode.d4.loss_cls: 1.8393  decode.d4.loss_mask: 0.5379  decode.d4.loss_dice: 0.5994  decode.d5.loss_cls: 1.9023  decode.d5.loss_mask: 0.5217  decode.d5.loss_dice: 0.6135  decode.d6.loss_cls: 1.8498  decode.d6.loss_mask: 0.4945  decode.d6.loss_dice: 0.6107  decode.d7.loss_cls: 1.8809  decode.d7.loss_mask: 0.5186  decode.d7.loss_dice: 0.5962  decode.d8.loss_cls: 1.8861  decode.d8.loss_mask: 0.5192  decode.d8.loss_dice: 0.5985
07/30 16:49:43 - mmengine - INFO - Iter(train) [ 1300/80000]  base_lr: 9.8537e-05 lr: 9.8537e-06  eta: 9:31:43  time: 0.4332  data_time: 0.0084  memory: 5277  grad_norm: 284.5433  loss: 33.2466  decode.loss_cls: 2.1133  decode.loss_mask: 0.4104  decode.loss_dice: 0.4780  decode.d0.loss_cls: 5.0131  decode.d0.loss_mask: 0.4695  decode.d0.loss_dice: 0.6571  decode.d1.loss_cls: 2.2101  decode.d1.loss_mask: 0.4254  decode.d1.loss_dice: 0.5060  decode.d2.loss_cls: 2.1730  decode.d2.loss_mask: 0.3864  decode.d2.loss_dice: 0.4440  decode.d3.loss_cls: 2.2280  decode.d3.loss_mask: 0.3981  decode.d3.loss_dice: 0.4772  decode.d4.loss_cls: 2.1669  decode.d4.loss_mask: 0.4118  decode.d4.loss_dice: 0.4736  decode.d5.loss_cls: 2.1487  decode.d5.loss_mask: 0.4452  decode.d5.loss_dice: 0.5147  decode.d6.loss_cls: 2.0570  decode.d6.loss_mask: 0.4066  decode.d6.loss_dice: 0.4689  decode.d7.loss_cls: 2.0725  decode.d7.loss_mask: 0.4145  decode.d7.loss_dice: 0.4668  decode.d8.loss_cls: 1.9529  decode.d8.loss_mask: 0.4015  decode.d8.loss_dice: 0.4554
07/30 16:50:04 - mmengine - INFO - Iter(train) [ 1350/80000]  base_lr: 9.8481e-05 lr: 9.8481e-06  eta: 9:31:16  time: 0.4343  data_time: 0.0089  memory: 5279  grad_norm: 209.5044  loss: 30.7974  decode.loss_cls: 1.6532  decode.loss_mask: 0.5318  decode.loss_dice: 0.5722  decode.d0.loss_cls: 4.8082  decode.d0.loss_mask: 0.5354  decode.d0.loss_dice: 0.7229  decode.d1.loss_cls: 1.8511  decode.d1.loss_mask: 0.4572  decode.d1.loss_dice: 0.5646  decode.d2.loss_cls: 1.6695  decode.d2.loss_mask: 0.4448  decode.d2.loss_dice: 0.4735  decode.d3.loss_cls: 1.7203  decode.d3.loss_mask: 0.4763  decode.d3.loss_dice: 0.5302  decode.d4.loss_cls: 1.6906  decode.d4.loss_mask: 0.5163  decode.d4.loss_dice: 0.5585  decode.d5.loss_cls: 1.7460  decode.d5.loss_mask: 0.4804  decode.d5.loss_dice: 0.5262  decode.d6.loss_cls: 1.6665  decode.d6.loss_mask: 0.5121  decode.d6.loss_dice: 0.5501  decode.d7.loss_cls: 1.6999  decode.d7.loss_mask: 0.5353  decode.d7.loss_dice: 0.5724  decode.d8.loss_cls: 1.6290  decode.d8.loss_mask: 0.5380  decode.d8.loss_dice: 0.5651
07/30 16:50:26 - mmengine - INFO - Iter(train) [ 1400/80000]  base_lr: 9.8425e-05 lr: 9.8425e-06  eta: 9:30:49  time: 0.4338  data_time: 0.0086  memory: 5279  grad_norm: 204.7853  loss: 31.4691  decode.loss_cls: 1.8935  decode.loss_mask: 0.4122  decode.loss_dice: 0.5271  decode.d0.loss_cls: 4.6430  decode.d0.loss_mask: 0.5428  decode.d0.loss_dice: 0.6869  decode.d1.loss_cls: 1.9547  decode.d1.loss_mask: 0.4202  decode.d1.loss_dice: 0.4831  decode.d2.loss_cls: 1.8876  decode.d2.loss_mask: 0.3931  decode.d2.loss_dice: 0.4388  decode.d3.loss_cls: 1.9659  decode.d3.loss_mask: 0.3958  decode.d3.loss_dice: 0.4730  decode.d4.loss_cls: 2.0224  decode.d4.loss_mask: 0.4015  decode.d4.loss_dice: 0.4653  decode.d5.loss_cls: 1.9325  decode.d5.loss_mask: 0.3924  decode.d5.loss_dice: 0.4757  decode.d6.loss_cls: 1.9346  decode.d6.loss_mask: 0.3986  decode.d6.loss_dice: 0.4582  decode.d7.loss_cls: 2.1490  decode.d7.loss_mask: 0.4145  decode.d7.loss_dice: 0.5071  decode.d8.loss_cls: 1.9073  decode.d8.loss_mask: 0.4113  decode.d8.loss_dice: 0.4807
07/30 16:50:48 - mmengine - INFO - Iter(train) [ 1450/80000]  base_lr: 9.8368e-05 lr: 9.8368e-06  eta: 9:30:24  time: 0.4341  data_time: 0.0088  memory: 5278  grad_norm: 216.9471  loss: 32.1202  decode.loss_cls: 2.0267  decode.loss_mask: 0.4820  decode.loss_dice: 0.4870  decode.d0.loss_cls: 4.5586  decode.d0.loss_mask: 0.5634  decode.d0.loss_dice: 0.6360  decode.d1.loss_cls: 2.0539  decode.d1.loss_mask: 0.4345  decode.d1.loss_dice: 0.4897  decode.d2.loss_cls: 1.9448  decode.d2.loss_mask: 0.4838  decode.d2.loss_dice: 0.5345  decode.d3.loss_cls: 1.9309  decode.d3.loss_mask: 0.4566  decode.d3.loss_dice: 0.4844  decode.d4.loss_cls: 2.0206  decode.d4.loss_mask: 0.4841  decode.d4.loss_dice: 0.5130  decode.d5.loss_cls: 1.9760  decode.d5.loss_mask: 0.4555  decode.d5.loss_dice: 0.4957  decode.d6.loss_cls: 1.8797  decode.d6.loss_mask: 0.4343  decode.d6.loss_dice: 0.4613  decode.d7.loss_cls: 1.9092  decode.d7.loss_mask: 0.4797  decode.d7.loss_dice: 0.5134  decode.d8.loss_cls: 1.9460  decode.d8.loss_mask: 0.4916  decode.d8.loss_dice: 0.4935
07/30 16:51:10 - mmengine - INFO - Iter(train) [ 1500/80000]  base_lr: 9.8312e-05 lr: 9.8312e-06  eta: 9:29:58  time: 0.4345  data_time: 0.0088  memory: 5244  grad_norm: 227.9999  loss: 30.3611  decode.loss_cls: 1.7688  decode.loss_mask: 0.5558  decode.loss_dice: 0.5230  decode.d0.loss_cls: 4.3753  decode.d0.loss_mask: 0.4867  decode.d0.loss_dice: 0.7028  decode.d1.loss_cls: 1.8437  decode.d1.loss_mask: 0.4656  decode.d1.loss_dice: 0.4602  decode.d2.loss_cls: 1.7761  decode.d2.loss_mask: 0.4280  decode.d2.loss_dice: 0.4360  decode.d3.loss_cls: 1.8570  decode.d3.loss_mask: 0.4331  decode.d3.loss_dice: 0.4510  decode.d4.loss_cls: 1.8263  decode.d4.loss_mask: 0.4355  decode.d4.loss_dice: 0.4585  decode.d5.loss_cls: 1.8148  decode.d5.loss_mask: 0.4351  decode.d5.loss_dice: 0.4675  decode.d6.loss_cls: 1.7867  decode.d6.loss_mask: 0.4682  decode.d6.loss_dice: 0.4808  decode.d7.loss_cls: 1.7834  decode.d7.loss_mask: 0.5209  decode.d7.loss_dice: 0.5574  decode.d8.loss_cls: 1.6977  decode.d8.loss_mask: 0.5390  decode.d8.loss_dice: 0.5261
07/30 16:51:31 - mmengine - INFO - Iter(train) [ 1550/80000]  base_lr: 9.8256e-05 lr: 9.8256e-06  eta: 9:29:33  time: 0.4343  data_time: 0.0089  memory: 5261  grad_norm: 197.5071  loss: 32.0327  decode.loss_cls: 1.8706  decode.loss_mask: 0.4287  decode.loss_dice: 0.6474  decode.d0.loss_cls: 4.3025  decode.d0.loss_mask: 0.5188  decode.d0.loss_dice: 0.7473  decode.d1.loss_cls: 1.8692  decode.d1.loss_mask: 0.4538  decode.d1.loss_dice: 0.6631  decode.d2.loss_cls: 1.8675  decode.d2.loss_mask: 0.4380  decode.d2.loss_dice: 0.6376  decode.d3.loss_cls: 1.8969  decode.d3.loss_mask: 0.4104  decode.d3.loss_dice: 0.5901  decode.d4.loss_cls: 1.8926  decode.d4.loss_mask: 0.4193  decode.d4.loss_dice: 0.6199  decode.d5.loss_cls: 1.9198  decode.d5.loss_mask: 0.4451  decode.d5.loss_dice: 0.6207  decode.d6.loss_cls: 1.8207  decode.d6.loss_mask: 0.4512  decode.d6.loss_dice: 0.6170  decode.d7.loss_cls: 1.8749  decode.d7.loss_mask: 0.4502  decode.d7.loss_dice: 0.6199  decode.d8.loss_cls: 1.8938  decode.d8.loss_mask: 0.4318  decode.d8.loss_dice: 0.6136
07/30 16:51:53 - mmengine - INFO - Iter(train) [ 1600/80000]  base_lr: 9.8199e-05 lr: 9.8199e-06  eta: 9:29:09  time: 0.4369  data_time: 0.0087  memory: 5227  grad_norm: 244.9828  loss: 29.3491  decode.loss_cls: 1.7720  decode.loss_mask: 0.3413  decode.loss_dice: 0.5232  decode.d0.loss_cls: 4.0867  decode.d0.loss_mask: 0.4318  decode.d0.loss_dice: 0.7051  decode.d1.loss_cls: 1.8967  decode.d1.loss_mask: 0.3401  decode.d1.loss_dice: 0.5418  decode.d2.loss_cls: 1.7642  decode.d2.loss_mask: 0.3692  decode.d2.loss_dice: 0.5192  decode.d3.loss_cls: 1.8770  decode.d3.loss_mask: 0.3467  decode.d3.loss_dice: 0.5077  decode.d4.loss_cls: 1.9253  decode.d4.loss_mask: 0.3256  decode.d4.loss_dice: 0.5042  decode.d5.loss_cls: 1.8198  decode.d5.loss_mask: 0.3022  decode.d5.loss_dice: 0.4906  decode.d6.loss_cls: 1.7714  decode.d6.loss_mask: 0.3133  decode.d6.loss_dice: 0.5135  decode.d7.loss_cls: 1.8843  decode.d7.loss_mask: 0.3350  decode.d7.loss_dice: 0.5029  decode.d8.loss_cls: 1.8209  decode.d8.loss_mask: 0.3191  decode.d8.loss_dice: 0.4986
07/30 16:52:15 - mmengine - INFO - Iter(train) [ 1650/80000]  base_lr: 9.8143e-05 lr: 9.8143e-06  eta: 9:28:44  time: 0.4339  data_time: 0.0089  memory: 5278  grad_norm: 216.8260  loss: 30.5444  decode.loss_cls: 1.9209  decode.loss_mask: 0.3711  decode.loss_dice: 0.4940  decode.d0.loss_cls: 4.0545  decode.d0.loss_mask: 0.4362  decode.d0.loss_dice: 0.6848  decode.d1.loss_cls: 1.9923  decode.d1.loss_mask: 0.3614  decode.d1.loss_dice: 0.5134  decode.d2.loss_cls: 1.8454  decode.d2.loss_mask: 0.3503  decode.d2.loss_dice: 0.4709  decode.d3.loss_cls: 1.8948  decode.d3.loss_mask: 0.3514  decode.d3.loss_dice: 0.4886  decode.d4.loss_cls: 1.9792  decode.d4.loss_mask: 0.3737  decode.d4.loss_dice: 0.5491  decode.d5.loss_cls: 1.9940  decode.d5.loss_mask: 0.3584  decode.d5.loss_dice: 0.5005  decode.d6.loss_cls: 1.9269  decode.d6.loss_mask: 0.3678  decode.d6.loss_dice: 0.4767  decode.d7.loss_cls: 2.0369  decode.d7.loss_mask: 0.3853  decode.d7.loss_dice: 0.5413  decode.d8.loss_cls: 1.9369  decode.d8.loss_mask: 0.3589  decode.d8.loss_dice: 0.5288
07/30 16:52:36 - mmengine - INFO - Iter(train) [ 1700/80000]  base_lr: 9.8087e-05 lr: 9.8087e-06  eta: 9:28:19  time: 0.4335  data_time: 0.0087  memory: 5244  grad_norm: 228.6314  loss: 26.0411  decode.loss_cls: 1.5275  decode.loss_mask: 0.3959  decode.loss_dice: 0.3882  decode.d0.loss_cls: 3.8118  decode.d0.loss_mask: 0.4734  decode.d0.loss_dice: 0.5656  decode.d1.loss_cls: 1.5262  decode.d1.loss_mask: 0.4251  decode.d1.loss_dice: 0.4239  decode.d2.loss_cls: 1.4479  decode.d2.loss_mask: 0.4033  decode.d2.loss_dice: 0.4386  decode.d3.loss_cls: 1.5009  decode.d3.loss_mask: 0.4157  decode.d3.loss_dice: 0.4384  decode.d4.loss_cls: 1.5484  decode.d4.loss_mask: 0.3978  decode.d4.loss_dice: 0.4263  decode.d5.loss_cls: 1.5535  decode.d5.loss_mask: 0.3882  decode.d5.loss_dice: 0.4240  decode.d6.loss_cls: 1.5134  decode.d6.loss_mask: 0.3816  decode.d6.loss_dice: 0.4410  decode.d7.loss_cls: 1.5820  decode.d7.loss_mask: 0.3983  decode.d7.loss_dice: 0.4194  decode.d8.loss_cls: 1.5919  decode.d8.loss_mask: 0.3874  decode.d8.loss_dice: 0.4054
07/30 16:52:58 - mmengine - INFO - Iter(train) [ 1750/80000]  base_lr: 9.8030e-05 lr: 9.8030e-06  eta: 9:27:55  time: 0.4356  data_time: 0.0086  memory: 5261  grad_norm: 187.4925  loss: 28.3959  decode.loss_cls: 1.7605  decode.loss_mask: 0.3846  decode.loss_dice: 0.4605  decode.d0.loss_cls: 3.7884  decode.d0.loss_mask: 0.4285  decode.d0.loss_dice: 0.6860  decode.d1.loss_cls: 1.9276  decode.d1.loss_mask: 0.3461  decode.d1.loss_dice: 0.4360  decode.d2.loss_cls: 1.8857  decode.d2.loss_mask: 0.3355  decode.d2.loss_dice: 0.4019  decode.d3.loss_cls: 1.7396  decode.d3.loss_mask: 0.3489  decode.d3.loss_dice: 0.4227  decode.d4.loss_cls: 1.7830  decode.d4.loss_mask: 0.3425  decode.d4.loss_dice: 0.4269  decode.d5.loss_cls: 1.7979  decode.d5.loss_mask: 0.3501  decode.d5.loss_dice: 0.4310  decode.d6.loss_cls: 1.7237  decode.d6.loss_mask: 0.3585  decode.d6.loss_dice: 0.4640  decode.d7.loss_cls: 1.7913  decode.d7.loss_mask: 0.3524  decode.d7.loss_dice: 0.4426  decode.d8.loss_cls: 1.8765  decode.d8.loss_mask: 0.4044  decode.d8.loss_dice: 0.4985
07/30 16:53:20 - mmengine - INFO - Iter(train) [ 1800/80000]  base_lr: 9.7974e-05 lr: 9.7974e-06  eta: 9:27:31  time: 0.4337  data_time: 0.0087  memory: 5246  grad_norm: 322.8570  loss: 26.7574  decode.loss_cls: 1.5121  decode.loss_mask: 0.4458  decode.loss_dice: 0.4507  decode.d0.loss_cls: 3.5653  decode.d0.loss_mask: 0.4678  decode.d0.loss_dice: 0.5576  decode.d1.loss_cls: 1.6122  decode.d1.loss_mask: 0.4253  decode.d1.loss_dice: 0.4592  decode.d2.loss_cls: 1.5490  decode.d2.loss_mask: 0.3949  decode.d2.loss_dice: 0.4178  decode.d3.loss_cls: 1.5925  decode.d3.loss_mask: 0.4207  decode.d3.loss_dice: 0.4521  decode.d4.loss_cls: 1.6434  decode.d4.loss_mask: 0.4172  decode.d4.loss_dice: 0.4347  decode.d5.loss_cls: 1.6886  decode.d5.loss_mask: 0.4172  decode.d5.loss_dice: 0.4346  decode.d6.loss_cls: 1.6812  decode.d6.loss_mask: 0.4107  decode.d6.loss_dice: 0.4157  decode.d7.loss_cls: 1.6191  decode.d7.loss_mask: 0.4111  decode.d7.loss_dice: 0.4175  decode.d8.loss_cls: 1.6162  decode.d8.loss_mask: 0.4140  decode.d8.loss_dice: 0.4130
07/30 16:53:42 - mmengine - INFO - Iter(train) [ 1850/80000]  base_lr: 9.7917e-05 lr: 9.7917e-06  eta: 9:27:06  time: 0.4336  data_time: 0.0085  memory: 5246  grad_norm: 266.5057  loss: 27.5104  decode.loss_cls: 1.5409  decode.loss_mask: 0.4692  decode.loss_dice: 0.5136  decode.d0.loss_cls: 3.3606  decode.d0.loss_mask: 0.5297  decode.d0.loss_dice: 0.6689  decode.d1.loss_cls: 1.6750  decode.d1.loss_mask: 0.4842  decode.d1.loss_dice: 0.5278  decode.d2.loss_cls: 1.5402  decode.d2.loss_mask: 0.4848  decode.d2.loss_dice: 0.5162  decode.d3.loss_cls: 1.6181  decode.d3.loss_mask: 0.4300  decode.d3.loss_dice: 0.4873  decode.d4.loss_cls: 1.5909  decode.d4.loss_mask: 0.4370  decode.d4.loss_dice: 0.4885  decode.d5.loss_cls: 1.5826  decode.d5.loss_mask: 0.4483  decode.d5.loss_dice: 0.5401  decode.d6.loss_cls: 1.5404  decode.d6.loss_mask: 0.4730  decode.d6.loss_dice: 0.5039  decode.d7.loss_cls: 1.5834  decode.d7.loss_mask: 0.4379  decode.d7.loss_dice: 0.5079  decode.d8.loss_cls: 1.5319  decode.d8.loss_mask: 0.4589  decode.d8.loss_dice: 0.5393
07/30 16:54:03 - mmengine - INFO - Iter(train) [ 1900/80000]  base_lr: 9.7861e-05 lr: 9.7861e-06  eta: 9:26:42  time: 0.4346  data_time: 0.0087  memory: 5245  grad_norm: 136.9429  loss: 24.7758  decode.loss_cls: 1.4541  decode.loss_mask: 0.4193  decode.loss_dice: 0.4574  decode.d0.loss_cls: 3.3087  decode.d0.loss_mask: 0.5072  decode.d0.loss_dice: 0.5766  decode.d1.loss_cls: 1.5629  decode.d1.loss_mask: 0.4015  decode.d1.loss_dice: 0.4263  decode.d2.loss_cls: 1.4330  decode.d2.loss_mask: 0.4003  decode.d2.loss_dice: 0.4363  decode.d3.loss_cls: 1.3645  decode.d3.loss_mask: 0.3975  decode.d3.loss_dice: 0.4277  decode.d4.loss_cls: 1.4243  decode.d4.loss_mask: 0.4038  decode.d4.loss_dice: 0.4425  decode.d5.loss_cls: 1.3435  decode.d5.loss_mask: 0.4199  decode.d5.loss_dice: 0.4032  decode.d6.loss_cls: 1.3915  decode.d6.loss_mask: 0.4487  decode.d6.loss_dice: 0.4107  decode.d7.loss_cls: 1.4046  decode.d7.loss_mask: 0.4077  decode.d7.loss_dice: 0.4552  decode.d8.loss_cls: 1.4305  decode.d8.loss_mask: 0.4005  decode.d8.loss_dice: 0.4159
07/30 16:54:25 - mmengine - INFO - Iter(train) [ 1950/80000]  base_lr: 9.7805e-05 lr: 9.7805e-06  eta: 9:26:18  time: 0.4339  data_time: 0.0086  memory: 5245  grad_norm: 145.6440  loss: 24.5259  decode.loss_cls: 1.5695  decode.loss_mask: 0.3375  decode.loss_dice: 0.3570  decode.d0.loss_cls: 3.2722  decode.d0.loss_mask: 0.3927  decode.d0.loss_dice: 0.5113  decode.d1.loss_cls: 1.6762  decode.d1.loss_mask: 0.3598  decode.d1.loss_dice: 0.3582  decode.d2.loss_cls: 1.5588  decode.d2.loss_mask: 0.3418  decode.d2.loss_dice: 0.3360  decode.d3.loss_cls: 1.5665  decode.d3.loss_mask: 0.3523  decode.d3.loss_dice: 0.3349  decode.d4.loss_cls: 1.5503  decode.d4.loss_mask: 0.3481  decode.d4.loss_dice: 0.3482  decode.d5.loss_cls: 1.5902  decode.d5.loss_mask: 0.3433  decode.d5.loss_dice: 0.3325  decode.d6.loss_cls: 1.5707  decode.d6.loss_mask: 0.3307  decode.d6.loss_dice: 0.3114  decode.d7.loss_cls: 1.5614  decode.d7.loss_mask: 0.3327  decode.d7.loss_dice: 0.3323  decode.d8.loss_cls: 1.5804  decode.d8.loss_mask: 0.3356  decode.d8.loss_dice: 0.3334
07/30 16:54:47 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 16:54:47 - mmengine - INFO - Iter(train) [ 2000/80000]  base_lr: 9.7748e-05 lr: 9.7748e-06  eta: 9:25:54  time: 0.4332  data_time: 0.0087  memory: 5261  grad_norm: 117.1344  loss: 22.4326  decode.loss_cls: 1.2193  decode.loss_mask: 0.4221  decode.loss_dice: 0.4128  decode.d0.loss_cls: 3.0027  decode.d0.loss_mask: 0.4614  decode.d0.loss_dice: 0.5188  decode.d1.loss_cls: 1.3128  decode.d1.loss_mask: 0.4083  decode.d1.loss_dice: 0.3950  decode.d2.loss_cls: 1.2202  decode.d2.loss_mask: 0.4004  decode.d2.loss_dice: 0.3811  decode.d3.loss_cls: 1.2834  decode.d3.loss_mask: 0.4016  decode.d3.loss_dice: 0.3819  decode.d4.loss_cls: 1.2032  decode.d4.loss_mask: 0.4267  decode.d4.loss_dice: 0.4148  decode.d5.loss_cls: 1.2344  decode.d5.loss_mask: 0.4193  decode.d5.loss_dice: 0.4068  decode.d6.loss_cls: 1.1924  decode.d6.loss_mask: 0.4092  decode.d6.loss_dice: 0.3705  decode.d7.loss_cls: 1.3186  decode.d7.loss_mask: 0.4044  decode.d7.loss_dice: 0.3806  decode.d8.loss_cls: 1.2290  decode.d8.loss_mask: 0.4059  decode.d8.loss_dice: 0.3951
07/30 16:55:09 - mmengine - INFO - Iter(train) [ 2050/80000]  base_lr: 9.7692e-05 lr: 9.7692e-06  eta: 9:25:36  time: 0.4340  data_time: 0.0087  memory: 5246  grad_norm: 173.7849  loss: 24.7726  decode.loss_cls: 1.6151  decode.loss_mask: 0.3637  decode.loss_dice: 0.4621  decode.d0.loss_cls: 3.0573  decode.d0.loss_mask: 0.3853  decode.d0.loss_dice: 0.5766  decode.d1.loss_cls: 1.5555  decode.d1.loss_mask: 0.3161  decode.d1.loss_dice: 0.4574  decode.d2.loss_cls: 1.4284  decode.d2.loss_mask: 0.3242  decode.d2.loss_dice: 0.4338  decode.d3.loss_cls: 1.4155  decode.d3.loss_mask: 0.3098  decode.d3.loss_dice: 0.4237  decode.d4.loss_cls: 1.5243  decode.d4.loss_mask: 0.3121  decode.d4.loss_dice: 0.3972  decode.d5.loss_cls: 1.5180  decode.d5.loss_mask: 0.3173  decode.d5.loss_dice: 0.4318  decode.d6.loss_cls: 1.5089  decode.d6.loss_mask: 0.3231  decode.d6.loss_dice: 0.4211  decode.d7.loss_cls: 1.5763  decode.d7.loss_mask: 0.3598  decode.d7.loss_dice: 0.4569  decode.d8.loss_cls: 1.6192  decode.d8.loss_mask: 0.3950  decode.d8.loss_dice: 0.4868
07/30 16:55:30 - mmengine - INFO - Iter(train) [ 2100/80000]  base_lr: 9.7635e-05 lr: 9.7635e-06  eta: 9:25:12  time: 0.4345  data_time: 0.0088  memory: 5265  grad_norm: 143.8010  loss: 22.8492  decode.loss_cls: 1.2986  decode.loss_mask: 0.4048  decode.loss_dice: 0.4176  decode.d0.loss_cls: 2.8834  decode.d0.loss_mask: 0.4108  decode.d0.loss_dice: 0.5645  decode.d1.loss_cls: 1.3751  decode.d1.loss_mask: 0.3227  decode.d1.loss_dice: 0.4181  decode.d2.loss_cls: 1.3013  decode.d2.loss_mask: 0.3195  decode.d2.loss_dice: 0.4166  decode.d3.loss_cls: 1.3111  decode.d3.loss_mask: 0.3278  decode.d3.loss_dice: 0.4052  decode.d4.loss_cls: 1.3577  decode.d4.loss_mask: 0.3280  decode.d4.loss_dice: 0.4133  decode.d5.loss_cls: 1.3278  decode.d5.loss_mask: 0.3148  decode.d5.loss_dice: 0.4073  decode.d6.loss_cls: 1.2808  decode.d6.loss_mask: 0.3724  decode.d6.loss_dice: 0.4339  decode.d7.loss_cls: 1.4391  decode.d7.loss_mask: 0.4041  decode.d7.loss_dice: 0.4325  decode.d8.loss_cls: 1.3188  decode.d8.loss_mask: 0.4042  decode.d8.loss_dice: 0.4373
07/30 16:55:52 - mmengine - INFO - Iter(train) [ 2150/80000]  base_lr: 9.7579e-05 lr: 9.7579e-06  eta: 9:24:48  time: 0.4333  data_time: 0.0086  memory: 5265  grad_norm: 204.1268  loss: 25.5039  decode.loss_cls: 1.5410  decode.loss_mask: 0.4413  decode.loss_dice: 0.4797  decode.d0.loss_cls: 2.8347  decode.d0.loss_mask: 0.4481  decode.d0.loss_dice: 0.5782  decode.d1.loss_cls: 1.6320  decode.d1.loss_mask: 0.4031  decode.d1.loss_dice: 0.4509  decode.d2.loss_cls: 1.4633  decode.d2.loss_mask: 0.3870  decode.d2.loss_dice: 0.4422  decode.d3.loss_cls: 1.6271  decode.d3.loss_mask: 0.3930  decode.d3.loss_dice: 0.4333  decode.d4.loss_cls: 1.6122  decode.d4.loss_mask: 0.4109  decode.d4.loss_dice: 0.4456  decode.d5.loss_cls: 1.5357  decode.d5.loss_mask: 0.3795  decode.d5.loss_dice: 0.4413  decode.d6.loss_cls: 1.4616  decode.d6.loss_mask: 0.3835  decode.d6.loss_dice: 0.4391  decode.d7.loss_cls: 1.5281  decode.d7.loss_mask: 0.4029  decode.d7.loss_dice: 0.4341  decode.d8.loss_cls: 1.6023  decode.d8.loss_mask: 0.4158  decode.d8.loss_dice: 0.4565
07/30 16:56:14 - mmengine - INFO - Iter(train) [ 2200/80000]  base_lr: 9.7523e-05 lr: 9.7523e-06  eta: 9:24:23  time: 0.4339  data_time: 0.0085  memory: 5245  grad_norm: 157.1168  loss: 21.9747  decode.loss_cls: 1.2717  decode.loss_mask: 0.3032  decode.loss_dice: 0.4125  decode.d0.loss_cls: 2.6499  decode.d0.loss_mask: 0.3127  decode.d0.loss_dice: 0.5004  decode.d1.loss_cls: 1.3861  decode.d1.loss_mask: 0.3254  decode.d1.loss_dice: 0.4417  decode.d2.loss_cls: 1.2428  decode.d2.loss_mask: 0.3200  decode.d2.loss_dice: 0.4486  decode.d3.loss_cls: 1.2708  decode.d3.loss_mask: 0.3286  decode.d3.loss_dice: 0.4262  decode.d4.loss_cls: 1.2847  decode.d4.loss_mask: 0.3356  decode.d4.loss_dice: 0.4360  decode.d5.loss_cls: 1.3384  decode.d5.loss_mask: 0.2955  decode.d5.loss_dice: 0.4545  decode.d6.loss_cls: 1.3384  decode.d6.loss_mask: 0.2987  decode.d6.loss_dice: 0.4180  decode.d7.loss_cls: 1.3805  decode.d7.loss_mask: 0.2884  decode.d7.loss_dice: 0.4314  decode.d8.loss_cls: 1.3189  decode.d8.loss_mask: 0.2997  decode.d8.loss_dice: 0.4153
07/30 16:56:35 - mmengine - INFO - Iter(train) [ 2250/80000]  base_lr: 9.7466e-05 lr: 9.7466e-06  eta: 9:24:00  time: 0.4340  data_time: 0.0086  memory: 5246  grad_norm: 154.2978  loss: 22.4453  decode.loss_cls: 1.2913  decode.loss_mask: 0.3018  decode.loss_dice: 0.3935  decode.d0.loss_cls: 2.7391  decode.d0.loss_mask: 0.3469  decode.d0.loss_dice: 0.5636  decode.d1.loss_cls: 1.5302  decode.d1.loss_mask: 0.3090  decode.d1.loss_dice: 0.4321  decode.d2.loss_cls: 1.3455  decode.d2.loss_mask: 0.3110  decode.d2.loss_dice: 0.4056  decode.d3.loss_cls: 1.3333  decode.d3.loss_mask: 0.3158  decode.d3.loss_dice: 0.4283  decode.d4.loss_cls: 1.4045  decode.d4.loss_mask: 0.2932  decode.d4.loss_dice: 0.4192  decode.d5.loss_cls: 1.3483  decode.d5.loss_mask: 0.3097  decode.d5.loss_dice: 0.4130  decode.d6.loss_cls: 1.3694  decode.d6.loss_mask: 0.3001  decode.d6.loss_dice: 0.4217  decode.d7.loss_cls: 1.3166  decode.d7.loss_mask: 0.3106  decode.d7.loss_dice: 0.4298  decode.d8.loss_cls: 1.3259  decode.d8.loss_mask: 0.3129  decode.d8.loss_dice: 0.4234
07/30 16:56:57 - mmengine - INFO - Iter(train) [ 2300/80000]  base_lr: 9.7410e-05 lr: 9.7410e-06  eta: 9:23:35  time: 0.4343  data_time: 0.0087  memory: 5245  grad_norm: 268.9599  loss: 27.0157  decode.loss_cls: 1.7598  decode.loss_mask: 0.3857  decode.loss_dice: 0.5150  decode.d0.loss_cls: 2.8820  decode.d0.loss_mask: 0.4192  decode.d0.loss_dice: 0.5690  decode.d1.loss_cls: 1.9211  decode.d1.loss_mask: 0.3609  decode.d1.loss_dice: 0.4552  decode.d2.loss_cls: 1.7302  decode.d2.loss_mask: 0.3579  decode.d2.loss_dice: 0.4495  decode.d3.loss_cls: 1.6809  decode.d3.loss_mask: 0.3489  decode.d3.loss_dice: 0.4610  decode.d4.loss_cls: 1.6707  decode.d4.loss_mask: 0.3490  decode.d4.loss_dice: 0.4365  decode.d5.loss_cls: 1.7307  decode.d5.loss_mask: 0.3608  decode.d5.loss_dice: 0.4728  decode.d6.loss_cls: 1.6034  decode.d6.loss_mask: 0.3843  decode.d6.loss_dice: 0.4890  decode.d7.loss_cls: 1.6503  decode.d7.loss_mask: 0.3769  decode.d7.loss_dice: 0.5119  decode.d8.loss_cls: 1.7700  decode.d8.loss_mask: 0.3774  decode.d8.loss_dice: 0.5357
07/30 16:57:19 - mmengine - INFO - Iter(train) [ 2350/80000]  base_lr: 9.7353e-05 lr: 9.7353e-06  eta: 9:23:13  time: 0.4346  data_time: 0.0086  memory: 5246  grad_norm: 206.3721  loss: 23.3647  decode.loss_cls: 1.3608  decode.loss_mask: 0.3765  decode.loss_dice: 0.4269  decode.d0.loss_cls: 2.6230  decode.d0.loss_mask: 0.4595  decode.d0.loss_dice: 0.5400  decode.d1.loss_cls: 1.4982  decode.d1.loss_mask: 0.3976  decode.d1.loss_dice: 0.4459  decode.d2.loss_cls: 1.3442  decode.d2.loss_mask: 0.4134  decode.d2.loss_dice: 0.4363  decode.d3.loss_cls: 1.3278  decode.d3.loss_mask: 0.3589  decode.d3.loss_dice: 0.4053  decode.d4.loss_cls: 1.3712  decode.d4.loss_mask: 0.3913  decode.d4.loss_dice: 0.4301  decode.d5.loss_cls: 1.3216  decode.d5.loss_mask: 0.3706  decode.d5.loss_dice: 0.4170  decode.d6.loss_cls: 1.3970  decode.d6.loss_mask: 0.3668  decode.d6.loss_dice: 0.4467  decode.d7.loss_cls: 1.4145  decode.d7.loss_mask: 0.3714  decode.d7.loss_dice: 0.4409  decode.d8.loss_cls: 1.4282  decode.d8.loss_mask: 0.3558  decode.d8.loss_dice: 0.4275
07/30 16:57:41 - mmengine - INFO - Iter(train) [ 2400/80000]  base_lr: 9.7297e-05 lr: 9.7297e-06  eta: 9:22:49  time: 0.4335  data_time: 0.0088  memory: 5279  grad_norm: 208.5313  loss: 21.6944  decode.loss_cls: 1.0489  decode.loss_mask: 0.5364  decode.loss_dice: 0.4691  decode.d0.loss_cls: 2.2059  decode.d0.loss_mask: 0.5487  decode.d0.loss_dice: 0.5494  decode.d1.loss_cls: 1.1117  decode.d1.loss_mask: 0.5471  decode.d1.loss_dice: 0.4838  decode.d2.loss_cls: 0.9527  decode.d2.loss_mask: 0.5428  decode.d2.loss_dice: 0.4773  decode.d3.loss_cls: 1.0239  decode.d3.loss_mask: 0.5382  decode.d3.loss_dice: 0.4796  decode.d4.loss_cls: 1.0383  decode.d4.loss_mask: 0.5068  decode.d4.loss_dice: 0.4607  decode.d5.loss_cls: 1.0249  decode.d5.loss_mask: 0.5269  decode.d5.loss_dice: 0.4704  decode.d6.loss_cls: 0.9667  decode.d6.loss_mask: 0.5343  decode.d6.loss_dice: 0.4834  decode.d7.loss_cls: 1.0985  decode.d7.loss_mask: 0.5271  decode.d7.loss_dice: 0.4537  decode.d8.loss_cls: 1.0747  decode.d8.loss_mask: 0.5230  decode.d8.loss_dice: 0.4896
07/30 16:58:02 - mmengine - INFO - Iter(train) [ 2450/80000]  base_lr: 9.7241e-05 lr: 9.7241e-06  eta: 9:22:27  time: 0.4354  data_time: 0.0090  memory: 5245  grad_norm: 204.4351  loss: 19.9498  decode.loss_cls: 1.1852  decode.loss_mask: 0.3185  decode.loss_dice: 0.3636  decode.d0.loss_cls: 2.3684  decode.d0.loss_mask: 0.3830  decode.d0.loss_dice: 0.4757  decode.d1.loss_cls: 1.2664  decode.d1.loss_mask: 0.3160  decode.d1.loss_dice: 0.3793  decode.d2.loss_cls: 1.0734  decode.d2.loss_mask: 0.3245  decode.d2.loss_dice: 0.3888  decode.d3.loss_cls: 1.0350  decode.d3.loss_mask: 0.3356  decode.d3.loss_dice: 0.3695  decode.d4.loss_cls: 1.1084  decode.d4.loss_mask: 0.3411  decode.d4.loss_dice: 0.3765  decode.d5.loss_cls: 1.1736  decode.d5.loss_mask: 0.3273  decode.d5.loss_dice: 0.3647  decode.d6.loss_cls: 1.1463  decode.d6.loss_mask: 0.3292  decode.d6.loss_dice: 0.3565  decode.d7.loss_cls: 1.1970  decode.d7.loss_mask: 0.3266  decode.d7.loss_dice: 0.3634  decode.d8.loss_cls: 1.2875  decode.d8.loss_mask: 0.3198  decode.d8.loss_dice: 0.3492
07/30 16:58:24 - mmengine - INFO - Iter(train) [ 2500/80000]  base_lr: 9.7184e-05 lr: 9.7184e-06  eta: 9:22:05  time: 0.4352  data_time: 0.0087  memory: 5261  grad_norm: 256.8330  loss: 26.5675  decode.loss_cls: 1.5847  decode.loss_mask: 0.3583  decode.loss_dice: 0.5146  decode.d0.loss_cls: 2.4904  decode.d0.loss_mask: 0.3946  decode.d0.loss_dice: 0.6987  decode.d1.loss_cls: 1.6716  decode.d1.loss_mask: 0.3585  decode.d1.loss_dice: 0.5491  decode.d2.loss_cls: 1.6429  decode.d2.loss_mask: 0.3906  decode.d2.loss_dice: 0.5561  decode.d3.loss_cls: 1.5922  decode.d3.loss_mask: 0.3799  decode.d3.loss_dice: 0.5322  decode.d4.loss_cls: 1.5740  decode.d4.loss_mask: 0.3808  decode.d4.loss_dice: 0.5599  decode.d5.loss_cls: 1.6117  decode.d5.loss_mask: 0.3565  decode.d5.loss_dice: 0.5444  decode.d6.loss_cls: 1.6202  decode.d6.loss_mask: 0.3725  decode.d6.loss_dice: 0.5682  decode.d7.loss_cls: 1.6548  decode.d7.loss_mask: 0.3855  decode.d7.loss_dice: 0.5913  decode.d8.loss_cls: 1.7600  decode.d8.loss_mask: 0.3517  decode.d8.loss_dice: 0.5219
07/30 16:58:46 - mmengine - INFO - Iter(train) [ 2550/80000]  base_lr: 9.7128e-05 lr: 9.7128e-06  eta: 9:21:42  time: 0.4345  data_time: 0.0086  memory: 5265  grad_norm: 144.4070  loss: 24.3550  decode.loss_cls: 1.4567  decode.loss_mask: 0.3065  decode.loss_dice: 0.5235  decode.d0.loss_cls: 2.4173  decode.d0.loss_mask: 0.3435  decode.d0.loss_dice: 0.6672  decode.d1.loss_cls: 1.4684  decode.d1.loss_mask: 0.3006  decode.d1.loss_dice: 0.5398  decode.d2.loss_cls: 1.4494  decode.d2.loss_mask: 0.3023  decode.d2.loss_dice: 0.5338  decode.d3.loss_cls: 1.4149  decode.d3.loss_mask: 0.3071  decode.d3.loss_dice: 0.5171  decode.d4.loss_cls: 1.4920  decode.d4.loss_mask: 0.3285  decode.d4.loss_dice: 0.5178  decode.d5.loss_cls: 1.4622  decode.d5.loss_mask: 0.3201  decode.d5.loss_dice: 0.5243  decode.d6.loss_cls: 1.5032  decode.d6.loss_mask: 0.3225  decode.d6.loss_dice: 0.5388  decode.d7.loss_cls: 1.5405  decode.d7.loss_mask: 0.3281  decode.d7.loss_dice: 0.5369  decode.d8.loss_cls: 1.5417  decode.d8.loss_mask: 0.3230  decode.d8.loss_dice: 0.5275
07/30 16:59:07 - mmengine - INFO - Iter(train) [ 2600/80000]  base_lr: 9.7071e-05 lr: 9.7071e-06  eta: 9:21:20  time: 0.4352  data_time: 0.0089  memory: 5265  grad_norm: 156.0786  loss: 22.8994  decode.loss_cls: 1.3415  decode.loss_mask: 0.3878  decode.loss_dice: 0.4095  decode.d0.loss_cls: 2.5040  decode.d0.loss_mask: 0.3770  decode.d0.loss_dice: 0.4638  decode.d1.loss_cls: 1.5274  decode.d1.loss_mask: 0.3517  decode.d1.loss_dice: 0.3675  decode.d2.loss_cls: 1.3037  decode.d2.loss_mask: 0.3943  decode.d2.loss_dice: 0.3643  decode.d3.loss_cls: 1.3751  decode.d3.loss_mask: 0.4060  decode.d3.loss_dice: 0.3734  decode.d4.loss_cls: 1.3999  decode.d4.loss_mask: 0.4154  decode.d4.loss_dice: 0.3967  decode.d5.loss_cls: 1.4309  decode.d5.loss_mask: 0.4029  decode.d5.loss_dice: 0.3558  decode.d6.loss_cls: 1.4032  decode.d6.loss_mask: 0.3920  decode.d6.loss_dice: 0.3589  decode.d7.loss_cls: 1.3958  decode.d7.loss_mask: 0.4070  decode.d7.loss_dice: 0.3768  decode.d8.loss_cls: 1.4110  decode.d8.loss_mask: 0.3976  decode.d8.loss_dice: 0.4083
07/30 16:59:29 - mmengine - INFO - Iter(train) [ 2650/80000]  base_lr: 9.7015e-05 lr: 9.7015e-06  eta: 9:20:57  time: 0.4355  data_time: 0.0089  memory: 5265  grad_norm: 184.7896  loss: 23.2342  decode.loss_cls: 1.3958  decode.loss_mask: 0.4067  decode.loss_dice: 0.3991  decode.d0.loss_cls: 2.4312  decode.d0.loss_mask: 0.4465  decode.d0.loss_dice: 0.4976  decode.d1.loss_cls: 1.4190  decode.d1.loss_mask: 0.4197  decode.d1.loss_dice: 0.4323  decode.d2.loss_cls: 1.3806  decode.d2.loss_mask: 0.4045  decode.d2.loss_dice: 0.4070  decode.d3.loss_cls: 1.3177  decode.d3.loss_mask: 0.3791  decode.d3.loss_dice: 0.4008  decode.d4.loss_cls: 1.3796  decode.d4.loss_mask: 0.3476  decode.d4.loss_dice: 0.3730  decode.d5.loss_cls: 1.4115  decode.d5.loss_mask: 0.3790  decode.d5.loss_dice: 0.4011  decode.d6.loss_cls: 1.4370  decode.d6.loss_mask: 0.3912  decode.d6.loss_dice: 0.4015  decode.d7.loss_cls: 1.5362  decode.d7.loss_mask: 0.3753  decode.d7.loss_dice: 0.3959  decode.d8.loss_cls: 1.4716  decode.d8.loss_mask: 0.3975  decode.d8.loss_dice: 0.3987
07/30 16:59:51 - mmengine - INFO - Iter(train) [ 2700/80000]  base_lr: 9.6958e-05 lr: 9.6958e-06  eta: 9:20:35  time: 0.4344  data_time: 0.0088  memory: 5245  grad_norm: 127.4927  loss: 20.3545  decode.loss_cls: 1.1650  decode.loss_mask: 0.3178  decode.loss_dice: 0.3693  decode.d0.loss_cls: 2.1323  decode.d0.loss_mask: 0.3687  decode.d0.loss_dice: 0.5212  decode.d1.loss_cls: 1.3094  decode.d1.loss_mask: 0.3306  decode.d1.loss_dice: 0.4219  decode.d2.loss_cls: 1.2182  decode.d2.loss_mask: 0.3231  decode.d2.loss_dice: 0.3957  decode.d3.loss_cls: 1.1712  decode.d3.loss_mask: 0.3367  decode.d3.loss_dice: 0.3774  decode.d4.loss_cls: 1.2489  decode.d4.loss_mask: 0.3230  decode.d4.loss_dice: 0.3660  decode.d5.loss_cls: 1.2332  decode.d5.loss_mask: 0.3151  decode.d5.loss_dice: 0.3759  decode.d6.loss_cls: 1.1757  decode.d6.loss_mask: 0.3385  decode.d6.loss_dice: 0.3978  decode.d7.loss_cls: 1.2127  decode.d7.loss_mask: 0.3328  decode.d7.loss_dice: 0.3781  decode.d8.loss_cls: 1.2241  decode.d8.loss_mask: 0.3167  decode.d8.loss_dice: 0.3577
07/30 17:00:13 - mmengine - INFO - Iter(train) [ 2750/80000]  base_lr: 9.6902e-05 lr: 9.6902e-06  eta: 9:20:11  time: 0.4344  data_time: 0.0086  memory: 5265  grad_norm: 166.2046  loss: 24.5704  decode.loss_cls: 1.7295  decode.loss_mask: 0.3190  decode.loss_dice: 0.4080  decode.d0.loss_cls: 2.5697  decode.d0.loss_mask: 0.3073  decode.d0.loss_dice: 0.4913  decode.d1.loss_cls: 1.7909  decode.d1.loss_mask: 0.3064  decode.d1.loss_dice: 0.4173  decode.d2.loss_cls: 1.5388  decode.d2.loss_mask: 0.3082  decode.d2.loss_dice: 0.3670  decode.d3.loss_cls: 1.6179  decode.d3.loss_mask: 0.3036  decode.d3.loss_dice: 0.3794  decode.d4.loss_cls: 1.5158  decode.d4.loss_mask: 0.3120  decode.d4.loss_dice: 0.4139  decode.d5.loss_cls: 1.5907  decode.d5.loss_mask: 0.3137  decode.d5.loss_dice: 0.3986  decode.d6.loss_cls: 1.6877  decode.d6.loss_mask: 0.3073  decode.d6.loss_dice: 0.4079  decode.d7.loss_cls: 1.6525  decode.d7.loss_mask: 0.3135  decode.d7.loss_dice: 0.4061  decode.d8.loss_cls: 1.6839  decode.d8.loss_mask: 0.3119  decode.d8.loss_dice: 0.4005
07/30 17:00:34 - mmengine - INFO - Iter(train) [ 2800/80000]  base_lr: 9.6846e-05 lr: 9.6846e-06  eta: 9:19:48  time: 0.4350  data_time: 0.0086  memory: 5229  grad_norm: 151.6318  loss: 21.4770  decode.loss_cls: 1.2846  decode.loss_mask: 0.3067  decode.loss_dice: 0.3555  decode.d0.loss_cls: 2.4023  decode.d0.loss_mask: 0.3579  decode.d0.loss_dice: 0.4817  decode.d1.loss_cls: 1.5525  decode.d1.loss_mask: 0.3301  decode.d1.loss_dice: 0.3424  decode.d2.loss_cls: 1.2879  decode.d2.loss_mask: 0.3092  decode.d2.loss_dice: 0.3410  decode.d3.loss_cls: 1.4125  decode.d3.loss_mask: 0.3090  decode.d3.loss_dice: 0.3388  decode.d4.loss_cls: 1.3645  decode.d4.loss_mask: 0.3009  decode.d4.loss_dice: 0.3329  decode.d5.loss_cls: 1.3485  decode.d5.loss_mask: 0.3120  decode.d5.loss_dice: 0.3559  decode.d6.loss_cls: 1.2781  decode.d6.loss_mask: 0.3113  decode.d6.loss_dice: 0.3531  decode.d7.loss_cls: 1.4189  decode.d7.loss_mask: 0.3033  decode.d7.loss_dice: 0.3430  decode.d8.loss_cls: 1.3895  decode.d8.loss_mask: 0.2960  decode.d8.loss_dice: 0.3568
07/30 17:00:56 - mmengine - INFO - Iter(train) [ 2850/80000]  base_lr: 9.6789e-05 lr: 9.6789e-06  eta: 9:19:25  time: 0.4341  data_time: 0.0088  memory: 5261  grad_norm: 207.3840  loss: 20.5620  decode.loss_cls: 1.2204  decode.loss_mask: 0.4437  decode.loss_dice: 0.3503  decode.d0.loss_cls: 2.0913  decode.d0.loss_mask: 0.4302  decode.d0.loss_dice: 0.4116  decode.d1.loss_cls: 1.2211  decode.d1.loss_mask: 0.4100  decode.d1.loss_dice: 0.3425  decode.d2.loss_cls: 1.0996  decode.d2.loss_mask: 0.4693  decode.d2.loss_dice: 0.3711  decode.d3.loss_cls: 1.0897  decode.d3.loss_mask: 0.4636  decode.d3.loss_dice: 0.3741  decode.d4.loss_cls: 1.1317  decode.d4.loss_mask: 0.4988  decode.d4.loss_dice: 0.3780  decode.d5.loss_cls: 1.1534  decode.d5.loss_mask: 0.4111  decode.d5.loss_dice: 0.3579  decode.d6.loss_cls: 1.1502  decode.d6.loss_mask: 0.4214  decode.d6.loss_dice: 0.3596  decode.d7.loss_cls: 1.2066  decode.d7.loss_mask: 0.4127  decode.d7.loss_dice: 0.3464  decode.d8.loss_cls: 1.1723  decode.d8.loss_mask: 0.4083  decode.d8.loss_dice: 0.3652
07/30 17:01:18 - mmengine - INFO - Iter(train) [ 2900/80000]  base_lr: 9.6733e-05 lr: 9.6733e-06  eta: 9:19:02  time: 0.4340  data_time: 0.0087  memory: 5245  grad_norm: 124.1459  loss: 19.8733  decode.loss_cls: 1.2671  decode.loss_mask: 0.3189  decode.loss_dice: 0.4359  decode.d0.loss_cls: 1.8483  decode.d0.loss_mask: 0.3330  decode.d0.loss_dice: 0.4793  decode.d1.loss_cls: 1.1173  decode.d1.loss_mask: 0.3370  decode.d1.loss_dice: 0.4214  decode.d2.loss_cls: 1.0430  decode.d2.loss_mask: 0.3277  decode.d2.loss_dice: 0.4564  decode.d3.loss_cls: 1.0850  decode.d3.loss_mask: 0.3243  decode.d3.loss_dice: 0.4437  decode.d4.loss_cls: 1.0928  decode.d4.loss_mask: 0.3259  decode.d4.loss_dice: 0.4493  decode.d5.loss_cls: 1.1616  decode.d5.loss_mask: 0.3210  decode.d5.loss_dice: 0.4236  decode.d6.loss_cls: 1.1664  decode.d6.loss_mask: 0.3236  decode.d6.loss_dice: 0.4439  decode.d7.loss_cls: 1.2189  decode.d7.loss_mask: 0.3180  decode.d7.loss_dice: 0.4290  decode.d8.loss_cls: 1.2019  decode.d8.loss_mask: 0.3192  decode.d8.loss_dice: 0.4401
07/30 17:01:40 - mmengine - INFO - Iter(train) [ 2950/80000]  base_lr: 9.6676e-05 lr: 9.6676e-06  eta: 9:18:40  time: 0.4340  data_time: 0.0087  memory: 5279  grad_norm: 144.0575  loss: 20.9766  decode.loss_cls: 1.2970  decode.loss_mask: 0.3223  decode.loss_dice: 0.4956  decode.d0.loss_cls: 2.0305  decode.d0.loss_mask: 0.3274  decode.d0.loss_dice: 0.5416  decode.d1.loss_cls: 1.2871  decode.d1.loss_mask: 0.3332  decode.d1.loss_dice: 0.4759  decode.d2.loss_cls: 1.1552  decode.d2.loss_mask: 0.3124  decode.d2.loss_dice: 0.4670  decode.d3.loss_cls: 1.2123  decode.d3.loss_mask: 0.3045  decode.d3.loss_dice: 0.4596  decode.d4.loss_cls: 1.1495  decode.d4.loss_mask: 0.3042  decode.d4.loss_dice: 0.4738  decode.d5.loss_cls: 1.2107  decode.d5.loss_mask: 0.2938  decode.d5.loss_dice: 0.4889  decode.d6.loss_cls: 1.1497  decode.d6.loss_mask: 0.3002  decode.d6.loss_dice: 0.4806  decode.d7.loss_cls: 1.2291  decode.d7.loss_mask: 0.3026  decode.d7.loss_dice: 0.4352  decode.d8.loss_cls: 1.3613  decode.d8.loss_mask: 0.3050  decode.d8.loss_dice: 0.4704
07/30 17:02:01 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 17:02:01 - mmengine - INFO - Iter(train) [ 3000/80000]  base_lr: 9.6620e-05 lr: 9.6620e-06  eta: 9:18:18  time: 0.4346  data_time: 0.0087  memory: 5244  grad_norm: 257.3001  loss: 22.2281  decode.loss_cls: 1.2135  decode.loss_mask: 0.4654  decode.loss_dice: 0.5331  decode.d0.loss_cls: 1.9703  decode.d0.loss_mask: 0.4505  decode.d0.loss_dice: 0.5499  decode.d1.loss_cls: 1.2327  decode.d1.loss_mask: 0.4438  decode.d1.loss_dice: 0.5140  decode.d2.loss_cls: 1.1407  decode.d2.loss_mask: 0.4608  decode.d2.loss_dice: 0.5016  decode.d3.loss_cls: 1.1801  decode.d3.loss_mask: 0.4568  decode.d3.loss_dice: 0.4873  decode.d4.loss_cls: 1.1854  decode.d4.loss_mask: 0.4578  decode.d4.loss_dice: 0.4834  decode.d5.loss_cls: 1.1907  decode.d5.loss_mask: 0.4733  decode.d5.loss_dice: 0.5068  decode.d6.loss_cls: 1.1743  decode.d6.loss_mask: 0.4224  decode.d6.loss_dice: 0.4693  decode.d7.loss_cls: 1.2528  decode.d7.loss_mask: 0.4311  decode.d7.loss_dice: 0.4523  decode.d8.loss_cls: 1.2696  decode.d8.loss_mask: 0.4237  decode.d8.loss_dice: 0.4347
07/30 17:02:23 - mmengine - INFO - Iter(train) [ 3050/80000]  base_lr: 9.6563e-05 lr: 9.6563e-06  eta: 9:17:55  time: 0.4338  data_time: 0.0087  memory: 5227  grad_norm: 144.4480  loss: 19.4760  decode.loss_cls: 1.0550  decode.loss_mask: 0.3269  decode.loss_dice: 0.4086  decode.d0.loss_cls: 1.9672  decode.d0.loss_mask: 0.3172  decode.d0.loss_dice: 0.4668  decode.d1.loss_cls: 1.1901  decode.d1.loss_mask: 0.3393  decode.d1.loss_dice: 0.4325  decode.d2.loss_cls: 1.1839  decode.d2.loss_mask: 0.3263  decode.d2.loss_dice: 0.3860  decode.d3.loss_cls: 1.1887  decode.d3.loss_mask: 0.3278  decode.d3.loss_dice: 0.3719  decode.d4.loss_cls: 1.1305  decode.d4.loss_mask: 0.3280  decode.d4.loss_dice: 0.3742  decode.d5.loss_cls: 1.1528  decode.d5.loss_mask: 0.3180  decode.d5.loss_dice: 0.3931  decode.d6.loss_cls: 1.0624  decode.d6.loss_mask: 0.3164  decode.d6.loss_dice: 0.3789  decode.d7.loss_cls: 1.1758  decode.d7.loss_mask: 0.3165  decode.d7.loss_dice: 0.3946  decode.d8.loss_cls: 1.1136  decode.d8.loss_mask: 0.3270  decode.d8.loss_dice: 0.4059
07/30 17:02:45 - mmengine - INFO - Iter(train) [ 3100/80000]  base_lr: 9.6507e-05 lr: 9.6507e-06  eta: 9:17:33  time: 0.4355  data_time: 0.0085  memory: 5245  grad_norm: 308.6335  loss: 23.8861  decode.loss_cls: 1.4275  decode.loss_mask: 0.4533  decode.loss_dice: 0.4630  decode.d0.loss_cls: 2.2754  decode.d0.loss_mask: 0.4448  decode.d0.loss_dice: 0.5744  decode.d1.loss_cls: 1.5327  decode.d1.loss_mask: 0.4197  decode.d1.loss_dice: 0.4573  decode.d2.loss_cls: 1.3747  decode.d2.loss_mask: 0.4184  decode.d2.loss_dice: 0.4478  decode.d3.loss_cls: 1.4133  decode.d3.loss_mask: 0.3922  decode.d3.loss_dice: 0.4463  decode.d4.loss_cls: 1.4567  decode.d4.loss_mask: 0.3926  decode.d4.loss_dice: 0.4492  decode.d5.loss_cls: 1.3935  decode.d5.loss_mask: 0.4016  decode.d5.loss_dice: 0.4583  decode.d6.loss_cls: 1.2831  decode.d6.loss_mask: 0.3929  decode.d6.loss_dice: 0.4461  decode.d7.loss_cls: 1.4022  decode.d7.loss_mask: 0.4743  decode.d7.loss_dice: 0.5077  decode.d8.loss_cls: 1.3909  decode.d8.loss_mask: 0.4279  decode.d8.loss_dice: 0.4681
07/30 17:03:06 - mmengine - INFO - Iter(train) [ 3150/80000]  base_lr: 9.6450e-05 lr: 9.6450e-06  eta: 9:17:10  time: 0.4351  data_time: 0.0088  memory: 5265  grad_norm: 174.7466  loss: 19.7644  decode.loss_cls: 1.1519  decode.loss_mask: 0.4065  decode.loss_dice: 0.3954  decode.d0.loss_cls: 1.8778  decode.d0.loss_mask: 0.4074  decode.d0.loss_dice: 0.4738  decode.d1.loss_cls: 1.1910  decode.d1.loss_mask: 0.3815  decode.d1.loss_dice: 0.4001  decode.d2.loss_cls: 1.1104  decode.d2.loss_mask: 0.3776  decode.d2.loss_dice: 0.3782  decode.d3.loss_cls: 1.0893  decode.d3.loss_mask: 0.3763  decode.d3.loss_dice: 0.3679  decode.d4.loss_cls: 1.0939  decode.d4.loss_mask: 0.3825  decode.d4.loss_dice: 0.3937  decode.d5.loss_cls: 1.1128  decode.d5.loss_mask: 0.3690  decode.d5.loss_dice: 0.3849  decode.d6.loss_cls: 1.1245  decode.d6.loss_mask: 0.3811  decode.d6.loss_dice: 0.3921  decode.d7.loss_cls: 1.1235  decode.d7.loss_mask: 0.3756  decode.d7.loss_dice: 0.3973  decode.d8.loss_cls: 1.0721  decode.d8.loss_mask: 0.3842  decode.d8.loss_dice: 0.3924
07/30 17:03:28 - mmengine - INFO - Iter(train) [ 3200/80000]  base_lr: 9.6394e-05 lr: 9.6394e-06  eta: 9:16:48  time: 0.4338  data_time: 0.0087  memory: 5265  grad_norm: 171.5174  loss: 17.9900  decode.loss_cls: 0.9921  decode.loss_mask: 0.3923  decode.loss_dice: 0.3352  decode.d0.loss_cls: 1.9083  decode.d0.loss_mask: 0.3891  decode.d0.loss_dice: 0.3994  decode.d1.loss_cls: 1.0416  decode.d1.loss_mask: 0.3736  decode.d1.loss_dice: 0.3249  decode.d2.loss_cls: 1.0030  decode.d2.loss_mask: 0.3810  decode.d2.loss_dice: 0.3192  decode.d3.loss_cls: 0.9919  decode.d3.loss_mask: 0.3799  decode.d3.loss_dice: 0.3343  decode.d4.loss_cls: 0.8679  decode.d4.loss_mask: 0.4015  decode.d4.loss_dice: 0.3503  decode.d5.loss_cls: 0.9425  decode.d5.loss_mask: 0.3947  decode.d5.loss_dice: 0.3473  decode.d6.loss_cls: 0.9436  decode.d6.loss_mask: 0.4061  decode.d6.loss_dice: 0.3649  decode.d7.loss_cls: 0.9200  decode.d7.loss_mask: 0.3921  decode.d7.loss_dice: 0.3568  decode.d8.loss_cls: 0.9878  decode.d8.loss_mask: 0.4011  decode.d8.loss_dice: 0.3475
07/30 17:03:50 - mmengine - INFO - Iter(train) [ 3250/80000]  base_lr: 9.6337e-05 lr: 9.6337e-06  eta: 9:16:25  time: 0.4329  data_time: 0.0087  memory: 5265  grad_norm: 148.3871  loss: 17.8134  decode.loss_cls: 1.0627  decode.loss_mask: 0.3271  decode.loss_dice: 0.3368  decode.d0.loss_cls: 1.7593  decode.d0.loss_mask: 0.4498  decode.d0.loss_dice: 0.4454  decode.d1.loss_cls: 1.0190  decode.d1.loss_mask: 0.3574  decode.d1.loss_dice: 0.3380  decode.d2.loss_cls: 0.9433  decode.d2.loss_mask: 0.3596  decode.d2.loss_dice: 0.3262  decode.d3.loss_cls: 1.0161  decode.d3.loss_mask: 0.3342  decode.d3.loss_dice: 0.2978  decode.d4.loss_cls: 0.9703  decode.d4.loss_mask: 0.3397  decode.d4.loss_dice: 0.3171  decode.d5.loss_cls: 0.9836  decode.d5.loss_mask: 0.3317  decode.d5.loss_dice: 0.3317  decode.d6.loss_cls: 0.9552  decode.d6.loss_mask: 0.3570  decode.d6.loss_dice: 0.3471  decode.d7.loss_cls: 1.0418  decode.d7.loss_mask: 0.3406  decode.d7.loss_dice: 0.3447  decode.d8.loss_cls: 1.1052  decode.d8.loss_mask: 0.3372  decode.d8.loss_dice: 0.3379
07/30 17:04:12 - mmengine - INFO - Iter(train) [ 3300/80000]  base_lr: 9.6281e-05 lr: 9.6281e-06  eta: 9:16:02  time: 0.4346  data_time: 0.0086  memory: 5279  grad_norm: 113.3174  loss: 20.1307  decode.loss_cls: 1.2018  decode.loss_mask: 0.2714  decode.loss_dice: 0.3611  decode.d0.loss_cls: 2.1086  decode.d0.loss_mask: 0.3319  decode.d0.loss_dice: 0.5601  decode.d1.loss_cls: 1.4449  decode.d1.loss_mask: 0.2674  decode.d1.loss_dice: 0.3749  decode.d2.loss_cls: 1.2069  decode.d2.loss_mask: 0.2663  decode.d2.loss_dice: 0.3645  decode.d3.loss_cls: 1.2006  decode.d3.loss_mask: 0.2638  decode.d3.loss_dice: 0.3612  decode.d4.loss_cls: 1.1595  decode.d4.loss_mask: 0.2657  decode.d4.loss_dice: 0.3822  decode.d5.loss_cls: 1.2154  decode.d5.loss_mask: 0.2691  decode.d5.loss_dice: 0.4002  decode.d6.loss_cls: 1.1814  decode.d6.loss_mask: 0.2715  decode.d6.loss_dice: 0.4046  decode.d7.loss_cls: 1.3509  decode.d7.loss_mask: 0.2818  decode.d7.loss_dice: 0.4125  decode.d8.loss_cls: 1.3091  decode.d8.loss_mask: 0.2656  decode.d8.loss_dice: 0.3755
07/30 17:04:33 - mmengine - INFO - Iter(train) [ 3350/80000]  base_lr: 9.6224e-05 lr: 9.6224e-06  eta: 9:15:40  time: 0.4352  data_time: 0.0088  memory: 5305  grad_norm: 118.0094  loss: 18.0866  decode.loss_cls: 1.0134  decode.loss_mask: 0.2836  decode.loss_dice: 0.3407  decode.d0.loss_cls: 1.9824  decode.d0.loss_mask: 0.3217  decode.d0.loss_dice: 0.4531  decode.d1.loss_cls: 1.1573  decode.d1.loss_mask: 0.2984  decode.d1.loss_dice: 0.3928  decode.d2.loss_cls: 1.0048  decode.d2.loss_mask: 0.2993  decode.d2.loss_dice: 0.3668  decode.d3.loss_cls: 1.0278  decode.d3.loss_mask: 0.2909  decode.d3.loss_dice: 0.3438  decode.d4.loss_cls: 1.0661  decode.d4.loss_mask: 0.3089  decode.d4.loss_dice: 0.3562  decode.d5.loss_cls: 1.0953  decode.d5.loss_mask: 0.2917  decode.d5.loss_dice: 0.3764  decode.d6.loss_cls: 1.0712  decode.d6.loss_mask: 0.2833  decode.d6.loss_dice: 0.3520  decode.d7.loss_cls: 1.0616  decode.d7.loss_mask: 0.2781  decode.d7.loss_dice: 0.3571  decode.d8.loss_cls: 0.9912  decode.d8.loss_mask: 0.2785  decode.d8.loss_dice: 0.3423
07/30 17:04:55 - mmengine - INFO - Iter(train) [ 3400/80000]  base_lr: 9.6168e-05 lr: 9.6168e-06  eta: 9:15:18  time: 0.4353  data_time: 0.0087  memory: 5265  grad_norm: 162.2533  loss: 20.6836  decode.loss_cls: 1.1971  decode.loss_mask: 0.3508  decode.loss_dice: 0.4355  decode.d0.loss_cls: 1.9217  decode.d0.loss_mask: 0.4257  decode.d0.loss_dice: 0.5302  decode.d1.loss_cls: 1.3450  decode.d1.loss_mask: 0.3330  decode.d1.loss_dice: 0.4172  decode.d2.loss_cls: 1.2079  decode.d2.loss_mask: 0.3502  decode.d2.loss_dice: 0.4272  decode.d3.loss_cls: 1.1972  decode.d3.loss_mask: 0.3525  decode.d3.loss_dice: 0.4331  decode.d4.loss_cls: 1.0642  decode.d4.loss_mask: 0.3897  decode.d4.loss_dice: 0.4404  decode.d5.loss_cls: 1.1188  decode.d5.loss_mask: 0.3718  decode.d5.loss_dice: 0.4326  decode.d6.loss_cls: 1.1293  decode.d6.loss_mask: 0.3414  decode.d6.loss_dice: 0.4264  decode.d7.loss_cls: 1.2096  decode.d7.loss_mask: 0.3936  decode.d7.loss_dice: 0.4486  decode.d8.loss_cls: 1.1896  decode.d8.loss_mask: 0.3613  decode.d8.loss_dice: 0.4421
07/30 17:05:17 - mmengine - INFO - Iter(train) [ 3450/80000]  base_lr: 9.6111e-05 lr: 9.6111e-06  eta: 9:14:55  time: 0.4339  data_time: 0.0087  memory: 5246  grad_norm: 200.8024  loss: 18.4679  decode.loss_cls: 0.9502  decode.loss_mask: 0.3111  decode.loss_dice: 0.3839  decode.d0.loss_cls: 1.9811  decode.d0.loss_mask: 0.3981  decode.d0.loss_dice: 0.4520  decode.d1.loss_cls: 1.2031  decode.d1.loss_mask: 0.3291  decode.d1.loss_dice: 0.4025  decode.d2.loss_cls: 0.9785  decode.d2.loss_mask: 0.3360  decode.d2.loss_dice: 0.3865  decode.d3.loss_cls: 0.9035  decode.d3.loss_mask: 0.3313  decode.d3.loss_dice: 0.3882  decode.d4.loss_cls: 0.9511  decode.d4.loss_mask: 0.3452  decode.d4.loss_dice: 0.3972  decode.d5.loss_cls: 0.9512  decode.d5.loss_mask: 0.3822  decode.d5.loss_dice: 0.4099  decode.d6.loss_cls: 0.9538  decode.d6.loss_mask: 0.3605  decode.d6.loss_dice: 0.3889  decode.d7.loss_cls: 1.1236  decode.d7.loss_mask: 0.3551  decode.d7.loss_dice: 0.4071  decode.d8.loss_cls: 1.0048  decode.d8.loss_mask: 0.3157  decode.d8.loss_dice: 0.3864
07/30 17:05:38 - mmengine - INFO - Iter(train) [ 3500/80000]  base_lr: 9.6055e-05 lr: 9.6055e-06  eta: 9:14:33  time: 0.4347  data_time: 0.0087  memory: 5265  grad_norm: 156.1428  loss: 22.7386  decode.loss_cls: 1.1997  decode.loss_mask: 0.4052  decode.loss_dice: 0.4869  decode.d0.loss_cls: 2.1033  decode.d0.loss_mask: 0.4089  decode.d0.loss_dice: 0.5139  decode.d1.loss_cls: 1.4291  decode.d1.loss_mask: 0.4370  decode.d1.loss_dice: 0.4933  decode.d2.loss_cls: 1.3205  decode.d2.loss_mask: 0.4423  decode.d2.loss_dice: 0.4833  decode.d3.loss_cls: 1.2785  decode.d3.loss_mask: 0.4435  decode.d3.loss_dice: 0.5152  decode.d4.loss_cls: 1.2427  decode.d4.loss_mask: 0.4560  decode.d4.loss_dice: 0.5146  decode.d5.loss_cls: 1.2989  decode.d5.loss_mask: 0.4461  decode.d5.loss_dice: 0.5177  decode.d6.loss_cls: 1.1385  decode.d6.loss_mask: 0.4341  decode.d6.loss_dice: 0.4880  decode.d7.loss_cls: 1.2751  decode.d7.loss_mask: 0.4148  decode.d7.loss_dice: 0.4822  decode.d8.loss_cls: 1.1994  decode.d8.loss_mask: 0.4091  decode.d8.loss_dice: 0.4608
07/30 17:06:00 - mmengine - INFO - Iter(train) [ 3550/80000]  base_lr: 9.5998e-05 lr: 9.5998e-06  eta: 9:14:12  time: 0.4358  data_time: 0.0088  memory: 5279  grad_norm: 136.8511  loss: 18.5666  decode.loss_cls: 1.0326  decode.loss_mask: 0.3057  decode.loss_dice: 0.3456  decode.d0.loss_cls: 1.9247  decode.d0.loss_mask: 0.3480  decode.d0.loss_dice: 0.4808  decode.d1.loss_cls: 1.3427  decode.d1.loss_mask: 0.2828  decode.d1.loss_dice: 0.3698  decode.d2.loss_cls: 1.1453  decode.d2.loss_mask: 0.3117  decode.d2.loss_dice: 0.3474  decode.d3.loss_cls: 1.1180  decode.d3.loss_mask: 0.3111  decode.d3.loss_dice: 0.3218  decode.d4.loss_cls: 1.0877  decode.d4.loss_mask: 0.2912  decode.d4.loss_dice: 0.3085  decode.d5.loss_cls: 1.1148  decode.d5.loss_mask: 0.3225  decode.d5.loss_dice: 0.3324  decode.d6.loss_cls: 0.9774  decode.d6.loss_mask: 0.3407  decode.d6.loss_dice: 0.3348  decode.d7.loss_cls: 1.1219  decode.d7.loss_mask: 0.3072  decode.d7.loss_dice: 0.3264  decode.d8.loss_cls: 1.0924  decode.d8.loss_mask: 0.2979  decode.d8.loss_dice: 0.3228
07/30 17:06:22 - mmengine - INFO - Iter(train) [ 3600/80000]  base_lr: 9.5942e-05 lr: 9.5942e-06  eta: 9:13:50  time: 0.4349  data_time: 0.0088  memory: 5279  grad_norm: 223.3956  loss: 20.3183  decode.loss_cls: 1.1404  decode.loss_mask: 0.4279  decode.loss_dice: 0.4148  decode.d0.loss_cls: 1.9119  decode.d0.loss_mask: 0.4095  decode.d0.loss_dice: 0.4984  decode.d1.loss_cls: 1.2935  decode.d1.loss_mask: 0.3943  decode.d1.loss_dice: 0.4351  decode.d2.loss_cls: 1.1097  decode.d2.loss_mask: 0.3947  decode.d2.loss_dice: 0.4086  decode.d3.loss_cls: 1.1201  decode.d3.loss_mask: 0.3813  decode.d3.loss_dice: 0.3958  decode.d4.loss_cls: 1.0754  decode.d4.loss_mask: 0.3747  decode.d4.loss_dice: 0.3927  decode.d5.loss_cls: 1.0545  decode.d5.loss_mask: 0.3979  decode.d5.loss_dice: 0.4099  decode.d6.loss_cls: 1.1002  decode.d6.loss_mask: 0.3821  decode.d6.loss_dice: 0.3941  decode.d7.loss_cls: 1.1859  decode.d7.loss_mask: 0.3775  decode.d7.loss_dice: 0.4026  decode.d8.loss_cls: 1.2124  decode.d8.loss_mask: 0.4043  decode.d8.loss_dice: 0.4179
07/30 17:06:44 - mmengine - INFO - Iter(train) [ 3650/80000]  base_lr: 9.5885e-05 lr: 9.5885e-06  eta: 9:13:28  time: 0.4353  data_time: 0.0089  memory: 5265  grad_norm: 119.5578  loss: 17.3097  decode.loss_cls: 0.9650  decode.loss_mask: 0.2958  decode.loss_dice: 0.3028  decode.d0.loss_cls: 2.0003  decode.d0.loss_mask: 0.3039  decode.d0.loss_dice: 0.4049  decode.d1.loss_cls: 1.2185  decode.d1.loss_mask: 0.2823  decode.d1.loss_dice: 0.3192  decode.d2.loss_cls: 0.9523  decode.d2.loss_mask: 0.2791  decode.d2.loss_dice: 0.3236  decode.d3.loss_cls: 0.9719  decode.d3.loss_mask: 0.2870  decode.d3.loss_dice: 0.3336  decode.d4.loss_cls: 1.0401  decode.d4.loss_mask: 0.2817  decode.d4.loss_dice: 0.2940  decode.d5.loss_cls: 1.0502  decode.d5.loss_mask: 0.2832  decode.d5.loss_dice: 0.3043  decode.d6.loss_cls: 0.9943  decode.d6.loss_mask: 0.2884  decode.d6.loss_dice: 0.3220  decode.d7.loss_cls: 1.0025  decode.d7.loss_mask: 0.2895  decode.d7.loss_dice: 0.3055  decode.d8.loss_cls: 1.0099  decode.d8.loss_mask: 0.2908  decode.d8.loss_dice: 0.3132
07/30 17:06:55 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 17:07:06 - mmengine - INFO - Iter(train) [ 3700/80000]  base_lr: 9.5829e-05 lr: 9.5829e-06  eta: 9:13:08  time: 0.4335  data_time: 0.0087  memory: 5246  grad_norm: 120.7349  loss: 15.6580  decode.loss_cls: 0.8317  decode.loss_mask: 0.2772  decode.loss_dice: 0.3077  decode.d0.loss_cls: 1.8185  decode.d0.loss_mask: 0.3153  decode.d0.loss_dice: 0.3678  decode.d1.loss_cls: 0.9993  decode.d1.loss_mask: 0.2958  decode.d1.loss_dice: 0.3013  decode.d2.loss_cls: 0.8019  decode.d2.loss_mask: 0.2826  decode.d2.loss_dice: 0.3052  decode.d3.loss_cls: 0.8818  decode.d3.loss_mask: 0.2850  decode.d3.loss_dice: 0.3158  decode.d4.loss_cls: 0.8731  decode.d4.loss_mask: 0.2901  decode.d4.loss_dice: 0.3056  decode.d5.loss_cls: 0.8408  decode.d5.loss_mask: 0.2879  decode.d5.loss_dice: 0.3138  decode.d6.loss_cls: 0.8671  decode.d6.loss_mask: 0.2855  decode.d6.loss_dice: 0.3236  decode.d7.loss_cls: 0.8511  decode.d7.loss_mask: 0.2902  decode.d7.loss_dice: 0.2999  decode.d8.loss_cls: 0.8555  decode.d8.loss_mask: 0.2898  decode.d8.loss_dice: 0.2970
07/30 17:07:27 - mmengine - INFO - Iter(train) [ 3750/80000]  base_lr: 9.5772e-05 lr: 9.5772e-06  eta: 9:12:46  time: 0.4342  data_time: 0.0085  memory: 5265  grad_norm: 106.3001  loss: 17.0311  decode.loss_cls: 1.0165  decode.loss_mask: 0.2459  decode.loss_dice: 0.3489  decode.d0.loss_cls: 1.8445  decode.d0.loss_mask: 0.2600  decode.d0.loss_dice: 0.4763  decode.d1.loss_cls: 1.1489  decode.d1.loss_mask: 0.2367  decode.d1.loss_dice: 0.3487  decode.d2.loss_cls: 0.9919  decode.d2.loss_mask: 0.2345  decode.d2.loss_dice: 0.3309  decode.d3.loss_cls: 0.9677  decode.d3.loss_mask: 0.2348  decode.d3.loss_dice: 0.3168  decode.d4.loss_cls: 1.0263  decode.d4.loss_mask: 0.2369  decode.d4.loss_dice: 0.3277  decode.d5.loss_cls: 1.0226  decode.d5.loss_mask: 0.2381  decode.d5.loss_dice: 0.3353  decode.d6.loss_cls: 1.0760  decode.d6.loss_mask: 0.2414  decode.d6.loss_dice: 0.3426  decode.d7.loss_cls: 1.0026  decode.d7.loss_mask: 0.2390  decode.d7.loss_dice: 0.3358  decode.d8.loss_cls: 1.0341  decode.d8.loss_mask: 0.2365  decode.d8.loss_dice: 0.3332
07/30 17:07:49 - mmengine - INFO - Iter(train) [ 3800/80000]  base_lr: 9.5716e-05 lr: 9.5716e-06  eta: 9:12:23  time: 0.4340  data_time: 0.0087  memory: 5265  grad_norm: 156.2088  loss: 18.3326  decode.loss_cls: 0.7735  decode.loss_mask: 0.4324  decode.loss_dice: 0.5003  decode.d0.loss_cls: 1.6486  decode.d0.loss_mask: 0.4555  decode.d0.loss_dice: 0.6006  decode.d1.loss_cls: 0.9935  decode.d1.loss_mask: 0.4427  decode.d1.loss_dice: 0.5389  decode.d2.loss_cls: 0.7659  decode.d2.loss_mask: 0.4192  decode.d2.loss_dice: 0.5045  decode.d3.loss_cls: 0.7837  decode.d3.loss_mask: 0.4186  decode.d3.loss_dice: 0.5031  decode.d4.loss_cls: 0.8104  decode.d4.loss_mask: 0.4201  decode.d4.loss_dice: 0.4995  decode.d5.loss_cls: 0.8026  decode.d5.loss_mask: 0.4141  decode.d5.loss_dice: 0.4797  decode.d6.loss_cls: 0.8106  decode.d6.loss_mask: 0.4190  decode.d6.loss_dice: 0.4816  decode.d7.loss_cls: 0.7611  decode.d7.loss_mask: 0.4340  decode.d7.loss_dice: 0.5019  decode.d8.loss_cls: 0.7804  decode.d8.loss_mask: 0.4197  decode.d8.loss_dice: 0.5169
07/30 17:08:11 - mmengine - INFO - Iter(train) [ 3850/80000]  base_lr: 9.5659e-05 lr: 9.5659e-06  eta: 9:12:01  time: 0.4345  data_time: 0.0087  memory: 5261  grad_norm: 148.5885  loss: 17.5692  decode.loss_cls: 0.9204  decode.loss_mask: 0.3074  decode.loss_dice: 0.3769  decode.d0.loss_cls: 1.9421  decode.d0.loss_mask: 0.2866  decode.d0.loss_dice: 0.4177  decode.d1.loss_cls: 1.2351  decode.d1.loss_mask: 0.2635  decode.d1.loss_dice: 0.3413  decode.d2.loss_cls: 1.0280  decode.d2.loss_mask: 0.2747  decode.d2.loss_dice: 0.3482  decode.d3.loss_cls: 0.9887  decode.d3.loss_mask: 0.2710  decode.d3.loss_dice: 0.3314  decode.d4.loss_cls: 1.0768  decode.d4.loss_mask: 0.2716  decode.d4.loss_dice: 0.3220  decode.d5.loss_cls: 0.9897  decode.d5.loss_mask: 0.2702  decode.d5.loss_dice: 0.3335  decode.d6.loss_cls: 0.9518  decode.d6.loss_mask: 0.2916  decode.d6.loss_dice: 0.3805  decode.d7.loss_cls: 1.0310  decode.d7.loss_mask: 0.2816  decode.d7.loss_dice: 0.3680  decode.d8.loss_cls: 1.0357  decode.d8.loss_mask: 0.2704  decode.d8.loss_dice: 0.3618
07/30 17:08:32 - mmengine - INFO - Iter(train) [ 3900/80000]  base_lr: 9.5603e-05 lr: 9.5603e-06  eta: 9:11:38  time: 0.4339  data_time: 0.0087  memory: 5246  grad_norm: 152.7398  loss: 20.8076  decode.loss_cls: 1.1985  decode.loss_mask: 0.3763  decode.loss_dice: 0.5201  decode.d0.loss_cls: 1.7867  decode.d0.loss_mask: 0.3991  decode.d0.loss_dice: 0.5586  decode.d1.loss_cls: 1.1336  decode.d1.loss_mask: 0.3667  decode.d1.loss_dice: 0.5005  decode.d2.loss_cls: 1.1305  decode.d2.loss_mask: 0.3660  decode.d2.loss_dice: 0.5080  decode.d3.loss_cls: 1.0555  decode.d3.loss_mask: 0.3590  decode.d3.loss_dice: 0.4989  decode.d4.loss_cls: 1.1743  decode.d4.loss_mask: 0.3620  decode.d4.loss_dice: 0.4918  decode.d5.loss_cls: 1.0951  decode.d5.loss_mask: 0.3665  decode.d5.loss_dice: 0.5022  decode.d6.loss_cls: 1.1472  decode.d6.loss_mask: 0.3676  decode.d6.loss_dice: 0.5035  decode.d7.loss_cls: 1.1345  decode.d7.loss_mask: 0.3601  decode.d7.loss_dice: 0.5066  decode.d8.loss_cls: 1.1222  decode.d8.loss_mask: 0.3825  decode.d8.loss_dice: 0.5336
07/30 17:08:54 - mmengine - INFO - Iter(train) [ 3950/80000]  base_lr: 9.5546e-05 lr: 9.5546e-06  eta: 9:11:17  time: 0.4349  data_time: 0.0089  memory: 5277  grad_norm: 137.9259  loss: 17.3690  decode.loss_cls: 0.8940  decode.loss_mask: 0.3602  decode.loss_dice: 0.3547  decode.d0.loss_cls: 1.8493  decode.d0.loss_mask: 0.3989  decode.d0.loss_dice: 0.4232  decode.d1.loss_cls: 1.1093  decode.d1.loss_mask: 0.3779  decode.d1.loss_dice: 0.3587  decode.d2.loss_cls: 0.8902  decode.d2.loss_mask: 0.3655  decode.d2.loss_dice: 0.3504  decode.d3.loss_cls: 0.9784  decode.d3.loss_mask: 0.3400  decode.d3.loss_dice: 0.3363  decode.d4.loss_cls: 0.9242  decode.d4.loss_mask: 0.3455  decode.d4.loss_dice: 0.3452  decode.d5.loss_cls: 0.9238  decode.d5.loss_mask: 0.3493  decode.d5.loss_dice: 0.3518  decode.d6.loss_cls: 0.9028  decode.d6.loss_mask: 0.3524  decode.d6.loss_dice: 0.3385  decode.d7.loss_cls: 0.8952  decode.d7.loss_mask: 0.3449  decode.d7.loss_dice: 0.3294  decode.d8.loss_cls: 0.8421  decode.d8.loss_mask: 0.3712  decode.d8.loss_dice: 0.3658
07/30 17:09:16 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 17:09:16 - mmengine - INFO - Iter(train) [ 4000/80000]  base_lr: 9.5490e-05 lr: 9.5490e-06  eta: 9:10:54  time: 0.4342  data_time: 0.0087  memory: 5322  grad_norm: 163.3676  loss: 18.5292  decode.loss_cls: 0.9772  decode.loss_mask: 0.3189  decode.loss_dice: 0.4197  decode.d0.loss_cls: 1.7125  decode.d0.loss_mask: 0.3690  decode.d0.loss_dice: 0.5342  decode.d1.loss_cls: 0.9727  decode.d1.loss_mask: 0.3498  decode.d1.loss_dice: 0.4394  decode.d2.loss_cls: 0.9663  decode.d2.loss_mask: 0.3369  decode.d2.loss_dice: 0.4274  decode.d3.loss_cls: 1.0288  decode.d3.loss_mask: 0.3318  decode.d3.loss_dice: 0.4300  decode.d4.loss_cls: 1.0652  decode.d4.loss_mask: 0.3279  decode.d4.loss_dice: 0.4315  decode.d5.loss_cls: 1.0069  decode.d5.loss_mask: 0.3380  decode.d5.loss_dice: 0.4638  decode.d6.loss_cls: 0.9565  decode.d6.loss_mask: 0.3240  decode.d6.loss_dice: 0.4046  decode.d7.loss_cls: 1.0726  decode.d7.loss_mask: 0.3324  decode.d7.loss_dice: 0.3891  decode.d8.loss_cls: 1.0854  decode.d8.loss_mask: 0.3279  decode.d8.loss_dice: 0.3888
07/30 17:09:38 - mmengine - INFO - Iter(train) [ 4050/80000]  base_lr: 9.5433e-05 lr: 9.5433e-06  eta: 9:10:32  time: 0.4344  data_time: 0.0087  memory: 5246  grad_norm: 131.2957  loss: 18.0244  decode.loss_cls: 0.9749  decode.loss_mask: 0.3420  decode.loss_dice: 0.3557  decode.d0.loss_cls: 1.7610  decode.d0.loss_mask: 0.3488  decode.d0.loss_dice: 0.4185  decode.d1.loss_cls: 1.1819  decode.d1.loss_mask: 0.3318  decode.d1.loss_dice: 0.3628  decode.d2.loss_cls: 0.9784  decode.d2.loss_mask: 0.3708  decode.d2.loss_dice: 0.3880  decode.d3.loss_cls: 0.9790  decode.d3.loss_mask: 0.3567  decode.d3.loss_dice: 0.3538  decode.d4.loss_cls: 0.9429  decode.d4.loss_mask: 0.3402  decode.d4.loss_dice: 0.3520  decode.d5.loss_cls: 1.0527  decode.d5.loss_mask: 0.3481  decode.d5.loss_dice: 0.3555  decode.d6.loss_cls: 1.0007  decode.d6.loss_mask: 0.3516  decode.d6.loss_dice: 0.3699  decode.d7.loss_cls: 0.9585  decode.d7.loss_mask: 0.3473  decode.d7.loss_dice: 0.3666  decode.d8.loss_cls: 1.0335  decode.d8.loss_mask: 0.3460  decode.d8.loss_dice: 0.3548
07/30 17:09:59 - mmengine - INFO - Iter(train) [ 4100/80000]  base_lr: 9.5377e-05 lr: 9.5377e-06  eta: 9:10:10  time: 0.4347  data_time: 0.0089  memory: 5305  grad_norm: 102.9793  loss: 16.5701  decode.loss_cls: 0.7804  decode.loss_mask: 0.3319  decode.loss_dice: 0.3802  decode.d0.loss_cls: 1.8467  decode.d0.loss_mask: 0.3798  decode.d0.loss_dice: 0.4825  decode.d1.loss_cls: 0.9836  decode.d1.loss_mask: 0.3545  decode.d1.loss_dice: 0.3746  decode.d2.loss_cls: 0.7760  decode.d2.loss_mask: 0.3213  decode.d2.loss_dice: 0.3698  decode.d3.loss_cls: 0.7641  decode.d3.loss_mask: 0.3289  decode.d3.loss_dice: 0.3678  decode.d4.loss_cls: 0.7795  decode.d4.loss_mask: 0.3393  decode.d4.loss_dice: 0.3783  decode.d5.loss_cls: 0.8670  decode.d5.loss_mask: 0.3562  decode.d5.loss_dice: 0.4035  decode.d6.loss_cls: 0.8346  decode.d6.loss_mask: 0.3540  decode.d6.loss_dice: 0.3639  decode.d7.loss_cls: 0.8310  decode.d7.loss_mask: 0.3344  decode.d7.loss_dice: 0.3611  decode.d8.loss_cls: 0.7996  decode.d8.loss_mask: 0.3644  decode.d8.loss_dice: 0.3612
07/30 17:10:21 - mmengine - INFO - Iter(train) [ 4150/80000]  base_lr: 9.5320e-05 lr: 9.5320e-06  eta: 9:09:48  time: 0.4333  data_time: 0.0089  memory: 5246  grad_norm: 186.0194  loss: 16.6366  decode.loss_cls: 0.6847  decode.loss_mask: 0.4577  decode.loss_dice: 0.3926  decode.d0.loss_cls: 1.4260  decode.d0.loss_mask: 0.5672  decode.d0.loss_dice: 0.4762  decode.d1.loss_cls: 0.8165  decode.d1.loss_mask: 0.4809  decode.d1.loss_dice: 0.3981  decode.d2.loss_cls: 0.6981  decode.d2.loss_mask: 0.5004  decode.d2.loss_dice: 0.3978  decode.d3.loss_cls: 0.6896  decode.d3.loss_mask: 0.5209  decode.d3.loss_dice: 0.3915  decode.d4.loss_cls: 0.7758  decode.d4.loss_mask: 0.4712  decode.d4.loss_dice: 0.3666  decode.d5.loss_cls: 0.7228  decode.d5.loss_mask: 0.4572  decode.d5.loss_dice: 0.3902  decode.d6.loss_cls: 0.7043  decode.d6.loss_mask: 0.4855  decode.d6.loss_dice: 0.3836  decode.d7.loss_cls: 0.6354  decode.d7.loss_mask: 0.4964  decode.d7.loss_dice: 0.3664  decode.d8.loss_cls: 0.6290  decode.d8.loss_mask: 0.4508  decode.d8.loss_dice: 0.4032
07/30 17:10:43 - mmengine - INFO - Iter(train) [ 4200/80000]  base_lr: 9.5263e-05 lr: 9.5263e-06  eta: 9:09:27  time: 0.4355  data_time: 0.0085  memory: 5278  grad_norm: 147.8275  loss: 18.3695  decode.loss_cls: 1.0481  decode.loss_mask: 0.2881  decode.loss_dice: 0.3875  decode.d0.loss_cls: 2.1244  decode.d0.loss_mask: 0.3030  decode.d0.loss_dice: 0.4579  decode.d1.loss_cls: 1.2602  decode.d1.loss_mask: 0.2803  decode.d1.loss_dice: 0.3873  decode.d2.loss_cls: 1.0548  decode.d2.loss_mask: 0.2855  decode.d2.loss_dice: 0.3914  decode.d3.loss_cls: 1.0324  decode.d3.loss_mask: 0.2510  decode.d3.loss_dice: 0.3599  decode.d4.loss_cls: 1.0025  decode.d4.loss_mask: 0.2573  decode.d4.loss_dice: 0.3664  decode.d5.loss_cls: 1.0939  decode.d5.loss_mask: 0.2877  decode.d5.loss_dice: 0.3840  decode.d6.loss_cls: 1.0243  decode.d6.loss_mask: 0.2725  decode.d6.loss_dice: 0.3546  decode.d7.loss_cls: 1.0498  decode.d7.loss_mask: 0.2760  decode.d7.loss_dice: 0.3794  decode.d8.loss_cls: 1.0798  decode.d8.loss_mask: 0.2680  decode.d8.loss_dice: 0.3615
07/30 17:11:05 - mmengine - INFO - Iter(train) [ 4250/80000]  base_lr: 9.5207e-05 lr: 9.5207e-06  eta: 9:09:05  time: 0.4342  data_time: 0.0087  memory: 5246  grad_norm: 191.2452  loss: 16.4647  decode.loss_cls: 0.6528  decode.loss_mask: 0.4961  decode.loss_dice: 0.3988  decode.d0.loss_cls: 1.5757  decode.d0.loss_mask: 0.4232  decode.d0.loss_dice: 0.4249  decode.d1.loss_cls: 0.8898  decode.d1.loss_mask: 0.3744  decode.d1.loss_dice: 0.3597  decode.d2.loss_cls: 0.7526  decode.d2.loss_mask: 0.3397  decode.d2.loss_dice: 0.3698  decode.d3.loss_cls: 0.8417  decode.d3.loss_mask: 0.3541  decode.d3.loss_dice: 0.3683  decode.d4.loss_cls: 0.8314  decode.d4.loss_mask: 0.3509  decode.d4.loss_dice: 0.3714  decode.d5.loss_cls: 0.8161  decode.d5.loss_mask: 0.3427  decode.d5.loss_dice: 0.3614  decode.d6.loss_cls: 0.6781  decode.d6.loss_mask: 0.3879  decode.d6.loss_dice: 0.3899  decode.d7.loss_cls: 0.7661  decode.d7.loss_mask: 0.5106  decode.d7.loss_dice: 0.3909  decode.d8.loss_cls: 0.7428  decode.d8.loss_mask: 0.4997  decode.d8.loss_dice: 0.4033
07/30 17:11:26 - mmengine - INFO - Iter(train) [ 4300/80000]  base_lr: 9.5150e-05 lr: 9.5150e-06  eta: 9:08:43  time: 0.4343  data_time: 0.0086  memory: 5265  grad_norm: 258.1034  loss: 19.6337  decode.loss_cls: 0.9500  decode.loss_mask: 0.4504  decode.loss_dice: 0.4947  decode.d0.loss_cls: 1.7765  decode.d0.loss_mask: 0.4471  decode.d0.loss_dice: 0.5789  decode.d1.loss_cls: 1.0818  decode.d1.loss_mask: 0.4188  decode.d1.loss_dice: 0.4927  decode.d2.loss_cls: 0.9026  decode.d2.loss_mask: 0.3911  decode.d2.loss_dice: 0.4625  decode.d3.loss_cls: 0.8902  decode.d3.loss_mask: 0.3961  decode.d3.loss_dice: 0.4940  decode.d4.loss_cls: 0.9486  decode.d4.loss_mask: 0.4043  decode.d4.loss_dice: 0.4906  decode.d5.loss_cls: 0.9241  decode.d5.loss_mask: 0.4153  decode.d5.loss_dice: 0.4789  decode.d6.loss_cls: 0.8896  decode.d6.loss_mask: 0.4336  decode.d6.loss_dice: 0.5075  decode.d7.loss_cls: 0.9952  decode.d7.loss_mask: 0.4432  decode.d7.loss_dice: 0.5256  decode.d8.loss_cls: 0.9526  decode.d8.loss_mask: 0.4765  decode.d8.loss_dice: 0.5207
07/30 17:11:48 - mmengine - INFO - Iter(train) [ 4350/80000]  base_lr: 9.5094e-05 lr: 9.5094e-06  eta: 9:08:21  time: 0.4350  data_time: 0.0088  memory: 5244  grad_norm: 173.1833  loss: 16.0934  decode.loss_cls: 0.7511  decode.loss_mask: 0.3532  decode.loss_dice: 0.3942  decode.d0.loss_cls: 1.6006  decode.d0.loss_mask: 0.4159  decode.d0.loss_dice: 0.5037  decode.d1.loss_cls: 0.8460  decode.d1.loss_mask: 0.3365  decode.d1.loss_dice: 0.3932  decode.d2.loss_cls: 0.7167  decode.d2.loss_mask: 0.3425  decode.d2.loss_dice: 0.4040  decode.d3.loss_cls: 0.7191  decode.d3.loss_mask: 0.3481  decode.d3.loss_dice: 0.4241  decode.d4.loss_cls: 0.7105  decode.d4.loss_mask: 0.3453  decode.d4.loss_dice: 0.4281  decode.d5.loss_cls: 0.7543  decode.d5.loss_mask: 0.3477  decode.d5.loss_dice: 0.4345  decode.d6.loss_cls: 0.7746  decode.d6.loss_mask: 0.3432  decode.d6.loss_dice: 0.4137  decode.d7.loss_cls: 0.7544  decode.d7.loss_mask: 0.3551  decode.d7.loss_dice: 0.4224  decode.d8.loss_cls: 0.7344  decode.d8.loss_mask: 0.3357  decode.d8.loss_dice: 0.3905
07/30 17:12:10 - mmengine - INFO - Iter(train) [ 4400/80000]  base_lr: 9.5037e-05 lr: 9.5037e-06  eta: 9:07:59  time: 0.4346  data_time: 0.0087  memory: 5278  grad_norm: 118.7439  loss: 19.5201  decode.loss_cls: 1.0568  decode.loss_mask: 0.3455  decode.loss_dice: 0.3906  decode.d0.loss_cls: 2.0392  decode.d0.loss_mask: 0.3475  decode.d0.loss_dice: 0.4965  decode.d1.loss_cls: 1.2829  decode.d1.loss_mask: 0.3472  decode.d1.loss_dice: 0.4054  decode.d2.loss_cls: 1.0671  decode.d2.loss_mask: 0.3571  decode.d2.loss_dice: 0.3976  decode.d3.loss_cls: 1.0564  decode.d3.loss_mask: 0.3500  decode.d3.loss_dice: 0.4167  decode.d4.loss_cls: 1.1547  decode.d4.loss_mask: 0.3504  decode.d4.loss_dice: 0.3908  decode.d5.loss_cls: 1.1028  decode.d5.loss_mask: 0.3504  decode.d5.loss_dice: 0.4035  decode.d6.loss_cls: 1.0831  decode.d6.loss_mask: 0.3500  decode.d6.loss_dice: 0.3810  decode.d7.loss_cls: 1.1098  decode.d7.loss_mask: 0.3404  decode.d7.loss_dice: 0.3691  decode.d8.loss_cls: 1.0520  decode.d8.loss_mask: 0.3383  decode.d8.loss_dice: 0.3873
07/30 17:12:32 - mmengine - INFO - Iter(train) [ 4450/80000]  base_lr: 9.4981e-05 lr: 9.4981e-06  eta: 9:07:37  time: 0.4346  data_time: 0.0088  memory: 5279  grad_norm: 163.3113  loss: 15.5572  decode.loss_cls: 0.7201  decode.loss_mask: 0.3293  decode.loss_dice: 0.3737  decode.d0.loss_cls: 1.5558  decode.d0.loss_mask: 0.3294  decode.d0.loss_dice: 0.4245  decode.d1.loss_cls: 0.9542  decode.d1.loss_mask: 0.3219  decode.d1.loss_dice: 0.4038  decode.d2.loss_cls: 0.7446  decode.d2.loss_mask: 0.3324  decode.d2.loss_dice: 0.4052  decode.d3.loss_cls: 0.8192  decode.d3.loss_mask: 0.3293  decode.d3.loss_dice: 0.3956  decode.d4.loss_cls: 0.6999  decode.d4.loss_mask: 0.3382  decode.d4.loss_dice: 0.3915  decode.d5.loss_cls: 0.7357  decode.d5.loss_mask: 0.3312  decode.d5.loss_dice: 0.3883  decode.d6.loss_cls: 0.7347  decode.d6.loss_mask: 0.3084  decode.d6.loss_dice: 0.3739  decode.d7.loss_cls: 0.6633  decode.d7.loss_mask: 0.3363  decode.d7.loss_dice: 0.3932  decode.d8.loss_cls: 0.7100  decode.d8.loss_mask: 0.3323  decode.d8.loss_dice: 0.3815
07/30 17:12:53 - mmengine - INFO - Iter(train) [ 4500/80000]  base_lr: 9.4924e-05 lr: 9.4924e-06  eta: 9:07:15  time: 0.4344  data_time: 0.0088  memory: 5277  grad_norm: 146.5894  loss: 14.7977  decode.loss_cls: 0.6938  decode.loss_mask: 0.3017  decode.loss_dice: 0.3417  decode.d0.loss_cls: 1.6872  decode.d0.loss_mask: 0.3368  decode.d0.loss_dice: 0.4052  decode.d1.loss_cls: 0.8640  decode.d1.loss_mask: 0.3042  decode.d1.loss_dice: 0.3589  decode.d2.loss_cls: 0.6956  decode.d2.loss_mask: 0.2998  decode.d2.loss_dice: 0.3202  decode.d3.loss_cls: 0.7782  decode.d3.loss_mask: 0.3014  decode.d3.loss_dice: 0.3328  decode.d4.loss_cls: 0.7313  decode.d4.loss_mask: 0.3099  decode.d4.loss_dice: 0.3274  decode.d5.loss_cls: 0.7451  decode.d5.loss_mask: 0.3041  decode.d5.loss_dice: 0.3116  decode.d6.loss_cls: 0.7053  decode.d6.loss_mask: 0.3007  decode.d6.loss_dice: 0.3554  decode.d7.loss_cls: 0.7151  decode.d7.loss_mask: 0.3021  decode.d7.loss_dice: 0.3118  decode.d8.loss_cls: 0.6930  decode.d8.loss_mask: 0.3168  decode.d8.loss_dice: 0.3465
07/30 17:13:15 - mmengine - INFO - Iter(train) [ 4550/80000]  base_lr: 9.4867e-05 lr: 9.4867e-06  eta: 9:06:54  time: 0.4381  data_time: 0.0088  memory: 5261  grad_norm: 150.5439  loss: 17.2940  decode.loss_cls: 0.9037  decode.loss_mask: 0.3285  decode.loss_dice: 0.3810  decode.d0.loss_cls: 1.8199  decode.d0.loss_mask: 0.3626  decode.d0.loss_dice: 0.4620  decode.d1.loss_cls: 1.2215  decode.d1.loss_mask: 0.3407  decode.d1.loss_dice: 0.3587  decode.d2.loss_cls: 0.8895  decode.d2.loss_mask: 0.3282  decode.d2.loss_dice: 0.3879  decode.d3.loss_cls: 0.8487  decode.d3.loss_mask: 0.3297  decode.d3.loss_dice: 0.3769  decode.d4.loss_cls: 0.8249  decode.d4.loss_mask: 0.3339  decode.d4.loss_dice: 0.3883  decode.d5.loss_cls: 0.9262  decode.d5.loss_mask: 0.3379  decode.d5.loss_dice: 0.3808  decode.d6.loss_cls: 0.8269  decode.d6.loss_mask: 0.3324  decode.d6.loss_dice: 0.3994  decode.d7.loss_cls: 0.8705  decode.d7.loss_mask: 0.3525  decode.d7.loss_dice: 0.3817  decode.d8.loss_cls: 0.9031  decode.d8.loss_mask: 0.3322  decode.d8.loss_dice: 0.3642
07/30 17:13:37 - mmengine - INFO - Iter(train) [ 4600/80000]  base_lr: 9.4811e-05 lr: 9.4811e-06  eta: 9:06:33  time: 0.4344  data_time: 0.0089  memory: 5244  grad_norm: 258.7164  loss: 19.6688  decode.loss_cls: 1.0841  decode.loss_mask: 0.4096  decode.loss_dice: 0.4131  decode.d0.loss_cls: 1.8402  decode.d0.loss_mask: 0.4412  decode.d0.loss_dice: 0.4806  decode.d1.loss_cls: 1.1663  decode.d1.loss_mask: 0.4241  decode.d1.loss_dice: 0.4490  decode.d2.loss_cls: 0.9920  decode.d2.loss_mask: 0.4068  decode.d2.loss_dice: 0.4244  decode.d3.loss_cls: 1.0185  decode.d3.loss_mask: 0.4106  decode.d3.loss_dice: 0.4279  decode.d4.loss_cls: 0.9173  decode.d4.loss_mask: 0.4232  decode.d4.loss_dice: 0.4575  decode.d5.loss_cls: 1.0294  decode.d5.loss_mask: 0.4223  decode.d5.loss_dice: 0.4561  decode.d6.loss_cls: 0.9660  decode.d6.loss_mask: 0.4163  decode.d6.loss_dice: 0.4477  decode.d7.loss_cls: 0.9821  decode.d7.loss_mask: 0.4151  decode.d7.loss_dice: 0.4645  decode.d8.loss_cls: 1.0268  decode.d8.loss_mask: 0.4117  decode.d8.loss_dice: 0.4441
07/30 17:13:59 - mmengine - INFO - Iter(train) [ 4650/80000]  base_lr: 9.4754e-05 lr: 9.4754e-06  eta: 9:06:11  time: 0.4356  data_time: 0.0088  memory: 5245  grad_norm: 200.3747  loss: 18.6265  decode.loss_cls: 0.9248  decode.loss_mask: 0.3022  decode.loss_dice: 0.4359  decode.d0.loss_cls: 1.7613  decode.d0.loss_mask: 0.3339  decode.d0.loss_dice: 0.5382  decode.d1.loss_cls: 0.9552  decode.d1.loss_mask: 0.3123  decode.d1.loss_dice: 0.4591  decode.d2.loss_cls: 1.0502  decode.d2.loss_mask: 0.2971  decode.d2.loss_dice: 0.4601  decode.d3.loss_cls: 0.9459  decode.d3.loss_mask: 0.3266  decode.d3.loss_dice: 0.4586  decode.d4.loss_cls: 0.9920  decode.d4.loss_mask: 0.3068  decode.d4.loss_dice: 0.4452  decode.d5.loss_cls: 1.0053  decode.d5.loss_mask: 0.3469  decode.d5.loss_dice: 0.4778  decode.d6.loss_cls: 1.0733  decode.d6.loss_mask: 0.3449  decode.d6.loss_dice: 0.4472  decode.d7.loss_cls: 1.0695  decode.d7.loss_mask: 0.2987  decode.d7.loss_dice: 0.4503  decode.d8.loss_cls: 1.0414  decode.d8.loss_mask: 0.3093  decode.d8.loss_dice: 0.4566
07/30 17:14:20 - mmengine - INFO - Iter(train) [ 4700/80000]  base_lr: 9.4698e-05 lr: 9.4698e-06  eta: 9:05:50  time: 0.4353  data_time: 0.0089  memory: 5265  grad_norm: 99.5814  loss: 14.9956  decode.loss_cls: 0.6809  decode.loss_mask: 0.2919  decode.loss_dice: 0.3657  decode.d0.loss_cls: 1.5496  decode.d0.loss_mask: 0.3044  decode.d0.loss_dice: 0.4740  decode.d1.loss_cls: 0.7959  decode.d1.loss_mask: 0.2922  decode.d1.loss_dice: 0.3946  decode.d2.loss_cls: 0.8118  decode.d2.loss_mask: 0.2897  decode.d2.loss_dice: 0.3705  decode.d3.loss_cls: 0.7422  decode.d3.loss_mask: 0.2871  decode.d3.loss_dice: 0.3688  decode.d4.loss_cls: 0.7770  decode.d4.loss_mask: 0.2802  decode.d4.loss_dice: 0.3687  decode.d5.loss_cls: 0.7576  decode.d5.loss_mask: 0.2877  decode.d5.loss_dice: 0.3650  decode.d6.loss_cls: 0.7432  decode.d6.loss_mask: 0.2861  decode.d6.loss_dice: 0.3625  decode.d7.loss_cls: 0.6788  decode.d7.loss_mask: 0.2848  decode.d7.loss_dice: 0.3654  decode.d8.loss_cls: 0.7600  decode.d8.loss_mask: 0.2840  decode.d8.loss_dice: 0.3754
07/30 17:14:42 - mmengine - INFO - Iter(train) [ 4750/80000]  base_lr: 9.4641e-05 lr: 9.4641e-06  eta: 9:05:28  time: 0.4355  data_time: 0.0087  memory: 5245  grad_norm: 144.3608  loss: 19.5516  decode.loss_cls: 1.0391  decode.loss_mask: 0.3113  decode.loss_dice: 0.4525  decode.d0.loss_cls: 2.0046  decode.d0.loss_mask: 0.3107  decode.d0.loss_dice: 0.5685  decode.d1.loss_cls: 1.1580  decode.d1.loss_mask: 0.2828  decode.d1.loss_dice: 0.4692  decode.d2.loss_cls: 1.0518  decode.d2.loss_mask: 0.3069  decode.d2.loss_dice: 0.4804  decode.d3.loss_cls: 1.1356  decode.d3.loss_mask: 0.3052  decode.d3.loss_dice: 0.4969  decode.d4.loss_cls: 1.1035  decode.d4.loss_mask: 0.3024  decode.d4.loss_dice: 0.4927  decode.d5.loss_cls: 1.0364  decode.d5.loss_mask: 0.2971  decode.d5.loss_dice: 0.4891  decode.d6.loss_cls: 1.0485  decode.d6.loss_mask: 0.3177  decode.d6.loss_dice: 0.4613  decode.d7.loss_cls: 0.9785  decode.d7.loss_mask: 0.3072  decode.d7.loss_dice: 0.4766  decode.d8.loss_cls: 1.0680  decode.d8.loss_mask: 0.3237  decode.d8.loss_dice: 0.4755
07/30 17:15:04 - mmengine - INFO - Iter(train) [ 4800/80000]  base_lr: 9.4584e-05 lr: 9.4584e-06  eta: 9:05:06  time: 0.4352  data_time: 0.0090  memory: 5305  grad_norm: 120.8269  loss: 18.8126  decode.loss_cls: 0.9317  decode.loss_mask: 0.4308  decode.loss_dice: 0.4732  decode.d0.loss_cls: 1.4725  decode.d0.loss_mask: 0.4363  decode.d0.loss_dice: 0.5382  decode.d1.loss_cls: 0.9985  decode.d1.loss_mask: 0.4242  decode.d1.loss_dice: 0.4735  decode.d2.loss_cls: 0.8372  decode.d2.loss_mask: 0.4341  decode.d2.loss_dice: 0.4828  decode.d3.loss_cls: 0.8098  decode.d3.loss_mask: 0.4422  decode.d3.loss_dice: 0.4733  decode.d4.loss_cls: 0.9465  decode.d4.loss_mask: 0.4281  decode.d4.loss_dice: 0.4844  decode.d5.loss_cls: 0.9803  decode.d5.loss_mask: 0.4161  decode.d5.loss_dice: 0.4709  decode.d6.loss_cls: 0.8707  decode.d6.loss_mask: 0.4234  decode.d6.loss_dice: 0.4662  decode.d7.loss_cls: 0.9121  decode.d7.loss_mask: 0.4228  decode.d7.loss_dice: 0.4827  decode.d8.loss_cls: 0.9567  decode.d8.loss_mask: 0.4223  decode.d8.loss_dice: 0.4711
07/30 17:15:26 - mmengine - INFO - Iter(train) [ 4850/80000]  base_lr: 9.4528e-05 lr: 9.4528e-06  eta: 9:04:45  time: 0.4343  data_time: 0.0088  memory: 5279  grad_norm: 149.4673  loss: 15.8595  decode.loss_cls: 0.7699  decode.loss_mask: 0.4099  decode.loss_dice: 0.3387  decode.d0.loss_cls: 1.4483  decode.d0.loss_mask: 0.3975  decode.d0.loss_dice: 0.3997  decode.d1.loss_cls: 0.7437  decode.d1.loss_mask: 0.3775  decode.d1.loss_dice: 0.3390  decode.d2.loss_cls: 0.7206  decode.d2.loss_mask: 0.3957  decode.d2.loss_dice: 0.3345  decode.d3.loss_cls: 0.7225  decode.d3.loss_mask: 0.3922  decode.d3.loss_dice: 0.3435  decode.d4.loss_cls: 0.7202  decode.d4.loss_mask: 0.3834  decode.d4.loss_dice: 0.3501  decode.d5.loss_cls: 0.8195  decode.d5.loss_mask: 0.3812  decode.d5.loss_dice: 0.3522  decode.d6.loss_cls: 0.6782  decode.d6.loss_mask: 0.4004  decode.d6.loss_dice: 0.3732  decode.d7.loss_cls: 0.8557  decode.d7.loss_mask: 0.4340  decode.d7.loss_dice: 0.3706  decode.d8.loss_cls: 0.8336  decode.d8.loss_mask: 0.4192  decode.d8.loss_dice: 0.3548
07/30 17:15:47 - mmengine - INFO - Iter(train) [ 4900/80000]  base_lr: 9.4471e-05 lr: 9.4471e-06  eta: 9:04:23  time: 0.4346  data_time: 0.0088  memory: 5279  grad_norm: 183.8231  loss: 18.2527  decode.loss_cls: 0.9893  decode.loss_mask: 0.3824  decode.loss_dice: 0.4736  decode.d0.loss_cls: 1.7071  decode.d0.loss_mask: 0.4218  decode.d0.loss_dice: 0.5250  decode.d1.loss_cls: 0.9503  decode.d1.loss_mask: 0.3516  decode.d1.loss_dice: 0.4668  decode.d2.loss_cls: 0.9043  decode.d2.loss_mask: 0.3602  decode.d2.loss_dice: 0.4776  decode.d3.loss_cls: 0.8675  decode.d3.loss_mask: 0.3521  decode.d3.loss_dice: 0.4590  decode.d4.loss_cls: 0.8786  decode.d4.loss_mask: 0.3465  decode.d4.loss_dice: 0.4695  decode.d5.loss_cls: 0.8541  decode.d5.loss_mask: 0.3849  decode.d5.loss_dice: 0.5079  decode.d6.loss_cls: 0.8521  decode.d6.loss_mask: 0.3566  decode.d6.loss_dice: 0.4843  decode.d7.loss_cls: 0.8493  decode.d7.loss_mask: 0.3596  decode.d7.loss_dice: 0.4685  decode.d8.loss_cls: 0.9208  decode.d8.loss_mask: 0.3587  decode.d8.loss_dice: 0.4729
07/30 17:16:09 - mmengine - INFO - Iter(train) [ 4950/80000]  base_lr: 9.4415e-05 lr: 9.4415e-06  eta: 9:04:02  time: 0.4359  data_time: 0.0089  memory: 5304  grad_norm: 144.9132  loss: 13.8841  decode.loss_cls: 0.5256  decode.loss_mask: 0.3161  decode.loss_dice: 0.4049  decode.d0.loss_cls: 1.5941  decode.d0.loss_mask: 0.3280  decode.d0.loss_dice: 0.4877  decode.d1.loss_cls: 0.7057  decode.d1.loss_mask: 0.3208  decode.d1.loss_dice: 0.4356  decode.d2.loss_cls: 0.5468  decode.d2.loss_mask: 0.3191  decode.d2.loss_dice: 0.4269  decode.d3.loss_cls: 0.5458  decode.d3.loss_mask: 0.3192  decode.d3.loss_dice: 0.3976  decode.d4.loss_cls: 0.5128  decode.d4.loss_mask: 0.3181  decode.d4.loss_dice: 0.3796  decode.d5.loss_cls: 0.5192  decode.d5.loss_mask: 0.3162  decode.d5.loss_dice: 0.3951  decode.d6.loss_cls: 0.4710  decode.d6.loss_mask: 0.3223  decode.d6.loss_dice: 0.3995  decode.d7.loss_cls: 0.5678  decode.d7.loss_mask: 0.3213  decode.d7.loss_dice: 0.4061  decode.d8.loss_cls: 0.5411  decode.d8.loss_mask: 0.3180  decode.d8.loss_dice: 0.4222
07/30 17:16:31 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 17:16:31 - mmengine - INFO - Iter(train) [ 5000/80000]  base_lr: 9.4358e-05 lr: 9.4358e-06  eta: 9:03:40  time: 0.4349  data_time: 0.0090  memory: 5261  grad_norm: 121.6241  loss: 14.9743  decode.loss_cls: 0.5783  decode.loss_mask: 0.3934  decode.loss_dice: 0.3829  decode.d0.loss_cls: 1.4898  decode.d0.loss_mask: 0.4011  decode.d0.loss_dice: 0.4541  decode.d1.loss_cls: 0.7099  decode.d1.loss_mask: 0.3781  decode.d1.loss_dice: 0.3964  decode.d2.loss_cls: 0.5718  decode.d2.loss_mask: 0.3857  decode.d2.loss_dice: 0.3930  decode.d3.loss_cls: 0.5669  decode.d3.loss_mask: 0.4262  decode.d3.loss_dice: 0.3922  decode.d4.loss_cls: 0.5980  decode.d4.loss_mask: 0.4138  decode.d4.loss_dice: 0.3957  decode.d5.loss_cls: 0.6366  decode.d5.loss_mask: 0.3723  decode.d5.loss_dice: 0.3955  decode.d6.loss_cls: 0.5805  decode.d6.loss_mask: 0.4135  decode.d6.loss_dice: 0.4199  decode.d7.loss_cls: 0.5617  decode.d7.loss_mask: 0.4124  decode.d7.loss_dice: 0.3950  decode.d8.loss_cls: 0.6276  decode.d8.loss_mask: 0.4054  decode.d8.loss_dice: 0.4265
07/30 17:16:31 - mmengine - INFO - Saving checkpoint at 5000 iterations
07/30 17:16:55 - mmengine - INFO - Iter(train) [ 5050/80000]  base_lr: 9.4301e-05 lr: 9.4301e-06  eta: 9:03:47  time: 0.4351  data_time: 0.0088  memory: 5265  grad_norm: 109.8108  loss: 12.9281  decode.loss_cls: 0.6308  decode.loss_mask: 0.2628  decode.loss_dice: 0.2519  decode.d0.loss_cls: 1.6054  decode.d0.loss_mask: 0.2567  decode.d0.loss_dice: 0.3065  decode.d1.loss_cls: 0.7450  decode.d1.loss_mask: 0.2803  decode.d1.loss_dice: 0.2899  decode.d2.loss_cls: 0.6702  decode.d2.loss_mask: 0.2755  decode.d2.loss_dice: 0.2689  decode.d3.loss_cls: 0.6149  decode.d3.loss_mask: 0.2724  decode.d3.loss_dice: 0.3075  decode.d4.loss_cls: 0.6215  decode.d4.loss_mask: 0.2814  decode.d4.loss_dice: 0.2664  decode.d5.loss_cls: 0.6503  decode.d5.loss_mask: 0.2735  decode.d5.loss_dice: 0.2900  decode.d6.loss_cls: 0.6275  decode.d6.loss_mask: 0.2787  decode.d6.loss_dice: 0.2572  decode.d7.loss_cls: 0.6051  decode.d7.loss_mask: 0.2844  decode.d7.loss_dice: 0.2763  decode.d8.loss_cls: 0.6105  decode.d8.loss_mask: 0.2725  decode.d8.loss_dice: 0.2941
07/30 17:17:16 - mmengine - INFO - Iter(train) [ 5100/80000]  base_lr: 9.4245e-05 lr: 9.4245e-06  eta: 9:03:25  time: 0.4350  data_time: 0.0087  memory: 5244  grad_norm: 116.3322  loss: 14.6099  decode.loss_cls: 0.6219  decode.loss_mask: 0.3130  decode.loss_dice: 0.3580  decode.d0.loss_cls: 1.6229  decode.d0.loss_mask: 0.3739  decode.d0.loss_dice: 0.4322  decode.d1.loss_cls: 0.8061  decode.d1.loss_mask: 0.3256  decode.d1.loss_dice: 0.3525  decode.d2.loss_cls: 0.6746  decode.d2.loss_mask: 0.3251  decode.d2.loss_dice: 0.3679  decode.d3.loss_cls: 0.6284  decode.d3.loss_mask: 0.3500  decode.d3.loss_dice: 0.3669  decode.d4.loss_cls: 0.5900  decode.d4.loss_mask: 0.3919  decode.d4.loss_dice: 0.3779  decode.d5.loss_cls: 0.6204  decode.d5.loss_mask: 0.3700  decode.d5.loss_dice: 0.3763  decode.d6.loss_cls: 0.5913  decode.d6.loss_mask: 0.3573  decode.d6.loss_dice: 0.3466  decode.d7.loss_cls: 0.6412  decode.d7.loss_mask: 0.3368  decode.d7.loss_dice: 0.3534  decode.d8.loss_cls: 0.6381  decode.d8.loss_mask: 0.3312  decode.d8.loss_dice: 0.3685
07/30 17:17:38 - mmengine - INFO - Iter(train) [ 5150/80000]  base_lr: 9.4188e-05 lr: 9.4188e-06  eta: 9:03:03  time: 0.4340  data_time: 0.0089  memory: 5261  grad_norm: 147.3468  loss: 16.6680  decode.loss_cls: 0.7846  decode.loss_mask: 0.3986  decode.loss_dice: 0.4268  decode.d0.loss_cls: 1.5803  decode.d0.loss_mask: 0.4477  decode.d0.loss_dice: 0.4464  decode.d1.loss_cls: 0.7800  decode.d1.loss_mask: 0.4176  decode.d1.loss_dice: 0.4470  decode.d2.loss_cls: 0.7217  decode.d2.loss_mask: 0.4267  decode.d2.loss_dice: 0.4299  decode.d3.loss_cls: 0.6452  decode.d3.loss_mask: 0.4283  decode.d3.loss_dice: 0.4261  decode.d4.loss_cls: 0.6682  decode.d4.loss_mask: 0.4351  decode.d4.loss_dice: 0.4376  decode.d5.loss_cls: 0.6213  decode.d5.loss_mask: 0.4498  decode.d5.loss_dice: 0.4566  decode.d6.loss_cls: 0.6591  decode.d6.loss_mask: 0.4488  decode.d6.loss_dice: 0.4442  decode.d7.loss_cls: 0.7106  decode.d7.loss_mask: 0.4343  decode.d7.loss_dice: 0.4565  decode.d8.loss_cls: 0.7644  decode.d8.loss_mask: 0.4227  decode.d8.loss_dice: 0.4519
07/30 17:18:00 - mmengine - INFO - Iter(train) [ 5200/80000]  base_lr: 9.4132e-05 lr: 9.4132e-06  eta: 9:02:41  time: 0.4340  data_time: 0.0087  memory: 5246  grad_norm: 105.1911  loss: 12.6813  decode.loss_cls: 0.4692  decode.loss_mask: 0.2777  decode.loss_dice: 0.3371  decode.d0.loss_cls: 1.4144  decode.d0.loss_mask: 0.2946  decode.d0.loss_dice: 0.3949  decode.d1.loss_cls: 0.7391  decode.d1.loss_mask: 0.2908  decode.d1.loss_dice: 0.3463  decode.d2.loss_cls: 0.6292  decode.d2.loss_mask: 0.2802  decode.d2.loss_dice: 0.3416  decode.d3.loss_cls: 0.5533  decode.d3.loss_mask: 0.2827  decode.d3.loss_dice: 0.3159  decode.d4.loss_cls: 0.5779  decode.d4.loss_mask: 0.2944  decode.d4.loss_dice: 0.3299  decode.d5.loss_cls: 0.5193  decode.d5.loss_mask: 0.2925  decode.d5.loss_dice: 0.3285  decode.d6.loss_cls: 0.5128  decode.d6.loss_mask: 0.2808  decode.d6.loss_dice: 0.3275  decode.d7.loss_cls: 0.4979  decode.d7.loss_mask: 0.2863  decode.d7.loss_dice: 0.3270  decode.d8.loss_cls: 0.5236  decode.d8.loss_mask: 0.2809  decode.d8.loss_dice: 0.3352
07/30 17:18:22 - mmengine - INFO - Iter(train) [ 5250/80000]  base_lr: 9.4075e-05 lr: 9.4075e-06  eta: 9:02:19  time: 0.4356  data_time: 0.0089  memory: 5277  grad_norm: 278.1322  loss: 18.1013  decode.loss_cls: 0.8193  decode.loss_mask: 0.4399  decode.loss_dice: 0.4601  decode.d0.loss_cls: 1.7982  decode.d0.loss_mask: 0.4695  decode.d0.loss_dice: 0.5204  decode.d1.loss_cls: 1.0062  decode.d1.loss_mask: 0.4727  decode.d1.loss_dice: 0.4387  decode.d2.loss_cls: 0.8953  decode.d2.loss_mask: 0.4286  decode.d2.loss_dice: 0.4151  decode.d3.loss_cls: 0.8176  decode.d3.loss_mask: 0.4483  decode.d3.loss_dice: 0.4062  decode.d4.loss_cls: 0.8379  decode.d4.loss_mask: 0.4459  decode.d4.loss_dice: 0.4639  decode.d5.loss_cls: 0.8435  decode.d5.loss_mask: 0.4200  decode.d5.loss_dice: 0.4130  decode.d6.loss_cls: 0.7344  decode.d6.loss_mask: 0.4287  decode.d6.loss_dice: 0.4212  decode.d7.loss_cls: 0.7693  decode.d7.loss_mask: 0.4184  decode.d7.loss_dice: 0.4261  decode.d8.loss_cls: 0.8095  decode.d8.loss_mask: 0.4150  decode.d8.loss_dice: 0.4185
07/30 17:18:43 - mmengine - INFO - Iter(train) [ 5300/80000]  base_lr: 9.4018e-05 lr: 9.4018e-06  eta: 9:01:57  time: 0.4370  data_time: 0.0088  memory: 5261  grad_norm: 139.7060  loss: 14.3873  decode.loss_cls: 0.7380  decode.loss_mask: 0.3309  decode.loss_dice: 0.3073  decode.d0.loss_cls: 1.5909  decode.d0.loss_mask: 0.3244  decode.d0.loss_dice: 0.3340  decode.d1.loss_cls: 0.7964  decode.d1.loss_mask: 0.3291  decode.d1.loss_dice: 0.3289  decode.d2.loss_cls: 0.6970  decode.d2.loss_mask: 0.3332  decode.d2.loss_dice: 0.3228  decode.d3.loss_cls: 0.5999  decode.d3.loss_mask: 0.3351  decode.d3.loss_dice: 0.3236  decode.d4.loss_cls: 0.6230  decode.d4.loss_mask: 0.3306  decode.d4.loss_dice: 0.3220  decode.d5.loss_cls: 0.7173  decode.d5.loss_mask: 0.3370  decode.d5.loss_dice: 0.3183  decode.d6.loss_cls: 0.6727  decode.d6.loss_mask: 0.3294  decode.d6.loss_dice: 0.3036  decode.d7.loss_cls: 0.7441  decode.d7.loss_mask: 0.3279  decode.d7.loss_dice: 0.3065  decode.d8.loss_cls: 0.7278  decode.d8.loss_mask: 0.3362  decode.d8.loss_dice: 0.2990
07/30 17:19:05 - mmengine - INFO - Iter(train) [ 5350/80000]  base_lr: 9.3962e-05 lr: 9.3962e-06  eta: 9:01:35  time: 0.4348  data_time: 0.0089  memory: 5304  grad_norm: 214.2620  loss: 18.0127  decode.loss_cls: 0.7322  decode.loss_mask: 0.4513  decode.loss_dice: 0.4962  decode.d0.loss_cls: 1.6142  decode.d0.loss_mask: 0.4707  decode.d0.loss_dice: 0.5698  decode.d1.loss_cls: 0.9996  decode.d1.loss_mask: 0.3769  decode.d1.loss_dice: 0.4619  decode.d2.loss_cls: 0.8258  decode.d2.loss_mask: 0.4428  decode.d2.loss_dice: 0.4409  decode.d3.loss_cls: 0.7698  decode.d3.loss_mask: 0.4896  decode.d3.loss_dice: 0.4500  decode.d4.loss_cls: 0.7649  decode.d4.loss_mask: 0.4763  decode.d4.loss_dice: 0.4609  decode.d5.loss_cls: 0.7644  decode.d5.loss_mask: 0.4913  decode.d5.loss_dice: 0.4631  decode.d6.loss_cls: 0.8767  decode.d6.loss_mask: 0.4734  decode.d6.loss_dice: 0.4395  decode.d7.loss_cls: 0.7816  decode.d7.loss_mask: 0.4136  decode.d7.loss_dice: 0.4400  decode.d8.loss_cls: 0.7047  decode.d8.loss_mask: 0.4091  decode.d8.loss_dice: 0.4614
07/30 17:19:27 - mmengine - INFO - Iter(train) [ 5400/80000]  base_lr: 9.3905e-05 lr: 9.3905e-06  eta: 9:01:12  time: 0.4341  data_time: 0.0085  memory: 5261  grad_norm: 112.9558  loss: 14.8992  decode.loss_cls: 0.7554  decode.loss_mask: 0.2760  decode.loss_dice: 0.3678  decode.d0.loss_cls: 1.4840  decode.d0.loss_mask: 0.2933  decode.d0.loss_dice: 0.4603  decode.d1.loss_cls: 0.9601  decode.d1.loss_mask: 0.2807  decode.d1.loss_dice: 0.3614  decode.d2.loss_cls: 0.7411  decode.d2.loss_mask: 0.2938  decode.d2.loss_dice: 0.3791  decode.d3.loss_cls: 0.7422  decode.d3.loss_mask: 0.2756  decode.d3.loss_dice: 0.3508  decode.d4.loss_cls: 0.7260  decode.d4.loss_mask: 0.2705  decode.d4.loss_dice: 0.3961  decode.d5.loss_cls: 0.7035  decode.d5.loss_mask: 0.2754  decode.d5.loss_dice: 0.3692  decode.d6.loss_cls: 0.7324  decode.d6.loss_mask: 0.2802  decode.d6.loss_dice: 0.3951  decode.d7.loss_cls: 0.7168  decode.d7.loss_mask: 0.2750  decode.d7.loss_dice: 0.3897  decode.d8.loss_cls: 0.6932  decode.d8.loss_mask: 0.2800  decode.d8.loss_dice: 0.3746
07/30 17:19:48 - mmengine - INFO - Iter(train) [ 5450/80000]  base_lr: 9.3848e-05 lr: 9.3848e-06  eta: 9:00:51  time: 0.4353  data_time: 0.0088  memory: 5265  grad_norm: 113.3490  loss: 11.7688  decode.loss_cls: 0.4009  decode.loss_mask: 0.2753  decode.loss_dice: 0.3427  decode.d0.loss_cls: 1.4862  decode.d0.loss_mask: 0.3139  decode.d0.loss_dice: 0.4357  decode.d1.loss_cls: 0.5414  decode.d1.loss_mask: 0.2800  decode.d1.loss_dice: 0.3515  decode.d2.loss_cls: 0.4463  decode.d2.loss_mask: 0.2772  decode.d2.loss_dice: 0.3533  decode.d3.loss_cls: 0.4465  decode.d3.loss_mask: 0.2664  decode.d3.loss_dice: 0.3314  decode.d4.loss_cls: 0.4042  decode.d4.loss_mask: 0.2783  decode.d4.loss_dice: 0.3557  decode.d5.loss_cls: 0.3944  decode.d5.loss_mask: 0.2781  decode.d5.loss_dice: 0.3638  decode.d6.loss_cls: 0.3937  decode.d6.loss_mask: 0.2706  decode.d6.loss_dice: 0.3412  decode.d7.loss_cls: 0.4716  decode.d7.loss_mask: 0.2700  decode.d7.loss_dice: 0.3480  decode.d8.loss_cls: 0.4567  decode.d8.loss_mask: 0.2673  decode.d8.loss_dice: 0.3266
07/30 17:20:10 - mmengine - INFO - Iter(train) [ 5500/80000]  base_lr: 9.3792e-05 lr: 9.3792e-06  eta: 9:00:29  time: 0.4353  data_time: 0.0089  memory: 5245  grad_norm: 113.1552  loss: 12.8628  decode.loss_cls: 0.5513  decode.loss_mask: 0.3371  decode.loss_dice: 0.3434  decode.d0.loss_cls: 1.5113  decode.d0.loss_mask: 0.3055  decode.d0.loss_dice: 0.3664  decode.d1.loss_cls: 0.7775  decode.d1.loss_mask: 0.3012  decode.d1.loss_dice: 0.3213  decode.d2.loss_cls: 0.5990  decode.d2.loss_mask: 0.2811  decode.d2.loss_dice: 0.3185  decode.d3.loss_cls: 0.4728  decode.d3.loss_mask: 0.2843  decode.d3.loss_dice: 0.3237  decode.d4.loss_cls: 0.4796  decode.d4.loss_mask: 0.2820  decode.d4.loss_dice: 0.3189  decode.d5.loss_cls: 0.5747  decode.d5.loss_mask: 0.2830  decode.d5.loss_dice: 0.3428  decode.d6.loss_cls: 0.5484  decode.d6.loss_mask: 0.3004  decode.d6.loss_dice: 0.3231  decode.d7.loss_cls: 0.5479  decode.d7.loss_mask: 0.2987  decode.d7.loss_dice: 0.3290  decode.d8.loss_cls: 0.4830  decode.d8.loss_mask: 0.3218  decode.d8.loss_dice: 0.3350
07/30 17:20:32 - mmengine - INFO - Iter(train) [ 5550/80000]  base_lr: 9.3735e-05 lr: 9.3735e-06  eta: 9:00:06  time: 0.4348  data_time: 0.0089  memory: 5261  grad_norm: 102.7921  loss: 12.5537  decode.loss_cls: 0.5390  decode.loss_mask: 0.2907  decode.loss_dice: 0.2873  decode.d0.loss_cls: 1.6298  decode.d0.loss_mask: 0.3399  decode.d0.loss_dice: 0.3636  decode.d1.loss_cls: 0.6572  decode.d1.loss_mask: 0.3028  decode.d1.loss_dice: 0.2898  decode.d2.loss_cls: 0.6121  decode.d2.loss_mask: 0.2924  decode.d2.loss_dice: 0.2744  decode.d3.loss_cls: 0.5901  decode.d3.loss_mask: 0.2923  decode.d3.loss_dice: 0.2680  decode.d4.loss_cls: 0.5451  decode.d4.loss_mask: 0.3118  decode.d4.loss_dice: 0.2789  decode.d5.loss_cls: 0.5742  decode.d5.loss_mask: 0.2926  decode.d5.loss_dice: 0.2682  decode.d6.loss_cls: 0.4800  decode.d6.loss_mask: 0.3100  decode.d6.loss_dice: 0.2779  decode.d7.loss_cls: 0.4917  decode.d7.loss_mask: 0.3116  decode.d7.loss_dice: 0.2762  decode.d8.loss_cls: 0.5012  decode.d8.loss_mask: 0.3132  decode.d8.loss_dice: 0.2916
07/30 17:20:54 - mmengine - INFO - Iter(train) [ 5600/80000]  base_lr: 9.3678e-05 lr: 9.3678e-06  eta: 8:59:44  time: 0.4354  data_time: 0.0087  memory: 5279  grad_norm: 298.3099  loss: 14.7111  decode.loss_cls: 0.5043  decode.loss_mask: 0.4332  decode.loss_dice: 0.3491  decode.d0.loss_cls: 1.5693  decode.d0.loss_mask: 0.5489  decode.d0.loss_dice: 0.4259  decode.d1.loss_cls: 0.6171  decode.d1.loss_mask: 0.5058  decode.d1.loss_dice: 0.3492  decode.d2.loss_cls: 0.5262  decode.d2.loss_mask: 0.4637  decode.d2.loss_dice: 0.3470  decode.d3.loss_cls: 0.5248  decode.d3.loss_mask: 0.4731  decode.d3.loss_dice: 0.3456  decode.d4.loss_cls: 0.5494  decode.d4.loss_mask: 0.4659  decode.d4.loss_dice: 0.3806  decode.d5.loss_cls: 0.5598  decode.d5.loss_mask: 0.4543  decode.d5.loss_dice: 0.3563  decode.d6.loss_cls: 0.5215  decode.d6.loss_mask: 0.4386  decode.d6.loss_dice: 0.3553  decode.d7.loss_cls: 0.4856  decode.d7.loss_mask: 0.4601  decode.d7.loss_dice: 0.3793  decode.d8.loss_cls: 0.5547  decode.d8.loss_mask: 0.4213  decode.d8.loss_dice: 0.3450
07/30 17:21:15 - mmengine - INFO - Iter(train) [ 5650/80000]  base_lr: 9.3622e-05 lr: 9.3622e-06  eta: 8:59:22  time: 0.4335  data_time: 0.0088  memory: 5278  grad_norm: 144.7918  loss: 14.8450  decode.loss_cls: 0.7731  decode.loss_mask: 0.3378  decode.loss_dice: 0.3835  decode.d0.loss_cls: 1.3208  decode.d0.loss_mask: 0.3451  decode.d0.loss_dice: 0.3980  decode.d1.loss_cls: 0.7676  decode.d1.loss_mask: 0.3354  decode.d1.loss_dice: 0.4031  decode.d2.loss_cls: 0.6964  decode.d2.loss_mask: 0.3248  decode.d2.loss_dice: 0.3558  decode.d3.loss_cls: 0.6910  decode.d3.loss_mask: 0.3409  decode.d3.loss_dice: 0.4044  decode.d4.loss_cls: 0.6625  decode.d4.loss_mask: 0.3343  decode.d4.loss_dice: 0.3792  decode.d5.loss_cls: 0.7093  decode.d5.loss_mask: 0.3259  decode.d5.loss_dice: 0.3499  decode.d6.loss_cls: 0.6508  decode.d6.loss_mask: 0.3317  decode.d6.loss_dice: 0.3780  decode.d7.loss_cls: 0.7010  decode.d7.loss_mask: 0.3297  decode.d7.loss_dice: 0.3707  decode.d8.loss_cls: 0.7444  decode.d8.loss_mask: 0.3295  decode.d8.loss_dice: 0.3702
07/30 17:21:37 - mmengine - INFO - Iter(train) [ 5700/80000]  base_lr: 9.3565e-05 lr: 9.3565e-06  eta: 8:59:00  time: 0.4354  data_time: 0.0087  memory: 5279  grad_norm: 198.9898  loss: 15.0742  decode.loss_cls: 0.5764  decode.loss_mask: 0.3979  decode.loss_dice: 0.4490  decode.d0.loss_cls: 1.4676  decode.d0.loss_mask: 0.4302  decode.d0.loss_dice: 0.5172  decode.d1.loss_cls: 0.6750  decode.d1.loss_mask: 0.4018  decode.d1.loss_dice: 0.4753  decode.d2.loss_cls: 0.5264  decode.d2.loss_mask: 0.4086  decode.d2.loss_dice: 0.4498  decode.d3.loss_cls: 0.6139  decode.d3.loss_mask: 0.3981  decode.d3.loss_dice: 0.4269  decode.d4.loss_cls: 0.5073  decode.d4.loss_mask: 0.3975  decode.d4.loss_dice: 0.4502  decode.d5.loss_cls: 0.5092  decode.d5.loss_mask: 0.3978  decode.d5.loss_dice: 0.4480  decode.d6.loss_cls: 0.5113  decode.d6.loss_mask: 0.3967  decode.d6.loss_dice: 0.4622  decode.d7.loss_cls: 0.5360  decode.d7.loss_mask: 0.3917  decode.d7.loss_dice: 0.4536  decode.d8.loss_cls: 0.5263  decode.d8.loss_mask: 0.4007  decode.d8.loss_dice: 0.4713
07/30 17:21:59 - mmengine - INFO - Iter(train) [ 5750/80000]  base_lr: 9.3508e-05 lr: 9.3508e-06  eta: 8:58:41  time: 0.4350  data_time: 0.0089  memory: 5278  grad_norm: 385.4154  loss: 16.3298  decode.loss_cls: 0.6226  decode.loss_mask: 0.4902  decode.loss_dice: 0.4848  decode.d0.loss_cls: 1.2944  decode.d0.loss_mask: 0.4425  decode.d0.loss_dice: 0.5046  decode.d1.loss_cls: 0.6897  decode.d1.loss_mask: 0.4105  decode.d1.loss_dice: 0.4699  decode.d2.loss_cls: 0.6184  decode.d2.loss_mask: 0.5081  decode.d2.loss_dice: 0.4836  decode.d3.loss_cls: 0.6401  decode.d3.loss_mask: 0.4920  decode.d3.loss_dice: 0.4944  decode.d4.loss_cls: 0.6608  decode.d4.loss_mask: 0.4286  decode.d4.loss_dice: 0.4806  decode.d5.loss_cls: 0.6283  decode.d5.loss_mask: 0.4462  decode.d5.loss_dice: 0.4752  decode.d6.loss_cls: 0.6406  decode.d6.loss_mask: 0.4110  decode.d6.loss_dice: 0.4590  decode.d7.loss_cls: 0.6783  decode.d7.loss_mask: 0.3994  decode.d7.loss_dice: 0.4719  decode.d8.loss_cls: 0.6094  decode.d8.loss_mask: 0.4251  decode.d8.loss_dice: 0.4697
07/30 17:22:21 - mmengine - INFO - Iter(train) [ 5800/80000]  base_lr: 9.3452e-05 lr: 9.3452e-06  eta: 8:58:18  time: 0.4354  data_time: 0.0086  memory: 5244  grad_norm: 92.9436  loss: 12.7061  decode.loss_cls: 0.5123  decode.loss_mask: 0.2425  decode.loss_dice: 0.2929  decode.d0.loss_cls: 1.6324  decode.d0.loss_mask: 0.2686  decode.d0.loss_dice: 0.3614  decode.d1.loss_cls: 0.8665  decode.d1.loss_mask: 0.2458  decode.d1.loss_dice: 0.3155  decode.d2.loss_cls: 0.7216  decode.d2.loss_mask: 0.2368  decode.d2.loss_dice: 0.2872  decode.d3.loss_cls: 0.5423  decode.d3.loss_mask: 0.2482  decode.d3.loss_dice: 0.2945  decode.d4.loss_cls: 0.5802  decode.d4.loss_mask: 0.2433  decode.d4.loss_dice: 0.2844  decode.d5.loss_cls: 0.6197  decode.d5.loss_mask: 0.2409  decode.d5.loss_dice: 0.2891  decode.d6.loss_cls: 0.5352  decode.d6.loss_mask: 0.2408  decode.d6.loss_dice: 0.2866  decode.d7.loss_cls: 0.5796  decode.d7.loss_mask: 0.2516  decode.d7.loss_dice: 0.2950  decode.d8.loss_cls: 0.6294  decode.d8.loss_mask: 0.2484  decode.d8.loss_dice: 0.3132
07/30 17:22:43 - mmengine - INFO - Iter(train) [ 5850/80000]  base_lr: 9.3395e-05 lr: 9.3395e-06  eta: 8:57:56  time: 0.4352  data_time: 0.0087  memory: 5246  grad_norm: 139.8097  loss: 14.2934  decode.loss_cls: 0.6249  decode.loss_mask: 0.2980  decode.loss_dice: 0.3581  decode.d0.loss_cls: 1.7177  decode.d0.loss_mask: 0.3410  decode.d0.loss_dice: 0.4138  decode.d1.loss_cls: 0.8932  decode.d1.loss_mask: 0.2919  decode.d1.loss_dice: 0.3389  decode.d2.loss_cls: 0.6895  decode.d2.loss_mask: 0.3063  decode.d2.loss_dice: 0.3644  decode.d3.loss_cls: 0.6683  decode.d3.loss_mask: 0.3188  decode.d3.loss_dice: 0.3598  decode.d4.loss_cls: 0.6436  decode.d4.loss_mask: 0.3105  decode.d4.loss_dice: 0.3342  decode.d5.loss_cls: 0.5897  decode.d5.loss_mask: 0.3106  decode.d5.loss_dice: 0.3268  decode.d6.loss_cls: 0.5699  decode.d6.loss_mask: 0.3130  decode.d6.loss_dice: 0.3384  decode.d7.loss_cls: 0.6485  decode.d7.loss_mask: 0.3029  decode.d7.loss_dice: 0.3239  decode.d8.loss_cls: 0.6512  decode.d8.loss_mask: 0.2952  decode.d8.loss_dice: 0.3501
07/30 17:23:04 - mmengine - INFO - Iter(train) [ 5900/80000]  base_lr: 9.3338e-05 lr: 9.3338e-06  eta: 8:57:35  time: 0.4348  data_time: 0.0088  memory: 5279  grad_norm: 155.6076  loss: 13.9561  decode.loss_cls: 0.5904  decode.loss_mask: 0.3309  decode.loss_dice: 0.3666  decode.d0.loss_cls: 1.5433  decode.d0.loss_mask: 0.3192  decode.d0.loss_dice: 0.4146  decode.d1.loss_cls: 0.6724  decode.d1.loss_mask: 0.3375  decode.d1.loss_dice: 0.4318  decode.d2.loss_cls: 0.5511  decode.d2.loss_mask: 0.3342  decode.d2.loss_dice: 0.4110  decode.d3.loss_cls: 0.5643  decode.d3.loss_mask: 0.3287  decode.d3.loss_dice: 0.3861  decode.d4.loss_cls: 0.5753  decode.d4.loss_mask: 0.3266  decode.d4.loss_dice: 0.3667  decode.d5.loss_cls: 0.6233  decode.d5.loss_mask: 0.3263  decode.d5.loss_dice: 0.3461  decode.d6.loss_cls: 0.5602  decode.d6.loss_mask: 0.3177  decode.d6.loss_dice: 0.3589  decode.d7.loss_cls: 0.5911  decode.d7.loss_mask: 0.3325  decode.d7.loss_dice: 0.3710  decode.d8.loss_cls: 0.5902  decode.d8.loss_mask: 0.3250  decode.d8.loss_dice: 0.3633
07/30 17:23:26 - mmengine - INFO - Iter(train) [ 5950/80000]  base_lr: 9.3282e-05 lr: 9.3282e-06  eta: 8:57:13  time: 0.4354  data_time: 0.0088  memory: 5261  grad_norm: 134.5486  loss: 17.6547  decode.loss_cls: 0.8984  decode.loss_mask: 0.3376  decode.loss_dice: 0.4431  decode.d0.loss_cls: 1.6007  decode.d0.loss_mask: 0.3343  decode.d0.loss_dice: 0.5045  decode.d1.loss_cls: 0.9290  decode.d1.loss_mask: 0.3452  decode.d1.loss_dice: 0.4482  decode.d2.loss_cls: 0.8299  decode.d2.loss_mask: 0.3435  decode.d2.loss_dice: 0.4547  decode.d3.loss_cls: 0.8842  decode.d3.loss_mask: 0.3433  decode.d3.loss_dice: 0.4828  decode.d4.loss_cls: 0.8508  decode.d4.loss_mask: 0.3344  decode.d4.loss_dice: 0.4834  decode.d5.loss_cls: 0.9631  decode.d5.loss_mask: 0.3387  decode.d5.loss_dice: 0.4275  decode.d6.loss_cls: 0.9101  decode.d6.loss_mask: 0.3357  decode.d6.loss_dice: 0.4337  decode.d7.loss_cls: 0.9248  decode.d7.loss_mask: 0.3385  decode.d7.loss_dice: 0.4474  decode.d8.loss_cls: 0.8744  decode.d8.loss_mask: 0.3391  decode.d8.loss_dice: 0.4736
07/30 17:23:48 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 17:23:48 - mmengine - INFO - Iter(train) [ 6000/80000]  base_lr: 9.3225e-05 lr: 9.3225e-06  eta: 8:56:51  time: 0.4352  data_time: 0.0089  memory: 5261  grad_norm: 176.7198  loss: 17.3289  decode.loss_cls: 0.7032  decode.loss_mask: 0.5091  decode.loss_dice: 0.4255  decode.d0.loss_cls: 1.5433  decode.d0.loss_mask: 0.4991  decode.d0.loss_dice: 0.4306  decode.d1.loss_cls: 0.7042  decode.d1.loss_mask: 0.5162  decode.d1.loss_dice: 0.4174  decode.d2.loss_cls: 0.6793  decode.d2.loss_mask: 0.5210  decode.d2.loss_dice: 0.4328  decode.d3.loss_cls: 0.6825  decode.d3.loss_mask: 0.5395  decode.d3.loss_dice: 0.4204  decode.d4.loss_cls: 0.6880  decode.d4.loss_mask: 0.5460  decode.d4.loss_dice: 0.4250  decode.d5.loss_cls: 0.7589  decode.d5.loss_mask: 0.5159  decode.d5.loss_dice: 0.4310  decode.d6.loss_cls: 0.7366  decode.d6.loss_mask: 0.4985  decode.d6.loss_dice: 0.4187  decode.d7.loss_cls: 0.6519  decode.d7.loss_mask: 0.5205  decode.d7.loss_dice: 0.4321  decode.d8.loss_cls: 0.7295  decode.d8.loss_mask: 0.5218  decode.d8.loss_dice: 0.4305
07/30 17:24:10 - mmengine - INFO - Iter(train) [ 6050/80000]  base_lr: 9.3168e-05 lr: 9.3168e-06  eta: 8:56:29  time: 0.4354  data_time: 0.0087  memory: 5265  grad_norm: 201.3213  loss: 14.1025  decode.loss_cls: 0.5833  decode.loss_mask: 0.3008  decode.loss_dice: 0.3965  decode.d0.loss_cls: 1.4138  decode.d0.loss_mask: 0.3876  decode.d0.loss_dice: 0.5319  decode.d1.loss_cls: 0.7345  decode.d1.loss_mask: 0.3116  decode.d1.loss_dice: 0.4437  decode.d2.loss_cls: 0.5679  decode.d2.loss_mask: 0.3123  decode.d2.loss_dice: 0.4298  decode.d3.loss_cls: 0.5221  decode.d3.loss_mask: 0.3195  decode.d3.loss_dice: 0.3891  decode.d4.loss_cls: 0.5847  decode.d4.loss_mask: 0.3299  decode.d4.loss_dice: 0.4285  decode.d5.loss_cls: 0.5613  decode.d5.loss_mask: 0.3203  decode.d5.loss_dice: 0.4244  decode.d6.loss_cls: 0.5080  decode.d6.loss_mask: 0.3284  decode.d6.loss_dice: 0.4197  decode.d7.loss_cls: 0.5403  decode.d7.loss_mask: 0.3170  decode.d7.loss_dice: 0.4285  decode.d8.loss_cls: 0.5444  decode.d8.loss_mask: 0.3225  decode.d8.loss_dice: 0.4003
07/30 17:24:31 - mmengine - INFO - Iter(train) [ 6100/80000]  base_lr: 9.3112e-05 lr: 9.3112e-06  eta: 8:56:07  time: 0.4337  data_time: 0.0088  memory: 5229  grad_norm: 146.0408  loss: 13.6683  decode.loss_cls: 0.5413  decode.loss_mask: 0.3359  decode.loss_dice: 0.3751  decode.d0.loss_cls: 1.4240  decode.d0.loss_mask: 0.3404  decode.d0.loss_dice: 0.4492  decode.d1.loss_cls: 0.5983  decode.d1.loss_mask: 0.3486  decode.d1.loss_dice: 0.3602  decode.d2.loss_cls: 0.5352  decode.d2.loss_mask: 0.3378  decode.d2.loss_dice: 0.3823  decode.d3.loss_cls: 0.6367  decode.d3.loss_mask: 0.3278  decode.d3.loss_dice: 0.3325  decode.d4.loss_cls: 0.5985  decode.d4.loss_mask: 0.3186  decode.d4.loss_dice: 0.3585  decode.d5.loss_cls: 0.5913  decode.d5.loss_mask: 0.3260  decode.d5.loss_dice: 0.3631  decode.d6.loss_cls: 0.5687  decode.d6.loss_mask: 0.3186  decode.d6.loss_dice: 0.3579  decode.d7.loss_cls: 0.5504  decode.d7.loss_mask: 0.3197  decode.d7.loss_dice: 0.3730  decode.d8.loss_cls: 0.5816  decode.d8.loss_mask: 0.3347  decode.d8.loss_dice: 0.3824
07/30 17:24:53 - mmengine - INFO - Iter(train) [ 6150/80000]  base_lr: 9.3055e-05 lr: 9.3055e-06  eta: 8:55:45  time: 0.4349  data_time: 0.0087  memory: 5279  grad_norm: 141.5457  loss: 15.1550  decode.loss_cls: 0.6645  decode.loss_mask: 0.3068  decode.loss_dice: 0.3682  decode.d0.loss_cls: 1.6530  decode.d0.loss_mask: 0.3393  decode.d0.loss_dice: 0.4657  decode.d1.loss_cls: 0.7624  decode.d1.loss_mask: 0.3240  decode.d1.loss_dice: 0.4012  decode.d2.loss_cls: 0.7542  decode.d2.loss_mask: 0.3040  decode.d2.loss_dice: 0.3804  decode.d3.loss_cls: 0.6891  decode.d3.loss_mask: 0.3065  decode.d3.loss_dice: 0.3823  decode.d4.loss_cls: 0.7144  decode.d4.loss_mask: 0.3234  decode.d4.loss_dice: 0.4076  decode.d5.loss_cls: 0.7307  decode.d5.loss_mask: 0.3300  decode.d5.loss_dice: 0.4158  decode.d6.loss_cls: 0.6861  decode.d6.loss_mask: 0.3193  decode.d6.loss_dice: 0.3956  decode.d7.loss_cls: 0.6881  decode.d7.loss_mask: 0.3078  decode.d7.loss_dice: 0.3852  decode.d8.loss_cls: 0.6582  decode.d8.loss_mask: 0.3111  decode.d8.loss_dice: 0.3801
07/30 17:25:15 - mmengine - INFO - Iter(train) [ 6200/80000]  base_lr: 9.2998e-05 lr: 9.2998e-06  eta: 8:55:23  time: 0.4350  data_time: 0.0088  memory: 5277  grad_norm: 125.7470  loss: 12.1986  decode.loss_cls: 0.4679  decode.loss_mask: 0.3483  decode.loss_dice: 0.3088  decode.d0.loss_cls: 1.5069  decode.d0.loss_mask: 0.3402  decode.d0.loss_dice: 0.3715  decode.d1.loss_cls: 0.6294  decode.d1.loss_mask: 0.2794  decode.d1.loss_dice: 0.3131  decode.d2.loss_cls: 0.4692  decode.d2.loss_mask: 0.3295  decode.d2.loss_dice: 0.3058  decode.d3.loss_cls: 0.4649  decode.d3.loss_mask: 0.2771  decode.d3.loss_dice: 0.2970  decode.d4.loss_cls: 0.4805  decode.d4.loss_mask: 0.2707  decode.d4.loss_dice: 0.3034  decode.d5.loss_cls: 0.4712  decode.d5.loss_mask: 0.2843  decode.d5.loss_dice: 0.3005  decode.d6.loss_cls: 0.5490  decode.d6.loss_mask: 0.2694  decode.d6.loss_dice: 0.2940  decode.d7.loss_cls: 0.5142  decode.d7.loss_mask: 0.3180  decode.d7.loss_dice: 0.3134  decode.d8.loss_cls: 0.4944  decode.d8.loss_mask: 0.3254  decode.d8.loss_dice: 0.3012
07/30 17:25:37 - mmengine - INFO - Iter(train) [ 6250/80000]  base_lr: 9.2942e-05 lr: 9.2942e-06  eta: 8:55:01  time: 0.4353  data_time: 0.0089  memory: 5265  grad_norm: 110.8428  loss: 12.3623  decode.loss_cls: 0.5240  decode.loss_mask: 0.2828  decode.loss_dice: 0.3429  decode.d0.loss_cls: 1.4752  decode.d0.loss_mask: 0.2894  decode.d0.loss_dice: 0.3702  decode.d1.loss_cls: 0.5831  decode.d1.loss_mask: 0.2786  decode.d1.loss_dice: 0.3226  decode.d2.loss_cls: 0.5206  decode.d2.loss_mask: 0.2774  decode.d2.loss_dice: 0.3514  decode.d3.loss_cls: 0.4799  decode.d3.loss_mask: 0.2763  decode.d3.loss_dice: 0.3549  decode.d4.loss_cls: 0.4895  decode.d4.loss_mask: 0.2736  decode.d4.loss_dice: 0.3546  decode.d5.loss_cls: 0.4855  decode.d5.loss_mask: 0.2956  decode.d5.loss_dice: 0.3234  decode.d6.loss_cls: 0.5163  decode.d6.loss_mask: 0.2745  decode.d6.loss_dice: 0.3276  decode.d7.loss_cls: 0.5440  decode.d7.loss_mask: 0.2799  decode.d7.loss_dice: 0.3423  decode.d8.loss_cls: 0.5374  decode.d8.loss_mask: 0.2680  decode.d8.loss_dice: 0.3207
07/30 17:25:58 - mmengine - INFO - Iter(train) [ 6300/80000]  base_lr: 9.2885e-05 lr: 9.2885e-06  eta: 8:54:39  time: 0.4357  data_time: 0.0090  memory: 5265  grad_norm: 106.3958  loss: 13.8237  decode.loss_cls: 0.7141  decode.loss_mask: 0.2585  decode.loss_dice: 0.3000  decode.d0.loss_cls: 1.7131  decode.d0.loss_mask: 0.2540  decode.d0.loss_dice: 0.3714  decode.d1.loss_cls: 0.8027  decode.d1.loss_mask: 0.2567  decode.d1.loss_dice: 0.3055  decode.d2.loss_cls: 0.6203  decode.d2.loss_mask: 0.2720  decode.d2.loss_dice: 0.3237  decode.d3.loss_cls: 0.6744  decode.d3.loss_mask: 0.2595  decode.d3.loss_dice: 0.3102  decode.d4.loss_cls: 0.6936  decode.d4.loss_mask: 0.2575  decode.d4.loss_dice: 0.3007  decode.d5.loss_cls: 0.6554  decode.d5.loss_mask: 0.2530  decode.d5.loss_dice: 0.3137  decode.d6.loss_cls: 0.7102  decode.d6.loss_mask: 0.2572  decode.d6.loss_dice: 0.3144  decode.d7.loss_cls: 0.8182  decode.d7.loss_mask: 0.2633  decode.d7.loss_dice: 0.3136  decode.d8.loss_cls: 0.6544  decode.d8.loss_mask: 0.2573  decode.d8.loss_dice: 0.3251
07/30 17:26:20 - mmengine - INFO - Iter(train) [ 6350/80000]  base_lr: 9.2828e-05 lr: 9.2828e-06  eta: 8:54:18  time: 0.4365  data_time: 0.0087  memory: 5323  grad_norm: 142.7811  loss: 13.7503  decode.loss_cls: 0.4967  decode.loss_mask: 0.3134  decode.loss_dice: 0.3926  decode.d0.loss_cls: 1.5892  decode.d0.loss_mask: 0.3275  decode.d0.loss_dice: 0.4196  decode.d1.loss_cls: 0.7039  decode.d1.loss_mask: 0.3477  decode.d1.loss_dice: 0.4351  decode.d2.loss_cls: 0.6048  decode.d2.loss_mask: 0.3178  decode.d2.loss_dice: 0.3932  decode.d3.loss_cls: 0.6223  decode.d3.loss_mask: 0.3195  decode.d3.loss_dice: 0.3640  decode.d4.loss_cls: 0.5501  decode.d4.loss_mask: 0.3092  decode.d4.loss_dice: 0.3683  decode.d5.loss_cls: 0.5621  decode.d5.loss_mask: 0.3119  decode.d5.loss_dice: 0.3689  decode.d6.loss_cls: 0.5713  decode.d6.loss_mask: 0.3080  decode.d6.loss_dice: 0.3637  decode.d7.loss_cls: 0.5088  decode.d7.loss_mask: 0.3115  decode.d7.loss_dice: 0.3707  decode.d8.loss_cls: 0.4962  decode.d8.loss_mask: 0.3224  decode.d8.loss_dice: 0.3801
07/30 17:26:42 - mmengine - INFO - Iter(train) [ 6400/80000]  base_lr: 9.2771e-05 lr: 9.2771e-06  eta: 8:53:57  time: 0.4367  data_time: 0.0089  memory: 5265  grad_norm: 121.1012  loss: 12.2468  decode.loss_cls: 0.4731  decode.loss_mask: 0.2801  decode.loss_dice: 0.3007  decode.d0.loss_cls: 1.3616  decode.d0.loss_mask: 0.3114  decode.d0.loss_dice: 0.4128  decode.d1.loss_cls: 0.5379  decode.d1.loss_mask: 0.2992  decode.d1.loss_dice: 0.3555  decode.d2.loss_cls: 0.5779  decode.d2.loss_mask: 0.2904  decode.d2.loss_dice: 0.3342  decode.d3.loss_cls: 0.5525  decode.d3.loss_mask: 0.2953  decode.d3.loss_dice: 0.3157  decode.d4.loss_cls: 0.5674  decode.d4.loss_mask: 0.2886  decode.d4.loss_dice: 0.3261  decode.d5.loss_cls: 0.4559  decode.d5.loss_mask: 0.3065  decode.d5.loss_dice: 0.3154  decode.d6.loss_cls: 0.4910  decode.d6.loss_mask: 0.2993  decode.d6.loss_dice: 0.3070  decode.d7.loss_cls: 0.4882  decode.d7.loss_mask: 0.2881  decode.d7.loss_dice: 0.3193  decode.d8.loss_cls: 0.4892  decode.d8.loss_mask: 0.2842  decode.d8.loss_dice: 0.3224
07/30 17:27:04 - mmengine - INFO - Iter(train) [ 6450/80000]  base_lr: 9.2715e-05 lr: 9.2715e-06  eta: 8:53:35  time: 0.4359  data_time: 0.0089  memory: 5265  grad_norm: 346.3403  loss: 18.2815  decode.loss_cls: 0.6765  decode.loss_mask: 0.4395  decode.loss_dice: 0.5558  decode.d0.loss_cls: 1.5754  decode.d0.loss_mask: 0.4594  decode.d0.loss_dice: 0.5964  decode.d1.loss_cls: 0.9911  decode.d1.loss_mask: 0.4476  decode.d1.loss_dice: 0.5387  decode.d2.loss_cls: 0.7382  decode.d2.loss_mask: 0.4646  decode.d2.loss_dice: 0.5542  decode.d3.loss_cls: 0.7549  decode.d3.loss_mask: 0.4428  decode.d3.loss_dice: 0.5258  decode.d4.loss_cls: 0.7357  decode.d4.loss_mask: 0.4596  decode.d4.loss_dice: 0.5162  decode.d5.loss_cls: 0.7498  decode.d5.loss_mask: 0.4351  decode.d5.loss_dice: 0.4967  decode.d6.loss_cls: 0.7044  decode.d6.loss_mask: 0.4725  decode.d6.loss_dice: 0.5167  decode.d7.loss_cls: 0.7474  decode.d7.loss_mask: 0.4395  decode.d7.loss_dice: 0.5252  decode.d8.loss_cls: 0.6969  decode.d8.loss_mask: 0.4778  decode.d8.loss_dice: 0.5473
07/30 17:27:26 - mmengine - INFO - Iter(train) [ 6500/80000]  base_lr: 9.2658e-05 lr: 9.2658e-06  eta: 8:53:14  time: 0.4359  data_time: 0.0088  memory: 5321  grad_norm: 209.3519  loss: 16.2396  decode.loss_cls: 0.7019  decode.loss_mask: 0.3910  decode.loss_dice: 0.3884  decode.d0.loss_cls: 1.5868  decode.d0.loss_mask: 0.4282  decode.d0.loss_dice: 0.5051  decode.d1.loss_cls: 0.7873  decode.d1.loss_mask: 0.3768  decode.d1.loss_dice: 0.4261  decode.d2.loss_cls: 0.6783  decode.d2.loss_mask: 0.3919  decode.d2.loss_dice: 0.3752  decode.d3.loss_cls: 0.8068  decode.d3.loss_mask: 0.3742  decode.d3.loss_dice: 0.4057  decode.d4.loss_cls: 0.7457  decode.d4.loss_mask: 0.3774  decode.d4.loss_dice: 0.4235  decode.d5.loss_cls: 0.7362  decode.d5.loss_mask: 0.3779  decode.d5.loss_dice: 0.3911  decode.d6.loss_cls: 0.7184  decode.d6.loss_mask: 0.3959  decode.d6.loss_dice: 0.4088  decode.d7.loss_cls: 0.7286  decode.d7.loss_mask: 0.4052  decode.d7.loss_dice: 0.4101  decode.d8.loss_cls: 0.7228  decode.d8.loss_mask: 0.3871  decode.d8.loss_dice: 0.3874
07/30 17:27:47 - mmengine - INFO - Iter(train) [ 6550/80000]  base_lr: 9.2601e-05 lr: 9.2601e-06  eta: 8:52:52  time: 0.4359  data_time: 0.0089  memory: 5261  grad_norm: 138.5368  loss: 14.1880  decode.loss_cls: 0.5532  decode.loss_mask: 0.3645  decode.loss_dice: 0.3683  decode.d0.loss_cls: 1.5116  decode.d0.loss_mask: 0.3719  decode.d0.loss_dice: 0.4091  decode.d1.loss_cls: 0.7189  decode.d1.loss_mask: 0.3252  decode.d1.loss_dice: 0.3387  decode.d2.loss_cls: 0.6817  decode.d2.loss_mask: 0.3383  decode.d2.loss_dice: 0.3746  decode.d3.loss_cls: 0.6187  decode.d3.loss_mask: 0.3221  decode.d3.loss_dice: 0.3391  decode.d4.loss_cls: 0.5847  decode.d4.loss_mask: 0.3404  decode.d4.loss_dice: 0.3676  decode.d5.loss_cls: 0.6109  decode.d5.loss_mask: 0.3347  decode.d5.loss_dice: 0.3556  decode.d6.loss_cls: 0.5993  decode.d6.loss_mask: 0.3584  decode.d6.loss_dice: 0.3770  decode.d7.loss_cls: 0.5942  decode.d7.loss_mask: 0.3614  decode.d7.loss_dice: 0.3687  decode.d8.loss_cls: 0.5701  decode.d8.loss_mask: 0.3612  decode.d8.loss_dice: 0.3682
07/30 17:28:09 - mmengine - INFO - Iter(train) [ 6600/80000]  base_lr: 9.2544e-05 lr: 9.2544e-06  eta: 8:52:30  time: 0.4354  data_time: 0.0091  memory: 5304  grad_norm: 88.3934  loss: 12.6615  decode.loss_cls: 0.4337  decode.loss_mask: 0.3303  decode.loss_dice: 0.3312  decode.d0.loss_cls: 1.4081  decode.d0.loss_mask: 0.3517  decode.d0.loss_dice: 0.4039  decode.d1.loss_cls: 0.6209  decode.d1.loss_mask: 0.3386  decode.d1.loss_dice: 0.3461  decode.d2.loss_cls: 0.5675  decode.d2.loss_mask: 0.3400  decode.d2.loss_dice: 0.3386  decode.d3.loss_cls: 0.4532  decode.d3.loss_mask: 0.3392  decode.d3.loss_dice: 0.3339  decode.d4.loss_cls: 0.4469  decode.d4.loss_mask: 0.3339  decode.d4.loss_dice: 0.3412  decode.d5.loss_cls: 0.5158  decode.d5.loss_mask: 0.3342  decode.d5.loss_dice: 0.3412  decode.d6.loss_cls: 0.4797  decode.d6.loss_mask: 0.3302  decode.d6.loss_dice: 0.3382  decode.d7.loss_cls: 0.4879  decode.d7.loss_mask: 0.3303  decode.d7.loss_dice: 0.3336  decode.d8.loss_cls: 0.4566  decode.d8.loss_mask: 0.3237  decode.d8.loss_dice: 0.3310
07/30 17:28:31 - mmengine - INFO - Iter(train) [ 6650/80000]  base_lr: 9.2488e-05 lr: 9.2488e-06  eta: 8:52:09  time: 0.4353  data_time: 0.0087  memory: 5229  grad_norm: 70.2485  loss: 11.7128  decode.loss_cls: 0.4400  decode.loss_mask: 0.3024  decode.loss_dice: 0.3510  decode.d0.loss_cls: 1.2259  decode.d0.loss_mask: 0.3155  decode.d0.loss_dice: 0.3646  decode.d1.loss_cls: 0.5384  decode.d1.loss_mask: 0.3122  decode.d1.loss_dice: 0.3467  decode.d2.loss_cls: 0.4065  decode.d2.loss_mask: 0.3008  decode.d2.loss_dice: 0.3353  decode.d3.loss_cls: 0.3936  decode.d3.loss_mask: 0.2984  decode.d3.loss_dice: 0.3807  decode.d4.loss_cls: 0.3864  decode.d4.loss_mask: 0.2983  decode.d4.loss_dice: 0.3392  decode.d5.loss_cls: 0.4033  decode.d5.loss_mask: 0.2988  decode.d5.loss_dice: 0.3662  decode.d6.loss_cls: 0.3903  decode.d6.loss_mask: 0.3047  decode.d6.loss_dice: 0.3728  decode.d7.loss_cls: 0.4197  decode.d7.loss_mask: 0.3020  decode.d7.loss_dice: 0.4000  decode.d8.loss_cls: 0.4407  decode.d8.loss_mask: 0.3009  decode.d8.loss_dice: 0.3773
07/30 17:28:53 - mmengine - INFO - Iter(train) [ 6700/80000]  base_lr: 9.2431e-05 lr: 9.2431e-06  eta: 8:51:47  time: 0.4351  data_time: 0.0088  memory: 5265  grad_norm: 80.8609  loss: 10.7281  decode.loss_cls: 0.3262  decode.loss_mask: 0.3085  decode.loss_dice: 0.3155  decode.d0.loss_cls: 1.2875  decode.d0.loss_mask: 0.3207  decode.d0.loss_dice: 0.3322  decode.d1.loss_cls: 0.4616  decode.d1.loss_mask: 0.3127  decode.d1.loss_dice: 0.3265  decode.d2.loss_cls: 0.3603  decode.d2.loss_mask: 0.3087  decode.d2.loss_dice: 0.3002  decode.d3.loss_cls: 0.3716  decode.d3.loss_mask: 0.3081  decode.d3.loss_dice: 0.2975  decode.d4.loss_cls: 0.3412  decode.d4.loss_mask: 0.2974  decode.d4.loss_dice: 0.3081  decode.d5.loss_cls: 0.3444  decode.d5.loss_mask: 0.3029  decode.d5.loss_dice: 0.3032  decode.d6.loss_cls: 0.3015  decode.d6.loss_mask: 0.3080  decode.d6.loss_dice: 0.3113  decode.d7.loss_cls: 0.3613  decode.d7.loss_mask: 0.3033  decode.d7.loss_dice: 0.3286  decode.d8.loss_cls: 0.3542  decode.d8.loss_mask: 0.3042  decode.d8.loss_dice: 0.3207
07/30 17:29:14 - mmengine - INFO - Iter(train) [ 6750/80000]  base_lr: 9.2374e-05 lr: 9.2374e-06  eta: 8:51:25  time: 0.4352  data_time: 0.0087  memory: 5305  grad_norm: 87.6922  loss: 11.6613  decode.loss_cls: 0.3854  decode.loss_mask: 0.2819  decode.loss_dice: 0.3550  decode.d0.loss_cls: 1.3221  decode.d0.loss_mask: 0.2970  decode.d0.loss_dice: 0.3885  decode.d1.loss_cls: 0.5864  decode.d1.loss_mask: 0.2921  decode.d1.loss_dice: 0.3557  decode.d2.loss_cls: 0.4423  decode.d2.loss_mask: 0.2858  decode.d2.loss_dice: 0.3315  decode.d3.loss_cls: 0.3836  decode.d3.loss_mask: 0.2851  decode.d3.loss_dice: 0.3543  decode.d4.loss_cls: 0.3764  decode.d4.loss_mask: 0.2876  decode.d4.loss_dice: 0.3701  decode.d5.loss_cls: 0.3983  decode.d5.loss_mask: 0.2907  decode.d5.loss_dice: 0.3882  decode.d6.loss_cls: 0.4038  decode.d6.loss_mask: 0.2873  decode.d6.loss_dice: 0.3656  decode.d7.loss_cls: 0.4351  decode.d7.loss_mask: 0.2830  decode.d7.loss_dice: 0.3659  decode.d8.loss_cls: 0.4282  decode.d8.loss_mask: 0.2837  decode.d8.loss_dice: 0.3509
07/30 17:29:36 - mmengine - INFO - Iter(train) [ 6800/80000]  base_lr: 9.2317e-05 lr: 9.2317e-06  eta: 8:51:04  time: 0.4360  data_time: 0.0088  memory: 5265  grad_norm: 83.1979  loss: 11.9552  decode.loss_cls: 0.5380  decode.loss_mask: 0.2824  decode.loss_dice: 0.2989  decode.d0.loss_cls: 1.4938  decode.d0.loss_mask: 0.2927  decode.d0.loss_dice: 0.3567  decode.d1.loss_cls: 0.5818  decode.d1.loss_mask: 0.2830  decode.d1.loss_dice: 0.3030  decode.d2.loss_cls: 0.4955  decode.d2.loss_mask: 0.2850  decode.d2.loss_dice: 0.2955  decode.d3.loss_cls: 0.4237  decode.d3.loss_mask: 0.2760  decode.d3.loss_dice: 0.3019  decode.d4.loss_cls: 0.4450  decode.d4.loss_mask: 0.2805  decode.d4.loss_dice: 0.3023  decode.d5.loss_cls: 0.5028  decode.d5.loss_mask: 0.2826  decode.d5.loss_dice: 0.3237  decode.d6.loss_cls: 0.5445  decode.d6.loss_mask: 0.2756  decode.d6.loss_dice: 0.3177  decode.d7.loss_cls: 0.5172  decode.d7.loss_mask: 0.2826  decode.d7.loss_dice: 0.3017  decode.d8.loss_cls: 0.4818  decode.d8.loss_mask: 0.2789  decode.d8.loss_dice: 0.3103
07/30 17:29:58 - mmengine - INFO - Iter(train) [ 6850/80000]  base_lr: 9.2261e-05 lr: 9.2261e-06  eta: 8:50:42  time: 0.4365  data_time: 0.0090  memory: 5261  grad_norm: 106.4205  loss: 12.4136  decode.loss_cls: 0.5537  decode.loss_mask: 0.2653  decode.loss_dice: 0.3258  decode.d0.loss_cls: 1.5826  decode.d0.loss_mask: 0.2815  decode.d0.loss_dice: 0.3845  decode.d1.loss_cls: 0.5808  decode.d1.loss_mask: 0.2723  decode.d1.loss_dice: 0.3526  decode.d2.loss_cls: 0.5168  decode.d2.loss_mask: 0.2729  decode.d2.loss_dice: 0.3306  decode.d3.loss_cls: 0.5760  decode.d3.loss_mask: 0.2644  decode.d3.loss_dice: 0.3185  decode.d4.loss_cls: 0.5259  decode.d4.loss_mask: 0.2655  decode.d4.loss_dice: 0.3295  decode.d5.loss_cls: 0.4836  decode.d5.loss_mask: 0.2625  decode.d5.loss_dice: 0.3274  decode.d6.loss_cls: 0.5143  decode.d6.loss_mask: 0.2692  decode.d6.loss_dice: 0.3331  decode.d7.loss_cls: 0.5178  decode.d7.loss_mask: 0.2699  decode.d7.loss_dice: 0.3295  decode.d8.loss_cls: 0.5023  decode.d8.loss_mask: 0.2700  decode.d8.loss_dice: 0.3350
07/30 17:30:20 - mmengine - INFO - Iter(train) [ 6900/80000]  base_lr: 9.2204e-05 lr: 9.2204e-06  eta: 8:50:21  time: 0.4357  data_time: 0.0088  memory: 5246  grad_norm: 129.9013  loss: 12.0020  decode.loss_cls: 0.4112  decode.loss_mask: 0.3779  decode.loss_dice: 0.3748  decode.d0.loss_cls: 1.1008  decode.d0.loss_mask: 0.3847  decode.d0.loss_dice: 0.4150  decode.d1.loss_cls: 0.4186  decode.d1.loss_mask: 0.3588  decode.d1.loss_dice: 0.3889  decode.d2.loss_cls: 0.3056  decode.d2.loss_mask: 0.3650  decode.d2.loss_dice: 0.3958  decode.d3.loss_cls: 0.3119  decode.d3.loss_mask: 0.3634  decode.d3.loss_dice: 0.3885  decode.d4.loss_cls: 0.3504  decode.d4.loss_mask: 0.3647  decode.d4.loss_dice: 0.3839  decode.d5.loss_cls: 0.3249  decode.d5.loss_mask: 0.3790  decode.d5.loss_dice: 0.3910  decode.d6.loss_cls: 0.3432  decode.d6.loss_mask: 0.3915  decode.d6.loss_dice: 0.3890  decode.d7.loss_cls: 0.4068  decode.d7.loss_mask: 0.3812  decode.d7.loss_dice: 0.3856  decode.d8.loss_cls: 0.3685  decode.d8.loss_mask: 0.3965  decode.d8.loss_dice: 0.3849
07/30 17:30:42 - mmengine - INFO - Iter(train) [ 6950/80000]  base_lr: 9.2147e-05 lr: 9.2147e-06  eta: 8:49:59  time: 0.4350  data_time: 0.0089  memory: 5265  grad_norm: 194.5836  loss: 17.7392  decode.loss_cls: 0.6551  decode.loss_mask: 0.4673  decode.loss_dice: 0.4970  decode.d0.loss_cls: 1.5463  decode.d0.loss_mask: 0.4725  decode.d0.loss_dice: 0.5498  decode.d1.loss_cls: 0.7767  decode.d1.loss_mask: 0.4639  decode.d1.loss_dice: 0.5008  decode.d2.loss_cls: 0.6649  decode.d2.loss_mask: 0.5197  decode.d2.loss_dice: 0.4619  decode.d3.loss_cls: 0.7625  decode.d3.loss_mask: 0.4901  decode.d3.loss_dice: 0.4893  decode.d4.loss_cls: 0.7602  decode.d4.loss_mask: 0.5192  decode.d4.loss_dice: 0.4924  decode.d5.loss_cls: 0.7285  decode.d5.loss_mask: 0.4651  decode.d5.loss_dice: 0.5005  decode.d6.loss_cls: 0.7167  decode.d6.loss_mask: 0.4703  decode.d6.loss_dice: 0.4849  decode.d7.loss_cls: 0.6897  decode.d7.loss_mask: 0.4670  decode.d7.loss_dice: 0.5010  decode.d8.loss_cls: 0.6892  decode.d8.loss_mask: 0.4429  decode.d8.loss_dice: 0.4935
07/30 17:31:03 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 17:31:03 - mmengine - INFO - Iter(train) [ 7000/80000]  base_lr: 9.2090e-05 lr: 9.2090e-06  eta: 8:49:37  time: 0.4352  data_time: 0.0089  memory: 5244  grad_norm: 132.5738  loss: 12.4533  decode.loss_cls: 0.4834  decode.loss_mask: 0.4068  decode.loss_dice: 0.3085  decode.d0.loss_cls: 1.1783  decode.d0.loss_mask: 0.4633  decode.d0.loss_dice: 0.3741  decode.d1.loss_cls: 0.5264  decode.d1.loss_mask: 0.4370  decode.d1.loss_dice: 0.3209  decode.d2.loss_cls: 0.4192  decode.d2.loss_mask: 0.4235  decode.d2.loss_dice: 0.3218  decode.d3.loss_cls: 0.4066  decode.d3.loss_mask: 0.4098  decode.d3.loss_dice: 0.3139  decode.d4.loss_cls: 0.3851  decode.d4.loss_mask: 0.4112  decode.d4.loss_dice: 0.3081  decode.d5.loss_cls: 0.3808  decode.d5.loss_mask: 0.4190  decode.d5.loss_dice: 0.3145  decode.d6.loss_cls: 0.3662  decode.d6.loss_mask: 0.4152  decode.d6.loss_dice: 0.3084  decode.d7.loss_cls: 0.4555  decode.d7.loss_mask: 0.4193  decode.d7.loss_dice: 0.3325  decode.d8.loss_cls: 0.4176  decode.d8.loss_mask: 0.4091  decode.d8.loss_dice: 0.3174
07/30 17:31:25 - mmengine - INFO - Iter(train) [ 7050/80000]  base_lr: 9.2034e-05 lr: 9.2034e-06  eta: 8:49:16  time: 0.4360  data_time: 0.0085  memory: 5246  grad_norm: 103.6544  loss: 10.6037  decode.loss_cls: 0.4201  decode.loss_mask: 0.2495  decode.loss_dice: 0.3126  decode.d0.loss_cls: 1.2406  decode.d0.loss_mask: 0.2418  decode.d0.loss_dice: 0.3496  decode.d1.loss_cls: 0.4742  decode.d1.loss_mask: 0.2406  decode.d1.loss_dice: 0.3100  decode.d2.loss_cls: 0.3754  decode.d2.loss_mask: 0.2447  decode.d2.loss_dice: 0.3134  decode.d3.loss_cls: 0.4146  decode.d3.loss_mask: 0.2516  decode.d3.loss_dice: 0.3101  decode.d4.loss_cls: 0.4518  decode.d4.loss_mask: 0.2457  decode.d4.loss_dice: 0.3032  decode.d5.loss_cls: 0.4295  decode.d5.loss_mask: 0.2454  decode.d5.loss_dice: 0.3083  decode.d6.loss_cls: 0.3633  decode.d6.loss_mask: 0.2401  decode.d6.loss_dice: 0.3107  decode.d7.loss_cls: 0.4077  decode.d7.loss_mask: 0.2458  decode.d7.loss_dice: 0.3131  decode.d8.loss_cls: 0.4115  decode.d8.loss_mask: 0.2597  decode.d8.loss_dice: 0.3190
07/30 17:31:47 - mmengine - INFO - Iter(train) [ 7100/80000]  base_lr: 9.1977e-05 lr: 9.1977e-06  eta: 8:48:54  time: 0.4351  data_time: 0.0088  memory: 5265  grad_norm: 114.0329  loss: 12.9268  decode.loss_cls: 0.4122  decode.loss_mask: 0.3882  decode.loss_dice: 0.3909  decode.d0.loss_cls: 1.2979  decode.d0.loss_mask: 0.3879  decode.d0.loss_dice: 0.4629  decode.d1.loss_cls: 0.6161  decode.d1.loss_mask: 0.3448  decode.d1.loss_dice: 0.3913  decode.d2.loss_cls: 0.5016  decode.d2.loss_mask: 0.3288  decode.d2.loss_dice: 0.3707  decode.d3.loss_cls: 0.4626  decode.d3.loss_mask: 0.3362  decode.d3.loss_dice: 0.3694  decode.d4.loss_cls: 0.4875  decode.d4.loss_mask: 0.3343  decode.d4.loss_dice: 0.3581  decode.d5.loss_cls: 0.4334  decode.d5.loss_mask: 0.3447  decode.d5.loss_dice: 0.3820  decode.d6.loss_cls: 0.4315  decode.d6.loss_mask: 0.3479  decode.d6.loss_dice: 0.3507  decode.d7.loss_cls: 0.5007  decode.d7.loss_mask: 0.3373  decode.d7.loss_dice: 0.3529  decode.d8.loss_cls: 0.5124  decode.d8.loss_mask: 0.3382  decode.d8.loss_dice: 0.3538
07/30 17:32:09 - mmengine - INFO - Iter(train) [ 7150/80000]  base_lr: 9.1920e-05 lr: 9.1920e-06  eta: 8:48:33  time: 0.4351  data_time: 0.0087  memory: 5244  grad_norm: 118.7249  loss: 11.1447  decode.loss_cls: 0.3713  decode.loss_mask: 0.2852  decode.loss_dice: 0.3251  decode.d0.loss_cls: 1.3108  decode.d0.loss_mask: 0.2830  decode.d0.loss_dice: 0.3622  decode.d1.loss_cls: 0.5015  decode.d1.loss_mask: 0.2877  decode.d1.loss_dice: 0.3186  decode.d2.loss_cls: 0.4065  decode.d2.loss_mask: 0.2880  decode.d2.loss_dice: 0.3504  decode.d3.loss_cls: 0.3842  decode.d3.loss_mask: 0.2808  decode.d3.loss_dice: 0.3429  decode.d4.loss_cls: 0.3794  decode.d4.loss_mask: 0.2851  decode.d4.loss_dice: 0.3467  decode.d5.loss_cls: 0.4092  decode.d5.loss_mask: 0.2801  decode.d5.loss_dice: 0.3250  decode.d6.loss_cls: 0.3547  decode.d6.loss_mask: 0.2873  decode.d6.loss_dice: 0.3270  decode.d7.loss_cls: 0.3955  decode.d7.loss_mask: 0.2985  decode.d7.loss_dice: 0.3398  decode.d8.loss_cls: 0.3994  decode.d8.loss_mask: 0.2907  decode.d8.loss_dice: 0.3281
07/30 17:32:31 - mmengine - INFO - Iter(train) [ 7200/80000]  base_lr: 9.1863e-05 lr: 9.1863e-06  eta: 8:48:11  time: 0.4350  data_time: 0.0088  memory: 5246  grad_norm: 150.9493  loss: 13.1384  decode.loss_cls: 0.5022  decode.loss_mask: 0.3590  decode.loss_dice: 0.3814  decode.d0.loss_cls: 1.4945  decode.d0.loss_mask: 0.3062  decode.d0.loss_dice: 0.3718  decode.d1.loss_cls: 0.6801  decode.d1.loss_mask: 0.2913  decode.d1.loss_dice: 0.3090  decode.d2.loss_cls: 0.5271  decode.d2.loss_mask: 0.3145  decode.d2.loss_dice: 0.3136  decode.d3.loss_cls: 0.5759  decode.d3.loss_mask: 0.3187  decode.d3.loss_dice: 0.3246  decode.d4.loss_cls: 0.5364  decode.d4.loss_mask: 0.3297  decode.d4.loss_dice: 0.3397  decode.d5.loss_cls: 0.5568  decode.d5.loss_mask: 0.3162  decode.d5.loss_dice: 0.3328  decode.d6.loss_cls: 0.5398  decode.d6.loss_mask: 0.3273  decode.d6.loss_dice: 0.3488  decode.d7.loss_cls: 0.5644  decode.d7.loss_mask: 0.3190  decode.d7.loss_dice: 0.3373  decode.d8.loss_cls: 0.5072  decode.d8.loss_mask: 0.3306  decode.d8.loss_dice: 0.3824
07/30 17:32:52 - mmengine - INFO - Iter(train) [ 7250/80000]  base_lr: 9.1807e-05 lr: 9.1807e-06  eta: 8:47:49  time: 0.4353  data_time: 0.0088  memory: 5279  grad_norm: 109.8677  loss: 13.2945  decode.loss_cls: 0.4777  decode.loss_mask: 0.2963  decode.loss_dice: 0.3509  decode.d0.loss_cls: 1.3566  decode.d0.loss_mask: 0.2944  decode.d0.loss_dice: 0.3656  decode.d1.loss_cls: 0.8793  decode.d1.loss_mask: 0.3007  decode.d1.loss_dice: 0.3739  decode.d2.loss_cls: 0.5668  decode.d2.loss_mask: 0.2947  decode.d2.loss_dice: 0.3663  decode.d3.loss_cls: 0.5271  decode.d3.loss_mask: 0.3031  decode.d3.loss_dice: 0.3611  decode.d4.loss_cls: 0.5667  decode.d4.loss_mask: 0.3004  decode.d4.loss_dice: 0.3671  decode.d5.loss_cls: 0.6319  decode.d5.loss_mask: 0.2977  decode.d5.loss_dice: 0.3716  decode.d6.loss_cls: 0.5450  decode.d6.loss_mask: 0.2905  decode.d6.loss_dice: 0.3481  decode.d7.loss_cls: 0.5639  decode.d7.loss_mask: 0.2941  decode.d7.loss_dice: 0.3472  decode.d8.loss_cls: 0.5872  decode.d8.loss_mask: 0.2989  decode.d8.loss_dice: 0.3697
07/30 17:33:14 - mmengine - INFO - Iter(train) [ 7300/80000]  base_lr: 9.1750e-05 lr: 9.1750e-06  eta: 8:47:28  time: 0.4358  data_time: 0.0088  memory: 5279  grad_norm: 181.3004  loss: 12.3832  decode.loss_cls: 0.5248  decode.loss_mask: 0.2862  decode.loss_dice: 0.3527  decode.d0.loss_cls: 1.2157  decode.d0.loss_mask: 0.3546  decode.d0.loss_dice: 0.4286  decode.d1.loss_cls: 0.5160  decode.d1.loss_mask: 0.3127  decode.d1.loss_dice: 0.3754  decode.d2.loss_cls: 0.4766  decode.d2.loss_mask: 0.2963  decode.d2.loss_dice: 0.3891  decode.d3.loss_cls: 0.5050  decode.d3.loss_mask: 0.2885  decode.d3.loss_dice: 0.3594  decode.d4.loss_cls: 0.4551  decode.d4.loss_mask: 0.2922  decode.d4.loss_dice: 0.3799  decode.d5.loss_cls: 0.4776  decode.d5.loss_mask: 0.2855  decode.d5.loss_dice: 0.3733  decode.d6.loss_cls: 0.4657  decode.d6.loss_mask: 0.2939  decode.d6.loss_dice: 0.3516  decode.d7.loss_cls: 0.5005  decode.d7.loss_mask: 0.2869  decode.d7.loss_dice: 0.3655  decode.d8.loss_cls: 0.5338  decode.d8.loss_mask: 0.2898  decode.d8.loss_dice: 0.3503
07/30 17:33:36 - mmengine - INFO - Iter(train) [ 7350/80000]  base_lr: 9.1693e-05 lr: 9.1693e-06  eta: 8:47:08  time: 0.4517  data_time: 0.0090  memory: 5261  grad_norm: 77.9761  loss: 10.4032  decode.loss_cls: 0.3855  decode.loss_mask: 0.2687  decode.loss_dice: 0.2657  decode.d0.loss_cls: 1.1936  decode.d0.loss_mask: 0.2780  decode.d0.loss_dice: 0.3034  decode.d1.loss_cls: 0.4224  decode.d1.loss_mask: 0.2690  decode.d1.loss_dice: 0.2672  decode.d2.loss_cls: 0.4286  decode.d2.loss_mask: 0.2651  decode.d2.loss_dice: 0.2596  decode.d3.loss_cls: 0.4275  decode.d3.loss_mask: 0.2796  decode.d3.loss_dice: 0.2721  decode.d4.loss_cls: 0.4077  decode.d4.loss_mask: 0.2984  decode.d4.loss_dice: 0.2935  decode.d5.loss_cls: 0.3909  decode.d5.loss_mask: 0.2910  decode.d5.loss_dice: 0.2844  decode.d6.loss_cls: 0.3798  decode.d6.loss_mask: 0.2796  decode.d6.loss_dice: 0.2719  decode.d7.loss_cls: 0.4112  decode.d7.loss_mask: 0.2707  decode.d7.loss_dice: 0.2662  decode.d8.loss_cls: 0.4199  decode.d8.loss_mask: 0.2758  decode.d8.loss_dice: 0.2758
07/30 17:33:58 - mmengine - INFO - Iter(train) [ 7400/80000]  base_lr: 9.1636e-05 lr: 9.1636e-06  eta: 8:46:46  time: 0.4341  data_time: 0.0089  memory: 5265  grad_norm: 138.8588  loss: 10.5401  decode.loss_cls: 0.2808  decode.loss_mask: 0.3377  decode.loss_dice: 0.2646  decode.d0.loss_cls: 1.1509  decode.d0.loss_mask: 0.3939  decode.d0.loss_dice: 0.3648  decode.d1.loss_cls: 0.4235  decode.d1.loss_mask: 0.3516  decode.d1.loss_dice: 0.2973  decode.d2.loss_cls: 0.3526  decode.d2.loss_mask: 0.3488  decode.d2.loss_dice: 0.2899  decode.d3.loss_cls: 0.3899  decode.d3.loss_mask: 0.3414  decode.d3.loss_dice: 0.2772  decode.d4.loss_cls: 0.3901  decode.d4.loss_mask: 0.3532  decode.d4.loss_dice: 0.2663  decode.d5.loss_cls: 0.3015  decode.d5.loss_mask: 0.3495  decode.d5.loss_dice: 0.2709  decode.d6.loss_cls: 0.3143  decode.d6.loss_mask: 0.3441  decode.d6.loss_dice: 0.2798  decode.d7.loss_cls: 0.2714  decode.d7.loss_mask: 0.3448  decode.d7.loss_dice: 0.2715  decode.d8.loss_cls: 0.2895  decode.d8.loss_mask: 0.3487  decode.d8.loss_dice: 0.2795
07/30 17:34:20 - mmengine - INFO - Iter(train) [ 7450/80000]  base_lr: 9.1579e-05 lr: 9.1579e-06  eta: 8:46:24  time: 0.4353  data_time: 0.0089  memory: 5261  grad_norm: 206.5242  loss: 13.5294  decode.loss_cls: 0.4723  decode.loss_mask: 0.3493  decode.loss_dice: 0.3733  decode.d0.loss_cls: 1.3726  decode.d0.loss_mask: 0.3539  decode.d0.loss_dice: 0.3644  decode.d1.loss_cls: 0.6570  decode.d1.loss_mask: 0.3695  decode.d1.loss_dice: 0.3898  decode.d2.loss_cls: 0.6227  decode.d2.loss_mask: 0.3492  decode.d2.loss_dice: 0.3588  decode.d3.loss_cls: 0.6434  decode.d3.loss_mask: 0.3578  decode.d3.loss_dice: 0.3651  decode.d4.loss_cls: 0.5770  decode.d4.loss_mask: 0.3642  decode.d4.loss_dice: 0.3727  decode.d5.loss_cls: 0.5492  decode.d5.loss_mask: 0.3605  decode.d5.loss_dice: 0.3254  decode.d6.loss_cls: 0.4851  decode.d6.loss_mask: 0.3506  decode.d6.loss_dice: 0.3556  decode.d7.loss_cls: 0.4952  decode.d7.loss_mask: 0.3388  decode.d7.loss_dice: 0.3849  decode.d8.loss_cls: 0.4639  decode.d8.loss_mask: 0.3486  decode.d8.loss_dice: 0.3586
07/30 17:34:41 - mmengine - INFO - Iter(train) [ 7500/80000]  base_lr: 9.1523e-05 lr: 9.1523e-06  eta: 8:46:03  time: 0.4355  data_time: 0.0090  memory: 5261  grad_norm: 76.4683  loss: 10.9491  decode.loss_cls: 0.4534  decode.loss_mask: 0.2651  decode.loss_dice: 0.2731  decode.d0.loss_cls: 1.4418  decode.d0.loss_mask: 0.2871  decode.d0.loss_dice: 0.3285  decode.d1.loss_cls: 0.5237  decode.d1.loss_mask: 0.2815  decode.d1.loss_dice: 0.2935  decode.d2.loss_cls: 0.4287  decode.d2.loss_mask: 0.2779  decode.d2.loss_dice: 0.2931  decode.d3.loss_cls: 0.4563  decode.d3.loss_mask: 0.2694  decode.d3.loss_dice: 0.2745  decode.d4.loss_cls: 0.4474  decode.d4.loss_mask: 0.2638  decode.d4.loss_dice: 0.2641  decode.d5.loss_cls: 0.3897  decode.d5.loss_mask: 0.2680  decode.d5.loss_dice: 0.2817  decode.d6.loss_cls: 0.3902  decode.d6.loss_mask: 0.2695  decode.d6.loss_dice: 0.2604  decode.d7.loss_cls: 0.4211  decode.d7.loss_mask: 0.2710  decode.d7.loss_dice: 0.2624  decode.d8.loss_cls: 0.4597  decode.d8.loss_mask: 0.2735  decode.d8.loss_dice: 0.2789
07/30 17:35:03 - mmengine - INFO - Iter(train) [ 7550/80000]  base_lr: 9.1466e-05 lr: 9.1466e-06  eta: 8:45:42  time: 0.4357  data_time: 0.0089  memory: 5226  grad_norm: 86.2054  loss: 10.6854  decode.loss_cls: 0.4198  decode.loss_mask: 0.2356  decode.loss_dice: 0.2987  decode.d0.loss_cls: 1.2770  decode.d0.loss_mask: 0.2383  decode.d0.loss_dice: 0.3436  decode.d1.loss_cls: 0.4842  decode.d1.loss_mask: 0.2349  decode.d1.loss_dice: 0.3270  decode.d2.loss_cls: 0.4107  decode.d2.loss_mask: 0.2336  decode.d2.loss_dice: 0.3224  decode.d3.loss_cls: 0.4514  decode.d3.loss_mask: 0.2321  decode.d3.loss_dice: 0.2831  decode.d4.loss_cls: 0.4787  decode.d4.loss_mask: 0.2353  decode.d4.loss_dice: 0.2774  decode.d5.loss_cls: 0.4363  decode.d5.loss_mask: 0.2367  decode.d5.loss_dice: 0.3080  decode.d6.loss_cls: 0.4570  decode.d6.loss_mask: 0.2329  decode.d6.loss_dice: 0.2919  decode.d7.loss_cls: 0.4066  decode.d7.loss_mask: 0.2394  decode.d7.loss_dice: 0.2939  decode.d8.loss_cls: 0.4453  decode.d8.loss_mask: 0.2410  decode.d8.loss_dice: 0.3128
07/30 17:35:25 - mmengine - INFO - Iter(train) [ 7600/80000]  base_lr: 9.1409e-05 lr: 9.1409e-06  eta: 8:45:20  time: 0.4366  data_time: 0.0089  memory: 5265  grad_norm: 108.5316  loss: 11.8351  decode.loss_cls: 0.4191  decode.loss_mask: 0.2966  decode.loss_dice: 0.3619  decode.d0.loss_cls: 1.3220  decode.d0.loss_mask: 0.2945  decode.d0.loss_dice: 0.3879  decode.d1.loss_cls: 0.5630  decode.d1.loss_mask: 0.2769  decode.d1.loss_dice: 0.3913  decode.d2.loss_cls: 0.5255  decode.d2.loss_mask: 0.2917  decode.d2.loss_dice: 0.3428  decode.d3.loss_cls: 0.4448  decode.d3.loss_mask: 0.3018  decode.d3.loss_dice: 0.3420  decode.d4.loss_cls: 0.4651  decode.d4.loss_mask: 0.2823  decode.d4.loss_dice: 0.3425  decode.d5.loss_cls: 0.3643  decode.d5.loss_mask: 0.2863  decode.d5.loss_dice: 0.3351  decode.d6.loss_cls: 0.4525  decode.d6.loss_mask: 0.2880  decode.d6.loss_dice: 0.3243  decode.d7.loss_cls: 0.3915  decode.d7.loss_mask: 0.3004  decode.d7.loss_dice: 0.3647  decode.d8.loss_cls: 0.4126  decode.d8.loss_mask: 0.2979  decode.d8.loss_dice: 0.3659
07/30 17:35:47 - mmengine - INFO - Iter(train) [ 7650/80000]  base_lr: 9.1352e-05 lr: 9.1352e-06  eta: 8:44:58  time: 0.4346  data_time: 0.0088  memory: 5265  grad_norm: 85.8429  loss: 11.5125  decode.loss_cls: 0.4434  decode.loss_mask: 0.3035  decode.loss_dice: 0.3158  decode.d0.loss_cls: 1.2529  decode.d0.loss_mask: 0.3199  decode.d0.loss_dice: 0.3506  decode.d1.loss_cls: 0.4734  decode.d1.loss_mask: 0.3116  decode.d1.loss_dice: 0.3361  decode.d2.loss_cls: 0.3502  decode.d2.loss_mask: 0.3057  decode.d2.loss_dice: 0.3426  decode.d3.loss_cls: 0.3888  decode.d3.loss_mask: 0.3056  decode.d3.loss_dice: 0.3051  decode.d4.loss_cls: 0.4305  decode.d4.loss_mask: 0.3147  decode.d4.loss_dice: 0.3178  decode.d5.loss_cls: 0.4046  decode.d5.loss_mask: 0.3100  decode.d5.loss_dice: 0.3253  decode.d6.loss_cls: 0.4558  decode.d6.loss_mask: 0.3100  decode.d6.loss_dice: 0.3220  decode.d7.loss_cls: 0.4831  decode.d7.loss_mask: 0.3094  decode.d7.loss_dice: 0.3231  decode.d8.loss_cls: 0.4851  decode.d8.loss_mask: 0.3102  decode.d8.loss_dice: 0.3056
07/30 17:36:09 - mmengine - INFO - Iter(train) [ 7700/80000]  base_lr: 9.1295e-05 lr: 9.1295e-06  eta: 8:44:37  time: 0.4367  data_time: 0.0089  memory: 5265  grad_norm: 135.4355  loss: 10.9951  decode.loss_cls: 0.4157  decode.loss_mask: 0.2171  decode.loss_dice: 0.3246  decode.d0.loss_cls: 1.3642  decode.d0.loss_mask: 0.2216  decode.d0.loss_dice: 0.3680  decode.d1.loss_cls: 0.5259  decode.d1.loss_mask: 0.2222  decode.d1.loss_dice: 0.3263  decode.d2.loss_cls: 0.4705  decode.d2.loss_mask: 0.2202  decode.d2.loss_dice: 0.3323  decode.d3.loss_cls: 0.4129  decode.d3.loss_mask: 0.2225  decode.d3.loss_dice: 0.3420  decode.d4.loss_cls: 0.4257  decode.d4.loss_mask: 0.2211  decode.d4.loss_dice: 0.3527  decode.d5.loss_cls: 0.4279  decode.d5.loss_mask: 0.2249  decode.d5.loss_dice: 0.3726  decode.d6.loss_cls: 0.4617  decode.d6.loss_mask: 0.2214  decode.d6.loss_dice: 0.3408  decode.d7.loss_cls: 0.3957  decode.d7.loss_mask: 0.2337  decode.d7.loss_dice: 0.3540  decode.d8.loss_cls: 0.4072  decode.d8.loss_mask: 0.2296  decode.d8.loss_dice: 0.3401
07/30 17:36:30 - mmengine - INFO - Iter(train) [ 7750/80000]  base_lr: 9.1238e-05 lr: 9.1238e-06  eta: 8:44:15  time: 0.4358  data_time: 0.0091  memory: 5278  grad_norm: 124.3881  loss: 13.8135  decode.loss_cls: 0.5397  decode.loss_mask: 0.3560  decode.loss_dice: 0.3985  decode.d0.loss_cls: 1.2086  decode.d0.loss_mask: 0.4483  decode.d0.loss_dice: 0.4443  decode.d1.loss_cls: 0.6603  decode.d1.loss_mask: 0.3483  decode.d1.loss_dice: 0.4161  decode.d2.loss_cls: 0.4935  decode.d2.loss_mask: 0.3780  decode.d2.loss_dice: 0.3959  decode.d3.loss_cls: 0.5354  decode.d3.loss_mask: 0.3668  decode.d3.loss_dice: 0.3777  decode.d4.loss_cls: 0.5245  decode.d4.loss_mask: 0.3774  decode.d4.loss_dice: 0.3767  decode.d5.loss_cls: 0.5117  decode.d5.loss_mask: 0.4084  decode.d5.loss_dice: 0.3755  decode.d6.loss_cls: 0.5675  decode.d6.loss_mask: 0.3208  decode.d6.loss_dice: 0.3671  decode.d7.loss_cls: 0.5637  decode.d7.loss_mask: 0.3810  decode.d7.loss_dice: 0.3872  decode.d8.loss_cls: 0.5237  decode.d8.loss_mask: 0.3780  decode.d8.loss_dice: 0.3830
07/30 17:36:52 - mmengine - INFO - Iter(train) [ 7800/80000]  base_lr: 9.1182e-05 lr: 9.1182e-06  eta: 8:43:53  time: 0.4353  data_time: 0.0089  memory: 5323  grad_norm: 118.2589  loss: 15.7418  decode.loss_cls: 0.6768  decode.loss_mask: 0.3619  decode.loss_dice: 0.4388  decode.d0.loss_cls: 1.4177  decode.d0.loss_mask: 0.3702  decode.d0.loss_dice: 0.5664  decode.d1.loss_cls: 0.7944  decode.d1.loss_mask: 0.3476  decode.d1.loss_dice: 0.4961  decode.d2.loss_cls: 0.6815  decode.d2.loss_mask: 0.3504  decode.d2.loss_dice: 0.4487  decode.d3.loss_cls: 0.6647  decode.d3.loss_mask: 0.3258  decode.d3.loss_dice: 0.4626  decode.d4.loss_cls: 0.6517  decode.d4.loss_mask: 0.3754  decode.d4.loss_dice: 0.4617  decode.d5.loss_cls: 0.6583  decode.d5.loss_mask: 0.3544  decode.d5.loss_dice: 0.4222  decode.d6.loss_cls: 0.6460  decode.d6.loss_mask: 0.3860  decode.d6.loss_dice: 0.4276  decode.d7.loss_cls: 0.6832  decode.d7.loss_mask: 0.3624  decode.d7.loss_dice: 0.4259  decode.d8.loss_cls: 0.6883  decode.d8.loss_mask: 0.3378  decode.d8.loss_dice: 0.4573
07/30 17:37:14 - mmengine - INFO - Iter(train) [ 7850/80000]  base_lr: 9.1125e-05 lr: 9.1125e-06  eta: 8:43:32  time: 0.4358  data_time: 0.0087  memory: 5246  grad_norm: 104.9583  loss: 11.1537  decode.loss_cls: 0.3934  decode.loss_mask: 0.2398  decode.loss_dice: 0.3400  decode.d0.loss_cls: 1.3363  decode.d0.loss_mask: 0.2426  decode.d0.loss_dice: 0.4009  decode.d1.loss_cls: 0.5257  decode.d1.loss_mask: 0.2524  decode.d1.loss_dice: 0.3704  decode.d2.loss_cls: 0.5613  decode.d2.loss_mask: 0.2459  decode.d2.loss_dice: 0.3547  decode.d3.loss_cls: 0.4850  decode.d3.loss_mask: 0.2399  decode.d3.loss_dice: 0.3508  decode.d4.loss_cls: 0.4116  decode.d4.loss_mask: 0.2479  decode.d4.loss_dice: 0.3638  decode.d5.loss_cls: 0.3520  decode.d5.loss_mask: 0.2431  decode.d5.loss_dice: 0.3826  decode.d6.loss_cls: 0.3462  decode.d6.loss_mask: 0.2405  decode.d6.loss_dice: 0.3387  decode.d7.loss_cls: 0.3190  decode.d7.loss_mask: 0.2425  decode.d7.loss_dice: 0.3506  decode.d8.loss_cls: 0.3425  decode.d8.loss_mask: 0.2512  decode.d8.loss_dice: 0.3825
07/30 17:37:36 - mmengine - INFO - Iter(train) [ 7900/80000]  base_lr: 9.1068e-05 lr: 9.1068e-06  eta: 8:43:11  time: 0.4355  data_time: 0.0088  memory: 5245  grad_norm: 120.8481  loss: 10.5266  decode.loss_cls: 0.5069  decode.loss_mask: 0.2523  decode.loss_dice: 0.2797  decode.d0.loss_cls: 1.4473  decode.d0.loss_mask: 0.2486  decode.d0.loss_dice: 0.3037  decode.d1.loss_cls: 0.3260  decode.d1.loss_mask: 0.2638  decode.d1.loss_dice: 0.2905  decode.d2.loss_cls: 0.3065  decode.d2.loss_mask: 0.2508  decode.d2.loss_dice: 0.2820  decode.d3.loss_cls: 0.4167  decode.d3.loss_mask: 0.2446  decode.d3.loss_dice: 0.2822  decode.d4.loss_cls: 0.3254  decode.d4.loss_mask: 0.2668  decode.d4.loss_dice: 0.3046  decode.d5.loss_cls: 0.3733  decode.d5.loss_mask: 0.2569  decode.d5.loss_dice: 0.2963  decode.d6.loss_cls: 0.4838  decode.d6.loss_mask: 0.2375  decode.d6.loss_dice: 0.2767  decode.d7.loss_cls: 0.4843  decode.d7.loss_mask: 0.2411  decode.d7.loss_dice: 0.2799  decode.d8.loss_cls: 0.4635  decode.d8.loss_mask: 0.2548  decode.d8.loss_dice: 0.2802
07/30 17:37:58 - mmengine - INFO - Iter(train) [ 7950/80000]  base_lr: 9.1011e-05 lr: 9.1011e-06  eta: 8:42:49  time: 0.4355  data_time: 0.0089  memory: 5304  grad_norm: 184.3946  loss: 12.6256  decode.loss_cls: 0.5406  decode.loss_mask: 0.3014  decode.loss_dice: 0.3865  decode.d0.loss_cls: 1.2443  decode.d0.loss_mask: 0.2779  decode.d0.loss_dice: 0.4149  decode.d1.loss_cls: 0.5344  decode.d1.loss_mask: 0.2903  decode.d1.loss_dice: 0.3982  decode.d2.loss_cls: 0.4462  decode.d2.loss_mask: 0.2927  decode.d2.loss_dice: 0.4204  decode.d3.loss_cls: 0.4727  decode.d3.loss_mask: 0.2872  decode.d3.loss_dice: 0.3990  decode.d4.loss_cls: 0.4341  decode.d4.loss_mask: 0.3005  decode.d4.loss_dice: 0.3946  decode.d5.loss_cls: 0.4619  decode.d5.loss_mask: 0.3013  decode.d5.loss_dice: 0.3931  decode.d6.loss_cls: 0.5038  decode.d6.loss_mask: 0.2972  decode.d6.loss_dice: 0.3817  decode.d7.loss_cls: 0.5199  decode.d7.loss_mask: 0.2816  decode.d7.loss_dice: 0.3920  decode.d8.loss_cls: 0.5709  decode.d8.loss_mask: 0.3017  decode.d8.loss_dice: 0.3844
07/30 17:38:19 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 17:38:19 - mmengine - INFO - Iter(train) [ 8000/80000]  base_lr: 9.0954e-05 lr: 9.0954e-06  eta: 8:42:28  time: 0.4358  data_time: 0.0087  memory: 5246  grad_norm: 90.1745  loss: 10.2847  decode.loss_cls: 0.3624  decode.loss_mask: 0.2815  decode.loss_dice: 0.3051  decode.d0.loss_cls: 1.2921  decode.d0.loss_mask: 0.2997  decode.d0.loss_dice: 0.3663  decode.d1.loss_cls: 0.3811  decode.d1.loss_mask: 0.2762  decode.d1.loss_dice: 0.2930  decode.d2.loss_cls: 0.3342  decode.d2.loss_mask: 0.2841  decode.d2.loss_dice: 0.3029  decode.d3.loss_cls: 0.3813  decode.d3.loss_mask: 0.2812  decode.d3.loss_dice: 0.2636  decode.d4.loss_cls: 0.3530  decode.d4.loss_mask: 0.2827  decode.d4.loss_dice: 0.2795  decode.d5.loss_cls: 0.3517  decode.d5.loss_mask: 0.2798  decode.d5.loss_dice: 0.2926  decode.d6.loss_cls: 0.3527  decode.d6.loss_mask: 0.2794  decode.d6.loss_dice: 0.2749  decode.d7.loss_cls: 0.3600  decode.d7.loss_mask: 0.2811  decode.d7.loss_dice: 0.2988  decode.d8.loss_cls: 0.3160  decode.d8.loss_mask: 0.2785  decode.d8.loss_dice: 0.2994
07/30 17:38:41 - mmengine - INFO - Iter(train) [ 8050/80000]  base_lr: 9.0897e-05 lr: 9.0897e-06  eta: 8:42:06  time: 0.4367  data_time: 0.0088  memory: 5265  grad_norm: 69.4758  loss: 10.5229  decode.loss_cls: 0.3953  decode.loss_mask: 0.2412  decode.loss_dice: 0.2991  decode.d0.loss_cls: 1.3143  decode.d0.loss_mask: 0.2653  decode.d0.loss_dice: 0.3313  decode.d1.loss_cls: 0.5053  decode.d1.loss_mask: 0.2500  decode.d1.loss_dice: 0.3208  decode.d2.loss_cls: 0.4351  decode.d2.loss_mask: 0.2482  decode.d2.loss_dice: 0.3033  decode.d3.loss_cls: 0.4557  decode.d3.loss_mask: 0.2423  decode.d3.loss_dice: 0.3182  decode.d4.loss_cls: 0.3790  decode.d4.loss_mask: 0.2458  decode.d4.loss_dice: 0.2879  decode.d5.loss_cls: 0.3639  decode.d5.loss_mask: 0.2438  decode.d5.loss_dice: 0.2869  decode.d6.loss_cls: 0.3988  decode.d6.loss_mask: 0.2437  decode.d6.loss_dice: 0.3069  decode.d7.loss_cls: 0.3748  decode.d7.loss_mask: 0.2409  decode.d7.loss_dice: 0.2849  decode.d8.loss_cls: 0.3944  decode.d8.loss_mask: 0.2435  decode.d8.loss_dice: 0.3023
07/30 17:39:03 - mmengine - INFO - Iter(train) [ 8100/80000]  base_lr: 9.0841e-05 lr: 9.0841e-06  eta: 8:41:45  time: 0.4360  data_time: 0.0089  memory: 5244  grad_norm: 84.3373  loss: 9.3719  decode.loss_cls: 0.2906  decode.loss_mask: 0.2531  decode.loss_dice: 0.2951  decode.d0.loss_cls: 1.1080  decode.d0.loss_mask: 0.2527  decode.d0.loss_dice: 0.3423  decode.d1.loss_cls: 0.3816  decode.d1.loss_mask: 0.2599  decode.d1.loss_dice: 0.3094  decode.d2.loss_cls: 0.3115  decode.d2.loss_mask: 0.2563  decode.d2.loss_dice: 0.2946  decode.d3.loss_cls: 0.2758  decode.d3.loss_mask: 0.2495  decode.d3.loss_dice: 0.2892  decode.d4.loss_cls: 0.2590  decode.d4.loss_mask: 0.2495  decode.d4.loss_dice: 0.2917  decode.d5.loss_cls: 0.2792  decode.d5.loss_mask: 0.2544  decode.d5.loss_dice: 0.3031  decode.d6.loss_cls: 0.2775  decode.d6.loss_mask: 0.2540  decode.d6.loss_dice: 0.3380  decode.d7.loss_cls: 0.2883  decode.d7.loss_mask: 0.2544  decode.d7.loss_dice: 0.3051  decode.d8.loss_cls: 0.2956  decode.d8.loss_mask: 0.2539  decode.d8.loss_dice: 0.2984
07/30 17:39:25 - mmengine - INFO - Iter(train) [ 8150/80000]  base_lr: 9.0784e-05 lr: 9.0784e-06  eta: 8:41:23  time: 0.4357  data_time: 0.0090  memory: 5227  grad_norm: 112.0850  loss: 13.9633  decode.loss_cls: 0.4949  decode.loss_mask: 0.3518  decode.loss_dice: 0.4043  decode.d0.loss_cls: 1.4703  decode.d0.loss_mask: 0.3855  decode.d0.loss_dice: 0.5186  decode.d1.loss_cls: 0.6874  decode.d1.loss_mask: 0.3533  decode.d1.loss_dice: 0.4569  decode.d2.loss_cls: 0.5006  decode.d2.loss_mask: 0.3451  decode.d2.loss_dice: 0.4188  decode.d3.loss_cls: 0.5438  decode.d3.loss_mask: 0.3325  decode.d3.loss_dice: 0.4054  decode.d4.loss_cls: 0.5489  decode.d4.loss_mask: 0.3495  decode.d4.loss_dice: 0.4002  decode.d5.loss_cls: 0.5575  decode.d5.loss_mask: 0.3391  decode.d5.loss_dice: 0.4039  decode.d6.loss_cls: 0.4711  decode.d6.loss_mask: 0.3464  decode.d6.loss_dice: 0.3853  decode.d7.loss_cls: 0.4971  decode.d7.loss_mask: 0.3488  decode.d7.loss_dice: 0.4163  decode.d8.loss_cls: 0.5030  decode.d8.loss_mask: 0.3296  decode.d8.loss_dice: 0.3974
07/30 17:39:47 - mmengine - INFO - Iter(train) [ 8200/80000]  base_lr: 9.0727e-05 lr: 9.0727e-06  eta: 8:41:02  time: 0.4365  data_time: 0.0088  memory: 5246  grad_norm: 186.0349  loss: 10.9528  decode.loss_cls: 0.3110  decode.loss_mask: 0.3066  decode.loss_dice: 0.3179  decode.d0.loss_cls: 1.3648  decode.d0.loss_mask: 0.3568  decode.d0.loss_dice: 0.3341  decode.d1.loss_cls: 0.4526  decode.d1.loss_mask: 0.2939  decode.d1.loss_dice: 0.3190  decode.d2.loss_cls: 0.4611  decode.d2.loss_mask: 0.2742  decode.d2.loss_dice: 0.3035  decode.d3.loss_cls: 0.3585  decode.d3.loss_mask: 0.2594  decode.d3.loss_dice: 0.2843  decode.d4.loss_cls: 0.3502  decode.d4.loss_mask: 0.3468  decode.d4.loss_dice: 0.3106  decode.d5.loss_cls: 0.3247  decode.d5.loss_mask: 0.3526  decode.d5.loss_dice: 0.3150  decode.d6.loss_cls: 0.3649  decode.d6.loss_mask: 0.3478  decode.d6.loss_dice: 0.3125  decode.d7.loss_cls: 0.2950  decode.d7.loss_mask: 0.3152  decode.d7.loss_dice: 0.3368  decode.d8.loss_cls: 0.2996  decode.d8.loss_mask: 0.3297  decode.d8.loss_dice: 0.3535
07/30 17:40:08 - mmengine - INFO - Iter(train) [ 8250/80000]  base_lr: 9.0670e-05 lr: 9.0670e-06  eta: 8:40:40  time: 0.4357  data_time: 0.0090  memory: 5265  grad_norm: 94.6823  loss: 10.4656  decode.loss_cls: 0.2962  decode.loss_mask: 0.2782  decode.loss_dice: 0.3287  decode.d0.loss_cls: 1.1399  decode.d0.loss_mask: 0.2925  decode.d0.loss_dice: 0.3591  decode.d1.loss_cls: 0.5639  decode.d1.loss_mask: 0.2779  decode.d1.loss_dice: 0.3611  decode.d2.loss_cls: 0.4301  decode.d2.loss_mask: 0.2841  decode.d2.loss_dice: 0.3549  decode.d3.loss_cls: 0.3139  decode.d3.loss_mask: 0.2803  decode.d3.loss_dice: 0.3306  decode.d4.loss_cls: 0.2601  decode.d4.loss_mask: 0.2832  decode.d4.loss_dice: 0.3356  decode.d5.loss_cls: 0.3393  decode.d5.loss_mask: 0.2811  decode.d5.loss_dice: 0.3271  decode.d6.loss_cls: 0.2949  decode.d6.loss_mask: 0.2730  decode.d6.loss_dice: 0.3279  decode.d7.loss_cls: 0.3148  decode.d7.loss_mask: 0.2750  decode.d7.loss_dice: 0.3194  decode.d8.loss_cls: 0.3414  decode.d8.loss_mask: 0.2794  decode.d8.loss_dice: 0.3219
07/30 17:40:30 - mmengine - INFO - Iter(train) [ 8300/80000]  base_lr: 9.0613e-05 lr: 9.0613e-06  eta: 8:40:19  time: 0.4361  data_time: 0.0090  memory: 5246  grad_norm: 173.2866  loss: 10.9455  decode.loss_cls: 0.2692  decode.loss_mask: 0.3690  decode.loss_dice: 0.2866  decode.d0.loss_cls: 1.1459  decode.d0.loss_mask: 0.3631  decode.d0.loss_dice: 0.3258  decode.d1.loss_cls: 0.4454  decode.d1.loss_mask: 0.3408  decode.d1.loss_dice: 0.3055  decode.d2.loss_cls: 0.4133  decode.d2.loss_mask: 0.3488  decode.d2.loss_dice: 0.2947  decode.d3.loss_cls: 0.3747  decode.d3.loss_mask: 0.3653  decode.d3.loss_dice: 0.2921  decode.d4.loss_cls: 0.3256  decode.d4.loss_mask: 0.3783  decode.d4.loss_dice: 0.3214  decode.d5.loss_cls: 0.2948  decode.d5.loss_mask: 0.3856  decode.d5.loss_dice: 0.3192  decode.d6.loss_cls: 0.3050  decode.d6.loss_mask: 0.3677  decode.d6.loss_dice: 0.3064  decode.d7.loss_cls: 0.3029  decode.d7.loss_mask: 0.3801  decode.d7.loss_dice: 0.3052  decode.d8.loss_cls: 0.3529  decode.d8.loss_mask: 0.3656  decode.d8.loss_dice: 0.2944
07/30 17:40:52 - mmengine - INFO - Iter(train) [ 8350/80000]  base_lr: 9.0556e-05 lr: 9.0556e-06  eta: 8:39:57  time: 0.4347  data_time: 0.0089  memory: 5261  grad_norm: 143.0330  loss: 13.3011  decode.loss_cls: 0.6205  decode.loss_mask: 0.3741  decode.loss_dice: 0.2954  decode.d0.loss_cls: 1.1991  decode.d0.loss_mask: 0.4013  decode.d0.loss_dice: 0.3683  decode.d1.loss_cls: 0.7035  decode.d1.loss_mask: 0.3458  decode.d1.loss_dice: 0.3149  decode.d2.loss_cls: 0.5594  decode.d2.loss_mask: 0.3600  decode.d2.loss_dice: 0.2929  decode.d3.loss_cls: 0.5905  decode.d3.loss_mask: 0.3581  decode.d3.loss_dice: 0.2785  decode.d4.loss_cls: 0.5177  decode.d4.loss_mask: 0.3594  decode.d4.loss_dice: 0.2817  decode.d5.loss_cls: 0.5881  decode.d5.loss_mask: 0.3572  decode.d5.loss_dice: 0.2934  decode.d6.loss_cls: 0.5887  decode.d6.loss_mask: 0.3598  decode.d6.loss_dice: 0.3006  decode.d7.loss_cls: 0.6015  decode.d7.loss_mask: 0.3526  decode.d7.loss_dice: 0.3071  decode.d8.loss_cls: 0.6614  decode.d8.loss_mask: 0.3527  decode.d8.loss_dice: 0.3168
07/30 17:41:14 - mmengine - INFO - Iter(train) [ 8400/80000]  base_lr: 9.0499e-05 lr: 9.0499e-06  eta: 8:39:35  time: 0.4342  data_time: 0.0088  memory: 5265  grad_norm: 160.3482  loss: 13.4960  decode.loss_cls: 0.4661  decode.loss_mask: 0.3943  decode.loss_dice: 0.3699  decode.d0.loss_cls: 1.3222  decode.d0.loss_mask: 0.3539  decode.d0.loss_dice: 0.3861  decode.d1.loss_cls: 0.5956  decode.d1.loss_mask: 0.3553  decode.d1.loss_dice: 0.3463  decode.d2.loss_cls: 0.6568  decode.d2.loss_mask: 0.3662  decode.d2.loss_dice: 0.3438  decode.d3.loss_cls: 0.5227  decode.d3.loss_mask: 0.3494  decode.d3.loss_dice: 0.3499  decode.d4.loss_cls: 0.5898  decode.d4.loss_mask: 0.3444  decode.d4.loss_dice: 0.3684  decode.d5.loss_cls: 0.4979  decode.d5.loss_mask: 0.4081  decode.d5.loss_dice: 0.3821  decode.d6.loss_cls: 0.5202  decode.d6.loss_mask: 0.4060  decode.d6.loss_dice: 0.3945  decode.d7.loss_cls: 0.4496  decode.d7.loss_mask: 0.3773  decode.d7.loss_dice: 0.3813  decode.d8.loss_cls: 0.4264  decode.d8.loss_mask: 0.3854  decode.d8.loss_dice: 0.3861
07/30 17:41:35 - mmengine - INFO - Iter(train) [ 8450/80000]  base_lr: 9.0443e-05 lr: 9.0443e-06  eta: 8:39:13  time: 0.4356  data_time: 0.0088  memory: 5244  grad_norm: 117.8385  loss: 12.6669  decode.loss_cls: 0.5451  decode.loss_mask: 0.2864  decode.loss_dice: 0.3859  decode.d0.loss_cls: 1.3594  decode.d0.loss_mask: 0.2939  decode.d0.loss_dice: 0.4528  decode.d1.loss_cls: 0.5590  decode.d1.loss_mask: 0.2963  decode.d1.loss_dice: 0.3708  decode.d2.loss_cls: 0.5709  decode.d2.loss_mask: 0.2966  decode.d2.loss_dice: 0.3801  decode.d3.loss_cls: 0.4605  decode.d3.loss_mask: 0.2809  decode.d3.loss_dice: 0.3958  decode.d4.loss_cls: 0.4621  decode.d4.loss_mask: 0.2830  decode.d4.loss_dice: 0.4140  decode.d5.loss_cls: 0.5259  decode.d5.loss_mask: 0.2911  decode.d5.loss_dice: 0.3800  decode.d6.loss_cls: 0.4366  decode.d6.loss_mask: 0.2909  decode.d6.loss_dice: 0.3861  decode.d7.loss_cls: 0.4591  decode.d7.loss_mask: 0.2885  decode.d7.loss_dice: 0.4001  decode.d8.loss_cls: 0.4414  decode.d8.loss_mask: 0.2867  decode.d8.loss_dice: 0.3868
07/30 17:41:57 - mmengine - INFO - Iter(train) [ 8500/80000]  base_lr: 9.0386e-05 lr: 9.0386e-06  eta: 8:38:52  time: 0.4351  data_time: 0.0089  memory: 5245  grad_norm: 102.7445  loss: 10.8805  decode.loss_cls: 0.4324  decode.loss_mask: 0.2588  decode.loss_dice: 0.3106  decode.d0.loss_cls: 1.2474  decode.d0.loss_mask: 0.2965  decode.d0.loss_dice: 0.3332  decode.d1.loss_cls: 0.4682  decode.d1.loss_mask: 0.2878  decode.d1.loss_dice: 0.3097  decode.d2.loss_cls: 0.4020  decode.d2.loss_mask: 0.2628  decode.d2.loss_dice: 0.2891  decode.d3.loss_cls: 0.4472  decode.d3.loss_mask: 0.2551  decode.d3.loss_dice: 0.3006  decode.d4.loss_cls: 0.4315  decode.d4.loss_mask: 0.2509  decode.d4.loss_dice: 0.2935  decode.d5.loss_cls: 0.4255  decode.d5.loss_mask: 0.2548  decode.d5.loss_dice: 0.3133  decode.d6.loss_cls: 0.3975  decode.d6.loss_mask: 0.2587  decode.d6.loss_dice: 0.3013  decode.d7.loss_cls: 0.4411  decode.d7.loss_mask: 0.2562  decode.d7.loss_dice: 0.3189  decode.d8.loss_cls: 0.4897  decode.d8.loss_mask: 0.2593  decode.d8.loss_dice: 0.2869
07/30 17:42:19 - mmengine - INFO - Iter(train) [ 8550/80000]  base_lr: 9.0329e-05 lr: 9.0329e-06  eta: 8:38:30  time: 0.4344  data_time: 0.0090  memory: 5246  grad_norm: 94.2431  loss: 8.9888  decode.loss_cls: 0.1674  decode.loss_mask: 0.3619  decode.loss_dice: 0.2495  decode.d0.loss_cls: 0.9651  decode.d0.loss_mask: 0.4146  decode.d0.loss_dice: 0.2729  decode.d1.loss_cls: 0.2275  decode.d1.loss_mask: 0.4081  decode.d1.loss_dice: 0.2676  decode.d2.loss_cls: 0.1975  decode.d2.loss_mask: 0.3649  decode.d2.loss_dice: 0.2561  decode.d3.loss_cls: 0.2130  decode.d3.loss_mask: 0.3578  decode.d3.loss_dice: 0.2518  decode.d4.loss_cls: 0.1988  decode.d4.loss_mask: 0.3651  decode.d4.loss_dice: 0.2590  decode.d5.loss_cls: 0.1831  decode.d5.loss_mask: 0.3661  decode.d5.loss_dice: 0.2535  decode.d6.loss_cls: 0.1800  decode.d6.loss_mask: 0.3582  decode.d6.loss_dice: 0.2528  decode.d7.loss_cls: 0.1835  decode.d7.loss_mask: 0.3611  decode.d7.loss_dice: 0.2533  decode.d8.loss_cls: 0.1700  decode.d8.loss_mask: 0.3734  decode.d8.loss_dice: 0.2551
07/30 17:42:41 - mmengine - INFO - Iter(train) [ 8600/80000]  base_lr: 9.0272e-05 lr: 9.0272e-06  eta: 8:38:08  time: 0.4373  data_time: 0.0089  memory: 5279  grad_norm: 125.3608  loss: 11.5284  decode.loss_cls: 0.5253  decode.loss_mask: 0.2817  decode.loss_dice: 0.3266  decode.d0.loss_cls: 1.3142  decode.d0.loss_mask: 0.2874  decode.d0.loss_dice: 0.3731  decode.d1.loss_cls: 0.5295  decode.d1.loss_mask: 0.2963  decode.d1.loss_dice: 0.3620  decode.d2.loss_cls: 0.4722  decode.d2.loss_mask: 0.2772  decode.d2.loss_dice: 0.3296  decode.d3.loss_cls: 0.4459  decode.d3.loss_mask: 0.2718  decode.d3.loss_dice: 0.3244  decode.d4.loss_cls: 0.3914  decode.d4.loss_mask: 0.2728  decode.d4.loss_dice: 0.3183  decode.d5.loss_cls: 0.3931  decode.d5.loss_mask: 0.2733  decode.d5.loss_dice: 0.3274  decode.d6.loss_cls: 0.3872  decode.d6.loss_mask: 0.2712  decode.d6.loss_dice: 0.3306  decode.d7.loss_cls: 0.4151  decode.d7.loss_mask: 0.2715  decode.d7.loss_dice: 0.3354  decode.d8.loss_cls: 0.5205  decode.d8.loss_mask: 0.2747  decode.d8.loss_dice: 0.3284
07/30 17:43:03 - mmengine - INFO - Iter(train) [ 8650/80000]  base_lr: 9.0215e-05 lr: 9.0215e-06  eta: 8:37:46  time: 0.4356  data_time: 0.0088  memory: 5265  grad_norm: 112.6002  loss: 10.0797  decode.loss_cls: 0.3899  decode.loss_mask: 0.2322  decode.loss_dice: 0.2806  decode.d0.loss_cls: 1.3135  decode.d0.loss_mask: 0.2504  decode.d0.loss_dice: 0.3293  decode.d1.loss_cls: 0.4637  decode.d1.loss_mask: 0.2338  decode.d1.loss_dice: 0.2916  decode.d2.loss_cls: 0.3972  decode.d2.loss_mask: 0.2289  decode.d2.loss_dice: 0.2875  decode.d3.loss_cls: 0.4160  decode.d3.loss_mask: 0.2315  decode.d3.loss_dice: 0.2682  decode.d4.loss_cls: 0.4327  decode.d4.loss_mask: 0.2284  decode.d4.loss_dice: 0.2729  decode.d5.loss_cls: 0.3844  decode.d5.loss_mask: 0.2314  decode.d5.loss_dice: 0.2772  decode.d6.loss_cls: 0.3550  decode.d6.loss_mask: 0.2297  decode.d6.loss_dice: 0.2689  decode.d7.loss_cls: 0.3470  decode.d7.loss_mask: 0.2343  decode.d7.loss_dice: 0.2818  decode.d8.loss_cls: 0.4116  decode.d8.loss_mask: 0.2326  decode.d8.loss_dice: 0.2776
07/30 17:43:24 - mmengine - INFO - Iter(train) [ 8700/80000]  base_lr: 9.0158e-05 lr: 9.0158e-06  eta: 8:37:25  time: 0.4359  data_time: 0.0088  memory: 5261  grad_norm: 66.0270  loss: 9.3025  decode.loss_cls: 0.3298  decode.loss_mask: 0.2259  decode.loss_dice: 0.2588  decode.d0.loss_cls: 1.3263  decode.d0.loss_mask: 0.2443  decode.d0.loss_dice: 0.3170  decode.d1.loss_cls: 0.3630  decode.d1.loss_mask: 0.2372  decode.d1.loss_dice: 0.2724  decode.d2.loss_cls: 0.2897  decode.d2.loss_mask: 0.2317  decode.d2.loss_dice: 0.2600  decode.d3.loss_cls: 0.3039  decode.d3.loss_mask: 0.2268  decode.d3.loss_dice: 0.2535  decode.d4.loss_cls: 0.3292  decode.d4.loss_mask: 0.2308  decode.d4.loss_dice: 0.2522  decode.d5.loss_cls: 0.3675  decode.d5.loss_mask: 0.2247  decode.d5.loss_dice: 0.2529  decode.d6.loss_cls: 0.3281  decode.d6.loss_mask: 0.2270  decode.d6.loss_dice: 0.2534  decode.d7.loss_cls: 0.3547  decode.d7.loss_mask: 0.2294  decode.d7.loss_dice: 0.2614  decode.d8.loss_cls: 0.3606  decode.d8.loss_mask: 0.2269  decode.d8.loss_dice: 0.2632
07/30 17:43:46 - mmengine - INFO - Iter(train) [ 8750/80000]  base_lr: 9.0101e-05 lr: 9.0101e-06  eta: 8:37:04  time: 0.4350  data_time: 0.0088  memory: 5279  grad_norm: 122.4473  loss: 10.1729  decode.loss_cls: 0.2526  decode.loss_mask: 0.2846  decode.loss_dice: 0.3409  decode.d0.loss_cls: 1.2884  decode.d0.loss_mask: 0.2929  decode.d0.loss_dice: 0.3534  decode.d1.loss_cls: 0.4206  decode.d1.loss_mask: 0.2916  decode.d1.loss_dice: 0.3449  decode.d2.loss_cls: 0.3358  decode.d2.loss_mask: 0.2936  decode.d2.loss_dice: 0.3459  decode.d3.loss_cls: 0.2172  decode.d3.loss_mask: 0.2961  decode.d3.loss_dice: 0.3532  decode.d4.loss_cls: 0.2576  decode.d4.loss_mask: 0.2960  decode.d4.loss_dice: 0.3711  decode.d5.loss_cls: 0.2896  decode.d5.loss_mask: 0.2832  decode.d5.loss_dice: 0.3349  decode.d6.loss_cls: 0.2473  decode.d6.loss_mask: 0.2844  decode.d6.loss_dice: 0.3296  decode.d7.loss_cls: 0.2748  decode.d7.loss_mask: 0.2902  decode.d7.loss_dice: 0.3410  decode.d8.loss_cls: 0.2038  decode.d8.loss_mask: 0.2996  decode.d8.loss_dice: 0.3582
07/30 17:44:08 - mmengine - INFO - Iter(train) [ 8800/80000]  base_lr: 9.0044e-05 lr: 9.0044e-06  eta: 8:36:42  time: 0.4356  data_time: 0.0089  memory: 5261  grad_norm: 113.5447  loss: 14.5105  decode.loss_cls: 0.5274  decode.loss_mask: 0.3519  decode.loss_dice: 0.3962  decode.d0.loss_cls: 1.4509  decode.d0.loss_mask: 0.3541  decode.d0.loss_dice: 0.4256  decode.d1.loss_cls: 0.7509  decode.d1.loss_mask: 0.3596  decode.d1.loss_dice: 0.4285  decode.d2.loss_cls: 0.6825  decode.d2.loss_mask: 0.3339  decode.d2.loss_dice: 0.3920  decode.d3.loss_cls: 0.6783  decode.d3.loss_mask: 0.3414  decode.d3.loss_dice: 0.3716  decode.d4.loss_cls: 0.6581  decode.d4.loss_mask: 0.3335  decode.d4.loss_dice: 0.3874  decode.d5.loss_cls: 0.6414  decode.d5.loss_mask: 0.3346  decode.d5.loss_dice: 0.3784  decode.d6.loss_cls: 0.5948  decode.d6.loss_mask: 0.3346  decode.d6.loss_dice: 0.3719  decode.d7.loss_cls: 0.5638  decode.d7.loss_mask: 0.3765  decode.d7.loss_dice: 0.3916  decode.d8.loss_cls: 0.5570  decode.d8.loss_mask: 0.3438  decode.d8.loss_dice: 0.3983
07/30 17:44:30 - mmengine - INFO - Iter(train) [ 8850/80000]  base_lr: 8.9987e-05 lr: 8.9987e-06  eta: 8:36:20  time: 0.4353  data_time: 0.0090  memory: 5246  grad_norm: 138.6157  loss: 12.4758  decode.loss_cls: 0.4890  decode.loss_mask: 0.2520  decode.loss_dice: 0.3492  decode.d0.loss_cls: 1.4223  decode.d0.loss_mask: 0.2708  decode.d0.loss_dice: 0.4387  decode.d1.loss_cls: 0.5750  decode.d1.loss_mask: 0.2680  decode.d1.loss_dice: 0.3735  decode.d2.loss_cls: 0.5259  decode.d2.loss_mask: 0.2548  decode.d2.loss_dice: 0.3834  decode.d3.loss_cls: 0.5130  decode.d3.loss_mask: 0.2522  decode.d3.loss_dice: 0.3655  decode.d4.loss_cls: 0.5350  decode.d4.loss_mask: 0.2559  decode.d4.loss_dice: 0.3869  decode.d5.loss_cls: 0.5386  decode.d5.loss_mask: 0.2529  decode.d5.loss_dice: 0.3612  decode.d6.loss_cls: 0.4939  decode.d6.loss_mask: 0.2554  decode.d6.loss_dice: 0.3782  decode.d7.loss_cls: 0.5075  decode.d7.loss_mask: 0.2569  decode.d7.loss_dice: 0.3646  decode.d8.loss_cls: 0.5195  decode.d8.loss_mask: 0.2511  decode.d8.loss_dice: 0.3848
07/30 17:44:52 - mmengine - INFO - Iter(train) [ 8900/80000]  base_lr: 8.9930e-05 lr: 8.9930e-06  eta: 8:35:58  time: 0.4356  data_time: 0.0090  memory: 5265  grad_norm: 59.1740  loss: 10.0856  decode.loss_cls: 0.3533  decode.loss_mask: 0.2581  decode.loss_dice: 0.3011  decode.d0.loss_cls: 1.3129  decode.d0.loss_mask: 0.2694  decode.d0.loss_dice: 0.3594  decode.d1.loss_cls: 0.3901  decode.d1.loss_mask: 0.2675  decode.d1.loss_dice: 0.3044  decode.d2.loss_cls: 0.3420  decode.d2.loss_mask: 0.2575  decode.d2.loss_dice: 0.2876  decode.d3.loss_cls: 0.3310  decode.d3.loss_mask: 0.2575  decode.d3.loss_dice: 0.3031  decode.d4.loss_cls: 0.3164  decode.d4.loss_mask: 0.2564  decode.d4.loss_dice: 0.2974  decode.d5.loss_cls: 0.3501  decode.d5.loss_mask: 0.2577  decode.d5.loss_dice: 0.2954  decode.d6.loss_cls: 0.3253  decode.d6.loss_mask: 0.2650  decode.d6.loss_dice: 0.3039  decode.d7.loss_cls: 0.3593  decode.d7.loss_mask: 0.2553  decode.d7.loss_dice: 0.2898  decode.d8.loss_cls: 0.3487  decode.d8.loss_mask: 0.2600  decode.d8.loss_dice: 0.3102
07/30 17:45:13 - mmengine - INFO - Iter(train) [ 8950/80000]  base_lr: 8.9873e-05 lr: 8.9873e-06  eta: 8:35:36  time: 0.4349  data_time: 0.0090  memory: 5279  grad_norm: 85.6822  loss: 10.2932  decode.loss_cls: 0.3262  decode.loss_mask: 0.2874  decode.loss_dice: 0.3175  decode.d0.loss_cls: 1.2781  decode.d0.loss_mask: 0.2946  decode.d0.loss_dice: 0.3432  decode.d1.loss_cls: 0.3863  decode.d1.loss_mask: 0.2818  decode.d1.loss_dice: 0.3004  decode.d2.loss_cls: 0.2933  decode.d2.loss_mask: 0.2835  decode.d2.loss_dice: 0.3015  decode.d3.loss_cls: 0.3111  decode.d3.loss_mask: 0.2827  decode.d3.loss_dice: 0.3125  decode.d4.loss_cls: 0.3004  decode.d4.loss_mask: 0.2829  decode.d4.loss_dice: 0.3081  decode.d5.loss_cls: 0.3547  decode.d5.loss_mask: 0.2840  decode.d5.loss_dice: 0.3274  decode.d6.loss_cls: 0.3113  decode.d6.loss_mask: 0.2783  decode.d6.loss_dice: 0.3153  decode.d7.loss_cls: 0.3685  decode.d7.loss_mask: 0.2913  decode.d7.loss_dice: 0.3186  decode.d8.loss_cls: 0.3364  decode.d8.loss_mask: 0.2882  decode.d8.loss_dice: 0.3280
07/30 17:45:35 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 17:45:35 - mmengine - INFO - Iter(train) [ 9000/80000]  base_lr: 8.9817e-05 lr: 8.9817e-06  eta: 8:35:16  time: 0.4338  data_time: 0.0089  memory: 5227  grad_norm: 147.4289  loss: 11.0181  decode.loss_cls: 0.4239  decode.loss_mask: 0.2806  decode.loss_dice: 0.3329  decode.d0.loss_cls: 1.2595  decode.d0.loss_mask: 0.2946  decode.d0.loss_dice: 0.3907  decode.d1.loss_cls: 0.4646  decode.d1.loss_mask: 0.2865  decode.d1.loss_dice: 0.3455  decode.d2.loss_cls: 0.3821  decode.d2.loss_mask: 0.2872  decode.d2.loss_dice: 0.3434  decode.d3.loss_cls: 0.3275  decode.d3.loss_mask: 0.2929  decode.d3.loss_dice: 0.3296  decode.d4.loss_cls: 0.4017  decode.d4.loss_mask: 0.2850  decode.d4.loss_dice: 0.3200  decode.d5.loss_cls: 0.3482  decode.d5.loss_mask: 0.2888  decode.d5.loss_dice: 0.3462  decode.d6.loss_cls: 0.3663  decode.d6.loss_mask: 0.2859  decode.d6.loss_dice: 0.3251  decode.d7.loss_cls: 0.4015  decode.d7.loss_mask: 0.2814  decode.d7.loss_dice: 0.3360  decode.d8.loss_cls: 0.3954  decode.d8.loss_mask: 0.2784  decode.d8.loss_dice: 0.3168
07/30 17:45:57 - mmengine - INFO - Iter(train) [ 9050/80000]  base_lr: 8.9760e-05 lr: 8.9760e-06  eta: 8:34:54  time: 0.4364  data_time: 0.0090  memory: 5303  grad_norm: 96.6391  loss: 12.1513  decode.loss_cls: 0.4912  decode.loss_mask: 0.2636  decode.loss_dice: 0.3052  decode.d0.loss_cls: 1.5194  decode.d0.loss_mask: 0.2730  decode.d0.loss_dice: 0.3933  decode.d1.loss_cls: 0.6346  decode.d1.loss_mask: 0.2737  decode.d1.loss_dice: 0.3289  decode.d2.loss_cls: 0.4859  decode.d2.loss_mask: 0.2754  decode.d2.loss_dice: 0.3375  decode.d3.loss_cls: 0.5100  decode.d3.loss_mask: 0.2548  decode.d3.loss_dice: 0.3278  decode.d4.loss_cls: 0.4989  decode.d4.loss_mask: 0.2585  decode.d4.loss_dice: 0.3187  decode.d5.loss_cls: 0.4873  decode.d5.loss_mask: 0.2554  decode.d5.loss_dice: 0.3335  decode.d6.loss_cls: 0.4859  decode.d6.loss_mask: 0.2577  decode.d6.loss_dice: 0.3245  decode.d7.loss_cls: 0.5548  decode.d7.loss_mask: 0.2565  decode.d7.loss_dice: 0.3176  decode.d8.loss_cls: 0.5464  decode.d8.loss_mask: 0.2614  decode.d8.loss_dice: 0.3198
07/30 17:46:19 - mmengine - INFO - Iter(train) [ 9100/80000]  base_lr: 8.9703e-05 lr: 8.9703e-06  eta: 8:34:32  time: 0.4367  data_time: 0.0090  memory: 5244  grad_norm: 94.2739  loss: 12.0121  decode.loss_cls: 0.5262  decode.loss_mask: 0.2427  decode.loss_dice: 0.2946  decode.d0.loss_cls: 1.3395  decode.d0.loss_mask: 0.2528  decode.d0.loss_dice: 0.3471  decode.d1.loss_cls: 0.6172  decode.d1.loss_mask: 0.2506  decode.d1.loss_dice: 0.3375  decode.d2.loss_cls: 0.5513  decode.d2.loss_mask: 0.2526  decode.d2.loss_dice: 0.3238  decode.d3.loss_cls: 0.5734  decode.d3.loss_mask: 0.2492  decode.d3.loss_dice: 0.3420  decode.d4.loss_cls: 0.5436  decode.d4.loss_mask: 0.2475  decode.d4.loss_dice: 0.3054  decode.d5.loss_cls: 0.5708  decode.d5.loss_mask: 0.2396  decode.d5.loss_dice: 0.3151  decode.d6.loss_cls: 0.5277  decode.d6.loss_mask: 0.2431  decode.d6.loss_dice: 0.3192  decode.d7.loss_cls: 0.5751  decode.d7.loss_mask: 0.2429  decode.d7.loss_dice: 0.3088  decode.d8.loss_cls: 0.5315  decode.d8.loss_mask: 0.2384  decode.d8.loss_dice: 0.3031
07/30 17:46:41 - mmengine - INFO - Iter(train) [ 9150/80000]  base_lr: 8.9646e-05 lr: 8.9646e-06  eta: 8:34:11  time: 0.4354  data_time: 0.0089  memory: 5304  grad_norm: 68.8500  loss: 8.9040  decode.loss_cls: 0.3629  decode.loss_mask: 0.2346  decode.loss_dice: 0.2577  decode.d0.loss_cls: 1.2143  decode.d0.loss_mask: 0.2461  decode.d0.loss_dice: 0.2952  decode.d1.loss_cls: 0.3937  decode.d1.loss_mask: 0.2374  decode.d1.loss_dice: 0.2735  decode.d2.loss_cls: 0.2560  decode.d2.loss_mask: 0.2375  decode.d2.loss_dice: 0.2695  decode.d3.loss_cls: 0.2507  decode.d3.loss_mask: 0.2298  decode.d3.loss_dice: 0.2590  decode.d4.loss_cls: 0.2574  decode.d4.loss_mask: 0.2314  decode.d4.loss_dice: 0.2509  decode.d5.loss_cls: 0.2773  decode.d5.loss_mask: 0.2308  decode.d5.loss_dice: 0.2623  decode.d6.loss_cls: 0.2658  decode.d6.loss_mask: 0.2349  decode.d6.loss_dice: 0.2573  decode.d7.loss_cls: 0.2830  decode.d7.loss_mask: 0.2361  decode.d7.loss_dice: 0.2721  decode.d8.loss_cls: 0.3202  decode.d8.loss_mask: 0.2356  decode.d8.loss_dice: 0.2710
07/30 17:47:02 - mmengine - INFO - Iter(train) [ 9200/80000]  base_lr: 8.9589e-05 lr: 8.9589e-06  eta: 8:33:49  time: 0.4364  data_time: 0.0088  memory: 5246  grad_norm: 154.2710  loss: 11.6778  decode.loss_cls: 0.3800  decode.loss_mask: 0.3022  decode.loss_dice: 0.3332  decode.d0.loss_cls: 1.4275  decode.d0.loss_mask: 0.2906  decode.d0.loss_dice: 0.3653  decode.d1.loss_cls: 0.5586  decode.d1.loss_mask: 0.2849  decode.d1.loss_dice: 0.3519  decode.d2.loss_cls: 0.5135  decode.d2.loss_mask: 0.2779  decode.d2.loss_dice: 0.3037  decode.d3.loss_cls: 0.4893  decode.d3.loss_mask: 0.2820  decode.d3.loss_dice: 0.3014  decode.d4.loss_cls: 0.4205  decode.d4.loss_mask: 0.2824  decode.d4.loss_dice: 0.3294  decode.d5.loss_cls: 0.4473  decode.d5.loss_mask: 0.2843  decode.d5.loss_dice: 0.3229  decode.d6.loss_cls: 0.4064  decode.d6.loss_mask: 0.2671  decode.d6.loss_dice: 0.3090  decode.d7.loss_cls: 0.3826  decode.d7.loss_mask: 0.3201  decode.d7.loss_dice: 0.3414  decode.d8.loss_cls: 0.3954  decode.d8.loss_mask: 0.3447  decode.d8.loss_dice: 0.3620
07/30 17:47:24 - mmengine - INFO - Iter(train) [ 9250/80000]  base_lr: 8.9532e-05 lr: 8.9532e-06  eta: 8:33:27  time: 0.4349  data_time: 0.0087  memory: 5265  grad_norm: 215.9016  loss: 12.1012  decode.loss_cls: 0.4060  decode.loss_mask: 0.3561  decode.loss_dice: 0.3789  decode.d0.loss_cls: 1.3429  decode.d0.loss_mask: 0.3564  decode.d0.loss_dice: 0.4124  decode.d1.loss_cls: 0.5141  decode.d1.loss_mask: 0.3137  decode.d1.loss_dice: 0.3582  decode.d2.loss_cls: 0.4499  decode.d2.loss_mask: 0.2966  decode.d2.loss_dice: 0.3174  decode.d3.loss_cls: 0.5058  decode.d3.loss_mask: 0.3031  decode.d3.loss_dice: 0.3289  decode.d4.loss_cls: 0.4463  decode.d4.loss_mask: 0.3020  decode.d4.loss_dice: 0.3381  decode.d5.loss_cls: 0.4070  decode.d5.loss_mask: 0.3451  decode.d5.loss_dice: 0.3596  decode.d6.loss_cls: 0.3915  decode.d6.loss_mask: 0.3396  decode.d6.loss_dice: 0.3243  decode.d7.loss_cls: 0.3936  decode.d7.loss_mask: 0.3463  decode.d7.loss_dice: 0.3450  decode.d8.loss_cls: 0.4335  decode.d8.loss_mask: 0.3486  decode.d8.loss_dice: 0.3404
07/30 17:47:46 - mmengine - INFO - Iter(train) [ 9300/80000]  base_lr: 8.9475e-05 lr: 8.9475e-06  eta: 8:33:06  time: 0.4355  data_time: 0.0088  memory: 5279  grad_norm: 217.8492  loss: 11.3890  decode.loss_cls: 0.2505  decode.loss_mask: 0.3013  decode.loss_dice: 0.3684  decode.d0.loss_cls: 1.2901  decode.d0.loss_mask: 0.3689  decode.d0.loss_dice: 0.4487  decode.d1.loss_cls: 0.5373  decode.d1.loss_mask: 0.2917  decode.d1.loss_dice: 0.3895  decode.d2.loss_cls: 0.3041  decode.d2.loss_mask: 0.3221  decode.d2.loss_dice: 0.3977  decode.d3.loss_cls: 0.3809  decode.d3.loss_mask: 0.3176  decode.d3.loss_dice: 0.3927  decode.d4.loss_cls: 0.3852  decode.d4.loss_mask: 0.2833  decode.d4.loss_dice: 0.3844  decode.d5.loss_cls: 0.3230  decode.d5.loss_mask: 0.3362  decode.d5.loss_dice: 0.3958  decode.d6.loss_cls: 0.3103  decode.d6.loss_mask: 0.3313  decode.d6.loss_dice: 0.3717  decode.d7.loss_cls: 0.3059  decode.d7.loss_mask: 0.2960  decode.d7.loss_dice: 0.3673  decode.d8.loss_cls: 0.2783  decode.d8.loss_mask: 0.2942  decode.d8.loss_dice: 0.3644
07/30 17:48:08 - mmengine - INFO - Iter(train) [ 9350/80000]  base_lr: 8.9418e-05 lr: 8.9418e-06  eta: 8:32:44  time: 0.4361  data_time: 0.0089  memory: 5322  grad_norm: 91.1889  loss: 10.2746  decode.loss_cls: 0.3599  decode.loss_mask: 0.3055  decode.loss_dice: 0.3008  decode.d0.loss_cls: 1.1023  decode.d0.loss_mask: 0.3260  decode.d0.loss_dice: 0.3558  decode.d1.loss_cls: 0.2917  decode.d1.loss_mask: 0.3114  decode.d1.loss_dice: 0.3233  decode.d2.loss_cls: 0.2659  decode.d2.loss_mask: 0.3147  decode.d2.loss_dice: 0.3294  decode.d3.loss_cls: 0.3681  decode.d3.loss_mask: 0.3052  decode.d3.loss_dice: 0.3043  decode.d4.loss_cls: 0.2954  decode.d4.loss_mask: 0.3100  decode.d4.loss_dice: 0.3113  decode.d5.loss_cls: 0.3380  decode.d5.loss_mask: 0.3031  decode.d5.loss_dice: 0.3239  decode.d6.loss_cls: 0.3459  decode.d6.loss_mask: 0.3078  decode.d6.loss_dice: 0.3097  decode.d7.loss_cls: 0.3259  decode.d7.loss_mask: 0.3050  decode.d7.loss_dice: 0.3136  decode.d8.loss_cls: 0.3062  decode.d8.loss_mask: 0.3100  decode.d8.loss_dice: 0.3046
07/30 17:48:29 - mmengine - INFO - Iter(train) [ 9400/80000]  base_lr: 8.9361e-05 lr: 8.9361e-06  eta: 8:32:22  time: 0.4351  data_time: 0.0088  memory: 5265  grad_norm: 153.8957  loss: 12.4932  decode.loss_cls: 0.4296  decode.loss_mask: 0.3195  decode.loss_dice: 0.3811  decode.d0.loss_cls: 1.0727  decode.d0.loss_mask: 0.3365  decode.d0.loss_dice: 0.5049  decode.d1.loss_cls: 0.4608  decode.d1.loss_mask: 0.3221  decode.d1.loss_dice: 0.4031  decode.d2.loss_cls: 0.4742  decode.d2.loss_mask: 0.3138  decode.d2.loss_dice: 0.3655  decode.d3.loss_cls: 0.4664  decode.d3.loss_mask: 0.3095  decode.d3.loss_dice: 0.3654  decode.d4.loss_cls: 0.4965  decode.d4.loss_mask: 0.3139  decode.d4.loss_dice: 0.3585  decode.d5.loss_cls: 0.6143  decode.d5.loss_mask: 0.3081  decode.d5.loss_dice: 0.3745  decode.d6.loss_cls: 0.4614  decode.d6.loss_mask: 0.3150  decode.d6.loss_dice: 0.3751  decode.d7.loss_cls: 0.4920  decode.d7.loss_mask: 0.3203  decode.d7.loss_dice: 0.3784  decode.d8.loss_cls: 0.4614  decode.d8.loss_mask: 0.3208  decode.d8.loss_dice: 0.3781
07/30 17:48:51 - mmengine - INFO - Iter(train) [ 9450/80000]  base_lr: 8.9304e-05 lr: 8.9304e-06  eta: 8:32:00  time: 0.4354  data_time: 0.0088  memory: 5303  grad_norm: 139.6110  loss: 10.9283  decode.loss_cls: 0.4441  decode.loss_mask: 0.2585  decode.loss_dice: 0.3112  decode.d0.loss_cls: 1.2700  decode.d0.loss_mask: 0.2779  decode.d0.loss_dice: 0.3557  decode.d1.loss_cls: 0.6135  decode.d1.loss_mask: 0.2477  decode.d1.loss_dice: 0.2772  decode.d2.loss_cls: 0.4679  decode.d2.loss_mask: 0.2472  decode.d2.loss_dice: 0.2843  decode.d3.loss_cls: 0.4277  decode.d3.loss_mask: 0.2448  decode.d3.loss_dice: 0.2879  decode.d4.loss_cls: 0.4186  decode.d4.loss_mask: 0.2481  decode.d4.loss_dice: 0.2753  decode.d5.loss_cls: 0.4105  decode.d5.loss_mask: 0.2441  decode.d5.loss_dice: 0.2737  decode.d6.loss_cls: 0.4135  decode.d6.loss_mask: 0.2465  decode.d6.loss_dice: 0.2765  decode.d7.loss_cls: 0.4542  decode.d7.loss_mask: 0.2598  decode.d7.loss_dice: 0.3206  decode.d8.loss_cls: 0.5035  decode.d8.loss_mask: 0.2655  decode.d8.loss_dice: 0.3022
07/30 17:49:13 - mmengine - INFO - Iter(train) [ 9500/80000]  base_lr: 8.9247e-05 lr: 8.9247e-06  eta: 8:31:38  time: 0.4349  data_time: 0.0087  memory: 5265  grad_norm: 138.0077  loss: 8.4791  decode.loss_cls: 0.2075  decode.loss_mask: 0.2541  decode.loss_dice: 0.2576  decode.d0.loss_cls: 1.1508  decode.d0.loss_mask: 0.2896  decode.d0.loss_dice: 0.3026  decode.d1.loss_cls: 0.3369  decode.d1.loss_mask: 0.2597  decode.d1.loss_dice: 0.2597  decode.d2.loss_cls: 0.3293  decode.d2.loss_mask: 0.2602  decode.d2.loss_dice: 0.2638  decode.d3.loss_cls: 0.1812  decode.d3.loss_mask: 0.2637  decode.d3.loss_dice: 0.2547  decode.d4.loss_cls: 0.2035  decode.d4.loss_mask: 0.2582  decode.d4.loss_dice: 0.2528  decode.d5.loss_cls: 0.2076  decode.d5.loss_mask: 0.2574  decode.d5.loss_dice: 0.2528  decode.d6.loss_cls: 0.2089  decode.d6.loss_mask: 0.2609  decode.d6.loss_dice: 0.2540  decode.d7.loss_cls: 0.2043  decode.d7.loss_mask: 0.2568  decode.d7.loss_dice: 0.2511  decode.d8.loss_cls: 0.2315  decode.d8.loss_mask: 0.2572  decode.d8.loss_dice: 0.2508
07/30 17:49:35 - mmengine - INFO - Iter(train) [ 9550/80000]  base_lr: 8.9190e-05 lr: 8.9190e-06  eta: 8:31:16  time: 0.4350  data_time: 0.0089  memory: 5265  grad_norm: 212.5348  loss: 15.5625  decode.loss_cls: 0.5412  decode.loss_mask: 0.4842  decode.loss_dice: 0.4768  decode.d0.loss_cls: 1.4508  decode.d0.loss_mask: 0.4490  decode.d0.loss_dice: 0.4791  decode.d1.loss_cls: 0.6081  decode.d1.loss_mask: 0.4549  decode.d1.loss_dice: 0.4265  decode.d2.loss_cls: 0.5773  decode.d2.loss_mask: 0.4684  decode.d2.loss_dice: 0.4263  decode.d3.loss_cls: 0.5194  decode.d3.loss_mask: 0.4606  decode.d3.loss_dice: 0.4349  decode.d4.loss_cls: 0.5098  decode.d4.loss_mask: 0.4717  decode.d4.loss_dice: 0.4553  decode.d5.loss_cls: 0.5310  decode.d5.loss_mask: 0.4601  decode.d5.loss_dice: 0.4508  decode.d6.loss_cls: 0.5221  decode.d6.loss_mask: 0.4422  decode.d6.loss_dice: 0.4382  decode.d7.loss_cls: 0.5898  decode.d7.loss_mask: 0.4579  decode.d7.loss_dice: 0.4390  decode.d8.loss_cls: 0.5884  decode.d8.loss_mask: 0.4689  decode.d8.loss_dice: 0.4798
07/30 17:49:56 - mmengine - INFO - Iter(train) [ 9600/80000]  base_lr: 8.9133e-05 lr: 8.9133e-06  eta: 8:30:55  time: 0.4348  data_time: 0.0085  memory: 5265  grad_norm: 150.7416  loss: 13.0505  decode.loss_cls: 0.5905  decode.loss_mask: 0.2631  decode.loss_dice: 0.3903  decode.d0.loss_cls: 1.5097  decode.d0.loss_mask: 0.3034  decode.d0.loss_dice: 0.4445  decode.d1.loss_cls: 0.6768  decode.d1.loss_mask: 0.2530  decode.d1.loss_dice: 0.3587  decode.d2.loss_cls: 0.5457  decode.d2.loss_mask: 0.2604  decode.d2.loss_dice: 0.3761  decode.d3.loss_cls: 0.5268  decode.d3.loss_mask: 0.2689  decode.d3.loss_dice: 0.3884  decode.d4.loss_cls: 0.4979  decode.d4.loss_mask: 0.2520  decode.d4.loss_dice: 0.3685  decode.d5.loss_cls: 0.4951  decode.d5.loss_mask: 0.2589  decode.d5.loss_dice: 0.3994  decode.d6.loss_cls: 0.5043  decode.d6.loss_mask: 0.2473  decode.d6.loss_dice: 0.3926  decode.d7.loss_cls: 0.4945  decode.d7.loss_mask: 0.2806  decode.d7.loss_dice: 0.3937  decode.d8.loss_cls: 0.6898  decode.d8.loss_mask: 0.2426  decode.d8.loss_dice: 0.3772
07/30 17:50:18 - mmengine - INFO - Iter(train) [ 9650/80000]  base_lr: 8.9076e-05 lr: 8.9076e-06  eta: 8:30:33  time: 0.4357  data_time: 0.0089  memory: 5261  grad_norm: 128.2366  loss: 11.9408  decode.loss_cls: 0.4018  decode.loss_mask: 0.3598  decode.loss_dice: 0.3540  decode.d0.loss_cls: 1.4261  decode.d0.loss_mask: 0.3066  decode.d0.loss_dice: 0.3926  decode.d1.loss_cls: 0.3973  decode.d1.loss_mask: 0.2908  decode.d1.loss_dice: 0.3483  decode.d2.loss_cls: 0.3399  decode.d2.loss_mask: 0.2888  decode.d2.loss_dice: 0.3383  decode.d3.loss_cls: 0.3352  decode.d3.loss_mask: 0.3480  decode.d3.loss_dice: 0.3508  decode.d4.loss_cls: 0.3545  decode.d4.loss_mask: 0.3330  decode.d4.loss_dice: 0.3599  decode.d5.loss_cls: 0.3580  decode.d5.loss_mask: 0.3655  decode.d5.loss_dice: 0.3715  decode.d6.loss_cls: 0.3972  decode.d6.loss_mask: 0.3737  decode.d6.loss_dice: 0.3687  decode.d7.loss_cls: 0.4549  decode.d7.loss_mask: 0.3707  decode.d7.loss_dice: 0.3708  decode.d8.loss_cls: 0.4687  decode.d8.loss_mask: 0.3345  decode.d8.loss_dice: 0.3811
07/30 17:50:40 - mmengine - INFO - Iter(train) [ 9700/80000]  base_lr: 8.9019e-05 lr: 8.9019e-06  eta: 8:30:11  time: 0.4353  data_time: 0.0090  memory: 5261  grad_norm: 73.8997  loss: 11.2123  decode.loss_cls: 0.2796  decode.loss_mask: 0.3154  decode.loss_dice: 0.3712  decode.d0.loss_cls: 1.2039  decode.d0.loss_mask: 0.3295  decode.d0.loss_dice: 0.4142  decode.d1.loss_cls: 0.4110  decode.d1.loss_mask: 0.3283  decode.d1.loss_dice: 0.3755  decode.d2.loss_cls: 0.3325  decode.d2.loss_mask: 0.3254  decode.d2.loss_dice: 0.3823  decode.d3.loss_cls: 0.3108  decode.d3.loss_mask: 0.3141  decode.d3.loss_dice: 0.3936  decode.d4.loss_cls: 0.3581  decode.d4.loss_mask: 0.3179  decode.d4.loss_dice: 0.3863  decode.d5.loss_cls: 0.2770  decode.d5.loss_mask: 0.3169  decode.d5.loss_dice: 0.3888  decode.d6.loss_cls: 0.3543  decode.d6.loss_mask: 0.3262  decode.d6.loss_dice: 0.3887  decode.d7.loss_cls: 0.3030  decode.d7.loss_mask: 0.3274  decode.d7.loss_dice: 0.3846  decode.d8.loss_cls: 0.2842  decode.d8.loss_mask: 0.3240  decode.d8.loss_dice: 0.3873
07/30 17:51:02 - mmengine - INFO - Iter(train) [ 9750/80000]  base_lr: 8.8962e-05 lr: 8.8962e-06  eta: 8:29:49  time: 0.4349  data_time: 0.0088  memory: 5265  grad_norm: 71.8872  loss: 10.2444  decode.loss_cls: 0.3136  decode.loss_mask: 0.3112  decode.loss_dice: 0.3004  decode.d0.loss_cls: 1.1843  decode.d0.loss_mask: 0.3219  decode.d0.loss_dice: 0.3466  decode.d1.loss_cls: 0.4125  decode.d1.loss_mask: 0.3086  decode.d1.loss_dice: 0.2783  decode.d2.loss_cls: 0.3090  decode.d2.loss_mask: 0.3031  decode.d2.loss_dice: 0.2978  decode.d3.loss_cls: 0.3224  decode.d3.loss_mask: 0.3032  decode.d3.loss_dice: 0.2914  decode.d4.loss_cls: 0.3171  decode.d4.loss_mask: 0.3097  decode.d4.loss_dice: 0.2981  decode.d5.loss_cls: 0.3468  decode.d5.loss_mask: 0.3042  decode.d5.loss_dice: 0.2967  decode.d6.loss_cls: 0.3247  decode.d6.loss_mask: 0.3082  decode.d6.loss_dice: 0.2819  decode.d7.loss_cls: 0.3202  decode.d7.loss_mask: 0.3115  decode.d7.loss_dice: 0.2948  decode.d8.loss_cls: 0.3153  decode.d8.loss_mask: 0.3126  decode.d8.loss_dice: 0.2981
07/30 17:51:24 - mmengine - INFO - Iter(train) [ 9800/80000]  base_lr: 8.8905e-05 lr: 8.8905e-06  eta: 8:29:27  time: 0.4355  data_time: 0.0089  memory: 5279  grad_norm: 74.1057  loss: 9.1511  decode.loss_cls: 0.2947  decode.loss_mask: 0.2505  decode.loss_dice: 0.2887  decode.d0.loss_cls: 1.0910  decode.d0.loss_mask: 0.2570  decode.d0.loss_dice: 0.3376  decode.d1.loss_cls: 0.3847  decode.d1.loss_mask: 0.2645  decode.d1.loss_dice: 0.3028  decode.d2.loss_cls: 0.3080  decode.d2.loss_mask: 0.2475  decode.d2.loss_dice: 0.2862  decode.d3.loss_cls: 0.3109  decode.d3.loss_mask: 0.2476  decode.d3.loss_dice: 0.2726  decode.d4.loss_cls: 0.2927  decode.d4.loss_mask: 0.2473  decode.d4.loss_dice: 0.3105  decode.d5.loss_cls: 0.2755  decode.d5.loss_mask: 0.2452  decode.d5.loss_dice: 0.2728  decode.d6.loss_cls: 0.2408  decode.d6.loss_mask: 0.2442  decode.d6.loss_dice: 0.2711  decode.d7.loss_cls: 0.2768  decode.d7.loss_mask: 0.2462  decode.d7.loss_dice: 0.2801  decode.d8.loss_cls: 0.2788  decode.d8.loss_mask: 0.2481  decode.d8.loss_dice: 0.2766
07/30 17:51:45 - mmengine - INFO - Iter(train) [ 9850/80000]  base_lr: 8.8848e-05 lr: 8.8848e-06  eta: 8:29:06  time: 0.4356  data_time: 0.0089  memory: 5265  grad_norm: 110.1426  loss: 11.4647  decode.loss_cls: 0.4596  decode.loss_mask: 0.2516  decode.loss_dice: 0.3394  decode.d0.loss_cls: 1.2510  decode.d0.loss_mask: 0.2689  decode.d0.loss_dice: 0.3771  decode.d1.loss_cls: 0.5295  decode.d1.loss_mask: 0.2593  decode.d1.loss_dice: 0.3388  decode.d2.loss_cls: 0.4922  decode.d2.loss_mask: 0.2537  decode.d2.loss_dice: 0.3219  decode.d3.loss_cls: 0.4886  decode.d3.loss_mask: 0.2549  decode.d3.loss_dice: 0.3181  decode.d4.loss_cls: 0.5215  decode.d4.loss_mask: 0.2473  decode.d4.loss_dice: 0.3187  decode.d5.loss_cls: 0.4485  decode.d5.loss_mask: 0.2564  decode.d5.loss_dice: 0.3226  decode.d6.loss_cls: 0.5026  decode.d6.loss_mask: 0.2510  decode.d6.loss_dice: 0.3013  decode.d7.loss_cls: 0.4552  decode.d7.loss_mask: 0.2501  decode.d7.loss_dice: 0.3115  decode.d8.loss_cls: 0.4978  decode.d8.loss_mask: 0.2498  decode.d8.loss_dice: 0.3255
07/30 17:52:07 - mmengine - INFO - Iter(train) [ 9900/80000]  base_lr: 8.8791e-05 lr: 8.8791e-06  eta: 8:28:44  time: 0.4344  data_time: 0.0090  memory: 5261  grad_norm: 81.3589  loss: 12.4856  decode.loss_cls: 0.3537  decode.loss_mask: 0.3818  decode.loss_dice: 0.3653  decode.d0.loss_cls: 1.1238  decode.d0.loss_mask: 0.3854  decode.d0.loss_dice: 0.4019  decode.d1.loss_cls: 0.7312  decode.d1.loss_mask: 0.3573  decode.d1.loss_dice: 0.3730  decode.d2.loss_cls: 0.4856  decode.d2.loss_mask: 0.3634  decode.d2.loss_dice: 0.3782  decode.d3.loss_cls: 0.3535  decode.d3.loss_mask: 0.3498  decode.d3.loss_dice: 0.3522  decode.d4.loss_cls: 0.4698  decode.d4.loss_mask: 0.4030  decode.d4.loss_dice: 0.3726  decode.d5.loss_cls: 0.4064  decode.d5.loss_mask: 0.3693  decode.d5.loss_dice: 0.3728  decode.d6.loss_cls: 0.3960  decode.d6.loss_mask: 0.3662  decode.d6.loss_dice: 0.3579  decode.d7.loss_cls: 0.3413  decode.d7.loss_mask: 0.3685  decode.d7.loss_dice: 0.3504  decode.d8.loss_cls: 0.4306  decode.d8.loss_mask: 0.3697  decode.d8.loss_dice: 0.3549
07/30 17:52:29 - mmengine - INFO - Iter(train) [ 9950/80000]  base_lr: 8.8734e-05 lr: 8.8734e-06  eta: 8:28:22  time: 0.4341  data_time: 0.0089  memory: 5265  grad_norm: 92.5315  loss: 12.2309  decode.loss_cls: 0.4033  decode.loss_mask: 0.3872  decode.loss_dice: 0.3834  decode.d0.loss_cls: 1.2211  decode.d0.loss_mask: 0.3867  decode.d0.loss_dice: 0.4067  decode.d1.loss_cls: 0.4234  decode.d1.loss_mask: 0.3587  decode.d1.loss_dice: 0.3529  decode.d2.loss_cls: 0.3924  decode.d2.loss_mask: 0.3742  decode.d2.loss_dice: 0.3709  decode.d3.loss_cls: 0.3591  decode.d3.loss_mask: 0.3629  decode.d3.loss_dice: 0.3685  decode.d4.loss_cls: 0.3780  decode.d4.loss_mask: 0.3759  decode.d4.loss_dice: 0.3774  decode.d5.loss_cls: 0.3733  decode.d5.loss_mask: 0.3876  decode.d5.loss_dice: 0.3751  decode.d6.loss_cls: 0.4285  decode.d6.loss_mask: 0.3811  decode.d6.loss_dice: 0.3797  decode.d7.loss_cls: 0.3934  decode.d7.loss_mask: 0.3548  decode.d7.loss_dice: 0.3851  decode.d8.loss_cls: 0.3655  decode.d8.loss_mask: 0.3583  decode.d8.loss_dice: 0.3655
07/30 17:52:51 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 17:52:51 - mmengine - INFO - Iter(train) [10000/80000]  base_lr: 8.8677e-05 lr: 8.8677e-06  eta: 8:28:00  time: 0.4347  data_time: 0.0087  memory: 5227  grad_norm: 133.8103  loss: 11.7688  decode.loss_cls: 0.4089  decode.loss_mask: 0.2665  decode.loss_dice: 0.3830  decode.d0.loss_cls: 1.2101  decode.d0.loss_mask: 0.2867  decode.d0.loss_dice: 0.4188  decode.d1.loss_cls: 0.5852  decode.d1.loss_mask: 0.2512  decode.d1.loss_dice: 0.3858  decode.d2.loss_cls: 0.5808  decode.d2.loss_mask: 0.2640  decode.d2.loss_dice: 0.3855  decode.d3.loss_cls: 0.4600  decode.d3.loss_mask: 0.2554  decode.d3.loss_dice: 0.3649  decode.d4.loss_cls: 0.4406  decode.d4.loss_mask: 0.2556  decode.d4.loss_dice: 0.3496  decode.d5.loss_cls: 0.4692  decode.d5.loss_mask: 0.2620  decode.d5.loss_dice: 0.3610  decode.d6.loss_cls: 0.3204  decode.d6.loss_mask: 0.3062  decode.d6.loss_dice: 0.3822  decode.d7.loss_cls: 0.4177  decode.d7.loss_mask: 0.2513  decode.d7.loss_dice: 0.3702  decode.d8.loss_cls: 0.4290  decode.d8.loss_mask: 0.2680  decode.d8.loss_dice: 0.3789
07/30 17:52:51 - mmengine - INFO - Saving checkpoint at 10000 iterations
07/30 17:53:14 - mmengine - INFO - Iter(train) [10050/80000]  base_lr: 8.8620e-05 lr: 8.8620e-06  eta: 8:27:51  time: 0.4349  data_time: 0.0091  memory: 5265  grad_norm: 118.4426  loss: 11.2905  decode.loss_cls: 0.4200  decode.loss_mask: 0.2814  decode.loss_dice: 0.3287  decode.d0.loss_cls: 1.1796  decode.d0.loss_mask: 0.2903  decode.d0.loss_dice: 0.4020  decode.d1.loss_cls: 0.4774  decode.d1.loss_mask: 0.2831  decode.d1.loss_dice: 0.3599  decode.d2.loss_cls: 0.4459  decode.d2.loss_mask: 0.2809  decode.d2.loss_dice: 0.3734  decode.d3.loss_cls: 0.4071  decode.d3.loss_mask: 0.2782  decode.d3.loss_dice: 0.3565  decode.d4.loss_cls: 0.3914  decode.d4.loss_mask: 0.2772  decode.d4.loss_dice: 0.3609  decode.d5.loss_cls: 0.3886  decode.d5.loss_mask: 0.2773  decode.d5.loss_dice: 0.3305  decode.d6.loss_cls: 0.4188  decode.d6.loss_mask: 0.2765  decode.d6.loss_dice: 0.3259  decode.d7.loss_cls: 0.4362  decode.d7.loss_mask: 0.2823  decode.d7.loss_dice: 0.3324  decode.d8.loss_cls: 0.4216  decode.d8.loss_mask: 0.2825  decode.d8.loss_dice: 0.3240
07/30 17:53:36 - mmengine - INFO - Iter(train) [10100/80000]  base_lr: 8.8563e-05 lr: 8.8563e-06  eta: 8:27:29  time: 0.4352  data_time: 0.0089  memory: 5277  grad_norm: 123.6608  loss: 9.3349  decode.loss_cls: 0.1932  decode.loss_mask: 0.3011  decode.loss_dice: 0.3191  decode.d0.loss_cls: 1.3173  decode.d0.loss_mask: 0.2989  decode.d0.loss_dice: 0.3297  decode.d1.loss_cls: 0.3352  decode.d1.loss_mask: 0.2943  decode.d1.loss_dice: 0.3283  decode.d2.loss_cls: 0.1976  decode.d2.loss_mask: 0.2983  decode.d2.loss_dice: 0.3534  decode.d3.loss_cls: 0.1724  decode.d3.loss_mask: 0.2959  decode.d3.loss_dice: 0.3166  decode.d4.loss_cls: 0.1645  decode.d4.loss_mask: 0.2910  decode.d4.loss_dice: 0.3138  decode.d5.loss_cls: 0.1886  decode.d5.loss_mask: 0.2883  decode.d5.loss_dice: 0.3021  decode.d6.loss_cls: 0.1750  decode.d6.loss_mask: 0.2981  decode.d6.loss_dice: 0.3185  decode.d7.loss_cls: 0.1958  decode.d7.loss_mask: 0.3008  decode.d7.loss_dice: 0.3294  decode.d8.loss_cls: 0.1956  decode.d8.loss_mask: 0.3041  decode.d8.loss_dice: 0.3178
07/30 17:53:58 - mmengine - INFO - Iter(train) [10150/80000]  base_lr: 8.8506e-05 lr: 8.8506e-06  eta: 8:27:07  time: 0.4346  data_time: 0.0089  memory: 5305  grad_norm: 107.6966  loss: 11.6724  decode.loss_cls: 0.4299  decode.loss_mask: 0.2721  decode.loss_dice: 0.3708  decode.d0.loss_cls: 1.2021  decode.d0.loss_mask: 0.2919  decode.d0.loss_dice: 0.4464  decode.d1.loss_cls: 0.5319  decode.d1.loss_mask: 0.2822  decode.d1.loss_dice: 0.3554  decode.d2.loss_cls: 0.4430  decode.d2.loss_mask: 0.2765  decode.d2.loss_dice: 0.3592  decode.d3.loss_cls: 0.4243  decode.d3.loss_mask: 0.2690  decode.d3.loss_dice: 0.3710  decode.d4.loss_cls: 0.4166  decode.d4.loss_mask: 0.2678  decode.d4.loss_dice: 0.3345  decode.d5.loss_cls: 0.4750  decode.d5.loss_mask: 0.2754  decode.d5.loss_dice: 0.3509  decode.d6.loss_cls: 0.4350  decode.d6.loss_mask: 0.2677  decode.d6.loss_dice: 0.3581  decode.d7.loss_cls: 0.4686  decode.d7.loss_mask: 0.2692  decode.d7.loss_dice: 0.3511  decode.d8.loss_cls: 0.4555  decode.d8.loss_mask: 0.2698  decode.d8.loss_dice: 0.3516
07/30 17:54:19 - mmengine - INFO - Iter(train) [10200/80000]  base_lr: 8.8449e-05 lr: 8.8449e-06  eta: 8:26:45  time: 0.4344  data_time: 0.0089  memory: 5227  grad_norm: 118.7299  loss: 13.2296  decode.loss_cls: 0.5492  decode.loss_mask: 0.3324  decode.loss_dice: 0.3651  decode.d0.loss_cls: 1.2463  decode.d0.loss_mask: 0.3376  decode.d0.loss_dice: 0.3839  decode.d1.loss_cls: 0.6064  decode.d1.loss_mask: 0.3207  decode.d1.loss_dice: 0.3651  decode.d2.loss_cls: 0.4897  decode.d2.loss_mask: 0.3253  decode.d2.loss_dice: 0.3585  decode.d3.loss_cls: 0.5683  decode.d3.loss_mask: 0.3269  decode.d3.loss_dice: 0.3561  decode.d4.loss_cls: 0.6072  decode.d4.loss_mask: 0.3157  decode.d4.loss_dice: 0.3346  decode.d5.loss_cls: 0.5868  decode.d5.loss_mask: 0.3200  decode.d5.loss_dice: 0.3773  decode.d6.loss_cls: 0.5703  decode.d6.loss_mask: 0.3308  decode.d6.loss_dice: 0.3458  decode.d7.loss_cls: 0.5321  decode.d7.loss_mask: 0.3303  decode.d7.loss_dice: 0.3535  decode.d8.loss_cls: 0.5994  decode.d8.loss_mask: 0.3238  decode.d8.loss_dice: 0.3706
07/30 17:54:41 - mmengine - INFO - Iter(train) [10250/80000]  base_lr: 8.8392e-05 lr: 8.8392e-06  eta: 8:26:24  time: 0.4343  data_time: 0.0090  memory: 5265  grad_norm: 93.3805  loss: 8.7589  decode.loss_cls: 0.1894  decode.loss_mask: 0.2750  decode.loss_dice: 0.2786  decode.d0.loss_cls: 1.0677  decode.d0.loss_mask: 0.2875  decode.d0.loss_dice: 0.3084  decode.d1.loss_cls: 0.4359  decode.d1.loss_mask: 0.2701  decode.d1.loss_dice: 0.2841  decode.d2.loss_cls: 0.3182  decode.d2.loss_mask: 0.2719  decode.d2.loss_dice: 0.2916  decode.d3.loss_cls: 0.2178  decode.d3.loss_mask: 0.2718  decode.d3.loss_dice: 0.2805  decode.d4.loss_cls: 0.2053  decode.d4.loss_mask: 0.2748  decode.d4.loss_dice: 0.2730  decode.d5.loss_cls: 0.2285  decode.d5.loss_mask: 0.2750  decode.d5.loss_dice: 0.2752  decode.d6.loss_cls: 0.1870  decode.d6.loss_mask: 0.2704  decode.d6.loss_dice: 0.2833  decode.d7.loss_cls: 0.1911  decode.d7.loss_mask: 0.2687  decode.d7.loss_dice: 0.2592  decode.d8.loss_cls: 0.1760  decode.d8.loss_mask: 0.2734  decode.d8.loss_dice: 0.2695
07/30 17:55:03 - mmengine - INFO - Iter(train) [10300/80000]  base_lr: 8.8335e-05 lr: 8.8335e-06  eta: 8:26:02  time: 0.4348  data_time: 0.0090  memory: 5244  grad_norm: 123.5196  loss: 11.5773  decode.loss_cls: 0.4800  decode.loss_mask: 0.2394  decode.loss_dice: 0.3619  decode.d0.loss_cls: 1.4081  decode.d0.loss_mask: 0.2518  decode.d0.loss_dice: 0.4032  decode.d1.loss_cls: 0.5635  decode.d1.loss_mask: 0.2491  decode.d1.loss_dice: 0.3666  decode.d2.loss_cls: 0.4004  decode.d2.loss_mask: 0.2417  decode.d2.loss_dice: 0.3517  decode.d3.loss_cls: 0.3581  decode.d3.loss_mask: 0.2418  decode.d3.loss_dice: 0.3756  decode.d4.loss_cls: 0.4572  decode.d4.loss_mask: 0.2421  decode.d4.loss_dice: 0.3645  decode.d5.loss_cls: 0.4595  decode.d5.loss_mask: 0.2402  decode.d5.loss_dice: 0.3556  decode.d6.loss_cls: 0.4184  decode.d6.loss_mask: 0.2418  decode.d6.loss_dice: 0.3720  decode.d7.loss_cls: 0.4904  decode.d7.loss_mask: 0.2402  decode.d7.loss_dice: 0.3363  decode.d8.loss_cls: 0.4751  decode.d8.loss_mask: 0.2358  decode.d8.loss_dice: 0.3552
07/30 17:55:25 - mmengine - INFO - Iter(train) [10350/80000]  base_lr: 8.8278e-05 lr: 8.8278e-06  eta: 8:25:40  time: 0.4348  data_time: 0.0088  memory: 5261  grad_norm: 89.8047  loss: 8.8747  decode.loss_cls: 0.1444  decode.loss_mask: 0.2904  decode.loss_dice: 0.3269  decode.d0.loss_cls: 1.3087  decode.d0.loss_mask: 0.2771  decode.d0.loss_dice: 0.3407  decode.d1.loss_cls: 0.2718  decode.d1.loss_mask: 0.2659  decode.d1.loss_dice: 0.3068  decode.d2.loss_cls: 0.2179  decode.d2.loss_mask: 0.2629  decode.d2.loss_dice: 0.2924  decode.d3.loss_cls: 0.2296  decode.d3.loss_mask: 0.2675  decode.d3.loss_dice: 0.2995  decode.d4.loss_cls: 0.1679  decode.d4.loss_mask: 0.2929  decode.d4.loss_dice: 0.2962  decode.d5.loss_cls: 0.1832  decode.d5.loss_mask: 0.2885  decode.d5.loss_dice: 0.3041  decode.d6.loss_cls: 0.1603  decode.d6.loss_mask: 0.2986  decode.d6.loss_dice: 0.2979  decode.d7.loss_cls: 0.1668  decode.d7.loss_mask: 0.2903  decode.d7.loss_dice: 0.2925  decode.d8.loss_cls: 0.1439  decode.d8.loss_mask: 0.2908  decode.d8.loss_dice: 0.2982
07/30 17:55:47 - mmengine - INFO - Iter(train) [10400/80000]  base_lr: 8.8221e-05 lr: 8.8221e-06  eta: 8:25:18  time: 0.4347  data_time: 0.0088  memory: 5227  grad_norm: 167.1211  loss: 11.5315  decode.loss_cls: 0.3320  decode.loss_mask: 0.2897  decode.loss_dice: 0.4261  decode.d0.loss_cls: 1.2253  decode.d0.loss_mask: 0.3089  decode.d0.loss_dice: 0.4427  decode.d1.loss_cls: 0.4822  decode.d1.loss_mask: 0.2802  decode.d1.loss_dice: 0.3832  decode.d2.loss_cls: 0.3943  decode.d2.loss_mask: 0.2836  decode.d2.loss_dice: 0.3734  decode.d3.loss_cls: 0.3965  decode.d3.loss_mask: 0.2780  decode.d3.loss_dice: 0.4125  decode.d4.loss_cls: 0.3159  decode.d4.loss_mask: 0.3157  decode.d4.loss_dice: 0.4376  decode.d5.loss_cls: 0.3102  decode.d5.loss_mask: 0.2990  decode.d5.loss_dice: 0.4407  decode.d6.loss_cls: 0.3287  decode.d6.loss_mask: 0.2927  decode.d6.loss_dice: 0.3847  decode.d7.loss_cls: 0.3443  decode.d7.loss_mask: 0.2946  decode.d7.loss_dice: 0.4148  decode.d8.loss_cls: 0.3612  decode.d8.loss_mask: 0.2825  decode.d8.loss_dice: 0.4004
07/30 17:56:08 - mmengine - INFO - Iter(train) [10450/80000]  base_lr: 8.8164e-05 lr: 8.8164e-06  eta: 8:24:56  time: 0.4343  data_time: 0.0089  memory: 5277  grad_norm: 98.0137  loss: 11.4403  decode.loss_cls: 0.3426  decode.loss_mask: 0.3020  decode.loss_dice: 0.3581  decode.d0.loss_cls: 1.2527  decode.d0.loss_mask: 0.3248  decode.d0.loss_dice: 0.3894  decode.d1.loss_cls: 0.4629  decode.d1.loss_mask: 0.3122  decode.d1.loss_dice: 0.3714  decode.d2.loss_cls: 0.4031  decode.d2.loss_mask: 0.3033  decode.d2.loss_dice: 0.3812  decode.d3.loss_cls: 0.3599  decode.d3.loss_mask: 0.3009  decode.d3.loss_dice: 0.3711  decode.d4.loss_cls: 0.3356  decode.d4.loss_mask: 0.3069  decode.d4.loss_dice: 0.3784  decode.d5.loss_cls: 0.3103  decode.d5.loss_mask: 0.2986  decode.d5.loss_dice: 0.3727  decode.d6.loss_cls: 0.3586  decode.d6.loss_mask: 0.3020  decode.d6.loss_dice: 0.3741  decode.d7.loss_cls: 0.4107  decode.d7.loss_mask: 0.3110  decode.d7.loss_dice: 0.3692  decode.d8.loss_cls: 0.3785  decode.d8.loss_mask: 0.3161  decode.d8.loss_dice: 0.3817
07/30 17:56:30 - mmengine - INFO - Iter(train) [10500/80000]  base_lr: 8.8107e-05 lr: 8.8107e-06  eta: 8:24:34  time: 0.4348  data_time: 0.0090  memory: 5246  grad_norm: 73.7817  loss: 9.3368  decode.loss_cls: 0.1175  decode.loss_mask: 0.3433  decode.loss_dice: 0.3465  decode.d0.loss_cls: 1.0990  decode.d0.loss_mask: 0.3583  decode.d0.loss_dice: 0.3835  decode.d1.loss_cls: 0.2481  decode.d1.loss_mask: 0.3500  decode.d1.loss_dice: 0.3625  decode.d2.loss_cls: 0.1567  decode.d2.loss_mask: 0.3432  decode.d2.loss_dice: 0.3713  decode.d3.loss_cls: 0.1050  decode.d3.loss_mask: 0.3431  decode.d3.loss_dice: 0.3579  decode.d4.loss_cls: 0.1011  decode.d4.loss_mask: 0.3417  decode.d4.loss_dice: 0.3620  decode.d5.loss_cls: 0.1143  decode.d5.loss_mask: 0.3418  decode.d5.loss_dice: 0.3643  decode.d6.loss_cls: 0.1181  decode.d6.loss_mask: 0.3493  decode.d6.loss_dice: 0.3456  decode.d7.loss_cls: 0.1154  decode.d7.loss_mask: 0.3528  decode.d7.loss_dice: 0.3464  decode.d8.loss_cls: 0.1141  decode.d8.loss_mask: 0.3418  decode.d8.loss_dice: 0.3421
07/30 17:56:52 - mmengine - INFO - Iter(train) [10550/80000]  base_lr: 8.8050e-05 lr: 8.8050e-06  eta: 8:24:12  time: 0.4353  data_time: 0.0089  memory: 5279  grad_norm: 93.3412  loss: 10.4387  decode.loss_cls: 0.2688  decode.loss_mask: 0.2866  decode.loss_dice: 0.3503  decode.d0.loss_cls: 1.1228  decode.d0.loss_mask: 0.3097  decode.d0.loss_dice: 0.4043  decode.d1.loss_cls: 0.5001  decode.d1.loss_mask: 0.2942  decode.d1.loss_dice: 0.3489  decode.d2.loss_cls: 0.3249  decode.d2.loss_mask: 0.2988  decode.d2.loss_dice: 0.3288  decode.d3.loss_cls: 0.2974  decode.d3.loss_mask: 0.2851  decode.d3.loss_dice: 0.3303  decode.d4.loss_cls: 0.3112  decode.d4.loss_mask: 0.2833  decode.d4.loss_dice: 0.3233  decode.d5.loss_cls: 0.3494  decode.d5.loss_mask: 0.2805  decode.d5.loss_dice: 0.3224  decode.d6.loss_cls: 0.3105  decode.d6.loss_mask: 0.2818  decode.d6.loss_dice: 0.3197  decode.d7.loss_cls: 0.2612  decode.d7.loss_mask: 0.2834  decode.d7.loss_dice: 0.3331  decode.d8.loss_cls: 0.3291  decode.d8.loss_mask: 0.3219  decode.d8.loss_dice: 0.3768
07/30 17:57:14 - mmengine - INFO - Iter(train) [10600/80000]  base_lr: 8.7993e-05 lr: 8.7993e-06  eta: 8:23:50  time: 0.4353  data_time: 0.0088  memory: 5261  grad_norm: 111.7659  loss: 11.1364  decode.loss_cls: 0.2965  decode.loss_mask: 0.2823  decode.loss_dice: 0.3214  decode.d0.loss_cls: 1.3672  decode.d0.loss_mask: 0.2903  decode.d0.loss_dice: 0.3638  decode.d1.loss_cls: 0.5192  decode.d1.loss_mask: 0.2891  decode.d1.loss_dice: 0.3353  decode.d2.loss_cls: 0.4112  decode.d2.loss_mask: 0.2893  decode.d2.loss_dice: 0.3273  decode.d3.loss_cls: 0.4439  decode.d3.loss_mask: 0.2804  decode.d3.loss_dice: 0.3287  decode.d4.loss_cls: 0.4226  decode.d4.loss_mask: 0.2837  decode.d4.loss_dice: 0.3281  decode.d5.loss_cls: 0.3435  decode.d5.loss_mask: 0.2836  decode.d5.loss_dice: 0.3309  decode.d6.loss_cls: 0.3967  decode.d6.loss_mask: 0.2789  decode.d6.loss_dice: 0.3248  decode.d7.loss_cls: 0.3982  decode.d7.loss_mask: 0.2797  decode.d7.loss_dice: 0.3290  decode.d8.loss_cls: 0.3737  decode.d8.loss_mask: 0.2825  decode.d8.loss_dice: 0.3344
07/30 17:57:35 - mmengine - INFO - Iter(train) [10650/80000]  base_lr: 8.7936e-05 lr: 8.7936e-06  eta: 8:23:28  time: 0.4348  data_time: 0.0088  memory: 5278  grad_norm: 93.0258  loss: 9.4354  decode.loss_cls: 0.2935  decode.loss_mask: 0.2186  decode.loss_dice: 0.2986  decode.d0.loss_cls: 1.2014  decode.d0.loss_mask: 0.2268  decode.d0.loss_dice: 0.3558  decode.d1.loss_cls: 0.4488  decode.d1.loss_mask: 0.2176  decode.d1.loss_dice: 0.3121  decode.d2.loss_cls: 0.3534  decode.d2.loss_mask: 0.2237  decode.d2.loss_dice: 0.3006  decode.d3.loss_cls: 0.3551  decode.d3.loss_mask: 0.2200  decode.d3.loss_dice: 0.3029  decode.d4.loss_cls: 0.3077  decode.d4.loss_mask: 0.2184  decode.d4.loss_dice: 0.2969  decode.d5.loss_cls: 0.3397  decode.d5.loss_mask: 0.2184  decode.d5.loss_dice: 0.3068  decode.d6.loss_cls: 0.2504  decode.d6.loss_mask: 0.2217  decode.d6.loss_dice: 0.3040  decode.d7.loss_cls: 0.2518  decode.d7.loss_mask: 0.2213  decode.d7.loss_dice: 0.3115  decode.d8.loss_cls: 0.3254  decode.d8.loss_mask: 0.2203  decode.d8.loss_dice: 0.3122
07/30 17:57:57 - mmengine - INFO - Iter(train) [10700/80000]  base_lr: 8.7879e-05 lr: 8.7879e-06  eta: 8:23:06  time: 0.4354  data_time: 0.0089  memory: 5245  grad_norm: 112.9057  loss: 12.8347  decode.loss_cls: 0.4547  decode.loss_mask: 0.3950  decode.loss_dice: 0.3568  decode.d0.loss_cls: 1.3443  decode.d0.loss_mask: 0.3859  decode.d0.loss_dice: 0.4207  decode.d1.loss_cls: 0.5804  decode.d1.loss_mask: 0.3442  decode.d1.loss_dice: 0.3768  decode.d2.loss_cls: 0.4880  decode.d2.loss_mask: 0.3656  decode.d2.loss_dice: 0.3849  decode.d3.loss_cls: 0.4516  decode.d3.loss_mask: 0.3850  decode.d3.loss_dice: 0.3680  decode.d4.loss_cls: 0.3838  decode.d4.loss_mask: 0.3753  decode.d4.loss_dice: 0.3605  decode.d5.loss_cls: 0.3642  decode.d5.loss_mask: 0.4203  decode.d5.loss_dice: 0.3867  decode.d6.loss_cls: 0.4087  decode.d6.loss_mask: 0.3685  decode.d6.loss_dice: 0.3871  decode.d7.loss_cls: 0.3852  decode.d7.loss_mask: 0.3657  decode.d7.loss_dice: 0.3617  decode.d8.loss_cls: 0.4572  decode.d8.loss_mask: 0.3416  decode.d8.loss_dice: 0.3662
07/30 17:58:19 - mmengine - INFO - Iter(train) [10750/80000]  base_lr: 8.7822e-05 lr: 8.7822e-06  eta: 8:22:44  time: 0.4341  data_time: 0.0089  memory: 5227  grad_norm: 160.9644  loss: 11.3013  decode.loss_cls: 0.2846  decode.loss_mask: 0.3014  decode.loss_dice: 0.4198  decode.d0.loss_cls: 1.2051  decode.d0.loss_mask: 0.3159  decode.d0.loss_dice: 0.4873  decode.d1.loss_cls: 0.3796  decode.d1.loss_mask: 0.3036  decode.d1.loss_dice: 0.4268  decode.d2.loss_cls: 0.3105  decode.d2.loss_mask: 0.2948  decode.d2.loss_dice: 0.4112  decode.d3.loss_cls: 0.3255  decode.d3.loss_mask: 0.2850  decode.d3.loss_dice: 0.3848  decode.d4.loss_cls: 0.2360  decode.d4.loss_mask: 0.3006  decode.d4.loss_dice: 0.4083  decode.d5.loss_cls: 0.3776  decode.d5.loss_mask: 0.3000  decode.d5.loss_dice: 0.4161  decode.d6.loss_cls: 0.2457  decode.d6.loss_mask: 0.2995  decode.d6.loss_dice: 0.4117  decode.d7.loss_cls: 0.3997  decode.d7.loss_mask: 0.3035  decode.d7.loss_dice: 0.4208  decode.d8.loss_cls: 0.3088  decode.d8.loss_mask: 0.3062  decode.d8.loss_dice: 0.4310
07/30 17:58:41 - mmengine - INFO - Iter(train) [10800/80000]  base_lr: 8.7765e-05 lr: 8.7765e-06  eta: 8:22:22  time: 0.4345  data_time: 0.0089  memory: 5246  grad_norm: 146.1147  loss: 10.6846  decode.loss_cls: 0.3411  decode.loss_mask: 0.2500  decode.loss_dice: 0.3520  decode.d0.loss_cls: 1.1916  decode.d0.loss_mask: 0.2592  decode.d0.loss_dice: 0.3880  decode.d1.loss_cls: 0.5038  decode.d1.loss_mask: 0.2541  decode.d1.loss_dice: 0.3415  decode.d2.loss_cls: 0.4166  decode.d2.loss_mask: 0.2534  decode.d2.loss_dice: 0.3659  decode.d3.loss_cls: 0.3659  decode.d3.loss_mask: 0.2541  decode.d3.loss_dice: 0.3487  decode.d4.loss_cls: 0.2946  decode.d4.loss_mask: 0.2477  decode.d4.loss_dice: 0.3625  decode.d5.loss_cls: 0.3919  decode.d5.loss_mask: 0.2526  decode.d5.loss_dice: 0.3486  decode.d6.loss_cls: 0.3693  decode.d6.loss_mask: 0.2495  decode.d6.loss_dice: 0.3536  decode.d7.loss_cls: 0.3502  decode.d7.loss_mask: 0.2542  decode.d7.loss_dice: 0.3638  decode.d8.loss_cls: 0.3362  decode.d8.loss_mask: 0.2544  decode.d8.loss_dice: 0.3694
07/30 17:59:02 - mmengine - INFO - Iter(train) [10850/80000]  base_lr: 8.7708e-05 lr: 8.7708e-06  eta: 8:21:59  time: 0.4339  data_time: 0.0087  memory: 5245  grad_norm: 112.6090  loss: 10.8915  decode.loss_cls: 0.3858  decode.loss_mask: 0.2335  decode.loss_dice: 0.3428  decode.d0.loss_cls: 1.3376  decode.d0.loss_mask: 0.2562  decode.d0.loss_dice: 0.3737  decode.d1.loss_cls: 0.6239  decode.d1.loss_mask: 0.2273  decode.d1.loss_dice: 0.3312  decode.d2.loss_cls: 0.4528  decode.d2.loss_mask: 0.2315  decode.d2.loss_dice: 0.3321  decode.d3.loss_cls: 0.3921  decode.d3.loss_mask: 0.2281  decode.d3.loss_dice: 0.3269  decode.d4.loss_cls: 0.3894  decode.d4.loss_mask: 0.2340  decode.d4.loss_dice: 0.3322  decode.d5.loss_cls: 0.4149  decode.d5.loss_mask: 0.2302  decode.d5.loss_dice: 0.3240  decode.d6.loss_cls: 0.4019  decode.d6.loss_mask: 0.2303  decode.d6.loss_dice: 0.3478  decode.d7.loss_cls: 0.3328  decode.d7.loss_mask: 0.2334  decode.d7.loss_dice: 0.3484  decode.d8.loss_cls: 0.4496  decode.d8.loss_mask: 0.2328  decode.d8.loss_dice: 0.3141
07/30 17:59:24 - mmengine - INFO - Iter(train) [10900/80000]  base_lr: 8.7650e-05 lr: 8.7650e-06  eta: 8:21:37  time: 0.4326  data_time: 0.0088  memory: 5265  grad_norm: 92.6751  loss: 12.0406  decode.loss_cls: 0.3518  decode.loss_mask: 0.3281  decode.loss_dice: 0.4322  decode.d0.loss_cls: 1.0875  decode.d0.loss_mask: 0.3229  decode.d0.loss_dice: 0.4578  decode.d1.loss_cls: 0.4429  decode.d1.loss_mask: 0.3196  decode.d1.loss_dice: 0.4368  decode.d2.loss_cls: 0.3854  decode.d2.loss_mask: 0.3259  decode.d2.loss_dice: 0.4221  decode.d3.loss_cls: 0.3795  decode.d3.loss_mask: 0.3067  decode.d3.loss_dice: 0.4315  decode.d4.loss_cls: 0.3519  decode.d4.loss_mask: 0.3089  decode.d4.loss_dice: 0.4477  decode.d5.loss_cls: 0.3582  decode.d5.loss_mask: 0.3477  decode.d5.loss_dice: 0.4669  decode.d6.loss_cls: 0.3840  decode.d6.loss_mask: 0.3243  decode.d6.loss_dice: 0.4399  decode.d7.loss_cls: 0.3454  decode.d7.loss_mask: 0.3297  decode.d7.loss_dice: 0.4433  decode.d8.loss_cls: 0.3034  decode.d8.loss_mask: 0.3304  decode.d8.loss_dice: 0.4283
07/30 17:59:46 - mmengine - INFO - Iter(train) [10950/80000]  base_lr: 8.7593e-05 lr: 8.7593e-06  eta: 8:21:15  time: 0.4353  data_time: 0.0088  memory: 5265  grad_norm: 106.7709  loss: 10.2416  decode.loss_cls: 0.3099  decode.loss_mask: 0.2707  decode.loss_dice: 0.3522  decode.d0.loss_cls: 1.2737  decode.d0.loss_mask: 0.2522  decode.d0.loss_dice: 0.4220  decode.d1.loss_cls: 0.3866  decode.d1.loss_mask: 0.2433  decode.d1.loss_dice: 0.3726  decode.d2.loss_cls: 0.3202  decode.d2.loss_mask: 0.2402  decode.d2.loss_dice: 0.3307  decode.d3.loss_cls: 0.2832  decode.d3.loss_mask: 0.2405  decode.d3.loss_dice: 0.3463  decode.d4.loss_cls: 0.2851  decode.d4.loss_mask: 0.2419  decode.d4.loss_dice: 0.3460  decode.d5.loss_cls: 0.2849  decode.d5.loss_mask: 0.2397  decode.d5.loss_dice: 0.3589  decode.d6.loss_cls: 0.2807  decode.d6.loss_mask: 0.2517  decode.d6.loss_dice: 0.3787  decode.d7.loss_cls: 0.2753  decode.d7.loss_mask: 0.2737  decode.d7.loss_dice: 0.3879  decode.d8.loss_cls: 0.3367  decode.d8.loss_mask: 0.2771  decode.d8.loss_dice: 0.3788
07/30 18:00:07 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 18:00:07 - mmengine - INFO - Iter(train) [11000/80000]  base_lr: 8.7536e-05 lr: 8.7536e-06  eta: 8:20:53  time: 0.4340  data_time: 0.0088  memory: 5245  grad_norm: 68.7762  loss: 9.5014  decode.loss_cls: 0.3310  decode.loss_mask: 0.2447  decode.loss_dice: 0.2935  decode.d0.loss_cls: 1.3187  decode.d0.loss_mask: 0.2692  decode.d0.loss_dice: 0.3075  decode.d1.loss_cls: 0.4174  decode.d1.loss_mask: 0.2364  decode.d1.loss_dice: 0.2924  decode.d2.loss_cls: 0.2943  decode.d2.loss_mask: 0.2307  decode.d2.loss_dice: 0.2954  decode.d3.loss_cls: 0.2849  decode.d3.loss_mask: 0.2344  decode.d3.loss_dice: 0.3083  decode.d4.loss_cls: 0.2920  decode.d4.loss_mask: 0.2388  decode.d4.loss_dice: 0.2989  decode.d5.loss_cls: 0.2745  decode.d5.loss_mask: 0.2381  decode.d5.loss_dice: 0.2949  decode.d6.loss_cls: 0.2738  decode.d6.loss_mask: 0.2375  decode.d6.loss_dice: 0.3054  decode.d7.loss_cls: 0.2986  decode.d7.loss_mask: 0.2425  decode.d7.loss_dice: 0.3004  decode.d8.loss_cls: 0.3014  decode.d8.loss_mask: 0.2384  decode.d8.loss_dice: 0.3072
07/30 18:00:29 - mmengine - INFO - Iter(train) [11050/80000]  base_lr: 8.7479e-05 lr: 8.7479e-06  eta: 8:20:31  time: 0.4337  data_time: 0.0087  memory: 5265  grad_norm: 61.7549  loss: 8.4927  decode.loss_cls: 0.2153  decode.loss_mask: 0.2477  decode.loss_dice: 0.2819  decode.d0.loss_cls: 1.0168  decode.d0.loss_mask: 0.2633  decode.d0.loss_dice: 0.2878  decode.d1.loss_cls: 0.3308  decode.d1.loss_mask: 0.2512  decode.d1.loss_dice: 0.2703  decode.d2.loss_cls: 0.1579  decode.d2.loss_mask: 0.2475  decode.d2.loss_dice: 0.2716  decode.d3.loss_cls: 0.2466  decode.d3.loss_mask: 0.2438  decode.d3.loss_dice: 0.2717  decode.d4.loss_cls: 0.2743  decode.d4.loss_mask: 0.2428  decode.d4.loss_dice: 0.2636  decode.d5.loss_cls: 0.2636  decode.d5.loss_mask: 0.2432  decode.d5.loss_dice: 0.2799  decode.d6.loss_cls: 0.2406  decode.d6.loss_mask: 0.2497  decode.d6.loss_dice: 0.2657  decode.d7.loss_cls: 0.2547  decode.d7.loss_mask: 0.2480  decode.d7.loss_dice: 0.2681  decode.d8.loss_cls: 0.2710  decode.d8.loss_mask: 0.2453  decode.d8.loss_dice: 0.2779
07/30 18:00:51 - mmengine - INFO - Iter(train) [11100/80000]  base_lr: 8.7422e-05 lr: 8.7422e-06  eta: 8:20:09  time: 0.4365  data_time: 0.0090  memory: 5279  grad_norm: 74.0809  loss: 7.8810  decode.loss_cls: 0.2184  decode.loss_mask: 0.2388  decode.loss_dice: 0.2373  decode.d0.loss_cls: 1.0548  decode.d0.loss_mask: 0.2497  decode.d0.loss_dice: 0.2436  decode.d1.loss_cls: 0.2930  decode.d1.loss_mask: 0.2397  decode.d1.loss_dice: 0.2406  decode.d2.loss_cls: 0.2084  decode.d2.loss_mask: 0.2419  decode.d2.loss_dice: 0.2635  decode.d3.loss_cls: 0.2219  decode.d3.loss_mask: 0.2382  decode.d3.loss_dice: 0.2432  decode.d4.loss_cls: 0.2027  decode.d4.loss_mask: 0.2374  decode.d4.loss_dice: 0.2438  decode.d5.loss_cls: 0.2207  decode.d5.loss_mask: 0.2343  decode.d5.loss_dice: 0.2421  decode.d6.loss_cls: 0.2227  decode.d6.loss_mask: 0.2360  decode.d6.loss_dice: 0.2442  decode.d7.loss_cls: 0.2011  decode.d7.loss_mask: 0.2401  decode.d7.loss_dice: 0.2383  decode.d8.loss_cls: 0.2073  decode.d8.loss_mask: 0.2384  decode.d8.loss_dice: 0.2390
07/30 18:01:13 - mmengine - INFO - Iter(train) [11150/80000]  base_lr: 8.7365e-05 lr: 8.7365e-06  eta: 8:19:47  time: 0.4343  data_time: 0.0089  memory: 5229  grad_norm: 86.6669  loss: 10.2988  decode.loss_cls: 0.3088  decode.loss_mask: 0.3373  decode.loss_dice: 0.2992  decode.d0.loss_cls: 1.1422  decode.d0.loss_mask: 0.3475  decode.d0.loss_dice: 0.3276  decode.d1.loss_cls: 0.3735  decode.d1.loss_mask: 0.3195  decode.d1.loss_dice: 0.2852  decode.d2.loss_cls: 0.2901  decode.d2.loss_mask: 0.3272  decode.d2.loss_dice: 0.3015  decode.d3.loss_cls: 0.3513  decode.d3.loss_mask: 0.3232  decode.d3.loss_dice: 0.2915  decode.d4.loss_cls: 0.3072  decode.d4.loss_mask: 0.3332  decode.d4.loss_dice: 0.2918  decode.d5.loss_cls: 0.3098  decode.d5.loss_mask: 0.3321  decode.d5.loss_dice: 0.2896  decode.d6.loss_cls: 0.2951  decode.d6.loss_mask: 0.3294  decode.d6.loss_dice: 0.2975  decode.d7.loss_cls: 0.3309  decode.d7.loss_mask: 0.3341  decode.d7.loss_dice: 0.3024  decode.d8.loss_cls: 0.2934  decode.d8.loss_mask: 0.3300  decode.d8.loss_dice: 0.2966
07/30 18:01:34 - mmengine - INFO - Iter(train) [11200/80000]  base_lr: 8.7308e-05 lr: 8.7308e-06  eta: 8:19:25  time: 0.4344  data_time: 0.0090  memory: 5245  grad_norm: 87.7481  loss: 11.7541  decode.loss_cls: 0.2413  decode.loss_mask: 0.4413  decode.loss_dice: 0.3925  decode.d0.loss_cls: 1.0248  decode.d0.loss_mask: 0.4508  decode.d0.loss_dice: 0.4333  decode.d1.loss_cls: 0.3014  decode.d1.loss_mask: 0.4351  decode.d1.loss_dice: 0.3982  decode.d2.loss_cls: 0.2602  decode.d2.loss_mask: 0.4334  decode.d2.loss_dice: 0.3790  decode.d3.loss_cls: 0.2569  decode.d3.loss_mask: 0.4534  decode.d3.loss_dice: 0.4162  decode.d4.loss_cls: 0.2849  decode.d4.loss_mask: 0.4700  decode.d4.loss_dice: 0.3989  decode.d5.loss_cls: 0.2596  decode.d5.loss_mask: 0.4402  decode.d5.loss_dice: 0.3850  decode.d6.loss_cls: 0.2689  decode.d6.loss_mask: 0.4447  decode.d6.loss_dice: 0.3771  decode.d7.loss_cls: 0.2461  decode.d7.loss_mask: 0.4315  decode.d7.loss_dice: 0.3774  decode.d8.loss_cls: 0.2474  decode.d8.loss_mask: 0.4331  decode.d8.loss_dice: 0.3716
07/30 18:01:56 - mmengine - INFO - Iter(train) [11250/80000]  base_lr: 8.7251e-05 lr: 8.7251e-06  eta: 8:19:03  time: 0.4363  data_time: 0.0090  memory: 5261  grad_norm: 139.0850  loss: 10.5944  decode.loss_cls: 0.3851  decode.loss_mask: 0.2710  decode.loss_dice: 0.3445  decode.d0.loss_cls: 1.0854  decode.d0.loss_mask: 0.2811  decode.d0.loss_dice: 0.3461  decode.d1.loss_cls: 0.3673  decode.d1.loss_mask: 0.2741  decode.d1.loss_dice: 0.3360  decode.d2.loss_cls: 0.4059  decode.d2.loss_mask: 0.2747  decode.d2.loss_dice: 0.3198  decode.d3.loss_cls: 0.3639  decode.d3.loss_mask: 0.2736  decode.d3.loss_dice: 0.3323  decode.d4.loss_cls: 0.3456  decode.d4.loss_mask: 0.2711  decode.d4.loss_dice: 0.3393  decode.d5.loss_cls: 0.3555  decode.d5.loss_mask: 0.2749  decode.d5.loss_dice: 0.3401  decode.d6.loss_cls: 0.3860  decode.d6.loss_mask: 0.2722  decode.d6.loss_dice: 0.3245  decode.d7.loss_cls: 0.4373  decode.d7.loss_mask: 0.2748  decode.d7.loss_dice: 0.3446  decode.d8.loss_cls: 0.3513  decode.d8.loss_mask: 0.2754  decode.d8.loss_dice: 0.3411
07/30 18:02:18 - mmengine - INFO - Iter(train) [11300/80000]  base_lr: 8.7194e-05 lr: 8.7194e-06  eta: 8:18:41  time: 0.4363  data_time: 0.0093  memory: 5277  grad_norm: 92.6185  loss: 9.8955  decode.loss_cls: 0.2968  decode.loss_mask: 0.2535  decode.loss_dice: 0.3275  decode.d0.loss_cls: 1.1620  decode.d0.loss_mask: 0.2726  decode.d0.loss_dice: 0.3912  decode.d1.loss_cls: 0.4408  decode.d1.loss_mask: 0.2493  decode.d1.loss_dice: 0.3485  decode.d2.loss_cls: 0.3524  decode.d2.loss_mask: 0.2586  decode.d2.loss_dice: 0.3527  decode.d3.loss_cls: 0.2549  decode.d3.loss_mask: 0.2509  decode.d3.loss_dice: 0.3391  decode.d4.loss_cls: 0.2979  decode.d4.loss_mask: 0.2487  decode.d4.loss_dice: 0.3359  decode.d5.loss_cls: 0.2735  decode.d5.loss_mask: 0.2546  decode.d5.loss_dice: 0.3594  decode.d6.loss_cls: 0.2564  decode.d6.loss_mask: 0.2524  decode.d6.loss_dice: 0.3399  decode.d7.loss_cls: 0.2622  decode.d7.loss_mask: 0.2517  decode.d7.loss_dice: 0.3467  decode.d8.loss_cls: 0.2830  decode.d8.loss_mask: 0.2542  decode.d8.loss_dice: 0.3283
07/30 18:02:40 - mmengine - INFO - Iter(train) [11350/80000]  base_lr: 8.7137e-05 lr: 8.7137e-06  eta: 8:18:20  time: 0.4364  data_time: 0.0092  memory: 5261  grad_norm: 132.4915  loss: 14.2645  decode.loss_cls: 0.5510  decode.loss_mask: 0.3072  decode.loss_dice: 0.3466  decode.d0.loss_cls: 1.4118  decode.d0.loss_mask: 0.3305  decode.d0.loss_dice: 0.4193  decode.d1.loss_cls: 0.8091  decode.d1.loss_mask: 0.3278  decode.d1.loss_dice: 0.4111  decode.d2.loss_cls: 0.6480  decode.d2.loss_mask: 0.3741  decode.d2.loss_dice: 0.4097  decode.d3.loss_cls: 0.7160  decode.d3.loss_mask: 0.3354  decode.d3.loss_dice: 0.3994  decode.d4.loss_cls: 0.6614  decode.d4.loss_mask: 0.3108  decode.d4.loss_dice: 0.3943  decode.d5.loss_cls: 0.6023  decode.d5.loss_mask: 0.3293  decode.d5.loss_dice: 0.4022  decode.d6.loss_cls: 0.5905  decode.d6.loss_mask: 0.3162  decode.d6.loss_dice: 0.3529  decode.d7.loss_cls: 0.6074  decode.d7.loss_mask: 0.3126  decode.d7.loss_dice: 0.3719  decode.d8.loss_cls: 0.5717  decode.d8.loss_mask: 0.3097  decode.d8.loss_dice: 0.3343
07/30 18:03:02 - mmengine - INFO - Iter(train) [11400/80000]  base_lr: 8.7079e-05 lr: 8.7079e-06  eta: 8:17:58  time: 0.4354  data_time: 0.0090  memory: 5261  grad_norm: 137.1746  loss: 12.9792  decode.loss_cls: 0.4150  decode.loss_mask: 0.4192  decode.loss_dice: 0.3767  decode.d0.loss_cls: 1.2958  decode.d0.loss_mask: 0.3769  decode.d0.loss_dice: 0.4102  decode.d1.loss_cls: 0.4672  decode.d1.loss_mask: 0.3374  decode.d1.loss_dice: 0.3800  decode.d2.loss_cls: 0.4895  decode.d2.loss_mask: 0.3192  decode.d2.loss_dice: 0.3370  decode.d3.loss_cls: 0.4649  decode.d3.loss_mask: 0.3749  decode.d3.loss_dice: 0.3541  decode.d4.loss_cls: 0.5260  decode.d4.loss_mask: 0.3190  decode.d4.loss_dice: 0.3384  decode.d5.loss_cls: 0.5504  decode.d5.loss_mask: 0.3961  decode.d5.loss_dice: 0.3531  decode.d6.loss_cls: 0.4864  decode.d6.loss_mask: 0.4227  decode.d6.loss_dice: 0.3643  decode.d7.loss_cls: 0.4951  decode.d7.loss_mask: 0.3845  decode.d7.loss_dice: 0.3533  decode.d8.loss_cls: 0.4215  decode.d8.loss_mask: 0.3954  decode.d8.loss_dice: 0.3549
07/30 18:03:23 - mmengine - INFO - Iter(train) [11450/80000]  base_lr: 8.7022e-05 lr: 8.7022e-06  eta: 8:17:36  time: 0.4372  data_time: 0.0089  memory: 5265  grad_norm: 130.8866  loss: 8.4140  decode.loss_cls: 0.2564  decode.loss_mask: 0.2340  decode.loss_dice: 0.2436  decode.d0.loss_cls: 1.0988  decode.d0.loss_mask: 0.2576  decode.d0.loss_dice: 0.2788  decode.d1.loss_cls: 0.3305  decode.d1.loss_mask: 0.2514  decode.d1.loss_dice: 0.2571  decode.d2.loss_cls: 0.2494  decode.d2.loss_mask: 0.2448  decode.d2.loss_dice: 0.2520  decode.d3.loss_cls: 0.2353  decode.d3.loss_mask: 0.2290  decode.d3.loss_dice: 0.2525  decode.d4.loss_cls: 0.2556  decode.d4.loss_mask: 0.2334  decode.d4.loss_dice: 0.2417  decode.d5.loss_cls: 0.3283  decode.d5.loss_mask: 0.2177  decode.d5.loss_dice: 0.2352  decode.d6.loss_cls: 0.2756  decode.d6.loss_mask: 0.2343  decode.d6.loss_dice: 0.2415  decode.d7.loss_cls: 0.2472  decode.d7.loss_mask: 0.2418  decode.d7.loss_dice: 0.2295  decode.d8.loss_cls: 0.2783  decode.d8.loss_mask: 0.2441  decode.d8.loss_dice: 0.2388
07/30 18:03:45 - mmengine - INFO - Iter(train) [11500/80000]  base_lr: 8.6965e-05 lr: 8.6965e-06  eta: 8:17:15  time: 0.4353  data_time: 0.0089  memory: 5246  grad_norm: 126.6415  loss: 10.9760  decode.loss_cls: 0.4371  decode.loss_mask: 0.2720  decode.loss_dice: 0.3118  decode.d0.loss_cls: 1.1130  decode.d0.loss_mask: 0.2902  decode.d0.loss_dice: 0.3274  decode.d1.loss_cls: 0.5132  decode.d1.loss_mask: 0.2672  decode.d1.loss_dice: 0.2873  decode.d2.loss_cls: 0.3839  decode.d2.loss_mask: 0.2708  decode.d2.loss_dice: 0.3283  decode.d3.loss_cls: 0.4102  decode.d3.loss_mask: 0.2742  decode.d3.loss_dice: 0.3170  decode.d4.loss_cls: 0.4234  decode.d4.loss_mask: 0.2759  decode.d4.loss_dice: 0.3318  decode.d5.loss_cls: 0.3710  decode.d5.loss_mask: 0.2932  decode.d5.loss_dice: 0.3381  decode.d6.loss_cls: 0.4503  decode.d6.loss_mask: 0.2751  decode.d6.loss_dice: 0.3460  decode.d7.loss_cls: 0.4434  decode.d7.loss_mask: 0.2746  decode.d7.loss_dice: 0.3141  decode.d8.loss_cls: 0.4569  decode.d8.loss_mask: 0.2713  decode.d8.loss_dice: 0.3074
07/30 18:04:07 - mmengine - INFO - Iter(train) [11550/80000]  base_lr: 8.6908e-05 lr: 8.6908e-06  eta: 8:16:53  time: 0.4352  data_time: 0.0088  memory: 5305  grad_norm: 168.2895  loss: 10.9455  decode.loss_cls: 0.3523  decode.loss_mask: 0.2947  decode.loss_dice: 0.3473  decode.d0.loss_cls: 1.3328  decode.d0.loss_mask: 0.3284  decode.d0.loss_dice: 0.3883  decode.d1.loss_cls: 0.4741  decode.d1.loss_mask: 0.3140  decode.d1.loss_dice: 0.3637  decode.d2.loss_cls: 0.3744  decode.d2.loss_mask: 0.2985  decode.d2.loss_dice: 0.3321  decode.d3.loss_cls: 0.2654  decode.d3.loss_mask: 0.2866  decode.d3.loss_dice: 0.3344  decode.d4.loss_cls: 0.3159  decode.d4.loss_mask: 0.3035  decode.d4.loss_dice: 0.3614  decode.d5.loss_cls: 0.3302  decode.d5.loss_mask: 0.3115  decode.d5.loss_dice: 0.3453  decode.d6.loss_cls: 0.3378  decode.d6.loss_mask: 0.2915  decode.d6.loss_dice: 0.3292  decode.d7.loss_cls: 0.3641  decode.d7.loss_mask: 0.2963  decode.d7.loss_dice: 0.3357  decode.d8.loss_cls: 0.3099  decode.d8.loss_mask: 0.2890  decode.d8.loss_dice: 0.3372
07/30 18:04:29 - mmengine - INFO - Iter(train) [11600/80000]  base_lr: 8.6851e-05 lr: 8.6851e-06  eta: 8:16:31  time: 0.4361  data_time: 0.0088  memory: 5322  grad_norm: 121.0517  loss: 10.9936  decode.loss_cls: 0.3480  decode.loss_mask: 0.2439  decode.loss_dice: 0.3659  decode.d0.loss_cls: 1.3721  decode.d0.loss_mask: 0.2540  decode.d0.loss_dice: 0.3791  decode.d1.loss_cls: 0.5254  decode.d1.loss_mask: 0.2599  decode.d1.loss_dice: 0.3954  decode.d2.loss_cls: 0.4574  decode.d2.loss_mask: 0.2587  decode.d2.loss_dice: 0.3818  decode.d3.loss_cls: 0.3758  decode.d3.loss_mask: 0.2482  decode.d3.loss_dice: 0.3442  decode.d4.loss_cls: 0.2948  decode.d4.loss_mask: 0.2550  decode.d4.loss_dice: 0.3582  decode.d5.loss_cls: 0.3414  decode.d5.loss_mask: 0.2397  decode.d5.loss_dice: 0.3769  decode.d6.loss_cls: 0.3469  decode.d6.loss_mask: 0.2467  decode.d6.loss_dice: 0.3746  decode.d7.loss_cls: 0.3520  decode.d7.loss_mask: 0.2418  decode.d7.loss_dice: 0.3686  decode.d8.loss_cls: 0.3797  decode.d8.loss_mask: 0.2491  decode.d8.loss_dice: 0.3581
07/30 18:04:51 - mmengine - INFO - Iter(train) [11650/80000]  base_lr: 8.6794e-05 lr: 8.6794e-06  eta: 8:16:10  time: 0.4369  data_time: 0.0089  memory: 5279  grad_norm: 301.0868  loss: 12.8768  decode.loss_cls: 0.5901  decode.loss_mask: 0.3145  decode.loss_dice: 0.3814  decode.d0.loss_cls: 1.3290  decode.d0.loss_mask: 0.2990  decode.d0.loss_dice: 0.3973  decode.d1.loss_cls: 0.6298  decode.d1.loss_mask: 0.3008  decode.d1.loss_dice: 0.3777  decode.d2.loss_cls: 0.6007  decode.d2.loss_mask: 0.2922  decode.d2.loss_dice: 0.3303  decode.d3.loss_cls: 0.5007  decode.d3.loss_mask: 0.3037  decode.d3.loss_dice: 0.3814  decode.d4.loss_cls: 0.4735  decode.d4.loss_mask: 0.3047  decode.d4.loss_dice: 0.3770  decode.d5.loss_cls: 0.5121  decode.d5.loss_mask: 0.3076  decode.d5.loss_dice: 0.3959  decode.d6.loss_cls: 0.4703  decode.d6.loss_mask: 0.2978  decode.d6.loss_dice: 0.3949  decode.d7.loss_cls: 0.4846  decode.d7.loss_mask: 0.3007  decode.d7.loss_dice: 0.3935  decode.d8.loss_cls: 0.4737  decode.d8.loss_mask: 0.2928  decode.d8.loss_dice: 0.3692
07/30 18:05:12 - mmengine - INFO - Iter(train) [11700/80000]  base_lr: 8.6737e-05 lr: 8.6737e-06  eta: 8:15:48  time: 0.4361  data_time: 0.0089  memory: 5279  grad_norm: 115.7321  loss: 9.7337  decode.loss_cls: 0.3770  decode.loss_mask: 0.2562  decode.loss_dice: 0.2814  decode.d0.loss_cls: 1.1258  decode.d0.loss_mask: 0.2612  decode.d0.loss_dice: 0.3228  decode.d1.loss_cls: 0.3497  decode.d1.loss_mask: 0.2578  decode.d1.loss_dice: 0.3154  decode.d2.loss_cls: 0.3045  decode.d2.loss_mask: 0.2608  decode.d2.loss_dice: 0.2891  decode.d3.loss_cls: 0.3414  decode.d3.loss_mask: 0.2533  decode.d3.loss_dice: 0.2861  decode.d4.loss_cls: 0.3221  decode.d4.loss_mask: 0.2531  decode.d4.loss_dice: 0.2828  decode.d5.loss_cls: 0.2988  decode.d5.loss_mask: 0.2510  decode.d5.loss_dice: 0.2773  decode.d6.loss_cls: 0.3330  decode.d6.loss_mask: 0.2596  decode.d6.loss_dice: 0.3141  decode.d7.loss_cls: 0.3836  decode.d7.loss_mask: 0.2536  decode.d7.loss_dice: 0.2871  decode.d8.loss_cls: 0.3692  decode.d8.loss_mask: 0.2670  decode.d8.loss_dice: 0.2987
07/30 18:05:34 - mmengine - INFO - Iter(train) [11750/80000]  base_lr: 8.6679e-05 lr: 8.6679e-06  eta: 8:15:27  time: 0.4362  data_time: 0.0090  memory: 5278  grad_norm: 109.4587  loss: 10.4465  decode.loss_cls: 0.2797  decode.loss_mask: 0.2885  decode.loss_dice: 0.3800  decode.d0.loss_cls: 1.2586  decode.d0.loss_mask: 0.2812  decode.d0.loss_dice: 0.4195  decode.d1.loss_cls: 0.3976  decode.d1.loss_mask: 0.2586  decode.d1.loss_dice: 0.3344  decode.d2.loss_cls: 0.3952  decode.d2.loss_mask: 0.2556  decode.d2.loss_dice: 0.3413  decode.d3.loss_cls: 0.3502  decode.d3.loss_mask: 0.2609  decode.d3.loss_dice: 0.3415  decode.d4.loss_cls: 0.3035  decode.d4.loss_mask: 0.2604  decode.d4.loss_dice: 0.3683  decode.d5.loss_cls: 0.2663  decode.d5.loss_mask: 0.2736  decode.d5.loss_dice: 0.3549  decode.d6.loss_cls: 0.3055  decode.d6.loss_mask: 0.2618  decode.d6.loss_dice: 0.3500  decode.d7.loss_cls: 0.3070  decode.d7.loss_mask: 0.2615  decode.d7.loss_dice: 0.3602  decode.d8.loss_cls: 0.3412  decode.d8.loss_mask: 0.2561  decode.d8.loss_dice: 0.3333
07/30 18:05:56 - mmengine - INFO - Iter(train) [11800/80000]  base_lr: 8.6622e-05 lr: 8.6622e-06  eta: 8:15:05  time: 0.4365  data_time: 0.0088  memory: 5245  grad_norm: 163.9075  loss: 9.2326  decode.loss_cls: 0.2026  decode.loss_mask: 0.2839  decode.loss_dice: 0.3015  decode.d0.loss_cls: 1.2106  decode.d0.loss_mask: 0.3111  decode.d0.loss_dice: 0.3539  decode.d1.loss_cls: 0.3404  decode.d1.loss_mask: 0.2907  decode.d1.loss_dice: 0.3080  decode.d2.loss_cls: 0.2535  decode.d2.loss_mask: 0.2884  decode.d2.loss_dice: 0.3108  decode.d3.loss_cls: 0.2191  decode.d3.loss_mask: 0.2888  decode.d3.loss_dice: 0.3111  decode.d4.loss_cls: 0.1986  decode.d4.loss_mask: 0.2849  decode.d4.loss_dice: 0.3037  decode.d5.loss_cls: 0.2059  decode.d5.loss_mask: 0.2902  decode.d5.loss_dice: 0.2949  decode.d6.loss_cls: 0.2088  decode.d6.loss_mask: 0.2819  decode.d6.loss_dice: 0.3029  decode.d7.loss_cls: 0.2047  decode.d7.loss_mask: 0.2834  decode.d7.loss_dice: 0.3066  decode.d8.loss_cls: 0.2013  decode.d8.loss_mask: 0.2860  decode.d8.loss_dice: 0.3045
07/30 18:06:18 - mmengine - INFO - Iter(train) [11850/80000]  base_lr: 8.6565e-05 lr: 8.6565e-06  eta: 8:14:43  time: 0.4358  data_time: 0.0087  memory: 5279  grad_norm: 90.4180  loss: 9.7931  decode.loss_cls: 0.3488  decode.loss_mask: 0.2101  decode.loss_dice: 0.2922  decode.d0.loss_cls: 1.1842  decode.d0.loss_mask: 0.2092  decode.d0.loss_dice: 0.3214  decode.d1.loss_cls: 0.5293  decode.d1.loss_mask: 0.2163  decode.d1.loss_dice: 0.3025  decode.d2.loss_cls: 0.4468  decode.d2.loss_mask: 0.2143  decode.d2.loss_dice: 0.2791  decode.d3.loss_cls: 0.3837  decode.d3.loss_mask: 0.2119  decode.d3.loss_dice: 0.2978  decode.d4.loss_cls: 0.3741  decode.d4.loss_mask: 0.2109  decode.d4.loss_dice: 0.3018  decode.d5.loss_cls: 0.4080  decode.d5.loss_mask: 0.2100  decode.d5.loss_dice: 0.2721  decode.d6.loss_cls: 0.3592  decode.d6.loss_mask: 0.2110  decode.d6.loss_dice: 0.2862  decode.d7.loss_cls: 0.3664  decode.d7.loss_mask: 0.2127  decode.d7.loss_dice: 0.2918  decode.d8.loss_cls: 0.3452  decode.d8.loss_mask: 0.2147  decode.d8.loss_dice: 0.2813
07/30 18:06:40 - mmengine - INFO - Iter(train) [11900/80000]  base_lr: 8.6508e-05 lr: 8.6508e-06  eta: 8:14:23  time: 0.4367  data_time: 0.0087  memory: 5305  grad_norm: 97.1656  loss: 9.0496  decode.loss_cls: 0.2747  decode.loss_mask: 0.1892  decode.loss_dice: 0.3136  decode.d0.loss_cls: 1.2458  decode.d0.loss_mask: 0.1950  decode.d0.loss_dice: 0.3395  decode.d1.loss_cls: 0.3551  decode.d1.loss_mask: 0.1934  decode.d1.loss_dice: 0.3334  decode.d2.loss_cls: 0.3349  decode.d2.loss_mask: 0.1827  decode.d2.loss_dice: 0.3145  decode.d3.loss_cls: 0.2840  decode.d3.loss_mask: 0.1875  decode.d3.loss_dice: 0.3196  decode.d4.loss_cls: 0.2706  decode.d4.loss_mask: 0.1899  decode.d4.loss_dice: 0.3129  decode.d5.loss_cls: 0.3158  decode.d5.loss_mask: 0.1775  decode.d5.loss_dice: 0.3162  decode.d6.loss_cls: 0.2834  decode.d6.loss_mask: 0.1803  decode.d6.loss_dice: 0.3136  decode.d7.loss_cls: 0.3254  decode.d7.loss_mask: 0.1813  decode.d7.loss_dice: 0.3170  decode.d8.loss_cls: 0.3032  decode.d8.loss_mask: 0.1863  decode.d8.loss_dice: 0.3135
07/30 18:07:02 - mmengine - INFO - Iter(train) [11950/80000]  base_lr: 8.6451e-05 lr: 8.6451e-06  eta: 8:14:01  time: 0.4360  data_time: 0.0089  memory: 5261  grad_norm: 99.2838  loss: 10.5039  decode.loss_cls: 0.3712  decode.loss_mask: 0.2291  decode.loss_dice: 0.3617  decode.d0.loss_cls: 1.1805  decode.d0.loss_mask: 0.2410  decode.d0.loss_dice: 0.3864  decode.d1.loss_cls: 0.4612  decode.d1.loss_mask: 0.2209  decode.d1.loss_dice: 0.3511  decode.d2.loss_cls: 0.3713  decode.d2.loss_mask: 0.2420  decode.d2.loss_dice: 0.3573  decode.d3.loss_cls: 0.4150  decode.d3.loss_mask: 0.2197  decode.d3.loss_dice: 0.3462  decode.d4.loss_cls: 0.3342  decode.d4.loss_mask: 0.2203  decode.d4.loss_dice: 0.3682  decode.d5.loss_cls: 0.3830  decode.d5.loss_mask: 0.2297  decode.d5.loss_dice: 0.3544  decode.d6.loss_cls: 0.3587  decode.d6.loss_mask: 0.2241  decode.d6.loss_dice: 0.3652  decode.d7.loss_cls: 0.3318  decode.d7.loss_mask: 0.2287  decode.d7.loss_dice: 0.3652  decode.d8.loss_cls: 0.3722  decode.d8.loss_mask: 0.2397  decode.d8.loss_dice: 0.3737
07/30 18:07:23 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 18:07:23 - mmengine - INFO - Iter(train) [12000/80000]  base_lr: 8.6394e-05 lr: 8.6394e-06  eta: 8:13:39  time: 0.4349  data_time: 0.0089  memory: 5246  grad_norm: 94.4528  loss: 8.7502  decode.loss_cls: 0.3739  decode.loss_mask: 0.1936  decode.loss_dice: 0.2447  decode.d0.loss_cls: 1.0575  decode.d0.loss_mask: 0.2018  decode.d0.loss_dice: 0.2936  decode.d1.loss_cls: 0.3615  decode.d1.loss_mask: 0.2026  decode.d1.loss_dice: 0.2467  decode.d2.loss_cls: 0.3227  decode.d2.loss_mask: 0.1951  decode.d2.loss_dice: 0.2482  decode.d3.loss_cls: 0.3348  decode.d3.loss_mask: 0.1918  decode.d3.loss_dice: 0.2414  decode.d4.loss_cls: 0.3657  decode.d4.loss_mask: 0.1934  decode.d4.loss_dice: 0.2445  decode.d5.loss_cls: 0.3474  decode.d5.loss_mask: 0.1933  decode.d5.loss_dice: 0.2592  decode.d6.loss_cls: 0.4056  decode.d6.loss_mask: 0.1921  decode.d6.loss_dice: 0.2569  decode.d7.loss_cls: 0.3604  decode.d7.loss_mask: 0.1934  decode.d7.loss_dice: 0.2394  decode.d8.loss_cls: 0.3570  decode.d8.loss_mask: 0.1960  decode.d8.loss_dice: 0.2359
07/30 18:07:45 - mmengine - INFO - Iter(train) [12050/80000]  base_lr: 8.6336e-05 lr: 8.6336e-06  eta: 8:13:17  time: 0.4356  data_time: 0.0089  memory: 5278  grad_norm: 83.0320  loss: 8.0705  decode.loss_cls: 0.1524  decode.loss_mask: 0.2718  decode.loss_dice: 0.2718  decode.d0.loss_cls: 1.0452  decode.d0.loss_mask: 0.2966  decode.d0.loss_dice: 0.3021  decode.d1.loss_cls: 0.2190  decode.d1.loss_mask: 0.2926  decode.d1.loss_dice: 0.2911  decode.d2.loss_cls: 0.1780  decode.d2.loss_mask: 0.2836  decode.d2.loss_dice: 0.2815  decode.d3.loss_cls: 0.1589  decode.d3.loss_mask: 0.2755  decode.d3.loss_dice: 0.2698  decode.d4.loss_cls: 0.1327  decode.d4.loss_mask: 0.2808  decode.d4.loss_dice: 0.2692  decode.d5.loss_cls: 0.1459  decode.d5.loss_mask: 0.2793  decode.d5.loss_dice: 0.2662  decode.d6.loss_cls: 0.1609  decode.d6.loss_mask: 0.2763  decode.d6.loss_dice: 0.2738  decode.d7.loss_cls: 0.1552  decode.d7.loss_mask: 0.2784  decode.d7.loss_dice: 0.2733  decode.d8.loss_cls: 0.1417  decode.d8.loss_mask: 0.2772  decode.d8.loss_dice: 0.2697
07/30 18:08:07 - mmengine - INFO - Iter(train) [12100/80000]  base_lr: 8.6279e-05 lr: 8.6279e-06  eta: 8:12:56  time: 0.4364  data_time: 0.0089  memory: 5322  grad_norm: 124.0849  loss: 10.1504  decode.loss_cls: 0.4087  decode.loss_mask: 0.2248  decode.loss_dice: 0.3074  decode.d0.loss_cls: 1.0890  decode.d0.loss_mask: 0.2484  decode.d0.loss_dice: 0.3659  decode.d1.loss_cls: 0.4341  decode.d1.loss_mask: 0.2335  decode.d1.loss_dice: 0.3352  decode.d2.loss_cls: 0.3764  decode.d2.loss_mask: 0.2290  decode.d2.loss_dice: 0.3455  decode.d3.loss_cls: 0.3116  decode.d3.loss_mask: 0.2330  decode.d3.loss_dice: 0.3412  decode.d4.loss_cls: 0.3771  decode.d4.loss_mask: 0.2360  decode.d4.loss_dice: 0.3602  decode.d5.loss_cls: 0.3442  decode.d5.loss_mask: 0.2285  decode.d5.loss_dice: 0.3289  decode.d6.loss_cls: 0.3045  decode.d6.loss_mask: 0.2271  decode.d6.loss_dice: 0.3405  decode.d7.loss_cls: 0.3666  decode.d7.loss_mask: 0.2361  decode.d7.loss_dice: 0.3434  decode.d8.loss_cls: 0.3882  decode.d8.loss_mask: 0.2354  decode.d8.loss_dice: 0.3498
07/30 18:08:29 - mmengine - INFO - Iter(train) [12150/80000]  base_lr: 8.6222e-05 lr: 8.6222e-06  eta: 8:12:34  time: 0.4355  data_time: 0.0089  memory: 5279  grad_norm: 190.0357  loss: 11.2320  decode.loss_cls: 0.3221  decode.loss_mask: 0.4856  decode.loss_dice: 0.3177  decode.d0.loss_cls: 1.1252  decode.d0.loss_mask: 0.4872  decode.d0.loss_dice: 0.3204  decode.d1.loss_cls: 0.4263  decode.d1.loss_mask: 0.4010  decode.d1.loss_dice: 0.3005  decode.d2.loss_cls: 0.3514  decode.d2.loss_mask: 0.4642  decode.d2.loss_dice: 0.3136  decode.d3.loss_cls: 0.2822  decode.d3.loss_mask: 0.3804  decode.d3.loss_dice: 0.2930  decode.d4.loss_cls: 0.2824  decode.d4.loss_mask: 0.3719  decode.d4.loss_dice: 0.2842  decode.d5.loss_cls: 0.2848  decode.d5.loss_mask: 0.3841  decode.d5.loss_dice: 0.2826  decode.d6.loss_cls: 0.3184  decode.d6.loss_mask: 0.3883  decode.d6.loss_dice: 0.2893  decode.d7.loss_cls: 0.3130  decode.d7.loss_mask: 0.3912  decode.d7.loss_dice: 0.2851  decode.d8.loss_cls: 0.3178  decode.d8.loss_mask: 0.4649  decode.d8.loss_dice: 0.3033
07/30 18:08:51 - mmengine - INFO - Iter(train) [12200/80000]  base_lr: 8.6165e-05 lr: 8.6165e-06  eta: 8:12:12  time: 0.4360  data_time: 0.0088  memory: 5265  grad_norm: 110.3433  loss: 8.7892  decode.loss_cls: 0.1703  decode.loss_mask: 0.2878  decode.loss_dice: 0.2957  decode.d0.loss_cls: 1.1364  decode.d0.loss_mask: 0.3296  decode.d0.loss_dice: 0.3300  decode.d1.loss_cls: 0.3148  decode.d1.loss_mask: 0.3066  decode.d1.loss_dice: 0.3025  decode.d2.loss_cls: 0.2100  decode.d2.loss_mask: 0.2922  decode.d2.loss_dice: 0.3005  decode.d3.loss_cls: 0.1970  decode.d3.loss_mask: 0.2928  decode.d3.loss_dice: 0.2792  decode.d4.loss_cls: 0.1644  decode.d4.loss_mask: 0.2938  decode.d4.loss_dice: 0.2875  decode.d5.loss_cls: 0.1475  decode.d5.loss_mask: 0.2932  decode.d5.loss_dice: 0.2971  decode.d6.loss_cls: 0.1656  decode.d6.loss_mask: 0.2854  decode.d6.loss_dice: 0.2872  decode.d7.loss_cls: 0.1914  decode.d7.loss_mask: 0.2871  decode.d7.loss_dice: 0.2911  decode.d8.loss_cls: 0.1750  decode.d8.loss_mask: 0.2866  decode.d8.loss_dice: 0.2908
07/30 18:09:12 - mmengine - INFO - Iter(train) [12250/80000]  base_lr: 8.6108e-05 lr: 8.6108e-06  eta: 8:11:51  time: 0.4358  data_time: 0.0089  memory: 5279  grad_norm: 109.3336  loss: 11.4439  decode.loss_cls: 0.2943  decode.loss_mask: 0.2719  decode.loss_dice: 0.4486  decode.d0.loss_cls: 1.3442  decode.d0.loss_mask: 0.2813  decode.d0.loss_dice: 0.4622  decode.d1.loss_cls: 0.4284  decode.d1.loss_mask: 0.2736  decode.d1.loss_dice: 0.4410  decode.d2.loss_cls: 0.3903  decode.d2.loss_mask: 0.2745  decode.d2.loss_dice: 0.4390  decode.d3.loss_cls: 0.3180  decode.d3.loss_mask: 0.2673  decode.d3.loss_dice: 0.4513  decode.d4.loss_cls: 0.3024  decode.d4.loss_mask: 0.2696  decode.d4.loss_dice: 0.4320  decode.d5.loss_cls: 0.3396  decode.d5.loss_mask: 0.2733  decode.d5.loss_dice: 0.4436  decode.d6.loss_cls: 0.2757  decode.d6.loss_mask: 0.2649  decode.d6.loss_dice: 0.4290  decode.d7.loss_cls: 0.3145  decode.d7.loss_mask: 0.2707  decode.d7.loss_dice: 0.4285  decode.d8.loss_cls: 0.3136  decode.d8.loss_mask: 0.2707  decode.d8.loss_dice: 0.4296
07/30 18:09:34 - mmengine - INFO - Iter(train) [12300/80000]  base_lr: 8.6051e-05 lr: 8.6051e-06  eta: 8:11:29  time: 0.4368  data_time: 0.0089  memory: 5261  grad_norm: 140.4795  loss: 9.8941  decode.loss_cls: 0.2297  decode.loss_mask: 0.3286  decode.loss_dice: 0.3376  decode.d0.loss_cls: 1.2360  decode.d0.loss_mask: 0.3196  decode.d0.loss_dice: 0.3301  decode.d1.loss_cls: 0.2118  decode.d1.loss_mask: 0.3059  decode.d1.loss_dice: 0.3117  decode.d2.loss_cls: 0.2399  decode.d2.loss_mask: 0.3303  decode.d2.loss_dice: 0.3133  decode.d3.loss_cls: 0.1519  decode.d3.loss_mask: 0.4041  decode.d3.loss_dice: 0.3399  decode.d4.loss_cls: 0.1464  decode.d4.loss_mask: 0.3970  decode.d4.loss_dice: 0.3439  decode.d5.loss_cls: 0.2979  decode.d5.loss_mask: 0.3038  decode.d5.loss_dice: 0.3245  decode.d6.loss_cls: 0.2751  decode.d6.loss_mask: 0.3145  decode.d6.loss_dice: 0.3198  decode.d7.loss_cls: 0.2731  decode.d7.loss_mask: 0.3181  decode.d7.loss_dice: 0.3337  decode.d8.loss_cls: 0.2072  decode.d8.loss_mask: 0.3159  decode.d8.loss_dice: 0.3330
07/30 18:09:56 - mmengine - INFO - Iter(train) [12350/80000]  base_lr: 8.5993e-05 lr: 8.5993e-06  eta: 8:11:07  time: 0.4361  data_time: 0.0088  memory: 5246  grad_norm: 79.1825  loss: 9.2770  decode.loss_cls: 0.3447  decode.loss_mask: 0.2293  decode.loss_dice: 0.2532  decode.d0.loss_cls: 1.1125  decode.d0.loss_mask: 0.2446  decode.d0.loss_dice: 0.2808  decode.d1.loss_cls: 0.5856  decode.d1.loss_mask: 0.2332  decode.d1.loss_dice: 0.2552  decode.d2.loss_cls: 0.3813  decode.d2.loss_mask: 0.2287  decode.d2.loss_dice: 0.2554  decode.d3.loss_cls: 0.3593  decode.d3.loss_mask: 0.2304  decode.d3.loss_dice: 0.2577  decode.d4.loss_cls: 0.3348  decode.d4.loss_mask: 0.2296  decode.d4.loss_dice: 0.2457  decode.d5.loss_cls: 0.3368  decode.d5.loss_mask: 0.2280  decode.d5.loss_dice: 0.2392  decode.d6.loss_cls: 0.3283  decode.d6.loss_mask: 0.2288  decode.d6.loss_dice: 0.2481  decode.d7.loss_cls: 0.3178  decode.d7.loss_mask: 0.2288  decode.d7.loss_dice: 0.2494  decode.d8.loss_cls: 0.3222  decode.d8.loss_mask: 0.2278  decode.d8.loss_dice: 0.2599
07/30 18:10:18 - mmengine - INFO - Iter(train) [12400/80000]  base_lr: 8.5936e-05 lr: 8.5936e-06  eta: 8:10:46  time: 0.4345  data_time: 0.0088  memory: 5261  grad_norm: 120.1793  loss: 9.3484  decode.loss_cls: 0.1913  decode.loss_mask: 0.3022  decode.loss_dice: 0.3194  decode.d0.loss_cls: 1.0370  decode.d0.loss_mask: 0.3174  decode.d0.loss_dice: 0.3823  decode.d1.loss_cls: 0.2998  decode.d1.loss_mask: 0.3033  decode.d1.loss_dice: 0.3240  decode.d2.loss_cls: 0.2300  decode.d2.loss_mask: 0.3036  decode.d2.loss_dice: 0.3375  decode.d3.loss_cls: 0.1975  decode.d3.loss_mask: 0.3014  decode.d3.loss_dice: 0.3168  decode.d4.loss_cls: 0.2306  decode.d4.loss_mask: 0.2985  decode.d4.loss_dice: 0.3252  decode.d5.loss_cls: 0.1824  decode.d5.loss_mask: 0.3053  decode.d5.loss_dice: 0.3274  decode.d6.loss_cls: 0.1708  decode.d6.loss_mask: 0.3034  decode.d6.loss_dice: 0.3190  decode.d7.loss_cls: 0.2256  decode.d7.loss_mask: 0.2987  decode.d7.loss_dice: 0.3270  decode.d8.loss_cls: 0.2265  decode.d8.loss_mask: 0.3043  decode.d8.loss_dice: 0.3404
07/30 18:10:40 - mmengine - INFO - Iter(train) [12450/80000]  base_lr: 8.5879e-05 lr: 8.5879e-06  eta: 8:10:24  time: 0.4358  data_time: 0.0088  memory: 5277  grad_norm: 87.7611  loss: 10.2071  decode.loss_cls: 0.3230  decode.loss_mask: 0.2393  decode.loss_dice: 0.3342  decode.d0.loss_cls: 1.0991  decode.d0.loss_mask: 0.2441  decode.d0.loss_dice: 0.3741  decode.d1.loss_cls: 0.4421  decode.d1.loss_mask: 0.2459  decode.d1.loss_dice: 0.3316  decode.d2.loss_cls: 0.3598  decode.d2.loss_mask: 0.2403  decode.d2.loss_dice: 0.3326  decode.d3.loss_cls: 0.3923  decode.d3.loss_mask: 0.2370  decode.d3.loss_dice: 0.3499  decode.d4.loss_cls: 0.2698  decode.d4.loss_mask: 0.2739  decode.d4.loss_dice: 0.3726  decode.d5.loss_cls: 0.3394  decode.d5.loss_mask: 0.2348  decode.d5.loss_dice: 0.3152  decode.d6.loss_cls: 0.3809  decode.d6.loss_mask: 0.2334  decode.d6.loss_dice: 0.3411  decode.d7.loss_cls: 0.3988  decode.d7.loss_mask: 0.2355  decode.d7.loss_dice: 0.3484  decode.d8.loss_cls: 0.3294  decode.d8.loss_mask: 0.2465  decode.d8.loss_dice: 0.3423
07/30 18:11:01 - mmengine - INFO - Iter(train) [12500/80000]  base_lr: 8.5822e-05 lr: 8.5822e-06  eta: 8:10:02  time: 0.4361  data_time: 0.0090  memory: 5261  grad_norm: 129.7281  loss: 10.7295  decode.loss_cls: 0.3446  decode.loss_mask: 0.2600  decode.loss_dice: 0.3243  decode.d0.loss_cls: 1.1657  decode.d0.loss_mask: 0.2710  decode.d0.loss_dice: 0.3475  decode.d1.loss_cls: 0.4384  decode.d1.loss_mask: 0.2615  decode.d1.loss_dice: 0.3390  decode.d2.loss_cls: 0.4206  decode.d2.loss_mask: 0.2608  decode.d2.loss_dice: 0.3307  decode.d3.loss_cls: 0.3620  decode.d3.loss_mask: 0.2613  decode.d3.loss_dice: 0.3324  decode.d4.loss_cls: 0.3904  decode.d4.loss_mask: 0.2598  decode.d4.loss_dice: 0.3461  decode.d5.loss_cls: 0.3920  decode.d5.loss_mask: 0.2653  decode.d5.loss_dice: 0.3435  decode.d6.loss_cls: 0.4370  decode.d6.loss_mask: 0.2572  decode.d6.loss_dice: 0.3304  decode.d7.loss_cls: 0.4740  decode.d7.loss_mask: 0.2611  decode.d7.loss_dice: 0.3372  decode.d8.loss_cls: 0.3284  decode.d8.loss_mask: 0.2645  decode.d8.loss_dice: 0.3227
07/30 18:11:23 - mmengine - INFO - Iter(train) [12550/80000]  base_lr: 8.5765e-05 lr: 8.5765e-06  eta: 8:09:41  time: 0.4359  data_time: 0.0090  memory: 5278  grad_norm: 83.8522  loss: 8.9719  decode.loss_cls: 0.2559  decode.loss_mask: 0.2877  decode.loss_dice: 0.2611  decode.d0.loss_cls: 1.1265  decode.d0.loss_mask: 0.2458  decode.d0.loss_dice: 0.2626  decode.d1.loss_cls: 0.3433  decode.d1.loss_mask: 0.2894  decode.d1.loss_dice: 0.2852  decode.d2.loss_cls: 0.2308  decode.d2.loss_mask: 0.2882  decode.d2.loss_dice: 0.2774  decode.d3.loss_cls: 0.2096  decode.d3.loss_mask: 0.2840  decode.d3.loss_dice: 0.2642  decode.d4.loss_cls: 0.2129  decode.d4.loss_mask: 0.2925  decode.d4.loss_dice: 0.2760  decode.d5.loss_cls: 0.2572  decode.d5.loss_mask: 0.2837  decode.d5.loss_dice: 0.2712  decode.d6.loss_cls: 0.2543  decode.d6.loss_mask: 0.2799  decode.d6.loss_dice: 0.2740  decode.d7.loss_cls: 0.2552  decode.d7.loss_mask: 0.2762  decode.d7.loss_dice: 0.2651  decode.d8.loss_cls: 0.3183  decode.d8.loss_mask: 0.2830  decode.d8.loss_dice: 0.2606
07/30 18:11:45 - mmengine - INFO - Iter(train) [12600/80000]  base_lr: 8.5707e-05 lr: 8.5707e-06  eta: 8:09:19  time: 0.4365  data_time: 0.0091  memory: 5261  grad_norm: 97.1207  loss: 12.0644  decode.loss_cls: 0.5010  decode.loss_mask: 0.2789  decode.loss_dice: 0.3574  decode.d0.loss_cls: 1.2522  decode.d0.loss_mask: 0.2940  decode.d0.loss_dice: 0.3677  decode.d1.loss_cls: 0.6344  decode.d1.loss_mask: 0.2830  decode.d1.loss_dice: 0.3638  decode.d2.loss_cls: 0.4526  decode.d2.loss_mask: 0.2844  decode.d2.loss_dice: 0.3287  decode.d3.loss_cls: 0.4311  decode.d3.loss_mask: 0.2809  decode.d3.loss_dice: 0.3294  decode.d4.loss_cls: 0.5664  decode.d4.loss_mask: 0.2878  decode.d4.loss_dice: 0.3281  decode.d5.loss_cls: 0.5074  decode.d5.loss_mask: 0.2832  decode.d5.loss_dice: 0.3487  decode.d6.loss_cls: 0.4522  decode.d6.loss_mask: 0.2812  decode.d6.loss_dice: 0.3320  decode.d7.loss_cls: 0.5019  decode.d7.loss_mask: 0.2835  decode.d7.loss_dice: 0.3441  decode.d8.loss_cls: 0.4900  decode.d8.loss_mask: 0.2804  decode.d8.loss_dice: 0.3376
07/30 18:12:07 - mmengine - INFO - Iter(train) [12650/80000]  base_lr: 8.5650e-05 lr: 8.5650e-06  eta: 8:08:57  time: 0.4347  data_time: 0.0089  memory: 5244  grad_norm: 112.2358  loss: 9.6926  decode.loss_cls: 0.3796  decode.loss_mask: 0.2266  decode.loss_dice: 0.2666  decode.d0.loss_cls: 1.1042  decode.d0.loss_mask: 0.2502  decode.d0.loss_dice: 0.2850  decode.d1.loss_cls: 0.5291  decode.d1.loss_mask: 0.2376  decode.d1.loss_dice: 0.2665  decode.d2.loss_cls: 0.3343  decode.d2.loss_mask: 0.2520  decode.d2.loss_dice: 0.2782  decode.d3.loss_cls: 0.3777  decode.d3.loss_mask: 0.2346  decode.d3.loss_dice: 0.2594  decode.d4.loss_cls: 0.3993  decode.d4.loss_mask: 0.2389  decode.d4.loss_dice: 0.2711  decode.d5.loss_cls: 0.3618  decode.d5.loss_mask: 0.2306  decode.d5.loss_dice: 0.2646  decode.d6.loss_cls: 0.3855  decode.d6.loss_mask: 0.2295  decode.d6.loss_dice: 0.2684  decode.d7.loss_cls: 0.3447  decode.d7.loss_mask: 0.2428  decode.d7.loss_dice: 0.2941  decode.d8.loss_cls: 0.3902  decode.d8.loss_mask: 0.2286  decode.d8.loss_dice: 0.2608
07/30 18:12:29 - mmengine - INFO - Iter(train) [12700/80000]  base_lr: 8.5593e-05 lr: 8.5593e-06  eta: 8:08:36  time: 0.4360  data_time: 0.0088  memory: 5265  grad_norm: 51.2567  loss: 7.8274  decode.loss_cls: 0.1637  decode.loss_mask: 0.2470  decode.loss_dice: 0.2526  decode.d0.loss_cls: 1.0956  decode.d0.loss_mask: 0.2548  decode.d0.loss_dice: 0.2884  decode.d1.loss_cls: 0.2253  decode.d1.loss_mask: 0.2501  decode.d1.loss_dice: 0.2626  decode.d2.loss_cls: 0.2035  decode.d2.loss_mask: 0.2538  decode.d2.loss_dice: 0.2809  decode.d3.loss_cls: 0.1780  decode.d3.loss_mask: 0.2481  decode.d3.loss_dice: 0.2559  decode.d4.loss_cls: 0.1960  decode.d4.loss_mask: 0.2524  decode.d4.loss_dice: 0.2594  decode.d5.loss_cls: 0.1580  decode.d5.loss_mask: 0.2437  decode.d5.loss_dice: 0.2680  decode.d6.loss_cls: 0.1661  decode.d6.loss_mask: 0.2478  decode.d6.loss_dice: 0.2514  decode.d7.loss_cls: 0.1369  decode.d7.loss_mask: 0.2443  decode.d7.loss_dice: 0.2542  decode.d8.loss_cls: 0.1841  decode.d8.loss_mask: 0.2472  decode.d8.loss_dice: 0.2576
07/30 18:12:50 - mmengine - INFO - Iter(train) [12750/80000]  base_lr: 8.5536e-05 lr: 8.5536e-06  eta: 8:08:14  time: 0.4360  data_time: 0.0090  memory: 5265  grad_norm: 115.4380  loss: 9.0864  decode.loss_cls: 0.2473  decode.loss_mask: 0.2387  decode.loss_dice: 0.3025  decode.d0.loss_cls: 1.2008  decode.d0.loss_mask: 0.2403  decode.d0.loss_dice: 0.3097  decode.d1.loss_cls: 0.3253  decode.d1.loss_mask: 0.2379  decode.d1.loss_dice: 0.2911  decode.d2.loss_cls: 0.2763  decode.d2.loss_mask: 0.2343  decode.d2.loss_dice: 0.3055  decode.d3.loss_cls: 0.3049  decode.d3.loss_mask: 0.2421  decode.d3.loss_dice: 0.3091  decode.d4.loss_cls: 0.3541  decode.d4.loss_mask: 0.2289  decode.d4.loss_dice: 0.2782  decode.d5.loss_cls: 0.2560  decode.d5.loss_mask: 0.2428  decode.d5.loss_dice: 0.2956  decode.d6.loss_cls: 0.2226  decode.d6.loss_mask: 0.2476  decode.d6.loss_dice: 0.2981  decode.d7.loss_cls: 0.2391  decode.d7.loss_mask: 0.2468  decode.d7.loss_dice: 0.3006  decode.d8.loss_cls: 0.2771  decode.d8.loss_mask: 0.2393  decode.d8.loss_dice: 0.2939
07/30 18:13:12 - mmengine - INFO - Iter(train) [12800/80000]  base_lr: 8.5478e-05 lr: 8.5478e-06  eta: 8:07:52  time: 0.4357  data_time: 0.0089  memory: 5279  grad_norm: 89.9896  loss: 10.4594  decode.loss_cls: 0.3062  decode.loss_mask: 0.3034  decode.loss_dice: 0.3593  decode.d0.loss_cls: 1.1548  decode.d0.loss_mask: 0.2810  decode.d0.loss_dice: 0.4043  decode.d1.loss_cls: 0.2959  decode.d1.loss_mask: 0.2881  decode.d1.loss_dice: 0.3833  decode.d2.loss_cls: 0.3720  decode.d2.loss_mask: 0.2878  decode.d2.loss_dice: 0.3654  decode.d3.loss_cls: 0.2463  decode.d3.loss_mask: 0.2832  decode.d3.loss_dice: 0.3703  decode.d4.loss_cls: 0.3477  decode.d4.loss_mask: 0.2725  decode.d4.loss_dice: 0.3569  decode.d5.loss_cls: 0.3363  decode.d5.loss_mask: 0.2734  decode.d5.loss_dice: 0.3654  decode.d6.loss_cls: 0.2591  decode.d6.loss_mask: 0.2795  decode.d6.loss_dice: 0.3676  decode.d7.loss_cls: 0.3354  decode.d7.loss_mask: 0.2763  decode.d7.loss_dice: 0.3534  decode.d8.loss_cls: 0.2687  decode.d8.loss_mask: 0.3036  decode.d8.loss_dice: 0.3622
07/30 18:13:34 - mmengine - INFO - Iter(train) [12850/80000]  base_lr: 8.5421e-05 lr: 8.5421e-06  eta: 8:07:31  time: 0.4358  data_time: 0.0087  memory: 5265  grad_norm: 204.9809  loss: 11.6302  decode.loss_cls: 0.4178  decode.loss_mask: 0.3060  decode.loss_dice: 0.3110  decode.d0.loss_cls: 1.4289  decode.d0.loss_mask: 0.3236  decode.d0.loss_dice: 0.3320  decode.d1.loss_cls: 0.6039  decode.d1.loss_mask: 0.3124  decode.d1.loss_dice: 0.3137  decode.d2.loss_cls: 0.5587  decode.d2.loss_mask: 0.3061  decode.d2.loss_dice: 0.2825  decode.d3.loss_cls: 0.4288  decode.d3.loss_mask: 0.3108  decode.d3.loss_dice: 0.3025  decode.d4.loss_cls: 0.4688  decode.d4.loss_mask: 0.3090  decode.d4.loss_dice: 0.3031  decode.d5.loss_cls: 0.4026  decode.d5.loss_mask: 0.3196  decode.d5.loss_dice: 0.2995  decode.d6.loss_cls: 0.3715  decode.d6.loss_mask: 0.3113  decode.d6.loss_dice: 0.3292  decode.d7.loss_cls: 0.3580  decode.d7.loss_mask: 0.3145  decode.d7.loss_dice: 0.2993  decode.d8.loss_cls: 0.4026  decode.d8.loss_mask: 0.3130  decode.d8.loss_dice: 0.2892
07/30 18:13:56 - mmengine - INFO - Iter(train) [12900/80000]  base_lr: 8.5364e-05 lr: 8.5364e-06  eta: 8:07:09  time: 0.4357  data_time: 0.0089  memory: 5265  grad_norm: 82.7746  loss: 7.7887  decode.loss_cls: 0.1531  decode.loss_mask: 0.2544  decode.loss_dice: 0.2619  decode.d0.loss_cls: 0.9476  decode.d0.loss_mask: 0.2707  decode.d0.loss_dice: 0.2891  decode.d1.loss_cls: 0.2027  decode.d1.loss_mask: 0.2561  decode.d1.loss_dice: 0.2858  decode.d2.loss_cls: 0.1759  decode.d2.loss_mask: 0.2556  decode.d2.loss_dice: 0.2704  decode.d3.loss_cls: 0.2019  decode.d3.loss_mask: 0.2550  decode.d3.loss_dice: 0.2673  decode.d4.loss_cls: 0.1662  decode.d4.loss_mask: 0.2564  decode.d4.loss_dice: 0.2730  decode.d5.loss_cls: 0.1695  decode.d5.loss_mask: 0.2574  decode.d5.loss_dice: 0.2770  decode.d6.loss_cls: 0.1648  decode.d6.loss_mask: 0.2576  decode.d6.loss_dice: 0.2644  decode.d7.loss_cls: 0.1373  decode.d7.loss_mask: 0.2572  decode.d7.loss_dice: 0.2725  decode.d8.loss_cls: 0.1759  decode.d8.loss_mask: 0.2543  decode.d8.loss_dice: 0.2577
07/30 18:14:18 - mmengine - INFO - Iter(train) [12950/80000]  base_lr: 8.5307e-05 lr: 8.5307e-06  eta: 8:06:47  time: 0.4364  data_time: 0.0087  memory: 5244  grad_norm: 57.6536  loss: 9.9313  decode.loss_cls: 0.3591  decode.loss_mask: 0.2592  decode.loss_dice: 0.2573  decode.d0.loss_cls: 1.2786  decode.d0.loss_mask: 0.2591  decode.d0.loss_dice: 0.3176  decode.d1.loss_cls: 0.4584  decode.d1.loss_mask: 0.2554  decode.d1.loss_dice: 0.2737  decode.d2.loss_cls: 0.4837  decode.d2.loss_mask: 0.2474  decode.d2.loss_dice: 0.2616  decode.d3.loss_cls: 0.3641  decode.d3.loss_mask: 0.2484  decode.d3.loss_dice: 0.2669  decode.d4.loss_cls: 0.3421  decode.d4.loss_mask: 0.2479  decode.d4.loss_dice: 0.2617  decode.d5.loss_cls: 0.3569  decode.d5.loss_mask: 0.2590  decode.d5.loss_dice: 0.2839  decode.d6.loss_cls: 0.3894  decode.d6.loss_mask: 0.2523  decode.d6.loss_dice: 0.2576  decode.d7.loss_cls: 0.3435  decode.d7.loss_mask: 0.2552  decode.d7.loss_dice: 0.2399  decode.d8.loss_cls: 0.3455  decode.d8.loss_mask: 0.2598  decode.d8.loss_dice: 0.2460
07/30 18:14:39 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 18:14:39 - mmengine - INFO - Iter(train) [13000/80000]  base_lr: 8.5249e-05 lr: 8.5249e-06  eta: 8:06:26  time: 0.4370  data_time: 0.0090  memory: 5303  grad_norm: 79.3069  loss: 9.3404  decode.loss_cls: 0.2976  decode.loss_mask: 0.2111  decode.loss_dice: 0.2890  decode.d0.loss_cls: 1.2203  decode.d0.loss_mask: 0.2140  decode.d0.loss_dice: 0.3055  decode.d1.loss_cls: 0.4243  decode.d1.loss_mask: 0.2105  decode.d1.loss_dice: 0.2709  decode.d2.loss_cls: 0.4166  decode.d2.loss_mask: 0.2085  decode.d2.loss_dice: 0.2823  decode.d3.loss_cls: 0.3634  decode.d3.loss_mask: 0.2112  decode.d3.loss_dice: 0.3032  decode.d4.loss_cls: 0.3616  decode.d4.loss_mask: 0.2116  decode.d4.loss_dice: 0.2930  decode.d5.loss_cls: 0.3434  decode.d5.loss_mask: 0.2105  decode.d5.loss_dice: 0.2915  decode.d6.loss_cls: 0.3036  decode.d6.loss_mask: 0.2139  decode.d6.loss_dice: 0.2823  decode.d7.loss_cls: 0.3103  decode.d7.loss_mask: 0.2105  decode.d7.loss_dice: 0.2692  decode.d8.loss_cls: 0.3077  decode.d8.loss_mask: 0.2129  decode.d8.loss_dice: 0.2899
07/30 18:15:01 - mmengine - INFO - Iter(train) [13050/80000]  base_lr: 8.5192e-05 lr: 8.5192e-06  eta: 8:06:04  time: 0.4361  data_time: 0.0088  memory: 5278  grad_norm: 138.3981  loss: 10.4219  decode.loss_cls: 0.3012  decode.loss_mask: 0.2847  decode.loss_dice: 0.3026  decode.d0.loss_cls: 1.1538  decode.d0.loss_mask: 0.3258  decode.d0.loss_dice: 0.3682  decode.d1.loss_cls: 0.4134  decode.d1.loss_mask: 0.3083  decode.d1.loss_dice: 0.3275  decode.d2.loss_cls: 0.3704  decode.d2.loss_mask: 0.3093  decode.d2.loss_dice: 0.3546  decode.d3.loss_cls: 0.3134  decode.d3.loss_mask: 0.2926  decode.d3.loss_dice: 0.3244  decode.d4.loss_cls: 0.3020  decode.d4.loss_mask: 0.2852  decode.d4.loss_dice: 0.3389  decode.d5.loss_cls: 0.3372  decode.d5.loss_mask: 0.2896  decode.d5.loss_dice: 0.3105  decode.d6.loss_cls: 0.3061  decode.d6.loss_mask: 0.2923  decode.d6.loss_dice: 0.3184  decode.d7.loss_cls: 0.3348  decode.d7.loss_mask: 0.2921  decode.d7.loss_dice: 0.3205  decode.d8.loss_cls: 0.3385  decode.d8.loss_mask: 0.2856  decode.d8.loss_dice: 0.3196
07/30 18:15:23 - mmengine - INFO - Iter(train) [13100/80000]  base_lr: 8.5135e-05 lr: 8.5135e-06  eta: 8:05:42  time: 0.4371  data_time: 0.0087  memory: 5305  grad_norm: 72.3651  loss: 8.9410  decode.loss_cls: 0.2159  decode.loss_mask: 0.2475  decode.loss_dice: 0.3162  decode.d0.loss_cls: 1.0959  decode.d0.loss_mask: 0.2543  decode.d0.loss_dice: 0.3499  decode.d1.loss_cls: 0.3822  decode.d1.loss_mask: 0.2509  decode.d1.loss_dice: 0.3304  decode.d2.loss_cls: 0.3420  decode.d2.loss_mask: 0.2420  decode.d2.loss_dice: 0.3064  decode.d3.loss_cls: 0.2437  decode.d3.loss_mask: 0.2472  decode.d3.loss_dice: 0.3056  decode.d4.loss_cls: 0.1842  decode.d4.loss_mask: 0.2465  decode.d4.loss_dice: 0.3124  decode.d5.loss_cls: 0.2176  decode.d5.loss_mask: 0.2445  decode.d5.loss_dice: 0.3115  decode.d6.loss_cls: 0.2034  decode.d6.loss_mask: 0.2449  decode.d6.loss_dice: 0.3071  decode.d7.loss_cls: 0.2305  decode.d7.loss_mask: 0.2486  decode.d7.loss_dice: 0.3105  decode.d8.loss_cls: 0.1940  decode.d8.loss_mask: 0.2453  decode.d8.loss_dice: 0.3100
07/30 18:15:45 - mmengine - INFO - Iter(train) [13150/80000]  base_lr: 8.5078e-05 lr: 8.5078e-06  eta: 8:05:21  time: 0.4357  data_time: 0.0091  memory: 5227  grad_norm: 64.6159  loss: 10.0934  decode.loss_cls: 0.3113  decode.loss_mask: 0.2659  decode.loss_dice: 0.3258  decode.d0.loss_cls: 1.0922  decode.d0.loss_mask: 0.2848  decode.d0.loss_dice: 0.3651  decode.d1.loss_cls: 0.3859  decode.d1.loss_mask: 0.2696  decode.d1.loss_dice: 0.3261  decode.d2.loss_cls: 0.3571  decode.d2.loss_mask: 0.2733  decode.d2.loss_dice: 0.3415  decode.d3.loss_cls: 0.3589  decode.d3.loss_mask: 0.2664  decode.d3.loss_dice: 0.3133  decode.d4.loss_cls: 0.3979  decode.d4.loss_mask: 0.2640  decode.d4.loss_dice: 0.3176  decode.d5.loss_cls: 0.3225  decode.d5.loss_mask: 0.2624  decode.d5.loss_dice: 0.3358  decode.d6.loss_cls: 0.2694  decode.d6.loss_mask: 0.2644  decode.d6.loss_dice: 0.3102  decode.d7.loss_cls: 0.3380  decode.d7.loss_mask: 0.2636  decode.d7.loss_dice: 0.3146  decode.d8.loss_cls: 0.3230  decode.d8.loss_mask: 0.2638  decode.d8.loss_dice: 0.3091
07/30 18:16:07 - mmengine - INFO - Iter(train) [13200/80000]  base_lr: 8.5020e-05 lr: 8.5020e-06  eta: 8:04:59  time: 0.4363  data_time: 0.0089  memory: 5246  grad_norm: 131.9525  loss: 12.0872  decode.loss_cls: 0.4221  decode.loss_mask: 0.3093  decode.loss_dice: 0.3966  decode.d0.loss_cls: 1.2407  decode.d0.loss_mask: 0.3243  decode.d0.loss_dice: 0.4275  decode.d1.loss_cls: 0.5260  decode.d1.loss_mask: 0.3220  decode.d1.loss_dice: 0.4067  decode.d2.loss_cls: 0.4384  decode.d2.loss_mask: 0.3139  decode.d2.loss_dice: 0.4074  decode.d3.loss_cls: 0.3863  decode.d3.loss_mask: 0.3118  decode.d3.loss_dice: 0.3632  decode.d4.loss_cls: 0.3364  decode.d4.loss_mask: 0.3227  decode.d4.loss_dice: 0.4344  decode.d5.loss_cls: 0.3579  decode.d5.loss_mask: 0.3108  decode.d5.loss_dice: 0.4153  decode.d6.loss_cls: 0.4531  decode.d6.loss_mask: 0.3057  decode.d6.loss_dice: 0.3867  decode.d7.loss_cls: 0.4317  decode.d7.loss_mask: 0.3044  decode.d7.loss_dice: 0.4054  decode.d8.loss_cls: 0.3388  decode.d8.loss_mask: 0.3062  decode.d8.loss_dice: 0.3817
07/30 18:16:28 - mmengine - INFO - Iter(train) [13250/80000]  base_lr: 8.4963e-05 lr: 8.4963e-06  eta: 8:04:37  time: 0.4359  data_time: 0.0088  memory: 5261  grad_norm: 97.1045  loss: 7.4845  decode.loss_cls: 0.2100  decode.loss_mask: 0.1940  decode.loss_dice: 0.2143  decode.d0.loss_cls: 1.1306  decode.d0.loss_mask: 0.2095  decode.d0.loss_dice: 0.2612  decode.d1.loss_cls: 0.2962  decode.d1.loss_mask: 0.1974  decode.d1.loss_dice: 0.2339  decode.d2.loss_cls: 0.2262  decode.d2.loss_mask: 0.2030  decode.d2.loss_dice: 0.2262  decode.d3.loss_cls: 0.2070  decode.d3.loss_mask: 0.1977  decode.d3.loss_dice: 0.2315  decode.d4.loss_cls: 0.2475  decode.d4.loss_mask: 0.2015  decode.d4.loss_dice: 0.2312  decode.d5.loss_cls: 0.2093  decode.d5.loss_mask: 0.1957  decode.d5.loss_dice: 0.2162  decode.d6.loss_cls: 0.1855  decode.d6.loss_mask: 0.2045  decode.d6.loss_dice: 0.2256  decode.d7.loss_cls: 0.2239  decode.d7.loss_mask: 0.2035  decode.d7.loss_dice: 0.2269  decode.d8.loss_cls: 0.2628  decode.d8.loss_mask: 0.1988  decode.d8.loss_dice: 0.2128
07/30 18:16:50 - mmengine - INFO - Iter(train) [13300/80000]  base_lr: 8.4906e-05 lr: 8.4906e-06  eta: 8:04:16  time: 0.4361  data_time: 0.0089  memory: 5265  grad_norm: 108.3743  loss: 9.6804  decode.loss_cls: 0.2116  decode.loss_mask: 0.3197  decode.loss_dice: 0.3186  decode.d0.loss_cls: 1.1324  decode.d0.loss_mask: 0.3240  decode.d0.loss_dice: 0.3438  decode.d1.loss_cls: 0.2459  decode.d1.loss_mask: 0.3151  decode.d1.loss_dice: 0.2991  decode.d2.loss_cls: 0.2704  decode.d2.loss_mask: 0.3182  decode.d2.loss_dice: 0.2987  decode.d3.loss_cls: 0.2381  decode.d3.loss_mask: 0.3219  decode.d3.loss_dice: 0.3070  decode.d4.loss_cls: 0.2774  decode.d4.loss_mask: 0.3165  decode.d4.loss_dice: 0.3132  decode.d5.loss_cls: 0.2718  decode.d5.loss_mask: 0.3263  decode.d5.loss_dice: 0.3158  decode.d6.loss_cls: 0.2354  decode.d6.loss_mask: 0.3230  decode.d6.loss_dice: 0.3088  decode.d7.loss_cls: 0.1882  decode.d7.loss_mask: 0.3204  decode.d7.loss_dice: 0.3163  decode.d8.loss_cls: 0.2533  decode.d8.loss_mask: 0.3259  decode.d8.loss_dice: 0.3234
07/30 18:17:12 - mmengine - INFO - Iter(train) [13350/80000]  base_lr: 8.4848e-05 lr: 8.4848e-06  eta: 8:03:54  time: 0.4359  data_time: 0.0090  memory: 5305  grad_norm: 74.8235  loss: 9.5934  decode.loss_cls: 0.2122  decode.loss_mask: 0.3113  decode.loss_dice: 0.2975  decode.d0.loss_cls: 1.1566  decode.d0.loss_mask: 0.3220  decode.d0.loss_dice: 0.2938  decode.d1.loss_cls: 0.3108  decode.d1.loss_mask: 0.3248  decode.d1.loss_dice: 0.3142  decode.d2.loss_cls: 0.2730  decode.d2.loss_mask: 0.3175  decode.d2.loss_dice: 0.3077  decode.d3.loss_cls: 0.2621  decode.d3.loss_mask: 0.3097  decode.d3.loss_dice: 0.2945  decode.d4.loss_cls: 0.2678  decode.d4.loss_mask: 0.3121  decode.d4.loss_dice: 0.3020  decode.d5.loss_cls: 0.2470  decode.d5.loss_mask: 0.3145  decode.d5.loss_dice: 0.2978  decode.d6.loss_cls: 0.2245  decode.d6.loss_mask: 0.3126  decode.d6.loss_dice: 0.3058  decode.d7.loss_cls: 0.2477  decode.d7.loss_mask: 0.3152  decode.d7.loss_dice: 0.2903  decode.d8.loss_cls: 0.2382  decode.d8.loss_mask: 0.3162  decode.d8.loss_dice: 0.2942
07/30 18:17:34 - mmengine - INFO - Iter(train) [13400/80000]  base_lr: 8.4791e-05 lr: 8.4791e-06  eta: 8:03:32  time: 0.4368  data_time: 0.0090  memory: 5229  grad_norm: 189.3388  loss: 8.6375  decode.loss_cls: 0.2583  decode.loss_mask: 0.2640  decode.loss_dice: 0.2656  decode.d0.loss_cls: 1.0107  decode.d0.loss_mask: 0.2673  decode.d0.loss_dice: 0.3154  decode.d1.loss_cls: 0.2945  decode.d1.loss_mask: 0.2629  decode.d1.loss_dice: 0.2528  decode.d2.loss_cls: 0.2490  decode.d2.loss_mask: 0.2651  decode.d2.loss_dice: 0.2703  decode.d3.loss_cls: 0.2461  decode.d3.loss_mask: 0.2644  decode.d3.loss_dice: 0.2493  decode.d4.loss_cls: 0.2324  decode.d4.loss_mask: 0.2632  decode.d4.loss_dice: 0.2621  decode.d5.loss_cls: 0.2061  decode.d5.loss_mask: 0.2631  decode.d5.loss_dice: 0.2716  decode.d6.loss_cls: 0.2511  decode.d6.loss_mask: 0.2648  decode.d6.loss_dice: 0.2577  decode.d7.loss_cls: 0.3143  decode.d7.loss_mask: 0.2627  decode.d7.loss_dice: 0.2563  decode.d8.loss_cls: 0.2880  decode.d8.loss_mask: 0.2600  decode.d8.loss_dice: 0.2485
07/30 18:17:56 - mmengine - INFO - Iter(train) [13450/80000]  base_lr: 8.4734e-05 lr: 8.4734e-06  eta: 8:03:11  time: 0.4377  data_time: 0.0091  memory: 5244  grad_norm: 59.9919  loss: 6.5555  decode.loss_cls: 0.0729  decode.loss_mask: 0.2452  decode.loss_dice: 0.2324  decode.d0.loss_cls: 0.8978  decode.d0.loss_mask: 0.2666  decode.d0.loss_dice: 0.2562  decode.d1.loss_cls: 0.1925  decode.d1.loss_mask: 0.2538  decode.d1.loss_dice: 0.2349  decode.d2.loss_cls: 0.1266  decode.d2.loss_mask: 0.2467  decode.d2.loss_dice: 0.2243  decode.d3.loss_cls: 0.0876  decode.d3.loss_mask: 0.2434  decode.d3.loss_dice: 0.2244  decode.d4.loss_cls: 0.0863  decode.d4.loss_mask: 0.2436  decode.d4.loss_dice: 0.2273  decode.d5.loss_cls: 0.1114  decode.d5.loss_mask: 0.2450  decode.d5.loss_dice: 0.2302  decode.d6.loss_cls: 0.0617  decode.d6.loss_mask: 0.2434  decode.d6.loss_dice: 0.2230  decode.d7.loss_cls: 0.0553  decode.d7.loss_mask: 0.2459  decode.d7.loss_dice: 0.2294  decode.d8.loss_cls: 0.0743  decode.d8.loss_mask: 0.2445  decode.d8.loss_dice: 0.2290
07/30 18:18:18 - mmengine - INFO - Iter(train) [13500/80000]  base_lr: 8.4677e-05 lr: 8.4677e-06  eta: 8:02:49  time: 0.4366  data_time: 0.0090  memory: 5277  grad_norm: 133.3592  loss: 10.4670  decode.loss_cls: 0.3180  decode.loss_mask: 0.2828  decode.loss_dice: 0.3301  decode.d0.loss_cls: 1.2131  decode.d0.loss_mask: 0.3045  decode.d0.loss_dice: 0.3780  decode.d1.loss_cls: 0.3789  decode.d1.loss_mask: 0.2929  decode.d1.loss_dice: 0.3227  decode.d2.loss_cls: 0.3921  decode.d2.loss_mask: 0.2897  decode.d2.loss_dice: 0.3351  decode.d3.loss_cls: 0.3605  decode.d3.loss_mask: 0.2857  decode.d3.loss_dice: 0.3285  decode.d4.loss_cls: 0.3061  decode.d4.loss_mask: 0.2832  decode.d4.loss_dice: 0.3233  decode.d5.loss_cls: 0.3239  decode.d5.loss_mask: 0.2885  decode.d5.loss_dice: 0.3471  decode.d6.loss_cls: 0.3261  decode.d6.loss_mask: 0.2826  decode.d6.loss_dice: 0.3305  decode.d7.loss_cls: 0.3192  decode.d7.loss_mask: 0.2847  decode.d7.loss_dice: 0.3166  decode.d8.loss_cls: 0.3245  decode.d8.loss_mask: 0.2821  decode.d8.loss_dice: 0.3160
07/30 18:18:40 - mmengine - INFO - Iter(train) [13550/80000]  base_lr: 8.4619e-05 lr: 8.4619e-06  eta: 8:02:29  time: 0.4366  data_time: 0.0090  memory: 5277  grad_norm: 76.2435  loss: 9.7879  decode.loss_cls: 0.2921  decode.loss_mask: 0.2545  decode.loss_dice: 0.3376  decode.d0.loss_cls: 1.1619  decode.d0.loss_mask: 0.2748  decode.d0.loss_dice: 0.3739  decode.d1.loss_cls: 0.3753  decode.d1.loss_mask: 0.2604  decode.d1.loss_dice: 0.3227  decode.d2.loss_cls: 0.3410  decode.d2.loss_mask: 0.2567  decode.d2.loss_dice: 0.3331  decode.d3.loss_cls: 0.2823  decode.d3.loss_mask: 0.2551  decode.d3.loss_dice: 0.3190  decode.d4.loss_cls: 0.2595  decode.d4.loss_mask: 0.2581  decode.d4.loss_dice: 0.3328  decode.d5.loss_cls: 0.2760  decode.d5.loss_mask: 0.2597  decode.d5.loss_dice: 0.3367  decode.d6.loss_cls: 0.2739  decode.d6.loss_mask: 0.2594  decode.d6.loss_dice: 0.3247  decode.d7.loss_cls: 0.3236  decode.d7.loss_mask: 0.2579  decode.d7.loss_dice: 0.3253  decode.d8.loss_cls: 0.2684  decode.d8.loss_mask: 0.2636  decode.d8.loss_dice: 0.3280
07/30 18:19:01 - mmengine - INFO - Iter(train) [13600/80000]  base_lr: 8.4562e-05 lr: 8.4562e-06  eta: 8:02:07  time: 0.4353  data_time: 0.0089  memory: 5305  grad_norm: 159.5235  loss: 13.1507  decode.loss_cls: 0.4929  decode.loss_mask: 0.3473  decode.loss_dice: 0.3597  decode.d0.loss_cls: 1.2073  decode.d0.loss_mask: 0.3654  decode.d0.loss_dice: 0.4044  decode.d1.loss_cls: 0.5730  decode.d1.loss_mask: 0.3645  decode.d1.loss_dice: 0.3672  decode.d2.loss_cls: 0.5272  decode.d2.loss_mask: 0.3623  decode.d2.loss_dice: 0.3540  decode.d3.loss_cls: 0.4743  decode.d3.loss_mask: 0.3541  decode.d3.loss_dice: 0.3737  decode.d4.loss_cls: 0.5412  decode.d4.loss_mask: 0.3553  decode.d4.loss_dice: 0.3784  decode.d5.loss_cls: 0.5119  decode.d5.loss_mask: 0.3546  decode.d5.loss_dice: 0.3687  decode.d6.loss_cls: 0.5190  decode.d6.loss_mask: 0.3414  decode.d6.loss_dice: 0.3685  decode.d7.loss_cls: 0.5150  decode.d7.loss_mask: 0.3414  decode.d7.loss_dice: 0.3871  decode.d8.loss_cls: 0.5113  decode.d8.loss_mask: 0.3515  decode.d8.loss_dice: 0.3779
07/30 18:19:23 - mmengine - INFO - Iter(train) [13650/80000]  base_lr: 8.4505e-05 lr: 8.4505e-06  eta: 8:01:46  time: 0.4374  data_time: 0.0087  memory: 5244  grad_norm: 175.1190  loss: 8.8228  decode.loss_cls: 0.2716  decode.loss_mask: 0.1835  decode.loss_dice: 0.3055  decode.d0.loss_cls: 1.2436  decode.d0.loss_mask: 0.2030  decode.d0.loss_dice: 0.3369  decode.d1.loss_cls: 0.3959  decode.d1.loss_mask: 0.1955  decode.d1.loss_dice: 0.3383  decode.d2.loss_cls: 0.2712  decode.d2.loss_mask: 0.1922  decode.d2.loss_dice: 0.3107  decode.d3.loss_cls: 0.2137  decode.d3.loss_mask: 0.1823  decode.d3.loss_dice: 0.3052  decode.d4.loss_cls: 0.3109  decode.d4.loss_mask: 0.1885  decode.d4.loss_dice: 0.3176  decode.d5.loss_cls: 0.2928  decode.d5.loss_mask: 0.1882  decode.d5.loss_dice: 0.3083  decode.d6.loss_cls: 0.2535  decode.d6.loss_mask: 0.1860  decode.d6.loss_dice: 0.3080  decode.d7.loss_cls: 0.2955  decode.d7.loss_mask: 0.1815  decode.d7.loss_dice: 0.2932  decode.d8.loss_cls: 0.2578  decode.d8.loss_mask: 0.1821  decode.d8.loss_dice: 0.3100
07/30 18:19:45 - mmengine - INFO - Iter(train) [13700/80000]  base_lr: 8.4447e-05 lr: 8.4447e-06  eta: 8:01:24  time: 0.4358  data_time: 0.0089  memory: 5245  grad_norm: 112.0466  loss: 9.2551  decode.loss_cls: 0.2362  decode.loss_mask: 0.2669  decode.loss_dice: 0.2700  decode.d0.loss_cls: 1.1075  decode.d0.loss_mask: 0.2805  decode.d0.loss_dice: 0.2938  decode.d1.loss_cls: 0.5129  decode.d1.loss_mask: 0.2648  decode.d1.loss_dice: 0.2735  decode.d2.loss_cls: 0.3476  decode.d2.loss_mask: 0.2694  decode.d2.loss_dice: 0.2816  decode.d3.loss_cls: 0.3043  decode.d3.loss_mask: 0.2704  decode.d3.loss_dice: 0.2517  decode.d4.loss_cls: 0.2739  decode.d4.loss_mask: 0.2683  decode.d4.loss_dice: 0.2952  decode.d5.loss_cls: 0.2778  decode.d5.loss_mask: 0.2701  decode.d5.loss_dice: 0.2653  decode.d6.loss_cls: 0.2434  decode.d6.loss_mask: 0.2689  decode.d6.loss_dice: 0.2768  decode.d7.loss_cls: 0.2455  decode.d7.loss_mask: 0.2715  decode.d7.loss_dice: 0.2670  decode.d8.loss_cls: 0.2470  decode.d8.loss_mask: 0.2691  decode.d8.loss_dice: 0.2842
07/30 18:20:07 - mmengine - INFO - Iter(train) [13750/80000]  base_lr: 8.4390e-05 lr: 8.4390e-06  eta: 8:01:02  time: 0.4363  data_time: 0.0088  memory: 5305  grad_norm: 52.1298  loss: 8.3478  decode.loss_cls: 0.2539  decode.loss_mask: 0.2234  decode.loss_dice: 0.2264  decode.d0.loss_cls: 1.1804  decode.d0.loss_mask: 0.2214  decode.d0.loss_dice: 0.2569  decode.d1.loss_cls: 0.2476  decode.d1.loss_mask: 0.2252  decode.d1.loss_dice: 0.2483  decode.d2.loss_cls: 0.2778  decode.d2.loss_mask: 0.2284  decode.d2.loss_dice: 0.2646  decode.d3.loss_cls: 0.2444  decode.d3.loss_mask: 0.2279  decode.d3.loss_dice: 0.2736  decode.d4.loss_cls: 0.2629  decode.d4.loss_mask: 0.2288  decode.d4.loss_dice: 0.2515  decode.d5.loss_cls: 0.2778  decode.d5.loss_mask: 0.2273  decode.d5.loss_dice: 0.2483  decode.d6.loss_cls: 0.2679  decode.d6.loss_mask: 0.2226  decode.d6.loss_dice: 0.2404  decode.d7.loss_cls: 0.3081  decode.d7.loss_mask: 0.2268  decode.d7.loss_dice: 0.2391  decode.d8.loss_cls: 0.2657  decode.d8.loss_mask: 0.2224  decode.d8.loss_dice: 0.2579
07/30 18:20:29 - mmengine - INFO - Iter(train) [13800/80000]  base_lr: 8.4333e-05 lr: 8.4333e-06  eta: 8:00:40  time: 0.4357  data_time: 0.0091  memory: 5265  grad_norm: 139.5623  loss: 9.6879  decode.loss_cls: 0.3322  decode.loss_mask: 0.2977  decode.loss_dice: 0.3087  decode.d0.loss_cls: 1.0203  decode.d0.loss_mask: 0.3380  decode.d0.loss_dice: 0.3652  decode.d1.loss_cls: 0.2977  decode.d1.loss_mask: 0.3027  decode.d1.loss_dice: 0.3308  decode.d2.loss_cls: 0.2832  decode.d2.loss_mask: 0.2967  decode.d2.loss_dice: 0.3076  decode.d3.loss_cls: 0.2325  decode.d3.loss_mask: 0.3023  decode.d3.loss_dice: 0.3151  decode.d4.loss_cls: 0.1840  decode.d4.loss_mask: 0.2958  decode.d4.loss_dice: 0.3146  decode.d5.loss_cls: 0.1931  decode.d5.loss_mask: 0.3029  decode.d5.loss_dice: 0.3247  decode.d6.loss_cls: 0.2766  decode.d6.loss_mask: 0.3047  decode.d6.loss_dice: 0.3238  decode.d7.loss_cls: 0.2973  decode.d7.loss_mask: 0.3017  decode.d7.loss_dice: 0.3164  decode.d8.loss_cls: 0.2974  decode.d8.loss_mask: 0.3039  decode.d8.loss_dice: 0.3203
07/30 18:20:50 - mmengine - INFO - Iter(train) [13850/80000]  base_lr: 8.4275e-05 lr: 8.4275e-06  eta: 8:00:18  time: 0.4348  data_time: 0.0091  memory: 5265  grad_norm: 62.6700  loss: 8.4858  decode.loss_cls: 0.2404  decode.loss_mask: 0.2267  decode.loss_dice: 0.2881  decode.d0.loss_cls: 1.0198  decode.d0.loss_mask: 0.2331  decode.d0.loss_dice: 0.3064  decode.d1.loss_cls: 0.3242  decode.d1.loss_mask: 0.2326  decode.d1.loss_dice: 0.3182  decode.d2.loss_cls: 0.2243  decode.d2.loss_mask: 0.2317  decode.d2.loss_dice: 0.2979  decode.d3.loss_cls: 0.2080  decode.d3.loss_mask: 0.2314  decode.d3.loss_dice: 0.3261  decode.d4.loss_cls: 0.2211  decode.d4.loss_mask: 0.2322  decode.d4.loss_dice: 0.3125  decode.d5.loss_cls: 0.2360  decode.d5.loss_mask: 0.2329  decode.d5.loss_dice: 0.2920  decode.d6.loss_cls: 0.2381  decode.d6.loss_mask: 0.2326  decode.d6.loss_dice: 0.2790  decode.d7.loss_cls: 0.2463  decode.d7.loss_mask: 0.2313  decode.d7.loss_dice: 0.2910  decode.d8.loss_cls: 0.1924  decode.d8.loss_mask: 0.2289  decode.d8.loss_dice: 0.3105
07/30 18:21:12 - mmengine - INFO - Iter(train) [13900/80000]  base_lr: 8.4218e-05 lr: 8.4218e-06  eta: 7:59:57  time: 0.4353  data_time: 0.0087  memory: 5265  grad_norm: 118.3880  loss: 10.9139  decode.loss_cls: 0.4480  decode.loss_mask: 0.2598  decode.loss_dice: 0.3203  decode.d0.loss_cls: 1.1685  decode.d0.loss_mask: 0.2820  decode.d0.loss_dice: 0.3757  decode.d1.loss_cls: 0.4757  decode.d1.loss_mask: 0.2648  decode.d1.loss_dice: 0.3312  decode.d2.loss_cls: 0.4049  decode.d2.loss_mask: 0.2587  decode.d2.loss_dice: 0.3159  decode.d3.loss_cls: 0.4485  decode.d3.loss_mask: 0.2554  decode.d3.loss_dice: 0.3362  decode.d4.loss_cls: 0.4145  decode.d4.loss_mask: 0.2626  decode.d4.loss_dice: 0.3303  decode.d5.loss_cls: 0.3776  decode.d5.loss_mask: 0.2593  decode.d5.loss_dice: 0.3364  decode.d6.loss_cls: 0.4037  decode.d6.loss_mask: 0.2644  decode.d6.loss_dice: 0.3614  decode.d7.loss_cls: 0.3761  decode.d7.loss_mask: 0.2570  decode.d7.loss_dice: 0.3370  decode.d8.loss_cls: 0.4061  decode.d8.loss_mask: 0.2611  decode.d8.loss_dice: 0.3207
07/30 18:21:34 - mmengine - INFO - Iter(train) [13950/80000]  base_lr: 8.4161e-05 lr: 8.4161e-06  eta: 7:59:35  time: 0.4349  data_time: 0.0090  memory: 5245  grad_norm: 76.8990  loss: 10.1136  decode.loss_cls: 0.2180  decode.loss_mask: 0.3376  decode.loss_dice: 0.3598  decode.d0.loss_cls: 0.9894  decode.d0.loss_mask: 0.3263  decode.d0.loss_dice: 0.3370  decode.d1.loss_cls: 0.2604  decode.d1.loss_mask: 0.3173  decode.d1.loss_dice: 0.3297  decode.d2.loss_cls: 0.2542  decode.d2.loss_mask: 0.3094  decode.d2.loss_dice: 0.3583  decode.d3.loss_cls: 0.2489  decode.d3.loss_mask: 0.3185  decode.d3.loss_dice: 0.3421  decode.d4.loss_cls: 0.3089  decode.d4.loss_mask: 0.3336  decode.d4.loss_dice: 0.3680  decode.d5.loss_cls: 0.2995  decode.d5.loss_mask: 0.3325  decode.d5.loss_dice: 0.3472  decode.d6.loss_cls: 0.2456  decode.d6.loss_mask: 0.3387  decode.d6.loss_dice: 0.3461  decode.d7.loss_cls: 0.2559  decode.d7.loss_mask: 0.3393  decode.d7.loss_dice: 0.3568  decode.d8.loss_cls: 0.2323  decode.d8.loss_mask: 0.3487  decode.d8.loss_dice: 0.3535
07/30 18:21:56 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 18:21:56 - mmengine - INFO - Iter(train) [14000/80000]  base_lr: 8.4103e-05 lr: 8.4103e-06  eta: 7:59:13  time: 0.4363  data_time: 0.0092  memory: 5278  grad_norm: 95.5314  loss: 9.4714  decode.loss_cls: 0.2680  decode.loss_mask: 0.3123  decode.loss_dice: 0.2768  decode.d0.loss_cls: 0.9602  decode.d0.loss_mask: 0.3295  decode.d0.loss_dice: 0.2943  decode.d1.loss_cls: 0.3742  decode.d1.loss_mask: 0.3257  decode.d1.loss_dice: 0.3039  decode.d2.loss_cls: 0.2647  decode.d2.loss_mask: 0.3106  decode.d2.loss_dice: 0.2843  decode.d3.loss_cls: 0.3002  decode.d3.loss_mask: 0.3102  decode.d3.loss_dice: 0.2882  decode.d4.loss_cls: 0.2823  decode.d4.loss_mask: 0.3115  decode.d4.loss_dice: 0.2801  decode.d5.loss_cls: 0.2273  decode.d5.loss_mask: 0.3085  decode.d5.loss_dice: 0.2803  decode.d6.loss_cls: 0.2623  decode.d6.loss_mask: 0.3110  decode.d6.loss_dice: 0.2820  decode.d7.loss_cls: 0.2848  decode.d7.loss_mask: 0.3136  decode.d7.loss_dice: 0.2850  decode.d8.loss_cls: 0.2513  decode.d8.loss_mask: 0.3068  decode.d8.loss_dice: 0.2814
07/30 18:22:17 - mmengine - INFO - Iter(train) [14050/80000]  base_lr: 8.4046e-05 lr: 8.4046e-06  eta: 7:58:51  time: 0.4347  data_time: 0.0090  memory: 5279  grad_norm: 85.0187  loss: 6.0847  decode.loss_cls: 0.0548  decode.loss_mask: 0.2138  decode.loss_dice: 0.2380  decode.d0.loss_cls: 0.9579  decode.d0.loss_mask: 0.2283  decode.d0.loss_dice: 0.2642  decode.d1.loss_cls: 0.1084  decode.d1.loss_mask: 0.2132  decode.d1.loss_dice: 0.2502  decode.d2.loss_cls: 0.0731  decode.d2.loss_mask: 0.2078  decode.d2.loss_dice: 0.2382  decode.d3.loss_cls: 0.0838  decode.d3.loss_mask: 0.2074  decode.d3.loss_dice: 0.2258  decode.d4.loss_cls: 0.0667  decode.d4.loss_mask: 0.2092  decode.d4.loss_dice: 0.2278  decode.d5.loss_cls: 0.0544  decode.d5.loss_mask: 0.2111  decode.d5.loss_dice: 0.2398  decode.d6.loss_cls: 0.0592  decode.d6.loss_mask: 0.2123  decode.d6.loss_dice: 0.2327  decode.d7.loss_cls: 0.0579  decode.d7.loss_mask: 0.2143  decode.d7.loss_dice: 0.2319  decode.d8.loss_cls: 0.0588  decode.d8.loss_mask: 0.2107  decode.d8.loss_dice: 0.2329
07/30 18:22:39 - mmengine - INFO - Iter(train) [14100/80000]  base_lr: 8.3989e-05 lr: 8.3989e-06  eta: 7:58:29  time: 0.4346  data_time: 0.0090  memory: 5244  grad_norm: 62.3376  loss: 8.5659  decode.loss_cls: 0.2003  decode.loss_mask: 0.2753  decode.loss_dice: 0.3011  decode.d0.loss_cls: 1.0226  decode.d0.loss_mask: 0.2849  decode.d0.loss_dice: 0.3006  decode.d1.loss_cls: 0.3078  decode.d1.loss_mask: 0.2823  decode.d1.loss_dice: 0.2803  decode.d2.loss_cls: 0.1991  decode.d2.loss_mask: 0.2817  decode.d2.loss_dice: 0.2797  decode.d3.loss_cls: 0.2539  decode.d3.loss_mask: 0.2783  decode.d3.loss_dice: 0.2566  decode.d4.loss_cls: 0.1997  decode.d4.loss_mask: 0.2762  decode.d4.loss_dice: 0.2786  decode.d5.loss_cls: 0.1595  decode.d5.loss_mask: 0.2754  decode.d5.loss_dice: 0.2882  decode.d6.loss_cls: 0.2119  decode.d6.loss_mask: 0.2727  decode.d6.loss_dice: 0.2878  decode.d7.loss_cls: 0.2026  decode.d7.loss_mask: 0.2777  decode.d7.loss_dice: 0.2988  decode.d8.loss_cls: 0.1588  decode.d8.loss_mask: 0.2752  decode.d8.loss_dice: 0.2982
07/30 18:23:01 - mmengine - INFO - Iter(train) [14150/80000]  base_lr: 8.3931e-05 lr: 8.3931e-06  eta: 7:58:07  time: 0.4362  data_time: 0.0090  memory: 5265  grad_norm: 77.5619  loss: 7.1239  decode.loss_cls: 0.1434  decode.loss_mask: 0.2162  decode.loss_dice: 0.2311  decode.d0.loss_cls: 0.9105  decode.d0.loss_mask: 0.2372  decode.d0.loss_dice: 0.2680  decode.d1.loss_cls: 0.2459  decode.d1.loss_mask: 0.2210  decode.d1.loss_dice: 0.2691  decode.d2.loss_cls: 0.1649  decode.d2.loss_mask: 0.2191  decode.d2.loss_dice: 0.2432  decode.d3.loss_cls: 0.1508  decode.d3.loss_mask: 0.2164  decode.d3.loss_dice: 0.2516  decode.d4.loss_cls: 0.1815  decode.d4.loss_mask: 0.2166  decode.d4.loss_dice: 0.2517  decode.d5.loss_cls: 0.1630  decode.d5.loss_mask: 0.2198  decode.d5.loss_dice: 0.2354  decode.d6.loss_cls: 0.1881  decode.d6.loss_mask: 0.2203  decode.d6.loss_dice: 0.2263  decode.d7.loss_cls: 0.1659  decode.d7.loss_mask: 0.2154  decode.d7.loss_dice: 0.2472  decode.d8.loss_cls: 0.1584  decode.d8.loss_mask: 0.2157  decode.d8.loss_dice: 0.2301
07/30 18:23:23 - mmengine - INFO - Iter(train) [14200/80000]  base_lr: 8.3874e-05 lr: 8.3874e-06  eta: 7:57:45  time: 0.4354  data_time: 0.0090  memory: 5261  grad_norm: 78.5976  loss: 7.2336  decode.loss_cls: 0.1199  decode.loss_mask: 0.2286  decode.loss_dice: 0.2904  decode.d0.loss_cls: 1.0504  decode.d0.loss_mask: 0.2276  decode.d0.loss_dice: 0.2814  decode.d1.loss_cls: 0.1333  decode.d1.loss_mask: 0.2259  decode.d1.loss_dice: 0.2752  decode.d2.loss_cls: 0.1560  decode.d2.loss_mask: 0.2267  decode.d2.loss_dice: 0.2712  decode.d3.loss_cls: 0.1876  decode.d3.loss_mask: 0.2247  decode.d3.loss_dice: 0.2794  decode.d4.loss_cls: 0.1530  decode.d4.loss_mask: 0.2297  decode.d4.loss_dice: 0.2980  decode.d5.loss_cls: 0.1234  decode.d5.loss_mask: 0.2203  decode.d5.loss_dice: 0.2849  decode.d6.loss_cls: 0.0810  decode.d6.loss_mask: 0.2165  decode.d6.loss_dice: 0.2747  decode.d7.loss_cls: 0.0901  decode.d7.loss_mask: 0.2220  decode.d7.loss_dice: 0.2605  decode.d8.loss_cls: 0.1021  decode.d8.loss_mask: 0.2253  decode.d8.loss_dice: 0.2737
07/30 18:23:44 - mmengine - INFO - Iter(train) [14250/80000]  base_lr: 8.3817e-05 lr: 8.3817e-06  eta: 7:57:23  time: 0.4356  data_time: 0.0092  memory: 5245  grad_norm: 102.2085  loss: 11.3262  decode.loss_cls: 0.4448  decode.loss_mask: 0.2526  decode.loss_dice: 0.3412  decode.d0.loss_cls: 1.2661  decode.d0.loss_mask: 0.2341  decode.d0.loss_dice: 0.3498  decode.d1.loss_cls: 0.5242  decode.d1.loss_mask: 0.2237  decode.d1.loss_dice: 0.3402  decode.d2.loss_cls: 0.4817  decode.d2.loss_mask: 0.2263  decode.d2.loss_dice: 0.3374  decode.d3.loss_cls: 0.4513  decode.d3.loss_mask: 0.2213  decode.d3.loss_dice: 0.3047  decode.d4.loss_cls: 0.4548  decode.d4.loss_mask: 0.2222  decode.d4.loss_dice: 0.3366  decode.d5.loss_cls: 0.5131  decode.d5.loss_mask: 0.2244  decode.d5.loss_dice: 0.3476  decode.d6.loss_cls: 0.4817  decode.d6.loss_mask: 0.2324  decode.d6.loss_dice: 0.3530  decode.d7.loss_cls: 0.4757  decode.d7.loss_mask: 0.2550  decode.d7.loss_dice: 0.3503  decode.d8.loss_cls: 0.4788  decode.d8.loss_mask: 0.2496  decode.d8.loss_dice: 0.3518
07/30 18:24:06 - mmengine - INFO - Iter(train) [14300/80000]  base_lr: 8.3759e-05 lr: 8.3759e-06  eta: 7:57:01  time: 0.4354  data_time: 0.0090  memory: 5303  grad_norm: 179.4107  loss: 11.9617  decode.loss_cls: 0.2913  decode.loss_mask: 0.4209  decode.loss_dice: 0.3284  decode.d0.loss_cls: 1.2149  decode.d0.loss_mask: 0.4203  decode.d0.loss_dice: 0.3758  decode.d1.loss_cls: 0.4453  decode.d1.loss_mask: 0.4029  decode.d1.loss_dice: 0.3598  decode.d2.loss_cls: 0.4150  decode.d2.loss_mask: 0.4284  decode.d2.loss_dice: 0.3578  decode.d3.loss_cls: 0.3336  decode.d3.loss_mask: 0.4352  decode.d3.loss_dice: 0.3487  decode.d4.loss_cls: 0.3441  decode.d4.loss_mask: 0.4241  decode.d4.loss_dice: 0.3392  decode.d5.loss_cls: 0.3134  decode.d5.loss_mask: 0.4261  decode.d5.loss_dice: 0.3518  decode.d6.loss_cls: 0.2936  decode.d6.loss_mask: 0.4339  decode.d6.loss_dice: 0.3463  decode.d7.loss_cls: 0.2678  decode.d7.loss_mask: 0.4318  decode.d7.loss_dice: 0.3449  decode.d8.loss_cls: 0.2779  decode.d8.loss_mask: 0.4206  decode.d8.loss_dice: 0.3681
07/30 18:24:28 - mmengine - INFO - Iter(train) [14350/80000]  base_lr: 8.3702e-05 lr: 8.3702e-06  eta: 7:56:40  time: 0.4365  data_time: 0.0091  memory: 5265  grad_norm: 79.5046  loss: 9.9462  decode.loss_cls: 0.3573  decode.loss_mask: 0.2612  decode.loss_dice: 0.2836  decode.d0.loss_cls: 1.1184  decode.d0.loss_mask: 0.2631  decode.d0.loss_dice: 0.3344  decode.d1.loss_cls: 0.4286  decode.d1.loss_mask: 0.2557  decode.d1.loss_dice: 0.2814  decode.d2.loss_cls: 0.4583  decode.d2.loss_mask: 0.2556  decode.d2.loss_dice: 0.2875  decode.d3.loss_cls: 0.3500  decode.d3.loss_mask: 0.2617  decode.d3.loss_dice: 0.2650  decode.d4.loss_cls: 0.3157  decode.d4.loss_mask: 0.2558  decode.d4.loss_dice: 0.2898  decode.d5.loss_cls: 0.3723  decode.d5.loss_mask: 0.2605  decode.d5.loss_dice: 0.2982  decode.d6.loss_cls: 0.3681  decode.d6.loss_mask: 0.2603  decode.d6.loss_dice: 0.2728  decode.d7.loss_cls: 0.3821  decode.d7.loss_mask: 0.2584  decode.d7.loss_dice: 0.2702  decode.d8.loss_cls: 0.3592  decode.d8.loss_mask: 0.2590  decode.d8.loss_dice: 0.2623
07/30 18:24:50 - mmengine - INFO - Iter(train) [14400/80000]  base_lr: 8.3644e-05 lr: 8.3644e-06  eta: 7:56:18  time: 0.4349  data_time: 0.0090  memory: 5246  grad_norm: 132.0224  loss: 9.4427  decode.loss_cls: 0.1788  decode.loss_mask: 0.2583  decode.loss_dice: 0.3068  decode.d0.loss_cls: 1.2887  decode.d0.loss_mask: 0.3000  decode.d0.loss_dice: 0.3556  decode.d1.loss_cls: 0.3884  decode.d1.loss_mask: 0.2794  decode.d1.loss_dice: 0.3215  decode.d2.loss_cls: 0.3229  decode.d2.loss_mask: 0.2581  decode.d2.loss_dice: 0.3244  decode.d3.loss_cls: 0.2836  decode.d3.loss_mask: 0.2659  decode.d3.loss_dice: 0.2925  decode.d4.loss_cls: 0.2114  decode.d4.loss_mask: 0.2700  decode.d4.loss_dice: 0.3265  decode.d5.loss_cls: 0.2412  decode.d5.loss_mask: 0.2698  decode.d5.loss_dice: 0.3186  decode.d6.loss_cls: 0.2448  decode.d6.loss_mask: 0.2571  decode.d6.loss_dice: 0.3023  decode.d7.loss_cls: 0.2571  decode.d7.loss_mask: 0.2535  decode.d7.loss_dice: 0.3153  decode.d8.loss_cls: 0.1907  decode.d8.loss_mask: 0.2579  decode.d8.loss_dice: 0.3017
07/30 18:25:12 - mmengine - INFO - Iter(train) [14450/80000]  base_lr: 8.3587e-05 lr: 8.3587e-06  eta: 7:55:56  time: 0.4352  data_time: 0.0091  memory: 5321  grad_norm: 72.8851  loss: 6.7710  decode.loss_cls: 0.1339  decode.loss_mask: 0.2089  decode.loss_dice: 0.2330  decode.d0.loss_cls: 1.0035  decode.d0.loss_mask: 0.1772  decode.d0.loss_dice: 0.2218  decode.d1.loss_cls: 0.1750  decode.d1.loss_mask: 0.1842  decode.d1.loss_dice: 0.2279  decode.d2.loss_cls: 0.1694  decode.d2.loss_mask: 0.1752  decode.d2.loss_dice: 0.2162  decode.d3.loss_cls: 0.1655  decode.d3.loss_mask: 0.1928  decode.d3.loss_dice: 0.2218  decode.d4.loss_cls: 0.2068  decode.d4.loss_mask: 0.1797  decode.d4.loss_dice: 0.2242  decode.d5.loss_cls: 0.2060  decode.d5.loss_mask: 0.1810  decode.d5.loss_dice: 0.2373  decode.d6.loss_cls: 0.2117  decode.d6.loss_mask: 0.1763  decode.d6.loss_dice: 0.2223  decode.d7.loss_cls: 0.1786  decode.d7.loss_mask: 0.2101  decode.d7.loss_dice: 0.2327  decode.d8.loss_cls: 0.1606  decode.d8.loss_mask: 0.2029  decode.d8.loss_dice: 0.2342
07/30 18:25:33 - mmengine - INFO - Iter(train) [14500/80000]  base_lr: 8.3530e-05 lr: 8.3530e-06  eta: 7:55:34  time: 0.4357  data_time: 0.0089  memory: 5244  grad_norm: 106.2838  loss: 9.6345  decode.loss_cls: 0.3400  decode.loss_mask: 0.2572  decode.loss_dice: 0.2973  decode.d0.loss_cls: 0.9831  decode.d0.loss_mask: 0.2558  decode.d0.loss_dice: 0.3034  decode.d1.loss_cls: 0.5040  decode.d1.loss_mask: 0.2600  decode.d1.loss_dice: 0.3001  decode.d2.loss_cls: 0.3785  decode.d2.loss_mask: 0.2573  decode.d2.loss_dice: 0.2877  decode.d3.loss_cls: 0.3452  decode.d3.loss_mask: 0.2489  decode.d3.loss_dice: 0.2802  decode.d4.loss_cls: 0.3009  decode.d4.loss_mask: 0.2518  decode.d4.loss_dice: 0.2735  decode.d5.loss_cls: 0.3593  decode.d5.loss_mask: 0.2543  decode.d5.loss_dice: 0.2897  decode.d6.loss_cls: 0.3552  decode.d6.loss_mask: 0.2480  decode.d6.loss_dice: 0.3001  decode.d7.loss_cls: 0.3055  decode.d7.loss_mask: 0.2562  decode.d7.loss_dice: 0.3120  decode.d8.loss_cls: 0.2837  decode.d8.loss_mask: 0.2591  decode.d8.loss_dice: 0.2868
07/30 18:25:55 - mmengine - INFO - Iter(train) [14550/80000]  base_lr: 8.3472e-05 lr: 8.3472e-06  eta: 7:55:12  time: 0.4357  data_time: 0.0091  memory: 5279  grad_norm: 106.9319  loss: 9.6294  decode.loss_cls: 0.3239  decode.loss_mask: 0.2363  decode.loss_dice: 0.2995  decode.d0.loss_cls: 1.2347  decode.d0.loss_mask: 0.2433  decode.d0.loss_dice: 0.3302  decode.d1.loss_cls: 0.3896  decode.d1.loss_mask: 0.2580  decode.d1.loss_dice: 0.3078  decode.d2.loss_cls: 0.3393  decode.d2.loss_mask: 0.2518  decode.d2.loss_dice: 0.3165  decode.d3.loss_cls: 0.2976  decode.d3.loss_mask: 0.2415  decode.d3.loss_dice: 0.2825  decode.d4.loss_cls: 0.2890  decode.d4.loss_mask: 0.2380  decode.d4.loss_dice: 0.2894  decode.d5.loss_cls: 0.3712  decode.d5.loss_mask: 0.2269  decode.d5.loss_dice: 0.2882  decode.d6.loss_cls: 0.2962  decode.d6.loss_mask: 0.2387  decode.d6.loss_dice: 0.3013  decode.d7.loss_cls: 0.3332  decode.d7.loss_mask: 0.2388  decode.d7.loss_dice: 0.2941  decode.d8.loss_cls: 0.3248  decode.d8.loss_mask: 0.2391  decode.d8.loss_dice: 0.3080
07/30 18:26:17 - mmengine - INFO - Iter(train) [14600/80000]  base_lr: 8.3415e-05 lr: 8.3415e-06  eta: 7:54:51  time: 0.4348  data_time: 0.0089  memory: 5323  grad_norm: 86.1396  loss: 11.7235  decode.loss_cls: 0.4532  decode.loss_mask: 0.2934  decode.loss_dice: 0.3200  decode.d0.loss_cls: 1.1870  decode.d0.loss_mask: 0.3030  decode.d0.loss_dice: 0.4277  decode.d1.loss_cls: 0.5095  decode.d1.loss_mask: 0.2854  decode.d1.loss_dice: 0.3313  decode.d2.loss_cls: 0.4686  decode.d2.loss_mask: 0.2814  decode.d2.loss_dice: 0.3295  decode.d3.loss_cls: 0.5028  decode.d3.loss_mask: 0.2932  decode.d3.loss_dice: 0.3333  decode.d4.loss_cls: 0.4553  decode.d4.loss_mask: 0.2944  decode.d4.loss_dice: 0.3489  decode.d5.loss_cls: 0.4321  decode.d5.loss_mask: 0.2882  decode.d5.loss_dice: 0.3480  decode.d6.loss_cls: 0.4657  decode.d6.loss_mask: 0.2879  decode.d6.loss_dice: 0.3090  decode.d7.loss_cls: 0.4081  decode.d7.loss_mask: 0.3277  decode.d7.loss_dice: 0.2977  decode.d8.loss_cls: 0.4909  decode.d8.loss_mask: 0.3130  decode.d8.loss_dice: 0.3372
07/30 18:26:39 - mmengine - INFO - Iter(train) [14650/80000]  base_lr: 8.3358e-05 lr: 8.3358e-06  eta: 7:54:29  time: 0.4353  data_time: 0.0091  memory: 5277  grad_norm: 78.8678  loss: 9.3864  decode.loss_cls: 0.2747  decode.loss_mask: 0.2462  decode.loss_dice: 0.2862  decode.d0.loss_cls: 1.0902  decode.d0.loss_mask: 0.2582  decode.d0.loss_dice: 0.3223  decode.d1.loss_cls: 0.3493  decode.d1.loss_mask: 0.2504  decode.d1.loss_dice: 0.2914  decode.d2.loss_cls: 0.3268  decode.d2.loss_mask: 0.2488  decode.d2.loss_dice: 0.2924  decode.d3.loss_cls: 0.3088  decode.d3.loss_mask: 0.2486  decode.d3.loss_dice: 0.3167  decode.d4.loss_cls: 0.3144  decode.d4.loss_mask: 0.2457  decode.d4.loss_dice: 0.3184  decode.d5.loss_cls: 0.3106  decode.d5.loss_mask: 0.2461  decode.d5.loss_dice: 0.2982  decode.d6.loss_cls: 0.2675  decode.d6.loss_mask: 0.2438  decode.d6.loss_dice: 0.3248  decode.d7.loss_cls: 0.2893  decode.d7.loss_mask: 0.2459  decode.d7.loss_dice: 0.3133  decode.d8.loss_cls: 0.2996  decode.d8.loss_mask: 0.2486  decode.d8.loss_dice: 0.3092
07/30 18:27:00 - mmengine - INFO - Iter(train) [14700/80000]  base_lr: 8.3300e-05 lr: 8.3300e-06  eta: 7:54:07  time: 0.4358  data_time: 0.0093  memory: 5304  grad_norm: 253.8211  loss: 11.2317  decode.loss_cls: 0.2925  decode.loss_mask: 0.3478  decode.loss_dice: 0.3808  decode.d0.loss_cls: 1.0894  decode.d0.loss_mask: 0.3711  decode.d0.loss_dice: 0.3885  decode.d1.loss_cls: 0.4255  decode.d1.loss_mask: 0.3347  decode.d1.loss_dice: 0.3502  decode.d2.loss_cls: 0.3638  decode.d2.loss_mask: 0.3533  decode.d2.loss_dice: 0.3472  decode.d3.loss_cls: 0.3325  decode.d3.loss_mask: 0.3334  decode.d3.loss_dice: 0.3571  decode.d4.loss_cls: 0.3388  decode.d4.loss_mask: 0.3320  decode.d4.loss_dice: 0.3658  decode.d5.loss_cls: 0.3709  decode.d5.loss_mask: 0.3241  decode.d5.loss_dice: 0.3504  decode.d6.loss_cls: 0.3235  decode.d6.loss_mask: 0.3168  decode.d6.loss_dice: 0.3522  decode.d7.loss_cls: 0.3263  decode.d7.loss_mask: 0.3187  decode.d7.loss_dice: 0.3872  decode.d8.loss_cls: 0.3177  decode.d8.loss_mask: 0.3548  decode.d8.loss_dice: 0.3846
07/30 18:27:22 - mmengine - INFO - Iter(train) [14750/80000]  base_lr: 8.3243e-05 lr: 8.3243e-06  eta: 7:53:45  time: 0.4355  data_time: 0.0091  memory: 5265  grad_norm: 39.9768  loss: 7.8022  decode.loss_cls: 0.2067  decode.loss_mask: 0.2683  decode.loss_dice: 0.2787  decode.d0.loss_cls: 1.0047  decode.d0.loss_mask: 0.2740  decode.d0.loss_dice: 0.2750  decode.d1.loss_cls: 0.1966  decode.d1.loss_mask: 0.2720  decode.d1.loss_dice: 0.2722  decode.d2.loss_cls: 0.1404  decode.d2.loss_mask: 0.2715  decode.d2.loss_dice: 0.2777  decode.d3.loss_cls: 0.1419  decode.d3.loss_mask: 0.2729  decode.d3.loss_dice: 0.2753  decode.d4.loss_cls: 0.1258  decode.d4.loss_mask: 0.2792  decode.d4.loss_dice: 0.2882  decode.d5.loss_cls: 0.1090  decode.d5.loss_mask: 0.2741  decode.d5.loss_dice: 0.2638  decode.d6.loss_cls: 0.1685  decode.d6.loss_mask: 0.2687  decode.d6.loss_dice: 0.2796  decode.d7.loss_cls: 0.1274  decode.d7.loss_mask: 0.2664  decode.d7.loss_dice: 0.2768  decode.d8.loss_cls: 0.1090  decode.d8.loss_mask: 0.2678  decode.d8.loss_dice: 0.2699
07/30 18:27:44 - mmengine - INFO - Iter(train) [14800/80000]  base_lr: 8.3185e-05 lr: 8.3185e-06  eta: 7:53:23  time: 0.4346  data_time: 0.0090  memory: 5227  grad_norm: 87.1956  loss: 8.9373  decode.loss_cls: 0.2856  decode.loss_mask: 0.2352  decode.loss_dice: 0.2912  decode.d0.loss_cls: 1.0468  decode.d0.loss_mask: 0.2424  decode.d0.loss_dice: 0.2791  decode.d1.loss_cls: 0.2884  decode.d1.loss_mask: 0.2407  decode.d1.loss_dice: 0.2959  decode.d2.loss_cls: 0.2495  decode.d2.loss_mask: 0.2390  decode.d2.loss_dice: 0.2931  decode.d3.loss_cls: 0.2541  decode.d3.loss_mask: 0.2388  decode.d3.loss_dice: 0.3073  decode.d4.loss_cls: 0.3726  decode.d4.loss_mask: 0.2402  decode.d4.loss_dice: 0.3019  decode.d5.loss_cls: 0.2694  decode.d5.loss_mask: 0.2348  decode.d5.loss_dice: 0.2981  decode.d6.loss_cls: 0.2762  decode.d6.loss_mask: 0.2380  decode.d6.loss_dice: 0.2848  decode.d7.loss_cls: 0.2909  decode.d7.loss_mask: 0.2354  decode.d7.loss_dice: 0.2873  decode.d8.loss_cls: 0.3008  decode.d8.loss_mask: 0.2370  decode.d8.loss_dice: 0.2831
07/30 18:28:06 - mmengine - INFO - Iter(train) [14850/80000]  base_lr: 8.3128e-05 lr: 8.3128e-06  eta: 7:53:01  time: 0.4348  data_time: 0.0087  memory: 5261  grad_norm: 92.2569  loss: 7.1111  decode.loss_cls: 0.1543  decode.loss_mask: 0.2075  decode.loss_dice: 0.2492  decode.d0.loss_cls: 1.1228  decode.d0.loss_mask: 0.2257  decode.d0.loss_dice: 0.2372  decode.d1.loss_cls: 0.2213  decode.d1.loss_mask: 0.1953  decode.d1.loss_dice: 0.2364  decode.d2.loss_cls: 0.1826  decode.d2.loss_mask: 0.1913  decode.d2.loss_dice: 0.2387  decode.d3.loss_cls: 0.1647  decode.d3.loss_mask: 0.1947  decode.d3.loss_dice: 0.2383  decode.d4.loss_cls: 0.1637  decode.d4.loss_mask: 0.1981  decode.d4.loss_dice: 0.2394  decode.d5.loss_cls: 0.1416  decode.d5.loss_mask: 0.2065  decode.d5.loss_dice: 0.2369  decode.d6.loss_cls: 0.1756  decode.d6.loss_mask: 0.2042  decode.d6.loss_dice: 0.2385  decode.d7.loss_cls: 0.1730  decode.d7.loss_mask: 0.2113  decode.d7.loss_dice: 0.2350  decode.d8.loss_cls: 0.1614  decode.d8.loss_mask: 0.2184  decode.d8.loss_dice: 0.2474
07/30 18:28:27 - mmengine - INFO - Iter(train) [14900/80000]  base_lr: 8.3070e-05 lr: 8.3070e-06  eta: 7:52:39  time: 0.4348  data_time: 0.0090  memory: 5244  grad_norm: 65.0676  loss: 9.1647  decode.loss_cls: 0.3225  decode.loss_mask: 0.2490  decode.loss_dice: 0.2848  decode.d0.loss_cls: 0.9854  decode.d0.loss_mask: 0.2754  decode.d0.loss_dice: 0.3064  decode.d1.loss_cls: 0.3360  decode.d1.loss_mask: 0.2538  decode.d1.loss_dice: 0.2770  decode.d2.loss_cls: 0.3069  decode.d2.loss_mask: 0.2553  decode.d2.loss_dice: 0.2923  decode.d3.loss_cls: 0.2712  decode.d3.loss_mask: 0.2549  decode.d3.loss_dice: 0.2582  decode.d4.loss_cls: 0.3478  decode.d4.loss_mask: 0.2506  decode.d4.loss_dice: 0.2774  decode.d5.loss_cls: 0.3127  decode.d5.loss_mask: 0.2537  decode.d5.loss_dice: 0.2679  decode.d6.loss_cls: 0.3142  decode.d6.loss_mask: 0.2519  decode.d6.loss_dice: 0.2657  decode.d7.loss_cls: 0.2866  decode.d7.loss_mask: 0.2543  decode.d7.loss_dice: 0.2778  decode.d8.loss_cls: 0.3288  decode.d8.loss_mask: 0.2525  decode.d8.loss_dice: 0.2936
07/30 18:28:49 - mmengine - INFO - Iter(train) [14950/80000]  base_lr: 8.3013e-05 lr: 8.3013e-06  eta: 7:52:17  time: 0.4344  data_time: 0.0090  memory: 5279  grad_norm: 140.6742  loss: 9.6697  decode.loss_cls: 0.3035  decode.loss_mask: 0.2758  decode.loss_dice: 0.3102  decode.d0.loss_cls: 1.1037  decode.d0.loss_mask: 0.2805  decode.d0.loss_dice: 0.3284  decode.d1.loss_cls: 0.3662  decode.d1.loss_mask: 0.2628  decode.d1.loss_dice: 0.3120  decode.d2.loss_cls: 0.3339  decode.d2.loss_mask: 0.2748  decode.d2.loss_dice: 0.3025  decode.d3.loss_cls: 0.2669  decode.d3.loss_mask: 0.2871  decode.d3.loss_dice: 0.2972  decode.d4.loss_cls: 0.3620  decode.d4.loss_mask: 0.2363  decode.d4.loss_dice: 0.2976  decode.d5.loss_cls: 0.2650  decode.d5.loss_mask: 0.2863  decode.d5.loss_dice: 0.3073  decode.d6.loss_cls: 0.2621  decode.d6.loss_mask: 0.3041  decode.d6.loss_dice: 0.3149  decode.d7.loss_cls: 0.2838  decode.d7.loss_mask: 0.2748  decode.d7.loss_dice: 0.3096  decode.d8.loss_cls: 0.2768  decode.d8.loss_mask: 0.2670  decode.d8.loss_dice: 0.3166
07/30 18:29:11 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 18:29:11 - mmengine - INFO - Iter(train) [15000/80000]  base_lr: 8.2956e-05 lr: 8.2956e-06  eta: 7:51:55  time: 0.4353  data_time: 0.0089  memory: 5279  grad_norm: 75.8990  loss: 7.6162  decode.loss_cls: 0.1454  decode.loss_mask: 0.2358  decode.loss_dice: 0.3026  decode.d0.loss_cls: 1.0493  decode.d0.loss_mask: 0.2371  decode.d0.loss_dice: 0.3032  decode.d1.loss_cls: 0.2485  decode.d1.loss_mask: 0.2307  decode.d1.loss_dice: 0.2984  decode.d2.loss_cls: 0.1307  decode.d2.loss_mask: 0.2354  decode.d2.loss_dice: 0.3289  decode.d3.loss_cls: 0.1093  decode.d3.loss_mask: 0.2333  decode.d3.loss_dice: 0.3139  decode.d4.loss_cls: 0.1015  decode.d4.loss_mask: 0.2305  decode.d4.loss_dice: 0.3057  decode.d5.loss_cls: 0.0944  decode.d5.loss_mask: 0.2323  decode.d5.loss_dice: 0.3120  decode.d6.loss_cls: 0.1328  decode.d6.loss_mask: 0.2302  decode.d6.loss_dice: 0.2884  decode.d7.loss_cls: 0.1278  decode.d7.loss_mask: 0.2359  decode.d7.loss_dice: 0.2901  decode.d8.loss_cls: 0.1092  decode.d8.loss_mask: 0.2307  decode.d8.loss_dice: 0.2922
07/30 18:29:11 - mmengine - INFO - Saving checkpoint at 15000 iterations
07/30 18:29:35 - mmengine - INFO - Iter(train) [15050/80000]  base_lr: 8.2898e-05 lr: 8.2898e-06  eta: 7:51:43  time: 0.4385  data_time: 0.0089  memory: 5265  grad_norm: 72.3366  loss: 9.4448  decode.loss_cls: 0.3394  decode.loss_mask: 0.2486  decode.loss_dice: 0.2985  decode.d0.loss_cls: 1.0251  decode.d0.loss_mask: 0.2544  decode.d0.loss_dice: 0.3459  decode.d1.loss_cls: 0.3646  decode.d1.loss_mask: 0.2499  decode.d1.loss_dice: 0.3047  decode.d2.loss_cls: 0.2949  decode.d2.loss_mask: 0.2525  decode.d2.loss_dice: 0.3027  decode.d3.loss_cls: 0.2548  decode.d3.loss_mask: 0.2540  decode.d3.loss_dice: 0.2954  decode.d4.loss_cls: 0.3151  decode.d4.loss_mask: 0.2488  decode.d4.loss_dice: 0.3157  decode.d5.loss_cls: 0.3222  decode.d5.loss_mask: 0.2502  decode.d5.loss_dice: 0.3092  decode.d6.loss_cls: 0.3087  decode.d6.loss_mask: 0.2493  decode.d6.loss_dice: 0.3102  decode.d7.loss_cls: 0.2861  decode.d7.loss_mask: 0.2504  decode.d7.loss_dice: 0.3231  decode.d8.loss_cls: 0.3298  decode.d8.loss_mask: 0.2465  decode.d8.loss_dice: 0.2943
07/30 18:29:57 - mmengine - INFO - Iter(train) [15100/80000]  base_lr: 8.2841e-05 lr: 8.2841e-06  eta: 7:51:22  time: 0.4399  data_time: 0.0089  memory: 5278  grad_norm: 72.3587  loss: 11.0191  decode.loss_cls: 0.2865  decode.loss_mask: 0.2941  decode.loss_dice: 0.3487  decode.d0.loss_cls: 1.1087  decode.d0.loss_mask: 0.2960  decode.d0.loss_dice: 0.3951  decode.d1.loss_cls: 0.4499  decode.d1.loss_mask: 0.3073  decode.d1.loss_dice: 0.3616  decode.d2.loss_cls: 0.4207  decode.d2.loss_mask: 0.3020  decode.d2.loss_dice: 0.3739  decode.d3.loss_cls: 0.4451  decode.d3.loss_mask: 0.3038  decode.d3.loss_dice: 0.3692  decode.d4.loss_cls: 0.2873  decode.d4.loss_mask: 0.3055  decode.d4.loss_dice: 0.3953  decode.d5.loss_cls: 0.3422  decode.d5.loss_mask: 0.3082  decode.d5.loss_dice: 0.3801  decode.d6.loss_cls: 0.3739  decode.d6.loss_mask: 0.3038  decode.d6.loss_dice: 0.3373  decode.d7.loss_cls: 0.2750  decode.d7.loss_mask: 0.3010  decode.d7.loss_dice: 0.3389  decode.d8.loss_cls: 0.3807  decode.d8.loss_mask: 0.2979  decode.d8.loss_dice: 0.3295
07/30 18:30:19 - mmengine - INFO - Iter(train) [15150/80000]  base_lr: 8.2783e-05 lr: 8.2783e-06  eta: 7:51:00  time: 0.4362  data_time: 0.0090  memory: 5265  grad_norm: 67.1099  loss: 7.6480  decode.loss_cls: 0.1702  decode.loss_mask: 0.2226  decode.loss_dice: 0.2749  decode.d0.loss_cls: 1.0460  decode.d0.loss_mask: 0.2408  decode.d0.loss_dice: 0.2772  decode.d1.loss_cls: 0.3133  decode.d1.loss_mask: 0.2242  decode.d1.loss_dice: 0.2628  decode.d2.loss_cls: 0.2743  decode.d2.loss_mask: 0.2241  decode.d2.loss_dice: 0.2621  decode.d3.loss_cls: 0.1977  decode.d3.loss_mask: 0.2233  decode.d3.loss_dice: 0.2642  decode.d4.loss_cls: 0.1724  decode.d4.loss_mask: 0.2273  decode.d4.loss_dice: 0.2656  decode.d5.loss_cls: 0.1083  decode.d5.loss_mask: 0.2209  decode.d5.loss_dice: 0.2740  decode.d6.loss_cls: 0.1493  decode.d6.loss_mask: 0.2244  decode.d6.loss_dice: 0.2606  decode.d7.loss_cls: 0.1279  decode.d7.loss_mask: 0.2270  decode.d7.loss_dice: 0.2736  decode.d8.loss_cls: 0.1399  decode.d8.loss_mask: 0.2252  decode.d8.loss_dice: 0.2738
07/30 18:30:40 - mmengine - INFO - Iter(train) [15200/80000]  base_lr: 8.2726e-05 lr: 8.2726e-06  eta: 7:50:38  time: 0.4369  data_time: 0.0089  memory: 5246  grad_norm: 89.2578  loss: 8.2439  decode.loss_cls: 0.1958  decode.loss_mask: 0.2585  decode.loss_dice: 0.2649  decode.d0.loss_cls: 1.2260  decode.d0.loss_mask: 0.2642  decode.d0.loss_dice: 0.2818  decode.d1.loss_cls: 0.2765  decode.d1.loss_mask: 0.2545  decode.d1.loss_dice: 0.2682  decode.d2.loss_cls: 0.1817  decode.d2.loss_mask: 0.2505  decode.d2.loss_dice: 0.2656  decode.d3.loss_cls: 0.1587  decode.d3.loss_mask: 0.2537  decode.d3.loss_dice: 0.2662  decode.d4.loss_cls: 0.2044  decode.d4.loss_mask: 0.2530  decode.d4.loss_dice: 0.2617  decode.d5.loss_cls: 0.2078  decode.d5.loss_mask: 0.2560  decode.d5.loss_dice: 0.2659  decode.d6.loss_cls: 0.1554  decode.d6.loss_mask: 0.2586  decode.d6.loss_dice: 0.2689  decode.d7.loss_cls: 0.2168  decode.d7.loss_mask: 0.2572  decode.d7.loss_dice: 0.2730  decode.d8.loss_cls: 0.1766  decode.d8.loss_mask: 0.2585  decode.d8.loss_dice: 0.2633
07/30 18:31:02 - mmengine - INFO - Iter(train) [15250/80000]  base_lr: 8.2668e-05 lr: 8.2668e-06  eta: 7:50:16  time: 0.4350  data_time: 0.0089  memory: 5261  grad_norm: 100.8122  loss: 8.9964  decode.loss_cls: 0.2858  decode.loss_mask: 0.2535  decode.loss_dice: 0.2707  decode.d0.loss_cls: 1.1157  decode.d0.loss_mask: 0.2676  decode.d0.loss_dice: 0.3012  decode.d1.loss_cls: 0.3557  decode.d1.loss_mask: 0.2532  decode.d1.loss_dice: 0.2654  decode.d2.loss_cls: 0.3045  decode.d2.loss_mask: 0.2589  decode.d2.loss_dice: 0.2818  decode.d3.loss_cls: 0.3153  decode.d3.loss_mask: 0.2546  decode.d3.loss_dice: 0.2647  decode.d4.loss_cls: 0.2814  decode.d4.loss_mask: 0.2515  decode.d4.loss_dice: 0.2681  decode.d5.loss_cls: 0.2787  decode.d5.loss_mask: 0.2492  decode.d5.loss_dice: 0.2722  decode.d6.loss_cls: 0.2708  decode.d6.loss_mask: 0.2502  decode.d6.loss_dice: 0.2607  decode.d7.loss_cls: 0.2688  decode.d7.loss_mask: 0.2519  decode.d7.loss_dice: 0.2750  decode.d8.loss_cls: 0.2553  decode.d8.loss_mask: 0.2500  decode.d8.loss_dice: 0.2640
07/30 18:31:24 - mmengine - INFO - Iter(train) [15300/80000]  base_lr: 8.2611e-05 lr: 8.2611e-06  eta: 7:49:55  time: 0.4351  data_time: 0.0088  memory: 5246  grad_norm: 49.0799  loss: 7.0961  decode.loss_cls: 0.1999  decode.loss_mask: 0.1835  decode.loss_dice: 0.2506  decode.d0.loss_cls: 1.1180  decode.d0.loss_mask: 0.1923  decode.d0.loss_dice: 0.2255  decode.d1.loss_cls: 0.2246  decode.d1.loss_mask: 0.1912  decode.d1.loss_dice: 0.2658  decode.d2.loss_cls: 0.1738  decode.d2.loss_mask: 0.1868  decode.d2.loss_dice: 0.2395  decode.d3.loss_cls: 0.1767  decode.d3.loss_mask: 0.1852  decode.d3.loss_dice: 0.2301  decode.d4.loss_cls: 0.1929  decode.d4.loss_mask: 0.1857  decode.d4.loss_dice: 0.2294  decode.d5.loss_cls: 0.1950  decode.d5.loss_mask: 0.1843  decode.d5.loss_dice: 0.2413  decode.d6.loss_cls: 0.1557  decode.d6.loss_mask: 0.1861  decode.d6.loss_dice: 0.2523  decode.d7.loss_cls: 0.1977  decode.d7.loss_mask: 0.1863  decode.d7.loss_dice: 0.2414  decode.d8.loss_cls: 0.1866  decode.d8.loss_mask: 0.1830  decode.d8.loss_dice: 0.2348
07/30 18:31:46 - mmengine - INFO - Iter(train) [15350/80000]  base_lr: 8.2554e-05 lr: 8.2554e-06  eta: 7:49:33  time: 0.4357  data_time: 0.0090  memory: 5261  grad_norm: 151.0558  loss: 9.4803  decode.loss_cls: 0.2629  decode.loss_mask: 0.2691  decode.loss_dice: 0.2795  decode.d0.loss_cls: 1.2590  decode.d0.loss_mask: 0.2718  decode.d0.loss_dice: 0.2967  decode.d1.loss_cls: 0.3496  decode.d1.loss_mask: 0.2979  decode.d1.loss_dice: 0.2892  decode.d2.loss_cls: 0.3131  decode.d2.loss_mask: 0.2934  decode.d2.loss_dice: 0.3027  decode.d3.loss_cls: 0.3525  decode.d3.loss_mask: 0.2719  decode.d3.loss_dice: 0.2813  decode.d4.loss_cls: 0.2762  decode.d4.loss_mask: 0.2702  decode.d4.loss_dice: 0.2785  decode.d5.loss_cls: 0.2323  decode.d5.loss_mask: 0.2707  decode.d5.loss_dice: 0.2752  decode.d6.loss_cls: 0.2594  decode.d6.loss_mask: 0.2671  decode.d6.loss_dice: 0.2967  decode.d7.loss_cls: 0.2774  decode.d7.loss_mask: 0.2703  decode.d7.loss_dice: 0.2855  decode.d8.loss_cls: 0.2729  decode.d8.loss_mask: 0.2744  decode.d8.loss_dice: 0.2831
07/30 18:32:08 - mmengine - INFO - Iter(train) [15400/80000]  base_lr: 8.2496e-05 lr: 8.2496e-06  eta: 7:49:11  time: 0.4354  data_time: 0.0089  memory: 5265  grad_norm: 107.3371  loss: 10.9073  decode.loss_cls: 0.4287  decode.loss_mask: 0.2604  decode.loss_dice: 0.3239  decode.d0.loss_cls: 1.2363  decode.d0.loss_mask: 0.2789  decode.d0.loss_dice: 0.3725  decode.d1.loss_cls: 0.4914  decode.d1.loss_mask: 0.2608  decode.d1.loss_dice: 0.2950  decode.d2.loss_cls: 0.4507  decode.d2.loss_mask: 0.2589  decode.d2.loss_dice: 0.3164  decode.d3.loss_cls: 0.4022  decode.d3.loss_mask: 0.2627  decode.d3.loss_dice: 0.3398  decode.d4.loss_cls: 0.4017  decode.d4.loss_mask: 0.2657  decode.d4.loss_dice: 0.3328  decode.d5.loss_cls: 0.3886  decode.d5.loss_mask: 0.2630  decode.d5.loss_dice: 0.3159  decode.d6.loss_cls: 0.3688  decode.d6.loss_mask: 0.2642  decode.d6.loss_dice: 0.3269  decode.d7.loss_cls: 0.4124  decode.d7.loss_mask: 0.2654  decode.d7.loss_dice: 0.3309  decode.d8.loss_cls: 0.4080  decode.d8.loss_mask: 0.2675  decode.d8.loss_dice: 0.3168
07/30 18:32:29 - mmengine - INFO - Iter(train) [15450/80000]  base_lr: 8.2439e-05 lr: 8.2439e-06  eta: 7:48:49  time: 0.4362  data_time: 0.0089  memory: 5246  grad_norm: 53.5015  loss: 7.3469  decode.loss_cls: 0.1418  decode.loss_mask: 0.2068  decode.loss_dice: 0.2733  decode.d0.loss_cls: 1.0243  decode.d0.loss_mask: 0.2110  decode.d0.loss_dice: 0.2976  decode.d1.loss_cls: 0.2319  decode.d1.loss_mask: 0.2110  decode.d1.loss_dice: 0.2791  decode.d2.loss_cls: 0.1720  decode.d2.loss_mask: 0.2142  decode.d2.loss_dice: 0.2819  decode.d3.loss_cls: 0.1602  decode.d3.loss_mask: 0.2086  decode.d3.loss_dice: 0.2742  decode.d4.loss_cls: 0.1707  decode.d4.loss_mask: 0.2063  decode.d4.loss_dice: 0.2650  decode.d5.loss_cls: 0.1717  decode.d5.loss_mask: 0.2062  decode.d5.loss_dice: 0.2681  decode.d6.loss_cls: 0.1378  decode.d6.loss_mask: 0.2057  decode.d6.loss_dice: 0.2587  decode.d7.loss_cls: 0.1461  decode.d7.loss_mask: 0.2075  decode.d7.loss_dice: 0.2800  decode.d8.loss_cls: 0.1462  decode.d8.loss_mask: 0.2064  decode.d8.loss_dice: 0.2826
07/30 18:32:51 - mmengine - INFO - Iter(train) [15500/80000]  base_lr: 8.2381e-05 lr: 8.2381e-06  eta: 7:48:28  time: 0.4344  data_time: 0.0089  memory: 5246  grad_norm: 180.9544  loss: 9.5790  decode.loss_cls: 0.1784  decode.loss_mask: 0.3208  decode.loss_dice: 0.3014  decode.d0.loss_cls: 1.1110  decode.d0.loss_mask: 0.3369  decode.d0.loss_dice: 0.3090  decode.d1.loss_cls: 0.3416  decode.d1.loss_mask: 0.3192  decode.d1.loss_dice: 0.3125  decode.d2.loss_cls: 0.3471  decode.d2.loss_mask: 0.3231  decode.d2.loss_dice: 0.3056  decode.d3.loss_cls: 0.2287  decode.d3.loss_mask: 0.3151  decode.d3.loss_dice: 0.3070  decode.d4.loss_cls: 0.2598  decode.d4.loss_mask: 0.3174  decode.d4.loss_dice: 0.2960  decode.d5.loss_cls: 0.2507  decode.d5.loss_mask: 0.3428  decode.d5.loss_dice: 0.3070  decode.d6.loss_cls: 0.2180  decode.d6.loss_mask: 0.3177  decode.d6.loss_dice: 0.2879  decode.d7.loss_cls: 0.2141  decode.d7.loss_mask: 0.3189  decode.d7.loss_dice: 0.3022  decode.d8.loss_cls: 0.1697  decode.d8.loss_mask: 0.3216  decode.d8.loss_dice: 0.2981
07/30 18:33:13 - mmengine - INFO - Iter(train) [15550/80000]  base_lr: 8.2324e-05 lr: 8.2324e-06  eta: 7:48:06  time: 0.4357  data_time: 0.0089  memory: 5304  grad_norm: 91.5537  loss: 6.4919  decode.loss_cls: 0.0942  decode.loss_mask: 0.2247  decode.loss_dice: 0.2091  decode.d0.loss_cls: 0.8983  decode.d0.loss_mask: 0.2253  decode.d0.loss_dice: 0.2222  decode.d1.loss_cls: 0.2400  decode.d1.loss_mask: 0.2236  decode.d1.loss_dice: 0.2144  decode.d2.loss_cls: 0.1594  decode.d2.loss_mask: 0.2216  decode.d2.loss_dice: 0.2166  decode.d3.loss_cls: 0.1419  decode.d3.loss_mask: 0.2203  decode.d3.loss_dice: 0.2166  decode.d4.loss_cls: 0.1114  decode.d4.loss_mask: 0.2200  decode.d4.loss_dice: 0.2139  decode.d5.loss_cls: 0.0788  decode.d5.loss_mask: 0.2214  decode.d5.loss_dice: 0.2194  decode.d6.loss_cls: 0.1205  decode.d6.loss_mask: 0.2198  decode.d6.loss_dice: 0.2140  decode.d7.loss_cls: 0.1343  decode.d7.loss_mask: 0.2198  decode.d7.loss_dice: 0.2197  decode.d8.loss_cls: 0.1434  decode.d8.loss_mask: 0.2233  decode.d8.loss_dice: 0.2040
07/30 18:33:35 - mmengine - INFO - Iter(train) [15600/80000]  base_lr: 8.2266e-05 lr: 8.2266e-06  eta: 7:47:45  time: 0.4370  data_time: 0.0092  memory: 5261  grad_norm: 114.2842  loss: 11.5459  decode.loss_cls: 0.3597  decode.loss_mask: 0.3272  decode.loss_dice: 0.3591  decode.d0.loss_cls: 1.0948  decode.d0.loss_mask: 0.3522  decode.d0.loss_dice: 0.4285  decode.d1.loss_cls: 0.4223  decode.d1.loss_mask: 0.3292  decode.d1.loss_dice: 0.3729  decode.d2.loss_cls: 0.4744  decode.d2.loss_mask: 0.3225  decode.d2.loss_dice: 0.3417  decode.d3.loss_cls: 0.4576  decode.d3.loss_mask: 0.3257  decode.d3.loss_dice: 0.3512  decode.d4.loss_cls: 0.4631  decode.d4.loss_mask: 0.3314  decode.d4.loss_dice: 0.3451  decode.d5.loss_cls: 0.3617  decode.d5.loss_mask: 0.3338  decode.d5.loss_dice: 0.3404  decode.d6.loss_cls: 0.3498  decode.d6.loss_mask: 0.3284  decode.d6.loss_dice: 0.3439  decode.d7.loss_cls: 0.3634  decode.d7.loss_mask: 0.3341  decode.d7.loss_dice: 0.3409  decode.d8.loss_cls: 0.3053  decode.d8.loss_mask: 0.3327  decode.d8.loss_dice: 0.3529
07/30 18:33:57 - mmengine - INFO - Iter(train) [15650/80000]  base_lr: 8.2209e-05 lr: 8.2209e-06  eta: 7:47:23  time: 0.4365  data_time: 0.0089  memory: 5245  grad_norm: 113.6905  loss: 9.1928  decode.loss_cls: 0.1892  decode.loss_mask: 0.2536  decode.loss_dice: 0.3270  decode.d0.loss_cls: 1.1043  decode.d0.loss_mask: 0.2718  decode.d0.loss_dice: 0.3890  decode.d1.loss_cls: 0.2644  decode.d1.loss_mask: 0.2556  decode.d1.loss_dice: 0.3369  decode.d2.loss_cls: 0.2736  decode.d2.loss_mask: 0.2555  decode.d2.loss_dice: 0.3503  decode.d3.loss_cls: 0.2163  decode.d3.loss_mask: 0.2535  decode.d3.loss_dice: 0.3434  decode.d4.loss_cls: 0.2747  decode.d4.loss_mask: 0.2736  decode.d4.loss_dice: 0.3609  decode.d5.loss_cls: 0.2187  decode.d5.loss_mask: 0.2563  decode.d5.loss_dice: 0.3466  decode.d6.loss_cls: 0.2014  decode.d6.loss_mask: 0.2538  decode.d6.loss_dice: 0.3329  decode.d7.loss_cls: 0.1774  decode.d7.loss_mask: 0.2636  decode.d7.loss_dice: 0.3454  decode.d8.loss_cls: 0.2183  decode.d8.loss_mask: 0.2569  decode.d8.loss_dice: 0.3276
07/30 18:34:19 - mmengine - INFO - Iter(train) [15700/80000]  base_lr: 8.2151e-05 lr: 8.2151e-06  eta: 7:47:01  time: 0.4359  data_time: 0.0088  memory: 5265  grad_norm: 104.3194  loss: 8.6946  decode.loss_cls: 0.3367  decode.loss_mask: 0.1908  decode.loss_dice: 0.2436  decode.d0.loss_cls: 1.1689  decode.d0.loss_mask: 0.2032  decode.d0.loss_dice: 0.2744  decode.d1.loss_cls: 0.4147  decode.d1.loss_mask: 0.1944  decode.d1.loss_dice: 0.2391  decode.d2.loss_cls: 0.3316  decode.d2.loss_mask: 0.1970  decode.d2.loss_dice: 0.2559  decode.d3.loss_cls: 0.3347  decode.d3.loss_mask: 0.1913  decode.d3.loss_dice: 0.2550  decode.d4.loss_cls: 0.2709  decode.d4.loss_mask: 0.1963  decode.d4.loss_dice: 0.2696  decode.d5.loss_cls: 0.3087  decode.d5.loss_mask: 0.1903  decode.d5.loss_dice: 0.2612  decode.d6.loss_cls: 0.3218  decode.d6.loss_mask: 0.1908  decode.d6.loss_dice: 0.2660  decode.d7.loss_cls: 0.3677  decode.d7.loss_mask: 0.1874  decode.d7.loss_dice: 0.2524  decode.d8.loss_cls: 0.3416  decode.d8.loss_mask: 0.1881  decode.d8.loss_dice: 0.2504
07/30 18:34:40 - mmengine - INFO - Iter(train) [15750/80000]  base_lr: 8.2094e-05 lr: 8.2094e-06  eta: 7:46:40  time: 0.4363  data_time: 0.0090  memory: 5261  grad_norm: 67.4576  loss: 7.8824  decode.loss_cls: 0.1052  decode.loss_mask: 0.2918  decode.loss_dice: 0.2767  decode.d0.loss_cls: 0.9570  decode.d0.loss_mask: 0.3045  decode.d0.loss_dice: 0.2899  decode.d1.loss_cls: 0.2442  decode.d1.loss_mask: 0.2923  decode.d1.loss_dice: 0.2894  decode.d2.loss_cls: 0.1786  decode.d2.loss_mask: 0.2889  decode.d2.loss_dice: 0.2759  decode.d3.loss_cls: 0.1497  decode.d3.loss_mask: 0.2924  decode.d3.loss_dice: 0.2771  decode.d4.loss_cls: 0.1286  decode.d4.loss_mask: 0.2922  decode.d4.loss_dice: 0.2792  decode.d5.loss_cls: 0.1040  decode.d5.loss_mask: 0.2945  decode.d5.loss_dice: 0.2784  decode.d6.loss_cls: 0.1072  decode.d6.loss_mask: 0.2923  decode.d6.loss_dice: 0.2724  decode.d7.loss_cls: 0.1088  decode.d7.loss_mask: 0.2893  decode.d7.loss_dice: 0.2696  decode.d8.loss_cls: 0.0841  decode.d8.loss_mask: 0.2903  decode.d8.loss_dice: 0.2781
07/30 18:35:02 - mmengine - INFO - Iter(train) [15800/80000]  base_lr: 8.2036e-05 lr: 8.2036e-06  eta: 7:46:18  time: 0.4359  data_time: 0.0090  memory: 5278  grad_norm: 84.0706  loss: 6.8794  decode.loss_cls: 0.1931  decode.loss_mask: 0.2152  decode.loss_dice: 0.2291  decode.d0.loss_cls: 0.9343  decode.d0.loss_mask: 0.2247  decode.d0.loss_dice: 0.2537  decode.d1.loss_cls: 0.1886  decode.d1.loss_mask: 0.2207  decode.d1.loss_dice: 0.2359  decode.d2.loss_cls: 0.1133  decode.d2.loss_mask: 0.2252  decode.d2.loss_dice: 0.2461  decode.d3.loss_cls: 0.1132  decode.d3.loss_mask: 0.2176  decode.d3.loss_dice: 0.2287  decode.d4.loss_cls: 0.1413  decode.d4.loss_mask: 0.2158  decode.d4.loss_dice: 0.2347  decode.d5.loss_cls: 0.1595  decode.d5.loss_mask: 0.2151  decode.d5.loss_dice: 0.2348  decode.d6.loss_cls: 0.1563  decode.d6.loss_mask: 0.2143  decode.d6.loss_dice: 0.2330  decode.d7.loss_cls: 0.1644  decode.d7.loss_mask: 0.2107  decode.d7.loss_dice: 0.2323  decode.d8.loss_cls: 0.1701  decode.d8.loss_mask: 0.2196  decode.d8.loss_dice: 0.2378
07/30 18:35:24 - mmengine - INFO - Iter(train) [15850/80000]  base_lr: 8.1979e-05 lr: 8.1979e-06  eta: 7:45:56  time: 0.4363  data_time: 0.0090  memory: 5261  grad_norm: 74.6414  loss: 8.7560  decode.loss_cls: 0.2693  decode.loss_mask: 0.2314  decode.loss_dice: 0.3040  decode.d0.loss_cls: 1.0940  decode.d0.loss_mask: 0.2303  decode.d0.loss_dice: 0.3097  decode.d1.loss_cls: 0.3568  decode.d1.loss_mask: 0.2318  decode.d1.loss_dice: 0.2924  decode.d2.loss_cls: 0.2735  decode.d2.loss_mask: 0.2345  decode.d2.loss_dice: 0.2850  decode.d3.loss_cls: 0.2415  decode.d3.loss_mask: 0.2371  decode.d3.loss_dice: 0.2868  decode.d4.loss_cls: 0.2326  decode.d4.loss_mask: 0.2364  decode.d4.loss_dice: 0.2966  decode.d5.loss_cls: 0.2117  decode.d5.loss_mask: 0.2371  decode.d5.loss_dice: 0.2950  decode.d6.loss_cls: 0.2689  decode.d6.loss_mask: 0.2374  decode.d6.loss_dice: 0.3028  decode.d7.loss_cls: 0.2259  decode.d7.loss_mask: 0.2329  decode.d7.loss_dice: 0.3049  decode.d8.loss_cls: 0.2711  decode.d8.loss_mask: 0.2303  decode.d8.loss_dice: 0.2942
07/30 18:35:46 - mmengine - INFO - Iter(train) [15900/80000]  base_lr: 8.1921e-05 lr: 8.1921e-06  eta: 7:45:35  time: 0.4360  data_time: 0.0089  memory: 5265  grad_norm: 73.5399  loss: 9.1877  decode.loss_cls: 0.2541  decode.loss_mask: 0.2356  decode.loss_dice: 0.3310  decode.d0.loss_cls: 1.0402  decode.d0.loss_mask: 0.2672  decode.d0.loss_dice: 0.3594  decode.d1.loss_cls: 0.3378  decode.d1.loss_mask: 0.2515  decode.d1.loss_dice: 0.3298  decode.d2.loss_cls: 0.3122  decode.d2.loss_mask: 0.2371  decode.d2.loss_dice: 0.3349  decode.d3.loss_cls: 0.2304  decode.d3.loss_mask: 0.2353  decode.d3.loss_dice: 0.3464  decode.d4.loss_cls: 0.1928  decode.d4.loss_mask: 0.2366  decode.d4.loss_dice: 0.3481  decode.d5.loss_cls: 0.3066  decode.d5.loss_mask: 0.2360  decode.d5.loss_dice: 0.3563  decode.d6.loss_cls: 0.2710  decode.d6.loss_mask: 0.2412  decode.d6.loss_dice: 0.3435  decode.d7.loss_cls: 0.2100  decode.d7.loss_mask: 0.2390  decode.d7.loss_dice: 0.3353  decode.d8.loss_cls: 0.1972  decode.d8.loss_mask: 0.2433  decode.d8.loss_dice: 0.3277
07/30 18:36:08 - mmengine - INFO - Iter(train) [15950/80000]  base_lr: 8.1864e-05 lr: 8.1864e-06  eta: 7:45:13  time: 0.4376  data_time: 0.0091  memory: 5261  grad_norm: 71.4131  loss: 10.9234  decode.loss_cls: 0.4109  decode.loss_mask: 0.2623  decode.loss_dice: 0.3446  decode.d0.loss_cls: 1.3456  decode.d0.loss_mask: 0.2663  decode.d0.loss_dice: 0.3369  decode.d1.loss_cls: 0.4110  decode.d1.loss_mask: 0.2773  decode.d1.loss_dice: 0.3096  decode.d2.loss_cls: 0.4548  decode.d2.loss_mask: 0.2623  decode.d2.loss_dice: 0.3129  decode.d3.loss_cls: 0.3976  decode.d3.loss_mask: 0.2555  decode.d3.loss_dice: 0.3030  decode.d4.loss_cls: 0.3963  decode.d4.loss_mask: 0.2611  decode.d4.loss_dice: 0.3393  decode.d5.loss_cls: 0.4214  decode.d5.loss_mask: 0.2610  decode.d5.loss_dice: 0.3211  decode.d6.loss_cls: 0.4049  decode.d6.loss_mask: 0.2569  decode.d6.loss_dice: 0.3010  decode.d7.loss_cls: 0.4321  decode.d7.loss_mask: 0.2608  decode.d7.loss_dice: 0.3124  decode.d8.loss_cls: 0.4367  decode.d8.loss_mask: 0.2578  decode.d8.loss_dice: 0.3100
07/30 18:36:29 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 18:36:29 - mmengine - INFO - Iter(train) [16000/80000]  base_lr: 8.1806e-05 lr: 8.1806e-06  eta: 7:44:51  time: 0.4354  data_time: 0.0092  memory: 5279  grad_norm: 68.3978  loss: 9.1213  decode.loss_cls: 0.1648  decode.loss_mask: 0.2920  decode.loss_dice: 0.3098  decode.d0.loss_cls: 0.9555  decode.d0.loss_mask: 0.2939  decode.d0.loss_dice: 0.3320  decode.d1.loss_cls: 0.4090  decode.d1.loss_mask: 0.2856  decode.d1.loss_dice: 0.3030  decode.d2.loss_cls: 0.3704  decode.d2.loss_mask: 0.2879  decode.d2.loss_dice: 0.2973  decode.d3.loss_cls: 0.1996  decode.d3.loss_mask: 0.2880  decode.d3.loss_dice: 0.2924  decode.d4.loss_cls: 0.2705  decode.d4.loss_mask: 0.2893  decode.d4.loss_dice: 0.3129  decode.d5.loss_cls: 0.2217  decode.d5.loss_mask: 0.2857  decode.d5.loss_dice: 0.2937  decode.d6.loss_cls: 0.1960  decode.d6.loss_mask: 0.2834  decode.d6.loss_dice: 0.2987  decode.d7.loss_cls: 0.2134  decode.d7.loss_mask: 0.2898  decode.d7.loss_dice: 0.3263  decode.d8.loss_cls: 0.1646  decode.d8.loss_mask: 0.2862  decode.d8.loss_dice: 0.3080
07/30 18:36:51 - mmengine - INFO - Iter(train) [16050/80000]  base_lr: 8.1749e-05 lr: 8.1749e-06  eta: 7:44:29  time: 0.4356  data_time: 0.0090  memory: 5245  grad_norm: 105.2374  loss: 9.5342  decode.loss_cls: 0.3130  decode.loss_mask: 0.2521  decode.loss_dice: 0.3148  decode.d0.loss_cls: 1.2879  decode.d0.loss_mask: 0.2624  decode.d0.loss_dice: 0.3338  decode.d1.loss_cls: 0.3681  decode.d1.loss_mask: 0.2559  decode.d1.loss_dice: 0.3147  decode.d2.loss_cls: 0.2747  decode.d2.loss_mask: 0.2521  decode.d2.loss_dice: 0.3142  decode.d3.loss_cls: 0.2094  decode.d3.loss_mask: 0.2588  decode.d3.loss_dice: 0.3064  decode.d4.loss_cls: 0.2301  decode.d4.loss_mask: 0.2555  decode.d4.loss_dice: 0.3166  decode.d5.loss_cls: 0.2466  decode.d5.loss_mask: 0.2550  decode.d5.loss_dice: 0.3461  decode.d6.loss_cls: 0.3223  decode.d6.loss_mask: 0.2571  decode.d6.loss_dice: 0.3260  decode.d7.loss_cls: 0.2492  decode.d7.loss_mask: 0.2543  decode.d7.loss_dice: 0.3157  decode.d8.loss_cls: 0.2699  decode.d8.loss_mask: 0.2503  decode.d8.loss_dice: 0.3210
07/30 18:37:13 - mmengine - INFO - Iter(train) [16100/80000]  base_lr: 8.1691e-05 lr: 8.1691e-06  eta: 7:44:08  time: 0.4357  data_time: 0.0089  memory: 5265  grad_norm: 131.8228  loss: 10.0765  decode.loss_cls: 0.3110  decode.loss_mask: 0.3173  decode.loss_dice: 0.3164  decode.d0.loss_cls: 1.1114  decode.d0.loss_mask: 0.3033  decode.d0.loss_dice: 0.2884  decode.d1.loss_cls: 0.4246  decode.d1.loss_mask: 0.2990  decode.d1.loss_dice: 0.2866  decode.d2.loss_cls: 0.3698  decode.d2.loss_mask: 0.3015  decode.d2.loss_dice: 0.3037  decode.d3.loss_cls: 0.2868  decode.d3.loss_mask: 0.2994  decode.d3.loss_dice: 0.2917  decode.d4.loss_cls: 0.2413  decode.d4.loss_mask: 0.3109  decode.d4.loss_dice: 0.2986  decode.d5.loss_cls: 0.2699  decode.d5.loss_mask: 0.3078  decode.d5.loss_dice: 0.3011  decode.d6.loss_cls: 0.2919  decode.d6.loss_mask: 0.3006  decode.d6.loss_dice: 0.3077  decode.d7.loss_cls: 0.3182  decode.d7.loss_mask: 0.3158  decode.d7.loss_dice: 0.3192  decode.d8.loss_cls: 0.3320  decode.d8.loss_mask: 0.3297  decode.d8.loss_dice: 0.3213
07/30 18:37:35 - mmengine - INFO - Iter(train) [16150/80000]  base_lr: 8.1634e-05 lr: 8.1634e-06  eta: 7:43:46  time: 0.4361  data_time: 0.0089  memory: 5265  grad_norm: 64.1222  loss: 6.8060  decode.loss_cls: 0.1174  decode.loss_mask: 0.1918  decode.loss_dice: 0.2352  decode.d0.loss_cls: 1.0911  decode.d0.loss_mask: 0.2000  decode.d0.loss_dice: 0.2561  decode.d1.loss_cls: 0.2115  decode.d1.loss_mask: 0.1914  decode.d1.loss_dice: 0.2357  decode.d2.loss_cls: 0.1962  decode.d2.loss_mask: 0.1939  decode.d2.loss_dice: 0.2443  decode.d3.loss_cls: 0.1607  decode.d3.loss_mask: 0.1944  decode.d3.loss_dice: 0.2334  decode.d4.loss_cls: 0.1528  decode.d4.loss_mask: 0.1923  decode.d4.loss_dice: 0.2294  decode.d5.loss_cls: 0.1247  decode.d5.loss_mask: 0.1963  decode.d5.loss_dice: 0.2509  decode.d6.loss_cls: 0.1557  decode.d6.loss_mask: 0.1932  decode.d6.loss_dice: 0.2335  decode.d7.loss_cls: 0.1292  decode.d7.loss_mask: 0.1961  decode.d7.loss_dice: 0.2254  decode.d8.loss_cls: 0.1390  decode.d8.loss_mask: 0.1953  decode.d8.loss_dice: 0.2390
07/30 18:37:57 - mmengine - INFO - Iter(train) [16200/80000]  base_lr: 8.1576e-05 lr: 8.1576e-06  eta: 7:43:24  time: 0.4360  data_time: 0.0090  memory: 5265  grad_norm: 58.4532  loss: 9.3616  decode.loss_cls: 0.2117  decode.loss_mask: 0.3081  decode.loss_dice: 0.3016  decode.d0.loss_cls: 1.0672  decode.d0.loss_mask: 0.3100  decode.d0.loss_dice: 0.3396  decode.d1.loss_cls: 0.3494  decode.d1.loss_mask: 0.2817  decode.d1.loss_dice: 0.3059  decode.d2.loss_cls: 0.3334  decode.d2.loss_mask: 0.2810  decode.d2.loss_dice: 0.2950  decode.d3.loss_cls: 0.2526  decode.d3.loss_mask: 0.2848  decode.d3.loss_dice: 0.3103  decode.d4.loss_cls: 0.2754  decode.d4.loss_mask: 0.2848  decode.d4.loss_dice: 0.3009  decode.d5.loss_cls: 0.2053  decode.d5.loss_mask: 0.2976  decode.d5.loss_dice: 0.3315  decode.d6.loss_cls: 0.2230  decode.d6.loss_mask: 0.2954  decode.d6.loss_dice: 0.3132  decode.d7.loss_cls: 0.2227  decode.d7.loss_mask: 0.2978  decode.d7.loss_dice: 0.3094  decode.d8.loss_cls: 0.1552  decode.d8.loss_mask: 0.3034  decode.d8.loss_dice: 0.3139
07/30 18:38:18 - mmengine - INFO - Iter(train) [16250/80000]  base_lr: 8.1518e-05 lr: 8.1518e-06  eta: 7:43:02  time: 0.4339  data_time: 0.0090  memory: 5229  grad_norm: 79.0588  loss: 8.9203  decode.loss_cls: 0.2306  decode.loss_mask: 0.2916  decode.loss_dice: 0.3031  decode.d0.loss_cls: 0.9269  decode.d0.loss_mask: 0.3009  decode.d0.loss_dice: 0.3065  decode.d1.loss_cls: 0.3346  decode.d1.loss_mask: 0.2915  decode.d1.loss_dice: 0.3141  decode.d2.loss_cls: 0.2369  decode.d2.loss_mask: 0.2919  decode.d2.loss_dice: 0.3090  decode.d3.loss_cls: 0.1740  decode.d3.loss_mask: 0.2922  decode.d3.loss_dice: 0.3010  decode.d4.loss_cls: 0.1925  decode.d4.loss_mask: 0.2976  decode.d4.loss_dice: 0.3026  decode.d5.loss_cls: 0.1508  decode.d5.loss_mask: 0.2956  decode.d5.loss_dice: 0.3003  decode.d6.loss_cls: 0.1995  decode.d6.loss_mask: 0.2905  decode.d6.loss_dice: 0.3029  decode.d7.loss_cls: 0.2824  decode.d7.loss_mask: 0.2908  decode.d7.loss_dice: 0.2958  decode.d8.loss_cls: 0.2019  decode.d8.loss_mask: 0.2941  decode.d8.loss_dice: 0.3183
07/30 18:38:40 - mmengine - INFO - Iter(train) [16300/80000]  base_lr: 8.1461e-05 lr: 8.1461e-06  eta: 7:42:40  time: 0.4377  data_time: 0.0088  memory: 5246  grad_norm: 64.6714  loss: 9.5532  decode.loss_cls: 0.2311  decode.loss_mask: 0.2354  decode.loss_dice: 0.3378  decode.d0.loss_cls: 1.2312  decode.d0.loss_mask: 0.2376  decode.d0.loss_dice: 0.3774  decode.d1.loss_cls: 0.3184  decode.d1.loss_mask: 0.2386  decode.d1.loss_dice: 0.3291  decode.d2.loss_cls: 0.3188  decode.d2.loss_mask: 0.2379  decode.d2.loss_dice: 0.3323  decode.d3.loss_cls: 0.3260  decode.d3.loss_mask: 0.2418  decode.d3.loss_dice: 0.3407  decode.d4.loss_cls: 0.2866  decode.d4.loss_mask: 0.2539  decode.d4.loss_dice: 0.3433  decode.d5.loss_cls: 0.2939  decode.d5.loss_mask: 0.2302  decode.d5.loss_dice: 0.3325  decode.d6.loss_cls: 0.2635  decode.d6.loss_mask: 0.2317  decode.d6.loss_dice: 0.3386  decode.d7.loss_cls: 0.2445  decode.d7.loss_mask: 0.2326  decode.d7.loss_dice: 0.3434  decode.d8.loss_cls: 0.2601  decode.d8.loss_mask: 0.2354  decode.d8.loss_dice: 0.3290
07/30 18:39:02 - mmengine - INFO - Iter(train) [16350/80000]  base_lr: 8.1403e-05 lr: 8.1403e-06  eta: 7:42:19  time: 0.4359  data_time: 0.0090  memory: 5244  grad_norm: 113.4288  loss: 9.5275  decode.loss_cls: 0.2396  decode.loss_mask: 0.2921  decode.loss_dice: 0.3277  decode.d0.loss_cls: 1.0950  decode.d0.loss_mask: 0.3442  decode.d0.loss_dice: 0.3097  decode.d1.loss_cls: 0.3903  decode.d1.loss_mask: 0.3035  decode.d1.loss_dice: 0.2964  decode.d2.loss_cls: 0.2334  decode.d2.loss_mask: 0.2925  decode.d2.loss_dice: 0.2754  decode.d3.loss_cls: 0.2707  decode.d3.loss_mask: 0.2907  decode.d3.loss_dice: 0.2897  decode.d4.loss_cls: 0.2558  decode.d4.loss_mask: 0.2939  decode.d4.loss_dice: 0.2867  decode.d5.loss_cls: 0.2997  decode.d5.loss_mask: 0.2926  decode.d5.loss_dice: 0.2963  decode.d6.loss_cls: 0.3353  decode.d6.loss_mask: 0.2905  decode.d6.loss_dice: 0.2811  decode.d7.loss_cls: 0.2586  decode.d7.loss_mask: 0.2903  decode.d7.loss_dice: 0.2843  decode.d8.loss_cls: 0.2400  decode.d8.loss_mask: 0.2897  decode.d8.loss_dice: 0.2819
07/30 18:39:24 - mmengine - INFO - Iter(train) [16400/80000]  base_lr: 8.1346e-05 lr: 8.1346e-06  eta: 7:41:57  time: 0.4367  data_time: 0.0090  memory: 5261  grad_norm: 95.2423  loss: 9.4219  decode.loss_cls: 0.2238  decode.loss_mask: 0.2705  decode.loss_dice: 0.3602  decode.d0.loss_cls: 1.1445  decode.d0.loss_mask: 0.2800  decode.d0.loss_dice: 0.3632  decode.d1.loss_cls: 0.2708  decode.d1.loss_mask: 0.2719  decode.d1.loss_dice: 0.3631  decode.d2.loss_cls: 0.1641  decode.d2.loss_mask: 0.2705  decode.d2.loss_dice: 0.3550  decode.d3.loss_cls: 0.2126  decode.d3.loss_mask: 0.2701  decode.d3.loss_dice: 0.3420  decode.d4.loss_cls: 0.2203  decode.d4.loss_mask: 0.2682  decode.d4.loss_dice: 0.3641  decode.d5.loss_cls: 0.2133  decode.d5.loss_mask: 0.2695  decode.d5.loss_dice: 0.3645  decode.d6.loss_cls: 0.2332  decode.d6.loss_mask: 0.2718  decode.d6.loss_dice: 0.3494  decode.d7.loss_cls: 0.2260  decode.d7.loss_mask: 0.2681  decode.d7.loss_dice: 0.3645  decode.d8.loss_cls: 0.2314  decode.d8.loss_mask: 0.2675  decode.d8.loss_dice: 0.3478
07/30 18:39:46 - mmengine - INFO - Iter(train) [16450/80000]  base_lr: 8.1288e-05 lr: 8.1288e-06  eta: 7:41:35  time: 0.4373  data_time: 0.0091  memory: 5277  grad_norm: 172.3805  loss: 11.5509  decode.loss_cls: 0.4051  decode.loss_mask: 0.3315  decode.loss_dice: 0.3768  decode.d0.loss_cls: 1.1823  decode.d0.loss_mask: 0.3347  decode.d0.loss_dice: 0.3561  decode.d1.loss_cls: 0.4895  decode.d1.loss_mask: 0.3088  decode.d1.loss_dice: 0.3373  decode.d2.loss_cls: 0.3615  decode.d2.loss_mask: 0.3275  decode.d2.loss_dice: 0.3439  decode.d3.loss_cls: 0.3709  decode.d3.loss_mask: 0.3143  decode.d3.loss_dice: 0.3239  decode.d4.loss_cls: 0.3737  decode.d4.loss_mask: 0.3250  decode.d4.loss_dice: 0.3543  decode.d5.loss_cls: 0.4306  decode.d5.loss_mask: 0.3196  decode.d5.loss_dice: 0.3496  decode.d6.loss_cls: 0.3709  decode.d6.loss_mask: 0.3234  decode.d6.loss_dice: 0.3239  decode.d7.loss_cls: 0.4448  decode.d7.loss_mask: 0.3214  decode.d7.loss_dice: 0.3529  decode.d8.loss_cls: 0.4105  decode.d8.loss_mask: 0.3257  decode.d8.loss_dice: 0.3607
07/30 18:40:07 - mmengine - INFO - Iter(train) [16500/80000]  base_lr: 8.1231e-05 lr: 8.1231e-06  eta: 7:41:14  time: 0.4354  data_time: 0.0090  memory: 5261  grad_norm: 64.9421  loss: 8.2034  decode.loss_cls: 0.2056  decode.loss_mask: 0.2555  decode.loss_dice: 0.3116  decode.d0.loss_cls: 0.9366  decode.d0.loss_mask: 0.2554  decode.d0.loss_dice: 0.3148  decode.d1.loss_cls: 0.1818  decode.d1.loss_mask: 0.2564  decode.d1.loss_dice: 0.2909  decode.d2.loss_cls: 0.2068  decode.d2.loss_mask: 0.2540  decode.d2.loss_dice: 0.2789  decode.d3.loss_cls: 0.1804  decode.d3.loss_mask: 0.2507  decode.d3.loss_dice: 0.2655  decode.d4.loss_cls: 0.1761  decode.d4.loss_mask: 0.2522  decode.d4.loss_dice: 0.3023  decode.d5.loss_cls: 0.1639  decode.d5.loss_mask: 0.2543  decode.d5.loss_dice: 0.3075  decode.d6.loss_cls: 0.2199  decode.d6.loss_mask: 0.2506  decode.d6.loss_dice: 0.2827  decode.d7.loss_cls: 0.2265  decode.d7.loss_mask: 0.2487  decode.d7.loss_dice: 0.3084  decode.d8.loss_cls: 0.2294  decode.d8.loss_mask: 0.2551  decode.d8.loss_dice: 0.2806
07/30 18:40:29 - mmengine - INFO - Iter(train) [16550/80000]  base_lr: 8.1173e-05 lr: 8.1173e-06  eta: 7:40:52  time: 0.4362  data_time: 0.0091  memory: 5278  grad_norm: 80.4325  loss: 10.4777  decode.loss_cls: 0.3608  decode.loss_mask: 0.3053  decode.loss_dice: 0.3461  decode.d0.loss_cls: 0.9698  decode.d0.loss_mask: 0.3175  decode.d0.loss_dice: 0.3354  decode.d1.loss_cls: 0.4154  decode.d1.loss_mask: 0.3039  decode.d1.loss_dice: 0.3259  decode.d2.loss_cls: 0.3887  decode.d2.loss_mask: 0.3030  decode.d2.loss_dice: 0.3262  decode.d3.loss_cls: 0.3366  decode.d3.loss_mask: 0.3053  decode.d3.loss_dice: 0.3211  decode.d4.loss_cls: 0.3669  decode.d4.loss_mask: 0.3005  decode.d4.loss_dice: 0.3274  decode.d5.loss_cls: 0.3113  decode.d5.loss_mask: 0.3021  decode.d5.loss_dice: 0.3164  decode.d6.loss_cls: 0.2914  decode.d6.loss_mask: 0.3022  decode.d6.loss_dice: 0.3042  decode.d7.loss_cls: 0.3377  decode.d7.loss_mask: 0.3030  decode.d7.loss_dice: 0.3326  decode.d8.loss_cls: 0.3842  decode.d8.loss_mask: 0.3091  decode.d8.loss_dice: 0.3277
07/30 18:40:51 - mmengine - INFO - Iter(train) [16600/80000]  base_lr: 8.1116e-05 lr: 8.1116e-06  eta: 7:40:30  time: 0.4351  data_time: 0.0089  memory: 5245  grad_norm: 109.7952  loss: 8.6838  decode.loss_cls: 0.2338  decode.loss_mask: 0.2403  decode.loss_dice: 0.2788  decode.d0.loss_cls: 0.9683  decode.d0.loss_mask: 0.2537  decode.d0.loss_dice: 0.3130  decode.d1.loss_cls: 0.3999  decode.d1.loss_mask: 0.2436  decode.d1.loss_dice: 0.3002  decode.d2.loss_cls: 0.2949  decode.d2.loss_mask: 0.2419  decode.d2.loss_dice: 0.3042  decode.d3.loss_cls: 0.2672  decode.d3.loss_mask: 0.2432  decode.d3.loss_dice: 0.2793  decode.d4.loss_cls: 0.2526  decode.d4.loss_mask: 0.2404  decode.d4.loss_dice: 0.2840  decode.d5.loss_cls: 0.2474  decode.d5.loss_mask: 0.2421  decode.d5.loss_dice: 0.2821  decode.d6.loss_cls: 0.2426  decode.d6.loss_mask: 0.2413  decode.d6.loss_dice: 0.2834  decode.d7.loss_cls: 0.2116  decode.d7.loss_mask: 0.2395  decode.d7.loss_dice: 0.3006  decode.d8.loss_cls: 0.2303  decode.d8.loss_mask: 0.2394  decode.d8.loss_dice: 0.2840
07/30 18:41:13 - mmengine - INFO - Iter(train) [16650/80000]  base_lr: 8.1058e-05 lr: 8.1058e-06  eta: 7:40:08  time: 0.4358  data_time: 0.0090  memory: 5229  grad_norm: 78.7511  loss: 11.0820  decode.loss_cls: 0.3338  decode.loss_mask: 0.3215  decode.loss_dice: 0.4028  decode.d0.loss_cls: 1.0595  decode.d0.loss_mask: 0.3414  decode.d0.loss_dice: 0.4078  decode.d1.loss_cls: 0.2689  decode.d1.loss_mask: 0.3394  decode.d1.loss_dice: 0.4016  decode.d2.loss_cls: 0.3215  decode.d2.loss_mask: 0.3379  decode.d2.loss_dice: 0.3956  decode.d3.loss_cls: 0.3283  decode.d3.loss_mask: 0.3312  decode.d3.loss_dice: 0.3867  decode.d4.loss_cls: 0.2926  decode.d4.loss_mask: 0.3242  decode.d4.loss_dice: 0.3921  decode.d5.loss_cls: 0.2876  decode.d5.loss_mask: 0.3310  decode.d5.loss_dice: 0.3810  decode.d6.loss_cls: 0.2847  decode.d6.loss_mask: 0.3293  decode.d6.loss_dice: 0.3983  decode.d7.loss_cls: 0.2958  decode.d7.loss_mask: 0.3270  decode.d7.loss_dice: 0.4160  decode.d8.loss_cls: 0.3097  decode.d8.loss_mask: 0.3233  decode.d8.loss_dice: 0.4113
07/30 18:41:35 - mmengine - INFO - Iter(train) [16700/80000]  base_lr: 8.1000e-05 lr: 8.1000e-06  eta: 7:39:47  time: 0.4360  data_time: 0.0091  memory: 5265  grad_norm: 89.7838  loss: 9.6721  decode.loss_cls: 0.1765  decode.loss_mask: 0.3345  decode.loss_dice: 0.3158  decode.d0.loss_cls: 1.0775  decode.d0.loss_mask: 0.3514  decode.d0.loss_dice: 0.3598  decode.d1.loss_cls: 0.3133  decode.d1.loss_mask: 0.3500  decode.d1.loss_dice: 0.3271  decode.d2.loss_cls: 0.1346  decode.d2.loss_mask: 0.3464  decode.d2.loss_dice: 0.3281  decode.d3.loss_cls: 0.1989  decode.d3.loss_mask: 0.3372  decode.d3.loss_dice: 0.3218  decode.d4.loss_cls: 0.2176  decode.d4.loss_mask: 0.3409  decode.d4.loss_dice: 0.3230  decode.d5.loss_cls: 0.2478  decode.d5.loss_mask: 0.3396  decode.d5.loss_dice: 0.3297  decode.d6.loss_cls: 0.2357  decode.d6.loss_mask: 0.3366  decode.d6.loss_dice: 0.3218  decode.d7.loss_cls: 0.2069  decode.d7.loss_mask: 0.3358  decode.d7.loss_dice: 0.3186  decode.d8.loss_cls: 0.1948  decode.d8.loss_mask: 0.3341  decode.d8.loss_dice: 0.3164
07/30 18:41:57 - mmengine - INFO - Iter(train) [16750/80000]  base_lr: 8.0943e-05 lr: 8.0943e-06  eta: 7:39:25  time: 0.4354  data_time: 0.0089  memory: 5245  grad_norm: 87.4926  loss: 8.1387  decode.loss_cls: 0.2352  decode.loss_mask: 0.2790  decode.loss_dice: 0.2444  decode.d0.loss_cls: 0.9119  decode.d0.loss_mask: 0.2947  decode.d0.loss_dice: 0.2545  decode.d1.loss_cls: 0.2314  decode.d1.loss_mask: 0.2880  decode.d1.loss_dice: 0.2327  decode.d2.loss_cls: 0.2225  decode.d2.loss_mask: 0.2817  decode.d2.loss_dice: 0.2481  decode.d3.loss_cls: 0.2254  decode.d3.loss_mask: 0.2823  decode.d3.loss_dice: 0.2405  decode.d4.loss_cls: 0.2285  decode.d4.loss_mask: 0.2780  decode.d4.loss_dice: 0.2602  decode.d5.loss_cls: 0.2347  decode.d5.loss_mask: 0.2789  decode.d5.loss_dice: 0.2584  decode.d6.loss_cls: 0.1701  decode.d6.loss_mask: 0.2822  decode.d6.loss_dice: 0.2491  decode.d7.loss_cls: 0.2108  decode.d7.loss_mask: 0.2776  decode.d7.loss_dice: 0.2413  decode.d8.loss_cls: 0.1768  decode.d8.loss_mask: 0.2804  decode.d8.loss_dice: 0.2393
07/30 18:42:18 - mmengine - INFO - Iter(train) [16800/80000]  base_lr: 8.0885e-05 lr: 8.0885e-06  eta: 7:39:03  time: 0.4363  data_time: 0.0089  memory: 5244  grad_norm: 112.7064  loss: 8.5932  decode.loss_cls: 0.2157  decode.loss_mask: 0.2414  decode.loss_dice: 0.2745  decode.d0.loss_cls: 1.0682  decode.d0.loss_mask: 0.2546  decode.d0.loss_dice: 0.3221  decode.d1.loss_cls: 0.2842  decode.d1.loss_mask: 0.2439  decode.d1.loss_dice: 0.3016  decode.d2.loss_cls: 0.2397  decode.d2.loss_mask: 0.2439  decode.d2.loss_dice: 0.2869  decode.d3.loss_cls: 0.2546  decode.d3.loss_mask: 0.2422  decode.d3.loss_dice: 0.2895  decode.d4.loss_cls: 0.2257  decode.d4.loss_mask: 0.2352  decode.d4.loss_dice: 0.2838  decode.d5.loss_cls: 0.2237  decode.d5.loss_mask: 0.2440  decode.d5.loss_dice: 0.2881  decode.d6.loss_cls: 0.2315  decode.d6.loss_mask: 0.2409  decode.d6.loss_dice: 0.2732  decode.d7.loss_cls: 0.2707  decode.d7.loss_mask: 0.2366  decode.d7.loss_dice: 0.2814  decode.d8.loss_cls: 0.2783  decode.d8.loss_mask: 0.2377  decode.d8.loss_dice: 0.2795
07/30 18:42:40 - mmengine - INFO - Iter(train) [16850/80000]  base_lr: 8.0828e-05 lr: 8.0828e-06  eta: 7:38:41  time: 0.4365  data_time: 0.0088  memory: 5265  grad_norm: 79.4163  loss: 6.7657  decode.loss_cls: 0.1115  decode.loss_mask: 0.2431  decode.loss_dice: 0.2610  decode.d0.loss_cls: 0.9456  decode.d0.loss_mask: 0.2576  decode.d0.loss_dice: 0.2986  decode.d1.loss_cls: 0.0972  decode.d1.loss_mask: 0.2541  decode.d1.loss_dice: 0.2805  decode.d2.loss_cls: 0.0668  decode.d2.loss_mask: 0.2457  decode.d2.loss_dice: 0.2620  decode.d3.loss_cls: 0.0565  decode.d3.loss_mask: 0.2434  decode.d3.loss_dice: 0.2580  decode.d4.loss_cls: 0.0569  decode.d4.loss_mask: 0.2380  decode.d4.loss_dice: 0.2576  decode.d5.loss_cls: 0.0487  decode.d5.loss_mask: 0.2415  decode.d5.loss_dice: 0.2596  decode.d6.loss_cls: 0.0526  decode.d6.loss_mask: 0.2421  decode.d6.loss_dice: 0.2612  decode.d7.loss_cls: 0.0991  decode.d7.loss_mask: 0.2452  decode.d7.loss_dice: 0.2645  decode.d8.loss_cls: 0.1062  decode.d8.loss_mask: 0.2449  decode.d8.loss_dice: 0.2659
07/30 18:43:02 - mmengine - INFO - Iter(train) [16900/80000]  base_lr: 8.0770e-05 lr: 8.0770e-06  eta: 7:38:20  time: 0.4371  data_time: 0.0091  memory: 5261  grad_norm: 84.4035  loss: 9.0250  decode.loss_cls: 0.2696  decode.loss_mask: 0.2386  decode.loss_dice: 0.3015  decode.d0.loss_cls: 1.0876  decode.d0.loss_mask: 0.2569  decode.d0.loss_dice: 0.3358  decode.d1.loss_cls: 0.3223  decode.d1.loss_mask: 0.2415  decode.d1.loss_dice: 0.3130  decode.d2.loss_cls: 0.2971  decode.d2.loss_mask: 0.2371  decode.d2.loss_dice: 0.2883  decode.d3.loss_cls: 0.2178  decode.d3.loss_mask: 0.2431  decode.d3.loss_dice: 0.3065  decode.d4.loss_cls: 0.3124  decode.d4.loss_mask: 0.2447  decode.d4.loss_dice: 0.2939  decode.d5.loss_cls: 0.2521  decode.d5.loss_mask: 0.2414  decode.d5.loss_dice: 0.3094  decode.d6.loss_cls: 0.2561  decode.d6.loss_mask: 0.2397  decode.d6.loss_dice: 0.2839  decode.d7.loss_cls: 0.2623  decode.d7.loss_mask: 0.2427  decode.d7.loss_dice: 0.3201  decode.d8.loss_cls: 0.2434  decode.d8.loss_mask: 0.2433  decode.d8.loss_dice: 0.3227
07/30 18:43:24 - mmengine - INFO - Iter(train) [16950/80000]  base_lr: 8.0712e-05 lr: 8.0712e-06  eta: 7:37:58  time: 0.4364  data_time: 0.0090  memory: 5278  grad_norm: 81.5691  loss: 8.5145  decode.loss_cls: 0.2553  decode.loss_mask: 0.2015  decode.loss_dice: 0.3094  decode.d0.loss_cls: 0.9439  decode.d0.loss_mask: 0.2113  decode.d0.loss_dice: 0.3124  decode.d1.loss_cls: 0.3069  decode.d1.loss_mask: 0.2037  decode.d1.loss_dice: 0.3021  decode.d2.loss_cls: 0.2669  decode.d2.loss_mask: 0.2018  decode.d2.loss_dice: 0.3199  decode.d3.loss_cls: 0.2980  decode.d3.loss_mask: 0.2001  decode.d3.loss_dice: 0.2934  decode.d4.loss_cls: 0.2582  decode.d4.loss_mask: 0.2006  decode.d4.loss_dice: 0.2916  decode.d5.loss_cls: 0.2725  decode.d5.loss_mask: 0.1996  decode.d5.loss_dice: 0.3064  decode.d6.loss_cls: 0.2777  decode.d6.loss_mask: 0.1999  decode.d6.loss_dice: 0.2844  decode.d7.loss_cls: 0.2983  decode.d7.loss_mask: 0.2014  decode.d7.loss_dice: 0.2858  decode.d8.loss_cls: 0.2971  decode.d8.loss_mask: 0.2002  decode.d8.loss_dice: 0.3143
07/30 18:43:46 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 18:43:46 - mmengine - INFO - Iter(train) [17000/80000]  base_lr: 8.0655e-05 lr: 8.0655e-06  eta: 7:37:36  time: 0.4356  data_time: 0.0088  memory: 5265  grad_norm: 108.3139  loss: 8.3986  decode.loss_cls: 0.1965  decode.loss_mask: 0.2274  decode.loss_dice: 0.3107  decode.d0.loss_cls: 0.9436  decode.d0.loss_mask: 0.2372  decode.d0.loss_dice: 0.3159  decode.d1.loss_cls: 0.3209  decode.d1.loss_mask: 0.2206  decode.d1.loss_dice: 0.3221  decode.d2.loss_cls: 0.2557  decode.d2.loss_mask: 0.2153  decode.d2.loss_dice: 0.2929  decode.d3.loss_cls: 0.2058  decode.d3.loss_mask: 0.2186  decode.d3.loss_dice: 0.3062  decode.d4.loss_cls: 0.2204  decode.d4.loss_mask: 0.2230  decode.d4.loss_dice: 0.2970  decode.d5.loss_cls: 0.2391  decode.d5.loss_mask: 0.2272  decode.d5.loss_dice: 0.3039  decode.d6.loss_cls: 0.2274  decode.d6.loss_mask: 0.2170  decode.d6.loss_dice: 0.2958  decode.d7.loss_cls: 0.2498  decode.d7.loss_mask: 0.2361  decode.d7.loss_dice: 0.3235  decode.d8.loss_cls: 0.2085  decode.d8.loss_mask: 0.2311  decode.d8.loss_dice: 0.3097
07/30 18:44:07 - mmengine - INFO - Iter(train) [17050/80000]  base_lr: 8.0597e-05 lr: 8.0597e-06  eta: 7:37:15  time: 0.4366  data_time: 0.0089  memory: 5265  grad_norm: 76.1786  loss: 7.8196  decode.loss_cls: 0.1136  decode.loss_mask: 0.2505  decode.loss_dice: 0.2677  decode.d0.loss_cls: 1.0306  decode.d0.loss_mask: 0.2574  decode.d0.loss_dice: 0.3050  decode.d1.loss_cls: 0.2389  decode.d1.loss_mask: 0.2533  decode.d1.loss_dice: 0.2708  decode.d2.loss_cls: 0.2601  decode.d2.loss_mask: 0.2484  decode.d2.loss_dice: 0.2647  decode.d3.loss_cls: 0.1563  decode.d3.loss_mask: 0.2529  decode.d3.loss_dice: 0.2771  decode.d4.loss_cls: 0.2120  decode.d4.loss_mask: 0.2499  decode.d4.loss_dice: 0.2955  decode.d5.loss_cls: 0.1768  decode.d5.loss_mask: 0.2497  decode.d5.loss_dice: 0.2711  decode.d6.loss_cls: 0.1096  decode.d6.loss_mask: 0.2497  decode.d6.loss_dice: 0.2756  decode.d7.loss_cls: 0.0974  decode.d7.loss_mask: 0.2517  decode.d7.loss_dice: 0.2777  decode.d8.loss_cls: 0.1413  decode.d8.loss_mask: 0.2487  decode.d8.loss_dice: 0.2654
07/30 18:44:29 - mmengine - INFO - Iter(train) [17100/80000]  base_lr: 8.0540e-05 lr: 8.0540e-06  eta: 7:36:53  time: 0.4356  data_time: 0.0090  memory: 5261  grad_norm: 58.5547  loss: 7.3522  decode.loss_cls: 0.1302  decode.loss_mask: 0.2621  decode.loss_dice: 0.2507  decode.d0.loss_cls: 0.9109  decode.d0.loss_mask: 0.2652  decode.d0.loss_dice: 0.2623  decode.d1.loss_cls: 0.1436  decode.d1.loss_mask: 0.2627  decode.d1.loss_dice: 0.2636  decode.d2.loss_cls: 0.1178  decode.d2.loss_mask: 0.2615  decode.d2.loss_dice: 0.2489  decode.d3.loss_cls: 0.1793  decode.d3.loss_mask: 0.2643  decode.d3.loss_dice: 0.2638  decode.d4.loss_cls: 0.1237  decode.d4.loss_mask: 0.2579  decode.d4.loss_dice: 0.2622  decode.d5.loss_cls: 0.1340  decode.d5.loss_mask: 0.2608  decode.d5.loss_dice: 0.2576  decode.d6.loss_cls: 0.1446  decode.d6.loss_mask: 0.2628  decode.d6.loss_dice: 0.2440  decode.d7.loss_cls: 0.1479  decode.d7.loss_mask: 0.2597  decode.d7.loss_dice: 0.2407  decode.d8.loss_cls: 0.1582  decode.d8.loss_mask: 0.2592  decode.d8.loss_dice: 0.2520
07/30 18:44:51 - mmengine - INFO - Iter(train) [17150/80000]  base_lr: 8.0482e-05 lr: 8.0482e-06  eta: 7:36:31  time: 0.4362  data_time: 0.0088  memory: 5246  grad_norm: 83.5143  loss: 7.3430  decode.loss_cls: 0.1434  decode.loss_mask: 0.2067  decode.loss_dice: 0.2959  decode.d0.loss_cls: 0.9770  decode.d0.loss_mask: 0.2029  decode.d0.loss_dice: 0.3289  decode.d1.loss_cls: 0.2101  decode.d1.loss_mask: 0.2107  decode.d1.loss_dice: 0.2952  decode.d2.loss_cls: 0.1453  decode.d2.loss_mask: 0.2044  decode.d2.loss_dice: 0.2809  decode.d3.loss_cls: 0.1624  decode.d3.loss_mask: 0.2008  decode.d3.loss_dice: 0.2852  decode.d4.loss_cls: 0.1126  decode.d4.loss_mask: 0.2048  decode.d4.loss_dice: 0.2902  decode.d5.loss_cls: 0.1201  decode.d5.loss_mask: 0.2062  decode.d5.loss_dice: 0.2967  decode.d6.loss_cls: 0.1601  decode.d6.loss_mask: 0.2061  decode.d6.loss_dice: 0.2921  decode.d7.loss_cls: 0.1652  decode.d7.loss_mask: 0.2086  decode.d7.loss_dice: 0.2895  decode.d8.loss_cls: 0.1412  decode.d8.loss_mask: 0.2036  decode.d8.loss_dice: 0.2962
07/30 18:45:13 - mmengine - INFO - Iter(train) [17200/80000]  base_lr: 8.0424e-05 lr: 8.0424e-06  eta: 7:36:10  time: 0.4526  data_time: 0.0091  memory: 5244  grad_norm: 71.2521  loss: 8.4894  decode.loss_cls: 0.1737  decode.loss_mask: 0.2359  decode.loss_dice: 0.3262  decode.d0.loss_cls: 0.9980  decode.d0.loss_mask: 0.2423  decode.d0.loss_dice: 0.3486  decode.d1.loss_cls: 0.2835  decode.d1.loss_mask: 0.2388  decode.d1.loss_dice: 0.3413  decode.d2.loss_cls: 0.2129  decode.d2.loss_mask: 0.2392  decode.d2.loss_dice: 0.3212  decode.d3.loss_cls: 0.1918  decode.d3.loss_mask: 0.2646  decode.d3.loss_dice: 0.3094  decode.d4.loss_cls: 0.1778  decode.d4.loss_mask: 0.2696  decode.d4.loss_dice: 0.3201  decode.d5.loss_cls: 0.1977  decode.d5.loss_mask: 0.2744  decode.d5.loss_dice: 0.3125  decode.d6.loss_cls: 0.1855  decode.d6.loss_mask: 0.2318  decode.d6.loss_dice: 0.3046  decode.d7.loss_cls: 0.1615  decode.d7.loss_mask: 0.2703  decode.d7.loss_dice: 0.3140  decode.d8.loss_cls: 0.1657  decode.d8.loss_mask: 0.2497  decode.d8.loss_dice: 0.3265
07/30 18:45:35 - mmengine - INFO - Iter(train) [17250/80000]  base_lr: 8.0367e-05 lr: 8.0367e-06  eta: 7:35:48  time: 0.4365  data_time: 0.0092  memory: 5246  grad_norm: 110.8942  loss: 9.1630  decode.loss_cls: 0.3150  decode.loss_mask: 0.2679  decode.loss_dice: 0.2322  decode.d0.loss_cls: 0.9938  decode.d0.loss_mask: 0.2788  decode.d0.loss_dice: 0.2511  decode.d1.loss_cls: 0.2953  decode.d1.loss_mask: 0.2754  decode.d1.loss_dice: 0.2482  decode.d2.loss_cls: 0.3199  decode.d2.loss_mask: 0.2794  decode.d2.loss_dice: 0.2601  decode.d3.loss_cls: 0.2901  decode.d3.loss_mask: 0.2793  decode.d3.loss_dice: 0.2510  decode.d4.loss_cls: 0.3534  decode.d4.loss_mask: 0.2705  decode.d4.loss_dice: 0.2547  decode.d5.loss_cls: 0.3451  decode.d5.loss_mask: 0.2670  decode.d5.loss_dice: 0.2592  decode.d6.loss_cls: 0.3478  decode.d6.loss_mask: 0.2658  decode.d6.loss_dice: 0.2342  decode.d7.loss_cls: 0.3525  decode.d7.loss_mask: 0.2656  decode.d7.loss_dice: 0.2393  decode.d8.loss_cls: 0.3618  decode.d8.loss_mask: 0.2675  decode.d8.loss_dice: 0.2413
07/30 18:45:57 - mmengine - INFO - Iter(train) [17300/80000]  base_lr: 8.0309e-05 lr: 8.0309e-06  eta: 7:35:27  time: 0.4361  data_time: 0.0093  memory: 5261  grad_norm: 175.8412  loss: 12.1744  decode.loss_cls: 0.2629  decode.loss_mask: 0.3913  decode.loss_dice: 0.4436  decode.d0.loss_cls: 1.1904  decode.d0.loss_mask: 0.4032  decode.d0.loss_dice: 0.4492  decode.d1.loss_cls: 0.3261  decode.d1.loss_mask: 0.4251  decode.d1.loss_dice: 0.4559  decode.d2.loss_cls: 0.3176  decode.d2.loss_mask: 0.3958  decode.d2.loss_dice: 0.4251  decode.d3.loss_cls: 0.3406  decode.d3.loss_mask: 0.4189  decode.d3.loss_dice: 0.4111  decode.d4.loss_cls: 0.2880  decode.d4.loss_mask: 0.3811  decode.d4.loss_dice: 0.4189  decode.d5.loss_cls: 0.2622  decode.d5.loss_mask: 0.4002  decode.d5.loss_dice: 0.4390  decode.d6.loss_cls: 0.2518  decode.d6.loss_mask: 0.4087  decode.d6.loss_dice: 0.4543  decode.d7.loss_cls: 0.2788  decode.d7.loss_mask: 0.3967  decode.d7.loss_dice: 0.4469  decode.d8.loss_cls: 0.2497  decode.d8.loss_mask: 0.3918  decode.d8.loss_dice: 0.4495
07/30 18:46:18 - mmengine - INFO - Iter(train) [17350/80000]  base_lr: 8.0251e-05 lr: 8.0251e-06  eta: 7:35:05  time: 0.4352  data_time: 0.0092  memory: 5261  grad_norm: 89.8777  loss: 8.8439  decode.loss_cls: 0.2097  decode.loss_mask: 0.2572  decode.loss_dice: 0.2555  decode.d0.loss_cls: 1.1197  decode.d0.loss_mask: 0.3052  decode.d0.loss_dice: 0.2699  decode.d1.loss_cls: 0.3531  decode.d1.loss_mask: 0.2717  decode.d1.loss_dice: 0.2581  decode.d2.loss_cls: 0.3320  decode.d2.loss_mask: 0.2662  decode.d2.loss_dice: 0.2474  decode.d3.loss_cls: 0.2804  decode.d3.loss_mask: 0.2656  decode.d3.loss_dice: 0.2667  decode.d4.loss_cls: 0.2606  decode.d4.loss_mask: 0.2736  decode.d4.loss_dice: 0.2789  decode.d5.loss_cls: 0.2600  decode.d5.loss_mask: 0.2671  decode.d5.loss_dice: 0.2485  decode.d6.loss_cls: 0.2268  decode.d6.loss_mask: 0.2571  decode.d6.loss_dice: 0.2623  decode.d7.loss_cls: 0.2416  decode.d7.loss_mask: 0.2720  decode.d7.loss_dice: 0.2764  decode.d8.loss_cls: 0.2253  decode.d8.loss_mask: 0.2682  decode.d8.loss_dice: 0.2672
07/30 18:46:40 - mmengine - INFO - Iter(train) [17400/80000]  base_lr: 8.0194e-05 lr: 8.0194e-06  eta: 7:34:43  time: 0.4350  data_time: 0.0092  memory: 5245  grad_norm: 121.8768  loss: 8.5801  decode.loss_cls: 0.2120  decode.loss_mask: 0.2762  decode.loss_dice: 0.2884  decode.d0.loss_cls: 1.0136  decode.d0.loss_mask: 0.3236  decode.d0.loss_dice: 0.3117  decode.d1.loss_cls: 0.3379  decode.d1.loss_mask: 0.2234  decode.d1.loss_dice: 0.2692  decode.d2.loss_cls: 0.2966  decode.d2.loss_mask: 0.2314  decode.d2.loss_dice: 0.2665  decode.d3.loss_cls: 0.2273  decode.d3.loss_mask: 0.2751  decode.d3.loss_dice: 0.2563  decode.d4.loss_cls: 0.1724  decode.d4.loss_mask: 0.2725  decode.d4.loss_dice: 0.2855  decode.d5.loss_cls: 0.1557  decode.d5.loss_mask: 0.2767  decode.d5.loss_dice: 0.2965  decode.d6.loss_cls: 0.1942  decode.d6.loss_mask: 0.2779  decode.d6.loss_dice: 0.2811  decode.d7.loss_cls: 0.2022  decode.d7.loss_mask: 0.2765  decode.d7.loss_dice: 0.2786  decode.d8.loss_cls: 0.2246  decode.d8.loss_mask: 0.2724  decode.d8.loss_dice: 0.3042
07/30 18:47:02 - mmengine - INFO - Iter(train) [17450/80000]  base_lr: 8.0136e-05 lr: 8.0136e-06  eta: 7:34:21  time: 0.4360  data_time: 0.0093  memory: 5245  grad_norm: 156.3868  loss: 13.5323  decode.loss_cls: 0.5160  decode.loss_mask: 0.2683  decode.loss_dice: 0.4436  decode.d0.loss_cls: 1.2456  decode.d0.loss_mask: 0.2821  decode.d0.loss_dice: 0.5222  decode.d1.loss_cls: 0.6785  decode.d1.loss_mask: 0.2746  decode.d1.loss_dice: 0.4166  decode.d2.loss_cls: 0.5769  decode.d2.loss_mask: 0.2796  decode.d2.loss_dice: 0.4465  decode.d3.loss_cls: 0.5179  decode.d3.loss_mask: 0.2830  decode.d3.loss_dice: 0.4389  decode.d4.loss_cls: 0.5203  decode.d4.loss_mask: 0.3067  decode.d4.loss_dice: 0.4298  decode.d5.loss_cls: 0.5468  decode.d5.loss_mask: 0.2983  decode.d5.loss_dice: 0.4449  decode.d6.loss_cls: 0.5706  decode.d6.loss_mask: 0.2939  decode.d6.loss_dice: 0.4196  decode.d7.loss_cls: 0.5090  decode.d7.loss_mask: 0.2976  decode.d7.loss_dice: 0.4236  decode.d8.loss_cls: 0.5298  decode.d8.loss_mask: 0.2998  decode.d8.loss_dice: 0.4512
07/30 18:47:24 - mmengine - INFO - Iter(train) [17500/80000]  base_lr: 8.0078e-05 lr: 8.0078e-06  eta: 7:33:59  time: 0.4347  data_time: 0.0088  memory: 5224  grad_norm: 156.7622  loss: 7.0695  decode.loss_cls: 0.0915  decode.loss_mask: 0.2428  decode.loss_dice: 0.2405  decode.d0.loss_cls: 0.9162  decode.d0.loss_mask: 0.2543  decode.d0.loss_dice: 0.2503  decode.d1.loss_cls: 0.1898  decode.d1.loss_mask: 0.2509  decode.d1.loss_dice: 0.2377  decode.d2.loss_cls: 0.2049  decode.d2.loss_mask: 0.2484  decode.d2.loss_dice: 0.2398  decode.d3.loss_cls: 0.1536  decode.d3.loss_mask: 0.2496  decode.d3.loss_dice: 0.2440  decode.d4.loss_cls: 0.1551  decode.d4.loss_mask: 0.2489  decode.d4.loss_dice: 0.2424  decode.d5.loss_cls: 0.1424  decode.d5.loss_mask: 0.2513  decode.d5.loss_dice: 0.2394  decode.d6.loss_cls: 0.1145  decode.d6.loss_mask: 0.2493  decode.d6.loss_dice: 0.2452  decode.d7.loss_cls: 0.1087  decode.d7.loss_mask: 0.2459  decode.d7.loss_dice: 0.2436  decode.d8.loss_cls: 0.0831  decode.d8.loss_mask: 0.2454  decode.d8.loss_dice: 0.2400
07/30 18:47:45 - mmengine - INFO - Iter(train) [17550/80000]  base_lr: 8.0021e-05 lr: 8.0021e-06  eta: 7:33:37  time: 0.4346  data_time: 0.0088  memory: 5305  grad_norm: 115.4419  loss: 8.6857  decode.loss_cls: 0.2927  decode.loss_mask: 0.2421  decode.loss_dice: 0.2988  decode.d0.loss_cls: 1.1570  decode.d0.loss_mask: 0.2471  decode.d0.loss_dice: 0.3425  decode.d1.loss_cls: 0.2772  decode.d1.loss_mask: 0.2384  decode.d1.loss_dice: 0.2869  decode.d2.loss_cls: 0.2157  decode.d2.loss_mask: 0.2372  decode.d2.loss_dice: 0.2846  decode.d3.loss_cls: 0.2113  decode.d3.loss_mask: 0.2368  decode.d3.loss_dice: 0.2972  decode.d4.loss_cls: 0.2055  decode.d4.loss_mask: 0.2374  decode.d4.loss_dice: 0.2947  decode.d5.loss_cls: 0.2205  decode.d5.loss_mask: 0.2412  decode.d5.loss_dice: 0.3212  decode.d6.loss_cls: 0.2070  decode.d6.loss_mask: 0.2357  decode.d6.loss_dice: 0.3104  decode.d7.loss_cls: 0.2448  decode.d7.loss_mask: 0.2409  decode.d7.loss_dice: 0.2916  decode.d8.loss_cls: 0.2193  decode.d8.loss_mask: 0.2413  decode.d8.loss_dice: 0.3088
07/30 18:48:07 - mmengine - INFO - Iter(train) [17600/80000]  base_lr: 7.9963e-05 lr: 7.9963e-06  eta: 7:33:15  time: 0.4349  data_time: 0.0090  memory: 5229  grad_norm: 65.5883  loss: 9.2660  decode.loss_cls: 0.2985  decode.loss_mask: 0.2338  decode.loss_dice: 0.2838  decode.d0.loss_cls: 1.0161  decode.d0.loss_mask: 0.2506  decode.d0.loss_dice: 0.3178  decode.d1.loss_cls: 0.5303  decode.d1.loss_mask: 0.2371  decode.d1.loss_dice: 0.2750  decode.d2.loss_cls: 0.3594  decode.d2.loss_mask: 0.2311  decode.d2.loss_dice: 0.2881  decode.d3.loss_cls: 0.3294  decode.d3.loss_mask: 0.2361  decode.d3.loss_dice: 0.2932  decode.d4.loss_cls: 0.2960  decode.d4.loss_mask: 0.2364  decode.d4.loss_dice: 0.2787  decode.d5.loss_cls: 0.3007  decode.d5.loss_mask: 0.2349  decode.d5.loss_dice: 0.2905  decode.d6.loss_cls: 0.2672  decode.d6.loss_mask: 0.2368  decode.d6.loss_dice: 0.2839  decode.d7.loss_cls: 0.3039  decode.d7.loss_mask: 0.2339  decode.d7.loss_dice: 0.2931  decode.d8.loss_cls: 0.2772  decode.d8.loss_mask: 0.2335  decode.d8.loss_dice: 0.3188
07/30 18:48:29 - mmengine - INFO - Iter(train) [17650/80000]  base_lr: 7.9906e-05 lr: 7.9906e-06  eta: 7:32:53  time: 0.4344  data_time: 0.0089  memory: 5261  grad_norm: 32.6539  loss: 5.7394  decode.loss_cls: 0.0481  decode.loss_mask: 0.2128  decode.loss_dice: 0.2227  decode.d0.loss_cls: 0.8077  decode.d0.loss_mask: 0.2204  decode.d0.loss_dice: 0.2345  decode.d1.loss_cls: 0.1352  decode.d1.loss_mask: 0.2146  decode.d1.loss_dice: 0.2206  decode.d2.loss_cls: 0.0595  decode.d2.loss_mask: 0.2146  decode.d2.loss_dice: 0.2222  decode.d3.loss_cls: 0.0533  decode.d3.loss_mask: 0.2152  decode.d3.loss_dice: 0.2230  decode.d4.loss_cls: 0.0466  decode.d4.loss_mask: 0.2125  decode.d4.loss_dice: 0.2170  decode.d5.loss_cls: 0.0524  decode.d5.loss_mask: 0.2143  decode.d5.loss_dice: 0.2238  decode.d6.loss_cls: 0.0452  decode.d6.loss_mask: 0.2140  decode.d6.loss_dice: 0.2294  decode.d7.loss_cls: 0.0534  decode.d7.loss_mask: 0.2149  decode.d7.loss_dice: 0.2214  decode.d8.loss_cls: 0.0526  decode.d8.loss_mask: 0.2152  decode.d8.loss_dice: 0.2225
07/30 18:48:51 - mmengine - INFO - Iter(train) [17700/80000]  base_lr: 7.9848e-05 lr: 7.9848e-06  eta: 7:32:31  time: 0.4355  data_time: 0.0097  memory: 5246  grad_norm: 94.3136  loss: 8.8802  decode.loss_cls: 0.2833  decode.loss_mask: 0.2456  decode.loss_dice: 0.2599  decode.d0.loss_cls: 1.0902  decode.d0.loss_mask: 0.2596  decode.d0.loss_dice: 0.2925  decode.d1.loss_cls: 0.3493  decode.d1.loss_mask: 0.2499  decode.d1.loss_dice: 0.2446  decode.d2.loss_cls: 0.2959  decode.d2.loss_mask: 0.2497  decode.d2.loss_dice: 0.2322  decode.d3.loss_cls: 0.3075  decode.d3.loss_mask: 0.2465  decode.d3.loss_dice: 0.2247  decode.d4.loss_cls: 0.2988  decode.d4.loss_mask: 0.2472  decode.d4.loss_dice: 0.2463  decode.d5.loss_cls: 0.3157  decode.d5.loss_mask: 0.2446  decode.d5.loss_dice: 0.2646  decode.d6.loss_cls: 0.3026  decode.d6.loss_mask: 0.2470  decode.d6.loss_dice: 0.2634  decode.d7.loss_cls: 0.2915  decode.d7.loss_mask: 0.2474  decode.d7.loss_dice: 0.2647  decode.d8.loss_cls: 0.3207  decode.d8.loss_mask: 0.2432  decode.d8.loss_dice: 0.2512
07/30 18:49:12 - mmengine - INFO - Iter(train) [17750/80000]  base_lr: 7.9790e-05 lr: 7.9790e-06  eta: 7:32:09  time: 0.4351  data_time: 0.0091  memory: 5279  grad_norm: 53.1562  loss: 8.1262  decode.loss_cls: 0.1584  decode.loss_mask: 0.2428  decode.loss_dice: 0.2624  decode.d0.loss_cls: 1.0563  decode.d0.loss_mask: 0.2569  decode.d0.loss_dice: 0.2938  decode.d1.loss_cls: 0.2828  decode.d1.loss_mask: 0.2452  decode.d1.loss_dice: 0.2586  decode.d2.loss_cls: 0.2332  decode.d2.loss_mask: 0.2482  decode.d2.loss_dice: 0.2602  decode.d3.loss_cls: 0.2471  decode.d3.loss_mask: 0.2440  decode.d3.loss_dice: 0.2665  decode.d4.loss_cls: 0.2297  decode.d4.loss_mask: 0.2439  decode.d4.loss_dice: 0.2586  decode.d5.loss_cls: 0.2182  decode.d5.loss_mask: 0.2469  decode.d5.loss_dice: 0.2613  decode.d6.loss_cls: 0.2013  decode.d6.loss_mask: 0.2466  decode.d6.loss_dice: 0.2634  decode.d7.loss_cls: 0.2442  decode.d7.loss_mask: 0.2446  decode.d7.loss_dice: 0.2514  decode.d8.loss_cls: 0.1594  decode.d8.loss_mask: 0.2453  decode.d8.loss_dice: 0.2549
07/30 18:49:34 - mmengine - INFO - Iter(train) [17800/80000]  base_lr: 7.9732e-05 lr: 7.9732e-06  eta: 7:31:47  time: 0.4336  data_time: 0.0088  memory: 5261  grad_norm: 77.1560  loss: 9.4291  decode.loss_cls: 0.3697  decode.loss_mask: 0.2184  decode.loss_dice: 0.2985  decode.d0.loss_cls: 1.1204  decode.d0.loss_mask: 0.2337  decode.d0.loss_dice: 0.3276  decode.d1.loss_cls: 0.4157  decode.d1.loss_mask: 0.2188  decode.d1.loss_dice: 0.3113  decode.d2.loss_cls: 0.3011  decode.d2.loss_mask: 0.2182  decode.d2.loss_dice: 0.2960  decode.d3.loss_cls: 0.3527  decode.d3.loss_mask: 0.2176  decode.d3.loss_dice: 0.2996  decode.d4.loss_cls: 0.2942  decode.d4.loss_mask: 0.2198  decode.d4.loss_dice: 0.3476  decode.d5.loss_cls: 0.3018  decode.d5.loss_mask: 0.2174  decode.d5.loss_dice: 0.2933  decode.d6.loss_cls: 0.2978  decode.d6.loss_mask: 0.2234  decode.d6.loss_dice: 0.3069  decode.d7.loss_cls: 0.3455  decode.d7.loss_mask: 0.2201  decode.d7.loss_dice: 0.3059  decode.d8.loss_cls: 0.3325  decode.d8.loss_mask: 0.2222  decode.d8.loss_dice: 0.3015
07/30 18:49:56 - mmengine - INFO - Iter(train) [17850/80000]  base_lr: 7.9675e-05 lr: 7.9675e-06  eta: 7:31:25  time: 0.4346  data_time: 0.0090  memory: 5277  grad_norm: 146.7236  loss: 11.1459  decode.loss_cls: 0.2771  decode.loss_mask: 0.3299  decode.loss_dice: 0.3601  decode.d0.loss_cls: 1.0563  decode.d0.loss_mask: 0.3371  decode.d0.loss_dice: 0.3970  decode.d1.loss_cls: 0.2724  decode.d1.loss_mask: 0.3361  decode.d1.loss_dice: 0.3675  decode.d2.loss_cls: 0.4569  decode.d2.loss_mask: 0.3225  decode.d2.loss_dice: 0.3600  decode.d3.loss_cls: 0.4099  decode.d3.loss_mask: 0.3171  decode.d3.loss_dice: 0.3566  decode.d4.loss_cls: 0.4420  decode.d4.loss_mask: 0.3224  decode.d4.loss_dice: 0.3646  decode.d5.loss_cls: 0.3686  decode.d5.loss_mask: 0.3257  decode.d5.loss_dice: 0.3518  decode.d6.loss_cls: 0.3135  decode.d6.loss_mask: 0.3301  decode.d6.loss_dice: 0.3551  decode.d7.loss_cls: 0.3596  decode.d7.loss_mask: 0.3210  decode.d7.loss_dice: 0.3344  decode.d8.loss_cls: 0.2918  decode.d8.loss_mask: 0.3372  decode.d8.loss_dice: 0.3715
07/30 18:50:18 - mmengine - INFO - Iter(train) [17900/80000]  base_lr: 7.9617e-05 lr: 7.9617e-06  eta: 7:31:03  time: 0.4347  data_time: 0.0087  memory: 5261  grad_norm: 95.4261  loss: 9.2491  decode.loss_cls: 0.2612  decode.loss_mask: 0.3155  decode.loss_dice: 0.2881  decode.d0.loss_cls: 1.2155  decode.d0.loss_mask: 0.2981  decode.d0.loss_dice: 0.2993  decode.d1.loss_cls: 0.2741  decode.d1.loss_mask: 0.2712  decode.d1.loss_dice: 0.2767  decode.d2.loss_cls: 0.2511  decode.d2.loss_mask: 0.2379  decode.d2.loss_dice: 0.2664  decode.d3.loss_cls: 0.2230  decode.d3.loss_mask: 0.2790  decode.d3.loss_dice: 0.2958  decode.d4.loss_cls: 0.3257  decode.d4.loss_mask: 0.2362  decode.d4.loss_dice: 0.2716  decode.d5.loss_cls: 0.2628  decode.d5.loss_mask: 0.2628  decode.d5.loss_dice: 0.2882  decode.d6.loss_cls: 0.2869  decode.d6.loss_mask: 0.2841  decode.d6.loss_dice: 0.2781  decode.d7.loss_cls: 0.2949  decode.d7.loss_mask: 0.2882  decode.d7.loss_dice: 0.2876  decode.d8.loss_cls: 0.2485  decode.d8.loss_mask: 0.2929  decode.d8.loss_dice: 0.2877
07/30 18:50:39 - mmengine - INFO - Iter(train) [17950/80000]  base_lr: 7.9559e-05 lr: 7.9559e-06  eta: 7:30:41  time: 0.4338  data_time: 0.0087  memory: 5265  grad_norm: 92.1479  loss: 6.4908  decode.loss_cls: 0.0441  decode.loss_mask: 0.2054  decode.loss_dice: 0.2932  decode.d0.loss_cls: 0.9983  decode.d0.loss_mask: 0.2177  decode.d0.loss_dice: 0.3137  decode.d1.loss_cls: 0.1343  decode.d1.loss_mask: 0.2023  decode.d1.loss_dice: 0.2786  decode.d2.loss_cls: 0.0617  decode.d2.loss_mask: 0.2041  decode.d2.loss_dice: 0.2878  decode.d3.loss_cls: 0.0558  decode.d3.loss_mask: 0.2059  decode.d3.loss_dice: 0.2842  decode.d4.loss_cls: 0.0543  decode.d4.loss_mask: 0.2032  decode.d4.loss_dice: 0.2853  decode.d5.loss_cls: 0.0609  decode.d5.loss_mask: 0.2022  decode.d5.loss_dice: 0.2782  decode.d6.loss_cls: 0.0591  decode.d6.loss_mask: 0.2035  decode.d6.loss_dice: 0.2779  decode.d7.loss_cls: 0.0461  decode.d7.loss_mask: 0.2015  decode.d7.loss_dice: 0.2846  decode.d8.loss_cls: 0.0504  decode.d8.loss_mask: 0.2045  decode.d8.loss_dice: 0.2923
07/30 18:51:01 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 18:51:01 - mmengine - INFO - Iter(train) [18000/80000]  base_lr: 7.9502e-05 lr: 7.9502e-06  eta: 7:30:19  time: 0.4350  data_time: 0.0090  memory: 5278  grad_norm: 74.0759  loss: 7.8972  decode.loss_cls: 0.1625  decode.loss_mask: 0.1719  decode.loss_dice: 0.2966  decode.d0.loss_cls: 1.0631  decode.d0.loss_mask: 0.1837  decode.d0.loss_dice: 0.3194  decode.d1.loss_cls: 0.3009  decode.d1.loss_mask: 0.1730  decode.d1.loss_dice: 0.2839  decode.d2.loss_cls: 0.2296  decode.d2.loss_mask: 0.1771  decode.d2.loss_dice: 0.2694  decode.d3.loss_cls: 0.2344  decode.d3.loss_mask: 0.1755  decode.d3.loss_dice: 0.2885  decode.d4.loss_cls: 0.2328  decode.d4.loss_mask: 0.1776  decode.d4.loss_dice: 0.2859  decode.d5.loss_cls: 0.2055  decode.d5.loss_mask: 0.1834  decode.d5.loss_dice: 0.3114  decode.d6.loss_cls: 0.2248  decode.d6.loss_mask: 0.1758  decode.d6.loss_dice: 0.2771  decode.d7.loss_cls: 0.3071  decode.d7.loss_mask: 0.1739  decode.d7.loss_dice: 0.2993  decode.d8.loss_cls: 0.2541  decode.d8.loss_mask: 0.1758  decode.d8.loss_dice: 0.2833
07/30 18:51:23 - mmengine - INFO - Iter(train) [18050/80000]  base_lr: 7.9444e-05 lr: 7.9444e-06  eta: 7:29:57  time: 0.4344  data_time: 0.0089  memory: 5227  grad_norm: 90.1733  loss: 7.2099  decode.loss_cls: 0.0693  decode.loss_mask: 0.2931  decode.loss_dice: 0.2585  decode.d0.loss_cls: 0.9193  decode.d0.loss_mask: 0.3037  decode.d0.loss_dice: 0.2756  decode.d1.loss_cls: 0.1015  decode.d1.loss_mask: 0.2977  decode.d1.loss_dice: 0.2586  decode.d2.loss_cls: 0.1027  decode.d2.loss_mask: 0.2925  decode.d2.loss_dice: 0.2526  decode.d3.loss_cls: 0.0789  decode.d3.loss_mask: 0.2954  decode.d3.loss_dice: 0.2548  decode.d4.loss_cls: 0.1007  decode.d4.loss_mask: 0.2973  decode.d4.loss_dice: 0.2570  decode.d5.loss_cls: 0.0812  decode.d5.loss_mask: 0.2980  decode.d5.loss_dice: 0.2593  decode.d6.loss_cls: 0.0659  decode.d6.loss_mask: 0.2933  decode.d6.loss_dice: 0.2609  decode.d7.loss_cls: 0.0618  decode.d7.loss_mask: 0.2913  decode.d7.loss_dice: 0.2619  decode.d8.loss_cls: 0.0733  decode.d8.loss_mask: 0.2933  decode.d8.loss_dice: 0.2604
07/30 18:51:45 - mmengine - INFO - Iter(train) [18100/80000]  base_lr: 7.9386e-05 lr: 7.9386e-06  eta: 7:29:35  time: 0.4342  data_time: 0.0090  memory: 5261  grad_norm: 102.0656  loss: 8.9858  decode.loss_cls: 0.2284  decode.loss_mask: 0.2898  decode.loss_dice: 0.3328  decode.d0.loss_cls: 0.9680  decode.d0.loss_mask: 0.3006  decode.d0.loss_dice: 0.3379  decode.d1.loss_cls: 0.2347  decode.d1.loss_mask: 0.2874  decode.d1.loss_dice: 0.3148  decode.d2.loss_cls: 0.2029  decode.d2.loss_mask: 0.2889  decode.d2.loss_dice: 0.3178  decode.d3.loss_cls: 0.1847  decode.d3.loss_mask: 0.2828  decode.d3.loss_dice: 0.2971  decode.d4.loss_cls: 0.1981  decode.d4.loss_mask: 0.2850  decode.d4.loss_dice: 0.3080  decode.d5.loss_cls: 0.1713  decode.d5.loss_mask: 0.2907  decode.d5.loss_dice: 0.3090  decode.d6.loss_cls: 0.2309  decode.d6.loss_mask: 0.2874  decode.d6.loss_dice: 0.2920  decode.d7.loss_cls: 0.2307  decode.d7.loss_mask: 0.2874  decode.d7.loss_dice: 0.3655  decode.d8.loss_cls: 0.2530  decode.d8.loss_mask: 0.2889  decode.d8.loss_dice: 0.3193
07/30 18:52:06 - mmengine - INFO - Iter(train) [18150/80000]  base_lr: 7.9329e-05 lr: 7.9329e-06  eta: 7:29:13  time: 0.4338  data_time: 0.0090  memory: 5246  grad_norm: 88.8710  loss: 9.7232  decode.loss_cls: 0.2470  decode.loss_mask: 0.3148  decode.loss_dice: 0.3269  decode.d0.loss_cls: 0.9494  decode.d0.loss_mask: 0.3275  decode.d0.loss_dice: 0.3668  decode.d1.loss_cls: 0.2081  decode.d1.loss_mask: 0.3153  decode.d1.loss_dice: 0.3351  decode.d2.loss_cls: 0.2619  decode.d2.loss_mask: 0.3112  decode.d2.loss_dice: 0.3390  decode.d3.loss_cls: 0.2235  decode.d3.loss_mask: 0.3156  decode.d3.loss_dice: 0.3359  decode.d4.loss_cls: 0.2487  decode.d4.loss_mask: 0.3229  decode.d4.loss_dice: 0.3443  decode.d5.loss_cls: 0.2142  decode.d5.loss_mask: 0.3170  decode.d5.loss_dice: 0.3487  decode.d6.loss_cls: 0.3272  decode.d6.loss_mask: 0.3135  decode.d6.loss_dice: 0.3245  decode.d7.loss_cls: 0.2157  decode.d7.loss_mask: 0.3181  decode.d7.loss_dice: 0.3238  decode.d8.loss_cls: 0.2630  decode.d8.loss_mask: 0.3182  decode.d8.loss_dice: 0.3456
07/30 18:52:28 - mmengine - INFO - Iter(train) [18200/80000]  base_lr: 7.9271e-05 lr: 7.9271e-06  eta: 7:28:51  time: 0.4351  data_time: 0.0090  memory: 5261  grad_norm: 78.9499  loss: 8.2567  decode.loss_cls: 0.2170  decode.loss_mask: 0.2250  decode.loss_dice: 0.2715  decode.d0.loss_cls: 0.9894  decode.d0.loss_mask: 0.2377  decode.d0.loss_dice: 0.3109  decode.d1.loss_cls: 0.3801  decode.d1.loss_mask: 0.2273  decode.d1.loss_dice: 0.2737  decode.d2.loss_cls: 0.2895  decode.d2.loss_mask: 0.2254  decode.d2.loss_dice: 0.2819  decode.d3.loss_cls: 0.1982  decode.d3.loss_mask: 0.2255  decode.d3.loss_dice: 0.2719  decode.d4.loss_cls: 0.2445  decode.d4.loss_mask: 0.2217  decode.d4.loss_dice: 0.2692  decode.d5.loss_cls: 0.2381  decode.d5.loss_mask: 0.2247  decode.d5.loss_dice: 0.2776  decode.d6.loss_cls: 0.1983  decode.d6.loss_mask: 0.2255  decode.d6.loss_dice: 0.2739  decode.d7.loss_cls: 0.2264  decode.d7.loss_mask: 0.2267  decode.d7.loss_dice: 0.2744  decode.d8.loss_cls: 0.2322  decode.d8.loss_mask: 0.2274  decode.d8.loss_dice: 0.2710
07/30 18:52:50 - mmengine - INFO - Iter(train) [18250/80000]  base_lr: 7.9213e-05 lr: 7.9213e-06  eta: 7:28:29  time: 0.4359  data_time: 0.0092  memory: 5279  grad_norm: 80.7057  loss: 10.3013  decode.loss_cls: 0.2337  decode.loss_mask: 0.3557  decode.loss_dice: 0.3365  decode.d0.loss_cls: 1.1663  decode.d0.loss_mask: 0.2862  decode.d0.loss_dice: 0.3540  decode.d1.loss_cls: 0.3694  decode.d1.loss_mask: 0.2940  decode.d1.loss_dice: 0.3352  decode.d2.loss_cls: 0.3077  decode.d2.loss_mask: 0.2895  decode.d2.loss_dice: 0.3413  decode.d3.loss_cls: 0.2607  decode.d3.loss_mask: 0.2858  decode.d3.loss_dice: 0.3536  decode.d4.loss_cls: 0.2391  decode.d4.loss_mask: 0.3399  decode.d4.loss_dice: 0.3266  decode.d5.loss_cls: 0.2938  decode.d5.loss_mask: 0.3356  decode.d5.loss_dice: 0.3291  decode.d6.loss_cls: 0.2267  decode.d6.loss_mask: 0.3616  decode.d6.loss_dice: 0.3208  decode.d7.loss_cls: 0.2740  decode.d7.loss_mask: 0.3585  decode.d7.loss_dice: 0.3438  decode.d8.loss_cls: 0.2739  decode.d8.loss_mask: 0.3490  decode.d8.loss_dice: 0.3593
07/30 18:53:12 - mmengine - INFO - Iter(train) [18300/80000]  base_lr: 7.9155e-05 lr: 7.9155e-06  eta: 7:28:08  time: 0.4354  data_time: 0.0090  memory: 5265  grad_norm: 62.4298  loss: 7.8909  decode.loss_cls: 0.2209  decode.loss_mask: 0.2240  decode.loss_dice: 0.2304  decode.d0.loss_cls: 1.0173  decode.d0.loss_mask: 0.2355  decode.d0.loss_dice: 0.2771  decode.d1.loss_cls: 0.2850  decode.d1.loss_mask: 0.2289  decode.d1.loss_dice: 0.2363  decode.d2.loss_cls: 0.2084  decode.d2.loss_mask: 0.2243  decode.d2.loss_dice: 0.2385  decode.d3.loss_cls: 0.2540  decode.d3.loss_mask: 0.2244  decode.d3.loss_dice: 0.2331  decode.d4.loss_cls: 0.2392  decode.d4.loss_mask: 0.2264  decode.d4.loss_dice: 0.2302  decode.d5.loss_cls: 0.2714  decode.d5.loss_mask: 0.2262  decode.d5.loss_dice: 0.2349  decode.d6.loss_cls: 0.2258  decode.d6.loss_mask: 0.2207  decode.d6.loss_dice: 0.2340  decode.d7.loss_cls: 0.2533  decode.d7.loss_mask: 0.2229  decode.d7.loss_dice: 0.2352  decode.d8.loss_cls: 0.2579  decode.d8.loss_mask: 0.2229  decode.d8.loss_dice: 0.2518
07/30 18:53:33 - mmengine - INFO - Iter(train) [18350/80000]  base_lr: 7.9098e-05 lr: 7.9098e-06  eta: 7:27:46  time: 0.4365  data_time: 0.0092  memory: 5279  grad_norm: 156.7656  loss: 11.0449  decode.loss_cls: 0.4660  decode.loss_mask: 0.2859  decode.loss_dice: 0.3083  decode.d0.loss_cls: 1.1803  decode.d0.loss_mask: 0.2950  decode.d0.loss_dice: 0.3610  decode.d1.loss_cls: 0.4627  decode.d1.loss_mask: 0.2991  decode.d1.loss_dice: 0.3319  decode.d2.loss_cls: 0.4312  decode.d2.loss_mask: 0.2975  decode.d2.loss_dice: 0.3126  decode.d3.loss_cls: 0.3905  decode.d3.loss_mask: 0.2951  decode.d3.loss_dice: 0.3111  decode.d4.loss_cls: 0.4011  decode.d4.loss_mask: 0.2978  decode.d4.loss_dice: 0.3074  decode.d5.loss_cls: 0.4472  decode.d5.loss_mask: 0.2931  decode.d5.loss_dice: 0.3018  decode.d6.loss_cls: 0.4182  decode.d6.loss_mask: 0.2923  decode.d6.loss_dice: 0.3256  decode.d7.loss_cls: 0.3134  decode.d7.loss_mask: 0.3108  decode.d7.loss_dice: 0.3458  decode.d8.loss_cls: 0.3727  decode.d8.loss_mask: 0.2776  decode.d8.loss_dice: 0.3119
07/30 18:53:55 - mmengine - INFO - Iter(train) [18400/80000]  base_lr: 7.9040e-05 lr: 7.9040e-06  eta: 7:27:24  time: 0.4364  data_time: 0.0092  memory: 5245  grad_norm: 72.6472  loss: 7.3685  decode.loss_cls: 0.1284  decode.loss_mask: 0.3464  decode.loss_dice: 0.2954  decode.d0.loss_cls: 0.8834  decode.d0.loss_mask: 0.2397  decode.d0.loss_dice: 0.2882  decode.d1.loss_cls: 0.1943  decode.d1.loss_mask: 0.2332  decode.d1.loss_dice: 0.2793  decode.d2.loss_cls: 0.1283  decode.d2.loss_mask: 0.2306  decode.d2.loss_dice: 0.2750  decode.d3.loss_cls: 0.1357  decode.d3.loss_mask: 0.2324  decode.d3.loss_dice: 0.2643  decode.d4.loss_cls: 0.1188  decode.d4.loss_mask: 0.2331  decode.d4.loss_dice: 0.2465  decode.d5.loss_cls: 0.1400  decode.d5.loss_mask: 0.2299  decode.d5.loss_dice: 0.2446  decode.d6.loss_cls: 0.1538  decode.d6.loss_mask: 0.2323  decode.d6.loss_dice: 0.2503  decode.d7.loss_cls: 0.1738  decode.d7.loss_mask: 0.2332  decode.d7.loss_dice: 0.2590  decode.d8.loss_cls: 0.1753  decode.d8.loss_mask: 0.2452  decode.d8.loss_dice: 0.2784
07/30 18:54:17 - mmengine - INFO - Iter(train) [18450/80000]  base_lr: 7.8982e-05 lr: 7.8982e-06  eta: 7:27:02  time: 0.4362  data_time: 0.0091  memory: 5261  grad_norm: 80.3037  loss: 8.4129  decode.loss_cls: 0.2155  decode.loss_mask: 0.2452  decode.loss_dice: 0.2942  decode.d0.loss_cls: 1.0219  decode.d0.loss_mask: 0.2583  decode.d0.loss_dice: 0.3238  decode.d1.loss_cls: 0.2422  decode.d1.loss_mask: 0.2475  decode.d1.loss_dice: 0.2952  decode.d2.loss_cls: 0.2025  decode.d2.loss_mask: 0.2470  decode.d2.loss_dice: 0.3020  decode.d3.loss_cls: 0.2209  decode.d3.loss_mask: 0.2487  decode.d3.loss_dice: 0.2997  decode.d4.loss_cls: 0.2457  decode.d4.loss_mask: 0.2464  decode.d4.loss_dice: 0.3049  decode.d5.loss_cls: 0.2084  decode.d5.loss_mask: 0.2444  decode.d5.loss_dice: 0.2935  decode.d6.loss_cls: 0.1788  decode.d6.loss_mask: 0.2462  decode.d6.loss_dice: 0.2985  decode.d7.loss_cls: 0.1913  decode.d7.loss_mask: 0.2428  decode.d7.loss_dice: 0.3019  decode.d8.loss_cls: 0.2091  decode.d8.loss_mask: 0.2420  decode.d8.loss_dice: 0.2944
07/30 18:54:39 - mmengine - INFO - Iter(train) [18500/80000]  base_lr: 7.8924e-05 lr: 7.8924e-06  eta: 7:26:41  time: 0.4369  data_time: 0.0091  memory: 5303  grad_norm: 87.8592  loss: 7.0985  decode.loss_cls: 0.1336  decode.loss_mask: 0.1909  decode.loss_dice: 0.2501  decode.d0.loss_cls: 1.0295  decode.d0.loss_mask: 0.2044  decode.d0.loss_dice: 0.2934  decode.d1.loss_cls: 0.2712  decode.d1.loss_mask: 0.1994  decode.d1.loss_dice: 0.2587  decode.d2.loss_cls: 0.1970  decode.d2.loss_mask: 0.1920  decode.d2.loss_dice: 0.2524  decode.d3.loss_cls: 0.1486  decode.d3.loss_mask: 0.1927  decode.d3.loss_dice: 0.2621  decode.d4.loss_cls: 0.1346  decode.d4.loss_mask: 0.1889  decode.d4.loss_dice: 0.2501  decode.d5.loss_cls: 0.1672  decode.d5.loss_mask: 0.1893  decode.d5.loss_dice: 0.2581  decode.d6.loss_cls: 0.1436  decode.d6.loss_mask: 0.1938  decode.d6.loss_dice: 0.2635  decode.d7.loss_cls: 0.1760  decode.d7.loss_mask: 0.1956  decode.d7.loss_dice: 0.2634  decode.d8.loss_cls: 0.1417  decode.d8.loss_mask: 0.1941  decode.d8.loss_dice: 0.2628
07/30 18:55:01 - mmengine - INFO - Iter(train) [18550/80000]  base_lr: 7.8867e-05 lr: 7.8867e-06  eta: 7:26:19  time: 0.4361  data_time: 0.0092  memory: 5279  grad_norm: 74.3505  loss: 8.8335  decode.loss_cls: 0.2231  decode.loss_mask: 0.2821  decode.loss_dice: 0.3167  decode.d0.loss_cls: 0.8614  decode.d0.loss_mask: 0.2923  decode.d0.loss_dice: 0.3244  decode.d1.loss_cls: 0.2338  decode.d1.loss_mask: 0.2827  decode.d1.loss_dice: 0.3228  decode.d2.loss_cls: 0.1793  decode.d2.loss_mask: 0.2853  decode.d2.loss_dice: 0.3186  decode.d3.loss_cls: 0.1892  decode.d3.loss_mask: 0.2972  decode.d3.loss_dice: 0.3379  decode.d4.loss_cls: 0.2155  decode.d4.loss_mask: 0.2801  decode.d4.loss_dice: 0.3147  decode.d5.loss_cls: 0.2606  decode.d5.loss_mask: 0.2818  decode.d5.loss_dice: 0.3192  decode.d6.loss_cls: 0.2242  decode.d6.loss_mask: 0.2837  decode.d6.loss_dice: 0.3110  decode.d7.loss_cls: 0.2043  decode.d7.loss_mask: 0.2847  decode.d7.loss_dice: 0.3117  decode.d8.loss_cls: 0.1965  decode.d8.loss_mask: 0.2846  decode.d8.loss_dice: 0.3141
07/30 18:55:22 - mmengine - INFO - Iter(train) [18600/80000]  base_lr: 7.8809e-05 lr: 7.8809e-06  eta: 7:25:57  time: 0.4361  data_time: 0.0092  memory: 5341  grad_norm: 67.3391  loss: 7.8210  decode.loss_cls: 0.2170  decode.loss_mask: 0.2412  decode.loss_dice: 0.2717  decode.d0.loss_cls: 1.1215  decode.d0.loss_mask: 0.2407  decode.d0.loss_dice: 0.2720  decode.d1.loss_cls: 0.2920  decode.d1.loss_mask: 0.2421  decode.d1.loss_dice: 0.2511  decode.d2.loss_cls: 0.1808  decode.d2.loss_mask: 0.2472  decode.d2.loss_dice: 0.2549  decode.d3.loss_cls: 0.1888  decode.d3.loss_mask: 0.2433  decode.d3.loss_dice: 0.2445  decode.d4.loss_cls: 0.1317  decode.d4.loss_mask: 0.2400  decode.d4.loss_dice: 0.2485  decode.d5.loss_cls: 0.1203  decode.d5.loss_mask: 0.2439  decode.d5.loss_dice: 0.2655  decode.d6.loss_cls: 0.1935  decode.d6.loss_mask: 0.2427  decode.d6.loss_dice: 0.2391  decode.d7.loss_cls: 0.2019  decode.d7.loss_mask: 0.2424  decode.d7.loss_dice: 0.2488  decode.d8.loss_cls: 0.2038  decode.d8.loss_mask: 0.2393  decode.d8.loss_dice: 0.2508
07/30 18:55:44 - mmengine - INFO - Iter(train) [18650/80000]  base_lr: 7.8751e-05 lr: 7.8751e-06  eta: 7:25:36  time: 0.4367  data_time: 0.0094  memory: 5265  grad_norm: 70.8535  loss: 9.5469  decode.loss_cls: 0.3554  decode.loss_mask: 0.2709  decode.loss_dice: 0.3034  decode.d0.loss_cls: 1.0661  decode.d0.loss_mask: 0.2826  decode.d0.loss_dice: 0.3255  decode.d1.loss_cls: 0.4191  decode.d1.loss_mask: 0.2672  decode.d1.loss_dice: 0.3091  decode.d2.loss_cls: 0.2401  decode.d2.loss_mask: 0.2653  decode.d2.loss_dice: 0.2989  decode.d3.loss_cls: 0.2012  decode.d3.loss_mask: 0.2751  decode.d3.loss_dice: 0.2965  decode.d4.loss_cls: 0.2997  decode.d4.loss_mask: 0.2691  decode.d4.loss_dice: 0.2992  decode.d5.loss_cls: 0.2856  decode.d5.loss_mask: 0.2649  decode.d5.loss_dice: 0.3031  decode.d6.loss_cls: 0.3429  decode.d6.loss_mask: 0.2614  decode.d6.loss_dice: 0.3327  decode.d7.loss_cls: 0.3167  decode.d7.loss_mask: 0.2594  decode.d7.loss_dice: 0.2931  decode.d8.loss_cls: 0.2780  decode.d8.loss_mask: 0.2686  decode.d8.loss_dice: 0.2960
07/30 18:56:06 - mmengine - INFO - Iter(train) [18700/80000]  base_lr: 7.8693e-05 lr: 7.8693e-06  eta: 7:25:14  time: 0.4357  data_time: 0.0093  memory: 5246  grad_norm: 109.6001  loss: 10.0801  decode.loss_cls: 0.2179  decode.loss_mask: 0.3628  decode.loss_dice: 0.3531  decode.d0.loss_cls: 1.0060  decode.d0.loss_mask: 0.3632  decode.d0.loss_dice: 0.3762  decode.d1.loss_cls: 0.2861  decode.d1.loss_mask: 0.3632  decode.d1.loss_dice: 0.3315  decode.d2.loss_cls: 0.2044  decode.d2.loss_mask: 0.3685  decode.d2.loss_dice: 0.3570  decode.d3.loss_cls: 0.2155  decode.d3.loss_mask: 0.3594  decode.d3.loss_dice: 0.3503  decode.d4.loss_cls: 0.1872  decode.d4.loss_mask: 0.3660  decode.d4.loss_dice: 0.3479  decode.d5.loss_cls: 0.2147  decode.d5.loss_mask: 0.3692  decode.d5.loss_dice: 0.3455  decode.d6.loss_cls: 0.2163  decode.d6.loss_mask: 0.3598  decode.d6.loss_dice: 0.3353  decode.d7.loss_cls: 0.1925  decode.d7.loss_mask: 0.3649  decode.d7.loss_dice: 0.3550  decode.d8.loss_cls: 0.2084  decode.d8.loss_mask: 0.3617  decode.d8.loss_dice: 0.3407
07/30 18:56:28 - mmengine - INFO - Iter(train) [18750/80000]  base_lr: 7.8636e-05 lr: 7.8636e-06  eta: 7:24:52  time: 0.4366  data_time: 0.0092  memory: 5261  grad_norm: 137.8846  loss: 9.8879  decode.loss_cls: 0.2913  decode.loss_mask: 0.2423  decode.loss_dice: 0.3655  decode.d0.loss_cls: 1.0693  decode.d0.loss_mask: 0.2674  decode.d0.loss_dice: 0.4152  decode.d1.loss_cls: 0.3914  decode.d1.loss_mask: 0.2378  decode.d1.loss_dice: 0.3532  decode.d2.loss_cls: 0.3506  decode.d2.loss_mask: 0.2383  decode.d2.loss_dice: 0.3471  decode.d3.loss_cls: 0.3168  decode.d3.loss_mask: 0.2382  decode.d3.loss_dice: 0.3705  decode.d4.loss_cls: 0.3297  decode.d4.loss_mask: 0.2319  decode.d4.loss_dice: 0.3666  decode.d5.loss_cls: 0.3035  decode.d5.loss_mask: 0.2525  decode.d5.loss_dice: 0.3659  decode.d6.loss_cls: 0.2560  decode.d6.loss_mask: 0.2492  decode.d6.loss_dice: 0.3645  decode.d7.loss_cls: 0.2513  decode.d7.loss_mask: 0.2427  decode.d7.loss_dice: 0.3570  decode.d8.loss_cls: 0.2401  decode.d8.loss_mask: 0.2272  decode.d8.loss_dice: 0.3548
07/30 18:56:50 - mmengine - INFO - Iter(train) [18800/80000]  base_lr: 7.8578e-05 lr: 7.8578e-06  eta: 7:24:30  time: 0.4362  data_time: 0.0093  memory: 5227  grad_norm: 82.0416  loss: 9.9780  decode.loss_cls: 0.2801  decode.loss_mask: 0.2626  decode.loss_dice: 0.3116  decode.d0.loss_cls: 1.0627  decode.d0.loss_mask: 0.2882  decode.d0.loss_dice: 0.3650  decode.d1.loss_cls: 0.4699  decode.d1.loss_mask: 0.2681  decode.d1.loss_dice: 0.3177  decode.d2.loss_cls: 0.3474  decode.d2.loss_mask: 0.2605  decode.d2.loss_dice: 0.3336  decode.d3.loss_cls: 0.3759  decode.d3.loss_mask: 0.2598  decode.d3.loss_dice: 0.3138  decode.d4.loss_cls: 0.3095  decode.d4.loss_mask: 0.2608  decode.d4.loss_dice: 0.3256  decode.d5.loss_cls: 0.2842  decode.d5.loss_mask: 0.2640  decode.d5.loss_dice: 0.3249  decode.d6.loss_cls: 0.3183  decode.d6.loss_mask: 0.2628  decode.d6.loss_dice: 0.3067  decode.d7.loss_cls: 0.3364  decode.d7.loss_mask: 0.2629  decode.d7.loss_dice: 0.3164  decode.d8.loss_cls: 0.3268  decode.d8.loss_mask: 0.2605  decode.d8.loss_dice: 0.3016
07/30 18:57:12 - mmengine - INFO - Iter(train) [18850/80000]  base_lr: 7.8520e-05 lr: 7.8520e-06  eta: 7:24:09  time: 0.4359  data_time: 0.0091  memory: 5277  grad_norm: 107.2543  loss: 9.3131  decode.loss_cls: 0.1987  decode.loss_mask: 0.2997  decode.loss_dice: 0.3038  decode.d0.loss_cls: 0.9618  decode.d0.loss_mask: 0.3018  decode.d0.loss_dice: 0.3225  decode.d1.loss_cls: 0.2966  decode.d1.loss_mask: 0.2934  decode.d1.loss_dice: 0.3084  decode.d2.loss_cls: 0.2800  decode.d2.loss_mask: 0.2945  decode.d2.loss_dice: 0.3102  decode.d3.loss_cls: 0.2400  decode.d3.loss_mask: 0.2953  decode.d3.loss_dice: 0.3151  decode.d4.loss_cls: 0.2318  decode.d4.loss_mask: 0.2965  decode.d4.loss_dice: 0.3153  decode.d5.loss_cls: 0.2434  decode.d5.loss_mask: 0.2986  decode.d5.loss_dice: 0.3313  decode.d6.loss_cls: 0.2859  decode.d6.loss_mask: 0.2984  decode.d6.loss_dice: 0.3097  decode.d7.loss_cls: 0.2350  decode.d7.loss_mask: 0.2988  decode.d7.loss_dice: 0.3118  decode.d8.loss_cls: 0.2390  decode.d8.loss_mask: 0.2932  decode.d8.loss_dice: 0.3025
07/30 18:57:33 - mmengine - INFO - Iter(train) [18900/80000]  base_lr: 7.8462e-05 lr: 7.8462e-06  eta: 7:23:47  time: 0.4360  data_time: 0.0090  memory: 5246  grad_norm: 122.3722  loss: 8.0616  decode.loss_cls: 0.0865  decode.loss_mask: 0.2405  decode.loss_dice: 0.3570  decode.d0.loss_cls: 1.0328  decode.d0.loss_mask: 0.2328  decode.d0.loss_dice: 0.3622  decode.d1.loss_cls: 0.3255  decode.d1.loss_mask: 0.2298  decode.d1.loss_dice: 0.3414  decode.d2.loss_cls: 0.2121  decode.d2.loss_mask: 0.2294  decode.d2.loss_dice: 0.3214  decode.d3.loss_cls: 0.1413  decode.d3.loss_mask: 0.2297  decode.d3.loss_dice: 0.3334  decode.d4.loss_cls: 0.0733  decode.d4.loss_mask: 0.2364  decode.d4.loss_dice: 0.3588  decode.d5.loss_cls: 0.0791  decode.d5.loss_mask: 0.2285  decode.d5.loss_dice: 0.3472  decode.d6.loss_cls: 0.0499  decode.d6.loss_mask: 0.2450  decode.d6.loss_dice: 0.3588  decode.d7.loss_cls: 0.1233  decode.d7.loss_mask: 0.2337  decode.d7.loss_dice: 0.3530  decode.d8.loss_cls: 0.1082  decode.d8.loss_mask: 0.2318  decode.d8.loss_dice: 0.3587
07/30 18:57:55 - mmengine - INFO - Iter(train) [18950/80000]  base_lr: 7.8405e-05 lr: 7.8405e-06  eta: 7:23:26  time: 0.4358  data_time: 0.0093  memory: 5305  grad_norm: 133.4599  loss: 8.6932  decode.loss_cls: 0.1067  decode.loss_mask: 0.3007  decode.loss_dice: 0.3591  decode.d0.loss_cls: 1.0638  decode.d0.loss_mask: 0.2724  decode.d0.loss_dice: 0.3364  decode.d1.loss_cls: 0.2411  decode.d1.loss_mask: 0.2875  decode.d1.loss_dice: 0.3314  decode.d2.loss_cls: 0.1710  decode.d2.loss_mask: 0.2857  decode.d2.loss_dice: 0.3006  decode.d3.loss_cls: 0.1223  decode.d3.loss_mask: 0.2918  decode.d3.loss_dice: 0.3565  decode.d4.loss_cls: 0.0913  decode.d4.loss_mask: 0.2958  decode.d4.loss_dice: 0.3407  decode.d5.loss_cls: 0.1245  decode.d5.loss_mask: 0.2955  decode.d5.loss_dice: 0.3248  decode.d6.loss_cls: 0.1074  decode.d6.loss_mask: 0.3004  decode.d6.loss_dice: 0.3744  decode.d7.loss_cls: 0.1591  decode.d7.loss_mask: 0.2966  decode.d7.loss_dice: 0.3474  decode.d8.loss_cls: 0.1232  decode.d8.loss_mask: 0.3118  decode.d8.loss_dice: 0.3734
07/30 18:58:17 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 18:58:17 - mmengine - INFO - Iter(train) [19000/80000]  base_lr: 7.8347e-05 lr: 7.8347e-06  eta: 7:23:04  time: 0.4363  data_time: 0.0092  memory: 5244  grad_norm: 71.8728  loss: 7.8894  decode.loss_cls: 0.1797  decode.loss_mask: 0.2568  decode.loss_dice: 0.2436  decode.d0.loss_cls: 1.0492  decode.d0.loss_mask: 0.2727  decode.d0.loss_dice: 0.2551  decode.d1.loss_cls: 0.1831  decode.d1.loss_mask: 0.2635  decode.d1.loss_dice: 0.2647  decode.d2.loss_cls: 0.1593  decode.d2.loss_mask: 0.2585  decode.d2.loss_dice: 0.2459  decode.d3.loss_cls: 0.2094  decode.d3.loss_mask: 0.2540  decode.d3.loss_dice: 0.2380  decode.d4.loss_cls: 0.1955  decode.d4.loss_mask: 0.2561  decode.d4.loss_dice: 0.2570  decode.d5.loss_cls: 0.2311  decode.d5.loss_mask: 0.2597  decode.d5.loss_dice: 0.2455  decode.d6.loss_cls: 0.2150  decode.d6.loss_mask: 0.2546  decode.d6.loss_dice: 0.2422  decode.d7.loss_cls: 0.2072  decode.d7.loss_mask: 0.2569  decode.d7.loss_dice: 0.2470  decode.d8.loss_cls: 0.1980  decode.d8.loss_mask: 0.2583  decode.d8.loss_dice: 0.2315
07/30 18:58:39 - mmengine - INFO - Iter(train) [19050/80000]  base_lr: 7.8289e-05 lr: 7.8289e-06  eta: 7:22:42  time: 0.4347  data_time: 0.0093  memory: 5278  grad_norm: 109.9048  loss: 11.3212  decode.loss_cls: 0.4906  decode.loss_mask: 0.2336  decode.loss_dice: 0.3386  decode.d0.loss_cls: 1.3201  decode.d0.loss_mask: 0.2480  decode.d0.loss_dice: 0.3620  decode.d1.loss_cls: 0.5257  decode.d1.loss_mask: 0.2391  decode.d1.loss_dice: 0.3274  decode.d2.loss_cls: 0.4520  decode.d2.loss_mask: 0.2409  decode.d2.loss_dice: 0.3311  decode.d3.loss_cls: 0.4344  decode.d3.loss_mask: 0.2349  decode.d3.loss_dice: 0.3153  decode.d4.loss_cls: 0.4799  decode.d4.loss_mask: 0.2308  decode.d4.loss_dice: 0.3337  decode.d5.loss_cls: 0.4908  decode.d5.loss_mask: 0.2322  decode.d5.loss_dice: 0.3317  decode.d6.loss_cls: 0.4479  decode.d6.loss_mask: 0.2303  decode.d6.loss_dice: 0.3501  decode.d7.loss_cls: 0.4662  decode.d7.loss_mask: 0.2308  decode.d7.loss_dice: 0.3506  decode.d8.loss_cls: 0.4855  decode.d8.loss_mask: 0.2352  decode.d8.loss_dice: 0.3320
07/30 18:59:01 - mmengine - INFO - Iter(train) [19100/80000]  base_lr: 7.8231e-05 lr: 7.8231e-06  eta: 7:22:20  time: 0.4372  data_time: 0.0092  memory: 5246  grad_norm: 58.5104  loss: 7.0893  decode.loss_cls: 0.1221  decode.loss_mask: 0.2363  decode.loss_dice: 0.2478  decode.d0.loss_cls: 0.9441  decode.d0.loss_mask: 0.2508  decode.d0.loss_dice: 0.2963  decode.d1.loss_cls: 0.1049  decode.d1.loss_mask: 0.2410  decode.d1.loss_dice: 0.2536  decode.d2.loss_cls: 0.1067  decode.d2.loss_mask: 0.2437  decode.d2.loss_dice: 0.2697  decode.d3.loss_cls: 0.0906  decode.d3.loss_mask: 0.2396  decode.d3.loss_dice: 0.2572  decode.d4.loss_cls: 0.1242  decode.d4.loss_mask: 0.2387  decode.d4.loss_dice: 0.2648  decode.d5.loss_cls: 0.1364  decode.d5.loss_mask: 0.2398  decode.d5.loss_dice: 0.2875  decode.d6.loss_cls: 0.1391  decode.d6.loss_mask: 0.2367  decode.d6.loss_dice: 0.2774  decode.d7.loss_cls: 0.1427  decode.d7.loss_mask: 0.2397  decode.d7.loss_dice: 0.2647  decode.d8.loss_cls: 0.0713  decode.d8.loss_mask: 0.2386  decode.d8.loss_dice: 0.2835
07/30 18:59:23 - mmengine - INFO - Iter(train) [19150/80000]  base_lr: 7.8173e-05 lr: 7.8173e-06  eta: 7:21:59  time: 0.4375  data_time: 0.0091  memory: 5261  grad_norm: 122.2656  loss: 8.0895  decode.loss_cls: 0.1366  decode.loss_mask: 0.2988  decode.loss_dice: 0.2767  decode.d0.loss_cls: 0.9621  decode.d0.loss_mask: 0.3163  decode.d0.loss_dice: 0.2993  decode.d1.loss_cls: 0.1798  decode.d1.loss_mask: 0.3051  decode.d1.loss_dice: 0.2891  decode.d2.loss_cls: 0.1431  decode.d2.loss_mask: 0.3092  decode.d2.loss_dice: 0.2855  decode.d3.loss_cls: 0.1060  decode.d3.loss_mask: 0.3014  decode.d3.loss_dice: 0.2774  decode.d4.loss_cls: 0.1142  decode.d4.loss_mask: 0.2997  decode.d4.loss_dice: 0.2782  decode.d5.loss_cls: 0.1355  decode.d5.loss_mask: 0.2988  decode.d5.loss_dice: 0.2771  decode.d6.loss_cls: 0.1505  decode.d6.loss_mask: 0.2979  decode.d6.loss_dice: 0.2776  decode.d7.loss_cls: 0.1450  decode.d7.loss_mask: 0.3016  decode.d7.loss_dice: 0.2829  decode.d8.loss_cls: 0.1607  decode.d8.loss_mask: 0.3020  decode.d8.loss_dice: 0.2814
07/30 18:59:44 - mmengine - INFO - Iter(train) [19200/80000]  base_lr: 7.8115e-05 lr: 7.8115e-06  eta: 7:21:37  time: 0.4357  data_time: 0.0090  memory: 5246  grad_norm: 79.4324  loss: 6.5280  decode.loss_cls: 0.1211  decode.loss_mask: 0.1731  decode.loss_dice: 0.2705  decode.d0.loss_cls: 0.8718  decode.d0.loss_mask: 0.1818  decode.d0.loss_dice: 0.3120  decode.d1.loss_cls: 0.1203  decode.d1.loss_mask: 0.1793  decode.d1.loss_dice: 0.2501  decode.d2.loss_cls: 0.1290  decode.d2.loss_mask: 0.1761  decode.d2.loss_dice: 0.2713  decode.d3.loss_cls: 0.1509  decode.d3.loss_mask: 0.1741  decode.d3.loss_dice: 0.2632  decode.d4.loss_cls: 0.1239  decode.d4.loss_mask: 0.1738  decode.d4.loss_dice: 0.2512  decode.d5.loss_cls: 0.1231  decode.d5.loss_mask: 0.1791  decode.d5.loss_dice: 0.2879  decode.d6.loss_cls: 0.1010  decode.d6.loss_mask: 0.1811  decode.d6.loss_dice: 0.2951  decode.d7.loss_cls: 0.1393  decode.d7.loss_mask: 0.1770  decode.d7.loss_dice: 0.2769  decode.d8.loss_cls: 0.1119  decode.d8.loss_mask: 0.1790  decode.d8.loss_dice: 0.2831
07/30 19:00:06 - mmengine - INFO - Iter(train) [19250/80000]  base_lr: 7.8058e-05 lr: 7.8058e-06  eta: 7:21:15  time: 0.4353  data_time: 0.0090  memory: 5265  grad_norm: 63.2173  loss: 7.8563  decode.loss_cls: 0.1036  decode.loss_mask: 0.2658  decode.loss_dice: 0.3270  decode.d0.loss_cls: 0.9704  decode.d0.loss_mask: 0.2988  decode.d0.loss_dice: 0.3405  decode.d1.loss_cls: 0.1211  decode.d1.loss_mask: 0.2733  decode.d1.loss_dice: 0.3219  decode.d2.loss_cls: 0.1291  decode.d2.loss_mask: 0.2707  decode.d2.loss_dice: 0.2997  decode.d3.loss_cls: 0.0870  decode.d3.loss_mask: 0.2761  decode.d3.loss_dice: 0.2966  decode.d4.loss_cls: 0.1026  decode.d4.loss_mask: 0.2697  decode.d4.loss_dice: 0.3279  decode.d5.loss_cls: 0.0884  decode.d5.loss_mask: 0.2690  decode.d5.loss_dice: 0.3070  decode.d6.loss_cls: 0.1000  decode.d6.loss_mask: 0.2698  decode.d6.loss_dice: 0.3190  decode.d7.loss_cls: 0.1031  decode.d7.loss_mask: 0.2702  decode.d7.loss_dice: 0.3139  decode.d8.loss_cls: 0.1377  decode.d8.loss_mask: 0.2734  decode.d8.loss_dice: 0.3230
07/30 19:00:28 - mmengine - INFO - Iter(train) [19300/80000]  base_lr: 7.8000e-05 lr: 7.8000e-06  eta: 7:20:54  time: 0.4355  data_time: 0.0090  memory: 5277  grad_norm: 110.5427  loss: 8.8146  decode.loss_cls: 0.2016  decode.loss_mask: 0.2528  decode.loss_dice: 0.3169  decode.d0.loss_cls: 1.0382  decode.d0.loss_mask: 0.2607  decode.d0.loss_dice: 0.3081  decode.d1.loss_cls: 0.2991  decode.d1.loss_mask: 0.2506  decode.d1.loss_dice: 0.3002  decode.d2.loss_cls: 0.2848  decode.d2.loss_mask: 0.2491  decode.d2.loss_dice: 0.2912  decode.d3.loss_cls: 0.2865  decode.d3.loss_mask: 0.2461  decode.d3.loss_dice: 0.2712  decode.d4.loss_cls: 0.2395  decode.d4.loss_mask: 0.2471  decode.d4.loss_dice: 0.3140  decode.d5.loss_cls: 0.2501  decode.d5.loss_mask: 0.2462  decode.d5.loss_dice: 0.2894  decode.d6.loss_cls: 0.2541  decode.d6.loss_mask: 0.2464  decode.d6.loss_dice: 0.3082  decode.d7.loss_cls: 0.2302  decode.d7.loss_mask: 0.2493  decode.d7.loss_dice: 0.3067  decode.d8.loss_cls: 0.2185  decode.d8.loss_mask: 0.2458  decode.d8.loss_dice: 0.3120
07/30 19:00:50 - mmengine - INFO - Iter(train) [19350/80000]  base_lr: 7.7942e-05 lr: 7.7942e-06  eta: 7:20:32  time: 0.4360  data_time: 0.0092  memory: 5245  grad_norm: 73.1609  loss: 7.9896  decode.loss_cls: 0.2045  decode.loss_mask: 0.2441  decode.loss_dice: 0.2922  decode.d0.loss_cls: 0.9868  decode.d0.loss_mask: 0.2430  decode.d0.loss_dice: 0.2885  decode.d1.loss_cls: 0.1939  decode.d1.loss_mask: 0.2442  decode.d1.loss_dice: 0.2899  decode.d2.loss_cls: 0.1194  decode.d2.loss_mask: 0.2479  decode.d2.loss_dice: 0.3250  decode.d3.loss_cls: 0.1229  decode.d3.loss_mask: 0.2397  decode.d3.loss_dice: 0.2765  decode.d4.loss_cls: 0.1608  decode.d4.loss_mask: 0.2387  decode.d4.loss_dice: 0.2974  decode.d5.loss_cls: 0.2207  decode.d5.loss_mask: 0.2388  decode.d5.loss_dice: 0.3010  decode.d6.loss_cls: 0.1792  decode.d6.loss_mask: 0.2401  decode.d6.loss_dice: 0.3037  decode.d7.loss_cls: 0.1878  decode.d7.loss_mask: 0.2428  decode.d7.loss_dice: 0.2973  decode.d8.loss_cls: 0.2218  decode.d8.loss_mask: 0.2429  decode.d8.loss_dice: 0.2983
07/30 19:01:12 - mmengine - INFO - Iter(train) [19400/80000]  base_lr: 7.7884e-05 lr: 7.7884e-06  eta: 7:20:10  time: 0.4362  data_time: 0.0093  memory: 5265  grad_norm: 65.3833  loss: 7.3559  decode.loss_cls: 0.1509  decode.loss_mask: 0.2289  decode.loss_dice: 0.2613  decode.d0.loss_cls: 0.8888  decode.d0.loss_mask: 0.2334  decode.d0.loss_dice: 0.2685  decode.d1.loss_cls: 0.2903  decode.d1.loss_mask: 0.2287  decode.d1.loss_dice: 0.2637  decode.d2.loss_cls: 0.2391  decode.d2.loss_mask: 0.2272  decode.d2.loss_dice: 0.2398  decode.d3.loss_cls: 0.1562  decode.d3.loss_mask: 0.2302  decode.d3.loss_dice: 0.2612  decode.d4.loss_cls: 0.1592  decode.d4.loss_mask: 0.2321  decode.d4.loss_dice: 0.2523  decode.d5.loss_cls: 0.1446  decode.d5.loss_mask: 0.2280  decode.d5.loss_dice: 0.2568  decode.d6.loss_cls: 0.1393  decode.d6.loss_mask: 0.2292  decode.d6.loss_dice: 0.2567  decode.d7.loss_cls: 0.1507  decode.d7.loss_mask: 0.2281  decode.d7.loss_dice: 0.2534  decode.d8.loss_cls: 0.1679  decode.d8.loss_mask: 0.2239  decode.d8.loss_dice: 0.2655
07/30 19:01:33 - mmengine - INFO - Iter(train) [19450/80000]  base_lr: 7.7826e-05 lr: 7.7826e-06  eta: 7:19:48  time: 0.4366  data_time: 0.0093  memory: 5279  grad_norm: 106.6320  loss: 9.3223  decode.loss_cls: 0.2625  decode.loss_mask: 0.2605  decode.loss_dice: 0.3051  decode.d0.loss_cls: 0.9481  decode.d0.loss_mask: 0.2713  decode.d0.loss_dice: 0.4070  decode.d1.loss_cls: 0.3343  decode.d1.loss_mask: 0.2624  decode.d1.loss_dice: 0.3231  decode.d2.loss_cls: 0.2326  decode.d2.loss_mask: 0.2655  decode.d2.loss_dice: 0.3562  decode.d3.loss_cls: 0.2513  decode.d3.loss_mask: 0.2633  decode.d3.loss_dice: 0.3319  decode.d4.loss_cls: 0.2753  decode.d4.loss_mask: 0.2612  decode.d4.loss_dice: 0.3122  decode.d5.loss_cls: 0.2230  decode.d5.loss_mask: 0.2646  decode.d5.loss_dice: 0.3350  decode.d6.loss_cls: 0.2777  decode.d6.loss_mask: 0.2619  decode.d6.loss_dice: 0.3081  decode.d7.loss_cls: 0.2861  decode.d7.loss_mask: 0.2643  decode.d7.loss_dice: 0.3166  decode.d8.loss_cls: 0.2826  decode.d8.loss_mask: 0.2654  decode.d8.loss_dice: 0.3131
07/30 19:01:55 - mmengine - INFO - Iter(train) [19500/80000]  base_lr: 7.7769e-05 lr: 7.7769e-06  eta: 7:19:27  time: 0.4363  data_time: 0.0092  memory: 5261  grad_norm: 69.2843  loss: 9.1183  decode.loss_cls: 0.2200  decode.loss_mask: 0.2755  decode.loss_dice: 0.3367  decode.d0.loss_cls: 1.1328  decode.d0.loss_mask: 0.2770  decode.d0.loss_dice: 0.3566  decode.d1.loss_cls: 0.3289  decode.d1.loss_mask: 0.2728  decode.d1.loss_dice: 0.3051  decode.d2.loss_cls: 0.2244  decode.d2.loss_mask: 0.2758  decode.d2.loss_dice: 0.3119  decode.d3.loss_cls: 0.1889  decode.d3.loss_mask: 0.2693  decode.d3.loss_dice: 0.3260  decode.d4.loss_cls: 0.2071  decode.d4.loss_mask: 0.2760  decode.d4.loss_dice: 0.3132  decode.d5.loss_cls: 0.1809  decode.d5.loss_mask: 0.2739  decode.d5.loss_dice: 0.3128  decode.d6.loss_cls: 0.2379  decode.d6.loss_mask: 0.2743  decode.d6.loss_dice: 0.3407  decode.d7.loss_cls: 0.2374  decode.d7.loss_mask: 0.2706  decode.d7.loss_dice: 0.3204  decode.d8.loss_cls: 0.1760  decode.d8.loss_mask: 0.2756  decode.d8.loss_dice: 0.3199
07/30 19:02:17 - mmengine - INFO - Iter(train) [19550/80000]  base_lr: 7.7711e-05 lr: 7.7711e-06  eta: 7:19:05  time: 0.4363  data_time: 0.0092  memory: 5229  grad_norm: 105.9882  loss: 11.3079  decode.loss_cls: 0.5192  decode.loss_mask: 0.2174  decode.loss_dice: 0.3097  decode.d0.loss_cls: 1.3707  decode.d0.loss_mask: 0.2334  decode.d0.loss_dice: 0.3460  decode.d1.loss_cls: 0.5571  decode.d1.loss_mask: 0.2233  decode.d1.loss_dice: 0.3198  decode.d2.loss_cls: 0.5020  decode.d2.loss_mask: 0.2216  decode.d2.loss_dice: 0.3253  decode.d3.loss_cls: 0.3691  decode.d3.loss_mask: 0.2334  decode.d3.loss_dice: 0.3480  decode.d4.loss_cls: 0.4688  decode.d4.loss_mask: 0.2198  decode.d4.loss_dice: 0.3604  decode.d5.loss_cls: 0.5025  decode.d5.loss_mask: 0.2186  decode.d5.loss_dice: 0.3363  decode.d6.loss_cls: 0.4875  decode.d6.loss_mask: 0.2223  decode.d6.loss_dice: 0.3444  decode.d7.loss_cls: 0.4860  decode.d7.loss_mask: 0.2234  decode.d7.loss_dice: 0.3233  decode.d8.loss_cls: 0.4895  decode.d8.loss_mask: 0.2201  decode.d8.loss_dice: 0.3090
07/30 19:02:39 - mmengine - INFO - Iter(train) [19600/80000]  base_lr: 7.7653e-05 lr: 7.7653e-06  eta: 7:18:43  time: 0.4369  data_time: 0.0090  memory: 5265  grad_norm: 175.0298  loss: 13.2666  decode.loss_cls: 0.5712  decode.loss_mask: 0.3116  decode.loss_dice: 0.4332  decode.d0.loss_cls: 1.3402  decode.d0.loss_mask: 0.3376  decode.d0.loss_dice: 0.4636  decode.d1.loss_cls: 0.6134  decode.d1.loss_mask: 0.3097  decode.d1.loss_dice: 0.3941  decode.d2.loss_cls: 0.4897  decode.d2.loss_mask: 0.3072  decode.d2.loss_dice: 0.4367  decode.d3.loss_cls: 0.4787  decode.d3.loss_mask: 0.3032  decode.d3.loss_dice: 0.4247  decode.d4.loss_cls: 0.4722  decode.d4.loss_mask: 0.3062  decode.d4.loss_dice: 0.4036  decode.d5.loss_cls: 0.4713  decode.d5.loss_mask: 0.3148  decode.d5.loss_dice: 0.3981  decode.d6.loss_cls: 0.5082  decode.d6.loss_mask: 0.3144  decode.d6.loss_dice: 0.4106  decode.d7.loss_cls: 0.4855  decode.d7.loss_mask: 0.3170  decode.d7.loss_dice: 0.4243  decode.d8.loss_cls: 0.5103  decode.d8.loss_mask: 0.3103  decode.d8.loss_dice: 0.4051
07/30 19:03:01 - mmengine - INFO - Iter(train) [19650/80000]  base_lr: 7.7595e-05 lr: 7.7595e-06  eta: 7:18:22  time: 0.4367  data_time: 0.0091  memory: 5246  grad_norm: 169.1428  loss: 8.2292  decode.loss_cls: 0.1434  decode.loss_mask: 0.2659  decode.loss_dice: 0.3171  decode.d0.loss_cls: 0.8879  decode.d0.loss_mask: 0.2624  decode.d0.loss_dice: 0.2971  decode.d1.loss_cls: 0.2142  decode.d1.loss_mask: 0.2652  decode.d1.loss_dice: 0.2953  decode.d2.loss_cls: 0.1680  decode.d2.loss_mask: 0.2803  decode.d2.loss_dice: 0.3382  decode.d3.loss_cls: 0.1989  decode.d3.loss_mask: 0.2630  decode.d3.loss_dice: 0.3091  decode.d4.loss_cls: 0.2151  decode.d4.loss_mask: 0.2658  decode.d4.loss_dice: 0.3053  decode.d5.loss_cls: 0.1896  decode.d5.loss_mask: 0.2640  decode.d5.loss_dice: 0.2721  decode.d6.loss_cls: 0.1880  decode.d6.loss_mask: 0.2633  decode.d6.loss_dice: 0.2951  decode.d7.loss_cls: 0.1779  decode.d7.loss_mask: 0.2626  decode.d7.loss_dice: 0.2978  decode.d8.loss_cls: 0.1718  decode.d8.loss_mask: 0.2710  decode.d8.loss_dice: 0.2836
07/30 19:03:23 - mmengine - INFO - Iter(train) [19700/80000]  base_lr: 7.7537e-05 lr: 7.7537e-06  eta: 7:18:00  time: 0.4366  data_time: 0.0089  memory: 5246  grad_norm: 66.0122  loss: 6.1721  decode.loss_cls: 0.0415  decode.loss_mask: 0.2064  decode.loss_dice: 0.2706  decode.d0.loss_cls: 0.9086  decode.d0.loss_mask: 0.2213  decode.d0.loss_dice: 0.2658  decode.d1.loss_cls: 0.0828  decode.d1.loss_mask: 0.2099  decode.d1.loss_dice: 0.2726  decode.d2.loss_cls: 0.0848  decode.d2.loss_mask: 0.2088  decode.d2.loss_dice: 0.2610  decode.d3.loss_cls: 0.0417  decode.d3.loss_mask: 0.2079  decode.d3.loss_dice: 0.2644  decode.d4.loss_cls: 0.0291  decode.d4.loss_mask: 0.2127  decode.d4.loss_dice: 0.2720  decode.d5.loss_cls: 0.0471  decode.d5.loss_mask: 0.2100  decode.d5.loss_dice: 0.2678  decode.d6.loss_cls: 0.0420  decode.d6.loss_mask: 0.2076  decode.d6.loss_dice: 0.2679  decode.d7.loss_cls: 0.0432  decode.d7.loss_mask: 0.2094  decode.d7.loss_dice: 0.2795  decode.d8.loss_cls: 0.0559  decode.d8.loss_mask: 0.2114  decode.d8.loss_dice: 0.2683
07/30 19:03:45 - mmengine - INFO - Iter(train) [19750/80000]  base_lr: 7.7479e-05 lr: 7.7479e-06  eta: 7:17:39  time: 0.4370  data_time: 0.0091  memory: 5245  grad_norm: 63.1227  loss: 7.5050  decode.loss_cls: 0.0832  decode.loss_mask: 0.2617  decode.loss_dice: 0.2925  decode.d0.loss_cls: 0.9867  decode.d0.loss_mask: 0.2861  decode.d0.loss_dice: 0.3231  decode.d1.loss_cls: 0.1760  decode.d1.loss_mask: 0.2719  decode.d1.loss_dice: 0.2867  decode.d2.loss_cls: 0.1287  decode.d2.loss_mask: 0.2681  decode.d2.loss_dice: 0.2854  decode.d3.loss_cls: 0.0994  decode.d3.loss_mask: 0.2691  decode.d3.loss_dice: 0.2832  decode.d4.loss_cls: 0.1073  decode.d4.loss_mask: 0.2657  decode.d4.loss_dice: 0.2799  decode.d5.loss_cls: 0.0766  decode.d5.loss_mask: 0.2660  decode.d5.loss_dice: 0.3007  decode.d6.loss_cls: 0.0848  decode.d6.loss_mask: 0.2633  decode.d6.loss_dice: 0.2820  decode.d7.loss_cls: 0.0639  decode.d7.loss_mask: 0.2623  decode.d7.loss_dice: 0.2802  decode.d8.loss_cls: 0.1365  decode.d8.loss_mask: 0.2630  decode.d8.loss_dice: 0.2712
07/30 19:04:06 - mmengine - INFO - Iter(train) [19800/80000]  base_lr: 7.7421e-05 lr: 7.7421e-06  eta: 7:17:17  time: 0.4369  data_time: 0.0090  memory: 5265  grad_norm: 54.6311  loss: 8.4888  decode.loss_cls: 0.2844  decode.loss_mask: 0.2289  decode.loss_dice: 0.2486  decode.d0.loss_cls: 1.3099  decode.d0.loss_mask: 0.2300  decode.d0.loss_dice: 0.2855  decode.d1.loss_cls: 0.3372  decode.d1.loss_mask: 0.2195  decode.d1.loss_dice: 0.2834  decode.d2.loss_cls: 0.2482  decode.d2.loss_mask: 0.2211  decode.d2.loss_dice: 0.2485  decode.d3.loss_cls: 0.2021  decode.d3.loss_mask: 0.2286  decode.d3.loss_dice: 0.2603  decode.d4.loss_cls: 0.3008  decode.d4.loss_mask: 0.2136  decode.d4.loss_dice: 0.2437  decode.d5.loss_cls: 0.2455  decode.d5.loss_mask: 0.2182  decode.d5.loss_dice: 0.2452  decode.d6.loss_cls: 0.2988  decode.d6.loss_mask: 0.2161  decode.d6.loss_dice: 0.2390  decode.d7.loss_cls: 0.2483  decode.d7.loss_mask: 0.2183  decode.d7.loss_dice: 0.2434  decode.d8.loss_cls: 0.2440  decode.d8.loss_mask: 0.2223  decode.d8.loss_dice: 0.2552
07/30 19:04:28 - mmengine - INFO - Iter(train) [19850/80000]  base_lr: 7.7363e-05 lr: 7.7363e-06  eta: 7:16:55  time: 0.4368  data_time: 0.0093  memory: 5265  grad_norm: 94.2396  loss: 9.3022  decode.loss_cls: 0.3120  decode.loss_mask: 0.2663  decode.loss_dice: 0.2693  decode.d0.loss_cls: 1.1802  decode.d0.loss_mask: 0.2643  decode.d0.loss_dice: 0.2839  decode.d1.loss_cls: 0.3051  decode.d1.loss_mask: 0.2580  decode.d1.loss_dice: 0.2704  decode.d2.loss_cls: 0.2916  decode.d2.loss_mask: 0.2628  decode.d2.loss_dice: 0.2691  decode.d3.loss_cls: 0.2909  decode.d3.loss_mask: 0.2671  decode.d3.loss_dice: 0.2759  decode.d4.loss_cls: 0.2912  decode.d4.loss_mask: 0.2681  decode.d4.loss_dice: 0.2765  decode.d5.loss_cls: 0.2727  decode.d5.loss_mask: 0.2680  decode.d5.loss_dice: 0.2520  decode.d6.loss_cls: 0.3280  decode.d6.loss_mask: 0.2622  decode.d6.loss_dice: 0.2740  decode.d7.loss_cls: 0.3338  decode.d7.loss_mask: 0.2617  decode.d7.loss_dice: 0.2629  decode.d8.loss_cls: 0.3670  decode.d8.loss_mask: 0.2591  decode.d8.loss_dice: 0.2584
07/30 19:04:50 - mmengine - INFO - Iter(train) [19900/80000]  base_lr: 7.7306e-05 lr: 7.7306e-06  eta: 7:16:34  time: 0.4360  data_time: 0.0094  memory: 5244  grad_norm: 94.4257  loss: 10.1436  decode.loss_cls: 0.4020  decode.loss_mask: 0.2503  decode.loss_dice: 0.3063  decode.d0.loss_cls: 1.1454  decode.d0.loss_mask: 0.2516  decode.d0.loss_dice: 0.3068  decode.d1.loss_cls: 0.4789  decode.d1.loss_mask: 0.2512  decode.d1.loss_dice: 0.3159  decode.d2.loss_cls: 0.3608  decode.d2.loss_mask: 0.2524  decode.d2.loss_dice: 0.3003  decode.d3.loss_cls: 0.3640  decode.d3.loss_mask: 0.2504  decode.d3.loss_dice: 0.3473  decode.d4.loss_cls: 0.3330  decode.d4.loss_mask: 0.2512  decode.d4.loss_dice: 0.3252  decode.d5.loss_cls: 0.3210  decode.d5.loss_mask: 0.2545  decode.d5.loss_dice: 0.3093  decode.d6.loss_cls: 0.3337  decode.d6.loss_mask: 0.2541  decode.d6.loss_dice: 0.2859  decode.d7.loss_cls: 0.3768  decode.d7.loss_mask: 0.2540  decode.d7.loss_dice: 0.3095  decode.d8.loss_cls: 0.3886  decode.d8.loss_mask: 0.2541  decode.d8.loss_dice: 0.3090
07/30 19:05:12 - mmengine - INFO - Iter(train) [19950/80000]  base_lr: 7.7248e-05 lr: 7.7248e-06  eta: 7:16:12  time: 0.4363  data_time: 0.0093  memory: 5261  grad_norm: 129.5994  loss: 7.3736  decode.loss_cls: 0.1228  decode.loss_mask: 0.2101  decode.loss_dice: 0.2710  decode.d0.loss_cls: 1.0288  decode.d0.loss_mask: 0.2081  decode.d0.loss_dice: 0.2779  decode.d1.loss_cls: 0.2432  decode.d1.loss_mask: 0.1989  decode.d1.loss_dice: 0.2486  decode.d2.loss_cls: 0.2449  decode.d2.loss_mask: 0.1991  decode.d2.loss_dice: 0.2476  decode.d3.loss_cls: 0.2527  decode.d3.loss_mask: 0.1965  decode.d3.loss_dice: 0.2420  decode.d4.loss_cls: 0.1756  decode.d4.loss_mask: 0.2018  decode.d4.loss_dice: 0.2815  decode.d5.loss_cls: 0.1398  decode.d5.loss_mask: 0.2018  decode.d5.loss_dice: 0.2741  decode.d6.loss_cls: 0.1368  decode.d6.loss_mask: 0.2025  decode.d6.loss_dice: 0.2753  decode.d7.loss_cls: 0.1893  decode.d7.loss_mask: 0.2014  decode.d7.loss_dice: 0.2580  decode.d8.loss_cls: 0.2013  decode.d8.loss_mask: 0.2008  decode.d8.loss_dice: 0.2413
07/30 19:05:34 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 19:05:34 - mmengine - INFO - Iter(train) [20000/80000]  base_lr: 7.7190e-05 lr: 7.7190e-06  eta: 7:15:51  time: 0.4375  data_time: 0.0093  memory: 5265  grad_norm: 109.9816  loss: 8.8373  decode.loss_cls: 0.1985  decode.loss_mask: 0.2909  decode.loss_dice: 0.3067  decode.d0.loss_cls: 0.9784  decode.d0.loss_mask: 0.3107  decode.d0.loss_dice: 0.3004  decode.d1.loss_cls: 0.2357  decode.d1.loss_mask: 0.2957  decode.d1.loss_dice: 0.3009  decode.d2.loss_cls: 0.2663  decode.d2.loss_mask: 0.2963  decode.d2.loss_dice: 0.2932  decode.d3.loss_cls: 0.1670  decode.d3.loss_mask: 0.2979  decode.d3.loss_dice: 0.2995  decode.d4.loss_cls: 0.2003  decode.d4.loss_mask: 0.2943  decode.d4.loss_dice: 0.2998  decode.d5.loss_cls: 0.1676  decode.d5.loss_mask: 0.2909  decode.d5.loss_dice: 0.3024  decode.d6.loss_cls: 0.2112  decode.d6.loss_mask: 0.2934  decode.d6.loss_dice: 0.3099  decode.d7.loss_cls: 0.2132  decode.d7.loss_mask: 0.2920  decode.d7.loss_dice: 0.2957  decode.d8.loss_cls: 0.2268  decode.d8.loss_mask: 0.2926  decode.d8.loss_dice: 0.3090
07/30 19:05:34 - mmengine - INFO - Saving checkpoint at 20000 iterations
07/30 19:05:57 - mmengine - INFO - Iter(train) [20050/80000]  base_lr: 7.7132e-05 lr: 7.7132e-06  eta: 7:15:34  time: 0.4357  data_time: 0.0092  memory: 5246  grad_norm: 140.5386  loss: 7.8843  decode.loss_cls: 0.1776  decode.loss_mask: 0.2497  decode.loss_dice: 0.3079  decode.d0.loss_cls: 0.9919  decode.d0.loss_mask: 0.2610  decode.d0.loss_dice: 0.3396  decode.d1.loss_cls: 0.1687  decode.d1.loss_mask: 0.2511  decode.d1.loss_dice: 0.3182  decode.d2.loss_cls: 0.1318  decode.d2.loss_mask: 0.2490  decode.d2.loss_dice: 0.2929  decode.d3.loss_cls: 0.0819  decode.d3.loss_mask: 0.2490  decode.d3.loss_dice: 0.3076  decode.d4.loss_cls: 0.0924  decode.d4.loss_mask: 0.2467  decode.d4.loss_dice: 0.3122  decode.d5.loss_cls: 0.1344  decode.d5.loss_mask: 0.2525  decode.d5.loss_dice: 0.3241  decode.d6.loss_cls: 0.1515  decode.d6.loss_mask: 0.2526  decode.d6.loss_dice: 0.3062  decode.d7.loss_cls: 0.1737  decode.d7.loss_mask: 0.2507  decode.d7.loss_dice: 0.3027  decode.d8.loss_cls: 0.1561  decode.d8.loss_mask: 0.2488  decode.d8.loss_dice: 0.3019
07/30 19:06:19 - mmengine - INFO - Iter(train) [20100/80000]  base_lr: 7.7074e-05 lr: 7.7074e-06  eta: 7:15:13  time: 0.4357  data_time: 0.0090  memory: 5261  grad_norm: 120.0024  loss: 9.3971  decode.loss_cls: 0.3119  decode.loss_mask: 0.2153  decode.loss_dice: 0.3281  decode.d0.loss_cls: 1.1304  decode.d0.loss_mask: 0.2191  decode.d0.loss_dice: 0.3548  decode.d1.loss_cls: 0.3756  decode.d1.loss_mask: 0.2128  decode.d1.loss_dice: 0.3397  decode.d2.loss_cls: 0.2730  decode.d2.loss_mask: 0.2138  decode.d2.loss_dice: 0.3167  decode.d3.loss_cls: 0.3423  decode.d3.loss_mask: 0.2160  decode.d3.loss_dice: 0.3087  decode.d4.loss_cls: 0.3214  decode.d4.loss_mask: 0.2128  decode.d4.loss_dice: 0.3070  decode.d5.loss_cls: 0.2710  decode.d5.loss_mask: 0.2197  decode.d5.loss_dice: 0.3200  decode.d6.loss_cls: 0.3220  decode.d6.loss_mask: 0.2208  decode.d6.loss_dice: 0.3087  decode.d7.loss_cls: 0.3271  decode.d7.loss_mask: 0.2128  decode.d7.loss_dice: 0.3052  decode.d8.loss_cls: 0.3853  decode.d8.loss_mask: 0.2021  decode.d8.loss_dice: 0.3028
07/30 19:06:41 - mmengine - INFO - Iter(train) [20150/80000]  base_lr: 7.7016e-05 lr: 7.7016e-06  eta: 7:14:51  time: 0.4358  data_time: 0.0092  memory: 5265  grad_norm: 70.4827  loss: 8.5525  decode.loss_cls: 0.3840  decode.loss_mask: 0.1919  decode.loss_dice: 0.2328  decode.d0.loss_cls: 1.0144  decode.d0.loss_mask: 0.1905  decode.d0.loss_dice: 0.2780  decode.d1.loss_cls: 0.3810  decode.d1.loss_mask: 0.1847  decode.d1.loss_dice: 0.2416  decode.d2.loss_cls: 0.3074  decode.d2.loss_mask: 0.1883  decode.d2.loss_dice: 0.2317  decode.d3.loss_cls: 0.2968  decode.d3.loss_mask: 0.1892  decode.d3.loss_dice: 0.2355  decode.d4.loss_cls: 0.3256  decode.d4.loss_mask: 0.1878  decode.d4.loss_dice: 0.2488  decode.d5.loss_cls: 0.3841  decode.d5.loss_mask: 0.1895  decode.d5.loss_dice: 0.2416  decode.d6.loss_cls: 0.4161  decode.d6.loss_mask: 0.1852  decode.d6.loss_dice: 0.2425  decode.d7.loss_cls: 0.3610  decode.d7.loss_mask: 0.1862  decode.d7.loss_dice: 0.2363  decode.d8.loss_cls: 0.3838  decode.d8.loss_mask: 0.1878  decode.d8.loss_dice: 0.2285
07/30 19:07:03 - mmengine - INFO - Iter(train) [20200/80000]  base_lr: 7.6958e-05 lr: 7.6958e-06  eta: 7:14:30  time: 0.4362  data_time: 0.0093  memory: 5279  grad_norm: 77.1792  loss: 9.9340  decode.loss_cls: 0.3182  decode.loss_mask: 0.2918  decode.loss_dice: 0.3164  decode.d0.loss_cls: 1.0146  decode.d0.loss_mask: 0.2932  decode.d0.loss_dice: 0.3292  decode.d1.loss_cls: 0.3800  decode.d1.loss_mask: 0.2951  decode.d1.loss_dice: 0.3131  decode.d2.loss_cls: 0.3244  decode.d2.loss_mask: 0.2930  decode.d2.loss_dice: 0.3092  decode.d3.loss_cls: 0.3150  decode.d3.loss_mask: 0.2918  decode.d3.loss_dice: 0.3110  decode.d4.loss_cls: 0.3180  decode.d4.loss_mask: 0.2923  decode.d4.loss_dice: 0.2904  decode.d5.loss_cls: 0.3540  decode.d5.loss_mask: 0.2895  decode.d5.loss_dice: 0.3057  decode.d6.loss_cls: 0.2975  decode.d6.loss_mask: 0.2918  decode.d6.loss_dice: 0.3070  decode.d7.loss_cls: 0.2925  decode.d7.loss_mask: 0.2919  decode.d7.loss_dice: 0.2886  decode.d8.loss_cls: 0.3261  decode.d8.loss_mask: 0.2899  decode.d8.loss_dice: 0.3027
07/30 19:07:25 - mmengine - INFO - Iter(train) [20250/80000]  base_lr: 7.6900e-05 lr: 7.6900e-06  eta: 7:14:08  time: 0.4352  data_time: 0.0091  memory: 5265  grad_norm: 89.0830  loss: 8.6348  decode.loss_cls: 0.3517  decode.loss_mask: 0.2298  decode.loss_dice: 0.2629  decode.d0.loss_cls: 0.8937  decode.d0.loss_mask: 0.2309  decode.d0.loss_dice: 0.2752  decode.d1.loss_cls: 0.2843  decode.d1.loss_mask: 0.2331  decode.d1.loss_dice: 0.3028  decode.d2.loss_cls: 0.2140  decode.d2.loss_mask: 0.2371  decode.d2.loss_dice: 0.2790  decode.d3.loss_cls: 0.2695  decode.d3.loss_mask: 0.2367  decode.d3.loss_dice: 0.2770  decode.d4.loss_cls: 0.2727  decode.d4.loss_mask: 0.2360  decode.d4.loss_dice: 0.2820  decode.d5.loss_cls: 0.2827  decode.d5.loss_mask: 0.2374  decode.d5.loss_dice: 0.2668  decode.d6.loss_cls: 0.3326  decode.d6.loss_mask: 0.2392  decode.d6.loss_dice: 0.2714  decode.d7.loss_cls: 0.2652  decode.d7.loss_mask: 0.2335  decode.d7.loss_dice: 0.2945  decode.d8.loss_cls: 0.3399  decode.d8.loss_mask: 0.2331  decode.d8.loss_dice: 0.2700
07/30 19:07:47 - mmengine - INFO - Iter(train) [20300/80000]  base_lr: 7.6842e-05 lr: 7.6842e-06  eta: 7:13:46  time: 0.4358  data_time: 0.0091  memory: 5265  grad_norm: 124.5940  loss: 10.0962  decode.loss_cls: 0.2913  decode.loss_mask: 0.2601  decode.loss_dice: 0.3318  decode.d0.loss_cls: 1.1938  decode.d0.loss_mask: 0.2778  decode.d0.loss_dice: 0.4114  decode.d1.loss_cls: 0.4278  decode.d1.loss_mask: 0.2641  decode.d1.loss_dice: 0.3463  decode.d2.loss_cls: 0.3745  decode.d2.loss_mask: 0.2674  decode.d2.loss_dice: 0.3603  decode.d3.loss_cls: 0.2678  decode.d3.loss_mask: 0.2660  decode.d3.loss_dice: 0.3204  decode.d4.loss_cls: 0.2719  decode.d4.loss_mask: 0.2646  decode.d4.loss_dice: 0.3642  decode.d5.loss_cls: 0.3073  decode.d5.loss_mask: 0.2611  decode.d5.loss_dice: 0.3495  decode.d6.loss_cls: 0.2558  decode.d6.loss_mask: 0.2593  decode.d6.loss_dice: 0.3310  decode.d7.loss_cls: 0.3132  decode.d7.loss_mask: 0.2630  decode.d7.loss_dice: 0.3429  decode.d8.loss_cls: 0.2594  decode.d8.loss_mask: 0.2618  decode.d8.loss_dice: 0.3304
07/30 19:08:08 - mmengine - INFO - Iter(train) [20350/80000]  base_lr: 7.6784e-05 lr: 7.6784e-06  eta: 7:13:24  time: 0.4359  data_time: 0.0092  memory: 5265  grad_norm: 118.8601  loss: 10.6384  decode.loss_cls: 0.3064  decode.loss_mask: 0.2892  decode.loss_dice: 0.4115  decode.d0.loss_cls: 1.1150  decode.d0.loss_mask: 0.2923  decode.d0.loss_dice: 0.4126  decode.d1.loss_cls: 0.4308  decode.d1.loss_mask: 0.2713  decode.d1.loss_dice: 0.3672  decode.d2.loss_cls: 0.3571  decode.d2.loss_mask: 0.2816  decode.d2.loss_dice: 0.3636  decode.d3.loss_cls: 0.2720  decode.d3.loss_mask: 0.2776  decode.d3.loss_dice: 0.3725  decode.d4.loss_cls: 0.2387  decode.d4.loss_mask: 0.2999  decode.d4.loss_dice: 0.3716  decode.d5.loss_cls: 0.3332  decode.d5.loss_mask: 0.2800  decode.d5.loss_dice: 0.3723  decode.d6.loss_cls: 0.2672  decode.d6.loss_mask: 0.3068  decode.d6.loss_dice: 0.4144  decode.d7.loss_cls: 0.2607  decode.d7.loss_mask: 0.2898  decode.d7.loss_dice: 0.4147  decode.d8.loss_cls: 0.2498  decode.d8.loss_mask: 0.2970  decode.d8.loss_dice: 0.4215
07/30 19:08:30 - mmengine - INFO - Iter(train) [20400/80000]  base_lr: 7.6727e-05 lr: 7.6727e-06  eta: 7:13:02  time: 0.4373  data_time: 0.0093  memory: 5278  grad_norm: 169.6465  loss: 9.6146  decode.loss_cls: 0.2616  decode.loss_mask: 0.2430  decode.loss_dice: 0.2842  decode.d0.loss_cls: 1.2371  decode.d0.loss_mask: 0.2286  decode.d0.loss_dice: 0.3455  decode.d1.loss_cls: 0.3859  decode.d1.loss_mask: 0.2425  decode.d1.loss_dice: 0.3068  decode.d2.loss_cls: 0.4104  decode.d2.loss_mask: 0.2524  decode.d2.loss_dice: 0.2983  decode.d3.loss_cls: 0.2683  decode.d3.loss_mask: 0.2509  decode.d3.loss_dice: 0.3218  decode.d4.loss_cls: 0.2982  decode.d4.loss_mask: 0.2540  decode.d4.loss_dice: 0.3019  decode.d5.loss_cls: 0.3021  decode.d5.loss_mask: 0.2573  decode.d5.loss_dice: 0.3263  decode.d6.loss_cls: 0.2779  decode.d6.loss_mask: 0.2563  decode.d6.loss_dice: 0.3251  decode.d7.loss_cls: 0.2266  decode.d7.loss_mask: 0.2641  decode.d7.loss_dice: 0.3022  decode.d8.loss_cls: 0.2937  decode.d8.loss_mask: 0.2817  decode.d8.loss_dice: 0.3098
07/30 19:08:52 - mmengine - INFO - Iter(train) [20450/80000]  base_lr: 7.6669e-05 lr: 7.6669e-06  eta: 7:12:40  time: 0.4357  data_time: 0.0090  memory: 5246  grad_norm: 103.2554  loss: 7.6213  decode.loss_cls: 0.0955  decode.loss_mask: 0.2670  decode.loss_dice: 0.3173  decode.d0.loss_cls: 0.9669  decode.d0.loss_mask: 0.2845  decode.d0.loss_dice: 0.3262  decode.d1.loss_cls: 0.1883  decode.d1.loss_mask: 0.2639  decode.d1.loss_dice: 0.3032  decode.d2.loss_cls: 0.0743  decode.d2.loss_mask: 0.2622  decode.d2.loss_dice: 0.3137  decode.d3.loss_cls: 0.0932  decode.d3.loss_mask: 0.2627  decode.d3.loss_dice: 0.3253  decode.d4.loss_cls: 0.0387  decode.d4.loss_mask: 0.2606  decode.d4.loss_dice: 0.3259  decode.d5.loss_cls: 0.0780  decode.d5.loss_mask: 0.2597  decode.d5.loss_dice: 0.3297  decode.d6.loss_cls: 0.1053  decode.d6.loss_mask: 0.2595  decode.d6.loss_dice: 0.2966  decode.d7.loss_cls: 0.0652  decode.d7.loss_mask: 0.2624  decode.d7.loss_dice: 0.3346  decode.d8.loss_cls: 0.0838  decode.d8.loss_mask: 0.2606  decode.d8.loss_dice: 0.3164
07/30 19:09:14 - mmengine - INFO - Iter(train) [20500/80000]  base_lr: 7.6611e-05 lr: 7.6611e-06  eta: 7:12:19  time: 0.4352  data_time: 0.0094  memory: 5246  grad_norm: 88.3733  loss: 8.5388  decode.loss_cls: 0.2228  decode.loss_mask: 0.2770  decode.loss_dice: 0.2704  decode.d0.loss_cls: 0.8932  decode.d0.loss_mask: 0.2843  decode.d0.loss_dice: 0.3135  decode.d1.loss_cls: 0.2823  decode.d1.loss_mask: 0.2803  decode.d1.loss_dice: 0.2860  decode.d2.loss_cls: 0.2143  decode.d2.loss_mask: 0.2807  decode.d2.loss_dice: 0.2844  decode.d3.loss_cls: 0.1228  decode.d3.loss_mask: 0.2765  decode.d3.loss_dice: 0.2941  decode.d4.loss_cls: 0.2480  decode.d4.loss_mask: 0.2777  decode.d4.loss_dice: 0.2896  decode.d5.loss_cls: 0.1679  decode.d5.loss_mask: 0.2815  decode.d5.loss_dice: 0.2922  decode.d6.loss_cls: 0.2339  decode.d6.loss_mask: 0.2850  decode.d6.loss_dice: 0.2934  decode.d7.loss_cls: 0.1866  decode.d7.loss_mask: 0.2836  decode.d7.loss_dice: 0.2859  decode.d8.loss_cls: 0.2779  decode.d8.loss_mask: 0.2776  decode.d8.loss_dice: 0.2753
07/30 19:09:36 - mmengine - INFO - Iter(train) [20550/80000]  base_lr: 7.6553e-05 lr: 7.6553e-06  eta: 7:11:57  time: 0.4367  data_time: 0.0091  memory: 5279  grad_norm: 100.7470  loss: 8.1813  decode.loss_cls: 0.1408  decode.loss_mask: 0.2709  decode.loss_dice: 0.2787  decode.d0.loss_cls: 1.0155  decode.d0.loss_mask: 0.2797  decode.d0.loss_dice: 0.3265  decode.d1.loss_cls: 0.1689  decode.d1.loss_mask: 0.2728  decode.d1.loss_dice: 0.2821  decode.d2.loss_cls: 0.2242  decode.d2.loss_mask: 0.2677  decode.d2.loss_dice: 0.2901  decode.d3.loss_cls: 0.1886  decode.d3.loss_mask: 0.2677  decode.d3.loss_dice: 0.2777  decode.d4.loss_cls: 0.1856  decode.d4.loss_mask: 0.2730  decode.d4.loss_dice: 0.2658  decode.d5.loss_cls: 0.1922  decode.d5.loss_mask: 0.2722  decode.d5.loss_dice: 0.2795  decode.d6.loss_cls: 0.1923  decode.d6.loss_mask: 0.2730  decode.d6.loss_dice: 0.2838  decode.d7.loss_cls: 0.1616  decode.d7.loss_mask: 0.2749  decode.d7.loss_dice: 0.2882  decode.d8.loss_cls: 0.1282  decode.d8.loss_mask: 0.2734  decode.d8.loss_dice: 0.2859
07/30 19:09:57 - mmengine - INFO - Iter(train) [20600/80000]  base_lr: 7.6495e-05 lr: 7.6495e-06  eta: 7:11:35  time: 0.4366  data_time: 0.0093  memory: 5303  grad_norm: 85.9419  loss: 8.9795  decode.loss_cls: 0.3122  decode.loss_mask: 0.2352  decode.loss_dice: 0.2606  decode.d0.loss_cls: 1.0938  decode.d0.loss_mask: 0.2673  decode.d0.loss_dice: 0.2738  decode.d1.loss_cls: 0.3726  decode.d1.loss_mask: 0.2382  decode.d1.loss_dice: 0.2442  decode.d2.loss_cls: 0.3337  decode.d2.loss_mask: 0.2398  decode.d2.loss_dice: 0.2377  decode.d3.loss_cls: 0.3579  decode.d3.loss_mask: 0.2328  decode.d3.loss_dice: 0.2525  decode.d4.loss_cls: 0.3850  decode.d4.loss_mask: 0.2377  decode.d4.loss_dice: 0.2637  decode.d5.loss_cls: 0.3346  decode.d5.loss_mask: 0.2377  decode.d5.loss_dice: 0.2567  decode.d6.loss_cls: 0.3171  decode.d6.loss_mask: 0.2329  decode.d6.loss_dice: 0.2609  decode.d7.loss_cls: 0.2865  decode.d7.loss_mask: 0.2301  decode.d7.loss_dice: 0.2381  decode.d8.loss_cls: 0.2643  decode.d8.loss_mask: 0.2349  decode.d8.loss_dice: 0.2471
07/30 19:10:19 - mmengine - INFO - Iter(train) [20650/80000]  base_lr: 7.6437e-05 lr: 7.6437e-06  eta: 7:11:13  time: 0.4360  data_time: 0.0092  memory: 5246  grad_norm: 78.2748  loss: 6.9778  decode.loss_cls: 0.0688  decode.loss_mask: 0.2275  decode.loss_dice: 0.2968  decode.d0.loss_cls: 1.0187  decode.d0.loss_mask: 0.2177  decode.d0.loss_dice: 0.3053  decode.d1.loss_cls: 0.1004  decode.d1.loss_mask: 0.2223  decode.d1.loss_dice: 0.2997  decode.d2.loss_cls: 0.1041  decode.d2.loss_mask: 0.2208  decode.d2.loss_dice: 0.2949  decode.d3.loss_cls: 0.0985  decode.d3.loss_mask: 0.2226  decode.d3.loss_dice: 0.2875  decode.d4.loss_cls: 0.0884  decode.d4.loss_mask: 0.2251  decode.d4.loss_dice: 0.2940  decode.d5.loss_cls: 0.0823  decode.d5.loss_mask: 0.2213  decode.d5.loss_dice: 0.2912  decode.d6.loss_cls: 0.0833  decode.d6.loss_mask: 0.2206  decode.d6.loss_dice: 0.2859  decode.d7.loss_cls: 0.0705  decode.d7.loss_mask: 0.2216  decode.d7.loss_dice: 0.2941  decode.d8.loss_cls: 0.0923  decode.d8.loss_mask: 0.2254  decode.d8.loss_dice: 0.2959
07/30 19:10:41 - mmengine - INFO - Iter(train) [20700/80000]  base_lr: 7.6379e-05 lr: 7.6379e-06  eta: 7:10:51  time: 0.4357  data_time: 0.0091  memory: 5265  grad_norm: 111.2143  loss: 8.2774  decode.loss_cls: 0.2404  decode.loss_mask: 0.2215  decode.loss_dice: 0.2923  decode.d0.loss_cls: 0.8776  decode.d0.loss_mask: 0.2234  decode.d0.loss_dice: 0.3577  decode.d1.loss_cls: 0.2821  decode.d1.loss_mask: 0.2220  decode.d1.loss_dice: 0.3363  decode.d2.loss_cls: 0.2682  decode.d2.loss_mask: 0.2217  decode.d2.loss_dice: 0.3041  decode.d3.loss_cls: 0.2599  decode.d3.loss_mask: 0.2022  decode.d3.loss_dice: 0.2850  decode.d4.loss_cls: 0.1882  decode.d4.loss_mask: 0.2135  decode.d4.loss_dice: 0.3078  decode.d5.loss_cls: 0.2435  decode.d5.loss_mask: 0.2157  decode.d5.loss_dice: 0.2915  decode.d6.loss_cls: 0.2419  decode.d6.loss_mask: 0.2087  decode.d6.loss_dice: 0.2952  decode.d7.loss_cls: 0.2339  decode.d7.loss_mask: 0.2117  decode.d7.loss_dice: 0.2883  decode.d8.loss_cls: 0.2250  decode.d8.loss_mask: 0.2194  decode.d8.loss_dice: 0.2987
07/30 19:11:03 - mmengine - INFO - Iter(train) [20750/80000]  base_lr: 7.6321e-05 lr: 7.6321e-06  eta: 7:10:29  time: 0.4353  data_time: 0.0091  memory: 5244  grad_norm: 86.4661  loss: 8.1828  decode.loss_cls: 0.1933  decode.loss_mask: 0.2785  decode.loss_dice: 0.2845  decode.d0.loss_cls: 0.9819  decode.d0.loss_mask: 0.2490  decode.d0.loss_dice: 0.2945  decode.d1.loss_cls: 0.3014  decode.d1.loss_mask: 0.2469  decode.d1.loss_dice: 0.2835  decode.d2.loss_cls: 0.2277  decode.d2.loss_mask: 0.2526  decode.d2.loss_dice: 0.2801  decode.d3.loss_cls: 0.2290  decode.d3.loss_mask: 0.2525  decode.d3.loss_dice: 0.2746  decode.d4.loss_cls: 0.1705  decode.d4.loss_mask: 0.2524  decode.d4.loss_dice: 0.2844  decode.d5.loss_cls: 0.1609  decode.d5.loss_mask: 0.2501  decode.d5.loss_dice: 0.2845  decode.d6.loss_cls: 0.1580  decode.d6.loss_mask: 0.2554  decode.d6.loss_dice: 0.2890  decode.d7.loss_cls: 0.1509  decode.d7.loss_mask: 0.2592  decode.d7.loss_dice: 0.2848  decode.d8.loss_cls: 0.1882  decode.d8.loss_mask: 0.2764  decode.d8.loss_dice: 0.2879
07/30 19:11:24 - mmengine - INFO - Iter(train) [20800/80000]  base_lr: 7.6263e-05 lr: 7.6263e-06  eta: 7:10:08  time: 0.4350  data_time: 0.0092  memory: 5261  grad_norm: 77.0322  loss: 7.6301  decode.loss_cls: 0.1253  decode.loss_mask: 0.2818  decode.loss_dice: 0.2509  decode.d0.loss_cls: 1.0102  decode.d0.loss_mask: 0.2874  decode.d0.loss_dice: 0.2679  decode.d1.loss_cls: 0.1638  decode.d1.loss_mask: 0.2886  decode.d1.loss_dice: 0.2619  decode.d2.loss_cls: 0.1829  decode.d2.loss_mask: 0.2868  decode.d2.loss_dice: 0.2532  decode.d3.loss_cls: 0.1327  decode.d3.loss_mask: 0.2824  decode.d3.loss_dice: 0.2572  decode.d4.loss_cls: 0.1185  decode.d4.loss_mask: 0.2848  decode.d4.loss_dice: 0.2569  decode.d5.loss_cls: 0.1417  decode.d5.loss_mask: 0.2860  decode.d5.loss_dice: 0.2554  decode.d6.loss_cls: 0.0907  decode.d6.loss_mask: 0.2861  decode.d6.loss_dice: 0.2521  decode.d7.loss_cls: 0.1448  decode.d7.loss_mask: 0.2877  decode.d7.loss_dice: 0.2612  decode.d8.loss_cls: 0.0962  decode.d8.loss_mask: 0.2832  decode.d8.loss_dice: 0.2520
07/30 19:11:46 - mmengine - INFO - Iter(train) [20850/80000]  base_lr: 7.6205e-05 lr: 7.6205e-06  eta: 7:09:46  time: 0.4362  data_time: 0.0090  memory: 5265  grad_norm: 66.1768  loss: 7.3757  decode.loss_cls: 0.2214  decode.loss_mask: 0.2120  decode.loss_dice: 0.2338  decode.d0.loss_cls: 0.9433  decode.d0.loss_mask: 0.2226  decode.d0.loss_dice: 0.2386  decode.d1.loss_cls: 0.2392  decode.d1.loss_mask: 0.2155  decode.d1.loss_dice: 0.2347  decode.d2.loss_cls: 0.2668  decode.d2.loss_mask: 0.2098  decode.d2.loss_dice: 0.2391  decode.d3.loss_cls: 0.2215  decode.d3.loss_mask: 0.2093  decode.d3.loss_dice: 0.2441  decode.d4.loss_cls: 0.2208  decode.d4.loss_mask: 0.2121  decode.d4.loss_dice: 0.2372  decode.d5.loss_cls: 0.2050  decode.d5.loss_mask: 0.2162  decode.d5.loss_dice: 0.2348  decode.d6.loss_cls: 0.1682  decode.d6.loss_mask: 0.2165  decode.d6.loss_dice: 0.2331  decode.d7.loss_cls: 0.1904  decode.d7.loss_mask: 0.2097  decode.d7.loss_dice: 0.2353  decode.d8.loss_cls: 0.2074  decode.d8.loss_mask: 0.2130  decode.d8.loss_dice: 0.2243
07/30 19:12:08 - mmengine - INFO - Iter(train) [20900/80000]  base_lr: 7.6147e-05 lr: 7.6147e-06  eta: 7:09:24  time: 0.4354  data_time: 0.0092  memory: 5229  grad_norm: 117.5351  loss: 7.9600  decode.loss_cls: 0.1432  decode.loss_mask: 0.3248  decode.loss_dice: 0.2825  decode.d0.loss_cls: 0.9837  decode.d0.loss_mask: 0.2991  decode.d0.loss_dice: 0.2901  decode.d1.loss_cls: 0.0970  decode.d1.loss_mask: 0.2969  decode.d1.loss_dice: 0.2836  decode.d2.loss_cls: 0.1616  decode.d2.loss_mask: 0.2926  decode.d2.loss_dice: 0.2601  decode.d3.loss_cls: 0.0784  decode.d3.loss_mask: 0.2969  decode.d3.loss_dice: 0.2808  decode.d4.loss_cls: 0.0569  decode.d4.loss_mask: 0.3065  decode.d4.loss_dice: 0.2952  decode.d5.loss_cls: 0.1363  decode.d5.loss_mask: 0.3014  decode.d5.loss_dice: 0.2833  decode.d6.loss_cls: 0.1348  decode.d6.loss_mask: 0.3314  decode.d6.loss_dice: 0.2713  decode.d7.loss_cls: 0.1603  decode.d7.loss_mask: 0.2940  decode.d7.loss_dice: 0.2795  decode.d8.loss_cls: 0.1416  decode.d8.loss_mask: 0.2982  decode.d8.loss_dice: 0.2978
07/30 19:12:30 - mmengine - INFO - Iter(train) [20950/80000]  base_lr: 7.6089e-05 lr: 7.6089e-06  eta: 7:09:02  time: 0.4396  data_time: 0.0093  memory: 5277  grad_norm: 175.4368  loss: 9.3004  decode.loss_cls: 0.2540  decode.loss_mask: 0.3003  decode.loss_dice: 0.2869  decode.d0.loss_cls: 0.9425  decode.d0.loss_mask: 0.3201  decode.d0.loss_dice: 0.3198  decode.d1.loss_cls: 0.2229  decode.d1.loss_mask: 0.3422  decode.d1.loss_dice: 0.2911  decode.d2.loss_cls: 0.2634  decode.d2.loss_mask: 0.3007  decode.d2.loss_dice: 0.2872  decode.d3.loss_cls: 0.2687  decode.d3.loss_mask: 0.2828  decode.d3.loss_dice: 0.2825  decode.d4.loss_cls: 0.3046  decode.d4.loss_mask: 0.3165  decode.d4.loss_dice: 0.2863  decode.d5.loss_cls: 0.2591  decode.d5.loss_mask: 0.3102  decode.d5.loss_dice: 0.2908  decode.d6.loss_cls: 0.2571  decode.d6.loss_mask: 0.2917  decode.d6.loss_dice: 0.2806  decode.d7.loss_cls: 0.2780  decode.d7.loss_mask: 0.3103  decode.d7.loss_dice: 0.2879  decode.d8.loss_cls: 0.2693  decode.d8.loss_mask: 0.3098  decode.d8.loss_dice: 0.2831
07/30 19:12:52 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 19:12:52 - mmengine - INFO - Iter(train) [21000/80000]  base_lr: 7.6031e-05 lr: 7.6031e-06  eta: 7:08:40  time: 0.4365  data_time: 0.0093  memory: 5279  grad_norm: 99.3145  loss: 8.9237  decode.loss_cls: 0.2280  decode.loss_mask: 0.2123  decode.loss_dice: 0.2976  decode.d0.loss_cls: 1.2641  decode.d0.loss_mask: 0.2250  decode.d0.loss_dice: 0.3499  decode.d1.loss_cls: 0.5040  decode.d1.loss_mask: 0.2181  decode.d1.loss_dice: 0.3215  decode.d2.loss_cls: 0.2654  decode.d2.loss_mask: 0.2172  decode.d2.loss_dice: 0.3048  decode.d3.loss_cls: 0.1990  decode.d3.loss_mask: 0.2137  decode.d3.loss_dice: 0.3006  decode.d4.loss_cls: 0.2733  decode.d4.loss_mask: 0.2158  decode.d4.loss_dice: 0.3161  decode.d5.loss_cls: 0.2449  decode.d5.loss_mask: 0.2160  decode.d5.loss_dice: 0.3085  decode.d6.loss_cls: 0.2456  decode.d6.loss_mask: 0.2121  decode.d6.loss_dice: 0.2887  decode.d7.loss_cls: 0.2418  decode.d7.loss_mask: 0.2137  decode.d7.loss_dice: 0.2880  decode.d8.loss_cls: 0.2229  decode.d8.loss_mask: 0.2168  decode.d8.loss_dice: 0.2984
07/30 19:13:13 - mmengine - INFO - Iter(train) [21050/80000]  base_lr: 7.5973e-05 lr: 7.5973e-06  eta: 7:08:19  time: 0.4365  data_time: 0.0093  memory: 5261  grad_norm: 175.0714  loss: 7.7588  decode.loss_cls: 0.1313  decode.loss_mask: 0.2717  decode.loss_dice: 0.2720  decode.d0.loss_cls: 0.9567  decode.d0.loss_mask: 0.2921  decode.d0.loss_dice: 0.2857  decode.d1.loss_cls: 0.1863  decode.d1.loss_mask: 0.2760  decode.d1.loss_dice: 0.2791  decode.d2.loss_cls: 0.1719  decode.d2.loss_mask: 0.2741  decode.d2.loss_dice: 0.2778  decode.d3.loss_cls: 0.1832  decode.d3.loss_mask: 0.2793  decode.d3.loss_dice: 0.2902  decode.d4.loss_cls: 0.1705  decode.d4.loss_mask: 0.2702  decode.d4.loss_dice: 0.2904  decode.d5.loss_cls: 0.1413  decode.d5.loss_mask: 0.2647  decode.d5.loss_dice: 0.2547  decode.d6.loss_cls: 0.1316  decode.d6.loss_mask: 0.2565  decode.d6.loss_dice: 0.2550  decode.d7.loss_cls: 0.1390  decode.d7.loss_mask: 0.2575  decode.d7.loss_dice: 0.2680  decode.d8.loss_cls: 0.1208  decode.d8.loss_mask: 0.2616  decode.d8.loss_dice: 0.2498
07/30 19:13:35 - mmengine - INFO - Iter(train) [21100/80000]  base_lr: 7.5915e-05 lr: 7.5915e-06  eta: 7:07:57  time: 0.4352  data_time: 0.0091  memory: 5265  grad_norm: 53.2060  loss: 7.8393  decode.loss_cls: 0.1415  decode.loss_mask: 0.2335  decode.loss_dice: 0.2917  decode.d0.loss_cls: 0.9911  decode.d0.loss_mask: 0.2386  decode.d0.loss_dice: 0.3121  decode.d1.loss_cls: 0.2915  decode.d1.loss_mask: 0.2334  decode.d1.loss_dice: 0.2905  decode.d2.loss_cls: 0.2479  decode.d2.loss_mask: 0.2332  decode.d2.loss_dice: 0.2831  decode.d3.loss_cls: 0.1837  decode.d3.loss_mask: 0.2354  decode.d3.loss_dice: 0.2743  decode.d4.loss_cls: 0.1768  decode.d4.loss_mask: 0.2332  decode.d4.loss_dice: 0.2831  decode.d5.loss_cls: 0.1815  decode.d5.loss_mask: 0.2317  decode.d5.loss_dice: 0.2907  decode.d6.loss_cls: 0.1257  decode.d6.loss_mask: 0.2306  decode.d6.loss_dice: 0.2934  decode.d7.loss_cls: 0.1027  decode.d7.loss_mask: 0.2319  decode.d7.loss_dice: 0.2925  decode.d8.loss_cls: 0.1459  decode.d8.loss_mask: 0.2328  decode.d8.loss_dice: 0.3051
07/30 19:13:57 - mmengine - INFO - Iter(train) [21150/80000]  base_lr: 7.5857e-05 lr: 7.5857e-06  eta: 7:07:35  time: 0.4358  data_time: 0.0091  memory: 5279  grad_norm: 95.5982  loss: 7.0366  decode.loss_cls: 0.2071  decode.loss_mask: 0.2164  decode.loss_dice: 0.2445  decode.d0.loss_cls: 0.9609  decode.d0.loss_mask: 0.2377  decode.d0.loss_dice: 0.2565  decode.d1.loss_cls: 0.1278  decode.d1.loss_mask: 0.2419  decode.d1.loss_dice: 0.2580  decode.d2.loss_cls: 0.0927  decode.d2.loss_mask: 0.2302  decode.d2.loss_dice: 0.2598  decode.d3.loss_cls: 0.0778  decode.d3.loss_mask: 0.2337  decode.d3.loss_dice: 0.2568  decode.d4.loss_cls: 0.1489  decode.d4.loss_mask: 0.2206  decode.d4.loss_dice: 0.2458  decode.d5.loss_cls: 0.0957  decode.d5.loss_mask: 0.2310  decode.d5.loss_dice: 0.2558  decode.d6.loss_cls: 0.1648  decode.d6.loss_mask: 0.2311  decode.d6.loss_dice: 0.2508  decode.d7.loss_cls: 0.1651  decode.d7.loss_mask: 0.2325  decode.d7.loss_dice: 0.2492  decode.d8.loss_cls: 0.1728  decode.d8.loss_mask: 0.2288  decode.d8.loss_dice: 0.2420
07/30 19:14:19 - mmengine - INFO - Iter(train) [21200/80000]  base_lr: 7.5799e-05 lr: 7.5799e-06  eta: 7:07:13  time: 0.4358  data_time: 0.0090  memory: 5240  grad_norm: 85.2000  loss: 7.9385  decode.loss_cls: 0.1856  decode.loss_mask: 0.2526  decode.loss_dice: 0.2392  decode.d0.loss_cls: 1.0148  decode.d0.loss_mask: 0.2772  decode.d0.loss_dice: 0.3300  decode.d1.loss_cls: 0.2204  decode.d1.loss_mask: 0.2621  decode.d1.loss_dice: 0.2656  decode.d2.loss_cls: 0.2268  decode.d2.loss_mask: 0.2557  decode.d2.loss_dice: 0.2480  decode.d3.loss_cls: 0.1917  decode.d3.loss_mask: 0.2595  decode.d3.loss_dice: 0.2417  decode.d4.loss_cls: 0.1835  decode.d4.loss_mask: 0.2571  decode.d4.loss_dice: 0.2413  decode.d5.loss_cls: 0.2117  decode.d5.loss_mask: 0.2546  decode.d5.loss_dice: 0.2551  decode.d6.loss_cls: 0.1988  decode.d6.loss_mask: 0.2542  decode.d6.loss_dice: 0.2443  decode.d7.loss_cls: 0.2009  decode.d7.loss_mask: 0.2529  decode.d7.loss_dice: 0.2478  decode.d8.loss_cls: 0.1719  decode.d8.loss_mask: 0.2540  decode.d8.loss_dice: 0.2392
07/30 19:14:41 - mmengine - INFO - Iter(train) [21250/80000]  base_lr: 7.5741e-05 lr: 7.5741e-06  eta: 7:06:51  time: 0.4358  data_time: 0.0092  memory: 5261  grad_norm: 394.1090  loss: 7.8036  decode.loss_cls: 0.1418  decode.loss_mask: 0.3136  decode.loss_dice: 0.2598  decode.d0.loss_cls: 0.8820  decode.d0.loss_mask: 0.3313  decode.d0.loss_dice: 0.2758  decode.d1.loss_cls: 0.1213  decode.d1.loss_mask: 0.3240  decode.d1.loss_dice: 0.2712  decode.d2.loss_cls: 0.0861  decode.d2.loss_mask: 0.3224  decode.d2.loss_dice: 0.2700  decode.d3.loss_cls: 0.1091  decode.d3.loss_mask: 0.3146  decode.d3.loss_dice: 0.2543  decode.d4.loss_cls: 0.1302  decode.d4.loss_mask: 0.3175  decode.d4.loss_dice: 0.2621  decode.d5.loss_cls: 0.1083  decode.d5.loss_mask: 0.3149  decode.d5.loss_dice: 0.2923  decode.d6.loss_cls: 0.0813  decode.d6.loss_mask: 0.3218  decode.d6.loss_dice: 0.2667  decode.d7.loss_cls: 0.1370  decode.d7.loss_mask: 0.3209  decode.d7.loss_dice: 0.2619  decode.d8.loss_cls: 0.1359  decode.d8.loss_mask: 0.3123  decode.d8.loss_dice: 0.2632
07/30 19:15:03 - mmengine - INFO - Iter(train) [21300/80000]  base_lr: 7.5683e-05 lr: 7.5683e-06  eta: 7:06:30  time: 0.4381  data_time: 0.0093  memory: 5265  grad_norm: 91.3459  loss: 9.9315  decode.loss_cls: 0.2476  decode.loss_mask: 0.2914  decode.loss_dice: 0.3505  decode.d0.loss_cls: 1.1243  decode.d0.loss_mask: 0.3071  decode.d0.loss_dice: 0.3574  decode.d1.loss_cls: 0.3396  decode.d1.loss_mask: 0.3013  decode.d1.loss_dice: 0.3966  decode.d2.loss_cls: 0.2520  decode.d2.loss_mask: 0.2928  decode.d2.loss_dice: 0.3551  decode.d3.loss_cls: 0.2240  decode.d3.loss_mask: 0.2947  decode.d3.loss_dice: 0.3572  decode.d4.loss_cls: 0.2135  decode.d4.loss_mask: 0.2947  decode.d4.loss_dice: 0.3628  decode.d5.loss_cls: 0.2561  decode.d5.loss_mask: 0.2938  decode.d5.loss_dice: 0.3713  decode.d6.loss_cls: 0.2586  decode.d6.loss_mask: 0.2947  decode.d6.loss_dice: 0.3523  decode.d7.loss_cls: 0.2198  decode.d7.loss_mask: 0.2979  decode.d7.loss_dice: 0.3413  decode.d8.loss_cls: 0.2302  decode.d8.loss_mask: 0.2964  decode.d8.loss_dice: 0.3564
07/30 19:15:24 - mmengine - INFO - Iter(train) [21350/80000]  base_lr: 7.5625e-05 lr: 7.5625e-06  eta: 7:06:08  time: 0.4360  data_time: 0.0091  memory: 5277  grad_norm: 69.1655  loss: 9.4920  decode.loss_cls: 0.2317  decode.loss_mask: 0.2615  decode.loss_dice: 0.3489  decode.d0.loss_cls: 1.1239  decode.d0.loss_mask: 0.2688  decode.d0.loss_dice: 0.3619  decode.d1.loss_cls: 0.3538  decode.d1.loss_mask: 0.2618  decode.d1.loss_dice: 0.3542  decode.d2.loss_cls: 0.2695  decode.d2.loss_mask: 0.2599  decode.d2.loss_dice: 0.3313  decode.d3.loss_cls: 0.2595  decode.d3.loss_mask: 0.2633  decode.d3.loss_dice: 0.3302  decode.d4.loss_cls: 0.2377  decode.d4.loss_mask: 0.2631  decode.d4.loss_dice: 0.3478  decode.d5.loss_cls: 0.2426  decode.d5.loss_mask: 0.2596  decode.d5.loss_dice: 0.3346  decode.d6.loss_cls: 0.2556  decode.d6.loss_mask: 0.2595  decode.d6.loss_dice: 0.3326  decode.d7.loss_cls: 0.2483  decode.d7.loss_mask: 0.2587  decode.d7.loss_dice: 0.3396  decode.d8.loss_cls: 0.2279  decode.d8.loss_mask: 0.2609  decode.d8.loss_dice: 0.3434
07/30 19:15:46 - mmengine - INFO - Iter(train) [21400/80000]  base_lr: 7.5567e-05 lr: 7.5567e-06  eta: 7:05:46  time: 0.4362  data_time: 0.0092  memory: 5265  grad_norm: 97.0888  loss: 7.5021  decode.loss_cls: 0.1575  decode.loss_mask: 0.2536  decode.loss_dice: 0.2368  decode.d0.loss_cls: 0.9654  decode.d0.loss_mask: 0.2640  decode.d0.loss_dice: 0.2572  decode.d1.loss_cls: 0.2450  decode.d1.loss_mask: 0.2521  decode.d1.loss_dice: 0.2446  decode.d2.loss_cls: 0.1900  decode.d2.loss_mask: 0.2539  decode.d2.loss_dice: 0.2373  decode.d3.loss_cls: 0.1890  decode.d3.loss_mask: 0.2502  decode.d3.loss_dice: 0.2355  decode.d4.loss_cls: 0.1868  decode.d4.loss_mask: 0.2507  decode.d4.loss_dice: 0.2275  decode.d5.loss_cls: 0.1654  decode.d5.loss_mask: 0.2526  decode.d5.loss_dice: 0.2302  decode.d6.loss_cls: 0.1722  decode.d6.loss_mask: 0.2550  decode.d6.loss_dice: 0.2382  decode.d7.loss_cls: 0.1510  decode.d7.loss_mask: 0.2536  decode.d7.loss_dice: 0.2270  decode.d8.loss_cls: 0.1787  decode.d8.loss_mask: 0.2557  decode.d8.loss_dice: 0.2257
07/30 19:16:08 - mmengine - INFO - Iter(train) [21450/80000]  base_lr: 7.5509e-05 lr: 7.5509e-06  eta: 7:05:24  time: 0.4364  data_time: 0.0093  memory: 5265  grad_norm: 47.7562  loss: 7.3466  decode.loss_cls: 0.1512  decode.loss_mask: 0.2494  decode.loss_dice: 0.2379  decode.d0.loss_cls: 0.9699  decode.d0.loss_mask: 0.2541  decode.d0.loss_dice: 0.2588  decode.d1.loss_cls: 0.2533  decode.d1.loss_mask: 0.2494  decode.d1.loss_dice: 0.2432  decode.d2.loss_cls: 0.1617  decode.d2.loss_mask: 0.2483  decode.d2.loss_dice: 0.2437  decode.d3.loss_cls: 0.1887  decode.d3.loss_mask: 0.2464  decode.d3.loss_dice: 0.2431  decode.d4.loss_cls: 0.1621  decode.d4.loss_mask: 0.2457  decode.d4.loss_dice: 0.2429  decode.d5.loss_cls: 0.1321  decode.d5.loss_mask: 0.2466  decode.d5.loss_dice: 0.2429  decode.d6.loss_cls: 0.1330  decode.d6.loss_mask: 0.2489  decode.d6.loss_dice: 0.2420  decode.d7.loss_cls: 0.1370  decode.d7.loss_mask: 0.2445  decode.d7.loss_dice: 0.2446  decode.d8.loss_cls: 0.1419  decode.d8.loss_mask: 0.2454  decode.d8.loss_dice: 0.2375
07/30 19:16:30 - mmengine - INFO - Iter(train) [21500/80000]  base_lr: 7.5451e-05 lr: 7.5451e-06  eta: 7:05:02  time: 0.4355  data_time: 0.0091  memory: 5246  grad_norm: 105.8154  loss: 8.0122  decode.loss_cls: 0.1448  decode.loss_mask: 0.3172  decode.loss_dice: 0.3032  decode.d0.loss_cls: 0.9012  decode.d0.loss_mask: 0.2393  decode.d0.loss_dice: 0.2701  decode.d1.loss_cls: 0.2532  decode.d1.loss_mask: 0.2371  decode.d1.loss_dice: 0.2529  decode.d2.loss_cls: 0.2072  decode.d2.loss_mask: 0.2323  decode.d2.loss_dice: 0.2496  decode.d3.loss_cls: 0.1846  decode.d3.loss_mask: 0.2415  decode.d3.loss_dice: 0.2583  decode.d4.loss_cls: 0.1873  decode.d4.loss_mask: 0.2362  decode.d4.loss_dice: 0.2581  decode.d5.loss_cls: 0.2309  decode.d5.loss_mask: 0.2509  decode.d5.loss_dice: 0.2791  decode.d6.loss_cls: 0.2517  decode.d6.loss_mask: 0.2503  decode.d6.loss_dice: 0.2701  decode.d7.loss_cls: 0.2428  decode.d7.loss_mask: 0.2493  decode.d7.loss_dice: 0.2644  decode.d8.loss_cls: 0.1768  decode.d8.loss_mask: 0.2907  decode.d8.loss_dice: 0.2813
07/30 19:16:51 - mmengine - INFO - Iter(train) [21550/80000]  base_lr: 7.5393e-05 lr: 7.5393e-06  eta: 7:04:41  time: 0.4359  data_time: 0.0091  memory: 5265  grad_norm: 96.1293  loss: 10.3760  decode.loss_cls: 0.4645  decode.loss_mask: 0.2667  decode.loss_dice: 0.3174  decode.d0.loss_cls: 0.9461  decode.d0.loss_mask: 0.2719  decode.d0.loss_dice: 0.3196  decode.d1.loss_cls: 0.4404  decode.d1.loss_mask: 0.2663  decode.d1.loss_dice: 0.3070  decode.d2.loss_cls: 0.4550  decode.d2.loss_mask: 0.2686  decode.d2.loss_dice: 0.3124  decode.d3.loss_cls: 0.4040  decode.d3.loss_mask: 0.2685  decode.d3.loss_dice: 0.3224  decode.d4.loss_cls: 0.4259  decode.d4.loss_mask: 0.2672  decode.d4.loss_dice: 0.3109  decode.d5.loss_cls: 0.3470  decode.d5.loss_mask: 0.2661  decode.d5.loss_dice: 0.3230  decode.d6.loss_cls: 0.3409  decode.d6.loss_mask: 0.2681  decode.d6.loss_dice: 0.3032  decode.d7.loss_cls: 0.3121  decode.d7.loss_mask: 0.2707  decode.d7.loss_dice: 0.3173  decode.d8.loss_cls: 0.4041  decode.d8.loss_mask: 0.2711  decode.d8.loss_dice: 0.3176
07/30 19:17:13 - mmengine - INFO - Iter(train) [21600/80000]  base_lr: 7.5335e-05 lr: 7.5335e-06  eta: 7:04:19  time: 0.4354  data_time: 0.0091  memory: 5261  grad_norm: 86.5264  loss: 8.2648  decode.loss_cls: 0.2073  decode.loss_mask: 0.2566  decode.loss_dice: 0.3246  decode.d0.loss_cls: 0.8763  decode.d0.loss_mask: 0.2618  decode.d0.loss_dice: 0.3516  decode.d1.loss_cls: 0.1856  decode.d1.loss_mask: 0.2519  decode.d1.loss_dice: 0.3150  decode.d2.loss_cls: 0.1990  decode.d2.loss_mask: 0.2510  decode.d2.loss_dice: 0.3219  decode.d3.loss_cls: 0.1755  decode.d3.loss_mask: 0.2524  decode.d3.loss_dice: 0.3195  decode.d4.loss_cls: 0.1912  decode.d4.loss_mask: 0.2553  decode.d4.loss_dice: 0.3224  decode.d5.loss_cls: 0.1307  decode.d5.loss_mask: 0.2538  decode.d5.loss_dice: 0.3190  decode.d6.loss_cls: 0.1698  decode.d6.loss_mask: 0.2519  decode.d6.loss_dice: 0.3092  decode.d7.loss_cls: 0.1562  decode.d7.loss_mask: 0.2553  decode.d7.loss_dice: 0.3233  decode.d8.loss_cls: 0.2056  decode.d8.loss_mask: 0.2511  decode.d8.loss_dice: 0.3199
07/30 19:17:35 - mmengine - INFO - Iter(train) [21650/80000]  base_lr: 7.5277e-05 lr: 7.5277e-06  eta: 7:03:57  time: 0.4350  data_time: 0.0092  memory: 5246  grad_norm: 73.3188  loss: 11.0992  decode.loss_cls: 0.4014  decode.loss_mask: 0.3310  decode.loss_dice: 0.3034  decode.d0.loss_cls: 1.1693  decode.d0.loss_mask: 0.3427  decode.d0.loss_dice: 0.3266  decode.d1.loss_cls: 0.3710  decode.d1.loss_mask: 0.3367  decode.d1.loss_dice: 0.3407  decode.d2.loss_cls: 0.3368  decode.d2.loss_mask: 0.3268  decode.d2.loss_dice: 0.3100  decode.d3.loss_cls: 0.4064  decode.d3.loss_mask: 0.3258  decode.d3.loss_dice: 0.3136  decode.d4.loss_cls: 0.3882  decode.d4.loss_mask: 0.3248  decode.d4.loss_dice: 0.3056  decode.d5.loss_cls: 0.3676  decode.d5.loss_mask: 0.3263  decode.d5.loss_dice: 0.3230  decode.d6.loss_cls: 0.4043  decode.d6.loss_mask: 0.3299  decode.d6.loss_dice: 0.3146  decode.d7.loss_cls: 0.3641  decode.d7.loss_mask: 0.3353  decode.d7.loss_dice: 0.3452  decode.d8.loss_cls: 0.3858  decode.d8.loss_mask: 0.3330  decode.d8.loss_dice: 0.3093
07/30 19:17:57 - mmengine - INFO - Iter(train) [21700/80000]  base_lr: 7.5219e-05 lr: 7.5219e-06  eta: 7:03:35  time: 0.4335  data_time: 0.0090  memory: 5261  grad_norm: 78.3322  loss: 8.2639  decode.loss_cls: 0.1784  decode.loss_mask: 0.3202  decode.loss_dice: 0.2414  decode.d0.loss_cls: 0.8231  decode.d0.loss_mask: 0.3332  decode.d0.loss_dice: 0.2713  decode.d1.loss_cls: 0.2052  decode.d1.loss_mask: 0.3146  decode.d1.loss_dice: 0.2523  decode.d2.loss_cls: 0.1458  decode.d2.loss_mask: 0.3151  decode.d2.loss_dice: 0.2434  decode.d3.loss_cls: 0.1934  decode.d3.loss_mask: 0.3177  decode.d3.loss_dice: 0.2481  decode.d4.loss_cls: 0.2063  decode.d4.loss_mask: 0.3143  decode.d4.loss_dice: 0.2419  decode.d5.loss_cls: 0.2642  decode.d5.loss_mask: 0.3129  decode.d5.loss_dice: 0.2449  decode.d6.loss_cls: 0.2065  decode.d6.loss_mask: 0.3215  decode.d6.loss_dice: 0.2521  decode.d7.loss_cls: 0.2133  decode.d7.loss_mask: 0.3211  decode.d7.loss_dice: 0.2469  decode.d8.loss_cls: 0.1459  decode.d8.loss_mask: 0.3204  decode.d8.loss_dice: 0.2486
07/30 19:18:19 - mmengine - INFO - Iter(train) [21750/80000]  base_lr: 7.5161e-05 lr: 7.5161e-06  eta: 7:03:13  time: 0.4334  data_time: 0.0089  memory: 5244  grad_norm: 76.5085  loss: 6.6916  decode.loss_cls: 0.1266  decode.loss_mask: 0.2151  decode.loss_dice: 0.2683  decode.d0.loss_cls: 0.9562  decode.d0.loss_mask: 0.2284  decode.d0.loss_dice: 0.2665  decode.d1.loss_cls: 0.1648  decode.d1.loss_mask: 0.2245  decode.d1.loss_dice: 0.2851  decode.d2.loss_cls: 0.0976  decode.d2.loss_mask: 0.2164  decode.d2.loss_dice: 0.2719  decode.d3.loss_cls: 0.0829  decode.d3.loss_mask: 0.2234  decode.d3.loss_dice: 0.2649  decode.d4.loss_cls: 0.0743  decode.d4.loss_mask: 0.2164  decode.d4.loss_dice: 0.2649  decode.d5.loss_cls: 0.0707  decode.d5.loss_mask: 0.2159  decode.d5.loss_dice: 0.2796  decode.d6.loss_cls: 0.1206  decode.d6.loss_mask: 0.2114  decode.d6.loss_dice: 0.2715  decode.d7.loss_cls: 0.0746  decode.d7.loss_mask: 0.2106  decode.d7.loss_dice: 0.2590  decode.d8.loss_cls: 0.0579  decode.d8.loss_mask: 0.2095  decode.d8.loss_dice: 0.2623
07/30 19:18:40 - mmengine - INFO - Iter(train) [21800/80000]  base_lr: 7.5103e-05 lr: 7.5103e-06  eta: 7:02:51  time: 0.4345  data_time: 0.0092  memory: 5261  grad_norm: 143.3834  loss: 8.4950  decode.loss_cls: 0.2342  decode.loss_mask: 0.2426  decode.loss_dice: 0.2593  decode.d0.loss_cls: 0.9849  decode.d0.loss_mask: 0.2553  decode.d0.loss_dice: 0.3040  decode.d1.loss_cls: 0.3480  decode.d1.loss_mask: 0.2523  decode.d1.loss_dice: 0.2846  decode.d2.loss_cls: 0.3064  decode.d2.loss_mask: 0.2479  decode.d2.loss_dice: 0.2643  decode.d3.loss_cls: 0.1702  decode.d3.loss_mask: 0.2497  decode.d3.loss_dice: 0.3025  decode.d4.loss_cls: 0.2477  decode.d4.loss_mask: 0.2464  decode.d4.loss_dice: 0.2676  decode.d5.loss_cls: 0.2571  decode.d5.loss_mask: 0.2469  decode.d5.loss_dice: 0.2707  decode.d6.loss_cls: 0.2137  decode.d6.loss_mask: 0.2430  decode.d6.loss_dice: 0.2686  decode.d7.loss_cls: 0.2497  decode.d7.loss_mask: 0.2458  decode.d7.loss_dice: 0.2602  decode.d8.loss_cls: 0.2578  decode.d8.loss_mask: 0.2444  decode.d8.loss_dice: 0.2692
07/30 19:19:02 - mmengine - INFO - Iter(train) [21850/80000]  base_lr: 7.5044e-05 lr: 7.5044e-06  eta: 7:02:29  time: 0.4347  data_time: 0.0091  memory: 5245  grad_norm: 69.5907  loss: 8.7902  decode.loss_cls: 0.2709  decode.loss_mask: 0.2441  decode.loss_dice: 0.2873  decode.d0.loss_cls: 1.0618  decode.d0.loss_mask: 0.2695  decode.d0.loss_dice: 0.3129  decode.d1.loss_cls: 0.3244  decode.d1.loss_mask: 0.2443  decode.d1.loss_dice: 0.2641  decode.d2.loss_cls: 0.3066  decode.d2.loss_mask: 0.2426  decode.d2.loss_dice: 0.2936  decode.d3.loss_cls: 0.2445  decode.d3.loss_mask: 0.2596  decode.d3.loss_dice: 0.3012  decode.d4.loss_cls: 0.2505  decode.d4.loss_mask: 0.2468  decode.d4.loss_dice: 0.2665  decode.d5.loss_cls: 0.2540  decode.d5.loss_mask: 0.2413  decode.d5.loss_dice: 0.2593  decode.d6.loss_cls: 0.2832  decode.d6.loss_mask: 0.2392  decode.d6.loss_dice: 0.2481  decode.d7.loss_cls: 0.2817  decode.d7.loss_mask: 0.2412  decode.d7.loss_dice: 0.2801  decode.d8.loss_cls: 0.2640  decode.d8.loss_mask: 0.2368  decode.d8.loss_dice: 0.2702
07/30 19:19:24 - mmengine - INFO - Iter(train) [21900/80000]  base_lr: 7.4986e-05 lr: 7.4986e-06  eta: 7:02:07  time: 0.4351  data_time: 0.0090  memory: 5265  grad_norm: 62.9931  loss: 6.6976  decode.loss_cls: 0.1214  decode.loss_mask: 0.2415  decode.loss_dice: 0.2218  decode.d0.loss_cls: 0.9160  decode.d0.loss_mask: 0.2425  decode.d0.loss_dice: 0.2216  decode.d1.loss_cls: 0.1384  decode.d1.loss_mask: 0.2392  decode.d1.loss_dice: 0.2203  decode.d2.loss_cls: 0.1106  decode.d2.loss_mask: 0.2401  decode.d2.loss_dice: 0.2253  decode.d3.loss_cls: 0.1097  decode.d3.loss_mask: 0.2452  decode.d3.loss_dice: 0.2187  decode.d4.loss_cls: 0.1101  decode.d4.loss_mask: 0.2437  decode.d4.loss_dice: 0.2271  decode.d5.loss_cls: 0.1180  decode.d5.loss_mask: 0.2472  decode.d5.loss_dice: 0.2210  decode.d6.loss_cls: 0.1492  decode.d6.loss_mask: 0.2465  decode.d6.loss_dice: 0.2170  decode.d7.loss_cls: 0.1247  decode.d7.loss_mask: 0.2593  decode.d7.loss_dice: 0.2236  decode.d8.loss_cls: 0.1224  decode.d8.loss_mask: 0.2535  decode.d8.loss_dice: 0.2219
07/30 19:19:45 - mmengine - INFO - Iter(train) [21950/80000]  base_lr: 7.4928e-05 lr: 7.4928e-06  eta: 7:01:45  time: 0.4347  data_time: 0.0090  memory: 5279  grad_norm: 124.0090  loss: 9.1531  decode.loss_cls: 0.2922  decode.loss_mask: 0.2362  decode.loss_dice: 0.2837  decode.d0.loss_cls: 1.3223  decode.d0.loss_mask: 0.2363  decode.d0.loss_dice: 0.3075  decode.d1.loss_cls: 0.2894  decode.d1.loss_mask: 0.2263  decode.d1.loss_dice: 0.2969  decode.d2.loss_cls: 0.2053  decode.d2.loss_mask: 0.2334  decode.d2.loss_dice: 0.3225  decode.d3.loss_cls: 0.2553  decode.d3.loss_mask: 0.2296  decode.d3.loss_dice: 0.2857  decode.d4.loss_cls: 0.2499  decode.d4.loss_mask: 0.2267  decode.d4.loss_dice: 0.2902  decode.d5.loss_cls: 0.3182  decode.d5.loss_mask: 0.2296  decode.d5.loss_dice: 0.2911  decode.d6.loss_cls: 0.3367  decode.d6.loss_mask: 0.2349  decode.d6.loss_dice: 0.3163  decode.d7.loss_cls: 0.2729  decode.d7.loss_mask: 0.2415  decode.d7.loss_dice: 0.2951  decode.d8.loss_cls: 0.2922  decode.d8.loss_mask: 0.2392  decode.d8.loss_dice: 0.2962
07/30 19:20:07 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 19:20:07 - mmengine - INFO - Iter(train) [22000/80000]  base_lr: 7.4870e-05 lr: 7.4870e-06  eta: 7:01:23  time: 0.4345  data_time: 0.0090  memory: 5246  grad_norm: 75.8500  loss: 8.7623  decode.loss_cls: 0.2963  decode.loss_mask: 0.2493  decode.loss_dice: 0.3423  decode.d0.loss_cls: 1.0745  decode.d0.loss_mask: 0.2337  decode.d0.loss_dice: 0.3110  decode.d1.loss_cls: 0.1890  decode.d1.loss_mask: 0.2279  decode.d1.loss_dice: 0.3006  decode.d2.loss_cls: 0.1935  decode.d2.loss_mask: 0.2291  decode.d2.loss_dice: 0.3179  decode.d3.loss_cls: 0.2237  decode.d3.loss_mask: 0.2293  decode.d3.loss_dice: 0.3295  decode.d4.loss_cls: 0.1803  decode.d4.loss_mask: 0.2291  decode.d4.loss_dice: 0.3265  decode.d5.loss_cls: 0.2168  decode.d5.loss_mask: 0.2292  decode.d5.loss_dice: 0.3380  decode.d6.loss_cls: 0.2243  decode.d6.loss_mask: 0.2333  decode.d6.loss_dice: 0.3181  decode.d7.loss_cls: 0.2848  decode.d7.loss_mask: 0.2308  decode.d7.loss_dice: 0.3172  decode.d8.loss_cls: 0.2860  decode.d8.loss_mask: 0.2664  decode.d8.loss_dice: 0.3340
07/30 19:20:29 - mmengine - INFO - Iter(train) [22050/80000]  base_lr: 7.4812e-05 lr: 7.4812e-06  eta: 7:01:01  time: 0.4356  data_time: 0.0092  memory: 5265  grad_norm: 89.3385  loss: 8.8928  decode.loss_cls: 0.2325  decode.loss_mask: 0.2308  decode.loss_dice: 0.2908  decode.d0.loss_cls: 1.1935  decode.d0.loss_mask: 0.2452  decode.d0.loss_dice: 0.3087  decode.d1.loss_cls: 0.3417  decode.d1.loss_mask: 0.2338  decode.d1.loss_dice: 0.2974  decode.d2.loss_cls: 0.2962  decode.d2.loss_mask: 0.2293  decode.d2.loss_dice: 0.2861  decode.d3.loss_cls: 0.2254  decode.d3.loss_mask: 0.2312  decode.d3.loss_dice: 0.2948  decode.d4.loss_cls: 0.2628  decode.d4.loss_mask: 0.2271  decode.d4.loss_dice: 0.2892  decode.d5.loss_cls: 0.3567  decode.d5.loss_mask: 0.2247  decode.d5.loss_dice: 0.2831  decode.d6.loss_cls: 0.2602  decode.d6.loss_mask: 0.2254  decode.d6.loss_dice: 0.2838  decode.d7.loss_cls: 0.2578  decode.d7.loss_mask: 0.2313  decode.d7.loss_dice: 0.2882  decode.d8.loss_cls: 0.2366  decode.d8.loss_mask: 0.2311  decode.d8.loss_dice: 0.2972
07/30 19:20:51 - mmengine - INFO - Iter(train) [22100/80000]  base_lr: 7.4754e-05 lr: 7.4754e-06  eta: 7:00:40  time: 0.4360  data_time: 0.0090  memory: 5277  grad_norm: 56.1263  loss: 7.8207  decode.loss_cls: 0.1275  decode.loss_mask: 0.2609  decode.loss_dice: 0.2834  decode.d0.loss_cls: 1.0007  decode.d0.loss_mask: 0.2691  decode.d0.loss_dice: 0.3232  decode.d1.loss_cls: 0.1855  decode.d1.loss_mask: 0.2616  decode.d1.loss_dice: 0.2978  decode.d2.loss_cls: 0.1251  decode.d2.loss_mask: 0.2632  decode.d2.loss_dice: 0.2989  decode.d3.loss_cls: 0.2112  decode.d3.loss_mask: 0.2601  decode.d3.loss_dice: 0.2899  decode.d4.loss_cls: 0.1228  decode.d4.loss_mask: 0.2635  decode.d4.loss_dice: 0.2911  decode.d5.loss_cls: 0.1092  decode.d5.loss_mask: 0.2640  decode.d5.loss_dice: 0.2927  decode.d6.loss_cls: 0.1470  decode.d6.loss_mask: 0.2612  decode.d6.loss_dice: 0.2791  decode.d7.loss_cls: 0.1260  decode.d7.loss_mask: 0.2606  decode.d7.loss_dice: 0.2888  decode.d8.loss_cls: 0.1019  decode.d8.loss_mask: 0.2648  decode.d8.loss_dice: 0.2900
07/30 19:21:13 - mmengine - INFO - Iter(train) [22150/80000]  base_lr: 7.4696e-05 lr: 7.4696e-06  eta: 7:00:18  time: 0.4356  data_time: 0.0092  memory: 5244  grad_norm: 96.1454  loss: 8.2460  decode.loss_cls: 0.1951  decode.loss_mask: 0.2441  decode.loss_dice: 0.2979  decode.d0.loss_cls: 0.9830  decode.d0.loss_mask: 0.2555  decode.d0.loss_dice: 0.3077  decode.d1.loss_cls: 0.3178  decode.d1.loss_mask: 0.2523  decode.d1.loss_dice: 0.3213  decode.d2.loss_cls: 0.2149  decode.d2.loss_mask: 0.2447  decode.d2.loss_dice: 0.3049  decode.d3.loss_cls: 0.1536  decode.d3.loss_mask: 0.2502  decode.d3.loss_dice: 0.3080  decode.d4.loss_cls: 0.1648  decode.d4.loss_mask: 0.2485  decode.d4.loss_dice: 0.3025  decode.d5.loss_cls: 0.1472  decode.d5.loss_mask: 0.2537  decode.d5.loss_dice: 0.3106  decode.d6.loss_cls: 0.1378  decode.d6.loss_mask: 0.2532  decode.d6.loss_dice: 0.3130  decode.d7.loss_cls: 0.1523  decode.d7.loss_mask: 0.2471  decode.d7.loss_dice: 0.3082  decode.d8.loss_cls: 0.2044  decode.d8.loss_mask: 0.2443  decode.d8.loss_dice: 0.3073
07/30 19:21:34 - mmengine - INFO - Iter(train) [22200/80000]  base_lr: 7.4638e-05 lr: 7.4638e-06  eta: 6:59:56  time: 0.4359  data_time: 0.0092  memory: 5227  grad_norm: 89.6008  loss: 7.0374  decode.loss_cls: 0.0452  decode.loss_mask: 0.2580  decode.loss_dice: 0.2665  decode.d0.loss_cls: 0.9073  decode.d0.loss_mask: 0.2670  decode.d0.loss_dice: 0.2818  decode.d1.loss_cls: 0.0966  decode.d1.loss_mask: 0.2813  decode.d1.loss_dice: 0.2990  decode.d2.loss_cls: 0.1089  decode.d2.loss_mask: 0.2762  decode.d2.loss_dice: 0.2853  decode.d3.loss_cls: 0.0766  decode.d3.loss_mask: 0.2727  decode.d3.loss_dice: 0.2826  decode.d4.loss_cls: 0.0618  decode.d4.loss_mask: 0.2800  decode.d4.loss_dice: 0.2853  decode.d5.loss_cls: 0.0566  decode.d5.loss_mask: 0.2748  decode.d5.loss_dice: 0.2813  decode.d6.loss_cls: 0.0501  decode.d6.loss_mask: 0.2699  decode.d6.loss_dice: 0.2813  decode.d7.loss_cls: 0.0685  decode.d7.loss_mask: 0.2636  decode.d7.loss_dice: 0.2747  decode.d8.loss_cls: 0.0461  decode.d8.loss_mask: 0.2620  decode.d8.loss_dice: 0.2765
07/30 19:21:56 - mmengine - INFO - Iter(train) [22250/80000]  base_lr: 7.4580e-05 lr: 7.4580e-06  eta: 6:59:34  time: 0.4361  data_time: 0.0092  memory: 5265  grad_norm: 63.8581  loss: 9.4197  decode.loss_cls: 0.2689  decode.loss_mask: 0.2490  decode.loss_dice: 0.3505  decode.d0.loss_cls: 1.0571  decode.d0.loss_mask: 0.2575  decode.d0.loss_dice: 0.3673  decode.d1.loss_cls: 0.3486  decode.d1.loss_mask: 0.2491  decode.d1.loss_dice: 0.3518  decode.d2.loss_cls: 0.2706  decode.d2.loss_mask: 0.2497  decode.d2.loss_dice: 0.3507  decode.d3.loss_cls: 0.2513  decode.d3.loss_mask: 0.2467  decode.d3.loss_dice: 0.3416  decode.d4.loss_cls: 0.2517  decode.d4.loss_mask: 0.2483  decode.d4.loss_dice: 0.3569  decode.d5.loss_cls: 0.2467  decode.d5.loss_mask: 0.2462  decode.d5.loss_dice: 0.3500  decode.d6.loss_cls: 0.2168  decode.d6.loss_mask: 0.2490  decode.d6.loss_dice: 0.3353  decode.d7.loss_cls: 0.2645  decode.d7.loss_mask: 0.2463  decode.d7.loss_dice: 0.3366  decode.d8.loss_cls: 0.2641  decode.d8.loss_mask: 0.2446  decode.d8.loss_dice: 0.3521
07/30 19:22:18 - mmengine - INFO - Iter(train) [22300/80000]  base_lr: 7.4522e-05 lr: 7.4522e-06  eta: 6:59:13  time: 0.4374  data_time: 0.0092  memory: 5246  grad_norm: 115.0191  loss: 7.0761  decode.loss_cls: 0.1679  decode.loss_mask: 0.2261  decode.loss_dice: 0.2664  decode.d0.loss_cls: 0.8619  decode.d0.loss_mask: 0.2553  decode.d0.loss_dice: 0.3122  decode.d1.loss_cls: 0.1286  decode.d1.loss_mask: 0.2358  decode.d1.loss_dice: 0.2769  decode.d2.loss_cls: 0.1209  decode.d2.loss_mask: 0.2286  decode.d2.loss_dice: 0.2683  decode.d3.loss_cls: 0.1326  decode.d3.loss_mask: 0.2345  decode.d3.loss_dice: 0.2919  decode.d4.loss_cls: 0.0840  decode.d4.loss_mask: 0.2348  decode.d4.loss_dice: 0.2850  decode.d5.loss_cls: 0.0990  decode.d5.loss_mask: 0.2273  decode.d5.loss_dice: 0.2777  decode.d6.loss_cls: 0.1487  decode.d6.loss_mask: 0.2285  decode.d6.loss_dice: 0.2762  decode.d7.loss_cls: 0.1121  decode.d7.loss_mask: 0.2264  decode.d7.loss_dice: 0.2711  decode.d8.loss_cls: 0.1080  decode.d8.loss_mask: 0.2263  decode.d8.loss_dice: 0.2629
07/30 19:22:40 - mmengine - INFO - Iter(train) [22350/80000]  base_lr: 7.4463e-05 lr: 7.4463e-06  eta: 6:58:51  time: 0.4371  data_time: 0.0093  memory: 5265  grad_norm: 63.9522  loss: 6.8323  decode.loss_cls: 0.1027  decode.loss_mask: 0.2275  decode.loss_dice: 0.2419  decode.d0.loss_cls: 1.0769  decode.d0.loss_mask: 0.2350  decode.d0.loss_dice: 0.2278  decode.d1.loss_cls: 0.1443  decode.d1.loss_mask: 0.2281  decode.d1.loss_dice: 0.2225  decode.d2.loss_cls: 0.1315  decode.d2.loss_mask: 0.2284  decode.d2.loss_dice: 0.2413  decode.d3.loss_cls: 0.1200  decode.d3.loss_mask: 0.2247  decode.d3.loss_dice: 0.2288  decode.d4.loss_cls: 0.0992  decode.d4.loss_mask: 0.2245  decode.d4.loss_dice: 0.2372  decode.d5.loss_cls: 0.1634  decode.d5.loss_mask: 0.2230  decode.d5.loss_dice: 0.2356  decode.d6.loss_cls: 0.1412  decode.d6.loss_mask: 0.2195  decode.d6.loss_dice: 0.2281  decode.d7.loss_cls: 0.1515  decode.d7.loss_mask: 0.2223  decode.d7.loss_dice: 0.2262  decode.d8.loss_cls: 0.1308  decode.d8.loss_mask: 0.2202  decode.d8.loss_dice: 0.2279
07/30 19:23:02 - mmengine - INFO - Iter(train) [22400/80000]  base_lr: 7.4405e-05 lr: 7.4405e-06  eta: 6:58:29  time: 0.4358  data_time: 0.0092  memory: 5305  grad_norm: 75.0155  loss: 7.0257  decode.loss_cls: 0.0379  decode.loss_mask: 0.2208  decode.loss_dice: 0.2549  decode.d0.loss_cls: 0.9262  decode.d0.loss_mask: 0.2405  decode.d0.loss_dice: 0.2893  decode.d1.loss_cls: 0.1583  decode.d1.loss_mask: 0.2263  decode.d1.loss_dice: 0.2764  decode.d2.loss_cls: 0.1305  decode.d2.loss_mask: 0.2438  decode.d2.loss_dice: 0.2906  decode.d3.loss_cls: 0.1286  decode.d3.loss_mask: 0.2154  decode.d3.loss_dice: 0.2548  decode.d4.loss_cls: 0.1531  decode.d4.loss_mask: 0.2253  decode.d4.loss_dice: 0.2771  decode.d5.loss_cls: 0.1074  decode.d5.loss_mask: 0.2523  decode.d5.loss_dice: 0.2840  decode.d6.loss_cls: 0.1201  decode.d6.loss_mask: 0.2211  decode.d6.loss_dice: 0.2620  decode.d7.loss_cls: 0.1113  decode.d7.loss_mask: 0.2400  decode.d7.loss_dice: 0.2706  decode.d8.loss_cls: 0.1186  decode.d8.loss_mask: 0.2179  decode.d8.loss_dice: 0.2705
07/30 19:23:24 - mmengine - INFO - Iter(train) [22450/80000]  base_lr: 7.4347e-05 lr: 7.4347e-06  eta: 6:58:08  time: 0.4371  data_time: 0.0092  memory: 5261  grad_norm: 57.0841  loss: 6.9170  decode.loss_cls: 0.0854  decode.loss_mask: 0.2092  decode.loss_dice: 0.2842  decode.d0.loss_cls: 1.0709  decode.d0.loss_mask: 0.2139  decode.d0.loss_dice: 0.2855  decode.d1.loss_cls: 0.1638  decode.d1.loss_mask: 0.2142  decode.d1.loss_dice: 0.3002  decode.d2.loss_cls: 0.0807  decode.d2.loss_mask: 0.2133  decode.d2.loss_dice: 0.2957  decode.d3.loss_cls: 0.1384  decode.d3.loss_mask: 0.2097  decode.d3.loss_dice: 0.2741  decode.d4.loss_cls: 0.1131  decode.d4.loss_mask: 0.2109  decode.d4.loss_dice: 0.2892  decode.d5.loss_cls: 0.0867  decode.d5.loss_mask: 0.2109  decode.d5.loss_dice: 0.2676  decode.d6.loss_cls: 0.0522  decode.d6.loss_mask: 0.2139  decode.d6.loss_dice: 0.2891  decode.d7.loss_cls: 0.0694  decode.d7.loss_mask: 0.2100  decode.d7.loss_dice: 0.2846  decode.d8.loss_cls: 0.0949  decode.d8.loss_mask: 0.2085  decode.d8.loss_dice: 0.2766
07/30 19:23:45 - mmengine - INFO - Iter(train) [22500/80000]  base_lr: 7.4289e-05 lr: 7.4289e-06  eta: 6:57:46  time: 0.4356  data_time: 0.0091  memory: 5224  grad_norm: 43.1861  loss: 7.1162  decode.loss_cls: 0.1761  decode.loss_mask: 0.2270  decode.loss_dice: 0.2464  decode.d0.loss_cls: 0.8233  decode.d0.loss_mask: 0.2311  decode.d0.loss_dice: 0.2425  decode.d1.loss_cls: 0.2135  decode.d1.loss_mask: 0.2284  decode.d1.loss_dice: 0.2597  decode.d2.loss_cls: 0.1805  decode.d2.loss_mask: 0.2273  decode.d2.loss_dice: 0.2381  decode.d3.loss_cls: 0.1732  decode.d3.loss_mask: 0.2256  decode.d3.loss_dice: 0.2345  decode.d4.loss_cls: 0.1824  decode.d4.loss_mask: 0.2283  decode.d4.loss_dice: 0.2552  decode.d5.loss_cls: 0.1716  decode.d5.loss_mask: 0.2260  decode.d5.loss_dice: 0.2359  decode.d6.loss_cls: 0.1277  decode.d6.loss_mask: 0.2269  decode.d6.loss_dice: 0.2429  decode.d7.loss_cls: 0.1758  decode.d7.loss_mask: 0.2286  decode.d7.loss_dice: 0.2545  decode.d8.loss_cls: 0.1809  decode.d8.loss_mask: 0.2263  decode.d8.loss_dice: 0.2258
07/30 19:24:07 - mmengine - INFO - Iter(train) [22550/80000]  base_lr: 7.4231e-05 lr: 7.4231e-06  eta: 6:57:24  time: 0.4385  data_time: 0.0092  memory: 5265  grad_norm: 87.4626  loss: 9.7513  decode.loss_cls: 0.4163  decode.loss_mask: 0.1847  decode.loss_dice: 0.3051  decode.d0.loss_cls: 1.0359  decode.d0.loss_mask: 0.1870  decode.d0.loss_dice: 0.2943  decode.d1.loss_cls: 0.5024  decode.d1.loss_mask: 0.1874  decode.d1.loss_dice: 0.2791  decode.d2.loss_cls: 0.4808  decode.d2.loss_mask: 0.1866  decode.d2.loss_dice: 0.2930  decode.d3.loss_cls: 0.3729  decode.d3.loss_mask: 0.1879  decode.d3.loss_dice: 0.3144  decode.d4.loss_cls: 0.4563  decode.d4.loss_mask: 0.1876  decode.d4.loss_dice: 0.3125  decode.d5.loss_cls: 0.4495  decode.d5.loss_mask: 0.1847  decode.d5.loss_dice: 0.2865  decode.d6.loss_cls: 0.3958  decode.d6.loss_mask: 0.1870  decode.d6.loss_dice: 0.2734  decode.d7.loss_cls: 0.4416  decode.d7.loss_mask: 0.1864  decode.d7.loss_dice: 0.2960  decode.d8.loss_cls: 0.3714  decode.d8.loss_mask: 0.1859  decode.d8.loss_dice: 0.3087
07/30 19:24:29 - mmengine - INFO - Iter(train) [22600/80000]  base_lr: 7.4173e-05 lr: 7.4173e-06  eta: 6:57:03  time: 0.4360  data_time: 0.0092  memory: 5261  grad_norm: 130.4845  loss: 9.2447  decode.loss_cls: 0.2392  decode.loss_mask: 0.2679  decode.loss_dice: 0.2996  decode.d0.loss_cls: 1.1103  decode.d0.loss_mask: 0.3105  decode.d0.loss_dice: 0.3361  decode.d1.loss_cls: 0.2985  decode.d1.loss_mask: 0.2787  decode.d1.loss_dice: 0.3246  decode.d2.loss_cls: 0.2584  decode.d2.loss_mask: 0.2881  decode.d2.loss_dice: 0.3164  decode.d3.loss_cls: 0.2219  decode.d3.loss_mask: 0.2839  decode.d3.loss_dice: 0.3167  decode.d4.loss_cls: 0.2133  decode.d4.loss_mask: 0.2778  decode.d4.loss_dice: 0.3060  decode.d5.loss_cls: 0.2193  decode.d5.loss_mask: 0.2733  decode.d5.loss_dice: 0.3018  decode.d6.loss_cls: 0.2622  decode.d6.loss_mask: 0.2799  decode.d6.loss_dice: 0.3477  decode.d7.loss_cls: 0.2221  decode.d7.loss_mask: 0.2772  decode.d7.loss_dice: 0.3200  decode.d8.loss_cls: 0.2064  decode.d8.loss_mask: 0.2757  decode.d8.loss_dice: 0.3115
07/30 19:24:51 - mmengine - INFO - Iter(train) [22650/80000]  base_lr: 7.4115e-05 lr: 7.4115e-06  eta: 6:56:41  time: 0.4352  data_time: 0.0092  memory: 5246  grad_norm: 65.0227  loss: 7.8828  decode.loss_cls: 0.1632  decode.loss_mask: 0.2618  decode.loss_dice: 0.2964  decode.d0.loss_cls: 0.8322  decode.d0.loss_mask: 0.2726  decode.d0.loss_dice: 0.3405  decode.d1.loss_cls: 0.2375  decode.d1.loss_mask: 0.2680  decode.d1.loss_dice: 0.2988  decode.d2.loss_cls: 0.1558  decode.d2.loss_mask: 0.2676  decode.d2.loss_dice: 0.2807  decode.d3.loss_cls: 0.1511  decode.d3.loss_mask: 0.2605  decode.d3.loss_dice: 0.2969  decode.d4.loss_cls: 0.1418  decode.d4.loss_mask: 0.2613  decode.d4.loss_dice: 0.2960  decode.d5.loss_cls: 0.1481  decode.d5.loss_mask: 0.2604  decode.d5.loss_dice: 0.3004  decode.d6.loss_cls: 0.1207  decode.d6.loss_mask: 0.2620  decode.d6.loss_dice: 0.2923  decode.d7.loss_cls: 0.1518  decode.d7.loss_mask: 0.2651  decode.d7.loss_dice: 0.2942  decode.d8.loss_cls: 0.1505  decode.d8.loss_mask: 0.2604  decode.d8.loss_dice: 0.2944
07/30 19:25:13 - mmengine - INFO - Iter(train) [22700/80000]  base_lr: 7.4056e-05 lr: 7.4056e-06  eta: 6:56:19  time: 0.4364  data_time: 0.0092  memory: 5279  grad_norm: 47.6489  loss: 6.9643  decode.loss_cls: 0.0862  decode.loss_mask: 0.2476  decode.loss_dice: 0.2539  decode.d0.loss_cls: 0.8631  decode.d0.loss_mask: 0.2623  decode.d0.loss_dice: 0.2680  decode.d1.loss_cls: 0.1339  decode.d1.loss_mask: 0.2538  decode.d1.loss_dice: 0.2559  decode.d2.loss_cls: 0.1467  decode.d2.loss_mask: 0.2491  decode.d2.loss_dice: 0.2694  decode.d3.loss_cls: 0.0653  decode.d3.loss_mask: 0.2524  decode.d3.loss_dice: 0.2580  decode.d4.loss_cls: 0.0656  decode.d4.loss_mask: 0.2558  decode.d4.loss_dice: 0.2678  decode.d5.loss_cls: 0.0591  decode.d5.loss_mask: 0.2545  decode.d5.loss_dice: 0.2775  decode.d6.loss_cls: 0.0842  decode.d6.loss_mask: 0.2525  decode.d6.loss_dice: 0.2556  decode.d7.loss_cls: 0.1732  decode.d7.loss_mask: 0.2505  decode.d7.loss_dice: 0.2722  decode.d8.loss_cls: 0.1070  decode.d8.loss_mask: 0.2475  decode.d8.loss_dice: 0.2756
07/30 19:25:35 - mmengine - INFO - Iter(train) [22750/80000]  base_lr: 7.3998e-05 lr: 7.3998e-06  eta: 6:55:57  time: 0.4358  data_time: 0.0092  memory: 5246  grad_norm: 46.0960  loss: 6.1008  decode.loss_cls: 0.0865  decode.loss_mask: 0.2100  decode.loss_dice: 0.2104  decode.d0.loss_cls: 0.8883  decode.d0.loss_mask: 0.2117  decode.d0.loss_dice: 0.2242  decode.d1.loss_cls: 0.1128  decode.d1.loss_mask: 0.2109  decode.d1.loss_dice: 0.2128  decode.d2.loss_cls: 0.1262  decode.d2.loss_mask: 0.2094  decode.d2.loss_dice: 0.2130  decode.d3.loss_cls: 0.1278  decode.d3.loss_mask: 0.2113  decode.d3.loss_dice: 0.2149  decode.d4.loss_cls: 0.1160  decode.d4.loss_mask: 0.2086  decode.d4.loss_dice: 0.2113  decode.d5.loss_cls: 0.1059  decode.d5.loss_mask: 0.2099  decode.d5.loss_dice: 0.2130  decode.d6.loss_cls: 0.1246  decode.d6.loss_mask: 0.2086  decode.d6.loss_dice: 0.2111  decode.d7.loss_cls: 0.0913  decode.d7.loss_mask: 0.2086  decode.d7.loss_dice: 0.2107  decode.d8.loss_cls: 0.0889  decode.d8.loss_mask: 0.2112  decode.d8.loss_dice: 0.2110
07/30 19:25:56 - mmengine - INFO - Iter(train) [22800/80000]  base_lr: 7.3940e-05 lr: 7.3940e-06  eta: 6:55:35  time: 0.4357  data_time: 0.0093  memory: 5246  grad_norm: 35.0483  loss: 7.1232  decode.loss_cls: 0.1279  decode.loss_mask: 0.2419  decode.loss_dice: 0.2451  decode.d0.loss_cls: 1.0405  decode.d0.loss_mask: 0.2568  decode.d0.loss_dice: 0.2504  decode.d1.loss_cls: 0.1498  decode.d1.loss_mask: 0.2506  decode.d1.loss_dice: 0.2672  decode.d2.loss_cls: 0.1268  decode.d2.loss_mask: 0.2459  decode.d2.loss_dice: 0.2440  decode.d3.loss_cls: 0.1060  decode.d3.loss_mask: 0.2454  decode.d3.loss_dice: 0.2599  decode.d4.loss_cls: 0.1188  decode.d4.loss_mask: 0.2432  decode.d4.loss_dice: 0.2650  decode.d5.loss_cls: 0.1141  decode.d5.loss_mask: 0.2432  decode.d5.loss_dice: 0.2658  decode.d6.loss_cls: 0.1228  decode.d6.loss_mask: 0.2432  decode.d6.loss_dice: 0.2404  decode.d7.loss_cls: 0.1305  decode.d7.loss_mask: 0.2406  decode.d7.loss_dice: 0.2358  decode.d8.loss_cls: 0.0882  decode.d8.loss_mask: 0.2411  decode.d8.loss_dice: 0.2723
07/30 19:26:18 - mmengine - INFO - Iter(train) [22850/80000]  base_lr: 7.3882e-05 lr: 7.3882e-06  eta: 6:55:14  time: 0.4353  data_time: 0.0093  memory: 5227  grad_norm: 74.1016  loss: 12.6351  decode.loss_cls: 0.4103  decode.loss_mask: 0.3954  decode.loss_dice: 0.3783  decode.d0.loss_cls: 1.0505  decode.d0.loss_mask: 0.3883  decode.d0.loss_dice: 0.4118  decode.d1.loss_cls: 0.3632  decode.d1.loss_mask: 0.3927  decode.d1.loss_dice: 0.4132  decode.d2.loss_cls: 0.3949  decode.d2.loss_mask: 0.3873  decode.d2.loss_dice: 0.4060  decode.d3.loss_cls: 0.4207  decode.d3.loss_mask: 0.3981  decode.d3.loss_dice: 0.3956  decode.d4.loss_cls: 0.3465  decode.d4.loss_mask: 0.3958  decode.d4.loss_dice: 0.4187  decode.d5.loss_cls: 0.4496  decode.d5.loss_mask: 0.3914  decode.d5.loss_dice: 0.4050  decode.d6.loss_cls: 0.4149  decode.d6.loss_mask: 0.3838  decode.d6.loss_dice: 0.3731  decode.d7.loss_cls: 0.4429  decode.d7.loss_mask: 0.3891  decode.d7.loss_dice: 0.4274  decode.d8.loss_cls: 0.4273  decode.d8.loss_mask: 0.3930  decode.d8.loss_dice: 0.3702
07/30 19:26:40 - mmengine - INFO - Iter(train) [22900/80000]  base_lr: 7.3824e-05 lr: 7.3824e-06  eta: 6:54:52  time: 0.4353  data_time: 0.0093  memory: 5279  grad_norm: 113.4325  loss: 11.5473  decode.loss_cls: 0.3798  decode.loss_mask: 0.3106  decode.loss_dice: 0.4166  decode.d0.loss_cls: 1.1375  decode.d0.loss_mask: 0.3383  decode.d0.loss_dice: 0.4334  decode.d1.loss_cls: 0.3562  decode.d1.loss_mask: 0.3144  decode.d1.loss_dice: 0.4253  decode.d2.loss_cls: 0.3712  decode.d2.loss_mask: 0.3146  decode.d2.loss_dice: 0.4222  decode.d3.loss_cls: 0.3439  decode.d3.loss_mask: 0.3107  decode.d3.loss_dice: 0.3864  decode.d4.loss_cls: 0.3248  decode.d4.loss_mask: 0.3071  decode.d4.loss_dice: 0.4064  decode.d5.loss_cls: 0.3356  decode.d5.loss_mask: 0.3064  decode.d5.loss_dice: 0.4263  decode.d6.loss_cls: 0.2984  decode.d6.loss_mask: 0.3032  decode.d6.loss_dice: 0.4261  decode.d7.loss_cls: 0.3460  decode.d7.loss_mask: 0.3089  decode.d7.loss_dice: 0.4445  decode.d8.loss_cls: 0.3345  decode.d8.loss_mask: 0.3091  decode.d8.loss_dice: 0.4091
07/30 19:27:02 - mmengine - INFO - Iter(train) [22950/80000]  base_lr: 7.3766e-05 lr: 7.3766e-06  eta: 6:54:30  time: 0.4350  data_time: 0.0091  memory: 5261  grad_norm: 61.5375  loss: 8.9815  decode.loss_cls: 0.1544  decode.loss_mask: 0.2846  decode.loss_dice: 0.3144  decode.d0.loss_cls: 1.1106  decode.d0.loss_mask: 0.2828  decode.d0.loss_dice: 0.3374  decode.d1.loss_cls: 0.2013  decode.d1.loss_mask: 0.2731  decode.d1.loss_dice: 0.3087  decode.d2.loss_cls: 0.2427  decode.d2.loss_mask: 0.2783  decode.d2.loss_dice: 0.3374  decode.d3.loss_cls: 0.1787  decode.d3.loss_mask: 0.2766  decode.d3.loss_dice: 0.3334  decode.d4.loss_cls: 0.1813  decode.d4.loss_mask: 0.2828  decode.d4.loss_dice: 0.3623  decode.d5.loss_cls: 0.2076  decode.d5.loss_mask: 0.2884  decode.d5.loss_dice: 0.3438  decode.d6.loss_cls: 0.2101  decode.d6.loss_mask: 0.2755  decode.d6.loss_dice: 0.3761  decode.d7.loss_cls: 0.2061  decode.d7.loss_mask: 0.2717  decode.d7.loss_dice: 0.3065  decode.d8.loss_cls: 0.1522  decode.d8.loss_mask: 0.2722  decode.d8.loss_dice: 0.3303
07/30 19:27:24 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 19:27:24 - mmengine - INFO - Iter(train) [23000/80000]  base_lr: 7.3707e-05 lr: 7.3707e-06  eta: 6:54:08  time: 0.4357  data_time: 0.0092  memory: 5246  grad_norm: 140.9213  loss: 10.5975  decode.loss_cls: 0.4317  decode.loss_mask: 0.2551  decode.loss_dice: 0.3515  decode.d0.loss_cls: 1.1397  decode.d0.loss_mask: 0.2669  decode.d0.loss_dice: 0.3418  decode.d1.loss_cls: 0.3596  decode.d1.loss_mask: 0.2593  decode.d1.loss_dice: 0.3504  decode.d2.loss_cls: 0.3610  decode.d2.loss_mask: 0.2611  decode.d2.loss_dice: 0.3565  decode.d3.loss_cls: 0.3219  decode.d3.loss_mask: 0.2568  decode.d3.loss_dice: 0.3379  decode.d4.loss_cls: 0.3432  decode.d4.loss_mask: 0.2582  decode.d4.loss_dice: 0.3476  decode.d5.loss_cls: 0.3730  decode.d5.loss_mask: 0.2569  decode.d5.loss_dice: 0.3373  decode.d6.loss_cls: 0.4381  decode.d6.loss_mask: 0.2589  decode.d6.loss_dice: 0.3471  decode.d7.loss_cls: 0.4032  decode.d7.loss_mask: 0.2580  decode.d7.loss_dice: 0.3400  decode.d8.loss_cls: 0.3742  decode.d8.loss_mask: 0.2573  decode.d8.loss_dice: 0.3532
07/30 19:27:45 - mmengine - INFO - Iter(train) [23050/80000]  base_lr: 7.3649e-05 lr: 7.3649e-06  eta: 6:53:46  time: 0.4359  data_time: 0.0093  memory: 5279  grad_norm: 58.0456  loss: 7.4549  decode.loss_cls: 0.1689  decode.loss_mask: 0.2085  decode.loss_dice: 0.2614  decode.d0.loss_cls: 0.9968  decode.d0.loss_mask: 0.2174  decode.d0.loss_dice: 0.2900  decode.d1.loss_cls: 0.1968  decode.d1.loss_mask: 0.2115  decode.d1.loss_dice: 0.2812  decode.d2.loss_cls: 0.1927  decode.d2.loss_mask: 0.2129  decode.d2.loss_dice: 0.2804  decode.d3.loss_cls: 0.1486  decode.d3.loss_mask: 0.2102  decode.d3.loss_dice: 0.2801  decode.d4.loss_cls: 0.1363  decode.d4.loss_mask: 0.2077  decode.d4.loss_dice: 0.3112  decode.d5.loss_cls: 0.2048  decode.d5.loss_mask: 0.2100  decode.d5.loss_dice: 0.2792  decode.d6.loss_cls: 0.1425  decode.d6.loss_mask: 0.2101  decode.d6.loss_dice: 0.2901  decode.d7.loss_cls: 0.1766  decode.d7.loss_mask: 0.2086  decode.d7.loss_dice: 0.2621  decode.d8.loss_cls: 0.1967  decode.d8.loss_mask: 0.2104  decode.d8.loss_dice: 0.2512
07/30 19:28:07 - mmengine - INFO - Iter(train) [23100/80000]  base_lr: 7.3591e-05 lr: 7.3591e-06  eta: 6:53:25  time: 0.4361  data_time: 0.0094  memory: 5277  grad_norm: 57.8174  loss: 7.9350  decode.loss_cls: 0.1394  decode.loss_mask: 0.2584  decode.loss_dice: 0.2883  decode.d0.loss_cls: 0.9314  decode.d0.loss_mask: 0.2616  decode.d0.loss_dice: 0.2980  decode.d1.loss_cls: 0.1647  decode.d1.loss_mask: 0.2605  decode.d1.loss_dice: 0.2889  decode.d2.loss_cls: 0.1461  decode.d2.loss_mask: 0.2597  decode.d2.loss_dice: 0.2821  decode.d3.loss_cls: 0.1722  decode.d3.loss_mask: 0.2660  decode.d3.loss_dice: 0.2961  decode.d4.loss_cls: 0.1927  decode.d4.loss_mask: 0.2618  decode.d4.loss_dice: 0.2977  decode.d5.loss_cls: 0.1738  decode.d5.loss_mask: 0.2577  decode.d5.loss_dice: 0.2912  decode.d6.loss_cls: 0.1868  decode.d6.loss_mask: 0.2603  decode.d6.loss_dice: 0.2853  decode.d7.loss_cls: 0.1637  decode.d7.loss_mask: 0.2557  decode.d7.loss_dice: 0.2881  decode.d8.loss_cls: 0.1605  decode.d8.loss_mask: 0.2563  decode.d8.loss_dice: 0.2900
07/30 19:28:29 - mmengine - INFO - Iter(train) [23150/80000]  base_lr: 7.3533e-05 lr: 7.3533e-06  eta: 6:53:03  time: 0.4356  data_time: 0.0093  memory: 5261  grad_norm: 128.3545  loss: 7.7205  decode.loss_cls: 0.0589  decode.loss_mask: 0.3552  decode.loss_dice: 0.2759  decode.d0.loss_cls: 0.7250  decode.d0.loss_mask: 0.3592  decode.d0.loss_dice: 0.2928  decode.d1.loss_cls: 0.0950  decode.d1.loss_mask: 0.3540  decode.d1.loss_dice: 0.2784  decode.d2.loss_cls: 0.1230  decode.d2.loss_mask: 0.3571  decode.d2.loss_dice: 0.2811  decode.d3.loss_cls: 0.0661  decode.d3.loss_mask: 0.3568  decode.d3.loss_dice: 0.2825  decode.d4.loss_cls: 0.0700  decode.d4.loss_mask: 0.3528  decode.d4.loss_dice: 0.2852  decode.d5.loss_cls: 0.0624  decode.d5.loss_mask: 0.3526  decode.d5.loss_dice: 0.2819  decode.d6.loss_cls: 0.0645  decode.d6.loss_mask: 0.3527  decode.d6.loss_dice: 0.2708  decode.d7.loss_cls: 0.0608  decode.d7.loss_mask: 0.3518  decode.d7.loss_dice: 0.2718  decode.d8.loss_cls: 0.0606  decode.d8.loss_mask: 0.3511  decode.d8.loss_dice: 0.2703
07/30 19:28:51 - mmengine - INFO - Iter(train) [23200/80000]  base_lr: 7.3475e-05 lr: 7.3475e-06  eta: 6:52:41  time: 0.4364  data_time: 0.0091  memory: 5278  grad_norm: 64.8402  loss: 8.4076  decode.loss_cls: 0.2771  decode.loss_mask: 0.2303  decode.loss_dice: 0.2815  decode.d0.loss_cls: 1.0163  decode.d0.loss_mask: 0.2256  decode.d0.loss_dice: 0.2868  decode.d1.loss_cls: 0.3010  decode.d1.loss_mask: 0.2280  decode.d1.loss_dice: 0.2721  decode.d2.loss_cls: 0.2306  decode.d2.loss_mask: 0.2294  decode.d2.loss_dice: 0.2690  decode.d3.loss_cls: 0.2524  decode.d3.loss_mask: 0.2331  decode.d3.loss_dice: 0.2810  decode.d4.loss_cls: 0.2216  decode.d4.loss_mask: 0.2271  decode.d4.loss_dice: 0.2766  decode.d5.loss_cls: 0.2457  decode.d5.loss_mask: 0.2270  decode.d5.loss_dice: 0.2800  decode.d6.loss_cls: 0.2931  decode.d6.loss_mask: 0.2211  decode.d6.loss_dice: 0.2811  decode.d7.loss_cls: 0.2610  decode.d7.loss_mask: 0.2248  decode.d7.loss_dice: 0.2748  decode.d8.loss_cls: 0.2488  decode.d8.loss_mask: 0.2203  decode.d8.loss_dice: 0.2902
07/30 19:29:13 - mmengine - INFO - Iter(train) [23250/80000]  base_lr: 7.3416e-05 lr: 7.3416e-06  eta: 6:52:19  time: 0.4360  data_time: 0.0091  memory: 5278  grad_norm: 76.9081  loss: 8.7631  decode.loss_cls: 0.3378  decode.loss_mask: 0.2491  decode.loss_dice: 0.2556  decode.d0.loss_cls: 1.0792  decode.d0.loss_mask: 0.2696  decode.d0.loss_dice: 0.2649  decode.d1.loss_cls: 0.3320  decode.d1.loss_mask: 0.2614  decode.d1.loss_dice: 0.2703  decode.d2.loss_cls: 0.2781  decode.d2.loss_mask: 0.2580  decode.d2.loss_dice: 0.2699  decode.d3.loss_cls: 0.2126  decode.d3.loss_mask: 0.2591  decode.d3.loss_dice: 0.2725  decode.d4.loss_cls: 0.2639  decode.d4.loss_mask: 0.2573  decode.d4.loss_dice: 0.2507  decode.d5.loss_cls: 0.2632  decode.d5.loss_mask: 0.2586  decode.d5.loss_dice: 0.2443  decode.d6.loss_cls: 0.2419  decode.d6.loss_mask: 0.2531  decode.d6.loss_dice: 0.2583  decode.d7.loss_cls: 0.2787  decode.d7.loss_mask: 0.2546  decode.d7.loss_dice: 0.2490  decode.d8.loss_cls: 0.3231  decode.d8.loss_mask: 0.2515  decode.d8.loss_dice: 0.2446
07/30 19:29:34 - mmengine - INFO - Iter(train) [23300/80000]  base_lr: 7.3358e-05 lr: 7.3358e-06  eta: 6:51:58  time: 0.4352  data_time: 0.0094  memory: 5277  grad_norm: 112.6196  loss: 9.0003  decode.loss_cls: 0.1776  decode.loss_mask: 0.2754  decode.loss_dice: 0.3459  decode.d0.loss_cls: 0.9689  decode.d0.loss_mask: 0.2798  decode.d0.loss_dice: 0.3458  decode.d1.loss_cls: 0.2430  decode.d1.loss_mask: 0.2763  decode.d1.loss_dice: 0.3501  decode.d2.loss_cls: 0.2362  decode.d2.loss_mask: 0.2717  decode.d2.loss_dice: 0.3360  decode.d3.loss_cls: 0.1765  decode.d3.loss_mask: 0.2682  decode.d3.loss_dice: 0.3313  decode.d4.loss_cls: 0.2475  decode.d4.loss_mask: 0.2714  decode.d4.loss_dice: 0.3255  decode.d5.loss_cls: 0.2495  decode.d5.loss_mask: 0.2738  decode.d5.loss_dice: 0.3323  decode.d6.loss_cls: 0.1935  decode.d6.loss_mask: 0.2689  decode.d6.loss_dice: 0.3263  decode.d7.loss_cls: 0.1862  decode.d7.loss_mask: 0.2762  decode.d7.loss_dice: 0.3423  decode.d8.loss_cls: 0.2235  decode.d8.loss_mask: 0.2699  decode.d8.loss_dice: 0.3306
07/30 19:29:56 - mmengine - INFO - Iter(train) [23350/80000]  base_lr: 7.3300e-05 lr: 7.3300e-06  eta: 6:51:36  time: 0.4369  data_time: 0.0094  memory: 5265  grad_norm: 64.4545  loss: 7.5969  decode.loss_cls: 0.1214  decode.loss_mask: 0.2473  decode.loss_dice: 0.2857  decode.d0.loss_cls: 0.9888  decode.d0.loss_mask: 0.2417  decode.d0.loss_dice: 0.2997  decode.d1.loss_cls: 0.1596  decode.d1.loss_mask: 0.2363  decode.d1.loss_dice: 0.2847  decode.d2.loss_cls: 0.1583  decode.d2.loss_mask: 0.2353  decode.d2.loss_dice: 0.2876  decode.d3.loss_cls: 0.1551  decode.d3.loss_mask: 0.2370  decode.d3.loss_dice: 0.2838  decode.d4.loss_cls: 0.1886  decode.d4.loss_mask: 0.2374  decode.d4.loss_dice: 0.2864  decode.d5.loss_cls: 0.1796  decode.d5.loss_mask: 0.2418  decode.d5.loss_dice: 0.2879  decode.d6.loss_cls: 0.1150  decode.d6.loss_mask: 0.2490  decode.d6.loss_dice: 0.2872  decode.d7.loss_cls: 0.1133  decode.d7.loss_mask: 0.2507  decode.d7.loss_dice: 0.2841  decode.d8.loss_cls: 0.1178  decode.d8.loss_mask: 0.2444  decode.d8.loss_dice: 0.2910
07/30 19:30:18 - mmengine - INFO - Iter(train) [23400/80000]  base_lr: 7.3242e-05 lr: 7.3242e-06  eta: 6:51:14  time: 0.4357  data_time: 0.0092  memory: 5244  grad_norm: 111.1755  loss: 8.5568  decode.loss_cls: 0.1994  decode.loss_mask: 0.2229  decode.loss_dice: 0.3028  decode.d0.loss_cls: 1.1686  decode.d0.loss_mask: 0.2361  decode.d0.loss_dice: 0.3285  decode.d1.loss_cls: 0.2361  decode.d1.loss_mask: 0.2327  decode.d1.loss_dice: 0.3234  decode.d2.loss_cls: 0.1689  decode.d2.loss_mask: 0.2333  decode.d2.loss_dice: 0.3113  decode.d3.loss_cls: 0.1734  decode.d3.loss_mask: 0.2307  decode.d3.loss_dice: 0.3100  decode.d4.loss_cls: 0.2182  decode.d4.loss_mask: 0.2310  decode.d4.loss_dice: 0.3136  decode.d5.loss_cls: 0.2788  decode.d5.loss_mask: 0.2296  decode.d5.loss_dice: 0.3065  decode.d6.loss_cls: 0.2686  decode.d6.loss_mask: 0.2286  decode.d6.loss_dice: 0.3035  decode.d7.loss_cls: 0.2381  decode.d7.loss_mask: 0.2247  decode.d7.loss_dice: 0.3059  decode.d8.loss_cls: 0.2133  decode.d8.loss_mask: 0.2267  decode.d8.loss_dice: 0.2916
07/30 19:30:40 - mmengine - INFO - Iter(train) [23450/80000]  base_lr: 7.3184e-05 lr: 7.3184e-06  eta: 6:50:53  time: 0.4366  data_time: 0.0093  memory: 5244  grad_norm: 122.6762  loss: 9.4252  decode.loss_cls: 0.2783  decode.loss_mask: 0.2340  decode.loss_dice: 0.3455  decode.d0.loss_cls: 1.1524  decode.d0.loss_mask: 0.2583  decode.d0.loss_dice: 0.3862  decode.d1.loss_cls: 0.3072  decode.d1.loss_mask: 0.2446  decode.d1.loss_dice: 0.3601  decode.d2.loss_cls: 0.2901  decode.d2.loss_mask: 0.2355  decode.d2.loss_dice: 0.3092  decode.d3.loss_cls: 0.2235  decode.d3.loss_mask: 0.2398  decode.d3.loss_dice: 0.3510  decode.d4.loss_cls: 0.2197  decode.d4.loss_mask: 0.2385  decode.d4.loss_dice: 0.3527  decode.d5.loss_cls: 0.2753  decode.d5.loss_mask: 0.2353  decode.d5.loss_dice: 0.3492  decode.d6.loss_cls: 0.2748  decode.d6.loss_mask: 0.2390  decode.d6.loss_dice: 0.3569  decode.d7.loss_cls: 0.2604  decode.d7.loss_mask: 0.2395  decode.d7.loss_dice: 0.3545  decode.d8.loss_cls: 0.2324  decode.d8.loss_mask: 0.2369  decode.d8.loss_dice: 0.3444
07/30 19:31:02 - mmengine - INFO - Iter(train) [23500/80000]  base_lr: 7.3125e-05 lr: 7.3125e-06  eta: 6:50:31  time: 0.4359  data_time: 0.0093  memory: 5246  grad_norm: 102.5748  loss: 8.2188  decode.loss_cls: 0.2688  decode.loss_mask: 0.2036  decode.loss_dice: 0.2902  decode.d0.loss_cls: 1.0098  decode.d0.loss_mask: 0.2214  decode.d0.loss_dice: 0.3017  decode.d1.loss_cls: 0.3163  decode.d1.loss_mask: 0.2135  decode.d1.loss_dice: 0.2825  decode.d2.loss_cls: 0.2790  decode.d2.loss_mask: 0.2101  decode.d2.loss_dice: 0.2851  decode.d3.loss_cls: 0.1758  decode.d3.loss_mask: 0.2064  decode.d3.loss_dice: 0.2982  decode.d4.loss_cls: 0.2207  decode.d4.loss_mask: 0.2067  decode.d4.loss_dice: 0.2774  decode.d5.loss_cls: 0.2228  decode.d5.loss_mask: 0.2068  decode.d5.loss_dice: 0.2813  decode.d6.loss_cls: 0.2307  decode.d6.loss_mask: 0.2055  decode.d6.loss_dice: 0.2847  decode.d7.loss_cls: 0.2749  decode.d7.loss_mask: 0.2064  decode.d7.loss_dice: 0.2763  decode.d8.loss_cls: 0.2642  decode.d8.loss_mask: 0.2081  decode.d8.loss_dice: 0.2897
07/30 19:31:24 - mmengine - INFO - Iter(train) [23550/80000]  base_lr: 7.3067e-05 lr: 7.3067e-06  eta: 6:50:09  time: 0.4355  data_time: 0.0094  memory: 5245  grad_norm: 107.1560  loss: 8.8836  decode.loss_cls: 0.1369  decode.loss_mask: 0.3188  decode.loss_dice: 0.3300  decode.d0.loss_cls: 1.0454  decode.d0.loss_mask: 0.2976  decode.d0.loss_dice: 0.3470  decode.d1.loss_cls: 0.1802  decode.d1.loss_mask: 0.3088  decode.d1.loss_dice: 0.3275  decode.d2.loss_cls: 0.1814  decode.d2.loss_mask: 0.2900  decode.d2.loss_dice: 0.3225  decode.d3.loss_cls: 0.1877  decode.d3.loss_mask: 0.2891  decode.d3.loss_dice: 0.3005  decode.d4.loss_cls: 0.1453  decode.d4.loss_mask: 0.3218  decode.d4.loss_dice: 0.3447  decode.d5.loss_cls: 0.1762  decode.d5.loss_mask: 0.3195  decode.d5.loss_dice: 0.3013  decode.d6.loss_cls: 0.1713  decode.d6.loss_mask: 0.3063  decode.d6.loss_dice: 0.3684  decode.d7.loss_cls: 0.1260  decode.d7.loss_mask: 0.3197  decode.d7.loss_dice: 0.3309  decode.d8.loss_cls: 0.1149  decode.d8.loss_mask: 0.3225  decode.d8.loss_dice: 0.3515
07/30 19:31:45 - mmengine - INFO - Iter(train) [23600/80000]  base_lr: 7.3009e-05 lr: 7.3009e-06  eta: 6:49:47  time: 0.4362  data_time: 0.0093  memory: 5245  grad_norm: 63.7649  loss: 7.8647  decode.loss_cls: 0.1490  decode.loss_mask: 0.2429  decode.loss_dice: 0.2615  decode.d0.loss_cls: 1.1835  decode.d0.loss_mask: 0.2540  decode.d0.loss_dice: 0.2727  decode.d1.loss_cls: 0.2298  decode.d1.loss_mask: 0.2475  decode.d1.loss_dice: 0.2606  decode.d2.loss_cls: 0.1798  decode.d2.loss_mask: 0.2447  decode.d2.loss_dice: 0.2761  decode.d3.loss_cls: 0.1718  decode.d3.loss_mask: 0.2433  decode.d3.loss_dice: 0.2805  decode.d4.loss_cls: 0.1538  decode.d4.loss_mask: 0.2402  decode.d4.loss_dice: 0.2624  decode.d5.loss_cls: 0.1331  decode.d5.loss_mask: 0.2420  decode.d5.loss_dice: 0.2861  decode.d6.loss_cls: 0.1862  decode.d6.loss_mask: 0.2411  decode.d6.loss_dice: 0.2658  decode.d7.loss_cls: 0.1737  decode.d7.loss_mask: 0.2443  decode.d7.loss_dice: 0.2581  decode.d8.loss_cls: 0.1734  decode.d8.loss_mask: 0.2413  decode.d8.loss_dice: 0.2656
07/30 19:32:07 - mmengine - INFO - Iter(train) [23650/80000]  base_lr: 7.2951e-05 lr: 7.2951e-06  eta: 6:49:25  time: 0.4365  data_time: 0.0093  memory: 5246  grad_norm: 85.9004  loss: 8.5557  decode.loss_cls: 0.1259  decode.loss_mask: 0.2910  decode.loss_dice: 0.3493  decode.d0.loss_cls: 0.8924  decode.d0.loss_mask: 0.2911  decode.d0.loss_dice: 0.3560  decode.d1.loss_cls: 0.2749  decode.d1.loss_mask: 0.2824  decode.d1.loss_dice: 0.3476  decode.d2.loss_cls: 0.1998  decode.d2.loss_mask: 0.2842  decode.d2.loss_dice: 0.3477  decode.d3.loss_cls: 0.1055  decode.d3.loss_mask: 0.2840  decode.d3.loss_dice: 0.3452  decode.d4.loss_cls: 0.1249  decode.d4.loss_mask: 0.2833  decode.d4.loss_dice: 0.3494  decode.d5.loss_cls: 0.1207  decode.d5.loss_mask: 0.2861  decode.d5.loss_dice: 0.3401  decode.d6.loss_cls: 0.1270  decode.d6.loss_mask: 0.2833  decode.d6.loss_dice: 0.3547  decode.d7.loss_cls: 0.1192  decode.d7.loss_mask: 0.2833  decode.d7.loss_dice: 0.3435  decode.d8.loss_cls: 0.1245  decode.d8.loss_mask: 0.2861  decode.d8.loss_dice: 0.3528
07/30 19:32:29 - mmengine - INFO - Iter(train) [23700/80000]  base_lr: 7.2892e-05 lr: 7.2892e-06  eta: 6:49:04  time: 0.4360  data_time: 0.0093  memory: 5244  grad_norm: 177.2653  loss: 9.8620  decode.loss_cls: 0.2263  decode.loss_mask: 0.4033  decode.loss_dice: 0.3045  decode.d0.loss_cls: 1.2010  decode.d0.loss_mask: 0.3240  decode.d0.loss_dice: 0.2894  decode.d1.loss_cls: 0.2948  decode.d1.loss_mask: 0.3104  decode.d1.loss_dice: 0.2702  decode.d2.loss_cls: 0.2413  decode.d2.loss_mask: 0.3088  decode.d2.loss_dice: 0.2700  decode.d3.loss_cls: 0.2954  decode.d3.loss_mask: 0.3084  decode.d3.loss_dice: 0.2706  decode.d4.loss_cls: 0.2706  decode.d4.loss_mask: 0.3620  decode.d4.loss_dice: 0.2938  decode.d5.loss_cls: 0.2429  decode.d5.loss_mask: 0.3701  decode.d5.loss_dice: 0.2957  decode.d6.loss_cls: 0.2241  decode.d6.loss_mask: 0.3957  decode.d6.loss_dice: 0.2973  decode.d7.loss_cls: 0.1877  decode.d7.loss_mask: 0.4007  decode.d7.loss_dice: 0.2945  decode.d8.loss_cls: 0.2064  decode.d8.loss_mask: 0.4057  decode.d8.loss_dice: 0.2965
07/30 19:32:51 - mmengine - INFO - Iter(train) [23750/80000]  base_lr: 7.2834e-05 lr: 7.2834e-06  eta: 6:48:42  time: 0.4358  data_time: 0.0092  memory: 5261  grad_norm: 115.2419  loss: 9.4933  decode.loss_cls: 0.2610  decode.loss_mask: 0.2618  decode.loss_dice: 0.3350  decode.d0.loss_cls: 1.0674  decode.d0.loss_mask: 0.2670  decode.d0.loss_dice: 0.3465  decode.d1.loss_cls: 0.2953  decode.d1.loss_mask: 0.2717  decode.d1.loss_dice: 0.3296  decode.d2.loss_cls: 0.2393  decode.d2.loss_mask: 0.2701  decode.d2.loss_dice: 0.3501  decode.d3.loss_cls: 0.2903  decode.d3.loss_mask: 0.2611  decode.d3.loss_dice: 0.3213  decode.d4.loss_cls: 0.2241  decode.d4.loss_mask: 0.2752  decode.d4.loss_dice: 0.3407  decode.d5.loss_cls: 0.3106  decode.d5.loss_mask: 0.2667  decode.d5.loss_dice: 0.3344  decode.d6.loss_cls: 0.2619  decode.d6.loss_mask: 0.2686  decode.d6.loss_dice: 0.3476  decode.d7.loss_cls: 0.1836  decode.d7.loss_mask: 0.2830  decode.d7.loss_dice: 0.3669  decode.d8.loss_cls: 0.2506  decode.d8.loss_mask: 0.2663  decode.d8.loss_dice: 0.3460
07/30 19:33:13 - mmengine - INFO - Iter(train) [23800/80000]  base_lr: 7.2776e-05 lr: 7.2776e-06  eta: 6:48:20  time: 0.4362  data_time: 0.0093  memory: 5277  grad_norm: 97.6044  loss: 9.3356  decode.loss_cls: 0.2388  decode.loss_mask: 0.3100  decode.loss_dice: 0.2789  decode.d0.loss_cls: 1.0153  decode.d0.loss_mask: 0.3479  decode.d0.loss_dice: 0.3023  decode.d1.loss_cls: 0.2769  decode.d1.loss_mask: 0.3293  decode.d1.loss_dice: 0.2830  decode.d2.loss_cls: 0.2809  decode.d2.loss_mask: 0.3271  decode.d2.loss_dice: 0.2885  decode.d3.loss_cls: 0.2721  decode.d3.loss_mask: 0.3254  decode.d3.loss_dice: 0.2775  decode.d4.loss_cls: 0.2305  decode.d4.loss_mask: 0.3166  decode.d4.loss_dice: 0.2846  decode.d5.loss_cls: 0.3077  decode.d5.loss_mask: 0.3216  decode.d5.loss_dice: 0.2752  decode.d6.loss_cls: 0.2212  decode.d6.loss_mask: 0.3118  decode.d6.loss_dice: 0.2774  decode.d7.loss_cls: 0.2308  decode.d7.loss_mask: 0.3167  decode.d7.loss_dice: 0.2788  decode.d8.loss_cls: 0.2054  decode.d8.loss_mask: 0.3132  decode.d8.loss_dice: 0.2903
07/30 19:33:34 - mmengine - INFO - Iter(train) [23850/80000]  base_lr: 7.2717e-05 lr: 7.2717e-06  eta: 6:47:58  time: 0.4352  data_time: 0.0091  memory: 5265  grad_norm: 119.2655  loss: 8.1324  decode.loss_cls: 0.1663  decode.loss_mask: 0.2948  decode.loss_dice: 0.3051  decode.d0.loss_cls: 0.8978  decode.d0.loss_mask: 0.3069  decode.d0.loss_dice: 0.3586  decode.d1.loss_cls: 0.0780  decode.d1.loss_mask: 0.2922  decode.d1.loss_dice: 0.3112  decode.d2.loss_cls: 0.0923  decode.d2.loss_mask: 0.2873  decode.d2.loss_dice: 0.3129  decode.d3.loss_cls: 0.0954  decode.d3.loss_mask: 0.2903  decode.d3.loss_dice: 0.3111  decode.d4.loss_cls: 0.1034  decode.d4.loss_mask: 0.2935  decode.d4.loss_dice: 0.3406  decode.d5.loss_cls: 0.1782  decode.d5.loss_mask: 0.2895  decode.d5.loss_dice: 0.3161  decode.d6.loss_cls: 0.1356  decode.d6.loss_mask: 0.2953  decode.d6.loss_dice: 0.3171  decode.d7.loss_cls: 0.1026  decode.d7.loss_mask: 0.2931  decode.d7.loss_dice: 0.3111  decode.d8.loss_cls: 0.1459  decode.d8.loss_mask: 0.2926  decode.d8.loss_dice: 0.3175
07/30 19:33:56 - mmengine - INFO - Iter(train) [23900/80000]  base_lr: 7.2659e-05 lr: 7.2659e-06  eta: 6:47:36  time: 0.4354  data_time: 0.0093  memory: 5278  grad_norm: 76.0241  loss: 7.8127  decode.loss_cls: 0.1744  decode.loss_mask: 0.2284  decode.loss_dice: 0.2415  decode.d0.loss_cls: 1.0247  decode.d0.loss_mask: 0.2360  decode.d0.loss_dice: 0.2644  decode.d1.loss_cls: 0.3415  decode.d1.loss_mask: 0.2318  decode.d1.loss_dice: 0.2479  decode.d2.loss_cls: 0.2291  decode.d2.loss_mask: 0.2285  decode.d2.loss_dice: 0.2552  decode.d3.loss_cls: 0.2195  decode.d3.loss_mask: 0.2294  decode.d3.loss_dice: 0.2498  decode.d4.loss_cls: 0.2191  decode.d4.loss_mask: 0.2269  decode.d4.loss_dice: 0.2503  decode.d5.loss_cls: 0.1932  decode.d5.loss_mask: 0.2274  decode.d5.loss_dice: 0.2572  decode.d6.loss_cls: 0.2229  decode.d6.loss_mask: 0.2354  decode.d6.loss_dice: 0.2440  decode.d7.loss_cls: 0.2075  decode.d7.loss_mask: 0.2320  decode.d7.loss_dice: 0.2516  decode.d8.loss_cls: 0.1647  decode.d8.loss_mask: 0.2306  decode.d8.loss_dice: 0.2478
07/30 19:34:18 - mmengine - INFO - Iter(train) [23950/80000]  base_lr: 7.2601e-05 lr: 7.2601e-06  eta: 6:47:15  time: 0.4357  data_time: 0.0092  memory: 5265  grad_norm: 110.4158  loss: 11.2839  decode.loss_cls: 0.3544  decode.loss_mask: 0.2302  decode.loss_dice: 0.3880  decode.d0.loss_cls: 1.2074  decode.d0.loss_mask: 0.2373  decode.d0.loss_dice: 0.3937  decode.d1.loss_cls: 0.5736  decode.d1.loss_mask: 0.2258  decode.d1.loss_dice: 0.3693  decode.d2.loss_cls: 0.4447  decode.d2.loss_mask: 0.2313  decode.d2.loss_dice: 0.3863  decode.d3.loss_cls: 0.3840  decode.d3.loss_mask: 0.2482  decode.d3.loss_dice: 0.3935  decode.d4.loss_cls: 0.3722  decode.d4.loss_mask: 0.2289  decode.d4.loss_dice: 0.3648  decode.d5.loss_cls: 0.4177  decode.d5.loss_mask: 0.2419  decode.d5.loss_dice: 0.3860  decode.d6.loss_cls: 0.4817  decode.d6.loss_mask: 0.2197  decode.d6.loss_dice: 0.3751  decode.d7.loss_cls: 0.4562  decode.d7.loss_mask: 0.2501  decode.d7.loss_dice: 0.3764  decode.d8.loss_cls: 0.4120  decode.d8.loss_mask: 0.2448  decode.d8.loss_dice: 0.3886
07/30 19:34:40 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 19:34:40 - mmengine - INFO - Iter(train) [24000/80000]  base_lr: 7.2543e-05 lr: 7.2543e-06  eta: 6:46:53  time: 0.4350  data_time: 0.0094  memory: 5278  grad_norm: 98.3431  loss: 11.9597  decode.loss_cls: 0.3074  decode.loss_mask: 0.4254  decode.loss_dice: 0.3355  decode.d0.loss_cls: 1.1151  decode.d0.loss_mask: 0.4635  decode.d0.loss_dice: 0.3664  decode.d1.loss_cls: 0.4249  decode.d1.loss_mask: 0.4269  decode.d1.loss_dice: 0.3433  decode.d2.loss_cls: 0.4044  decode.d2.loss_mask: 0.4153  decode.d2.loss_dice: 0.3323  decode.d3.loss_cls: 0.4116  decode.d3.loss_mask: 0.4214  decode.d3.loss_dice: 0.3341  decode.d4.loss_cls: 0.3927  decode.d4.loss_mask: 0.4232  decode.d4.loss_dice: 0.3449  decode.d5.loss_cls: 0.3357  decode.d5.loss_mask: 0.4241  decode.d5.loss_dice: 0.3363  decode.d6.loss_cls: 0.3138  decode.d6.loss_mask: 0.4260  decode.d6.loss_dice: 0.3293  decode.d7.loss_cls: 0.3052  decode.d7.loss_mask: 0.4215  decode.d7.loss_dice: 0.3308  decode.d8.loss_cls: 0.2841  decode.d8.loss_mask: 0.4295  decode.d8.loss_dice: 0.3350
07/30 19:35:02 - mmengine - INFO - Iter(train) [24050/80000]  base_lr: 7.2484e-05 lr: 7.2484e-06  eta: 6:46:31  time: 0.4365  data_time: 0.0091  memory: 5265  grad_norm: 53.3949  loss: 6.4688  decode.loss_cls: 0.0688  decode.loss_mask: 0.2112  decode.loss_dice: 0.2561  decode.d0.loss_cls: 1.0316  decode.d0.loss_mask: 0.2173  decode.d0.loss_dice: 0.2694  decode.d1.loss_cls: 0.0971  decode.d1.loss_mask: 0.2098  decode.d1.loss_dice: 0.2666  decode.d2.loss_cls: 0.0911  decode.d2.loss_mask: 0.2079  decode.d2.loss_dice: 0.2563  decode.d3.loss_cls: 0.0892  decode.d3.loss_mask: 0.2118  decode.d3.loss_dice: 0.2668  decode.d4.loss_cls: 0.0818  decode.d4.loss_mask: 0.2106  decode.d4.loss_dice: 0.2535  decode.d5.loss_cls: 0.0811  decode.d5.loss_mask: 0.2123  decode.d5.loss_dice: 0.2599  decode.d6.loss_cls: 0.0650  decode.d6.loss_mask: 0.2125  decode.d6.loss_dice: 0.2570  decode.d7.loss_cls: 0.0743  decode.d7.loss_mask: 0.2098  decode.d7.loss_dice: 0.2600  decode.d8.loss_cls: 0.0715  decode.d8.loss_mask: 0.2133  decode.d8.loss_dice: 0.2549
07/30 19:35:24 - mmengine - INFO - Iter(train) [24100/80000]  base_lr: 7.2426e-05 lr: 7.2426e-06  eta: 6:46:09  time: 0.4365  data_time: 0.0093  memory: 5304  grad_norm: 84.1812  loss: 7.1709  decode.loss_cls: 0.0628  decode.loss_mask: 0.2808  decode.loss_dice: 0.2808  decode.d0.loss_cls: 0.7938  decode.d0.loss_mask: 0.2793  decode.d0.loss_dice: 0.3203  decode.d1.loss_cls: 0.1368  decode.d1.loss_mask: 0.2822  decode.d1.loss_dice: 0.2910  decode.d2.loss_cls: 0.0843  decode.d2.loss_mask: 0.2803  decode.d2.loss_dice: 0.2886  decode.d3.loss_cls: 0.0865  decode.d3.loss_mask: 0.2763  decode.d3.loss_dice: 0.2823  decode.d4.loss_cls: 0.0590  decode.d4.loss_mask: 0.2763  decode.d4.loss_dice: 0.2864  decode.d5.loss_cls: 0.0693  decode.d5.loss_mask: 0.2715  decode.d5.loss_dice: 0.2770  decode.d6.loss_cls: 0.0397  decode.d6.loss_mask: 0.2706  decode.d6.loss_dice: 0.2839  decode.d7.loss_cls: 0.0666  decode.d7.loss_mask: 0.2735  decode.d7.loss_dice: 0.2782  decode.d8.loss_cls: 0.1360  decode.d8.loss_mask: 0.2763  decode.d8.loss_dice: 0.2805
07/30 19:35:45 - mmengine - INFO - Iter(train) [24150/80000]  base_lr: 7.2368e-05 lr: 7.2368e-06  eta: 6:45:48  time: 0.4359  data_time: 0.0092  memory: 5277  grad_norm: 84.4303  loss: 8.4761  decode.loss_cls: 0.1535  decode.loss_mask: 0.2245  decode.loss_dice: 0.3572  decode.d0.loss_cls: 1.0142  decode.d0.loss_mask: 0.2147  decode.d0.loss_dice: 0.3155  decode.d1.loss_cls: 0.1813  decode.d1.loss_mask: 0.2184  decode.d1.loss_dice: 0.3325  decode.d2.loss_cls: 0.2099  decode.d2.loss_mask: 0.2180  decode.d2.loss_dice: 0.3475  decode.d3.loss_cls: 0.2474  decode.d3.loss_mask: 0.2189  decode.d3.loss_dice: 0.3380  decode.d4.loss_cls: 0.2718  decode.d4.loss_mask: 0.2204  decode.d4.loss_dice: 0.3288  decode.d5.loss_cls: 0.2129  decode.d5.loss_mask: 0.2181  decode.d5.loss_dice: 0.3174  decode.d6.loss_cls: 0.2284  decode.d6.loss_mask: 0.2212  decode.d6.loss_dice: 0.3532  decode.d7.loss_cls: 0.1933  decode.d7.loss_mask: 0.2229  decode.d7.loss_dice: 0.3503  decode.d8.loss_cls: 0.1899  decode.d8.loss_mask: 0.2212  decode.d8.loss_dice: 0.3347
07/30 19:36:07 - mmengine - INFO - Iter(train) [24200/80000]  base_lr: 7.2309e-05 lr: 7.2309e-06  eta: 6:45:26  time: 0.4373  data_time: 0.0093  memory: 5245  grad_norm: 53.4793  loss: 8.1517  decode.loss_cls: 0.2043  decode.loss_mask: 0.2486  decode.loss_dice: 0.2541  decode.d0.loss_cls: 1.0724  decode.d0.loss_mask: 0.2550  decode.d0.loss_dice: 0.3104  decode.d1.loss_cls: 0.2387  decode.d1.loss_mask: 0.2453  decode.d1.loss_dice: 0.2747  decode.d2.loss_cls: 0.2223  decode.d2.loss_mask: 0.2466  decode.d2.loss_dice: 0.2723  decode.d3.loss_cls: 0.1733  decode.d3.loss_mask: 0.2489  decode.d3.loss_dice: 0.2799  decode.d4.loss_cls: 0.2110  decode.d4.loss_mask: 0.2442  decode.d4.loss_dice: 0.2517  decode.d5.loss_cls: 0.1736  decode.d5.loss_mask: 0.2488  decode.d5.loss_dice: 0.2885  decode.d6.loss_cls: 0.2053  decode.d6.loss_mask: 0.2441  decode.d6.loss_dice: 0.2861  decode.d7.loss_cls: 0.2173  decode.d7.loss_mask: 0.2442  decode.d7.loss_dice: 0.2858  decode.d8.loss_cls: 0.2094  decode.d8.loss_mask: 0.2453  decode.d8.loss_dice: 0.2497
07/30 19:36:29 - mmengine - INFO - Iter(train) [24250/80000]  base_lr: 7.2251e-05 lr: 7.2251e-06  eta: 6:45:04  time: 0.4359  data_time: 0.0094  memory: 5265  grad_norm: 47.9710  loss: 7.7549  decode.loss_cls: 0.0804  decode.loss_mask: 0.3005  decode.loss_dice: 0.3255  decode.d0.loss_cls: 0.8336  decode.d0.loss_mask: 0.3081  decode.d0.loss_dice: 0.3305  decode.d1.loss_cls: 0.0947  decode.d1.loss_mask: 0.3000  decode.d1.loss_dice: 0.3311  decode.d2.loss_cls: 0.1252  decode.d2.loss_mask: 0.2994  decode.d2.loss_dice: 0.3131  decode.d3.loss_cls: 0.0686  decode.d3.loss_mask: 0.3020  decode.d3.loss_dice: 0.3065  decode.d4.loss_cls: 0.0975  decode.d4.loss_mask: 0.3019  decode.d4.loss_dice: 0.3169  decode.d5.loss_cls: 0.0624  decode.d5.loss_mask: 0.2991  decode.d5.loss_dice: 0.3255  decode.d6.loss_cls: 0.0560  decode.d6.loss_mask: 0.3048  decode.d6.loss_dice: 0.2960  decode.d7.loss_cls: 0.0489  decode.d7.loss_mask: 0.3046  decode.d7.loss_dice: 0.3305  decode.d8.loss_cls: 0.0736  decode.d8.loss_mask: 0.3020  decode.d8.loss_dice: 0.3162
07/30 19:36:51 - mmengine - INFO - Iter(train) [24300/80000]  base_lr: 7.2193e-05 lr: 7.2193e-06  eta: 6:44:42  time: 0.4365  data_time: 0.0092  memory: 5265  grad_norm: 68.9333  loss: 9.6056  decode.loss_cls: 0.3258  decode.loss_mask: 0.2378  decode.loss_dice: 0.2363  decode.d0.loss_cls: 1.3132  decode.d0.loss_mask: 0.2601  decode.d0.loss_dice: 0.2619  decode.d1.loss_cls: 0.3473  decode.d1.loss_mask: 0.2476  decode.d1.loss_dice: 0.2753  decode.d2.loss_cls: 0.3588  decode.d2.loss_mask: 0.2586  decode.d2.loss_dice: 0.2672  decode.d3.loss_cls: 0.3814  decode.d3.loss_mask: 0.2503  decode.d3.loss_dice: 0.2723  decode.d4.loss_cls: 0.3102  decode.d4.loss_mask: 0.2710  decode.d4.loss_dice: 0.2502  decode.d5.loss_cls: 0.3008  decode.d5.loss_mask: 0.2707  decode.d5.loss_dice: 0.2796  decode.d6.loss_cls: 0.3906  decode.d6.loss_mask: 0.2431  decode.d6.loss_dice: 0.2657  decode.d7.loss_cls: 0.3569  decode.d7.loss_mask: 0.2457  decode.d7.loss_dice: 0.2686  decode.d8.loss_cls: 0.3438  decode.d8.loss_mask: 0.2449  decode.d8.loss_dice: 0.2698
07/30 19:37:13 - mmengine - INFO - Iter(train) [24350/80000]  base_lr: 7.2134e-05 lr: 7.2134e-06  eta: 6:44:21  time: 0.4355  data_time: 0.0093  memory: 5278  grad_norm: 93.1234  loss: 9.2680  decode.loss_cls: 0.2900  decode.loss_mask: 0.2530  decode.loss_dice: 0.2990  decode.d0.loss_cls: 1.0529  decode.d0.loss_mask: 0.2601  decode.d0.loss_dice: 0.2860  decode.d1.loss_cls: 0.3058  decode.d1.loss_mask: 0.2555  decode.d1.loss_dice: 0.2991  decode.d2.loss_cls: 0.2909  decode.d2.loss_mask: 0.2545  decode.d2.loss_dice: 0.2902  decode.d3.loss_cls: 0.2736  decode.d3.loss_mask: 0.2555  decode.d3.loss_dice: 0.2735  decode.d4.loss_cls: 0.3249  decode.d4.loss_mask: 0.2558  decode.d4.loss_dice: 0.3004  decode.d5.loss_cls: 0.3313  decode.d5.loss_mask: 0.2509  decode.d5.loss_dice: 0.2601  decode.d6.loss_cls: 0.3147  decode.d6.loss_mask: 0.2566  decode.d6.loss_dice: 0.2924  decode.d7.loss_cls: 0.3168  decode.d7.loss_mask: 0.2540  decode.d7.loss_dice: 0.2798  decode.d8.loss_cls: 0.3435  decode.d8.loss_mask: 0.2543  decode.d8.loss_dice: 0.2929
07/30 19:37:35 - mmengine - INFO - Iter(train) [24400/80000]  base_lr: 7.2076e-05 lr: 7.2076e-06  eta: 6:43:59  time: 0.4365  data_time: 0.0092  memory: 5246  grad_norm: 87.8604  loss: 8.0067  decode.loss_cls: 0.2124  decode.loss_mask: 0.2439  decode.loss_dice: 0.3066  decode.d0.loss_cls: 0.8749  decode.d0.loss_mask: 0.2433  decode.d0.loss_dice: 0.3555  decode.d1.loss_cls: 0.1687  decode.d1.loss_mask: 0.2449  decode.d1.loss_dice: 0.3073  decode.d2.loss_cls: 0.1436  decode.d2.loss_mask: 0.2426  decode.d2.loss_dice: 0.2948  decode.d3.loss_cls: 0.1917  decode.d3.loss_mask: 0.2423  decode.d3.loss_dice: 0.3042  decode.d4.loss_cls: 0.1394  decode.d4.loss_mask: 0.2422  decode.d4.loss_dice: 0.3026  decode.d5.loss_cls: 0.1595  decode.d5.loss_mask: 0.2402  decode.d5.loss_dice: 0.3084  decode.d6.loss_cls: 0.2153  decode.d6.loss_mask: 0.2416  decode.d6.loss_dice: 0.2974  decode.d7.loss_cls: 0.1881  decode.d7.loss_mask: 0.2432  decode.d7.loss_dice: 0.3024  decode.d8.loss_cls: 0.1937  decode.d8.loss_mask: 0.2425  decode.d8.loss_dice: 0.3135
07/30 19:37:56 - mmengine - INFO - Iter(train) [24450/80000]  base_lr: 7.2018e-05 lr: 7.2018e-06  eta: 6:43:37  time: 0.4375  data_time: 0.0091  memory: 5246  grad_norm: 88.0518  loss: 6.4919  decode.loss_cls: 0.1407  decode.loss_mask: 0.2202  decode.loss_dice: 0.2323  decode.d0.loss_cls: 0.8756  decode.d0.loss_mask: 0.2228  decode.d0.loss_dice: 0.2505  decode.d1.loss_cls: 0.1290  decode.d1.loss_mask: 0.2239  decode.d1.loss_dice: 0.2393  decode.d2.loss_cls: 0.1231  decode.d2.loss_mask: 0.2182  decode.d2.loss_dice: 0.2218  decode.d3.loss_cls: 0.0963  decode.d3.loss_mask: 0.2209  decode.d3.loss_dice: 0.2332  decode.d4.loss_cls: 0.1162  decode.d4.loss_mask: 0.2211  decode.d4.loss_dice: 0.2228  decode.d5.loss_cls: 0.1021  decode.d5.loss_mask: 0.2169  decode.d5.loss_dice: 0.2350  decode.d6.loss_cls: 0.1029  decode.d6.loss_mask: 0.2205  decode.d6.loss_dice: 0.2234  decode.d7.loss_cls: 0.1370  decode.d7.loss_mask: 0.2196  decode.d7.loss_dice: 0.2338  decode.d8.loss_cls: 0.1339  decode.d8.loss_mask: 0.2199  decode.d8.loss_dice: 0.2390
07/30 19:38:18 - mmengine - INFO - Iter(train) [24500/80000]  base_lr: 7.1959e-05 lr: 7.1959e-06  eta: 6:43:16  time: 0.4371  data_time: 0.0093  memory: 5241  grad_norm: 55.4566  loss: 6.8749  decode.loss_cls: 0.1097  decode.loss_mask: 0.2459  decode.loss_dice: 0.2357  decode.d0.loss_cls: 0.9138  decode.d0.loss_mask: 0.2497  decode.d0.loss_dice: 0.2445  decode.d1.loss_cls: 0.1719  decode.d1.loss_mask: 0.2463  decode.d1.loss_dice: 0.2309  decode.d2.loss_cls: 0.1160  decode.d2.loss_mask: 0.2483  decode.d2.loss_dice: 0.2318  decode.d3.loss_cls: 0.0732  decode.d3.loss_mask: 0.2487  decode.d3.loss_dice: 0.2450  decode.d4.loss_cls: 0.1365  decode.d4.loss_mask: 0.2486  decode.d4.loss_dice: 0.2443  decode.d5.loss_cls: 0.1312  decode.d5.loss_mask: 0.2459  decode.d5.loss_dice: 0.2328  decode.d6.loss_cls: 0.1251  decode.d6.loss_mask: 0.2442  decode.d6.loss_dice: 0.2358  decode.d7.loss_cls: 0.1436  decode.d7.loss_mask: 0.2470  decode.d7.loss_dice: 0.2330  decode.d8.loss_cls: 0.1134  decode.d8.loss_mask: 0.2468  decode.d8.loss_dice: 0.2350
07/30 19:38:40 - mmengine - INFO - Iter(train) [24550/80000]  base_lr: 7.1901e-05 lr: 7.1901e-06  eta: 6:42:54  time: 0.4376  data_time: 0.0093  memory: 5304  grad_norm: 36.6877  loss: 6.4244  decode.loss_cls: 0.0564  decode.loss_mask: 0.2314  decode.loss_dice: 0.2186  decode.d0.loss_cls: 1.0551  decode.d0.loss_mask: 0.2366  decode.d0.loss_dice: 0.2393  decode.d1.loss_cls: 0.1061  decode.d1.loss_mask: 0.2326  decode.d1.loss_dice: 0.2233  decode.d2.loss_cls: 0.1495  decode.d2.loss_mask: 0.2235  decode.d2.loss_dice: 0.2354  decode.d3.loss_cls: 0.0758  decode.d3.loss_mask: 0.2326  decode.d3.loss_dice: 0.2344  decode.d4.loss_cls: 0.0829  decode.d4.loss_mask: 0.2287  decode.d4.loss_dice: 0.2366  decode.d5.loss_cls: 0.0797  decode.d5.loss_mask: 0.2365  decode.d5.loss_dice: 0.2372  decode.d6.loss_cls: 0.0533  decode.d6.loss_mask: 0.2306  decode.d6.loss_dice: 0.2460  decode.d7.loss_cls: 0.0625  decode.d7.loss_mask: 0.2310  decode.d7.loss_dice: 0.2361  decode.d8.loss_cls: 0.0548  decode.d8.loss_mask: 0.2325  decode.d8.loss_dice: 0.2254
07/30 19:39:02 - mmengine - INFO - Iter(train) [24600/80000]  base_lr: 7.1843e-05 lr: 7.1843e-06  eta: 6:42:32  time: 0.4359  data_time: 0.0091  memory: 5277  grad_norm: 39.0270  loss: 6.8267  decode.loss_cls: 0.0662  decode.loss_mask: 0.2436  decode.loss_dice: 0.2694  decode.d0.loss_cls: 0.8394  decode.d0.loss_mask: 0.2446  decode.d0.loss_dice: 0.3395  decode.d1.loss_cls: 0.0823  decode.d1.loss_mask: 0.2390  decode.d1.loss_dice: 0.2947  decode.d2.loss_cls: 0.0815  decode.d2.loss_mask: 0.2396  decode.d2.loss_dice: 0.2892  decode.d3.loss_cls: 0.0758  decode.d3.loss_mask: 0.2385  decode.d3.loss_dice: 0.2619  decode.d4.loss_cls: 0.0891  decode.d4.loss_mask: 0.2402  decode.d4.loss_dice: 0.2707  decode.d5.loss_cls: 0.0794  decode.d5.loss_mask: 0.2415  decode.d5.loss_dice: 0.2668  decode.d6.loss_cls: 0.0771  decode.d6.loss_mask: 0.2432  decode.d6.loss_dice: 0.2877  decode.d7.loss_cls: 0.0736  decode.d7.loss_mask: 0.2429  decode.d7.loss_dice: 0.2835  decode.d8.loss_cls: 0.0782  decode.d8.loss_mask: 0.2421  decode.d8.loss_dice: 0.3057
07/30 19:39:24 - mmengine - INFO - Iter(train) [24650/80000]  base_lr: 7.1784e-05 lr: 7.1784e-06  eta: 6:42:10  time: 0.4364  data_time: 0.0093  memory: 5278  grad_norm: 81.1693  loss: 7.8852  decode.loss_cls: 0.1591  decode.loss_mask: 0.2732  decode.loss_dice: 0.2559  decode.d0.loss_cls: 0.8700  decode.d0.loss_mask: 0.2982  decode.d0.loss_dice: 0.3023  decode.d1.loss_cls: 0.1617  decode.d1.loss_mask: 0.2832  decode.d1.loss_dice: 0.2832  decode.d2.loss_cls: 0.1993  decode.d2.loss_mask: 0.2763  decode.d2.loss_dice: 0.2402  decode.d3.loss_cls: 0.2378  decode.d3.loss_mask: 0.2727  decode.d3.loss_dice: 0.2657  decode.d4.loss_cls: 0.1770  decode.d4.loss_mask: 0.2724  decode.d4.loss_dice: 0.2682  decode.d5.loss_cls: 0.1728  decode.d5.loss_mask: 0.2738  decode.d5.loss_dice: 0.2610  decode.d6.loss_cls: 0.1653  decode.d6.loss_mask: 0.2738  decode.d6.loss_dice: 0.2607  decode.d7.loss_cls: 0.1626  decode.d7.loss_mask: 0.2751  decode.d7.loss_dice: 0.2580  decode.d8.loss_cls: 0.1452  decode.d8.loss_mask: 0.2758  decode.d8.loss_dice: 0.2646
07/30 19:39:45 - mmengine - INFO - Iter(train) [24700/80000]  base_lr: 7.1726e-05 lr: 7.1726e-06  eta: 6:41:49  time: 0.4357  data_time: 0.0092  memory: 5244  grad_norm: 86.8190  loss: 8.5669  decode.loss_cls: 0.2404  decode.loss_mask: 0.2459  decode.loss_dice: 0.2624  decode.d0.loss_cls: 1.1434  decode.d0.loss_mask: 0.2525  decode.d0.loss_dice: 0.2629  decode.d1.loss_cls: 0.2690  decode.d1.loss_mask: 0.2473  decode.d1.loss_dice: 0.2575  decode.d2.loss_cls: 0.2757  decode.d2.loss_mask: 0.2449  decode.d2.loss_dice: 0.2676  decode.d3.loss_cls: 0.2125  decode.d3.loss_mask: 0.2518  decode.d3.loss_dice: 0.2652  decode.d4.loss_cls: 0.2796  decode.d4.loss_mask: 0.2476  decode.d4.loss_dice: 0.2616  decode.d5.loss_cls: 0.2701  decode.d5.loss_mask: 0.2488  decode.d5.loss_dice: 0.2639  decode.d6.loss_cls: 0.2986  decode.d6.loss_mask: 0.2484  decode.d6.loss_dice: 0.2620  decode.d7.loss_cls: 0.2397  decode.d7.loss_mask: 0.2494  decode.d7.loss_dice: 0.2614  decode.d8.loss_cls: 0.2260  decode.d8.loss_mask: 0.2487  decode.d8.loss_dice: 0.2621
07/30 19:40:07 - mmengine - INFO - Iter(train) [24750/80000]  base_lr: 7.1668e-05 lr: 7.1668e-06  eta: 6:41:27  time: 0.4393  data_time: 0.0094  memory: 5305  grad_norm: 53.5184  loss: 7.1746  decode.loss_cls: 0.1212  decode.loss_mask: 0.2309  decode.loss_dice: 0.2612  decode.d0.loss_cls: 1.1254  decode.d0.loss_mask: 0.2366  decode.d0.loss_dice: 0.2699  decode.d1.loss_cls: 0.1113  decode.d1.loss_mask: 0.2295  decode.d1.loss_dice: 0.2604  decode.d2.loss_cls: 0.1211  decode.d2.loss_mask: 0.2368  decode.d2.loss_dice: 0.2939  decode.d3.loss_cls: 0.1327  decode.d3.loss_mask: 0.2270  decode.d3.loss_dice: 0.2566  decode.d4.loss_cls: 0.1285  decode.d4.loss_mask: 0.2299  decode.d4.loss_dice: 0.2638  decode.d5.loss_cls: 0.1235  decode.d5.loss_mask: 0.2294  decode.d5.loss_dice: 0.2693  decode.d6.loss_cls: 0.1349  decode.d6.loss_mask: 0.2339  decode.d6.loss_dice: 0.2604  decode.d7.loss_cls: 0.1025  decode.d7.loss_mask: 0.2276  decode.d7.loss_dice: 0.2719  decode.d8.loss_cls: 0.1088  decode.d8.loss_mask: 0.2279  decode.d8.loss_dice: 0.2480
07/30 19:40:29 - mmengine - INFO - Iter(train) [24800/80000]  base_lr: 7.1609e-05 lr: 7.1609e-06  eta: 6:41:05  time: 0.4376  data_time: 0.0093  memory: 5244  grad_norm: 148.1023  loss: 8.5075  decode.loss_cls: 0.1651  decode.loss_mask: 0.2373  decode.loss_dice: 0.2925  decode.d0.loss_cls: 1.1760  decode.d0.loss_mask: 0.2489  decode.d0.loss_dice: 0.3365  decode.d1.loss_cls: 0.1648  decode.d1.loss_mask: 0.2749  decode.d1.loss_dice: 0.3293  decode.d2.loss_cls: 0.1375  decode.d2.loss_mask: 0.2682  decode.d2.loss_dice: 0.2845  decode.d3.loss_cls: 0.2654  decode.d3.loss_mask: 0.2533  decode.d3.loss_dice: 0.2791  decode.d4.loss_cls: 0.1635  decode.d4.loss_mask: 0.2499  decode.d4.loss_dice: 0.2797  decode.d5.loss_cls: 0.3147  decode.d5.loss_mask: 0.2452  decode.d5.loss_dice: 0.3045  decode.d6.loss_cls: 0.2795  decode.d6.loss_mask: 0.2468  decode.d6.loss_dice: 0.2714  decode.d7.loss_cls: 0.1952  decode.d7.loss_mask: 0.2490  decode.d7.loss_dice: 0.2773  decode.d8.loss_cls: 0.1876  decode.d8.loss_mask: 0.2474  decode.d8.loss_dice: 0.2824
07/30 19:40:51 - mmengine - INFO - Iter(train) [24850/80000]  base_lr: 7.1551e-05 lr: 7.1551e-06  eta: 6:40:44  time: 0.4382  data_time: 0.0092  memory: 5265  grad_norm: 106.1745  loss: 9.0638  decode.loss_cls: 0.2209  decode.loss_mask: 0.3039  decode.loss_dice: 0.3050  decode.d0.loss_cls: 0.8779  decode.d0.loss_mask: 0.3200  decode.d0.loss_dice: 0.3425  decode.d1.loss_cls: 0.1558  decode.d1.loss_mask: 0.3203  decode.d1.loss_dice: 0.3046  decode.d2.loss_cls: 0.1592  decode.d2.loss_mask: 0.3282  decode.d2.loss_dice: 0.3378  decode.d3.loss_cls: 0.1956  decode.d3.loss_mask: 0.3192  decode.d3.loss_dice: 0.3360  decode.d4.loss_cls: 0.2012  decode.d4.loss_mask: 0.3173  decode.d4.loss_dice: 0.3434  decode.d5.loss_cls: 0.2232  decode.d5.loss_mask: 0.3162  decode.d5.loss_dice: 0.3100  decode.d6.loss_cls: 0.2295  decode.d6.loss_mask: 0.3188  decode.d6.loss_dice: 0.3323  decode.d7.loss_cls: 0.1792  decode.d7.loss_mask: 0.3142  decode.d7.loss_dice: 0.3301  decode.d8.loss_cls: 0.1968  decode.d8.loss_mask: 0.3081  decode.d8.loss_dice: 0.3163
07/30 19:41:13 - mmengine - INFO - Iter(train) [24900/80000]  base_lr: 7.1492e-05 lr: 7.1492e-06  eta: 6:40:22  time: 0.4381  data_time: 0.0093  memory: 5229  grad_norm: 59.5870  loss: 7.8883  decode.loss_cls: 0.0689  decode.loss_mask: 0.3360  decode.loss_dice: 0.2889  decode.d0.loss_cls: 0.9823  decode.d0.loss_mask: 0.2669  decode.d0.loss_dice: 0.2624  decode.d1.loss_cls: 0.2198  decode.d1.loss_mask: 0.2687  decode.d1.loss_dice: 0.2616  decode.d2.loss_cls: 0.2456  decode.d2.loss_mask: 0.2689  decode.d2.loss_dice: 0.2631  decode.d3.loss_cls: 0.1423  decode.d3.loss_mask: 0.2855  decode.d3.loss_dice: 0.2743  decode.d4.loss_cls: 0.1000  decode.d4.loss_mask: 0.3001  decode.d4.loss_dice: 0.2834  decode.d5.loss_cls: 0.0917  decode.d5.loss_mask: 0.3033  decode.d5.loss_dice: 0.2767  decode.d6.loss_cls: 0.0723  decode.d6.loss_mask: 0.3380  decode.d6.loss_dice: 0.2802  decode.d7.loss_cls: 0.0754  decode.d7.loss_mask: 0.3462  decode.d7.loss_dice: 0.2819  decode.d8.loss_cls: 0.0775  decode.d8.loss_mask: 0.3394  decode.d8.loss_dice: 0.2872
07/30 19:41:35 - mmengine - INFO - Iter(train) [24950/80000]  base_lr: 7.1434e-05 lr: 7.1434e-06  eta: 6:40:01  time: 0.4384  data_time: 0.0094  memory: 5246  grad_norm: 64.3124  loss: 5.9247  decode.loss_cls: 0.0617  decode.loss_mask: 0.1851  decode.loss_dice: 0.2402  decode.d0.loss_cls: 0.8782  decode.d0.loss_mask: 0.1891  decode.d0.loss_dice: 0.2434  decode.d1.loss_cls: 0.1331  decode.d1.loss_mask: 0.1866  decode.d1.loss_dice: 0.2466  decode.d2.loss_cls: 0.1139  decode.d2.loss_mask: 0.1846  decode.d2.loss_dice: 0.2343  decode.d3.loss_cls: 0.0732  decode.d3.loss_mask: 0.1875  decode.d3.loss_dice: 0.2408  decode.d4.loss_cls: 0.0617  decode.d4.loss_mask: 0.1868  decode.d4.loss_dice: 0.2432  decode.d5.loss_cls: 0.0630  decode.d5.loss_mask: 0.1853  decode.d5.loss_dice: 0.2402  decode.d6.loss_cls: 0.0827  decode.d6.loss_mask: 0.1868  decode.d6.loss_dice: 0.2458  decode.d7.loss_cls: 0.0993  decode.d7.loss_mask: 0.1869  decode.d7.loss_dice: 0.2366  decode.d8.loss_cls: 0.0719  decode.d8.loss_mask: 0.1877  decode.d8.loss_dice: 0.2485
07/30 19:41:57 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 19:41:57 - mmengine - INFO - Iter(train) [25000/80000]  base_lr: 7.1376e-05 lr: 7.1376e-06  eta: 6:39:39  time: 0.4563  data_time: 0.0092  memory: 5244  grad_norm: 94.5738  loss: 6.7717  decode.loss_cls: 0.1470  decode.loss_mask: 0.2089  decode.loss_dice: 0.2293  decode.d0.loss_cls: 1.0154  decode.d0.loss_mask: 0.2234  decode.d0.loss_dice: 0.2350  decode.d1.loss_cls: 0.1649  decode.d1.loss_mask: 0.2152  decode.d1.loss_dice: 0.2274  decode.d2.loss_cls: 0.1603  decode.d2.loss_mask: 0.2161  decode.d2.loss_dice: 0.2334  decode.d3.loss_cls: 0.1306  decode.d3.loss_mask: 0.2125  decode.d3.loss_dice: 0.2346  decode.d4.loss_cls: 0.1259  decode.d4.loss_mask: 0.2100  decode.d4.loss_dice: 0.2286  decode.d5.loss_cls: 0.1481  decode.d5.loss_mask: 0.2104  decode.d5.loss_dice: 0.2452  decode.d6.loss_cls: 0.1369  decode.d6.loss_mask: 0.2118  decode.d6.loss_dice: 0.2338  decode.d7.loss_cls: 0.1472  decode.d7.loss_mask: 0.2141  decode.d7.loss_dice: 0.2324  decode.d8.loss_cls: 0.1319  decode.d8.loss_mask: 0.2136  decode.d8.loss_dice: 0.2277
07/30 19:41:57 - mmengine - INFO - Saving checkpoint at 25000 iterations
07/30 19:42:21 - mmengine - INFO - Iter(train) [25050/80000]  base_lr: 7.1317e-05 lr: 7.1317e-06  eta: 6:39:22  time: 0.4375  data_time: 0.0093  memory: 5245  grad_norm: 132.2681  loss: 8.3722  decode.loss_cls: 0.1424  decode.loss_mask: 0.3026  decode.loss_dice: 0.2772  decode.d0.loss_cls: 1.0741  decode.d0.loss_mask: 0.3221  decode.d0.loss_dice: 0.3122  decode.d1.loss_cls: 0.2042  decode.d1.loss_mask: 0.3061  decode.d1.loss_dice: 0.2774  decode.d2.loss_cls: 0.1767  decode.d2.loss_mask: 0.3093  decode.d2.loss_dice: 0.2727  decode.d3.loss_cls: 0.1400  decode.d3.loss_mask: 0.3067  decode.d3.loss_dice: 0.2796  decode.d4.loss_cls: 0.1343  decode.d4.loss_mask: 0.3134  decode.d4.loss_dice: 0.2773  decode.d5.loss_cls: 0.1308  decode.d5.loss_mask: 0.3040  decode.d5.loss_dice: 0.2936  decode.d6.loss_cls: 0.2062  decode.d6.loss_mask: 0.3016  decode.d6.loss_dice: 0.2793  decode.d7.loss_cls: 0.1671  decode.d7.loss_mask: 0.2980  decode.d7.loss_dice: 0.2823  decode.d8.loss_cls: 0.0955  decode.d8.loss_mask: 0.3082  decode.d8.loss_dice: 0.2772
07/30 19:42:43 - mmengine - INFO - Iter(train) [25100/80000]  base_lr: 7.1259e-05 lr: 7.1259e-06  eta: 6:39:01  time: 0.4380  data_time: 0.0093  memory: 5261  grad_norm: 80.3567  loss: 8.5653  decode.loss_cls: 0.2089  decode.loss_mask: 0.2677  decode.loss_dice: 0.2693  decode.d0.loss_cls: 1.1962  decode.d0.loss_mask: 0.2778  decode.d0.loss_dice: 0.2767  decode.d1.loss_cls: 0.2646  decode.d1.loss_mask: 0.2726  decode.d1.loss_dice: 0.2762  decode.d2.loss_cls: 0.2266  decode.d2.loss_mask: 0.2680  decode.d2.loss_dice: 0.2649  decode.d3.loss_cls: 0.2013  decode.d3.loss_mask: 0.2670  decode.d3.loss_dice: 0.2691  decode.d4.loss_cls: 0.2320  decode.d4.loss_mask: 0.2709  decode.d4.loss_dice: 0.2668  decode.d5.loss_cls: 0.1977  decode.d5.loss_mask: 0.2669  decode.d5.loss_dice: 0.2627  decode.d6.loss_cls: 0.2259  decode.d6.loss_mask: 0.2716  decode.d6.loss_dice: 0.2615  decode.d7.loss_cls: 0.2096  decode.d7.loss_mask: 0.2699  decode.d7.loss_dice: 0.2636  decode.d8.loss_cls: 0.2343  decode.d8.loss_mask: 0.2693  decode.d8.loss_dice: 0.2556
07/30 19:43:05 - mmengine - INFO - Iter(train) [25150/80000]  base_lr: 7.1200e-05 lr: 7.1200e-06  eta: 6:38:39  time: 0.4383  data_time: 0.0094  memory: 5277  grad_norm: 96.3146  loss: 8.5523  decode.loss_cls: 0.1837  decode.loss_mask: 0.2830  decode.loss_dice: 0.2691  decode.d0.loss_cls: 0.9186  decode.d0.loss_mask: 0.2976  decode.d0.loss_dice: 0.3148  decode.d1.loss_cls: 0.2490  decode.d1.loss_mask: 0.2834  decode.d1.loss_dice: 0.2770  decode.d2.loss_cls: 0.2499  decode.d2.loss_mask: 0.2763  decode.d2.loss_dice: 0.2862  decode.d3.loss_cls: 0.2448  decode.d3.loss_mask: 0.2781  decode.d3.loss_dice: 0.2706  decode.d4.loss_cls: 0.2150  decode.d4.loss_mask: 0.2739  decode.d4.loss_dice: 0.2754  decode.d5.loss_cls: 0.2981  decode.d5.loss_mask: 0.2684  decode.d5.loss_dice: 0.2795  decode.d6.loss_cls: 0.1749  decode.d6.loss_mask: 0.2825  decode.d6.loss_dice: 0.2708  decode.d7.loss_cls: 0.2466  decode.d7.loss_mask: 0.2706  decode.d7.loss_dice: 0.2813  decode.d8.loss_cls: 0.1738  decode.d8.loss_mask: 0.2920  decode.d8.loss_dice: 0.2674
07/30 19:43:27 - mmengine - INFO - Iter(train) [25200/80000]  base_lr: 7.1142e-05 lr: 7.1142e-06  eta: 6:38:17  time: 0.4388  data_time: 0.0093  memory: 5279  grad_norm: 109.6437  loss: 9.3327  decode.loss_cls: 0.2199  decode.loss_mask: 0.2700  decode.loss_dice: 0.3700  decode.d0.loss_cls: 0.9777  decode.d0.loss_mask: 0.2844  decode.d0.loss_dice: 0.4192  decode.d1.loss_cls: 0.2466  decode.d1.loss_mask: 0.2758  decode.d1.loss_dice: 0.3457  decode.d2.loss_cls: 0.1926  decode.d2.loss_mask: 0.2718  decode.d2.loss_dice: 0.3626  decode.d3.loss_cls: 0.2870  decode.d3.loss_mask: 0.2687  decode.d3.loss_dice: 0.3635  decode.d4.loss_cls: 0.2746  decode.d4.loss_mask: 0.2701  decode.d4.loss_dice: 0.3571  decode.d5.loss_cls: 0.2039  decode.d5.loss_mask: 0.2707  decode.d5.loss_dice: 0.3523  decode.d6.loss_cls: 0.2202  decode.d6.loss_mask: 0.2636  decode.d6.loss_dice: 0.3732  decode.d7.loss_cls: 0.1686  decode.d7.loss_mask: 0.2702  decode.d7.loss_dice: 0.3432  decode.d8.loss_cls: 0.2056  decode.d8.loss_mask: 0.2687  decode.d8.loss_dice: 0.3353
07/30 19:43:49 - mmengine - INFO - Iter(train) [25250/80000]  base_lr: 7.1084e-05 lr: 7.1084e-06  eta: 6:37:56  time: 0.4389  data_time: 0.0092  memory: 5279  grad_norm: 103.1460  loss: 9.0558  decode.loss_cls: 0.2959  decode.loss_mask: 0.1800  decode.loss_dice: 0.3621  decode.d0.loss_cls: 1.1053  decode.d0.loss_mask: 0.1851  decode.d0.loss_dice: 0.3345  decode.d1.loss_cls: 0.3215  decode.d1.loss_mask: 0.1804  decode.d1.loss_dice: 0.3342  decode.d2.loss_cls: 0.2965  decode.d2.loss_mask: 0.1804  decode.d2.loss_dice: 0.3182  decode.d3.loss_cls: 0.2907  decode.d3.loss_mask: 0.1795  decode.d3.loss_dice: 0.3251  decode.d4.loss_cls: 0.3398  decode.d4.loss_mask: 0.1804  decode.d4.loss_dice: 0.3287  decode.d5.loss_cls: 0.3551  decode.d5.loss_mask: 0.1775  decode.d5.loss_dice: 0.3312  decode.d6.loss_cls: 0.3118  decode.d6.loss_mask: 0.1766  decode.d6.loss_dice: 0.3072  decode.d7.loss_cls: 0.2882  decode.d7.loss_mask: 0.1792  decode.d7.loss_dice: 0.3482  decode.d8.loss_cls: 0.3227  decode.d8.loss_mask: 0.1799  decode.d8.loss_dice: 0.3399
07/30 19:44:10 - mmengine - INFO - Iter(train) [25300/80000]  base_lr: 7.1025e-05 lr: 7.1025e-06  eta: 6:37:34  time: 0.4381  data_time: 0.0091  memory: 5245  grad_norm: 126.6411  loss: 7.1539  decode.loss_cls: 0.1948  decode.loss_mask: 0.1992  decode.loss_dice: 0.2475  decode.d0.loss_cls: 0.8500  decode.d0.loss_mask: 0.2023  decode.d0.loss_dice: 0.2653  decode.d1.loss_cls: 0.1984  decode.d1.loss_mask: 0.2023  decode.d1.loss_dice: 0.2599  decode.d2.loss_cls: 0.1975  decode.d2.loss_mask: 0.2030  decode.d2.loss_dice: 0.2540  decode.d3.loss_cls: 0.2152  decode.d3.loss_mask: 0.2009  decode.d3.loss_dice: 0.2509  decode.d4.loss_cls: 0.1976  decode.d4.loss_mask: 0.1985  decode.d4.loss_dice: 0.2577  decode.d5.loss_cls: 0.1752  decode.d5.loss_mask: 0.1976  decode.d5.loss_dice: 0.2366  decode.d6.loss_cls: 0.1776  decode.d6.loss_mask: 0.1959  decode.d6.loss_dice: 0.2342  decode.d7.loss_cls: 0.2154  decode.d7.loss_mask: 0.1996  decode.d7.loss_dice: 0.2614  decode.d8.loss_cls: 0.2041  decode.d8.loss_mask: 0.1994  decode.d8.loss_dice: 0.2619
07/30 19:44:32 - mmengine - INFO - Iter(train) [25350/80000]  base_lr: 7.0967e-05 lr: 7.0967e-06  eta: 6:37:13  time: 0.4373  data_time: 0.0093  memory: 5303  grad_norm: 119.0631  loss: 7.9274  decode.loss_cls: 0.1279  decode.loss_mask: 0.3079  decode.loss_dice: 0.2685  decode.d0.loss_cls: 0.9565  decode.d0.loss_mask: 0.3091  decode.d0.loss_dice: 0.2825  decode.d1.loss_cls: 0.1571  decode.d1.loss_mask: 0.2949  decode.d1.loss_dice: 0.2558  decode.d2.loss_cls: 0.1388  decode.d2.loss_mask: 0.2995  decode.d2.loss_dice: 0.2613  decode.d3.loss_cls: 0.1176  decode.d3.loss_mask: 0.2952  decode.d3.loss_dice: 0.2581  decode.d4.loss_cls: 0.1312  decode.d4.loss_mask: 0.3035  decode.d4.loss_dice: 0.2689  decode.d5.loss_cls: 0.1220  decode.d5.loss_mask: 0.2953  decode.d5.loss_dice: 0.2540  decode.d6.loss_cls: 0.1839  decode.d6.loss_mask: 0.3003  decode.d6.loss_dice: 0.2776  decode.d7.loss_cls: 0.2152  decode.d7.loss_mask: 0.2957  decode.d7.loss_dice: 0.2553  decode.d8.loss_cls: 0.1160  decode.d8.loss_mask: 0.3041  decode.d8.loss_dice: 0.2738
07/30 19:44:54 - mmengine - INFO - Iter(train) [25400/80000]  base_lr: 7.0908e-05 lr: 7.0908e-06  eta: 6:36:51  time: 0.4381  data_time: 0.0092  memory: 5265  grad_norm: 42.5377  loss: 7.6800  decode.loss_cls: 0.1864  decode.loss_mask: 0.2013  decode.loss_dice: 0.2914  decode.d0.loss_cls: 0.9437  decode.d0.loss_mask: 0.1915  decode.d0.loss_dice: 0.2953  decode.d1.loss_cls: 0.1992  decode.d1.loss_mask: 0.1945  decode.d1.loss_dice: 0.2780  decode.d2.loss_cls: 0.2005  decode.d2.loss_mask: 0.1968  decode.d2.loss_dice: 0.2930  decode.d3.loss_cls: 0.2241  decode.d3.loss_mask: 0.2149  decode.d3.loss_dice: 0.2954  decode.d4.loss_cls: 0.1842  decode.d4.loss_mask: 0.2021  decode.d4.loss_dice: 0.3012  decode.d5.loss_cls: 0.2146  decode.d5.loss_mask: 0.2096  decode.d5.loss_dice: 0.2753  decode.d6.loss_cls: 0.2157  decode.d6.loss_mask: 0.2083  decode.d6.loss_dice: 0.2819  decode.d7.loss_cls: 0.1942  decode.d7.loss_mask: 0.1991  decode.d7.loss_dice: 0.3095  decode.d8.loss_cls: 0.2118  decode.d8.loss_mask: 0.1981  decode.d8.loss_dice: 0.2686
07/30 19:45:16 - mmengine - INFO - Iter(train) [25450/80000]  base_lr: 7.0850e-05 lr: 7.0850e-06  eta: 6:36:29  time: 0.4362  data_time: 0.0093  memory: 5265  grad_norm: 103.5637  loss: 8.8903  decode.loss_cls: 0.3255  decode.loss_mask: 0.2130  decode.loss_dice: 0.2449  decode.d0.loss_cls: 1.1017  decode.d0.loss_mask: 0.2153  decode.d0.loss_dice: 0.2521  decode.d1.loss_cls: 0.4031  decode.d1.loss_mask: 0.2100  decode.d1.loss_dice: 0.2530  decode.d2.loss_cls: 0.3654  decode.d2.loss_mask: 0.2116  decode.d2.loss_dice: 0.2528  decode.d3.loss_cls: 0.3652  decode.d3.loss_mask: 0.2140  decode.d3.loss_dice: 0.2408  decode.d4.loss_cls: 0.3358  decode.d4.loss_mask: 0.2126  decode.d4.loss_dice: 0.2458  decode.d5.loss_cls: 0.3373  decode.d5.loss_mask: 0.2157  decode.d5.loss_dice: 0.2434  decode.d6.loss_cls: 0.3255  decode.d6.loss_mask: 0.2136  decode.d6.loss_dice: 0.2517  decode.d7.loss_cls: 0.3513  decode.d7.loss_mask: 0.2170  decode.d7.loss_dice: 0.2427  decode.d8.loss_cls: 0.3722  decode.d8.loss_mask: 0.2132  decode.d8.loss_dice: 0.2441
07/30 19:45:38 - mmengine - INFO - Iter(train) [25500/80000]  base_lr: 7.0791e-05 lr: 7.0791e-06  eta: 6:36:08  time: 0.4368  data_time: 0.0093  memory: 5229  grad_norm: 35.6494  loss: 8.4097  decode.loss_cls: 0.0992  decode.loss_mask: 0.2693  decode.loss_dice: 0.3404  decode.d0.loss_cls: 1.0310  decode.d0.loss_mask: 0.2708  decode.d0.loss_dice: 0.3488  decode.d1.loss_cls: 0.2318  decode.d1.loss_mask: 0.2703  decode.d1.loss_dice: 0.3353  decode.d2.loss_cls: 0.1427  decode.d2.loss_mask: 0.2676  decode.d2.loss_dice: 0.3385  decode.d3.loss_cls: 0.1959  decode.d3.loss_mask: 0.2660  decode.d3.loss_dice: 0.3344  decode.d4.loss_cls: 0.1440  decode.d4.loss_mask: 0.2649  decode.d4.loss_dice: 0.3362  decode.d5.loss_cls: 0.1202  decode.d5.loss_mask: 0.2687  decode.d5.loss_dice: 0.3356  decode.d6.loss_cls: 0.1179  decode.d6.loss_mask: 0.2701  decode.d6.loss_dice: 0.3342  decode.d7.loss_cls: 0.1611  decode.d7.loss_mask: 0.2665  decode.d7.loss_dice: 0.3335  decode.d8.loss_cls: 0.1005  decode.d8.loss_mask: 0.2672  decode.d8.loss_dice: 0.3470
07/30 19:46:00 - mmengine - INFO - Iter(train) [25550/80000]  base_lr: 7.0733e-05 lr: 7.0733e-06  eta: 6:35:46  time: 0.4370  data_time: 0.0095  memory: 5279  grad_norm: 170.1258  loss: 8.6391  decode.loss_cls: 0.2273  decode.loss_mask: 0.2530  decode.loss_dice: 0.2391  decode.d0.loss_cls: 1.0309  decode.d0.loss_mask: 0.2579  decode.d0.loss_dice: 0.3102  decode.d1.loss_cls: 0.3237  decode.d1.loss_mask: 0.2470  decode.d1.loss_dice: 0.2599  decode.d2.loss_cls: 0.3511  decode.d2.loss_mask: 0.2389  decode.d2.loss_dice: 0.2348  decode.d3.loss_cls: 0.3086  decode.d3.loss_mask: 0.2422  decode.d3.loss_dice: 0.2484  decode.d4.loss_cls: 0.3119  decode.d4.loss_mask: 0.2447  decode.d4.loss_dice: 0.2527  decode.d5.loss_cls: 0.3397  decode.d5.loss_mask: 0.2605  decode.d5.loss_dice: 0.2426  decode.d6.loss_cls: 0.2698  decode.d6.loss_mask: 0.2574  decode.d6.loss_dice: 0.2594  decode.d7.loss_cls: 0.2403  decode.d7.loss_mask: 0.2522  decode.d7.loss_dice: 0.2455  decode.d8.loss_cls: 0.2015  decode.d8.loss_mask: 0.2501  decode.d8.loss_dice: 0.2376
07/30 19:46:22 - mmengine - INFO - Iter(train) [25600/80000]  base_lr: 7.0675e-05 lr: 7.0675e-06  eta: 6:35:24  time: 0.4360  data_time: 0.0094  memory: 5265  grad_norm: 73.9219  loss: 8.4106  decode.loss_cls: 0.1850  decode.loss_mask: 0.2554  decode.loss_dice: 0.3103  decode.d0.loss_cls: 0.9757  decode.d0.loss_mask: 0.2648  decode.d0.loss_dice: 0.3115  decode.d1.loss_cls: 0.2784  decode.d1.loss_mask: 0.2625  decode.d1.loss_dice: 0.3094  decode.d2.loss_cls: 0.1784  decode.d2.loss_mask: 0.2606  decode.d2.loss_dice: 0.3088  decode.d3.loss_cls: 0.2143  decode.d3.loss_mask: 0.2550  decode.d3.loss_dice: 0.3055  decode.d4.loss_cls: 0.2577  decode.d4.loss_mask: 0.2569  decode.d4.loss_dice: 0.3016  decode.d5.loss_cls: 0.1650  decode.d5.loss_mask: 0.2576  decode.d5.loss_dice: 0.2977  decode.d6.loss_cls: 0.1481  decode.d6.loss_mask: 0.2524  decode.d6.loss_dice: 0.2992  decode.d7.loss_cls: 0.2174  decode.d7.loss_mask: 0.2533  decode.d7.loss_dice: 0.3039  decode.d8.loss_cls: 0.1685  decode.d8.loss_mask: 0.2536  decode.d8.loss_dice: 0.3019
07/30 19:46:43 - mmengine - INFO - Iter(train) [25650/80000]  base_lr: 7.0616e-05 lr: 7.0616e-06  eta: 6:35:02  time: 0.4366  data_time: 0.0094  memory: 5277  grad_norm: 143.3673  loss: 9.5712  decode.loss_cls: 0.2958  decode.loss_mask: 0.2176  decode.loss_dice: 0.3329  decode.d0.loss_cls: 1.0130  decode.d0.loss_mask: 0.2187  decode.d0.loss_dice: 0.3253  decode.d1.loss_cls: 0.3852  decode.d1.loss_mask: 0.2084  decode.d1.loss_dice: 0.3399  decode.d2.loss_cls: 0.4153  decode.d2.loss_mask: 0.2132  decode.d2.loss_dice: 0.3251  decode.d3.loss_cls: 0.3107  decode.d3.loss_mask: 0.2121  decode.d3.loss_dice: 0.3195  decode.d4.loss_cls: 0.2928  decode.d4.loss_mask: 0.2152  decode.d4.loss_dice: 0.3538  decode.d5.loss_cls: 0.3363  decode.d5.loss_mask: 0.2160  decode.d5.loss_dice: 0.3599  decode.d6.loss_cls: 0.4066  decode.d6.loss_mask: 0.2095  decode.d6.loss_dice: 0.3372  decode.d7.loss_cls: 0.3040  decode.d7.loss_mask: 0.2111  decode.d7.loss_dice: 0.3328  decode.d8.loss_cls: 0.3046  decode.d8.loss_mask: 0.2120  decode.d8.loss_dice: 0.3468
07/30 19:47:05 - mmengine - INFO - Iter(train) [25700/80000]  base_lr: 7.0558e-05 lr: 7.0558e-06  eta: 6:34:41  time: 0.4362  data_time: 0.0095  memory: 5265  grad_norm: 261.8670  loss: 8.7086  decode.loss_cls: 0.1565  decode.loss_mask: 0.3190  decode.loss_dice: 0.2886  decode.d0.loss_cls: 0.8763  decode.d0.loss_mask: 0.3391  decode.d0.loss_dice: 0.3058  decode.d1.loss_cls: 0.2322  decode.d1.loss_mask: 0.3220  decode.d1.loss_dice: 0.2965  decode.d2.loss_cls: 0.1545  decode.d2.loss_mask: 0.3256  decode.d2.loss_dice: 0.3355  decode.d3.loss_cls: 0.1427  decode.d3.loss_mask: 0.3241  decode.d3.loss_dice: 0.3251  decode.d4.loss_cls: 0.1945  decode.d4.loss_mask: 0.3218  decode.d4.loss_dice: 0.2985  decode.d5.loss_cls: 0.1839  decode.d5.loss_mask: 0.3206  decode.d5.loss_dice: 0.3320  decode.d6.loss_cls: 0.1529  decode.d6.loss_mask: 0.3202  decode.d6.loss_dice: 0.2931  decode.d7.loss_cls: 0.1382  decode.d7.loss_mask: 0.3233  decode.d7.loss_dice: 0.2924  decode.d8.loss_cls: 0.1277  decode.d8.loss_mask: 0.3252  decode.d8.loss_dice: 0.3410
07/30 19:47:27 - mmengine - INFO - Iter(train) [25750/80000]  base_lr: 7.0499e-05 lr: 7.0499e-06  eta: 6:34:19  time: 0.4365  data_time: 0.0094  memory: 5279  grad_norm: 68.3365  loss: 7.4583  decode.loss_cls: 0.1343  decode.loss_mask: 0.2070  decode.loss_dice: 0.2564  decode.d0.loss_cls: 1.0950  decode.d0.loss_mask: 0.2188  decode.d0.loss_dice: 0.2768  decode.d1.loss_cls: 0.2537  decode.d1.loss_mask: 0.2117  decode.d1.loss_dice: 0.2530  decode.d2.loss_cls: 0.2386  decode.d2.loss_mask: 0.2109  decode.d2.loss_dice: 0.2589  decode.d3.loss_cls: 0.2827  decode.d3.loss_mask: 0.2095  decode.d3.loss_dice: 0.2559  decode.d4.loss_cls: 0.1600  decode.d4.loss_mask: 0.2101  decode.d4.loss_dice: 0.2530  decode.d5.loss_cls: 0.1789  decode.d5.loss_mask: 0.2075  decode.d5.loss_dice: 0.2619  decode.d6.loss_cls: 0.1238  decode.d6.loss_mask: 0.2106  decode.d6.loss_dice: 0.2580  decode.d7.loss_cls: 0.1888  decode.d7.loss_mask: 0.2055  decode.d7.loss_dice: 0.2619  decode.d8.loss_cls: 0.1111  decode.d8.loss_mask: 0.2088  decode.d8.loss_dice: 0.2552
07/30 19:47:49 - mmengine - INFO - Iter(train) [25800/80000]  base_lr: 7.0441e-05 lr: 7.0441e-06  eta: 6:33:57  time: 0.4355  data_time: 0.0094  memory: 5227  grad_norm: 139.2104  loss: 8.5161  decode.loss_cls: 0.1864  decode.loss_mask: 0.2733  decode.loss_dice: 0.2778  decode.d0.loss_cls: 1.1307  decode.d0.loss_mask: 0.2800  decode.d0.loss_dice: 0.3194  decode.d1.loss_cls: 0.2222  decode.d1.loss_mask: 0.2891  decode.d1.loss_dice: 0.2815  decode.d2.loss_cls: 0.1854  decode.d2.loss_mask: 0.2872  decode.d2.loss_dice: 0.2804  decode.d3.loss_cls: 0.2011  decode.d3.loss_mask: 0.2786  decode.d3.loss_dice: 0.2771  decode.d4.loss_cls: 0.1971  decode.d4.loss_mask: 0.2819  decode.d4.loss_dice: 0.2957  decode.d5.loss_cls: 0.1614  decode.d5.loss_mask: 0.2755  decode.d5.loss_dice: 0.2724  decode.d6.loss_cls: 0.1327  decode.d6.loss_mask: 0.2908  decode.d6.loss_dice: 0.2847  decode.d7.loss_cls: 0.2162  decode.d7.loss_mask: 0.2871  decode.d7.loss_dice: 0.2906  decode.d8.loss_cls: 0.1941  decode.d8.loss_mask: 0.2676  decode.d8.loss_dice: 0.2980
07/30 19:48:11 - mmengine - INFO - Iter(train) [25850/80000]  base_lr: 7.0382e-05 lr: 7.0382e-06  eta: 6:33:35  time: 0.4358  data_time: 0.0094  memory: 5303  grad_norm: 65.5131  loss: 9.4953  decode.loss_cls: 0.2892  decode.loss_mask: 0.2491  decode.loss_dice: 0.2967  decode.d0.loss_cls: 1.0890  decode.d0.loss_mask: 0.2518  decode.d0.loss_dice: 0.3296  decode.d1.loss_cls: 0.3708  decode.d1.loss_mask: 0.2454  decode.d1.loss_dice: 0.2882  decode.d2.loss_cls: 0.3587  decode.d2.loss_mask: 0.2498  decode.d2.loss_dice: 0.3116  decode.d3.loss_cls: 0.3198  decode.d3.loss_mask: 0.2668  decode.d3.loss_dice: 0.2922  decode.d4.loss_cls: 0.3233  decode.d4.loss_mask: 0.2474  decode.d4.loss_dice: 0.3048  decode.d5.loss_cls: 0.3372  decode.d5.loss_mask: 0.2384  decode.d5.loss_dice: 0.2844  decode.d6.loss_cls: 0.3000  decode.d6.loss_mask: 0.2422  decode.d6.loss_dice: 0.2858  decode.d7.loss_cls: 0.3303  decode.d7.loss_mask: 0.2416  decode.d7.loss_dice: 0.2915  decode.d8.loss_cls: 0.3018  decode.d8.loss_mask: 0.2531  decode.d8.loss_dice: 0.3046
07/30 19:48:33 - mmengine - INFO - Iter(train) [25900/80000]  base_lr: 7.0324e-05 lr: 7.0324e-06  eta: 6:33:13  time: 0.4368  data_time: 0.0093  memory: 5244  grad_norm: 53.6144  loss: 6.2388  decode.loss_cls: 0.0782  decode.loss_mask: 0.2160  decode.loss_dice: 0.2408  decode.d0.loss_cls: 0.8579  decode.d0.loss_mask: 0.2215  decode.d0.loss_dice: 0.2428  decode.d1.loss_cls: 0.1206  decode.d1.loss_mask: 0.2128  decode.d1.loss_dice: 0.2382  decode.d2.loss_cls: 0.1278  decode.d2.loss_mask: 0.2153  decode.d2.loss_dice: 0.2399  decode.d3.loss_cls: 0.0799  decode.d3.loss_mask: 0.2166  decode.d3.loss_dice: 0.2397  decode.d4.loss_cls: 0.0938  decode.d4.loss_mask: 0.2168  decode.d4.loss_dice: 0.2447  decode.d5.loss_cls: 0.0631  decode.d5.loss_mask: 0.2173  decode.d5.loss_dice: 0.2408  decode.d6.loss_cls: 0.0713  decode.d6.loss_mask: 0.2136  decode.d6.loss_dice: 0.2390  decode.d7.loss_cls: 0.0847  decode.d7.loss_mask: 0.2143  decode.d7.loss_dice: 0.2423  decode.d8.loss_cls: 0.0935  decode.d8.loss_mask: 0.2135  decode.d8.loss_dice: 0.2422
07/30 19:48:54 - mmengine - INFO - Iter(train) [25950/80000]  base_lr: 7.0265e-05 lr: 7.0265e-06  eta: 6:32:52  time: 0.4356  data_time: 0.0093  memory: 5261  grad_norm: 84.1309  loss: 7.7787  decode.loss_cls: 0.2184  decode.loss_mask: 0.2271  decode.loss_dice: 0.3051  decode.d0.loss_cls: 0.9705  decode.d0.loss_mask: 0.2309  decode.d0.loss_dice: 0.3221  decode.d1.loss_cls: 0.1051  decode.d1.loss_mask: 0.2296  decode.d1.loss_dice: 0.3409  decode.d2.loss_cls: 0.1127  decode.d2.loss_mask: 0.2305  decode.d2.loss_dice: 0.3168  decode.d3.loss_cls: 0.0865  decode.d3.loss_mask: 0.2312  decode.d3.loss_dice: 0.3462  decode.d4.loss_cls: 0.1541  decode.d4.loss_mask: 0.2252  decode.d4.loss_dice: 0.3385  decode.d5.loss_cls: 0.1485  decode.d5.loss_mask: 0.2276  decode.d5.loss_dice: 0.3273  decode.d6.loss_cls: 0.1538  decode.d6.loss_mask: 0.2249  decode.d6.loss_dice: 0.3013  decode.d7.loss_cls: 0.1326  decode.d7.loss_mask: 0.2254  decode.d7.loss_dice: 0.3153  decode.d8.loss_cls: 0.1949  decode.d8.loss_mask: 0.2255  decode.d8.loss_dice: 0.3100
07/30 19:49:16 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 19:49:16 - mmengine - INFO - Iter(train) [26000/80000]  base_lr: 7.0207e-05 lr: 7.0207e-06  eta: 6:32:30  time: 0.4351  data_time: 0.0094  memory: 5277  grad_norm: 133.6730  loss: 9.2771  decode.loss_cls: 0.3201  decode.loss_mask: 0.2868  decode.loss_dice: 0.3245  decode.d0.loss_cls: 1.0246  decode.d0.loss_mask: 0.2657  decode.d0.loss_dice: 0.3470  decode.d1.loss_cls: 0.2587  decode.d1.loss_mask: 0.2649  decode.d1.loss_dice: 0.3385  decode.d2.loss_cls: 0.1719  decode.d2.loss_mask: 0.2751  decode.d2.loss_dice: 0.3450  decode.d3.loss_cls: 0.2062  decode.d3.loss_mask: 0.2745  decode.d3.loss_dice: 0.3513  decode.d4.loss_cls: 0.1959  decode.d4.loss_mask: 0.2717  decode.d4.loss_dice: 0.3489  decode.d5.loss_cls: 0.2225  decode.d5.loss_mask: 0.2869  decode.d5.loss_dice: 0.3562  decode.d6.loss_cls: 0.2017  decode.d6.loss_mask: 0.2810  decode.d6.loss_dice: 0.3310  decode.d7.loss_cls: 0.2196  decode.d7.loss_mask: 0.2736  decode.d7.loss_dice: 0.3204  decode.d8.loss_cls: 0.3089  decode.d8.loss_mask: 0.2853  decode.d8.loss_dice: 0.3190
07/30 19:49:38 - mmengine - INFO - Iter(train) [26050/80000]  base_lr: 7.0148e-05 lr: 7.0148e-06  eta: 6:32:08  time: 0.4355  data_time: 0.0095  memory: 5245  grad_norm: 59.7987  loss: 10.0483  decode.loss_cls: 0.3243  decode.loss_mask: 0.2626  decode.loss_dice: 0.3487  decode.d0.loss_cls: 1.1088  decode.d0.loss_mask: 0.2689  decode.d0.loss_dice: 0.3612  decode.d1.loss_cls: 0.3838  decode.d1.loss_mask: 0.2659  decode.d1.loss_dice: 0.3400  decode.d2.loss_cls: 0.3165  decode.d2.loss_mask: 0.2651  decode.d2.loss_dice: 0.3354  decode.d3.loss_cls: 0.3555  decode.d3.loss_mask: 0.2625  decode.d3.loss_dice: 0.3242  decode.d4.loss_cls: 0.2565  decode.d4.loss_mask: 0.2699  decode.d4.loss_dice: 0.3757  decode.d5.loss_cls: 0.2722  decode.d5.loss_mask: 0.2671  decode.d5.loss_dice: 0.3285  decode.d6.loss_cls: 0.2693  decode.d6.loss_mask: 0.2759  decode.d6.loss_dice: 0.3487  decode.d7.loss_cls: 0.3324  decode.d7.loss_mask: 0.2694  decode.d7.loss_dice: 0.3364  decode.d8.loss_cls: 0.3343  decode.d8.loss_mask: 0.2629  decode.d8.loss_dice: 0.3255
07/30 19:50:00 - mmengine - INFO - Iter(train) [26100/80000]  base_lr: 7.0090e-05 lr: 7.0090e-06  eta: 6:31:46  time: 0.4365  data_time: 0.0094  memory: 5229  grad_norm: 110.3928  loss: 7.0239  decode.loss_cls: 0.1887  decode.loss_mask: 0.2395  decode.loss_dice: 0.2490  decode.d0.loss_cls: 0.8867  decode.d0.loss_mask: 0.2494  decode.d0.loss_dice: 0.2627  decode.d1.loss_cls: 0.1186  decode.d1.loss_mask: 0.2379  decode.d1.loss_dice: 0.2533  decode.d2.loss_cls: 0.0854  decode.d2.loss_mask: 0.2416  decode.d2.loss_dice: 0.2556  decode.d3.loss_cls: 0.1388  decode.d3.loss_mask: 0.2416  decode.d3.loss_dice: 0.2426  decode.d4.loss_cls: 0.1433  decode.d4.loss_mask: 0.2386  decode.d4.loss_dice: 0.2446  decode.d5.loss_cls: 0.1553  decode.d5.loss_mask: 0.2387  decode.d5.loss_dice: 0.2397  decode.d6.loss_cls: 0.1383  decode.d6.loss_mask: 0.2394  decode.d6.loss_dice: 0.2367  decode.d7.loss_cls: 0.1374  decode.d7.loss_mask: 0.2387  decode.d7.loss_dice: 0.2429  decode.d8.loss_cls: 0.1508  decode.d8.loss_mask: 0.2379  decode.d8.loss_dice: 0.2501
07/30 19:50:22 - mmengine - INFO - Iter(train) [26150/80000]  base_lr: 7.0031e-05 lr: 7.0031e-06  eta: 6:31:24  time: 0.4361  data_time: 0.0095  memory: 5244  grad_norm: 65.6308  loss: 8.2519  decode.loss_cls: 0.1932  decode.loss_mask: 0.2286  decode.loss_dice: 0.2970  decode.d0.loss_cls: 0.9356  decode.d0.loss_mask: 0.2325  decode.d0.loss_dice: 0.3068  decode.d1.loss_cls: 0.2665  decode.d1.loss_mask: 0.2342  decode.d1.loss_dice: 0.2956  decode.d2.loss_cls: 0.2602  decode.d2.loss_mask: 0.2316  decode.d2.loss_dice: 0.2631  decode.d3.loss_cls: 0.2453  decode.d3.loss_mask: 0.2262  decode.d3.loss_dice: 0.2830  decode.d4.loss_cls: 0.2045  decode.d4.loss_mask: 0.2259  decode.d4.loss_dice: 0.2691  decode.d5.loss_cls: 0.2031  decode.d5.loss_mask: 0.2290  decode.d5.loss_dice: 0.2974  decode.d6.loss_cls: 0.2797  decode.d6.loss_mask: 0.2253  decode.d6.loss_dice: 0.3148  decode.d7.loss_cls: 0.2266  decode.d7.loss_mask: 0.2275  decode.d7.loss_dice: 0.3075  decode.d8.loss_cls: 0.2111  decode.d8.loss_mask: 0.2299  decode.d8.loss_dice: 0.3008
07/30 19:50:44 - mmengine - INFO - Iter(train) [26200/80000]  base_lr: 6.9973e-05 lr: 6.9973e-06  eta: 6:31:03  time: 0.4358  data_time: 0.0097  memory: 5227  grad_norm: 76.1215  loss: 9.4407  decode.loss_cls: 0.2913  decode.loss_mask: 0.3480  decode.loss_dice: 0.3115  decode.d0.loss_cls: 0.8665  decode.d0.loss_mask: 0.3572  decode.d0.loss_dice: 0.3305  decode.d1.loss_cls: 0.2665  decode.d1.loss_mask: 0.3464  decode.d1.loss_dice: 0.3242  decode.d2.loss_cls: 0.2358  decode.d2.loss_mask: 0.3464  decode.d2.loss_dice: 0.3070  decode.d3.loss_cls: 0.2034  decode.d3.loss_mask: 0.3424  decode.d3.loss_dice: 0.3172  decode.d4.loss_cls: 0.1791  decode.d4.loss_mask: 0.3390  decode.d4.loss_dice: 0.3181  decode.d5.loss_cls: 0.1589  decode.d5.loss_mask: 0.3385  decode.d5.loss_dice: 0.3112  decode.d6.loss_cls: 0.2298  decode.d6.loss_mask: 0.3399  decode.d6.loss_dice: 0.3208  decode.d7.loss_cls: 0.1997  decode.d7.loss_mask: 0.3386  decode.d7.loss_dice: 0.3104  decode.d8.loss_cls: 0.2196  decode.d8.loss_mask: 0.3428  decode.d8.loss_dice: 0.3000
07/30 19:51:05 - mmengine - INFO - Iter(train) [26250/80000]  base_lr: 6.9914e-05 lr: 6.9914e-06  eta: 6:30:41  time: 0.4356  data_time: 0.0093  memory: 5265  grad_norm: 54.3333  loss: 6.7793  decode.loss_cls: 0.0945  decode.loss_mask: 0.2351  decode.loss_dice: 0.2576  decode.d0.loss_cls: 0.8835  decode.d0.loss_mask: 0.2385  decode.d0.loss_dice: 0.2875  decode.d1.loss_cls: 0.1205  decode.d1.loss_mask: 0.2305  decode.d1.loss_dice: 0.2824  decode.d2.loss_cls: 0.0876  decode.d2.loss_mask: 0.2311  decode.d2.loss_dice: 0.2564  decode.d3.loss_cls: 0.0929  decode.d3.loss_mask: 0.2325  decode.d3.loss_dice: 0.2702  decode.d4.loss_cls: 0.0907  decode.d4.loss_mask: 0.2303  decode.d4.loss_dice: 0.2744  decode.d5.loss_cls: 0.0800  decode.d5.loss_mask: 0.2295  decode.d5.loss_dice: 0.2726  decode.d6.loss_cls: 0.1011  decode.d6.loss_mask: 0.2300  decode.d6.loss_dice: 0.2414  decode.d7.loss_cls: 0.1008  decode.d7.loss_mask: 0.2364  decode.d7.loss_dice: 0.2737  decode.d8.loss_cls: 0.1137  decode.d8.loss_mask: 0.2322  decode.d8.loss_dice: 0.2716
07/30 19:51:27 - mmengine - INFO - Iter(train) [26300/80000]  base_lr: 6.9856e-05 lr: 6.9856e-06  eta: 6:30:19  time: 0.4362  data_time: 0.0093  memory: 5279  grad_norm: 48.0358  loss: 7.7730  decode.loss_cls: 0.2418  decode.loss_mask: 0.2055  decode.loss_dice: 0.2847  decode.d0.loss_cls: 1.0643  decode.d0.loss_mask: 0.2023  decode.d0.loss_dice: 0.2886  decode.d1.loss_cls: 0.2204  decode.d1.loss_mask: 0.1996  decode.d1.loss_dice: 0.2726  decode.d2.loss_cls: 0.2229  decode.d2.loss_mask: 0.1993  decode.d2.loss_dice: 0.2898  decode.d3.loss_cls: 0.2005  decode.d3.loss_mask: 0.1962  decode.d3.loss_dice: 0.2830  decode.d4.loss_cls: 0.1900  decode.d4.loss_mask: 0.1984  decode.d4.loss_dice: 0.2823  decode.d5.loss_cls: 0.1882  decode.d5.loss_mask: 0.2014  decode.d5.loss_dice: 0.2786  decode.d6.loss_cls: 0.1558  decode.d6.loss_mask: 0.2027  decode.d6.loss_dice: 0.2814  decode.d7.loss_cls: 0.1896  decode.d7.loss_mask: 0.2017  decode.d7.loss_dice: 0.2798  decode.d8.loss_cls: 0.2725  decode.d8.loss_mask: 0.2016  decode.d8.loss_dice: 0.2774
07/30 19:51:49 - mmengine - INFO - Iter(train) [26350/80000]  base_lr: 6.9797e-05 lr: 6.9797e-06  eta: 6:29:57  time: 0.4366  data_time: 0.0094  memory: 5261  grad_norm: 57.6905  loss: 7.1242  decode.loss_cls: 0.0976  decode.loss_mask: 0.2510  decode.loss_dice: 0.2629  decode.d0.loss_cls: 0.9263  decode.d0.loss_mask: 0.2593  decode.d0.loss_dice: 0.2685  decode.d1.loss_cls: 0.1550  decode.d1.loss_mask: 0.2518  decode.d1.loss_dice: 0.2651  decode.d2.loss_cls: 0.1652  decode.d2.loss_mask: 0.2515  decode.d2.loss_dice: 0.2605  decode.d3.loss_cls: 0.1330  decode.d3.loss_mask: 0.2505  decode.d3.loss_dice: 0.2615  decode.d4.loss_cls: 0.1015  decode.d4.loss_mask: 0.2521  decode.d4.loss_dice: 0.2612  decode.d5.loss_cls: 0.1025  decode.d5.loss_mask: 0.2494  decode.d5.loss_dice: 0.2507  decode.d6.loss_cls: 0.0887  decode.d6.loss_mask: 0.2507  decode.d6.loss_dice: 0.2692  decode.d7.loss_cls: 0.1152  decode.d7.loss_mask: 0.2515  decode.d7.loss_dice: 0.2608  decode.d8.loss_cls: 0.0909  decode.d8.loss_mask: 0.2523  decode.d8.loss_dice: 0.2680
07/30 19:52:11 - mmengine - INFO - Iter(train) [26400/80000]  base_lr: 6.9738e-05 lr: 6.9738e-06  eta: 6:29:36  time: 0.4366  data_time: 0.0092  memory: 5229  grad_norm: 112.9147  loss: 7.2090  decode.loss_cls: 0.1962  decode.loss_mask: 0.2249  decode.loss_dice: 0.2292  decode.d0.loss_cls: 1.0440  decode.d0.loss_mask: 0.2343  decode.d0.loss_dice: 0.2723  decode.d1.loss_cls: 0.1751  decode.d1.loss_mask: 0.2260  decode.d1.loss_dice: 0.2421  decode.d2.loss_cls: 0.1788  decode.d2.loss_mask: 0.2231  decode.d2.loss_dice: 0.2422  decode.d3.loss_cls: 0.1536  decode.d3.loss_mask: 0.2190  decode.d3.loss_dice: 0.2426  decode.d4.loss_cls: 0.1447  decode.d4.loss_mask: 0.2234  decode.d4.loss_dice: 0.2402  decode.d5.loss_cls: 0.1324  decode.d5.loss_mask: 0.2238  decode.d5.loss_dice: 0.2631  decode.d6.loss_cls: 0.1511  decode.d6.loss_mask: 0.2246  decode.d6.loss_dice: 0.2448  decode.d7.loss_cls: 0.1705  decode.d7.loss_mask: 0.2234  decode.d7.loss_dice: 0.2312  decode.d8.loss_cls: 0.1648  decode.d8.loss_mask: 0.2244  decode.d8.loss_dice: 0.2431
07/30 19:52:33 - mmengine - INFO - Iter(train) [26450/80000]  base_lr: 6.9680e-05 lr: 6.9680e-06  eta: 6:29:14  time: 0.4359  data_time: 0.0094  memory: 5244  grad_norm: 52.8331  loss: 7.0576  decode.loss_cls: 0.1262  decode.loss_mask: 0.2300  decode.loss_dice: 0.2566  decode.d0.loss_cls: 0.7718  decode.d0.loss_mask: 0.2560  decode.d0.loss_dice: 0.2485  decode.d1.loss_cls: 0.1914  decode.d1.loss_mask: 0.2371  decode.d1.loss_dice: 0.2525  decode.d2.loss_cls: 0.1542  decode.d2.loss_mask: 0.2398  decode.d2.loss_dice: 0.2376  decode.d3.loss_cls: 0.1559  decode.d3.loss_mask: 0.2393  decode.d3.loss_dice: 0.2547  decode.d4.loss_cls: 0.1798  decode.d4.loss_mask: 0.2317  decode.d4.loss_dice: 0.2481  decode.d5.loss_cls: 0.1726  decode.d5.loss_mask: 0.2345  decode.d5.loss_dice: 0.2626  decode.d6.loss_cls: 0.1567  decode.d6.loss_mask: 0.2308  decode.d6.loss_dice: 0.2417  decode.d7.loss_cls: 0.1362  decode.d7.loss_mask: 0.2308  decode.d7.loss_dice: 0.2575  decode.d8.loss_cls: 0.1285  decode.d8.loss_mask: 0.2295  decode.d8.loss_dice: 0.2653
07/30 19:52:54 - mmengine - INFO - Iter(train) [26500/80000]  base_lr: 6.9621e-05 lr: 6.9621e-06  eta: 6:28:52  time: 0.4374  data_time: 0.0091  memory: 5279  grad_norm: 72.7506  loss: 7.0181  decode.loss_cls: 0.1522  decode.loss_mask: 0.1722  decode.loss_dice: 0.3069  decode.d0.loss_cls: 1.1796  decode.d0.loss_mask: 0.1739  decode.d0.loss_dice: 0.3028  decode.d1.loss_cls: 0.1535  decode.d1.loss_mask: 0.1635  decode.d1.loss_dice: 0.3129  decode.d2.loss_cls: 0.1217  decode.d2.loss_mask: 0.1630  decode.d2.loss_dice: 0.2869  decode.d3.loss_cls: 0.1437  decode.d3.loss_mask: 0.1610  decode.d3.loss_dice: 0.2816  decode.d4.loss_cls: 0.1435  decode.d4.loss_mask: 0.1606  decode.d4.loss_dice: 0.2759  decode.d5.loss_cls: 0.1116  decode.d5.loss_mask: 0.1636  decode.d5.loss_dice: 0.2939  decode.d6.loss_cls: 0.1063  decode.d6.loss_mask: 0.1700  decode.d6.loss_dice: 0.2901  decode.d7.loss_cls: 0.1363  decode.d7.loss_mask: 0.1747  decode.d7.loss_dice: 0.2968  decode.d8.loss_cls: 0.1645  decode.d8.loss_mask: 0.1701  decode.d8.loss_dice: 0.2849
07/30 19:53:16 - mmengine - INFO - Iter(train) [26550/80000]  base_lr: 6.9563e-05 lr: 6.9563e-06  eta: 6:28:30  time: 0.4358  data_time: 0.0091  memory: 5279  grad_norm: 177.3870  loss: 9.5625  decode.loss_cls: 0.2484  decode.loss_mask: 0.2377  decode.loss_dice: 0.3465  decode.d0.loss_cls: 1.0772  decode.d0.loss_mask: 0.2142  decode.d0.loss_dice: 0.3790  decode.d1.loss_cls: 0.2617  decode.d1.loss_mask: 0.2361  decode.d1.loss_dice: 0.3628  decode.d2.loss_cls: 0.2420  decode.d2.loss_mask: 0.2475  decode.d2.loss_dice: 0.3718  decode.d3.loss_cls: 0.2741  decode.d3.loss_mask: 0.2656  decode.d3.loss_dice: 0.4052  decode.d4.loss_cls: 0.2061  decode.d4.loss_mask: 0.2951  decode.d4.loss_dice: 0.3968  decode.d5.loss_cls: 0.2097  decode.d5.loss_mask: 0.2718  decode.d5.loss_dice: 0.3997  decode.d6.loss_cls: 0.2398  decode.d6.loss_mask: 0.2478  decode.d6.loss_dice: 0.3855  decode.d7.loss_cls: 0.2018  decode.d7.loss_mask: 0.2608  decode.d7.loss_dice: 0.4163  decode.d8.loss_cls: 0.2445  decode.d8.loss_mask: 0.2505  decode.d8.loss_dice: 0.3662
07/30 19:53:38 - mmengine - INFO - Iter(train) [26600/80000]  base_lr: 6.9504e-05 lr: 6.9504e-06  eta: 6:28:09  time: 0.4366  data_time: 0.0094  memory: 5277  grad_norm: 78.4997  loss: 7.9433  decode.loss_cls: 0.1983  decode.loss_mask: 0.2309  decode.loss_dice: 0.2977  decode.d0.loss_cls: 0.9187  decode.d0.loss_mask: 0.2330  decode.d0.loss_dice: 0.3170  decode.d1.loss_cls: 0.2478  decode.d1.loss_mask: 0.2322  decode.d1.loss_dice: 0.3005  decode.d2.loss_cls: 0.1948  decode.d2.loss_mask: 0.2287  decode.d2.loss_dice: 0.3040  decode.d3.loss_cls: 0.1572  decode.d3.loss_mask: 0.2308  decode.d3.loss_dice: 0.3070  decode.d4.loss_cls: 0.1493  decode.d4.loss_mask: 0.2323  decode.d4.loss_dice: 0.2974  decode.d5.loss_cls: 0.1531  decode.d5.loss_mask: 0.2334  decode.d5.loss_dice: 0.3087  decode.d6.loss_cls: 0.1842  decode.d6.loss_mask: 0.2323  decode.d6.loss_dice: 0.3012  decode.d7.loss_cls: 0.1882  decode.d7.loss_mask: 0.2337  decode.d7.loss_dice: 0.3011  decode.d8.loss_cls: 0.1830  decode.d8.loss_mask: 0.2332  decode.d8.loss_dice: 0.3134
07/30 19:54:00 - mmengine - INFO - Iter(train) [26650/80000]  base_lr: 6.9446e-05 lr: 6.9446e-06  eta: 6:27:47  time: 0.4366  data_time: 0.0093  memory: 5265  grad_norm: 114.2946  loss: 8.2019  decode.loss_cls: 0.0804  decode.loss_mask: 0.2854  decode.loss_dice: 0.3302  decode.d0.loss_cls: 1.0228  decode.d0.loss_mask: 0.2967  decode.d0.loss_dice: 0.3382  decode.d1.loss_cls: 0.1946  decode.d1.loss_mask: 0.2909  decode.d1.loss_dice: 0.3100  decode.d2.loss_cls: 0.1375  decode.d2.loss_mask: 0.2921  decode.d2.loss_dice: 0.3083  decode.d3.loss_cls: 0.1131  decode.d3.loss_mask: 0.2875  decode.d3.loss_dice: 0.3103  decode.d4.loss_cls: 0.1098  decode.d4.loss_mask: 0.2861  decode.d4.loss_dice: 0.3108  decode.d5.loss_cls: 0.0987  decode.d5.loss_mask: 0.2917  decode.d5.loss_dice: 0.3144  decode.d6.loss_cls: 0.1588  decode.d6.loss_mask: 0.2862  decode.d6.loss_dice: 0.3062  decode.d7.loss_cls: 0.0822  decode.d7.loss_mask: 0.2888  decode.d7.loss_dice: 0.3134  decode.d8.loss_cls: 0.1788  decode.d8.loss_mask: 0.2874  decode.d8.loss_dice: 0.2907
07/30 19:54:22 - mmengine - INFO - Iter(train) [26700/80000]  base_lr: 6.9387e-05 lr: 6.9387e-06  eta: 6:27:25  time: 0.4357  data_time: 0.0095  memory: 5265  grad_norm: 164.2041  loss: 10.4243  decode.loss_cls: 0.3514  decode.loss_mask: 0.2448  decode.loss_dice: 0.3021  decode.d0.loss_cls: 1.0774  decode.d0.loss_mask: 0.2590  decode.d0.loss_dice: 0.3487  decode.d1.loss_cls: 0.4018  decode.d1.loss_mask: 0.2529  decode.d1.loss_dice: 0.3018  decode.d2.loss_cls: 0.3870  decode.d2.loss_mask: 0.2423  decode.d2.loss_dice: 0.3088  decode.d3.loss_cls: 0.3761  decode.d3.loss_mask: 0.2400  decode.d3.loss_dice: 0.3162  decode.d4.loss_cls: 0.4296  decode.d4.loss_mask: 0.2413  decode.d4.loss_dice: 0.3165  decode.d5.loss_cls: 0.4328  decode.d5.loss_mask: 0.2434  decode.d5.loss_dice: 0.3277  decode.d6.loss_cls: 0.4283  decode.d6.loss_mask: 0.2440  decode.d6.loss_dice: 0.3300  decode.d7.loss_cls: 0.4184  decode.d7.loss_mask: 0.2471  decode.d7.loss_dice: 0.3148  decode.d8.loss_cls: 0.4835  decode.d8.loss_mask: 0.2441  decode.d8.loss_dice: 0.3124
07/30 19:54:44 - mmengine - INFO - Iter(train) [26750/80000]  base_lr: 6.9328e-05 lr: 6.9328e-06  eta: 6:27:03  time: 0.4356  data_time: 0.0093  memory: 5261  grad_norm: 133.6622  loss: 10.2348  decode.loss_cls: 0.3643  decode.loss_mask: 0.2959  decode.loss_dice: 0.2737  decode.d0.loss_cls: 1.1193  decode.d0.loss_mask: 0.3122  decode.d0.loss_dice: 0.3130  decode.d1.loss_cls: 0.3813  decode.d1.loss_mask: 0.2994  decode.d1.loss_dice: 0.3154  decode.d2.loss_cls: 0.3271  decode.d2.loss_mask: 0.2893  decode.d2.loss_dice: 0.2809  decode.d3.loss_cls: 0.3382  decode.d3.loss_mask: 0.2920  decode.d3.loss_dice: 0.2642  decode.d4.loss_cls: 0.3570  decode.d4.loss_mask: 0.2920  decode.d4.loss_dice: 0.2874  decode.d5.loss_cls: 0.4141  decode.d5.loss_mask: 0.2886  decode.d5.loss_dice: 0.2742  decode.d6.loss_cls: 0.3800  decode.d6.loss_mask: 0.2939  decode.d6.loss_dice: 0.2885  decode.d7.loss_cls: 0.3499  decode.d7.loss_mask: 0.2956  decode.d7.loss_dice: 0.3034  decode.d8.loss_cls: 0.3690  decode.d8.loss_mask: 0.2962  decode.d8.loss_dice: 0.2787
07/30 19:55:05 - mmengine - INFO - Iter(train) [26800/80000]  base_lr: 6.9270e-05 lr: 6.9270e-06  eta: 6:26:41  time: 0.4362  data_time: 0.0091  memory: 5278  grad_norm: 53.1610  loss: 6.7109  decode.loss_cls: 0.1153  decode.loss_mask: 0.2023  decode.loss_dice: 0.2589  decode.d0.loss_cls: 0.9352  decode.d0.loss_mask: 0.2101  decode.d0.loss_dice: 0.2553  decode.d1.loss_cls: 0.1863  decode.d1.loss_mask: 0.2014  decode.d1.loss_dice: 0.2568  decode.d2.loss_cls: 0.1305  decode.d2.loss_mask: 0.2038  decode.d2.loss_dice: 0.2491  decode.d3.loss_cls: 0.1097  decode.d3.loss_mask: 0.2027  decode.d3.loss_dice: 0.2526  decode.d4.loss_cls: 0.1206  decode.d4.loss_mask: 0.2030  decode.d4.loss_dice: 0.2414  decode.d5.loss_cls: 0.1543  decode.d5.loss_mask: 0.1989  decode.d5.loss_dice: 0.2629  decode.d6.loss_cls: 0.1322  decode.d6.loss_mask: 0.2005  decode.d6.loss_dice: 0.2445  decode.d7.loss_cls: 0.1487  decode.d7.loss_mask: 0.2004  decode.d7.loss_dice: 0.2608  decode.d8.loss_cls: 0.1335  decode.d8.loss_mask: 0.1997  decode.d8.loss_dice: 0.2397
07/30 19:55:27 - mmengine - INFO - Iter(train) [26850/80000]  base_lr: 6.9211e-05 lr: 6.9211e-06  eta: 6:26:20  time: 0.4370  data_time: 0.0094  memory: 5265  grad_norm: 121.8999  loss: 8.8201  decode.loss_cls: 0.2267  decode.loss_mask: 0.2072  decode.loss_dice: 0.3308  decode.d0.loss_cls: 1.0333  decode.d0.loss_mask: 0.2481  decode.d0.loss_dice: 0.3513  decode.d1.loss_cls: 0.3074  decode.d1.loss_mask: 0.2318  decode.d1.loss_dice: 0.3367  decode.d2.loss_cls: 0.1978  decode.d2.loss_mask: 0.2136  decode.d2.loss_dice: 0.3318  decode.d3.loss_cls: 0.2449  decode.d3.loss_mask: 0.2131  decode.d3.loss_dice: 0.3358  decode.d4.loss_cls: 0.2385  decode.d4.loss_mask: 0.2161  decode.d4.loss_dice: 0.3316  decode.d5.loss_cls: 0.2164  decode.d5.loss_mask: 0.2207  decode.d5.loss_dice: 0.3488  decode.d6.loss_cls: 0.2612  decode.d6.loss_mask: 0.2123  decode.d6.loss_dice: 0.3429  decode.d7.loss_cls: 0.2709  decode.d7.loss_mask: 0.2068  decode.d7.loss_dice: 0.3201  decode.d8.loss_cls: 0.2886  decode.d8.loss_mask: 0.2059  decode.d8.loss_dice: 0.3289
07/30 19:55:49 - mmengine - INFO - Iter(train) [26900/80000]  base_lr: 6.9153e-05 lr: 6.9153e-06  eta: 6:25:58  time: 0.4360  data_time: 0.0094  memory: 5244  grad_norm: 64.1747  loss: 7.4216  decode.loss_cls: 0.0414  decode.loss_mask: 0.3067  decode.loss_dice: 0.2661  decode.d0.loss_cls: 0.9951  decode.d0.loss_mask: 0.3020  decode.d0.loss_dice: 0.2794  decode.d1.loss_cls: 0.1376  decode.d1.loss_mask: 0.2984  decode.d1.loss_dice: 0.2759  decode.d2.loss_cls: 0.0892  decode.d2.loss_mask: 0.2798  decode.d2.loss_dice: 0.2634  decode.d3.loss_cls: 0.0941  decode.d3.loss_mask: 0.2792  decode.d3.loss_dice: 0.2566  decode.d4.loss_cls: 0.0940  decode.d4.loss_mask: 0.2853  decode.d4.loss_dice: 0.2636  decode.d5.loss_cls: 0.1076  decode.d5.loss_mask: 0.2844  decode.d5.loss_dice: 0.2632  decode.d6.loss_cls: 0.1182  decode.d6.loss_mask: 0.2828  decode.d6.loss_dice: 0.2544  decode.d7.loss_cls: 0.1230  decode.d7.loss_mask: 0.2822  decode.d7.loss_dice: 0.2585  decode.d8.loss_cls: 0.0701  decode.d8.loss_mask: 0.3066  decode.d8.loss_dice: 0.2630
07/30 19:56:11 - mmengine - INFO - Iter(train) [26950/80000]  base_lr: 6.9094e-05 lr: 6.9094e-06  eta: 6:25:36  time: 0.4357  data_time: 0.0094  memory: 5277  grad_norm: 105.9751  loss: 7.9501  decode.loss_cls: 0.0954  decode.loss_mask: 0.3221  decode.loss_dice: 0.2787  decode.d0.loss_cls: 0.9025  decode.d0.loss_mask: 0.3274  decode.d0.loss_dice: 0.2775  decode.d1.loss_cls: 0.0825  decode.d1.loss_mask: 0.3298  decode.d1.loss_dice: 0.2910  decode.d2.loss_cls: 0.1000  decode.d2.loss_mask: 0.3301  decode.d2.loss_dice: 0.2770  decode.d3.loss_cls: 0.1048  decode.d3.loss_mask: 0.3279  decode.d3.loss_dice: 0.2997  decode.d4.loss_cls: 0.1435  decode.d4.loss_mask: 0.3236  decode.d4.loss_dice: 0.2821  decode.d5.loss_cls: 0.1377  decode.d5.loss_mask: 0.3126  decode.d5.loss_dice: 0.2816  decode.d6.loss_cls: 0.1324  decode.d6.loss_mask: 0.3165  decode.d6.loss_dice: 0.2520  decode.d7.loss_cls: 0.1006  decode.d7.loss_mask: 0.3308  decode.d7.loss_dice: 0.2836  decode.d8.loss_cls: 0.1333  decode.d8.loss_mask: 0.3155  decode.d8.loss_dice: 0.2579
07/30 19:56:33 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 19:56:33 - mmengine - INFO - Iter(train) [27000/80000]  base_lr: 6.9035e-05 lr: 6.9035e-06  eta: 6:25:14  time: 0.4362  data_time: 0.0094  memory: 5265  grad_norm: 76.2206  loss: 7.5078  decode.loss_cls: 0.2070  decode.loss_mask: 0.2394  decode.loss_dice: 0.2167  decode.d0.loss_cls: 0.9721  decode.d0.loss_mask: 0.2457  decode.d0.loss_dice: 0.2290  decode.d1.loss_cls: 0.2049  decode.d1.loss_mask: 0.2435  decode.d1.loss_dice: 0.2223  decode.d2.loss_cls: 0.2223  decode.d2.loss_mask: 0.2425  decode.d2.loss_dice: 0.2201  decode.d3.loss_cls: 0.1989  decode.d3.loss_mask: 0.2410  decode.d3.loss_dice: 0.2173  decode.d4.loss_cls: 0.1974  decode.d4.loss_mask: 0.2392  decode.d4.loss_dice: 0.2211  decode.d5.loss_cls: 0.2047  decode.d5.loss_mask: 0.2400  decode.d5.loss_dice: 0.2205  decode.d6.loss_cls: 0.2059  decode.d6.loss_mask: 0.2450  decode.d6.loss_dice: 0.2247  decode.d7.loss_cls: 0.2430  decode.d7.loss_mask: 0.2426  decode.d7.loss_dice: 0.2140  decode.d8.loss_cls: 0.2155  decode.d8.loss_mask: 0.2445  decode.d8.loss_dice: 0.2267
07/30 19:56:55 - mmengine - INFO - Iter(train) [27050/80000]  base_lr: 6.8977e-05 lr: 6.8977e-06  eta: 6:24:53  time: 0.4361  data_time: 0.0093  memory: 5277  grad_norm: 102.7554  loss: 7.9145  decode.loss_cls: 0.2108  decode.loss_mask: 0.2288  decode.loss_dice: 0.2389  decode.d0.loss_cls: 1.0328  decode.d0.loss_mask: 0.2379  decode.d0.loss_dice: 0.2594  decode.d1.loss_cls: 0.3210  decode.d1.loss_mask: 0.2342  decode.d1.loss_dice: 0.2409  decode.d2.loss_cls: 0.2616  decode.d2.loss_mask: 0.2347  decode.d2.loss_dice: 0.2487  decode.d3.loss_cls: 0.2708  decode.d3.loss_mask: 0.2332  decode.d3.loss_dice: 0.2473  decode.d4.loss_cls: 0.2207  decode.d4.loss_mask: 0.2317  decode.d4.loss_dice: 0.2392  decode.d5.loss_cls: 0.2362  decode.d5.loss_mask: 0.2301  decode.d5.loss_dice: 0.2358  decode.d6.loss_cls: 0.2106  decode.d6.loss_mask: 0.2308  decode.d6.loss_dice: 0.2391  decode.d7.loss_cls: 0.2100  decode.d7.loss_mask: 0.2287  decode.d7.loss_dice: 0.2257  decode.d8.loss_cls: 0.2092  decode.d8.loss_mask: 0.2319  decode.d8.loss_dice: 0.2337
07/30 19:57:16 - mmengine - INFO - Iter(train) [27100/80000]  base_lr: 6.8918e-05 lr: 6.8918e-06  eta: 6:24:31  time: 0.4365  data_time: 0.0091  memory: 5279  grad_norm: 57.2502  loss: 7.2735  decode.loss_cls: 0.1822  decode.loss_mask: 0.2087  decode.loss_dice: 0.2791  decode.d0.loss_cls: 0.9331  decode.d0.loss_mask: 0.2110  decode.d0.loss_dice: 0.2991  decode.d1.loss_cls: 0.1180  decode.d1.loss_mask: 0.2079  decode.d1.loss_dice: 0.2855  decode.d2.loss_cls: 0.1245  decode.d2.loss_mask: 0.2102  decode.d2.loss_dice: 0.2766  decode.d3.loss_cls: 0.1608  decode.d3.loss_mask: 0.2066  decode.d3.loss_dice: 0.2601  decode.d4.loss_cls: 0.1537  decode.d4.loss_mask: 0.2118  decode.d4.loss_dice: 0.2838  decode.d5.loss_cls: 0.1724  decode.d5.loss_mask: 0.2026  decode.d5.loss_dice: 0.2812  decode.d6.loss_cls: 0.1970  decode.d6.loss_mask: 0.1987  decode.d6.loss_dice: 0.2877  decode.d7.loss_cls: 0.1395  decode.d7.loss_mask: 0.2090  decode.d7.loss_dice: 0.3204  decode.d8.loss_cls: 0.1473  decode.d8.loss_mask: 0.2086  decode.d8.loss_dice: 0.2964
07/30 19:57:38 - mmengine - INFO - Iter(train) [27150/80000]  base_lr: 6.8860e-05 lr: 6.8860e-06  eta: 6:24:09  time: 0.4365  data_time: 0.0094  memory: 5246  grad_norm: 139.7426  loss: 7.6961  decode.loss_cls: 0.1471  decode.loss_mask: 0.2165  decode.loss_dice: 0.2704  decode.d0.loss_cls: 1.0237  decode.d0.loss_mask: 0.2260  decode.d0.loss_dice: 0.2897  decode.d1.loss_cls: 0.2397  decode.d1.loss_mask: 0.2215  decode.d1.loss_dice: 0.2892  decode.d2.loss_cls: 0.2182  decode.d2.loss_mask: 0.2194  decode.d2.loss_dice: 0.2744  decode.d3.loss_cls: 0.2100  decode.d3.loss_mask: 0.2186  decode.d3.loss_dice: 0.2745  decode.d4.loss_cls: 0.1783  decode.d4.loss_mask: 0.2169  decode.d4.loss_dice: 0.2753  decode.d5.loss_cls: 0.2025  decode.d5.loss_mask: 0.2146  decode.d5.loss_dice: 0.2685  decode.d6.loss_cls: 0.1899  decode.d6.loss_mask: 0.2177  decode.d6.loss_dice: 0.2691  decode.d7.loss_cls: 0.1707  decode.d7.loss_mask: 0.2157  decode.d7.loss_dice: 0.2899  decode.d8.loss_cls: 0.1550  decode.d8.loss_mask: 0.2164  decode.d8.loss_dice: 0.2765
07/30 19:58:00 - mmengine - INFO - Iter(train) [27200/80000]  base_lr: 6.8801e-05 lr: 6.8801e-06  eta: 6:23:47  time: 0.4373  data_time: 0.0093  memory: 5245  grad_norm: 106.6669  loss: 7.8650  decode.loss_cls: 0.1314  decode.loss_mask: 0.2746  decode.loss_dice: 0.3096  decode.d0.loss_cls: 0.8221  decode.d0.loss_mask: 0.3093  decode.d0.loss_dice: 0.3222  decode.d1.loss_cls: 0.2143  decode.d1.loss_mask: 0.2807  decode.d1.loss_dice: 0.2938  decode.d2.loss_cls: 0.1267  decode.d2.loss_mask: 0.2817  decode.d2.loss_dice: 0.2952  decode.d3.loss_cls: 0.1536  decode.d3.loss_mask: 0.2765  decode.d3.loss_dice: 0.3070  decode.d4.loss_cls: 0.1294  decode.d4.loss_mask: 0.2767  decode.d4.loss_dice: 0.3135  decode.d5.loss_cls: 0.1222  decode.d5.loss_mask: 0.2746  decode.d5.loss_dice: 0.2967  decode.d6.loss_cls: 0.1087  decode.d6.loss_mask: 0.2728  decode.d6.loss_dice: 0.2930  decode.d7.loss_cls: 0.1173  decode.d7.loss_mask: 0.2776  decode.d7.loss_dice: 0.2940  decode.d8.loss_cls: 0.1091  decode.d8.loss_mask: 0.2740  decode.d8.loss_dice: 0.3067
07/30 19:58:22 - mmengine - INFO - Iter(train) [27250/80000]  base_lr: 6.8742e-05 lr: 6.8742e-06  eta: 6:23:26  time: 0.4372  data_time: 0.0093  memory: 5265  grad_norm: 45.0954  loss: 7.8573  decode.loss_cls: 0.2128  decode.loss_mask: 0.1727  decode.loss_dice: 0.3023  decode.d0.loss_cls: 1.0208  decode.d0.loss_mask: 0.1792  decode.d0.loss_dice: 0.3305  decode.d1.loss_cls: 0.2819  decode.d1.loss_mask: 0.1775  decode.d1.loss_dice: 0.3077  decode.d2.loss_cls: 0.2100  decode.d2.loss_mask: 0.1768  decode.d2.loss_dice: 0.3035  decode.d3.loss_cls: 0.1910  decode.d3.loss_mask: 0.1799  decode.d3.loss_dice: 0.3193  decode.d4.loss_cls: 0.2245  decode.d4.loss_mask: 0.1756  decode.d4.loss_dice: 0.3200  decode.d5.loss_cls: 0.2029  decode.d5.loss_mask: 0.1728  decode.d5.loss_dice: 0.3047  decode.d6.loss_cls: 0.2130  decode.d6.loss_mask: 0.1767  decode.d6.loss_dice: 0.3121  decode.d7.loss_cls: 0.2071  decode.d7.loss_mask: 0.1748  decode.d7.loss_dice: 0.3048  decode.d8.loss_cls: 0.1989  decode.d8.loss_mask: 0.1774  decode.d8.loss_dice: 0.3262
07/30 19:58:44 - mmengine - INFO - Iter(train) [27300/80000]  base_lr: 6.8684e-05 lr: 6.8684e-06  eta: 6:23:04  time: 0.4369  data_time: 0.0093  memory: 5279  grad_norm: 173.7486  loss: 8.0831  decode.loss_cls: 0.0830  decode.loss_mask: 0.2767  decode.loss_dice: 0.3553  decode.d0.loss_cls: 0.9186  decode.d0.loss_mask: 0.2772  decode.d0.loss_dice: 0.3382  decode.d1.loss_cls: 0.1675  decode.d1.loss_mask: 0.2535  decode.d1.loss_dice: 0.3303  decode.d2.loss_cls: 0.1346  decode.d2.loss_mask: 0.2591  decode.d2.loss_dice: 0.3418  decode.d3.loss_cls: 0.1450  decode.d3.loss_mask: 0.2596  decode.d3.loss_dice: 0.3519  decode.d4.loss_cls: 0.0782  decode.d4.loss_mask: 0.2513  decode.d4.loss_dice: 0.3475  decode.d5.loss_cls: 0.0820  decode.d5.loss_mask: 0.2594  decode.d5.loss_dice: 0.3374  decode.d6.loss_cls: 0.0976  decode.d6.loss_mask: 0.2927  decode.d6.loss_dice: 0.3403  decode.d7.loss_cls: 0.1384  decode.d7.loss_mask: 0.2746  decode.d7.loss_dice: 0.3465  decode.d8.loss_cls: 0.1840  decode.d8.loss_mask: 0.2386  decode.d8.loss_dice: 0.3225
07/30 19:59:06 - mmengine - INFO - Iter(train) [27350/80000]  base_lr: 6.8625e-05 lr: 6.8625e-06  eta: 6:22:42  time: 0.4365  data_time: 0.0094  memory: 5244  grad_norm: 133.7929  loss: 9.4302  decode.loss_cls: 0.3161  decode.loss_mask: 0.2485  decode.loss_dice: 0.2992  decode.d0.loss_cls: 1.1832  decode.d0.loss_mask: 0.2628  decode.d0.loss_dice: 0.3023  decode.d1.loss_cls: 0.3078  decode.d1.loss_mask: 0.2517  decode.d1.loss_dice: 0.3125  decode.d2.loss_cls: 0.3410  decode.d2.loss_mask: 0.2493  decode.d2.loss_dice: 0.2949  decode.d3.loss_cls: 0.3033  decode.d3.loss_mask: 0.2476  decode.d3.loss_dice: 0.3113  decode.d4.loss_cls: 0.2711  decode.d4.loss_mask: 0.2453  decode.d4.loss_dice: 0.3084  decode.d5.loss_cls: 0.2575  decode.d5.loss_mask: 0.2469  decode.d5.loss_dice: 0.3218  decode.d6.loss_cls: 0.2859  decode.d6.loss_mask: 0.2505  decode.d6.loss_dice: 0.3047  decode.d7.loss_cls: 0.3242  decode.d7.loss_mask: 0.2515  decode.d7.loss_dice: 0.3108  decode.d8.loss_cls: 0.2710  decode.d8.loss_mask: 0.2474  decode.d8.loss_dice: 0.3016
07/30 19:59:27 - mmengine - INFO - Iter(train) [27400/80000]  base_lr: 6.8566e-05 lr: 6.8566e-06  eta: 6:22:20  time: 0.4361  data_time: 0.0092  memory: 5261  grad_norm: 113.5729  loss: 8.1645  decode.loss_cls: 0.1575  decode.loss_mask: 0.2689  decode.loss_dice: 0.2907  decode.d0.loss_cls: 1.0951  decode.d0.loss_mask: 0.2603  decode.d0.loss_dice: 0.2613  decode.d1.loss_cls: 0.1616  decode.d1.loss_mask: 0.2642  decode.d1.loss_dice: 0.2978  decode.d2.loss_cls: 0.1874  decode.d2.loss_mask: 0.2526  decode.d2.loss_dice: 0.2914  decode.d3.loss_cls: 0.2121  decode.d3.loss_mask: 0.2523  decode.d3.loss_dice: 0.2958  decode.d4.loss_cls: 0.1839  decode.d4.loss_mask: 0.2570  decode.d4.loss_dice: 0.2903  decode.d5.loss_cls: 0.1896  decode.d5.loss_mask: 0.2510  decode.d5.loss_dice: 0.2823  decode.d6.loss_cls: 0.1789  decode.d6.loss_mask: 0.2467  decode.d6.loss_dice: 0.2826  decode.d7.loss_cls: 0.1909  decode.d7.loss_mask: 0.2529  decode.d7.loss_dice: 0.2842  decode.d8.loss_cls: 0.1767  decode.d8.loss_mask: 0.2559  decode.d8.loss_dice: 0.2927
07/30 19:59:49 - mmengine - INFO - Iter(train) [27450/80000]  base_lr: 6.8508e-05 lr: 6.8508e-06  eta: 6:21:58  time: 0.4357  data_time: 0.0094  memory: 5227  grad_norm: 110.8501  loss: 8.2868  decode.loss_cls: 0.1855  decode.loss_mask: 0.3067  decode.loss_dice: 0.3276  decode.d0.loss_cls: 0.8610  decode.d0.loss_mask: 0.3119  decode.d0.loss_dice: 0.3204  decode.d1.loss_cls: 0.1774  decode.d1.loss_mask: 0.2918  decode.d1.loss_dice: 0.2932  decode.d2.loss_cls: 0.1421  decode.d2.loss_mask: 0.2970  decode.d2.loss_dice: 0.2850  decode.d3.loss_cls: 0.2105  decode.d3.loss_mask: 0.3021  decode.d3.loss_dice: 0.2899  decode.d4.loss_cls: 0.1875  decode.d4.loss_mask: 0.3007  decode.d4.loss_dice: 0.2820  decode.d5.loss_cls: 0.1147  decode.d5.loss_mask: 0.2960  decode.d5.loss_dice: 0.3109  decode.d6.loss_cls: 0.1027  decode.d6.loss_mask: 0.3025  decode.d6.loss_dice: 0.3225  decode.d7.loss_cls: 0.1107  decode.d7.loss_mask: 0.3052  decode.d7.loss_dice: 0.3171  decode.d8.loss_cls: 0.1056  decode.d8.loss_mask: 0.3031  decode.d8.loss_dice: 0.3236
07/30 20:00:11 - mmengine - INFO - Iter(train) [27500/80000]  base_lr: 6.8449e-05 lr: 6.8449e-06  eta: 6:21:37  time: 0.4365  data_time: 0.0095  memory: 5261  grad_norm: 106.5591  loss: 8.7793  decode.loss_cls: 0.1795  decode.loss_mask: 0.2767  decode.loss_dice: 0.3221  decode.d0.loss_cls: 0.9426  decode.d0.loss_mask: 0.2764  decode.d0.loss_dice: 0.3108  decode.d1.loss_cls: 0.2064  decode.d1.loss_mask: 0.2790  decode.d1.loss_dice: 0.3000  decode.d2.loss_cls: 0.1896  decode.d2.loss_mask: 0.2809  decode.d2.loss_dice: 0.3295  decode.d3.loss_cls: 0.2243  decode.d3.loss_mask: 0.2827  decode.d3.loss_dice: 0.3102  decode.d4.loss_cls: 0.2615  decode.d4.loss_mask: 0.2824  decode.d4.loss_dice: 0.3099  decode.d5.loss_cls: 0.2591  decode.d5.loss_mask: 0.2794  decode.d5.loss_dice: 0.3170  decode.d6.loss_cls: 0.2447  decode.d6.loss_mask: 0.2776  decode.d6.loss_dice: 0.3318  decode.d7.loss_cls: 0.1918  decode.d7.loss_mask: 0.2755  decode.d7.loss_dice: 0.2978  decode.d8.loss_cls: 0.1520  decode.d8.loss_mask: 0.2750  decode.d8.loss_dice: 0.3133
07/30 20:00:33 - mmengine - INFO - Iter(train) [27550/80000]  base_lr: 6.8390e-05 lr: 6.8390e-06  eta: 6:21:15  time: 0.4366  data_time: 0.0094  memory: 5246  grad_norm: 39.4736  loss: 5.7020  decode.loss_cls: 0.0343  decode.loss_mask: 0.2138  decode.loss_dice: 0.2247  decode.d0.loss_cls: 1.0314  decode.d0.loss_mask: 0.2119  decode.d0.loss_dice: 0.2209  decode.d1.loss_cls: 0.0756  decode.d1.loss_mask: 0.2090  decode.d1.loss_dice: 0.2313  decode.d2.loss_cls: 0.0394  decode.d2.loss_mask: 0.2093  decode.d2.loss_dice: 0.2296  decode.d3.loss_cls: 0.0340  decode.d3.loss_mask: 0.2097  decode.d3.loss_dice: 0.2242  decode.d4.loss_cls: 0.0245  decode.d4.loss_mask: 0.2092  decode.d4.loss_dice: 0.2217  decode.d5.loss_cls: 0.0246  decode.d5.loss_mask: 0.2100  decode.d5.loss_dice: 0.2258  decode.d6.loss_cls: 0.0295  decode.d6.loss_mask: 0.2085  decode.d6.loss_dice: 0.2207  decode.d7.loss_cls: 0.0273  decode.d7.loss_mask: 0.2120  decode.d7.loss_dice: 0.2216  decode.d8.loss_cls: 0.0324  decode.d8.loss_mask: 0.2126  decode.d8.loss_dice: 0.2226
07/30 20:00:55 - mmengine - INFO - Iter(train) [27600/80000]  base_lr: 6.8332e-05 lr: 6.8332e-06  eta: 6:20:53  time: 0.4368  data_time: 0.0094  memory: 5304  grad_norm: 62.4685  loss: 9.3163  decode.loss_cls: 0.3332  decode.loss_mask: 0.2704  decode.loss_dice: 0.2502  decode.d0.loss_cls: 1.0420  decode.d0.loss_mask: 0.2765  decode.d0.loss_dice: 0.2861  decode.d1.loss_cls: 0.3186  decode.d1.loss_mask: 0.2709  decode.d1.loss_dice: 0.2550  decode.d2.loss_cls: 0.2986  decode.d2.loss_mask: 0.2707  decode.d2.loss_dice: 0.2394  decode.d3.loss_cls: 0.3199  decode.d3.loss_mask: 0.2719  decode.d3.loss_dice: 0.2636  decode.d4.loss_cls: 0.3085  decode.d4.loss_mask: 0.2690  decode.d4.loss_dice: 0.2687  decode.d5.loss_cls: 0.3478  decode.d5.loss_mask: 0.2696  decode.d5.loss_dice: 0.2536  decode.d6.loss_cls: 0.3829  decode.d6.loss_mask: 0.2728  decode.d6.loss_dice: 0.2508  decode.d7.loss_cls: 0.3470  decode.d7.loss_mask: 0.2727  decode.d7.loss_dice: 0.2358  decode.d8.loss_cls: 0.3427  decode.d8.loss_mask: 0.2698  decode.d8.loss_dice: 0.2575
07/30 20:01:17 - mmengine - INFO - Iter(train) [27650/80000]  base_lr: 6.8273e-05 lr: 6.8273e-06  eta: 6:20:31  time: 0.4366  data_time: 0.0094  memory: 5265  grad_norm: 113.9662  loss: 7.7520  decode.loss_cls: 0.0952  decode.loss_mask: 0.3028  decode.loss_dice: 0.2601  decode.d0.loss_cls: 0.8456  decode.d0.loss_mask: 0.3446  decode.d0.loss_dice: 0.3132  decode.d1.loss_cls: 0.1121  decode.d1.loss_mask: 0.3152  decode.d1.loss_dice: 0.2707  decode.d2.loss_cls: 0.1155  decode.d2.loss_mask: 0.3355  decode.d2.loss_dice: 0.2791  decode.d3.loss_cls: 0.1200  decode.d3.loss_mask: 0.3132  decode.d3.loss_dice: 0.2609  decode.d4.loss_cls: 0.1239  decode.d4.loss_mask: 0.3088  decode.d4.loss_dice: 0.2776  decode.d5.loss_cls: 0.1496  decode.d5.loss_mask: 0.3076  decode.d5.loss_dice: 0.2660  decode.d6.loss_cls: 0.1291  decode.d6.loss_mask: 0.3051  decode.d6.loss_dice: 0.2602  decode.d7.loss_cls: 0.1206  decode.d7.loss_mask: 0.3035  decode.d7.loss_dice: 0.2580  decode.d8.loss_cls: 0.0932  decode.d8.loss_mask: 0.3044  decode.d8.loss_dice: 0.2606
07/30 20:01:38 - mmengine - INFO - Iter(train) [27700/80000]  base_lr: 6.8214e-05 lr: 6.8214e-06  eta: 6:20:10  time: 0.4371  data_time: 0.0094  memory: 5246  grad_norm: 40.7269  loss: 6.0160  decode.loss_cls: 0.0242  decode.loss_mask: 0.2225  decode.loss_dice: 0.2520  decode.d0.loss_cls: 0.8119  decode.d0.loss_mask: 0.2234  decode.d0.loss_dice: 0.2568  decode.d1.loss_cls: 0.1088  decode.d1.loss_mask: 0.2217  decode.d1.loss_dice: 0.2506  decode.d2.loss_cls: 0.1128  decode.d2.loss_mask: 0.2176  decode.d2.loss_dice: 0.2452  decode.d3.loss_cls: 0.0754  decode.d3.loss_mask: 0.2192  decode.d3.loss_dice: 0.2450  decode.d4.loss_cls: 0.0469  decode.d4.loss_mask: 0.2212  decode.d4.loss_dice: 0.2454  decode.d5.loss_cls: 0.0394  decode.d5.loss_mask: 0.2228  decode.d5.loss_dice: 0.2492  decode.d6.loss_cls: 0.0406  decode.d6.loss_mask: 0.2228  decode.d6.loss_dice: 0.2421  decode.d7.loss_cls: 0.0337  decode.d7.loss_mask: 0.2238  decode.d7.loss_dice: 0.2455  decode.d8.loss_cls: 0.0345  decode.d8.loss_mask: 0.2187  decode.d8.loss_dice: 0.2425
07/30 20:02:00 - mmengine - INFO - Iter(train) [27750/80000]  base_lr: 6.8156e-05 lr: 6.8156e-06  eta: 6:19:48  time: 0.4367  data_time: 0.0093  memory: 5265  grad_norm: 125.8330  loss: 7.8894  decode.loss_cls: 0.2143  decode.loss_mask: 0.2261  decode.loss_dice: 0.2841  decode.d0.loss_cls: 1.0819  decode.d0.loss_mask: 0.2320  decode.d0.loss_dice: 0.2716  decode.d1.loss_cls: 0.2913  decode.d1.loss_mask: 0.2229  decode.d1.loss_dice: 0.2677  decode.d2.loss_cls: 0.2119  decode.d2.loss_mask: 0.2225  decode.d2.loss_dice: 0.2626  decode.d3.loss_cls: 0.2089  decode.d3.loss_mask: 0.2301  decode.d3.loss_dice: 0.2679  decode.d4.loss_cls: 0.2089  decode.d4.loss_mask: 0.2281  decode.d4.loss_dice: 0.2715  decode.d5.loss_cls: 0.1683  decode.d5.loss_mask: 0.2313  decode.d5.loss_dice: 0.2704  decode.d6.loss_cls: 0.1480  decode.d6.loss_mask: 0.2291  decode.d6.loss_dice: 0.2652  decode.d7.loss_cls: 0.1828  decode.d7.loss_mask: 0.2289  decode.d7.loss_dice: 0.2932  decode.d8.loss_cls: 0.1703  decode.d8.loss_mask: 0.2289  decode.d8.loss_dice: 0.2686
07/30 20:02:22 - mmengine - INFO - Iter(train) [27800/80000]  base_lr: 6.8097e-05 lr: 6.8097e-06  eta: 6:19:26  time: 0.4526  data_time: 0.0093  memory: 5305  grad_norm: 64.0173  loss: 6.5635  decode.loss_cls: 0.1367  decode.loss_mask: 0.2285  decode.loss_dice: 0.2119  decode.d0.loss_cls: 0.9057  decode.d0.loss_mask: 0.2309  decode.d0.loss_dice: 0.2305  decode.d1.loss_cls: 0.0900  decode.d1.loss_mask: 0.2319  decode.d1.loss_dice: 0.2196  decode.d2.loss_cls: 0.0698  decode.d2.loss_mask: 0.2295  decode.d2.loss_dice: 0.2370  decode.d3.loss_cls: 0.1079  decode.d3.loss_mask: 0.2282  decode.d3.loss_dice: 0.2262  decode.d4.loss_cls: 0.1534  decode.d4.loss_mask: 0.2261  decode.d4.loss_dice: 0.2146  decode.d5.loss_cls: 0.1631  decode.d5.loss_mask: 0.2299  decode.d5.loss_dice: 0.2203  decode.d6.loss_cls: 0.1391  decode.d6.loss_mask: 0.2297  decode.d6.loss_dice: 0.2244  decode.d7.loss_cls: 0.1617  decode.d7.loss_mask: 0.2257  decode.d7.loss_dice: 0.2182  decode.d8.loss_cls: 0.1282  decode.d8.loss_mask: 0.2265  decode.d8.loss_dice: 0.2182
07/30 20:02:44 - mmengine - INFO - Iter(train) [27850/80000]  base_lr: 6.8038e-05 lr: 6.8038e-06  eta: 6:19:05  time: 0.4361  data_time: 0.0093  memory: 5279  grad_norm: 43.0403  loss: 5.6618  decode.loss_cls: 0.0453  decode.loss_mask: 0.2304  decode.loss_dice: 0.2200  decode.d0.loss_cls: 0.8025  decode.d0.loss_mask: 0.2386  decode.d0.loss_dice: 0.2213  decode.d1.loss_cls: 0.0414  decode.d1.loss_mask: 0.2321  decode.d1.loss_dice: 0.2207  decode.d2.loss_cls: 0.0299  decode.d2.loss_mask: 0.2287  decode.d2.loss_dice: 0.2177  decode.d3.loss_cls: 0.0445  decode.d3.loss_mask: 0.2285  decode.d3.loss_dice: 0.2164  decode.d4.loss_cls: 0.0447  decode.d4.loss_mask: 0.2271  decode.d4.loss_dice: 0.2226  decode.d5.loss_cls: 0.0459  decode.d5.loss_mask: 0.2306  decode.d5.loss_dice: 0.2220  decode.d6.loss_cls: 0.0370  decode.d6.loss_mask: 0.2280  decode.d6.loss_dice: 0.2147  decode.d7.loss_cls: 0.0381  decode.d7.loss_mask: 0.2280  decode.d7.loss_dice: 0.2156  decode.d8.loss_cls: 0.0386  decode.d8.loss_mask: 0.2282  decode.d8.loss_dice: 0.2225
07/30 20:03:06 - mmengine - INFO - Iter(train) [27900/80000]  base_lr: 6.7979e-05 lr: 6.7979e-06  eta: 6:18:43  time: 0.4382  data_time: 0.0095  memory: 5244  grad_norm: 64.5103  loss: 7.7688  decode.loss_cls: 0.1338  decode.loss_mask: 0.2516  decode.loss_dice: 0.2979  decode.d0.loss_cls: 1.1065  decode.d0.loss_mask: 0.2601  decode.d0.loss_dice: 0.3159  decode.d1.loss_cls: 0.0763  decode.d1.loss_mask: 0.2561  decode.d1.loss_dice: 0.3167  decode.d2.loss_cls: 0.0953  decode.d2.loss_mask: 0.2519  decode.d2.loss_dice: 0.3081  decode.d3.loss_cls: 0.1112  decode.d3.loss_mask: 0.2523  decode.d3.loss_dice: 0.3032  decode.d4.loss_cls: 0.1020  decode.d4.loss_mask: 0.2527  decode.d4.loss_dice: 0.2992  decode.d5.loss_cls: 0.1301  decode.d5.loss_mask: 0.2531  decode.d5.loss_dice: 0.3127  decode.d6.loss_cls: 0.1393  decode.d6.loss_mask: 0.2552  decode.d6.loss_dice: 0.2863  decode.d7.loss_cls: 0.1567  decode.d7.loss_mask: 0.2568  decode.d7.loss_dice: 0.3016  decode.d8.loss_cls: 0.1319  decode.d8.loss_mask: 0.2517  decode.d8.loss_dice: 0.3026
07/30 20:03:28 - mmengine - INFO - Iter(train) [27950/80000]  base_lr: 6.7921e-05 lr: 6.7921e-06  eta: 6:18:21  time: 0.4368  data_time: 0.0094  memory: 5277  grad_norm: 104.2143  loss: 8.0674  decode.loss_cls: 0.1872  decode.loss_mask: 0.2550  decode.loss_dice: 0.2630  decode.d0.loss_cls: 1.0356  decode.d0.loss_mask: 0.2559  decode.d0.loss_dice: 0.3088  decode.d1.loss_cls: 0.1795  decode.d1.loss_mask: 0.2459  decode.d1.loss_dice: 0.2619  decode.d2.loss_cls: 0.1672  decode.d2.loss_mask: 0.2503  decode.d2.loss_dice: 0.2996  decode.d3.loss_cls: 0.1998  decode.d3.loss_mask: 0.2501  decode.d3.loss_dice: 0.2854  decode.d4.loss_cls: 0.2249  decode.d4.loss_mask: 0.2482  decode.d4.loss_dice: 0.2770  decode.d5.loss_cls: 0.2168  decode.d5.loss_mask: 0.2463  decode.d5.loss_dice: 0.2755  decode.d6.loss_cls: 0.1956  decode.d6.loss_mask: 0.2405  decode.d6.loss_dice: 0.2455  decode.d7.loss_cls: 0.2134  decode.d7.loss_mask: 0.2431  decode.d7.loss_dice: 0.2656  decode.d8.loss_cls: 0.2025  decode.d8.loss_mask: 0.2439  decode.d8.loss_dice: 0.2831
07/30 20:03:50 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 20:03:50 - mmengine - INFO - Iter(train) [28000/80000]  base_lr: 6.7862e-05 lr: 6.7862e-06  eta: 6:17:59  time: 0.4378  data_time: 0.0095  memory: 5246  grad_norm: 67.6914  loss: 7.0011  decode.loss_cls: 0.1734  decode.loss_mask: 0.1948  decode.loss_dice: 0.2491  decode.d0.loss_cls: 0.9151  decode.d0.loss_mask: 0.2043  decode.d0.loss_dice: 0.3137  decode.d1.loss_cls: 0.1604  decode.d1.loss_mask: 0.1964  decode.d1.loss_dice: 0.2561  decode.d2.loss_cls: 0.1469  decode.d2.loss_mask: 0.1967  decode.d2.loss_dice: 0.2554  decode.d3.loss_cls: 0.1559  decode.d3.loss_mask: 0.1969  decode.d3.loss_dice: 0.2509  decode.d4.loss_cls: 0.1594  decode.d4.loss_mask: 0.1985  decode.d4.loss_dice: 0.2572  decode.d5.loss_cls: 0.1713  decode.d5.loss_mask: 0.1994  decode.d5.loss_dice: 0.2448  decode.d6.loss_cls: 0.1746  decode.d6.loss_mask: 0.1979  decode.d6.loss_dice: 0.2411  decode.d7.loss_cls: 0.1547  decode.d7.loss_mask: 0.1986  decode.d7.loss_dice: 0.2764  decode.d8.loss_cls: 0.1949  decode.d8.loss_mask: 0.1975  decode.d8.loss_dice: 0.2687
07/30 20:04:11 - mmengine - INFO - Iter(train) [28050/80000]  base_lr: 6.7803e-05 lr: 6.7803e-06  eta: 6:17:38  time: 0.4369  data_time: 0.0094  memory: 5245  grad_norm: 113.5686  loss: 9.5742  decode.loss_cls: 0.1692  decode.loss_mask: 0.3403  decode.loss_dice: 0.3045  decode.d0.loss_cls: 1.1064  decode.d0.loss_mask: 0.3253  decode.d0.loss_dice: 0.3166  decode.d1.loss_cls: 0.3330  decode.d1.loss_mask: 0.3249  decode.d1.loss_dice: 0.3132  decode.d2.loss_cls: 0.3534  decode.d2.loss_mask: 0.3245  decode.d2.loss_dice: 0.3014  decode.d3.loss_cls: 0.2683  decode.d3.loss_mask: 0.3251  decode.d3.loss_dice: 0.3030  decode.d4.loss_cls: 0.2296  decode.d4.loss_mask: 0.3296  decode.d4.loss_dice: 0.3045  decode.d5.loss_cls: 0.2402  decode.d5.loss_mask: 0.3291  decode.d5.loss_dice: 0.3111  decode.d6.loss_cls: 0.1940  decode.d6.loss_mask: 0.3193  decode.d6.loss_dice: 0.2948  decode.d7.loss_cls: 0.2000  decode.d7.loss_mask: 0.3119  decode.d7.loss_dice: 0.2943  decode.d8.loss_cls: 0.1776  decode.d8.loss_mask: 0.3252  decode.d8.loss_dice: 0.3039
07/30 20:04:33 - mmengine - INFO - Iter(train) [28100/80000]  base_lr: 6.7745e-05 lr: 6.7745e-06  eta: 6:17:16  time: 0.4370  data_time: 0.0093  memory: 5261  grad_norm: 32.5523  loss: 6.8243  decode.loss_cls: 0.0599  decode.loss_mask: 0.2461  decode.loss_dice: 0.2715  decode.d0.loss_cls: 0.9014  decode.d0.loss_mask: 0.2586  decode.d0.loss_dice: 0.2945  decode.d1.loss_cls: 0.1290  decode.d1.loss_mask: 0.2487  decode.d1.loss_dice: 0.2710  decode.d2.loss_cls: 0.0389  decode.d2.loss_mask: 0.2501  decode.d2.loss_dice: 0.2895  decode.d3.loss_cls: 0.0668  decode.d3.loss_mask: 0.2490  decode.d3.loss_dice: 0.2898  decode.d4.loss_cls: 0.0590  decode.d4.loss_mask: 0.2480  decode.d4.loss_dice: 0.2820  decode.d5.loss_cls: 0.0594  decode.d5.loss_mask: 0.2471  decode.d5.loss_dice: 0.2830  decode.d6.loss_cls: 0.0549  decode.d6.loss_mask: 0.2501  decode.d6.loss_dice: 0.2805  decode.d7.loss_cls: 0.0633  decode.d7.loss_mask: 0.2493  decode.d7.loss_dice: 0.2870  decode.d8.loss_cls: 0.0598  decode.d8.loss_mask: 0.2473  decode.d8.loss_dice: 0.2888
07/30 20:04:55 - mmengine - INFO - Iter(train) [28150/80000]  base_lr: 6.7686e-05 lr: 6.7686e-06  eta: 6:16:54  time: 0.4375  data_time: 0.0094  memory: 5261  grad_norm: 46.9359  loss: 7.1155  decode.loss_cls: 0.1454  decode.loss_mask: 0.2128  decode.loss_dice: 0.2559  decode.d0.loss_cls: 0.8512  decode.d0.loss_mask: 0.2244  decode.d0.loss_dice: 0.2830  decode.d1.loss_cls: 0.2143  decode.d1.loss_mask: 0.2177  decode.d1.loss_dice: 0.2529  decode.d2.loss_cls: 0.1832  decode.d2.loss_mask: 0.2183  decode.d2.loss_dice: 0.2802  decode.d3.loss_cls: 0.1770  decode.d3.loss_mask: 0.2199  decode.d3.loss_dice: 0.2486  decode.d4.loss_cls: 0.1695  decode.d4.loss_mask: 0.2137  decode.d4.loss_dice: 0.2638  decode.d5.loss_cls: 0.1640  decode.d5.loss_mask: 0.2110  decode.d5.loss_dice: 0.2511  decode.d6.loss_cls: 0.1608  decode.d6.loss_mask: 0.2151  decode.d6.loss_dice: 0.2569  decode.d7.loss_cls: 0.1358  decode.d7.loss_mask: 0.2127  decode.d7.loss_dice: 0.2576  decode.d8.loss_cls: 0.1346  decode.d8.loss_mask: 0.2146  decode.d8.loss_dice: 0.2695
07/30 20:05:17 - mmengine - INFO - Iter(train) [28200/80000]  base_lr: 6.7627e-05 lr: 6.7627e-06  eta: 6:16:33  time: 0.4368  data_time: 0.0094  memory: 5278  grad_norm: 63.4776  loss: 7.4496  decode.loss_cls: 0.1749  decode.loss_mask: 0.2176  decode.loss_dice: 0.2565  decode.d0.loss_cls: 0.9892  decode.d0.loss_mask: 0.2212  decode.d0.loss_dice: 0.2683  decode.d1.loss_cls: 0.2620  decode.d1.loss_mask: 0.2205  decode.d1.loss_dice: 0.2521  decode.d2.loss_cls: 0.2309  decode.d2.loss_mask: 0.2168  decode.d2.loss_dice: 0.2666  decode.d3.loss_cls: 0.1442  decode.d3.loss_mask: 0.2188  decode.d3.loss_dice: 0.2753  decode.d4.loss_cls: 0.1457  decode.d4.loss_mask: 0.2176  decode.d4.loss_dice: 0.2881  decode.d5.loss_cls: 0.1957  decode.d5.loss_mask: 0.2164  decode.d5.loss_dice: 0.2650  decode.d6.loss_cls: 0.1350  decode.d6.loss_mask: 0.2301  decode.d6.loss_dice: 0.2945  decode.d7.loss_cls: 0.1286  decode.d7.loss_mask: 0.2173  decode.d7.loss_dice: 0.2752  decode.d8.loss_cls: 0.1475  decode.d8.loss_mask: 0.2163  decode.d8.loss_dice: 0.2619
07/30 20:05:39 - mmengine - INFO - Iter(train) [28250/80000]  base_lr: 6.7568e-05 lr: 6.7568e-06  eta: 6:16:11  time: 0.4376  data_time: 0.0094  memory: 5265  grad_norm: 50.5702  loss: 6.9425  decode.loss_cls: 0.1596  decode.loss_mask: 0.2022  decode.loss_dice: 0.2324  decode.d0.loss_cls: 0.9552  decode.d0.loss_mask: 0.2133  decode.d0.loss_dice: 0.2540  decode.d1.loss_cls: 0.2044  decode.d1.loss_mask: 0.2088  decode.d1.loss_dice: 0.2284  decode.d2.loss_cls: 0.1747  decode.d2.loss_mask: 0.2070  decode.d2.loss_dice: 0.2354  decode.d3.loss_cls: 0.1827  decode.d3.loss_mask: 0.2052  decode.d3.loss_dice: 0.2334  decode.d4.loss_cls: 0.1818  decode.d4.loss_mask: 0.2025  decode.d4.loss_dice: 0.2352  decode.d5.loss_cls: 0.1850  decode.d5.loss_mask: 0.2006  decode.d5.loss_dice: 0.2404  decode.d6.loss_cls: 0.1632  decode.d6.loss_mask: 0.2066  decode.d6.loss_dice: 0.2469  decode.d7.loss_cls: 0.1508  decode.d7.loss_mask: 0.2026  decode.d7.loss_dice: 0.2455  decode.d8.loss_cls: 0.1522  decode.d8.loss_mask: 0.2029  decode.d8.loss_dice: 0.2296
07/30 20:06:01 - mmengine - INFO - Iter(train) [28300/80000]  base_lr: 6.7510e-05 lr: 6.7510e-06  eta: 6:15:49  time: 0.4370  data_time: 0.0094  memory: 5261  grad_norm: 60.8749  loss: 6.5084  decode.loss_cls: 0.0989  decode.loss_mask: 0.1961  decode.loss_dice: 0.2444  decode.d0.loss_cls: 0.9692  decode.d0.loss_mask: 0.2081  decode.d0.loss_dice: 0.2636  decode.d1.loss_cls: 0.2062  decode.d1.loss_mask: 0.2003  decode.d1.loss_dice: 0.2615  decode.d2.loss_cls: 0.1212  decode.d2.loss_mask: 0.1939  decode.d2.loss_dice: 0.2356  decode.d3.loss_cls: 0.1280  decode.d3.loss_mask: 0.1936  decode.d3.loss_dice: 0.2325  decode.d4.loss_cls: 0.1429  decode.d4.loss_mask: 0.1963  decode.d4.loss_dice: 0.2368  decode.d5.loss_cls: 0.1028  decode.d5.loss_mask: 0.1946  decode.d5.loss_dice: 0.2311  decode.d6.loss_cls: 0.1155  decode.d6.loss_mask: 0.1942  decode.d6.loss_dice: 0.2357  decode.d7.loss_cls: 0.1266  decode.d7.loss_mask: 0.1975  decode.d7.loss_dice: 0.2397  decode.d8.loss_cls: 0.1012  decode.d8.loss_mask: 0.1963  decode.d8.loss_dice: 0.2441
07/30 20:06:23 - mmengine - INFO - Iter(train) [28350/80000]  base_lr: 6.7451e-05 lr: 6.7451e-06  eta: 6:15:27  time: 0.4367  data_time: 0.0095  memory: 5265  grad_norm: 120.2333  loss: 9.2274  decode.loss_cls: 0.2692  decode.loss_mask: 0.2868  decode.loss_dice: 0.2770  decode.d0.loss_cls: 1.1061  decode.d0.loss_mask: 0.3131  decode.d0.loss_dice: 0.3047  decode.d1.loss_cls: 0.3001  decode.d1.loss_mask: 0.2910  decode.d1.loss_dice: 0.2875  decode.d2.loss_cls: 0.2234  decode.d2.loss_mask: 0.2891  decode.d2.loss_dice: 0.2793  decode.d3.loss_cls: 0.2345  decode.d3.loss_mask: 0.2894  decode.d3.loss_dice: 0.2855  decode.d4.loss_cls: 0.2857  decode.d4.loss_mask: 0.2854  decode.d4.loss_dice: 0.2824  decode.d5.loss_cls: 0.2687  decode.d5.loss_mask: 0.2903  decode.d5.loss_dice: 0.2849  decode.d6.loss_cls: 0.2570  decode.d6.loss_mask: 0.2882  decode.d6.loss_dice: 0.2775  decode.d7.loss_cls: 0.2573  decode.d7.loss_mask: 0.2886  decode.d7.loss_dice: 0.2847  decode.d8.loss_cls: 0.2739  decode.d8.loss_mask: 0.2853  decode.d8.loss_dice: 0.2807
07/30 20:06:44 - mmengine - INFO - Iter(train) [28400/80000]  base_lr: 6.7392e-05 lr: 6.7392e-06  eta: 6:15:06  time: 0.4372  data_time: 0.0095  memory: 5279  grad_norm: 124.0892  loss: 11.2217  decode.loss_cls: 0.3329  decode.loss_mask: 0.2733  decode.loss_dice: 0.3822  decode.d0.loss_cls: 1.2656  decode.d0.loss_mask: 0.2743  decode.d0.loss_dice: 0.3431  decode.d1.loss_cls: 0.5670  decode.d1.loss_mask: 0.2730  decode.d1.loss_dice: 0.3454  decode.d2.loss_cls: 0.4380  decode.d2.loss_mask: 0.2779  decode.d2.loss_dice: 0.3273  decode.d3.loss_cls: 0.4195  decode.d3.loss_mask: 0.2726  decode.d3.loss_dice: 0.3641  decode.d4.loss_cls: 0.4205  decode.d4.loss_mask: 0.2686  decode.d4.loss_dice: 0.3665  decode.d5.loss_cls: 0.3590  decode.d5.loss_mask: 0.2734  decode.d5.loss_dice: 0.3571  decode.d6.loss_cls: 0.4053  decode.d6.loss_mask: 0.2680  decode.d6.loss_dice: 0.3352  decode.d7.loss_cls: 0.3721  decode.d7.loss_mask: 0.2733  decode.d7.loss_dice: 0.3678  decode.d8.loss_cls: 0.3635  decode.d8.loss_mask: 0.2721  decode.d8.loss_dice: 0.3635
07/30 20:07:06 - mmengine - INFO - Iter(train) [28450/80000]  base_lr: 6.7333e-05 lr: 6.7333e-06  eta: 6:14:44  time: 0.4364  data_time: 0.0095  memory: 5244  grad_norm: 90.1179  loss: 9.1760  decode.loss_cls: 0.2099  decode.loss_mask: 0.2735  decode.loss_dice: 0.3223  decode.d0.loss_cls: 1.0547  decode.d0.loss_mask: 0.2982  decode.d0.loss_dice: 0.3338  decode.d1.loss_cls: 0.2698  decode.d1.loss_mask: 0.2819  decode.d1.loss_dice: 0.3356  decode.d2.loss_cls: 0.2384  decode.d2.loss_mask: 0.2742  decode.d2.loss_dice: 0.3200  decode.d3.loss_cls: 0.2235  decode.d3.loss_mask: 0.2736  decode.d3.loss_dice: 0.3217  decode.d4.loss_cls: 0.2152  decode.d4.loss_mask: 0.2728  decode.d4.loss_dice: 0.3369  decode.d5.loss_cls: 0.1938  decode.d5.loss_mask: 0.2723  decode.d5.loss_dice: 0.3357  decode.d6.loss_cls: 0.2398  decode.d6.loss_mask: 0.2733  decode.d6.loss_dice: 0.3177  decode.d7.loss_cls: 0.2541  decode.d7.loss_mask: 0.2700  decode.d7.loss_dice: 0.3261  decode.d8.loss_cls: 0.2397  decode.d8.loss_mask: 0.2706  decode.d8.loss_dice: 0.3270
07/30 20:07:28 - mmengine - INFO - Iter(train) [28500/80000]  base_lr: 6.7274e-05 lr: 6.7274e-06  eta: 6:14:22  time: 0.4379  data_time: 0.0096  memory: 5246  grad_norm: 58.6487  loss: 7.6102  decode.loss_cls: 0.1375  decode.loss_mask: 0.2107  decode.loss_dice: 0.3017  decode.d0.loss_cls: 1.1099  decode.d0.loss_mask: 0.2150  decode.d0.loss_dice: 0.3080  decode.d1.loss_cls: 0.2557  decode.d1.loss_mask: 0.2068  decode.d1.loss_dice: 0.2865  decode.d2.loss_cls: 0.1764  decode.d2.loss_mask: 0.2065  decode.d2.loss_dice: 0.2793  decode.d3.loss_cls: 0.1410  decode.d3.loss_mask: 0.2108  decode.d3.loss_dice: 0.2955  decode.d4.loss_cls: 0.1616  decode.d4.loss_mask: 0.2075  decode.d4.loss_dice: 0.2795  decode.d5.loss_cls: 0.1357  decode.d5.loss_mask: 0.2112  decode.d5.loss_dice: 0.3115  decode.d6.loss_cls: 0.1453  decode.d6.loss_mask: 0.2099  decode.d6.loss_dice: 0.2998  decode.d7.loss_cls: 0.1460  decode.d7.loss_mask: 0.2082  decode.d7.loss_dice: 0.3051  decode.d8.loss_cls: 0.1421  decode.d8.loss_mask: 0.2092  decode.d8.loss_dice: 0.2962
07/30 20:07:50 - mmengine - INFO - Iter(train) [28550/80000]  base_lr: 6.7216e-05 lr: 6.7216e-06  eta: 6:14:00  time: 0.4373  data_time: 0.0095  memory: 5265  grad_norm: 72.6667  loss: 6.4996  decode.loss_cls: 0.1384  decode.loss_mask: 0.2040  decode.loss_dice: 0.2256  decode.d0.loss_cls: 0.9371  decode.d0.loss_mask: 0.2158  decode.d0.loss_dice: 0.2647  decode.d1.loss_cls: 0.1184  decode.d1.loss_mask: 0.2139  decode.d1.loss_dice: 0.2516  decode.d2.loss_cls: 0.1084  decode.d2.loss_mask: 0.2104  decode.d2.loss_dice: 0.2329  decode.d3.loss_cls: 0.1065  decode.d3.loss_mask: 0.2093  decode.d3.loss_dice: 0.2167  decode.d4.loss_cls: 0.0826  decode.d4.loss_mask: 0.2091  decode.d4.loss_dice: 0.2432  decode.d5.loss_cls: 0.0991  decode.d5.loss_mask: 0.2123  decode.d5.loss_dice: 0.2543  decode.d6.loss_cls: 0.1307  decode.d6.loss_mask: 0.2101  decode.d6.loss_dice: 0.2401  decode.d7.loss_cls: 0.1244  decode.d7.loss_mask: 0.2080  decode.d7.loss_dice: 0.2444  decode.d8.loss_cls: 0.1430  decode.d8.loss_mask: 0.2072  decode.d8.loss_dice: 0.2375
07/30 20:08:12 - mmengine - INFO - Iter(train) [28600/80000]  base_lr: 6.7157e-05 lr: 6.7157e-06  eta: 6:13:39  time: 0.4374  data_time: 0.0096  memory: 5246  grad_norm: 62.0311  loss: 8.3212  decode.loss_cls: 0.1315  decode.loss_mask: 0.2482  decode.loss_dice: 0.3637  decode.d0.loss_cls: 1.0323  decode.d0.loss_mask: 0.2626  decode.d0.loss_dice: 0.3979  decode.d1.loss_cls: 0.1752  decode.d1.loss_mask: 0.2512  decode.d1.loss_dice: 0.3638  decode.d2.loss_cls: 0.1196  decode.d2.loss_mask: 0.2523  decode.d2.loss_dice: 0.3671  decode.d3.loss_cls: 0.1380  decode.d3.loss_mask: 0.2503  decode.d3.loss_dice: 0.3597  decode.d4.loss_cls: 0.1196  decode.d4.loss_mask: 0.2502  decode.d4.loss_dice: 0.3656  decode.d5.loss_cls: 0.1090  decode.d5.loss_mask: 0.2468  decode.d5.loss_dice: 0.3597  decode.d6.loss_cls: 0.1139  decode.d6.loss_mask: 0.2498  decode.d6.loss_dice: 0.3541  decode.d7.loss_cls: 0.1119  decode.d7.loss_mask: 0.2493  decode.d7.loss_dice: 0.3549  decode.d8.loss_cls: 0.1087  decode.d8.loss_mask: 0.2492  decode.d8.loss_dice: 0.3652
07/30 20:08:34 - mmengine - INFO - Iter(train) [28650/80000]  base_lr: 6.7098e-05 lr: 6.7098e-06  eta: 6:13:17  time: 0.4366  data_time: 0.0095  memory: 5279  grad_norm: 82.3445  loss: 9.6691  decode.loss_cls: 0.1954  decode.loss_mask: 0.2804  decode.loss_dice: 0.3587  decode.d0.loss_cls: 1.0349  decode.d0.loss_mask: 0.2911  decode.d0.loss_dice: 0.4397  decode.d1.loss_cls: 0.2690  decode.d1.loss_mask: 0.2847  decode.d1.loss_dice: 0.3691  decode.d2.loss_cls: 0.2438  decode.d2.loss_mask: 0.2795  decode.d2.loss_dice: 0.3378  decode.d3.loss_cls: 0.2500  decode.d3.loss_mask: 0.2820  decode.d3.loss_dice: 0.3536  decode.d4.loss_cls: 0.2320  decode.d4.loss_mask: 0.2781  decode.d4.loss_dice: 0.3715  decode.d5.loss_cls: 0.2078  decode.d5.loss_mask: 0.2776  decode.d5.loss_dice: 0.3460  decode.d6.loss_cls: 0.2427  decode.d6.loss_mask: 0.2898  decode.d6.loss_dice: 0.3762  decode.d7.loss_cls: 0.2143  decode.d7.loss_mask: 0.2849  decode.d7.loss_dice: 0.3783  decode.d8.loss_cls: 0.2387  decode.d8.loss_mask: 0.2838  decode.d8.loss_dice: 0.3777
07/30 20:08:56 - mmengine - INFO - Iter(train) [28700/80000]  base_lr: 6.7039e-05 lr: 6.7039e-06  eta: 6:12:55  time: 0.4368  data_time: 0.0095  memory: 5304  grad_norm: 89.6566  loss: 8.4762  decode.loss_cls: 0.2477  decode.loss_mask: 0.2562  decode.loss_dice: 0.3129  decode.d0.loss_cls: 0.9683  decode.d0.loss_mask: 0.2612  decode.d0.loss_dice: 0.3120  decode.d1.loss_cls: 0.2578  decode.d1.loss_mask: 0.2600  decode.d1.loss_dice: 0.2832  decode.d2.loss_cls: 0.2171  decode.d2.loss_mask: 0.2578  decode.d2.loss_dice: 0.3160  decode.d3.loss_cls: 0.1877  decode.d3.loss_mask: 0.2586  decode.d3.loss_dice: 0.3196  decode.d4.loss_cls: 0.1479  decode.d4.loss_mask: 0.2570  decode.d4.loss_dice: 0.3209  decode.d5.loss_cls: 0.1980  decode.d5.loss_mask: 0.2576  decode.d5.loss_dice: 0.3172  decode.d6.loss_cls: 0.1579  decode.d6.loss_mask: 0.2562  decode.d6.loss_dice: 0.3322  decode.d7.loss_cls: 0.1670  decode.d7.loss_mask: 0.2593  decode.d7.loss_dice: 0.3119  decode.d8.loss_cls: 0.2080  decode.d8.loss_mask: 0.2589  decode.d8.loss_dice: 0.3101
07/30 20:09:17 - mmengine - INFO - Iter(train) [28750/80000]  base_lr: 6.6980e-05 lr: 6.6980e-06  eta: 6:12:33  time: 0.4367  data_time: 0.0094  memory: 5265  grad_norm: 100.9385  loss: 9.0065  decode.loss_cls: 0.3017  decode.loss_mask: 0.2233  decode.loss_dice: 0.2716  decode.d0.loss_cls: 0.9584  decode.d0.loss_mask: 0.2356  decode.d0.loss_dice: 0.2955  decode.d1.loss_cls: 0.3617  decode.d1.loss_mask: 0.2256  decode.d1.loss_dice: 0.2774  decode.d2.loss_cls: 0.3214  decode.d2.loss_mask: 0.2280  decode.d2.loss_dice: 0.2905  decode.d3.loss_cls: 0.3673  decode.d3.loss_mask: 0.2269  decode.d3.loss_dice: 0.2899  decode.d4.loss_cls: 0.2878  decode.d4.loss_mask: 0.2238  decode.d4.loss_dice: 0.2795  decode.d5.loss_cls: 0.3020  decode.d5.loss_mask: 0.2290  decode.d5.loss_dice: 0.2919  decode.d6.loss_cls: 0.2979  decode.d6.loss_mask: 0.2252  decode.d6.loss_dice: 0.2935  decode.d7.loss_cls: 0.3225  decode.d7.loss_mask: 0.2227  decode.d7.loss_dice: 0.2752  decode.d8.loss_cls: 0.3726  decode.d8.loss_mask: 0.2249  decode.d8.loss_dice: 0.2831
07/30 20:09:39 - mmengine - INFO - Iter(train) [28800/80000]  base_lr: 6.6922e-05 lr: 6.6922e-06  eta: 6:12:12  time: 0.4367  data_time: 0.0095  memory: 5277  grad_norm: 102.0049  loss: 7.8936  decode.loss_cls: 0.1261  decode.loss_mask: 0.2443  decode.loss_dice: 0.3010  decode.d0.loss_cls: 0.9390  decode.d0.loss_mask: 0.2491  decode.d0.loss_dice: 0.3162  decode.d1.loss_cls: 0.1684  decode.d1.loss_mask: 0.2530  decode.d1.loss_dice: 0.2938  decode.d2.loss_cls: 0.0954  decode.d2.loss_mask: 0.2513  decode.d2.loss_dice: 0.2978  decode.d3.loss_cls: 0.1737  decode.d3.loss_mask: 0.2590  decode.d3.loss_dice: 0.3009  decode.d4.loss_cls: 0.1878  decode.d4.loss_mask: 0.2701  decode.d4.loss_dice: 0.3092  decode.d5.loss_cls: 0.1720  decode.d5.loss_mask: 0.2628  decode.d5.loss_dice: 0.3001  decode.d6.loss_cls: 0.2298  decode.d6.loss_mask: 0.2668  decode.d6.loss_dice: 0.2952  decode.d7.loss_cls: 0.1104  decode.d7.loss_mask: 0.2523  decode.d7.loss_dice: 0.2985  decode.d8.loss_cls: 0.1139  decode.d8.loss_mask: 0.2499  decode.d8.loss_dice: 0.3059
07/30 20:10:01 - mmengine - INFO - Iter(train) [28850/80000]  base_lr: 6.6863e-05 lr: 6.6863e-06  eta: 6:11:50  time: 0.4378  data_time: 0.0094  memory: 5279  grad_norm: 107.9925  loss: 8.0704  decode.loss_cls: 0.2151  decode.loss_mask: 0.2424  decode.loss_dice: 0.2622  decode.d0.loss_cls: 1.0797  decode.d0.loss_mask: 0.2443  decode.d0.loss_dice: 0.2677  decode.d1.loss_cls: 0.2412  decode.d1.loss_mask: 0.2395  decode.d1.loss_dice: 0.2588  decode.d2.loss_cls: 0.2591  decode.d2.loss_mask: 0.2524  decode.d2.loss_dice: 0.2527  decode.d3.loss_cls: 0.1803  decode.d3.loss_mask: 0.2543  decode.d3.loss_dice: 0.2671  decode.d4.loss_cls: 0.1587  decode.d4.loss_mask: 0.2439  decode.d4.loss_dice: 0.2620  decode.d5.loss_cls: 0.2362  decode.d5.loss_mask: 0.2423  decode.d5.loss_dice: 0.2707  decode.d6.loss_cls: 0.2024  decode.d6.loss_mask: 0.2447  decode.d6.loss_dice: 0.2726  decode.d7.loss_cls: 0.2068  decode.d7.loss_mask: 0.2432  decode.d7.loss_dice: 0.2696  decode.d8.loss_cls: 0.1935  decode.d8.loss_mask: 0.2413  decode.d8.loss_dice: 0.2658
07/30 20:10:23 - mmengine - INFO - Iter(train) [28900/80000]  base_lr: 6.6804e-05 lr: 6.6804e-06  eta: 6:11:28  time: 0.4378  data_time: 0.0095  memory: 5279  grad_norm: 67.2061  loss: 8.2630  decode.loss_cls: 0.1403  decode.loss_mask: 0.2627  decode.loss_dice: 0.2944  decode.d0.loss_cls: 1.1569  decode.d0.loss_mask: 0.2558  decode.d0.loss_dice: 0.2712  decode.d1.loss_cls: 0.2022  decode.d1.loss_mask: 0.2521  decode.d1.loss_dice: 0.2698  decode.d2.loss_cls: 0.2004  decode.d2.loss_mask: 0.2532  decode.d2.loss_dice: 0.2774  decode.d3.loss_cls: 0.1587  decode.d3.loss_mask: 0.2597  decode.d3.loss_dice: 0.2860  decode.d4.loss_cls: 0.1514  decode.d4.loss_mask: 0.2619  decode.d4.loss_dice: 0.2852  decode.d5.loss_cls: 0.2049  decode.d5.loss_mask: 0.2632  decode.d5.loss_dice: 0.3036  decode.d6.loss_cls: 0.1787  decode.d6.loss_mask: 0.2887  decode.d6.loss_dice: 0.3130  decode.d7.loss_cls: 0.1846  decode.d7.loss_mask: 0.2617  decode.d7.loss_dice: 0.3060  decode.d8.loss_cls: 0.1337  decode.d8.loss_mask: 0.2676  decode.d8.loss_dice: 0.3178
07/30 20:10:45 - mmengine - INFO - Iter(train) [28950/80000]  base_lr: 6.6745e-05 lr: 6.6745e-06  eta: 6:11:07  time: 0.4374  data_time: 0.0095  memory: 5244  grad_norm: 110.7887  loss: 9.1234  decode.loss_cls: 0.2616  decode.loss_mask: 0.2591  decode.loss_dice: 0.3033  decode.d0.loss_cls: 0.9413  decode.d0.loss_mask: 0.2745  decode.d0.loss_dice: 0.3150  decode.d1.loss_cls: 0.2816  decode.d1.loss_mask: 0.2647  decode.d1.loss_dice: 0.2862  decode.d2.loss_cls: 0.2623  decode.d2.loss_mask: 0.2905  decode.d2.loss_dice: 0.2995  decode.d3.loss_cls: 0.2822  decode.d3.loss_mask: 0.2576  decode.d3.loss_dice: 0.3097  decode.d4.loss_cls: 0.2939  decode.d4.loss_mask: 0.2576  decode.d4.loss_dice: 0.2927  decode.d5.loss_cls: 0.3097  decode.d5.loss_mask: 0.2587  decode.d5.loss_dice: 0.2874  decode.d6.loss_cls: 0.2989  decode.d6.loss_mask: 0.2623  decode.d6.loss_dice: 0.2895  decode.d7.loss_cls: 0.2688  decode.d7.loss_mask: 0.2619  decode.d7.loss_dice: 0.3120  decode.d8.loss_cls: 0.2866  decode.d8.loss_mask: 0.2558  decode.d8.loss_dice: 0.2984
07/30 20:11:07 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 20:11:07 - mmengine - INFO - Iter(train) [29000/80000]  base_lr: 6.6686e-05 lr: 6.6686e-06  eta: 6:10:45  time: 0.4366  data_time: 0.0094  memory: 5279  grad_norm: 237.1857  loss: 8.7310  decode.loss_cls: 0.0697  decode.loss_mask: 0.3686  decode.loss_dice: 0.3493  decode.d0.loss_cls: 0.7918  decode.d0.loss_mask: 0.3958  decode.d0.loss_dice: 0.3732  decode.d1.loss_cls: 0.1340  decode.d1.loss_mask: 0.3548  decode.d1.loss_dice: 0.3341  decode.d2.loss_cls: 0.1222  decode.d2.loss_mask: 0.3584  decode.d2.loss_dice: 0.3334  decode.d3.loss_cls: 0.1102  decode.d3.loss_mask: 0.3592  decode.d3.loss_dice: 0.3344  decode.d4.loss_cls: 0.0631  decode.d4.loss_mask: 0.3662  decode.d4.loss_dice: 0.3465  decode.d5.loss_cls: 0.0668  decode.d5.loss_mask: 0.3696  decode.d5.loss_dice: 0.3445  decode.d6.loss_cls: 0.0550  decode.d6.loss_mask: 0.3781  decode.d6.loss_dice: 0.3424  decode.d7.loss_cls: 0.0663  decode.d7.loss_mask: 0.3844  decode.d7.loss_dice: 0.3492  decode.d8.loss_cls: 0.0836  decode.d8.loss_mask: 0.3775  decode.d8.loss_dice: 0.3487
07/30 20:11:29 - mmengine - INFO - Iter(train) [29050/80000]  base_lr: 6.6628e-05 lr: 6.6628e-06  eta: 6:10:23  time: 0.4368  data_time: 0.0095  memory: 5244  grad_norm: 372.1710  loss: 7.8403  decode.loss_cls: 0.0603  decode.loss_mask: 0.3659  decode.loss_dice: 0.2835  decode.d0.loss_cls: 0.9106  decode.d0.loss_mask: 0.3719  decode.d0.loss_dice: 0.2970  decode.d1.loss_cls: 0.0206  decode.d1.loss_mask: 0.3681  decode.d1.loss_dice: 0.2861  decode.d2.loss_cls: 0.0499  decode.d2.loss_mask: 0.3688  decode.d2.loss_dice: 0.2880  decode.d3.loss_cls: 0.0453  decode.d3.loss_mask: 0.3646  decode.d3.loss_dice: 0.2985  decode.d4.loss_cls: 0.0396  decode.d4.loss_mask: 0.3650  decode.d4.loss_dice: 0.2829  decode.d5.loss_cls: 0.0384  decode.d5.loss_mask: 0.3686  decode.d5.loss_dice: 0.2842  decode.d6.loss_cls: 0.0448  decode.d6.loss_mask: 0.3680  decode.d6.loss_dice: 0.2819  decode.d7.loss_cls: 0.0422  decode.d7.loss_mask: 0.3691  decode.d7.loss_dice: 0.2815  decode.d8.loss_cls: 0.0512  decode.d8.loss_mask: 0.3649  decode.d8.loss_dice: 0.2789
07/30 20:11:50 - mmengine - INFO - Iter(train) [29100/80000]  base_lr: 6.6569e-05 lr: 6.6569e-06  eta: 6:10:01  time: 0.4369  data_time: 0.0094  memory: 5277  grad_norm: 37.6627  loss: 6.1449  decode.loss_cls: 0.0311  decode.loss_mask: 0.2111  decode.loss_dice: 0.2322  decode.d0.loss_cls: 1.0328  decode.d0.loss_mask: 0.2128  decode.d0.loss_dice: 0.2387  decode.d1.loss_cls: 0.0895  decode.d1.loss_mask: 0.2097  decode.d1.loss_dice: 0.2427  decode.d2.loss_cls: 0.1182  decode.d2.loss_mask: 0.2083  decode.d2.loss_dice: 0.2386  decode.d3.loss_cls: 0.0916  decode.d3.loss_mask: 0.2079  decode.d3.loss_dice: 0.2290  decode.d4.loss_cls: 0.0447  decode.d4.loss_mask: 0.2081  decode.d4.loss_dice: 0.2366  decode.d5.loss_cls: 0.1309  decode.d5.loss_mask: 0.2111  decode.d5.loss_dice: 0.2358  decode.d6.loss_cls: 0.0512  decode.d6.loss_mask: 0.2084  decode.d6.loss_dice: 0.2350  decode.d7.loss_cls: 0.0692  decode.d7.loss_mask: 0.2082  decode.d7.loss_dice: 0.2340  decode.d8.loss_cls: 0.0322  decode.d8.loss_mask: 0.2073  decode.d8.loss_dice: 0.2379
07/30 20:12:12 - mmengine - INFO - Iter(train) [29150/80000]  base_lr: 6.6510e-05 lr: 6.6510e-06  eta: 6:09:40  time: 0.4365  data_time: 0.0094  memory: 5279  grad_norm: 86.0788  loss: 7.0709  decode.loss_cls: 0.1990  decode.loss_mask: 0.2328  decode.loss_dice: 0.2471  decode.d0.loss_cls: 0.9528  decode.d0.loss_mask: 0.2418  decode.d0.loss_dice: 0.2639  decode.d1.loss_cls: 0.1453  decode.d1.loss_mask: 0.2368  decode.d1.loss_dice: 0.2629  decode.d2.loss_cls: 0.1267  decode.d2.loss_mask: 0.2361  decode.d2.loss_dice: 0.2519  decode.d3.loss_cls: 0.1449  decode.d3.loss_mask: 0.2315  decode.d3.loss_dice: 0.2664  decode.d4.loss_cls: 0.1424  decode.d4.loss_mask: 0.2322  decode.d4.loss_dice: 0.2353  decode.d5.loss_cls: 0.0989  decode.d5.loss_mask: 0.2337  decode.d5.loss_dice: 0.2658  decode.d6.loss_cls: 0.1262  decode.d6.loss_mask: 0.2381  decode.d6.loss_dice: 0.2656  decode.d7.loss_cls: 0.1132  decode.d7.loss_mask: 0.2367  decode.d7.loss_dice: 0.2444  decode.d8.loss_cls: 0.1052  decode.d8.loss_mask: 0.2304  decode.d8.loss_dice: 0.2629
07/30 20:12:34 - mmengine - INFO - Iter(train) [29200/80000]  base_lr: 6.6451e-05 lr: 6.6451e-06  eta: 6:09:18  time: 0.4368  data_time: 0.0094  memory: 5303  grad_norm: 89.6537  loss: 8.3276  decode.loss_cls: 0.1441  decode.loss_mask: 0.2633  decode.loss_dice: 0.2733  decode.d0.loss_cls: 1.2080  decode.d0.loss_mask: 0.2738  decode.d0.loss_dice: 0.2755  decode.d1.loss_cls: 0.1963  decode.d1.loss_mask: 0.2692  decode.d1.loss_dice: 0.2863  decode.d2.loss_cls: 0.2116  decode.d2.loss_mask: 0.2658  decode.d2.loss_dice: 0.2720  decode.d3.loss_cls: 0.1662  decode.d3.loss_mask: 0.2614  decode.d3.loss_dice: 0.2946  decode.d4.loss_cls: 0.2062  decode.d4.loss_mask: 0.2647  decode.d4.loss_dice: 0.2819  decode.d5.loss_cls: 0.2569  decode.d5.loss_mask: 0.2620  decode.d5.loss_dice: 0.2590  decode.d6.loss_cls: 0.1941  decode.d6.loss_mask: 0.2629  decode.d6.loss_dice: 0.2680  decode.d7.loss_cls: 0.1761  decode.d7.loss_mask: 0.2687  decode.d7.loss_dice: 0.2885  decode.d8.loss_cls: 0.1260  decode.d8.loss_mask: 0.2662  decode.d8.loss_dice: 0.2848
07/30 20:12:56 - mmengine - INFO - Iter(train) [29250/80000]  base_lr: 6.6392e-05 lr: 6.6392e-06  eta: 6:08:56  time: 0.4373  data_time: 0.0095  memory: 5261  grad_norm: 44.3097  loss: 7.6924  decode.loss_cls: 0.0881  decode.loss_mask: 0.2792  decode.loss_dice: 0.2883  decode.d0.loss_cls: 0.9779  decode.d0.loss_mask: 0.2871  decode.d0.loss_dice: 0.3036  decode.d1.loss_cls: 0.1351  decode.d1.loss_mask: 0.2850  decode.d1.loss_dice: 0.2983  decode.d2.loss_cls: 0.0837  decode.d2.loss_mask: 0.2819  decode.d2.loss_dice: 0.2998  decode.d3.loss_cls: 0.0980  decode.d3.loss_mask: 0.2796  decode.d3.loss_dice: 0.3157  decode.d4.loss_cls: 0.1170  decode.d4.loss_mask: 0.2764  decode.d4.loss_dice: 0.3070  decode.d5.loss_cls: 0.0790  decode.d5.loss_mask: 0.2792  decode.d5.loss_dice: 0.3103  decode.d6.loss_cls: 0.1243  decode.d6.loss_mask: 0.2783  decode.d6.loss_dice: 0.2981  decode.d7.loss_cls: 0.0751  decode.d7.loss_mask: 0.2818  decode.d7.loss_dice: 0.3023  decode.d8.loss_cls: 0.0772  decode.d8.loss_mask: 0.2800  decode.d8.loss_dice: 0.3049
07/30 20:13:18 - mmengine - INFO - Iter(train) [29300/80000]  base_lr: 6.6333e-05 lr: 6.6333e-06  eta: 6:08:34  time: 0.4364  data_time: 0.0092  memory: 5304  grad_norm: 101.1853  loss: 8.1874  decode.loss_cls: 0.2225  decode.loss_mask: 0.1932  decode.loss_dice: 0.2894  decode.d0.loss_cls: 0.9822  decode.d0.loss_mask: 0.2009  decode.d0.loss_dice: 0.3371  decode.d1.loss_cls: 0.2798  decode.d1.loss_mask: 0.1973  decode.d1.loss_dice: 0.2968  decode.d2.loss_cls: 0.2885  decode.d2.loss_mask: 0.1966  decode.d2.loss_dice: 0.2915  decode.d3.loss_cls: 0.2238  decode.d3.loss_mask: 0.1956  decode.d3.loss_dice: 0.3081  decode.d4.loss_cls: 0.2020  decode.d4.loss_mask: 0.1934  decode.d4.loss_dice: 0.3237  decode.d5.loss_cls: 0.2277  decode.d5.loss_mask: 0.1959  decode.d5.loss_dice: 0.3308  decode.d6.loss_cls: 0.2213  decode.d6.loss_mask: 0.1934  decode.d6.loss_dice: 0.3012  decode.d7.loss_cls: 0.2450  decode.d7.loss_mask: 0.1939  decode.d7.loss_dice: 0.3105  decode.d8.loss_cls: 0.2532  decode.d8.loss_mask: 0.1913  decode.d8.loss_dice: 0.3007
07/30 20:13:40 - mmengine - INFO - Iter(train) [29350/80000]  base_lr: 6.6274e-05 lr: 6.6274e-06  eta: 6:08:13  time: 0.4378  data_time: 0.0094  memory: 5279  grad_norm: 165.5506  loss: 9.4000  decode.loss_cls: 0.3103  decode.loss_mask: 0.2404  decode.loss_dice: 0.2935  decode.d0.loss_cls: 1.0699  decode.d0.loss_mask: 0.2500  decode.d0.loss_dice: 0.2997  decode.d1.loss_cls: 0.3768  decode.d1.loss_mask: 0.2485  decode.d1.loss_dice: 0.3110  decode.d2.loss_cls: 0.3038  decode.d2.loss_mask: 0.2401  decode.d2.loss_dice: 0.3063  decode.d3.loss_cls: 0.3172  decode.d3.loss_mask: 0.2417  decode.d3.loss_dice: 0.2926  decode.d4.loss_cls: 0.3067  decode.d4.loss_mask: 0.2393  decode.d4.loss_dice: 0.3060  decode.d5.loss_cls: 0.3271  decode.d5.loss_mask: 0.2388  decode.d5.loss_dice: 0.3123  decode.d6.loss_cls: 0.2813  decode.d6.loss_mask: 0.2408  decode.d6.loss_dice: 0.3142  decode.d7.loss_cls: 0.2839  decode.d7.loss_mask: 0.2427  decode.d7.loss_dice: 0.3380  decode.d8.loss_cls: 0.3324  decode.d8.loss_mask: 0.2423  decode.d8.loss_dice: 0.2927
07/30 20:14:02 - mmengine - INFO - Iter(train) [29400/80000]  base_lr: 6.6215e-05 lr: 6.6215e-06  eta: 6:07:51  time: 0.4373  data_time: 0.0095  memory: 5246  grad_norm: 47.9865  loss: 6.7372  decode.loss_cls: 0.0957  decode.loss_mask: 0.2417  decode.loss_dice: 0.2520  decode.d0.loss_cls: 0.9131  decode.d0.loss_mask: 0.2446  decode.d0.loss_dice: 0.2620  decode.d1.loss_cls: 0.1152  decode.d1.loss_mask: 0.2379  decode.d1.loss_dice: 0.2530  decode.d2.loss_cls: 0.0946  decode.d2.loss_mask: 0.2374  decode.d2.loss_dice: 0.2567  decode.d3.loss_cls: 0.1026  decode.d3.loss_mask: 0.2413  decode.d3.loss_dice: 0.2533  decode.d4.loss_cls: 0.1132  decode.d4.loss_mask: 0.2449  decode.d4.loss_dice: 0.2560  decode.d5.loss_cls: 0.0978  decode.d5.loss_mask: 0.2391  decode.d5.loss_dice: 0.2457  decode.d6.loss_cls: 0.0786  decode.d6.loss_mask: 0.2403  decode.d6.loss_dice: 0.2561  decode.d7.loss_cls: 0.0728  decode.d7.loss_mask: 0.2397  decode.d7.loss_dice: 0.2571  decode.d8.loss_cls: 0.0922  decode.d8.loss_mask: 0.2408  decode.d8.loss_dice: 0.2617
07/30 20:14:24 - mmengine - INFO - Iter(train) [29450/80000]  base_lr: 6.6157e-05 lr: 6.6157e-06  eta: 6:07:29  time: 0.4352  data_time: 0.0094  memory: 5244  grad_norm: 65.2281  loss: 7.6083  decode.loss_cls: 0.1299  decode.loss_mask: 0.2451  decode.loss_dice: 0.3174  decode.d0.loss_cls: 0.9000  decode.d0.loss_mask: 0.2558  decode.d0.loss_dice: 0.3061  decode.d1.loss_cls: 0.1789  decode.d1.loss_mask: 0.2586  decode.d1.loss_dice: 0.3052  decode.d2.loss_cls: 0.1389  decode.d2.loss_mask: 0.2429  decode.d2.loss_dice: 0.3120  decode.d3.loss_cls: 0.1344  decode.d3.loss_mask: 0.2444  decode.d3.loss_dice: 0.3119  decode.d4.loss_cls: 0.0988  decode.d4.loss_mask: 0.2462  decode.d4.loss_dice: 0.3355  decode.d5.loss_cls: 0.1114  decode.d5.loss_mask: 0.2440  decode.d5.loss_dice: 0.3203  decode.d6.loss_cls: 0.1007  decode.d6.loss_mask: 0.2396  decode.d6.loss_dice: 0.3198  decode.d7.loss_cls: 0.1049  decode.d7.loss_mask: 0.2451  decode.d7.loss_dice: 0.3131  decode.d8.loss_cls: 0.1106  decode.d8.loss_mask: 0.2396  decode.d8.loss_dice: 0.2971
07/30 20:14:45 - mmengine - INFO - Iter(train) [29500/80000]  base_lr: 6.6098e-05 lr: 6.6098e-06  eta: 6:07:08  time: 0.4359  data_time: 0.0094  memory: 5245  grad_norm: 68.8206  loss: 8.0039  decode.loss_cls: 0.2322  decode.loss_mask: 0.2494  decode.loss_dice: 0.2458  decode.d0.loss_cls: 1.0702  decode.d0.loss_mask: 0.2576  decode.d0.loss_dice: 0.2605  decode.d1.loss_cls: 0.2027  decode.d1.loss_mask: 0.2585  decode.d1.loss_dice: 0.2672  decode.d2.loss_cls: 0.1708  decode.d2.loss_mask: 0.2529  decode.d2.loss_dice: 0.2445  decode.d3.loss_cls: 0.1791  decode.d3.loss_mask: 0.2529  decode.d3.loss_dice: 0.2624  decode.d4.loss_cls: 0.2640  decode.d4.loss_mask: 0.2469  decode.d4.loss_dice: 0.2339  decode.d5.loss_cls: 0.2482  decode.d5.loss_mask: 0.2512  decode.d5.loss_dice: 0.2444  decode.d6.loss_cls: 0.2164  decode.d6.loss_mask: 0.2510  decode.d6.loss_dice: 0.2387  decode.d7.loss_cls: 0.1894  decode.d7.loss_mask: 0.2485  decode.d7.loss_dice: 0.2523  decode.d8.loss_cls: 0.2238  decode.d8.loss_mask: 0.2493  decode.d8.loss_dice: 0.2390
07/30 20:15:07 - mmengine - INFO - Iter(train) [29550/80000]  base_lr: 6.6039e-05 lr: 6.6039e-06  eta: 6:06:46  time: 0.4372  data_time: 0.0096  memory: 5279  grad_norm: 71.1109  loss: 6.7970  decode.loss_cls: 0.1008  decode.loss_mask: 0.2039  decode.loss_dice: 0.2781  decode.d0.loss_cls: 0.9698  decode.d0.loss_mask: 0.2117  decode.d0.loss_dice: 0.2957  decode.d1.loss_cls: 0.1865  decode.d1.loss_mask: 0.1982  decode.d1.loss_dice: 0.2811  decode.d2.loss_cls: 0.1256  decode.d2.loss_mask: 0.1989  decode.d2.loss_dice: 0.2608  decode.d3.loss_cls: 0.1654  decode.d3.loss_mask: 0.2027  decode.d3.loss_dice: 0.2595  decode.d4.loss_cls: 0.0903  decode.d4.loss_mask: 0.2050  decode.d4.loss_dice: 0.2668  decode.d5.loss_cls: 0.0895  decode.d5.loss_mask: 0.2061  decode.d5.loss_dice: 0.2725  decode.d6.loss_cls: 0.0560  decode.d6.loss_mask: 0.2053  decode.d6.loss_dice: 0.2744  decode.d7.loss_cls: 0.1306  decode.d7.loss_mask: 0.2019  decode.d7.loss_dice: 0.2711  decode.d8.loss_cls: 0.1051  decode.d8.loss_mask: 0.2048  decode.d8.loss_dice: 0.2790
07/30 20:15:29 - mmengine - INFO - Iter(train) [29600/80000]  base_lr: 6.5980e-05 lr: 6.5980e-06  eta: 6:06:24  time: 0.4373  data_time: 0.0095  memory: 5305  grad_norm: 29.7490  loss: 7.3061  decode.loss_cls: 0.0911  decode.loss_mask: 0.2135  decode.loss_dice: 0.3232  decode.d0.loss_cls: 0.8514  decode.d0.loss_mask: 0.2201  decode.d0.loss_dice: 0.3299  decode.d1.loss_cls: 0.1608  decode.d1.loss_mask: 0.2212  decode.d1.loss_dice: 0.2742  decode.d2.loss_cls: 0.1297  decode.d2.loss_mask: 0.2220  decode.d2.loss_dice: 0.2778  decode.d3.loss_cls: 0.1483  decode.d3.loss_mask: 0.2192  decode.d3.loss_dice: 0.2840  decode.d4.loss_cls: 0.1404  decode.d4.loss_mask: 0.2234  decode.d4.loss_dice: 0.2810  decode.d5.loss_cls: 0.1515  decode.d5.loss_mask: 0.2247  decode.d5.loss_dice: 0.2880  decode.d6.loss_cls: 0.1800  decode.d6.loss_mask: 0.2220  decode.d6.loss_dice: 0.2724  decode.d7.loss_cls: 0.1930  decode.d7.loss_mask: 0.2186  decode.d7.loss_dice: 0.2937  decode.d8.loss_cls: 0.1386  decode.d8.loss_mask: 0.2201  decode.d8.loss_dice: 0.2920
07/30 20:15:51 - mmengine - INFO - Iter(train) [29650/80000]  base_lr: 6.5921e-05 lr: 6.5921e-06  eta: 6:06:02  time: 0.4369  data_time: 0.0096  memory: 5265  grad_norm: 65.0110  loss: 7.7587  decode.loss_cls: 0.1530  decode.loss_mask: 0.2714  decode.loss_dice: 0.2817  decode.d0.loss_cls: 0.9150  decode.d0.loss_mask: 0.2795  decode.d0.loss_dice: 0.3092  decode.d1.loss_cls: 0.1343  decode.d1.loss_mask: 0.2756  decode.d1.loss_dice: 0.2822  decode.d2.loss_cls: 0.1475  decode.d2.loss_mask: 0.2706  decode.d2.loss_dice: 0.3009  decode.d3.loss_cls: 0.1244  decode.d3.loss_mask: 0.2676  decode.d3.loss_dice: 0.2819  decode.d4.loss_cls: 0.1454  decode.d4.loss_mask: 0.2699  decode.d4.loss_dice: 0.3115  decode.d5.loss_cls: 0.1486  decode.d5.loss_mask: 0.2670  decode.d5.loss_dice: 0.3127  decode.d6.loss_cls: 0.1102  decode.d6.loss_mask: 0.2672  decode.d6.loss_dice: 0.2761  decode.d7.loss_cls: 0.1228  decode.d7.loss_mask: 0.2702  decode.d7.loss_dice: 0.2877  decode.d8.loss_cls: 0.1283  decode.d8.loss_mask: 0.2707  decode.d8.loss_dice: 0.2757
07/30 20:16:13 - mmengine - INFO - Iter(train) [29700/80000]  base_lr: 6.5862e-05 lr: 6.5862e-06  eta: 6:05:41  time: 0.4379  data_time: 0.0095  memory: 5261  grad_norm: 67.0470  loss: 6.7708  decode.loss_cls: 0.1406  decode.loss_mask: 0.2014  decode.loss_dice: 0.2697  decode.d0.loss_cls: 1.0337  decode.d0.loss_mask: 0.2110  decode.d0.loss_dice: 0.2719  decode.d1.loss_cls: 0.1355  decode.d1.loss_mask: 0.2040  decode.d1.loss_dice: 0.2508  decode.d2.loss_cls: 0.1255  decode.d2.loss_mask: 0.2027  decode.d2.loss_dice: 0.2774  decode.d3.loss_cls: 0.1194  decode.d3.loss_mask: 0.2037  decode.d3.loss_dice: 0.2602  decode.d4.loss_cls: 0.0997  decode.d4.loss_mask: 0.2036  decode.d4.loss_dice: 0.2518  decode.d5.loss_cls: 0.1067  decode.d5.loss_mask: 0.2026  decode.d5.loss_dice: 0.2491  decode.d6.loss_cls: 0.1300  decode.d6.loss_mask: 0.2030  decode.d6.loss_dice: 0.2609  decode.d7.loss_cls: 0.1033  decode.d7.loss_mask: 0.2020  decode.d7.loss_dice: 0.2685  decode.d8.loss_cls: 0.1249  decode.d8.loss_mask: 0.2001  decode.d8.loss_dice: 0.2570
07/30 20:16:35 - mmengine - INFO - Iter(train) [29750/80000]  base_lr: 6.5803e-05 lr: 6.5803e-06  eta: 6:05:19  time: 0.4379  data_time: 0.0095  memory: 5229  grad_norm: 56.9758  loss: 6.8500  decode.loss_cls: 0.1581  decode.loss_mask: 0.1845  decode.loss_dice: 0.2419  decode.d0.loss_cls: 1.0857  decode.d0.loss_mask: 0.1910  decode.d0.loss_dice: 0.2556  decode.d1.loss_cls: 0.1980  decode.d1.loss_mask: 0.1851  decode.d1.loss_dice: 0.2405  decode.d2.loss_cls: 0.1432  decode.d2.loss_mask: 0.1841  decode.d2.loss_dice: 0.2360  decode.d3.loss_cls: 0.1416  decode.d3.loss_mask: 0.1831  decode.d3.loss_dice: 0.2324  decode.d4.loss_cls: 0.1522  decode.d4.loss_mask: 0.1856  decode.d4.loss_dice: 0.2483  decode.d5.loss_cls: 0.1164  decode.d5.loss_mask: 0.1864  decode.d5.loss_dice: 0.2376  decode.d6.loss_cls: 0.1192  decode.d6.loss_mask: 0.1942  decode.d6.loss_dice: 0.2631  decode.d7.loss_cls: 0.2059  decode.d7.loss_mask: 0.1909  decode.d7.loss_dice: 0.2633  decode.d8.loss_cls: 0.1391  decode.d8.loss_mask: 0.2136  decode.d8.loss_dice: 0.2734
07/30 20:16:57 - mmengine - INFO - Iter(train) [29800/80000]  base_lr: 6.5744e-05 lr: 6.5744e-06  eta: 6:04:57  time: 0.4376  data_time: 0.0096  memory: 5279  grad_norm: 59.3049  loss: 9.7069  decode.loss_cls: 0.3459  decode.loss_mask: 0.2273  decode.loss_dice: 0.2733  decode.d0.loss_cls: 1.3047  decode.d0.loss_mask: 0.2333  decode.d0.loss_dice: 0.3130  decode.d1.loss_cls: 0.3489  decode.d1.loss_mask: 0.2295  decode.d1.loss_dice: 0.3113  decode.d2.loss_cls: 0.3287  decode.d2.loss_mask: 0.2266  decode.d2.loss_dice: 0.3054  decode.d3.loss_cls: 0.3821  decode.d3.loss_mask: 0.2286  decode.d3.loss_dice: 0.2949  decode.d4.loss_cls: 0.3362  decode.d4.loss_mask: 0.2257  decode.d4.loss_dice: 0.3021  decode.d5.loss_cls: 0.4003  decode.d5.loss_mask: 0.2225  decode.d5.loss_dice: 0.2854  decode.d6.loss_cls: 0.3485  decode.d6.loss_mask: 0.2284  decode.d6.loss_dice: 0.2769  decode.d7.loss_cls: 0.3296  decode.d7.loss_mask: 0.2271  decode.d7.loss_dice: 0.2787  decode.d8.loss_cls: 0.3964  decode.d8.loss_mask: 0.2222  decode.d8.loss_dice: 0.2732
07/30 20:17:18 - mmengine - INFO - Iter(train) [29850/80000]  base_lr: 6.5685e-05 lr: 6.5685e-06  eta: 6:04:36  time: 0.4360  data_time: 0.0096  memory: 5246  grad_norm: 85.6805  loss: 7.9905  decode.loss_cls: 0.1787  decode.loss_mask: 0.2904  decode.loss_dice: 0.2455  decode.d0.loss_cls: 0.9298  decode.d0.loss_mask: 0.3054  decode.d0.loss_dice: 0.2352  decode.d1.loss_cls: 0.2196  decode.d1.loss_mask: 0.2966  decode.d1.loss_dice: 0.2725  decode.d2.loss_cls: 0.2087  decode.d2.loss_mask: 0.2906  decode.d2.loss_dice: 0.2386  decode.d3.loss_cls: 0.1843  decode.d3.loss_mask: 0.2911  decode.d3.loss_dice: 0.2402  decode.d4.loss_cls: 0.1876  decode.d4.loss_mask: 0.2886  decode.d4.loss_dice: 0.2432  decode.d5.loss_cls: 0.1904  decode.d5.loss_mask: 0.2828  decode.d5.loss_dice: 0.2491  decode.d6.loss_cls: 0.1922  decode.d6.loss_mask: 0.2844  decode.d6.loss_dice: 0.2414  decode.d7.loss_cls: 0.1632  decode.d7.loss_mask: 0.2925  decode.d7.loss_dice: 0.2411  decode.d8.loss_cls: 0.1852  decode.d8.loss_mask: 0.2906  decode.d8.loss_dice: 0.2311
07/30 20:17:40 - mmengine - INFO - Iter(train) [29900/80000]  base_lr: 6.5626e-05 lr: 6.5626e-06  eta: 6:04:14  time: 0.4369  data_time: 0.0094  memory: 5261  grad_norm: 73.0974  loss: 7.9465  decode.loss_cls: 0.1416  decode.loss_mask: 0.2645  decode.loss_dice: 0.2731  decode.d0.loss_cls: 0.9710  decode.d0.loss_mask: 0.2756  decode.d0.loss_dice: 0.2963  decode.d1.loss_cls: 0.1964  decode.d1.loss_mask: 0.2689  decode.d1.loss_dice: 0.2748  decode.d2.loss_cls: 0.1975  decode.d2.loss_mask: 0.2661  decode.d2.loss_dice: 0.2704  decode.d3.loss_cls: 0.1848  decode.d3.loss_mask: 0.2663  decode.d3.loss_dice: 0.2768  decode.d4.loss_cls: 0.1321  decode.d4.loss_mask: 0.2783  decode.d4.loss_dice: 0.2911  decode.d5.loss_cls: 0.1454  decode.d5.loss_mask: 0.2830  decode.d5.loss_dice: 0.2936  decode.d6.loss_cls: 0.1483  decode.d6.loss_mask: 0.2672  decode.d6.loss_dice: 0.2765  decode.d7.loss_cls: 0.1711  decode.d7.loss_mask: 0.2649  decode.d7.loss_dice: 0.2722  decode.d8.loss_cls: 0.1676  decode.d8.loss_mask: 0.2639  decode.d8.loss_dice: 0.2672
07/30 20:18:02 - mmengine - INFO - Iter(train) [29950/80000]  base_lr: 6.5567e-05 lr: 6.5567e-06  eta: 6:03:52  time: 0.4365  data_time: 0.0096  memory: 5278  grad_norm: 127.2691  loss: 9.0521  decode.loss_cls: 0.2776  decode.loss_mask: 0.2729  decode.loss_dice: 0.2679  decode.d0.loss_cls: 1.1839  decode.d0.loss_mask: 0.2855  decode.d0.loss_dice: 0.2991  decode.d1.loss_cls: 0.2189  decode.d1.loss_mask: 0.2795  decode.d1.loss_dice: 0.3032  decode.d2.loss_cls: 0.2712  decode.d2.loss_mask: 0.2754  decode.d2.loss_dice: 0.2709  decode.d3.loss_cls: 0.2062  decode.d3.loss_mask: 0.2748  decode.d3.loss_dice: 0.2576  decode.d4.loss_cls: 0.3236  decode.d4.loss_mask: 0.2762  decode.d4.loss_dice: 0.2833  decode.d5.loss_cls: 0.2454  decode.d5.loss_mask: 0.2745  decode.d5.loss_dice: 0.3126  decode.d6.loss_cls: 0.2416  decode.d6.loss_mask: 0.2765  decode.d6.loss_dice: 0.2816  decode.d7.loss_cls: 0.2589  decode.d7.loss_mask: 0.2770  decode.d7.loss_dice: 0.2799  decode.d8.loss_cls: 0.2229  decode.d8.loss_mask: 0.2740  decode.d8.loss_dice: 0.2793
07/30 20:18:24 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 20:18:24 - mmengine - INFO - Iter(train) [30000/80000]  base_lr: 6.5508e-05 lr: 6.5508e-06  eta: 6:03:30  time: 0.4373  data_time: 0.0092  memory: 5265  grad_norm: 118.7952  loss: 6.9102  decode.loss_cls: 0.0530  decode.loss_mask: 0.2734  decode.loss_dice: 0.2565  decode.d0.loss_cls: 1.0414  decode.d0.loss_mask: 0.2920  decode.d0.loss_dice: 0.2655  decode.d1.loss_cls: 0.0613  decode.d1.loss_mask: 0.2923  decode.d1.loss_dice: 0.2733  decode.d2.loss_cls: 0.0442  decode.d2.loss_mask: 0.2785  decode.d2.loss_dice: 0.2662  decode.d3.loss_cls: 0.0353  decode.d3.loss_mask: 0.2701  decode.d3.loss_dice: 0.2560  decode.d4.loss_cls: 0.0354  decode.d4.loss_mask: 0.2751  decode.d4.loss_dice: 0.2527  decode.d5.loss_cls: 0.0780  decode.d5.loss_mask: 0.2738  decode.d5.loss_dice: 0.2473  decode.d6.loss_cls: 0.0608  decode.d6.loss_mask: 0.2706  decode.d6.loss_dice: 0.2577  decode.d7.loss_cls: 0.0868  decode.d7.loss_mask: 0.2755  decode.d7.loss_dice: 0.2550  decode.d8.loss_cls: 0.0513  decode.d8.loss_mask: 0.2743  decode.d8.loss_dice: 0.2570
07/30 20:18:24 - mmengine - INFO - Saving checkpoint at 30000 iterations
07/30 20:18:48 - mmengine - INFO - Iter(train) [30050/80000]  base_lr: 6.5449e-05 lr: 6.5449e-06  eta: 6:03:12  time: 0.4362  data_time: 0.0094  memory: 5261  grad_norm: 130.8543  loss: 9.2358  decode.loss_cls: 0.2853  decode.loss_mask: 0.3274  decode.loss_dice: 0.2765  decode.d0.loss_cls: 1.1424  decode.d0.loss_mask: 0.3150  decode.d0.loss_dice: 0.2844  decode.d1.loss_cls: 0.3153  decode.d1.loss_mask: 0.3107  decode.d1.loss_dice: 0.2732  decode.d2.loss_cls: 0.1492  decode.d2.loss_mask: 0.3354  decode.d2.loss_dice: 0.2859  decode.d3.loss_cls: 0.2513  decode.d3.loss_mask: 0.3029  decode.d3.loss_dice: 0.3081  decode.d4.loss_cls: 0.2221  decode.d4.loss_mask: 0.2992  decode.d4.loss_dice: 0.2705  decode.d5.loss_cls: 0.2383  decode.d5.loss_mask: 0.2934  decode.d5.loss_dice: 0.2721  decode.d6.loss_cls: 0.1508  decode.d6.loss_mask: 0.3533  decode.d6.loss_dice: 0.2797  decode.d7.loss_cls: 0.2553  decode.d7.loss_mask: 0.2968  decode.d7.loss_dice: 0.2712  decode.d8.loss_cls: 0.1941  decode.d8.loss_mask: 0.3768  decode.d8.loss_dice: 0.2993
07/30 20:19:10 - mmengine - INFO - Iter(train) [30100/80000]  base_lr: 6.5390e-05 lr: 6.5390e-06  eta: 6:02:50  time: 0.4359  data_time: 0.0093  memory: 5261  grad_norm: 33.0092  loss: 5.1320  decode.loss_cls: 0.0264  decode.loss_mask: 0.1918  decode.loss_dice: 0.1969  decode.d0.loss_cls: 0.9323  decode.d0.loss_mask: 0.2002  decode.d0.loss_dice: 0.2130  decode.d1.loss_cls: 0.0481  decode.d1.loss_mask: 0.1973  decode.d1.loss_dice: 0.2046  decode.d2.loss_cls: 0.0329  decode.d2.loss_mask: 0.1897  decode.d2.loss_dice: 0.1962  decode.d3.loss_cls: 0.0370  decode.d3.loss_mask: 0.1920  decode.d3.loss_dice: 0.1957  decode.d4.loss_cls: 0.0398  decode.d4.loss_mask: 0.1932  decode.d4.loss_dice: 0.1924  decode.d5.loss_cls: 0.0302  decode.d5.loss_mask: 0.1927  decode.d5.loss_dice: 0.1894  decode.d6.loss_cls: 0.0241  decode.d6.loss_mask: 0.1925  decode.d6.loss_dice: 0.1945  decode.d7.loss_cls: 0.0210  decode.d7.loss_mask: 0.1942  decode.d7.loss_dice: 0.1968  decode.d8.loss_cls: 0.0260  decode.d8.loss_mask: 0.1934  decode.d8.loss_dice: 0.1977
07/30 20:19:32 - mmengine - INFO - Iter(train) [30150/80000]  base_lr: 6.5331e-05 lr: 6.5331e-06  eta: 6:02:28  time: 0.4364  data_time: 0.0092  memory: 5305  grad_norm: 68.4511  loss: 8.0277  decode.loss_cls: 0.1424  decode.loss_mask: 0.2543  decode.loss_dice: 0.2477  decode.d0.loss_cls: 1.2495  decode.d0.loss_mask: 0.2536  decode.d0.loss_dice: 0.2677  decode.d1.loss_cls: 0.2406  decode.d1.loss_mask: 0.2704  decode.d1.loss_dice: 0.2540  decode.d2.loss_cls: 0.2026  decode.d2.loss_mask: 0.2601  decode.d2.loss_dice: 0.2545  decode.d3.loss_cls: 0.1692  decode.d3.loss_mask: 0.2491  decode.d3.loss_dice: 0.2669  decode.d4.loss_cls: 0.1675  decode.d4.loss_mask: 0.2528  decode.d4.loss_dice: 0.2524  decode.d5.loss_cls: 0.1776  decode.d5.loss_mask: 0.2565  decode.d5.loss_dice: 0.2707  decode.d6.loss_cls: 0.1711  decode.d6.loss_mask: 0.2576  decode.d6.loss_dice: 0.2792  decode.d7.loss_cls: 0.1825  decode.d7.loss_mask: 0.2533  decode.d7.loss_dice: 0.2468  decode.d8.loss_cls: 0.1700  decode.d8.loss_mask: 0.2576  decode.d8.loss_dice: 0.2497
07/30 20:19:53 - mmengine - INFO - Iter(train) [30200/80000]  base_lr: 6.5273e-05 lr: 6.5273e-06  eta: 6:02:07  time: 0.4368  data_time: 0.0093  memory: 5279  grad_norm: 89.3350  loss: 8.4310  decode.loss_cls: 0.1367  decode.loss_mask: 0.3329  decode.loss_dice: 0.2776  decode.d0.loss_cls: 0.9730  decode.d0.loss_mask: 0.3651  decode.d0.loss_dice: 0.2995  decode.d1.loss_cls: 0.1460  decode.d1.loss_mask: 0.3556  decode.d1.loss_dice: 0.2787  decode.d2.loss_cls: 0.1421  decode.d2.loss_mask: 0.3579  decode.d2.loss_dice: 0.2868  decode.d3.loss_cls: 0.1708  decode.d3.loss_mask: 0.3464  decode.d3.loss_dice: 0.2778  decode.d4.loss_cls: 0.1568  decode.d4.loss_mask: 0.3425  decode.d4.loss_dice: 0.2886  decode.d5.loss_cls: 0.1086  decode.d5.loss_mask: 0.3408  decode.d5.loss_dice: 0.2856  decode.d6.loss_cls: 0.0854  decode.d6.loss_mask: 0.3327  decode.d6.loss_dice: 0.2876  decode.d7.loss_cls: 0.0854  decode.d7.loss_mask: 0.3349  decode.d7.loss_dice: 0.3011  decode.d8.loss_cls: 0.1295  decode.d8.loss_mask: 0.3322  decode.d8.loss_dice: 0.2724
07/30 20:20:15 - mmengine - INFO - Iter(train) [30250/80000]  base_lr: 6.5214e-05 lr: 6.5214e-06  eta: 6:01:45  time: 0.4365  data_time: 0.0094  memory: 5244  grad_norm: 62.1730  loss: 8.1526  decode.loss_cls: 0.1671  decode.loss_mask: 0.2017  decode.loss_dice: 0.3114  decode.d0.loss_cls: 0.9182  decode.d0.loss_mask: 0.2076  decode.d0.loss_dice: 0.3357  decode.d1.loss_cls: 0.2899  decode.d1.loss_mask: 0.2023  decode.d1.loss_dice: 0.2971  decode.d2.loss_cls: 0.2080  decode.d2.loss_mask: 0.1999  decode.d2.loss_dice: 0.3027  decode.d3.loss_cls: 0.2041  decode.d3.loss_mask: 0.2025  decode.d3.loss_dice: 0.3099  decode.d4.loss_cls: 0.2421  decode.d4.loss_mask: 0.2013  decode.d4.loss_dice: 0.3082  decode.d5.loss_cls: 0.2640  decode.d5.loss_mask: 0.1973  decode.d5.loss_dice: 0.3238  decode.d6.loss_cls: 0.2910  decode.d6.loss_mask: 0.1999  decode.d6.loss_dice: 0.3088  decode.d7.loss_cls: 0.2532  decode.d7.loss_mask: 0.2004  decode.d7.loss_dice: 0.3109  decode.d8.loss_cls: 0.2198  decode.d8.loss_mask: 0.1977  decode.d8.loss_dice: 0.2759
07/30 20:20:37 - mmengine - INFO - Iter(train) [30300/80000]  base_lr: 6.5155e-05 lr: 6.5155e-06  eta: 6:01:23  time: 0.4365  data_time: 0.0094  memory: 5226  grad_norm: 71.7032  loss: 6.9144  decode.loss_cls: 0.0980  decode.loss_mask: 0.2162  decode.loss_dice: 0.2566  decode.d0.loss_cls: 1.0828  decode.d0.loss_mask: 0.2246  decode.d0.loss_dice: 0.2703  decode.d1.loss_cls: 0.1033  decode.d1.loss_mask: 0.2175  decode.d1.loss_dice: 0.2794  decode.d2.loss_cls: 0.1413  decode.d2.loss_mask: 0.2159  decode.d2.loss_dice: 0.2604  decode.d3.loss_cls: 0.1212  decode.d3.loss_mask: 0.2127  decode.d3.loss_dice: 0.2564  decode.d4.loss_cls: 0.1762  decode.d4.loss_mask: 0.2120  decode.d4.loss_dice: 0.2538  decode.d5.loss_cls: 0.1617  decode.d5.loss_mask: 0.2140  decode.d5.loss_dice: 0.2461  decode.d6.loss_cls: 0.1336  decode.d6.loss_mask: 0.2116  decode.d6.loss_dice: 0.2413  decode.d7.loss_cls: 0.0689  decode.d7.loss_mask: 0.2119  decode.d7.loss_dice: 0.2501  decode.d8.loss_cls: 0.1188  decode.d8.loss_mask: 0.2103  decode.d8.loss_dice: 0.2476
07/30 20:20:59 - mmengine - INFO - Iter(train) [30350/80000]  base_lr: 6.5096e-05 lr: 6.5096e-06  eta: 6:01:01  time: 0.4355  data_time: 0.0095  memory: 5261  grad_norm: 63.4593  loss: 9.3303  decode.loss_cls: 0.2761  decode.loss_mask: 0.2765  decode.loss_dice: 0.3141  decode.d0.loss_cls: 1.0110  decode.d0.loss_mask: 0.2939  decode.d0.loss_dice: 0.3689  decode.d1.loss_cls: 0.2846  decode.d1.loss_mask: 0.2663  decode.d1.loss_dice: 0.3202  decode.d2.loss_cls: 0.2452  decode.d2.loss_mask: 0.2716  decode.d2.loss_dice: 0.3217  decode.d3.loss_cls: 0.2806  decode.d3.loss_mask: 0.2690  decode.d3.loss_dice: 0.3222  decode.d4.loss_cls: 0.2476  decode.d4.loss_mask: 0.2696  decode.d4.loss_dice: 0.3221  decode.d5.loss_cls: 0.2627  decode.d5.loss_mask: 0.2733  decode.d5.loss_dice: 0.3169  decode.d6.loss_cls: 0.2340  decode.d6.loss_mask: 0.2748  decode.d6.loss_dice: 0.3335  decode.d7.loss_cls: 0.2431  decode.d7.loss_mask: 0.2781  decode.d7.loss_dice: 0.3229  decode.d8.loss_cls: 0.2316  decode.d8.loss_mask: 0.2781  decode.d8.loss_dice: 0.3202
07/30 20:21:21 - mmengine - INFO - Iter(train) [30400/80000]  base_lr: 6.5037e-05 lr: 6.5037e-06  eta: 6:00:40  time: 0.4375  data_time: 0.0094  memory: 5305  grad_norm: 59.5451  loss: 8.4437  decode.loss_cls: 0.2922  decode.loss_mask: 0.2452  decode.loss_dice: 0.2745  decode.d0.loss_cls: 1.0015  decode.d0.loss_mask: 0.2323  decode.d0.loss_dice: 0.2715  decode.d1.loss_cls: 0.2817  decode.d1.loss_mask: 0.2308  decode.d1.loss_dice: 0.2607  decode.d2.loss_cls: 0.2595  decode.d2.loss_mask: 0.2475  decode.d2.loss_dice: 0.2676  decode.d3.loss_cls: 0.2685  decode.d3.loss_mask: 0.2423  decode.d3.loss_dice: 0.2673  decode.d4.loss_cls: 0.2481  decode.d4.loss_mask: 0.2299  decode.d4.loss_dice: 0.2649  decode.d5.loss_cls: 0.2191  decode.d5.loss_mask: 0.2336  decode.d5.loss_dice: 0.2614  decode.d6.loss_cls: 0.2335  decode.d6.loss_mask: 0.2441  decode.d6.loss_dice: 0.2685  decode.d7.loss_cls: 0.2644  decode.d7.loss_mask: 0.2483  decode.d7.loss_dice: 0.2885  decode.d8.loss_cls: 0.2519  decode.d8.loss_mask: 0.2567  decode.d8.loss_dice: 0.2875
07/30 20:21:43 - mmengine - INFO - Iter(train) [30450/80000]  base_lr: 6.4978e-05 lr: 6.4978e-06  eta: 6:00:18  time: 0.4364  data_time: 0.0092  memory: 5246  grad_norm: 88.5100  loss: 7.8860  decode.loss_cls: 0.1664  decode.loss_mask: 0.2107  decode.loss_dice: 0.2737  decode.d0.loss_cls: 1.0595  decode.d0.loss_mask: 0.2159  decode.d0.loss_dice: 0.3023  decode.d1.loss_cls: 0.3545  decode.d1.loss_mask: 0.2093  decode.d1.loss_dice: 0.2667  decode.d2.loss_cls: 0.2317  decode.d2.loss_mask: 0.2130  decode.d2.loss_dice: 0.2795  decode.d3.loss_cls: 0.2656  decode.d3.loss_mask: 0.2080  decode.d3.loss_dice: 0.2696  decode.d4.loss_cls: 0.2234  decode.d4.loss_mask: 0.2100  decode.d4.loss_dice: 0.2670  decode.d5.loss_cls: 0.1839  decode.d5.loss_mask: 0.2086  decode.d5.loss_dice: 0.2699  decode.d6.loss_cls: 0.1706  decode.d6.loss_mask: 0.2108  decode.d6.loss_dice: 0.2799  decode.d7.loss_cls: 0.1671  decode.d7.loss_mask: 0.2097  decode.d7.loss_dice: 0.2830  decode.d8.loss_cls: 0.1794  decode.d8.loss_mask: 0.2100  decode.d8.loss_dice: 0.2863
07/30 20:22:04 - mmengine - INFO - Iter(train) [30500/80000]  base_lr: 6.4919e-05 lr: 6.4919e-06  eta: 5:59:56  time: 0.4371  data_time: 0.0092  memory: 5227  grad_norm: 106.4640  loss: 8.2296  decode.loss_cls: 0.2386  decode.loss_mask: 0.2366  decode.loss_dice: 0.3249  decode.d0.loss_cls: 1.0479  decode.d0.loss_mask: 0.2501  decode.d0.loss_dice: 0.3451  decode.d1.loss_cls: 0.2938  decode.d1.loss_mask: 0.2399  decode.d1.loss_dice: 0.3045  decode.d2.loss_cls: 0.1690  decode.d2.loss_mask: 0.2361  decode.d2.loss_dice: 0.2977  decode.d3.loss_cls: 0.1150  decode.d3.loss_mask: 0.2354  decode.d3.loss_dice: 0.3283  decode.d4.loss_cls: 0.1516  decode.d4.loss_mask: 0.2379  decode.d4.loss_dice: 0.3075  decode.d5.loss_cls: 0.1446  decode.d5.loss_mask: 0.2419  decode.d5.loss_dice: 0.3202  decode.d6.loss_cls: 0.2115  decode.d6.loss_mask: 0.2396  decode.d6.loss_dice: 0.3053  decode.d7.loss_cls: 0.1691  decode.d7.loss_mask: 0.2370  decode.d7.loss_dice: 0.3157  decode.d8.loss_cls: 0.1628  decode.d8.loss_mask: 0.2343  decode.d8.loss_dice: 0.2880
07/30 20:22:26 - mmengine - INFO - Iter(train) [30550/80000]  base_lr: 6.4859e-05 lr: 6.4859e-06  eta: 5:59:34  time: 0.4372  data_time: 0.0093  memory: 5245  grad_norm: 96.8954  loss: 7.3826  decode.loss_cls: 0.1173  decode.loss_mask: 0.2328  decode.loss_dice: 0.2751  decode.d0.loss_cls: 0.9853  decode.d0.loss_mask: 0.2300  decode.d0.loss_dice: 0.2942  decode.d1.loss_cls: 0.1646  decode.d1.loss_mask: 0.2323  decode.d1.loss_dice: 0.2799  decode.d2.loss_cls: 0.1167  decode.d2.loss_mask: 0.2352  decode.d2.loss_dice: 0.2864  decode.d3.loss_cls: 0.1384  decode.d3.loss_mask: 0.2321  decode.d3.loss_dice: 0.2847  decode.d4.loss_cls: 0.1652  decode.d4.loss_mask: 0.2361  decode.d4.loss_dice: 0.2836  decode.d5.loss_cls: 0.1201  decode.d5.loss_mask: 0.2364  decode.d5.loss_dice: 0.2873  decode.d6.loss_cls: 0.1576  decode.d6.loss_mask: 0.2324  decode.d6.loss_dice: 0.2862  decode.d7.loss_cls: 0.1212  decode.d7.loss_mask: 0.2326  decode.d7.loss_dice: 0.2868  decode.d8.loss_cls: 0.1225  decode.d8.loss_mask: 0.2330  decode.d8.loss_dice: 0.2766
07/30 20:22:48 - mmengine - INFO - Iter(train) [30600/80000]  base_lr: 6.4800e-05 lr: 6.4800e-06  eta: 5:59:13  time: 0.4369  data_time: 0.0095  memory: 5261  grad_norm: 105.2531  loss: 8.2434  decode.loss_cls: 0.1415  decode.loss_mask: 0.2744  decode.loss_dice: 0.3148  decode.d0.loss_cls: 0.9053  decode.d0.loss_mask: 0.2819  decode.d0.loss_dice: 0.3660  decode.d1.loss_cls: 0.1475  decode.d1.loss_mask: 0.2738  decode.d1.loss_dice: 0.3097  decode.d2.loss_cls: 0.1800  decode.d2.loss_mask: 0.2765  decode.d2.loss_dice: 0.3034  decode.d3.loss_cls: 0.1650  decode.d3.loss_mask: 0.2725  decode.d3.loss_dice: 0.3194  decode.d4.loss_cls: 0.1609  decode.d4.loss_mask: 0.2687  decode.d4.loss_dice: 0.2892  decode.d5.loss_cls: 0.1530  decode.d5.loss_mask: 0.2678  decode.d5.loss_dice: 0.3013  decode.d6.loss_cls: 0.1739  decode.d6.loss_mask: 0.2694  decode.d6.loss_dice: 0.3001  decode.d7.loss_cls: 0.1679  decode.d7.loss_mask: 0.2757  decode.d7.loss_dice: 0.3189  decode.d8.loss_cls: 0.1702  decode.d8.loss_mask: 0.2687  decode.d8.loss_dice: 0.3261
07/30 20:23:10 - mmengine - INFO - Iter(train) [30650/80000]  base_lr: 6.4741e-05 lr: 6.4741e-06  eta: 5:58:51  time: 0.4365  data_time: 0.0093  memory: 5305  grad_norm: 63.9328  loss: 7.0044  decode.loss_cls: 0.1146  decode.loss_mask: 0.2395  decode.loss_dice: 0.2808  decode.d0.loss_cls: 0.9115  decode.d0.loss_mask: 0.2313  decode.d0.loss_dice: 0.2943  decode.d1.loss_cls: 0.1087  decode.d1.loss_mask: 0.2451  decode.d1.loss_dice: 0.2791  decode.d2.loss_cls: 0.1124  decode.d2.loss_mask: 0.2430  decode.d2.loss_dice: 0.2748  decode.d3.loss_cls: 0.0848  decode.d3.loss_mask: 0.2474  decode.d3.loss_dice: 0.2781  decode.d4.loss_cls: 0.0972  decode.d4.loss_mask: 0.2490  decode.d4.loss_dice: 0.2790  decode.d5.loss_cls: 0.1009  decode.d5.loss_mask: 0.2446  decode.d5.loss_dice: 0.2706  decode.d6.loss_cls: 0.0958  decode.d6.loss_mask: 0.2397  decode.d6.loss_dice: 0.2620  decode.d7.loss_cls: 0.1173  decode.d7.loss_mask: 0.2422  decode.d7.loss_dice: 0.2746  decode.d8.loss_cls: 0.0701  decode.d8.loss_mask: 0.2395  decode.d8.loss_dice: 0.2767
07/30 20:23:32 - mmengine - INFO - Iter(train) [30700/80000]  base_lr: 6.4682e-05 lr: 6.4682e-06  eta: 5:58:29  time: 0.4373  data_time: 0.0094  memory: 5279  grad_norm: 103.0304  loss: 8.9217  decode.loss_cls: 0.3027  decode.loss_mask: 0.2082  decode.loss_dice: 0.2871  decode.d0.loss_cls: 1.0476  decode.d0.loss_mask: 0.2202  decode.d0.loss_dice: 0.2983  decode.d1.loss_cls: 0.5406  decode.d1.loss_mask: 0.2032  decode.d1.loss_dice: 0.2779  decode.d2.loss_cls: 0.3536  decode.d2.loss_mask: 0.2088  decode.d2.loss_dice: 0.2580  decode.d3.loss_cls: 0.2960  decode.d3.loss_mask: 0.2152  decode.d3.loss_dice: 0.2765  decode.d4.loss_cls: 0.2736  decode.d4.loss_mask: 0.2106  decode.d4.loss_dice: 0.3044  decode.d5.loss_cls: 0.2569  decode.d5.loss_mask: 0.2077  decode.d5.loss_dice: 0.2709  decode.d6.loss_cls: 0.3141  decode.d6.loss_mask: 0.2074  decode.d6.loss_dice: 0.2746  decode.d7.loss_cls: 0.3140  decode.d7.loss_mask: 0.2065  decode.d7.loss_dice: 0.2709  decode.d8.loss_cls: 0.3487  decode.d8.loss_mask: 0.2062  decode.d8.loss_dice: 0.2612
07/30 20:23:54 - mmengine - INFO - Iter(train) [30750/80000]  base_lr: 6.4623e-05 lr: 6.4623e-06  eta: 5:58:07  time: 0.4362  data_time: 0.0094  memory: 5277  grad_norm: 123.4035  loss: 8.1704  decode.loss_cls: 0.1961  decode.loss_mask: 0.2785  decode.loss_dice: 0.2732  decode.d0.loss_cls: 1.0650  decode.d0.loss_mask: 0.2907  decode.d0.loss_dice: 0.2775  decode.d1.loss_cls: 0.2353  decode.d1.loss_mask: 0.2823  decode.d1.loss_dice: 0.2738  decode.d2.loss_cls: 0.1442  decode.d2.loss_mask: 0.2851  decode.d2.loss_dice: 0.2637  decode.d3.loss_cls: 0.1835  decode.d3.loss_mask: 0.2759  decode.d3.loss_dice: 0.2651  decode.d4.loss_cls: 0.1644  decode.d4.loss_mask: 0.2783  decode.d4.loss_dice: 0.2539  decode.d5.loss_cls: 0.1331  decode.d5.loss_mask: 0.2769  decode.d5.loss_dice: 0.2702  decode.d6.loss_cls: 0.2044  decode.d6.loss_mask: 0.2755  decode.d6.loss_dice: 0.2711  decode.d7.loss_cls: 0.1826  decode.d7.loss_mask: 0.2831  decode.d7.loss_dice: 0.2671  decode.d8.loss_cls: 0.1737  decode.d8.loss_mask: 0.2815  decode.d8.loss_dice: 0.2646
07/30 20:24:16 - mmengine - INFO - Iter(train) [30800/80000]  base_lr: 6.4564e-05 lr: 6.4564e-06  eta: 5:57:46  time: 0.4361  data_time: 0.0095  memory: 5277  grad_norm: 34.4889  loss: 6.2983  decode.loss_cls: 0.0628  decode.loss_mask: 0.2347  decode.loss_dice: 0.2445  decode.d0.loss_cls: 0.8893  decode.d0.loss_mask: 0.2429  decode.d0.loss_dice: 0.2404  decode.d1.loss_cls: 0.0810  decode.d1.loss_mask: 0.2379  decode.d1.loss_dice: 0.2408  decode.d2.loss_cls: 0.0751  decode.d2.loss_mask: 0.2374  decode.d2.loss_dice: 0.2380  decode.d3.loss_cls: 0.0797  decode.d3.loss_mask: 0.2383  decode.d3.loss_dice: 0.2376  decode.d4.loss_cls: 0.0672  decode.d4.loss_mask: 0.2357  decode.d4.loss_dice: 0.2377  decode.d5.loss_cls: 0.0650  decode.d5.loss_mask: 0.2399  decode.d5.loss_dice: 0.2414  decode.d6.loss_cls: 0.0657  decode.d6.loss_mask: 0.2352  decode.d6.loss_dice: 0.2421  decode.d7.loss_cls: 0.0666  decode.d7.loss_mask: 0.2328  decode.d7.loss_dice: 0.2388  decode.d8.loss_cls: 0.0687  decode.d8.loss_mask: 0.2367  decode.d8.loss_dice: 0.2443
07/30 20:24:37 - mmengine - INFO - Iter(train) [30850/80000]  base_lr: 6.4505e-05 lr: 6.4505e-06  eta: 5:57:24  time: 0.4361  data_time: 0.0095  memory: 5279  grad_norm: 134.3947  loss: 8.7887  decode.loss_cls: 0.1664  decode.loss_mask: 0.3243  decode.loss_dice: 0.3026  decode.d0.loss_cls: 0.9171  decode.d0.loss_mask: 0.3357  decode.d0.loss_dice: 0.3144  decode.d1.loss_cls: 0.2405  decode.d1.loss_mask: 0.3262  decode.d1.loss_dice: 0.3178  decode.d2.loss_cls: 0.2046  decode.d2.loss_mask: 0.3242  decode.d2.loss_dice: 0.3068  decode.d3.loss_cls: 0.2160  decode.d3.loss_mask: 0.3219  decode.d3.loss_dice: 0.3072  decode.d4.loss_cls: 0.1309  decode.d4.loss_mask: 0.3250  decode.d4.loss_dice: 0.3114  decode.d5.loss_cls: 0.1275  decode.d5.loss_mask: 0.3254  decode.d5.loss_dice: 0.3127  decode.d6.loss_cls: 0.1608  decode.d6.loss_mask: 0.3297  decode.d6.loss_dice: 0.3003  decode.d7.loss_cls: 0.1359  decode.d7.loss_mask: 0.3264  decode.d7.loss_dice: 0.3091  decode.d8.loss_cls: 0.1320  decode.d8.loss_mask: 0.3288  decode.d8.loss_dice: 0.3073
07/30 20:24:59 - mmengine - INFO - Iter(train) [30900/80000]  base_lr: 6.4446e-05 lr: 6.4446e-06  eta: 5:57:02  time: 0.4368  data_time: 0.0095  memory: 5244  grad_norm: 120.0930  loss: 8.1708  decode.loss_cls: 0.1686  decode.loss_mask: 0.2498  decode.loss_dice: 0.2942  decode.d0.loss_cls: 0.9280  decode.d0.loss_mask: 0.2674  decode.d0.loss_dice: 0.2937  decode.d1.loss_cls: 0.2948  decode.d1.loss_mask: 0.2546  decode.d1.loss_dice: 0.2993  decode.d2.loss_cls: 0.2030  decode.d2.loss_mask: 0.2572  decode.d2.loss_dice: 0.3086  decode.d3.loss_cls: 0.1684  decode.d3.loss_mask: 0.2524  decode.d3.loss_dice: 0.3053  decode.d4.loss_cls: 0.1825  decode.d4.loss_mask: 0.2511  decode.d4.loss_dice: 0.2965  decode.d5.loss_cls: 0.1199  decode.d5.loss_mask: 0.2553  decode.d5.loss_dice: 0.3247  decode.d6.loss_cls: 0.1716  decode.d6.loss_mask: 0.2548  decode.d6.loss_dice: 0.3164  decode.d7.loss_cls: 0.1696  decode.d7.loss_mask: 0.2539  decode.d7.loss_dice: 0.3147  decode.d8.loss_cls: 0.1610  decode.d8.loss_mask: 0.2492  decode.d8.loss_dice: 0.3041
07/30 20:25:21 - mmengine - INFO - Iter(train) [30950/80000]  base_lr: 6.4387e-05 lr: 6.4387e-06  eta: 5:56:40  time: 0.4373  data_time: 0.0094  memory: 5278  grad_norm: 46.8030  loss: 6.0529  decode.loss_cls: 0.0558  decode.loss_mask: 0.2108  decode.loss_dice: 0.2424  decode.d0.loss_cls: 0.9067  decode.d0.loss_mask: 0.2190  decode.d0.loss_dice: 0.2518  decode.d1.loss_cls: 0.1062  decode.d1.loss_mask: 0.2122  decode.d1.loss_dice: 0.2443  decode.d2.loss_cls: 0.0850  decode.d2.loss_mask: 0.2131  decode.d2.loss_dice: 0.2569  decode.d3.loss_cls: 0.0695  decode.d3.loss_mask: 0.2109  decode.d3.loss_dice: 0.2335  decode.d4.loss_cls: 0.0622  decode.d4.loss_mask: 0.2080  decode.d4.loss_dice: 0.2320  decode.d5.loss_cls: 0.0666  decode.d5.loss_mask: 0.2078  decode.d5.loss_dice: 0.2392  decode.d6.loss_cls: 0.0560  decode.d6.loss_mask: 0.2101  decode.d6.loss_dice: 0.2476  decode.d7.loss_cls: 0.0559  decode.d7.loss_mask: 0.2099  decode.d7.loss_dice: 0.2368  decode.d8.loss_cls: 0.0541  decode.d8.loss_mask: 0.2089  decode.d8.loss_dice: 0.2399
07/30 20:25:43 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 20:25:43 - mmengine - INFO - Iter(train) [31000/80000]  base_lr: 6.4328e-05 lr: 6.4328e-06  eta: 5:56:18  time: 0.4372  data_time: 0.0095  memory: 5261  grad_norm: 61.5060  loss: 6.8897  decode.loss_cls: 0.1076  decode.loss_mask: 0.2527  decode.loss_dice: 0.2585  decode.d0.loss_cls: 0.9286  decode.d0.loss_mask: 0.2615  decode.d0.loss_dice: 0.2866  decode.d1.loss_cls: 0.1205  decode.d1.loss_mask: 0.2526  decode.d1.loss_dice: 0.2823  decode.d2.loss_cls: 0.0621  decode.d2.loss_mask: 0.2513  decode.d2.loss_dice: 0.2750  decode.d3.loss_cls: 0.0436  decode.d3.loss_mask: 0.2527  decode.d3.loss_dice: 0.2674  decode.d4.loss_cls: 0.0460  decode.d4.loss_mask: 0.2507  decode.d4.loss_dice: 0.2713  decode.d5.loss_cls: 0.1092  decode.d5.loss_mask: 0.2488  decode.d5.loss_dice: 0.2614  decode.d6.loss_cls: 0.0863  decode.d6.loss_mask: 0.2491  decode.d6.loss_dice: 0.2650  decode.d7.loss_cls: 0.0799  decode.d7.loss_mask: 0.2536  decode.d7.loss_dice: 0.2667  decode.d8.loss_cls: 0.0865  decode.d8.loss_mask: 0.2496  decode.d8.loss_dice: 0.2625
07/30 20:26:05 - mmengine - INFO - Iter(train) [31050/80000]  base_lr: 6.4269e-05 lr: 6.4269e-06  eta: 5:55:57  time: 0.4371  data_time: 0.0095  memory: 5244  grad_norm: 117.9329  loss: 8.4894  decode.loss_cls: 0.2921  decode.loss_mask: 0.2448  decode.loss_dice: 0.2257  decode.d0.loss_cls: 1.1591  decode.d0.loss_mask: 0.2371  decode.d0.loss_dice: 0.2365  decode.d1.loss_cls: 0.3699  decode.d1.loss_mask: 0.2541  decode.d1.loss_dice: 0.2318  decode.d2.loss_cls: 0.3274  decode.d2.loss_mask: 0.2541  decode.d2.loss_dice: 0.2219  decode.d3.loss_cls: 0.3143  decode.d3.loss_mask: 0.2532  decode.d3.loss_dice: 0.2246  decode.d4.loss_cls: 0.2404  decode.d4.loss_mask: 0.2521  decode.d4.loss_dice: 0.2256  decode.d5.loss_cls: 0.2462  decode.d5.loss_mask: 0.2563  decode.d5.loss_dice: 0.2225  decode.d6.loss_cls: 0.2347  decode.d6.loss_mask: 0.2515  decode.d6.loss_dice: 0.2240  decode.d7.loss_cls: 0.2443  decode.d7.loss_mask: 0.2483  decode.d7.loss_dice: 0.2277  decode.d8.loss_cls: 0.3017  decode.d8.loss_mask: 0.2473  decode.d8.loss_dice: 0.2202
07/30 20:26:27 - mmengine - INFO - Iter(train) [31100/80000]  base_lr: 6.4210e-05 lr: 6.4210e-06  eta: 5:55:35  time: 0.4359  data_time: 0.0094  memory: 5229  grad_norm: 59.6884  loss: 8.2711  decode.loss_cls: 0.1358  decode.loss_mask: 0.2782  decode.loss_dice: 0.2763  decode.d0.loss_cls: 1.0467  decode.d0.loss_mask: 0.2831  decode.d0.loss_dice: 0.2896  decode.d1.loss_cls: 0.2520  decode.d1.loss_mask: 0.2834  decode.d1.loss_dice: 0.2849  decode.d2.loss_cls: 0.2377  decode.d2.loss_mask: 0.2760  decode.d2.loss_dice: 0.2704  decode.d3.loss_cls: 0.1398  decode.d3.loss_mask: 0.2825  decode.d3.loss_dice: 0.2950  decode.d4.loss_cls: 0.2150  decode.d4.loss_mask: 0.2811  decode.d4.loss_dice: 0.2740  decode.d5.loss_cls: 0.2105  decode.d5.loss_mask: 0.2833  decode.d5.loss_dice: 0.2756  decode.d6.loss_cls: 0.1384  decode.d6.loss_mask: 0.2820  decode.d6.loss_dice: 0.2750  decode.d7.loss_cls: 0.1453  decode.d7.loss_mask: 0.2788  decode.d7.loss_dice: 0.2759  decode.d8.loss_cls: 0.1458  decode.d8.loss_mask: 0.2772  decode.d8.loss_dice: 0.2817
07/30 20:26:48 - mmengine - INFO - Iter(train) [31150/80000]  base_lr: 6.4151e-05 lr: 6.4151e-06  eta: 5:55:13  time: 0.4378  data_time: 0.0095  memory: 5278  grad_norm: 76.5064  loss: 8.2371  decode.loss_cls: 0.2158  decode.loss_mask: 0.2207  decode.loss_dice: 0.2743  decode.d0.loss_cls: 1.0269  decode.d0.loss_mask: 0.2274  decode.d0.loss_dice: 0.2985  decode.d1.loss_cls: 0.2934  decode.d1.loss_mask: 0.2277  decode.d1.loss_dice: 0.3089  decode.d2.loss_cls: 0.2225  decode.d2.loss_mask: 0.2292  decode.d2.loss_dice: 0.2986  decode.d3.loss_cls: 0.2141  decode.d3.loss_mask: 0.2277  decode.d3.loss_dice: 0.2977  decode.d4.loss_cls: 0.1975  decode.d4.loss_mask: 0.2242  decode.d4.loss_dice: 0.3266  decode.d5.loss_cls: 0.2035  decode.d5.loss_mask: 0.2216  decode.d5.loss_dice: 0.2942  decode.d6.loss_cls: 0.2068  decode.d6.loss_mask: 0.2235  decode.d6.loss_dice: 0.2758  decode.d7.loss_cls: 0.2394  decode.d7.loss_mask: 0.2249  decode.d7.loss_dice: 0.2817  decode.d8.loss_cls: 0.2379  decode.d8.loss_mask: 0.2222  decode.d8.loss_dice: 0.2739
07/30 20:27:10 - mmengine - INFO - Iter(train) [31200/80000]  base_lr: 6.4092e-05 lr: 6.4092e-06  eta: 5:54:51  time: 0.4365  data_time: 0.0093  memory: 5279  grad_norm: 88.0602  loss: 9.5737  decode.loss_cls: 0.1635  decode.loss_mask: 0.3442  decode.loss_dice: 0.3193  decode.d0.loss_cls: 1.1081  decode.d0.loss_mask: 0.3398  decode.d0.loss_dice: 0.3664  decode.d1.loss_cls: 0.2449  decode.d1.loss_mask: 0.3398  decode.d1.loss_dice: 0.3246  decode.d2.loss_cls: 0.2322  decode.d2.loss_mask: 0.3460  decode.d2.loss_dice: 0.3358  decode.d3.loss_cls: 0.1895  decode.d3.loss_mask: 0.3445  decode.d3.loss_dice: 0.3211  decode.d4.loss_cls: 0.1815  decode.d4.loss_mask: 0.3472  decode.d4.loss_dice: 0.3247  decode.d5.loss_cls: 0.1842  decode.d5.loss_mask: 0.3494  decode.d5.loss_dice: 0.3273  decode.d6.loss_cls: 0.2079  decode.d6.loss_mask: 0.3290  decode.d6.loss_dice: 0.3267  decode.d7.loss_cls: 0.1667  decode.d7.loss_mask: 0.3385  decode.d7.loss_dice: 0.3217  decode.d8.loss_cls: 0.1929  decode.d8.loss_mask: 0.3401  decode.d8.loss_dice: 0.3160
07/30 20:27:32 - mmengine - INFO - Iter(train) [31250/80000]  base_lr: 6.4033e-05 lr: 6.4033e-06  eta: 5:54:29  time: 0.4367  data_time: 0.0093  memory: 5245  grad_norm: 58.0317  loss: 6.9725  decode.loss_cls: 0.1341  decode.loss_mask: 0.2019  decode.loss_dice: 0.2471  decode.d0.loss_cls: 1.0155  decode.d0.loss_mask: 0.2008  decode.d0.loss_dice: 0.2669  decode.d1.loss_cls: 0.2234  decode.d1.loss_mask: 0.1972  decode.d1.loss_dice: 0.2723  decode.d2.loss_cls: 0.1891  decode.d2.loss_mask: 0.2054  decode.d2.loss_dice: 0.2663  decode.d3.loss_cls: 0.1201  decode.d3.loss_mask: 0.2009  decode.d3.loss_dice: 0.2542  decode.d4.loss_cls: 0.1307  decode.d4.loss_mask: 0.2003  decode.d4.loss_dice: 0.2474  decode.d5.loss_cls: 0.1840  decode.d5.loss_mask: 0.2100  decode.d5.loss_dice: 0.2539  decode.d6.loss_cls: 0.1435  decode.d6.loss_mask: 0.1961  decode.d6.loss_dice: 0.2396  decode.d7.loss_cls: 0.1532  decode.d7.loss_mask: 0.1996  decode.d7.loss_dice: 0.2378  decode.d8.loss_cls: 0.1413  decode.d8.loss_mask: 0.1991  decode.d8.loss_dice: 0.2407
07/30 20:27:54 - mmengine - INFO - Iter(train) [31300/80000]  base_lr: 6.3973e-05 lr: 6.3973e-06  eta: 5:54:08  time: 0.4361  data_time: 0.0093  memory: 5227  grad_norm: 49.3417  loss: 6.3365  decode.loss_cls: 0.0541  decode.loss_mask: 0.2424  decode.loss_dice: 0.2226  decode.d0.loss_cls: 1.0713  decode.d0.loss_mask: 0.2445  decode.d0.loss_dice: 0.2349  decode.d1.loss_cls: 0.1106  decode.d1.loss_mask: 0.2436  decode.d1.loss_dice: 0.2296  decode.d2.loss_cls: 0.0589  decode.d2.loss_mask: 0.2424  decode.d2.loss_dice: 0.2263  decode.d3.loss_cls: 0.0660  decode.d3.loss_mask: 0.2463  decode.d3.loss_dice: 0.2270  decode.d4.loss_cls: 0.0531  decode.d4.loss_mask: 0.2416  decode.d4.loss_dice: 0.2253  decode.d5.loss_cls: 0.0528  decode.d5.loss_mask: 0.2442  decode.d5.loss_dice: 0.2285  decode.d6.loss_cls: 0.0533  decode.d6.loss_mask: 0.2457  decode.d6.loss_dice: 0.2254  decode.d7.loss_cls: 0.0558  decode.d7.loss_mask: 0.2423  decode.d7.loss_dice: 0.2253  decode.d8.loss_cls: 0.0563  decode.d8.loss_mask: 0.2427  decode.d8.loss_dice: 0.2234
07/30 20:28:16 - mmengine - INFO - Iter(train) [31350/80000]  base_lr: 6.3914e-05 lr: 6.3914e-06  eta: 5:53:46  time: 0.4364  data_time: 0.0095  memory: 5245  grad_norm: 46.7407  loss: 7.5936  decode.loss_cls: 0.1446  decode.loss_mask: 0.2718  decode.loss_dice: 0.2562  decode.d0.loss_cls: 0.8864  decode.d0.loss_mask: 0.2772  decode.d0.loss_dice: 0.2793  decode.d1.loss_cls: 0.1104  decode.d1.loss_mask: 0.2772  decode.d1.loss_dice: 0.2630  decode.d2.loss_cls: 0.1467  decode.d2.loss_mask: 0.2694  decode.d2.loss_dice: 0.2661  decode.d3.loss_cls: 0.2138  decode.d3.loss_mask: 0.2769  decode.d3.loss_dice: 0.2397  decode.d4.loss_cls: 0.1474  decode.d4.loss_mask: 0.2729  decode.d4.loss_dice: 0.2618  decode.d5.loss_cls: 0.1608  decode.d5.loss_mask: 0.2739  decode.d5.loss_dice: 0.2731  decode.d6.loss_cls: 0.1504  decode.d6.loss_mask: 0.2713  decode.d6.loss_dice: 0.2517  decode.d7.loss_cls: 0.1315  decode.d7.loss_mask: 0.2714  decode.d7.loss_dice: 0.2593  decode.d8.loss_cls: 0.1329  decode.d8.loss_mask: 0.2717  decode.d8.loss_dice: 0.2849
07/30 20:28:38 - mmengine - INFO - Iter(train) [31400/80000]  base_lr: 6.3855e-05 lr: 6.3855e-06  eta: 5:53:24  time: 0.4367  data_time: 0.0094  memory: 5277  grad_norm: 132.0606  loss: 8.4016  decode.loss_cls: 0.1210  decode.loss_mask: 0.2845  decode.loss_dice: 0.3001  decode.d0.loss_cls: 1.0349  decode.d0.loss_mask: 0.3014  decode.d0.loss_dice: 0.2972  decode.d1.loss_cls: 0.2162  decode.d1.loss_mask: 0.2942  decode.d1.loss_dice: 0.2936  decode.d2.loss_cls: 0.1604  decode.d2.loss_mask: 0.2901  decode.d2.loss_dice: 0.3028  decode.d3.loss_cls: 0.1451  decode.d3.loss_mask: 0.2918  decode.d3.loss_dice: 0.2909  decode.d4.loss_cls: 0.2447  decode.d4.loss_mask: 0.2863  decode.d4.loss_dice: 0.2857  decode.d5.loss_cls: 0.1395  decode.d5.loss_mask: 0.2949  decode.d5.loss_dice: 0.3019  decode.d6.loss_cls: 0.1809  decode.d6.loss_mask: 0.2840  decode.d6.loss_dice: 0.2815  decode.d7.loss_cls: 0.1401  decode.d7.loss_mask: 0.2882  decode.d7.loss_dice: 0.2873  decode.d8.loss_cls: 0.1836  decode.d8.loss_mask: 0.2835  decode.d8.loss_dice: 0.2955
07/30 20:29:00 - mmengine - INFO - Iter(train) [31450/80000]  base_lr: 6.3796e-05 lr: 6.3796e-06  eta: 5:53:02  time: 0.4367  data_time: 0.0095  memory: 5279  grad_norm: 59.0052  loss: 6.5485  decode.loss_cls: 0.0519  decode.loss_mask: 0.2351  decode.loss_dice: 0.2711  decode.d0.loss_cls: 0.8601  decode.d0.loss_mask: 0.2402  decode.d0.loss_dice: 0.2744  decode.d1.loss_cls: 0.0911  decode.d1.loss_mask: 0.2386  decode.d1.loss_dice: 0.2844  decode.d2.loss_cls: 0.0329  decode.d2.loss_mask: 0.2375  decode.d2.loss_dice: 0.2683  decode.d3.loss_cls: 0.0688  decode.d3.loss_mask: 0.2373  decode.d3.loss_dice: 0.2735  decode.d4.loss_cls: 0.0625  decode.d4.loss_mask: 0.2352  decode.d4.loss_dice: 0.2706  decode.d5.loss_cls: 0.0581  decode.d5.loss_mask: 0.2333  decode.d5.loss_dice: 0.2862  decode.d6.loss_cls: 0.0484  decode.d6.loss_mask: 0.2309  decode.d6.loss_dice: 0.2646  decode.d7.loss_cls: 0.0940  decode.d7.loss_mask: 0.2368  decode.d7.loss_dice: 0.2773  decode.d8.loss_cls: 0.0678  decode.d8.loss_mask: 0.2340  decode.d8.loss_dice: 0.2834
07/30 20:29:22 - mmengine - INFO - Iter(train) [31500/80000]  base_lr: 6.3737e-05 lr: 6.3737e-06  eta: 5:52:41  time: 0.4540  data_time: 0.0095  memory: 5305  grad_norm: 61.4672  loss: 6.7154  decode.loss_cls: 0.0901  decode.loss_mask: 0.2586  decode.loss_dice: 0.2546  decode.d0.loss_cls: 0.8460  decode.d0.loss_mask: 0.2681  decode.d0.loss_dice: 0.2558  decode.d1.loss_cls: 0.0936  decode.d1.loss_mask: 0.2615  decode.d1.loss_dice: 0.2608  decode.d2.loss_cls: 0.0818  decode.d2.loss_mask: 0.2611  decode.d2.loss_dice: 0.2632  decode.d3.loss_cls: 0.0693  decode.d3.loss_mask: 0.2610  decode.d3.loss_dice: 0.2525  decode.d4.loss_cls: 0.0658  decode.d4.loss_mask: 0.2603  decode.d4.loss_dice: 0.2517  decode.d5.loss_cls: 0.0685  decode.d5.loss_mask: 0.2585  decode.d5.loss_dice: 0.2553  decode.d6.loss_cls: 0.0928  decode.d6.loss_mask: 0.2625  decode.d6.loss_dice: 0.2545  decode.d7.loss_cls: 0.0547  decode.d7.loss_mask: 0.2613  decode.d7.loss_dice: 0.2547  decode.d8.loss_cls: 0.0823  decode.d8.loss_mask: 0.2614  decode.d8.loss_dice: 0.2533
07/30 20:29:43 - mmengine - INFO - Iter(train) [31550/80000]  base_lr: 6.3678e-05 lr: 6.3678e-06  eta: 5:52:19  time: 0.4373  data_time: 0.0094  memory: 5265  grad_norm: 62.2551  loss: 6.5770  decode.loss_cls: 0.1769  decode.loss_mask: 0.1936  decode.loss_dice: 0.2246  decode.d0.loss_cls: 0.8802  decode.d0.loss_mask: 0.1980  decode.d0.loss_dice: 0.2072  decode.d1.loss_cls: 0.1646  decode.d1.loss_mask: 0.1951  decode.d1.loss_dice: 0.2197  decode.d2.loss_cls: 0.1507  decode.d2.loss_mask: 0.1920  decode.d2.loss_dice: 0.2312  decode.d3.loss_cls: 0.1529  decode.d3.loss_mask: 0.1940  decode.d3.loss_dice: 0.2339  decode.d4.loss_cls: 0.1792  decode.d4.loss_mask: 0.1939  decode.d4.loss_dice: 0.2146  decode.d5.loss_cls: 0.1681  decode.d5.loss_mask: 0.1926  decode.d5.loss_dice: 0.2373  decode.d6.loss_cls: 0.1582  decode.d6.loss_mask: 0.1962  decode.d6.loss_dice: 0.2345  decode.d7.loss_cls: 0.1709  decode.d7.loss_mask: 0.1949  decode.d7.loss_dice: 0.2322  decode.d8.loss_cls: 0.1628  decode.d8.loss_mask: 0.1953  decode.d8.loss_dice: 0.2317
07/30 20:30:05 - mmengine - INFO - Iter(train) [31600/80000]  base_lr: 6.3619e-05 lr: 6.3619e-06  eta: 5:51:57  time: 0.4368  data_time: 0.0093  memory: 5227  grad_norm: 56.2587  loss: 6.4691  decode.loss_cls: 0.0571  decode.loss_mask: 0.2335  decode.loss_dice: 0.2415  decode.d0.loss_cls: 0.8396  decode.d0.loss_mask: 0.2349  decode.d0.loss_dice: 0.2665  decode.d1.loss_cls: 0.1061  decode.d1.loss_mask: 0.2348  decode.d1.loss_dice: 0.2640  decode.d2.loss_cls: 0.0664  decode.d2.loss_mask: 0.2333  decode.d2.loss_dice: 0.2633  decode.d3.loss_cls: 0.0596  decode.d3.loss_mask: 0.2352  decode.d3.loss_dice: 0.2589  decode.d4.loss_cls: 0.0581  decode.d4.loss_mask: 0.2368  decode.d4.loss_dice: 0.2822  decode.d5.loss_cls: 0.0655  decode.d5.loss_mask: 0.2338  decode.d5.loss_dice: 0.2750  decode.d6.loss_cls: 0.0822  decode.d6.loss_mask: 0.2320  decode.d6.loss_dice: 0.2670  decode.d7.loss_cls: 0.0788  decode.d7.loss_mask: 0.2366  decode.d7.loss_dice: 0.2726  decode.d8.loss_cls: 0.0526  decode.d8.loss_mask: 0.2366  decode.d8.loss_dice: 0.2647
07/30 20:30:27 - mmengine - INFO - Iter(train) [31650/80000]  base_lr: 6.3560e-05 lr: 6.3560e-06  eta: 5:51:36  time: 0.4372  data_time: 0.0095  memory: 5265  grad_norm: 46.1787  loss: 7.5763  decode.loss_cls: 0.1119  decode.loss_mask: 0.2637  decode.loss_dice: 0.2888  decode.d0.loss_cls: 0.8920  decode.d0.loss_mask: 0.2753  decode.d0.loss_dice: 0.2885  decode.d1.loss_cls: 0.1756  decode.d1.loss_mask: 0.2655  decode.d1.loss_dice: 0.2839  decode.d2.loss_cls: 0.1309  decode.d2.loss_mask: 0.2646  decode.d2.loss_dice: 0.2950  decode.d3.loss_cls: 0.1285  decode.d3.loss_mask: 0.2645  decode.d3.loss_dice: 0.2872  decode.d4.loss_cls: 0.1231  decode.d4.loss_mask: 0.2623  decode.d4.loss_dice: 0.2804  decode.d5.loss_cls: 0.1506  decode.d5.loss_mask: 0.2623  decode.d5.loss_dice: 0.2852  decode.d6.loss_cls: 0.1596  decode.d6.loss_mask: 0.2651  decode.d6.loss_dice: 0.2732  decode.d7.loss_cls: 0.1133  decode.d7.loss_mask: 0.2649  decode.d7.loss_dice: 0.2754  decode.d8.loss_cls: 0.1073  decode.d8.loss_mask: 0.2639  decode.d8.loss_dice: 0.2736
07/30 20:30:49 - mmengine - INFO - Iter(train) [31700/80000]  base_lr: 6.3500e-05 lr: 6.3500e-06  eta: 5:51:14  time: 0.4374  data_time: 0.0095  memory: 5265  grad_norm: 76.2958  loss: 7.1479  decode.loss_cls: 0.1176  decode.loss_mask: 0.2564  decode.loss_dice: 0.2711  decode.d0.loss_cls: 0.8608  decode.d0.loss_mask: 0.2679  decode.d0.loss_dice: 0.2767  decode.d1.loss_cls: 0.1050  decode.d1.loss_mask: 0.2561  decode.d1.loss_dice: 0.2694  decode.d2.loss_cls: 0.1318  decode.d2.loss_mask: 0.2570  decode.d2.loss_dice: 0.2712  decode.d3.loss_cls: 0.0970  decode.d3.loss_mask: 0.2582  decode.d3.loss_dice: 0.2701  decode.d4.loss_cls: 0.1116  decode.d4.loss_mask: 0.2582  decode.d4.loss_dice: 0.2763  decode.d5.loss_cls: 0.1181  decode.d5.loss_mask: 0.2566  decode.d5.loss_dice: 0.2644  decode.d6.loss_cls: 0.1059  decode.d6.loss_mask: 0.2554  decode.d6.loss_dice: 0.2600  decode.d7.loss_cls: 0.1092  decode.d7.loss_mask: 0.2590  decode.d7.loss_dice: 0.2714  decode.d8.loss_cls: 0.1024  decode.d8.loss_mask: 0.2551  decode.d8.loss_dice: 0.2780
07/30 20:31:11 - mmengine - INFO - Iter(train) [31750/80000]  base_lr: 6.3441e-05 lr: 6.3441e-06  eta: 5:50:52  time: 0.4373  data_time: 0.0094  memory: 5245  grad_norm: 775.1185  loss: 6.9905  decode.loss_cls: 0.1290  decode.loss_mask: 0.2038  decode.loss_dice: 0.2750  decode.d0.loss_cls: 0.9862  decode.d0.loss_mask: 0.2106  decode.d0.loss_dice: 0.2910  decode.d1.loss_cls: 0.1783  decode.d1.loss_mask: 0.2037  decode.d1.loss_dice: 0.2706  decode.d2.loss_cls: 0.0914  decode.d2.loss_mask: 0.2031  decode.d2.loss_dice: 0.2764  decode.d3.loss_cls: 0.1630  decode.d3.loss_mask: 0.2021  decode.d3.loss_dice: 0.2630  decode.d4.loss_cls: 0.0903  decode.d4.loss_mask: 0.2051  decode.d4.loss_dice: 0.2816  decode.d5.loss_cls: 0.1252  decode.d5.loss_mask: 0.2026  decode.d5.loss_dice: 0.2645  decode.d6.loss_cls: 0.1362  decode.d6.loss_mask: 0.2042  decode.d6.loss_dice: 0.2650  decode.d7.loss_cls: 0.1477  decode.d7.loss_mask: 0.2063  decode.d7.loss_dice: 0.2784  decode.d8.loss_cls: 0.1579  decode.d8.loss_mask: 0.2039  decode.d8.loss_dice: 0.2745
07/30 20:31:33 - mmengine - INFO - Iter(train) [31800/80000]  base_lr: 6.3382e-05 lr: 6.3382e-06  eta: 5:50:30  time: 0.4373  data_time: 0.0094  memory: 5277  grad_norm: 48.1741  loss: 6.9839  decode.loss_cls: 0.0851  decode.loss_mask: 0.2518  decode.loss_dice: 0.2574  decode.d0.loss_cls: 0.9671  decode.d0.loss_mask: 0.2501  decode.d0.loss_dice: 0.2494  decode.d1.loss_cls: 0.1382  decode.d1.loss_mask: 0.2469  decode.d1.loss_dice: 0.2476  decode.d2.loss_cls: 0.1293  decode.d2.loss_mask: 0.2449  decode.d2.loss_dice: 0.2412  decode.d3.loss_cls: 0.1171  decode.d3.loss_mask: 0.2449  decode.d3.loss_dice: 0.2446  decode.d4.loss_cls: 0.1145  decode.d4.loss_mask: 0.2450  decode.d4.loss_dice: 0.2491  decode.d5.loss_cls: 0.1112  decode.d5.loss_mask: 0.2456  decode.d5.loss_dice: 0.2487  decode.d6.loss_cls: 0.1202  decode.d6.loss_mask: 0.2431  decode.d6.loss_dice: 0.2400  decode.d7.loss_cls: 0.1146  decode.d7.loss_mask: 0.2459  decode.d7.loss_dice: 0.2520  decode.d8.loss_cls: 0.1458  decode.d8.loss_mask: 0.2440  decode.d8.loss_dice: 0.2490
07/30 20:31:55 - mmengine - INFO - Iter(train) [31850/80000]  base_lr: 6.3323e-05 lr: 6.3323e-06  eta: 5:50:09  time: 0.4370  data_time: 0.0093  memory: 5261  grad_norm: 60.9239  loss: 6.9605  decode.loss_cls: 0.1001  decode.loss_mask: 0.2239  decode.loss_dice: 0.2818  decode.d0.loss_cls: 0.9807  decode.d0.loss_mask: 0.2288  decode.d0.loss_dice: 0.2803  decode.d1.loss_cls: 0.1003  decode.d1.loss_mask: 0.2303  decode.d1.loss_dice: 0.2870  decode.d2.loss_cls: 0.0981  decode.d2.loss_mask: 0.2275  decode.d2.loss_dice: 0.2776  decode.d3.loss_cls: 0.1100  decode.d3.loss_mask: 0.2269  decode.d3.loss_dice: 0.2754  decode.d4.loss_cls: 0.1195  decode.d4.loss_mask: 0.2270  decode.d4.loss_dice: 0.2781  decode.d5.loss_cls: 0.1195  decode.d5.loss_mask: 0.2254  decode.d5.loss_dice: 0.2817  decode.d6.loss_cls: 0.1031  decode.d6.loss_mask: 0.2234  decode.d6.loss_dice: 0.2732  decode.d7.loss_cls: 0.0926  decode.d7.loss_mask: 0.2204  decode.d7.loss_dice: 0.2776  decode.d8.loss_cls: 0.0837  decode.d8.loss_mask: 0.2214  decode.d8.loss_dice: 0.2854
07/30 20:32:17 - mmengine - INFO - Iter(train) [31900/80000]  base_lr: 6.3264e-05 lr: 6.3264e-06  eta: 5:49:47  time: 0.4372  data_time: 0.0093  memory: 5279  grad_norm: 115.6785  loss: 8.9457  decode.loss_cls: 0.2580  decode.loss_mask: 0.2634  decode.loss_dice: 0.2937  decode.d0.loss_cls: 1.0535  decode.d0.loss_mask: 0.2559  decode.d0.loss_dice: 0.3246  decode.d1.loss_cls: 0.3298  decode.d1.loss_mask: 0.2591  decode.d1.loss_dice: 0.3033  decode.d2.loss_cls: 0.2006  decode.d2.loss_mask: 0.2582  decode.d2.loss_dice: 0.3075  decode.d3.loss_cls: 0.2130  decode.d3.loss_mask: 0.2637  decode.d3.loss_dice: 0.2918  decode.d4.loss_cls: 0.2362  decode.d4.loss_mask: 0.2572  decode.d4.loss_dice: 0.2868  decode.d5.loss_cls: 0.2888  decode.d5.loss_mask: 0.2595  decode.d5.loss_dice: 0.2860  decode.d6.loss_cls: 0.2691  decode.d6.loss_mask: 0.2591  decode.d6.loss_dice: 0.2888  decode.d7.loss_cls: 0.2787  decode.d7.loss_mask: 0.2601  decode.d7.loss_dice: 0.2811  decode.d8.loss_cls: 0.2639  decode.d8.loss_mask: 0.2606  decode.d8.loss_dice: 0.2938
07/30 20:32:38 - mmengine - INFO - Iter(train) [31950/80000]  base_lr: 6.3204e-05 lr: 6.3204e-06  eta: 5:49:25  time: 0.4372  data_time: 0.0093  memory: 5265  grad_norm: 64.2218  loss: 7.2190  decode.loss_cls: 0.1822  decode.loss_mask: 0.2201  decode.loss_dice: 0.2375  decode.d0.loss_cls: 1.0714  decode.d0.loss_mask: 0.2267  decode.d0.loss_dice: 0.2419  decode.d1.loss_cls: 0.2136  decode.d1.loss_mask: 0.2196  decode.d1.loss_dice: 0.2221  decode.d2.loss_cls: 0.2014  decode.d2.loss_mask: 0.2182  decode.d2.loss_dice: 0.2315  decode.d3.loss_cls: 0.1759  decode.d3.loss_mask: 0.2180  decode.d3.loss_dice: 0.2366  decode.d4.loss_cls: 0.1687  decode.d4.loss_mask: 0.2192  decode.d4.loss_dice: 0.2321  decode.d5.loss_cls: 0.1876  decode.d5.loss_mask: 0.2192  decode.d5.loss_dice: 0.2408  decode.d6.loss_cls: 0.1545  decode.d6.loss_mask: 0.2190  decode.d6.loss_dice: 0.2273  decode.d7.loss_cls: 0.1511  decode.d7.loss_mask: 0.2206  decode.d7.loss_dice: 0.2390  decode.d8.loss_cls: 0.1652  decode.d8.loss_mask: 0.2162  decode.d8.loss_dice: 0.2416
07/30 20:33:00 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 20:33:00 - mmengine - INFO - Iter(train) [32000/80000]  base_lr: 6.3145e-05 lr: 6.3145e-06  eta: 5:49:03  time: 0.4362  data_time: 0.0092  memory: 5265  grad_norm: 69.8847  loss: 6.8434  decode.loss_cls: 0.0986  decode.loss_mask: 0.2423  decode.loss_dice: 0.2668  decode.d0.loss_cls: 0.9599  decode.d0.loss_mask: 0.2531  decode.d0.loss_dice: 0.2675  decode.d1.loss_cls: 0.0954  decode.d1.loss_mask: 0.2432  decode.d1.loss_dice: 0.2646  decode.d2.loss_cls: 0.0927  decode.d2.loss_mask: 0.2413  decode.d2.loss_dice: 0.2620  decode.d3.loss_cls: 0.0735  decode.d3.loss_mask: 0.2410  decode.d3.loss_dice: 0.2666  decode.d4.loss_cls: 0.1034  decode.d4.loss_mask: 0.2444  decode.d4.loss_dice: 0.2671  decode.d5.loss_cls: 0.0957  decode.d5.loss_mask: 0.2404  decode.d5.loss_dice: 0.2724  decode.d6.loss_cls: 0.0828  decode.d6.loss_mask: 0.2442  decode.d6.loss_dice: 0.2613  decode.d7.loss_cls: 0.0715  decode.d7.loss_mask: 0.2445  decode.d7.loss_dice: 0.2645  decode.d8.loss_cls: 0.0718  decode.d8.loss_mask: 0.2427  decode.d8.loss_dice: 0.2683
07/30 20:33:22 - mmengine - INFO - Iter(train) [32050/80000]  base_lr: 6.3086e-05 lr: 6.3086e-06  eta: 5:48:42  time: 0.4368  data_time: 0.0092  memory: 5277  grad_norm: 62.0543  loss: 6.8503  decode.loss_cls: 0.1988  decode.loss_mask: 0.2236  decode.loss_dice: 0.2157  decode.d0.loss_cls: 0.9118  decode.d0.loss_mask: 0.2283  decode.d0.loss_dice: 0.2234  decode.d1.loss_cls: 0.1445  decode.d1.loss_mask: 0.2248  decode.d1.loss_dice: 0.2482  decode.d2.loss_cls: 0.1445  decode.d2.loss_mask: 0.2259  decode.d2.loss_dice: 0.2129  decode.d3.loss_cls: 0.1431  decode.d3.loss_mask: 0.2281  decode.d3.loss_dice: 0.2299  decode.d4.loss_cls: 0.1506  decode.d4.loss_mask: 0.2230  decode.d4.loss_dice: 0.2343  decode.d5.loss_cls: 0.1269  decode.d5.loss_mask: 0.2252  decode.d5.loss_dice: 0.2371  decode.d6.loss_cls: 0.1365  decode.d6.loss_mask: 0.2244  decode.d6.loss_dice: 0.2226  decode.d7.loss_cls: 0.1628  decode.d7.loss_mask: 0.2210  decode.d7.loss_dice: 0.2277  decode.d8.loss_cls: 0.2197  decode.d8.loss_mask: 0.2268  decode.d8.loss_dice: 0.2084
07/30 20:33:44 - mmengine - INFO - Iter(train) [32100/80000]  base_lr: 6.3027e-05 lr: 6.3027e-06  eta: 5:48:20  time: 0.4366  data_time: 0.0093  memory: 5245  grad_norm: 87.7091  loss: 8.6244  decode.loss_cls: 0.1938  decode.loss_mask: 0.2525  decode.loss_dice: 0.2935  decode.d0.loss_cls: 0.9605  decode.d0.loss_mask: 0.2649  decode.d0.loss_dice: 0.3386  decode.d1.loss_cls: 0.2451  decode.d1.loss_mask: 0.2628  decode.d1.loss_dice: 0.3279  decode.d2.loss_cls: 0.2658  decode.d2.loss_mask: 0.2585  decode.d2.loss_dice: 0.3222  decode.d3.loss_cls: 0.2278  decode.d3.loss_mask: 0.2545  decode.d3.loss_dice: 0.2898  decode.d4.loss_cls: 0.2375  decode.d4.loss_mask: 0.2647  decode.d4.loss_dice: 0.2896  decode.d5.loss_cls: 0.2219  decode.d5.loss_mask: 0.2575  decode.d5.loss_dice: 0.2849  decode.d6.loss_cls: 0.2075  decode.d6.loss_mask: 0.2569  decode.d6.loss_dice: 0.2866  decode.d7.loss_cls: 0.2092  decode.d7.loss_mask: 0.2618  decode.d7.loss_dice: 0.2798  decode.d8.loss_cls: 0.2237  decode.d8.loss_mask: 0.2646  decode.d8.loss_dice: 0.3201
07/30 20:34:06 - mmengine - INFO - Iter(train) [32150/80000]  base_lr: 6.2968e-05 lr: 6.2968e-06  eta: 5:47:58  time: 0.4369  data_time: 0.0091  memory: 5265  grad_norm: 84.4121  loss: 6.7409  decode.loss_cls: 0.1782  decode.loss_mask: 0.1631  decode.loss_dice: 0.2186  decode.d0.loss_cls: 1.2575  decode.d0.loss_mask: 0.1741  decode.d0.loss_dice: 0.2787  decode.d1.loss_cls: 0.2146  decode.d1.loss_mask: 0.1613  decode.d1.loss_dice: 0.2403  decode.d2.loss_cls: 0.1878  decode.d2.loss_mask: 0.1594  decode.d2.loss_dice: 0.2048  decode.d3.loss_cls: 0.1718  decode.d3.loss_mask: 0.1607  decode.d3.loss_dice: 0.2147  decode.d4.loss_cls: 0.1942  decode.d4.loss_mask: 0.1616  decode.d4.loss_dice: 0.2240  decode.d5.loss_cls: 0.1555  decode.d5.loss_mask: 0.1588  decode.d5.loss_dice: 0.2152  decode.d6.loss_cls: 0.1760  decode.d6.loss_mask: 0.1586  decode.d6.loss_dice: 0.2129  decode.d7.loss_cls: 0.1878  decode.d7.loss_mask: 0.1577  decode.d7.loss_dice: 0.2155  decode.d8.loss_cls: 0.1651  decode.d8.loss_mask: 0.1605  decode.d8.loss_dice: 0.2120
07/30 20:34:28 - mmengine - INFO - Iter(train) [32200/80000]  base_lr: 6.2908e-05 lr: 6.2908e-06  eta: 5:47:36  time: 0.4367  data_time: 0.0092  memory: 5246  grad_norm: 131.4188  loss: 9.9814  decode.loss_cls: 0.2739  decode.loss_mask: 0.3578  decode.loss_dice: 0.3210  decode.d0.loss_cls: 1.0290  decode.d0.loss_mask: 0.3286  decode.d0.loss_dice: 0.3556  decode.d1.loss_cls: 0.3029  decode.d1.loss_mask: 0.3295  decode.d1.loss_dice: 0.3274  decode.d2.loss_cls: 0.2586  decode.d2.loss_mask: 0.3328  decode.d2.loss_dice: 0.3020  decode.d3.loss_cls: 0.2378  decode.d3.loss_mask: 0.3434  decode.d3.loss_dice: 0.3138  decode.d4.loss_cls: 0.2553  decode.d4.loss_mask: 0.3256  decode.d4.loss_dice: 0.3129  decode.d5.loss_cls: 0.2282  decode.d5.loss_mask: 0.4424  decode.d5.loss_dice: 0.3196  decode.d6.loss_cls: 0.2246  decode.d6.loss_mask: 0.3165  decode.d6.loss_dice: 0.3288  decode.d7.loss_cls: 0.2532  decode.d7.loss_mask: 0.3224  decode.d7.loss_dice: 0.3172  decode.d8.loss_cls: 0.2521  decode.d8.loss_mask: 0.3690  decode.d8.loss_dice: 0.2994
07/30 20:34:49 - mmengine - INFO - Iter(train) [32250/80000]  base_lr: 6.2849e-05 lr: 6.2849e-06  eta: 5:47:15  time: 0.4365  data_time: 0.0094  memory: 5265  grad_norm: 129.1127  loss: 10.6756  decode.loss_cls: 0.3495  decode.loss_mask: 0.3424  decode.loss_dice: 0.3501  decode.d0.loss_cls: 1.0692  decode.d0.loss_mask: 0.3401  decode.d0.loss_dice: 0.3523  decode.d1.loss_cls: 0.4296  decode.d1.loss_mask: 0.3346  decode.d1.loss_dice: 0.2882  decode.d2.loss_cls: 0.3140  decode.d2.loss_mask: 0.3331  decode.d2.loss_dice: 0.3415  decode.d3.loss_cls: 0.2922  decode.d3.loss_mask: 0.3291  decode.d3.loss_dice: 0.3093  decode.d4.loss_cls: 0.2973  decode.d4.loss_mask: 0.3477  decode.d4.loss_dice: 0.3603  decode.d5.loss_cls: 0.3270  decode.d5.loss_mask: 0.3541  decode.d5.loss_dice: 0.3414  decode.d6.loss_cls: 0.3072  decode.d6.loss_mask: 0.3201  decode.d6.loss_dice: 0.3332  decode.d7.loss_cls: 0.2735  decode.d7.loss_mask: 0.3271  decode.d7.loss_dice: 0.3252  decode.d8.loss_cls: 0.3349  decode.d8.loss_mask: 0.3291  decode.d8.loss_dice: 0.3224
07/30 20:35:11 - mmengine - INFO - Iter(train) [32300/80000]  base_lr: 6.2790e-05 lr: 6.2790e-06  eta: 5:46:53  time: 0.4381  data_time: 0.0093  memory: 5261  grad_norm: 100.2050  loss: 6.7769  decode.loss_cls: 0.1349  decode.loss_mask: 0.1982  decode.loss_dice: 0.2670  decode.d0.loss_cls: 1.0316  decode.d0.loss_mask: 0.1956  decode.d0.loss_dice: 0.3002  decode.d1.loss_cls: 0.1443  decode.d1.loss_mask: 0.1991  decode.d1.loss_dice: 0.2478  decode.d2.loss_cls: 0.0939  decode.d2.loss_mask: 0.1948  decode.d2.loss_dice: 0.2596  decode.d3.loss_cls: 0.0923  decode.d3.loss_mask: 0.1965  decode.d3.loss_dice: 0.2466  decode.d4.loss_cls: 0.1176  decode.d4.loss_mask: 0.1929  decode.d4.loss_dice: 0.2409  decode.d5.loss_cls: 0.1122  decode.d5.loss_mask: 0.1940  decode.d5.loss_dice: 0.2683  decode.d6.loss_cls: 0.1480  decode.d6.loss_mask: 0.1940  decode.d6.loss_dice: 0.2524  decode.d7.loss_cls: 0.0991  decode.d7.loss_mask: 0.1945  decode.d7.loss_dice: 0.2844  decode.d8.loss_cls: 0.1807  decode.d8.loss_mask: 0.1992  decode.d8.loss_dice: 0.2967
07/30 20:35:33 - mmengine - INFO - Iter(train) [32350/80000]  base_lr: 6.2731e-05 lr: 6.2731e-06  eta: 5:46:31  time: 0.4378  data_time: 0.0094  memory: 5303  grad_norm: 72.5645  loss: 8.3503  decode.loss_cls: 0.2523  decode.loss_mask: 0.2204  decode.loss_dice: 0.2342  decode.d0.loss_cls: 1.0736  decode.d0.loss_mask: 0.2277  decode.d0.loss_dice: 0.2978  decode.d1.loss_cls: 0.3809  decode.d1.loss_mask: 0.2201  decode.d1.loss_dice: 0.2574  decode.d2.loss_cls: 0.3053  decode.d2.loss_mask: 0.2229  decode.d2.loss_dice: 0.2638  decode.d3.loss_cls: 0.2723  decode.d3.loss_mask: 0.2179  decode.d3.loss_dice: 0.2507  decode.d4.loss_cls: 0.2191  decode.d4.loss_mask: 0.2194  decode.d4.loss_dice: 0.2608  decode.d5.loss_cls: 0.2223  decode.d5.loss_mask: 0.2192  decode.d5.loss_dice: 0.2653  decode.d6.loss_cls: 0.2692  decode.d6.loss_mask: 0.2196  decode.d6.loss_dice: 0.2660  decode.d7.loss_cls: 0.2901  decode.d7.loss_mask: 0.2192  decode.d7.loss_dice: 0.2763  decode.d8.loss_cls: 0.2104  decode.d8.loss_mask: 0.2220  decode.d8.loss_dice: 0.2740
07/30 20:35:55 - mmengine - INFO - Iter(train) [32400/80000]  base_lr: 6.2672e-05 lr: 6.2672e-06  eta: 5:46:09  time: 0.4365  data_time: 0.0094  memory: 5244  grad_norm: 86.4047  loss: 6.7418  decode.loss_cls: 0.1773  decode.loss_mask: 0.1915  decode.loss_dice: 0.2271  decode.d0.loss_cls: 1.0610  decode.d0.loss_mask: 0.1957  decode.d0.loss_dice: 0.2211  decode.d1.loss_cls: 0.1795  decode.d1.loss_mask: 0.1914  decode.d1.loss_dice: 0.2182  decode.d2.loss_cls: 0.1566  decode.d2.loss_mask: 0.1931  decode.d2.loss_dice: 0.2175  decode.d3.loss_cls: 0.1767  decode.d3.loss_mask: 0.1914  decode.d3.loss_dice: 0.2288  decode.d4.loss_cls: 0.1763  decode.d4.loss_mask: 0.1892  decode.d4.loss_dice: 0.2256  decode.d5.loss_cls: 0.1580  decode.d5.loss_mask: 0.1899  decode.d5.loss_dice: 0.2289  decode.d6.loss_cls: 0.1399  decode.d6.loss_mask: 0.1927  decode.d6.loss_dice: 0.2368  decode.d7.loss_cls: 0.1327  decode.d7.loss_mask: 0.1929  decode.d7.loss_dice: 0.2358  decode.d8.loss_cls: 0.1972  decode.d8.loss_mask: 0.1937  decode.d8.loss_dice: 0.2253
07/30 20:36:17 - mmengine - INFO - Iter(train) [32450/80000]  base_lr: 6.2612e-05 lr: 6.2612e-06  eta: 5:45:48  time: 0.4367  data_time: 0.0093  memory: 5305  grad_norm: 90.8073  loss: 9.8071  decode.loss_cls: 0.2368  decode.loss_mask: 0.2674  decode.loss_dice: 0.3832  decode.d0.loss_cls: 1.0587  decode.d0.loss_mask: 0.2686  decode.d0.loss_dice: 0.4047  decode.d1.loss_cls: 0.3158  decode.d1.loss_mask: 0.2570  decode.d1.loss_dice: 0.3906  decode.d2.loss_cls: 0.3182  decode.d2.loss_mask: 0.2683  decode.d2.loss_dice: 0.3924  decode.d3.loss_cls: 0.2176  decode.d3.loss_mask: 0.2579  decode.d3.loss_dice: 0.3742  decode.d4.loss_cls: 0.1974  decode.d4.loss_mask: 0.2672  decode.d4.loss_dice: 0.3898  decode.d5.loss_cls: 0.2015  decode.d5.loss_mask: 0.2632  decode.d5.loss_dice: 0.4074  decode.d6.loss_cls: 0.2241  decode.d6.loss_mask: 0.2665  decode.d6.loss_dice: 0.3930  decode.d7.loss_cls: 0.2239  decode.d7.loss_mask: 0.2545  decode.d7.loss_dice: 0.3750  decode.d8.loss_cls: 0.2332  decode.d8.loss_mask: 0.2720  decode.d8.loss_dice: 0.4271
07/30 20:36:39 - mmengine - INFO - Iter(train) [32500/80000]  base_lr: 6.2553e-05 lr: 6.2553e-06  eta: 5:45:26  time: 0.4381  data_time: 0.0096  memory: 5261  grad_norm: 82.5912  loss: 8.6950  decode.loss_cls: 0.2116  decode.loss_mask: 0.2866  decode.loss_dice: 0.2675  decode.d0.loss_cls: 1.0796  decode.d0.loss_mask: 0.3116  decode.d0.loss_dice: 0.2805  decode.d1.loss_cls: 0.2833  decode.d1.loss_mask: 0.2834  decode.d1.loss_dice: 0.2648  decode.d2.loss_cls: 0.2462  decode.d2.loss_mask: 0.2871  decode.d2.loss_dice: 0.2630  decode.d3.loss_cls: 0.2351  decode.d3.loss_mask: 0.2884  decode.d3.loss_dice: 0.2555  decode.d4.loss_cls: 0.1878  decode.d4.loss_mask: 0.2875  decode.d4.loss_dice: 0.2712  decode.d5.loss_cls: 0.2652  decode.d5.loss_mask: 0.2883  decode.d5.loss_dice: 0.2584  decode.d6.loss_cls: 0.2774  decode.d6.loss_mask: 0.2860  decode.d6.loss_dice: 0.2621  decode.d7.loss_cls: 0.1437  decode.d7.loss_mask: 0.2917  decode.d7.loss_dice: 0.2586  decode.d8.loss_cls: 0.2214  decode.d8.loss_mask: 0.2843  decode.d8.loss_dice: 0.2675
07/30 20:37:01 - mmengine - INFO - Iter(train) [32550/80000]  base_lr: 6.2494e-05 lr: 6.2494e-06  eta: 5:45:04  time: 0.4370  data_time: 0.0097  memory: 5213  grad_norm: 63.8661  loss: 8.5097  decode.loss_cls: 0.1464  decode.loss_mask: 0.2886  decode.loss_dice: 0.3279  decode.d0.loss_cls: 0.9125  decode.d0.loss_mask: 0.2960  decode.d0.loss_dice: 0.3346  decode.d1.loss_cls: 0.2375  decode.d1.loss_mask: 0.2865  decode.d1.loss_dice: 0.3042  decode.d2.loss_cls: 0.1966  decode.d2.loss_mask: 0.2867  decode.d2.loss_dice: 0.3138  decode.d3.loss_cls: 0.1277  decode.d3.loss_mask: 0.2891  decode.d3.loss_dice: 0.3267  decode.d4.loss_cls: 0.1311  decode.d4.loss_mask: 0.2870  decode.d4.loss_dice: 0.3305  decode.d5.loss_cls: 0.1262  decode.d5.loss_mask: 0.2872  decode.d5.loss_dice: 0.3223  decode.d6.loss_cls: 0.1267  decode.d6.loss_mask: 0.2871  decode.d6.loss_dice: 0.3162  decode.d7.loss_cls: 0.1875  decode.d7.loss_mask: 0.2874  decode.d7.loss_dice: 0.3411  decode.d8.loss_cls: 0.1833  decode.d8.loss_mask: 0.2876  decode.d8.loss_dice: 0.3337
07/30 20:37:23 - mmengine - INFO - Iter(train) [32600/80000]  base_lr: 6.2434e-05 lr: 6.2434e-06  eta: 5:44:42  time: 0.4378  data_time: 0.0094  memory: 5279  grad_norm: 43.1204  loss: 7.9469  decode.loss_cls: 0.1542  decode.loss_mask: 0.2328  decode.loss_dice: 0.3002  decode.d0.loss_cls: 1.0417  decode.d0.loss_mask: 0.2413  decode.d0.loss_dice: 0.3416  decode.d1.loss_cls: 0.1801  decode.d1.loss_mask: 0.2339  decode.d1.loss_dice: 0.3011  decode.d2.loss_cls: 0.1784  decode.d2.loss_mask: 0.2350  decode.d2.loss_dice: 0.2986  decode.d3.loss_cls: 0.1811  decode.d3.loss_mask: 0.2310  decode.d3.loss_dice: 0.2685  decode.d4.loss_cls: 0.1727  decode.d4.loss_mask: 0.2318  decode.d4.loss_dice: 0.2881  decode.d5.loss_cls: 0.1616  decode.d5.loss_mask: 0.2314  decode.d5.loss_dice: 0.2998  decode.d6.loss_cls: 0.1743  decode.d6.loss_mask: 0.2328  decode.d6.loss_dice: 0.3008  decode.d7.loss_cls: 0.1877  decode.d7.loss_mask: 0.2339  decode.d7.loss_dice: 0.3062  decode.d8.loss_cls: 0.1773  decode.d8.loss_mask: 0.2371  decode.d8.loss_dice: 0.2916
07/30 20:37:44 - mmengine - INFO - Iter(train) [32650/80000]  base_lr: 6.2375e-05 lr: 6.2375e-06  eta: 5:44:21  time: 0.4370  data_time: 0.0095  memory: 5279  grad_norm: 87.2354  loss: 6.1510  decode.loss_cls: 0.0394  decode.loss_mask: 0.2478  decode.loss_dice: 0.2553  decode.d0.loss_cls: 0.7380  decode.d0.loss_mask: 0.2551  decode.d0.loss_dice: 0.2794  decode.d1.loss_cls: 0.0521  decode.d1.loss_mask: 0.2465  decode.d1.loss_dice: 0.2612  decode.d2.loss_cls: 0.0341  decode.d2.loss_mask: 0.2500  decode.d2.loss_dice: 0.2588  decode.d3.loss_cls: 0.0244  decode.d3.loss_mask: 0.2488  decode.d3.loss_dice: 0.2522  decode.d4.loss_cls: 0.0567  decode.d4.loss_mask: 0.2486  decode.d4.loss_dice: 0.2509  decode.d5.loss_cls: 0.0286  decode.d5.loss_mask: 0.2502  decode.d5.loss_dice: 0.2546  decode.d6.loss_cls: 0.0272  decode.d6.loss_mask: 0.2502  decode.d6.loss_dice: 0.2483  decode.d7.loss_cls: 0.0397  decode.d7.loss_mask: 0.2512  decode.d7.loss_dice: 0.2559  decode.d8.loss_cls: 0.0401  decode.d8.loss_mask: 0.2502  decode.d8.loss_dice: 0.2553
07/30 20:38:06 - mmengine - INFO - Iter(train) [32700/80000]  base_lr: 6.2316e-05 lr: 6.2316e-06  eta: 5:43:59  time: 0.4391  data_time: 0.0095  memory: 5278  grad_norm: 39.2697  loss: 5.1952  decode.loss_cls: 0.0467  decode.loss_mask: 0.1643  decode.loss_dice: 0.2153  decode.d0.loss_cls: 0.8908  decode.d0.loss_mask: 0.1650  decode.d0.loss_dice: 0.2306  decode.d1.loss_cls: 0.0482  decode.d1.loss_mask: 0.1647  decode.d1.loss_dice: 0.2151  decode.d2.loss_cls: 0.0386  decode.d2.loss_mask: 0.1653  decode.d2.loss_dice: 0.2171  decode.d3.loss_cls: 0.0555  decode.d3.loss_mask: 0.1655  decode.d3.loss_dice: 0.2170  decode.d4.loss_cls: 0.0460  decode.d4.loss_mask: 0.1667  decode.d4.loss_dice: 0.2175  decode.d5.loss_cls: 0.0400  decode.d5.loss_mask: 0.1667  decode.d5.loss_dice: 0.2199  decode.d6.loss_cls: 0.0746  decode.d6.loss_mask: 0.1664  decode.d6.loss_dice: 0.2119  decode.d7.loss_cls: 0.0786  decode.d7.loss_mask: 0.1665  decode.d7.loss_dice: 0.2188  decode.d8.loss_cls: 0.0461  decode.d8.loss_mask: 0.1648  decode.d8.loss_dice: 0.2112
07/30 20:38:28 - mmengine - INFO - Iter(train) [32750/80000]  base_lr: 6.2257e-05 lr: 6.2257e-06  eta: 5:43:37  time: 0.4376  data_time: 0.0097  memory: 5213  grad_norm: 66.1261  loss: 6.8197  decode.loss_cls: 0.1392  decode.loss_mask: 0.2009  decode.loss_dice: 0.2535  decode.d0.loss_cls: 0.9626  decode.d0.loss_mask: 0.2007  decode.d0.loss_dice: 0.2804  decode.d1.loss_cls: 0.2439  decode.d1.loss_mask: 0.2006  decode.d1.loss_dice: 0.2605  decode.d2.loss_cls: 0.1621  decode.d2.loss_mask: 0.1981  decode.d2.loss_dice: 0.2416  decode.d3.loss_cls: 0.1415  decode.d3.loss_mask: 0.1968  decode.d3.loss_dice: 0.2454  decode.d4.loss_cls: 0.1336  decode.d4.loss_mask: 0.1992  decode.d4.loss_dice: 0.2413  decode.d5.loss_cls: 0.1588  decode.d5.loss_mask: 0.1997  decode.d5.loss_dice: 0.2367  decode.d6.loss_cls: 0.1654  decode.d6.loss_mask: 0.1982  decode.d6.loss_dice: 0.2410  decode.d7.loss_cls: 0.1129  decode.d7.loss_mask: 0.1991  decode.d7.loss_dice: 0.2475  decode.d8.loss_cls: 0.1261  decode.d8.loss_mask: 0.1984  decode.d8.loss_dice: 0.2341
07/30 20:38:50 - mmengine - INFO - Iter(train) [32800/80000]  base_lr: 6.2197e-05 lr: 6.2197e-06  eta: 5:43:15  time: 0.4366  data_time: 0.0096  memory: 5279  grad_norm: 286.6469  loss: 12.4978  decode.loss_cls: 0.3209  decode.loss_mask: 0.4759  decode.loss_dice: 0.3712  decode.d0.loss_cls: 0.9762  decode.d0.loss_mask: 0.5216  decode.d0.loss_dice: 0.4315  decode.d1.loss_cls: 0.2155  decode.d1.loss_mask: 0.5238  decode.d1.loss_dice: 0.3981  decode.d2.loss_cls: 0.2997  decode.d2.loss_mask: 0.5116  decode.d2.loss_dice: 0.4008  decode.d3.loss_cls: 0.3039  decode.d3.loss_mask: 0.5012  decode.d3.loss_dice: 0.3903  decode.d4.loss_cls: 0.2749  decode.d4.loss_mask: 0.5062  decode.d4.loss_dice: 0.4062  decode.d5.loss_cls: 0.2643  decode.d5.loss_mask: 0.4850  decode.d5.loss_dice: 0.4005  decode.d6.loss_cls: 0.3183  decode.d6.loss_mask: 0.4727  decode.d6.loss_dice: 0.3890  decode.d7.loss_cls: 0.3515  decode.d7.loss_mask: 0.4752  decode.d7.loss_dice: 0.3649  decode.d8.loss_cls: 0.2990  decode.d8.loss_mask: 0.4793  decode.d8.loss_dice: 0.3686
07/30 20:39:12 - mmengine - INFO - Iter(train) [32850/80000]  base_lr: 6.2138e-05 lr: 6.2138e-06  eta: 5:42:54  time: 0.4377  data_time: 0.0094  memory: 5265  grad_norm: 170.6385  loss: 7.2274  decode.loss_cls: 0.1375  decode.loss_mask: 0.2368  decode.loss_dice: 0.2559  decode.d0.loss_cls: 0.9580  decode.d0.loss_mask: 0.2556  decode.d0.loss_dice: 0.2778  decode.d1.loss_cls: 0.1480  decode.d1.loss_mask: 0.2413  decode.d1.loss_dice: 0.2613  decode.d2.loss_cls: 0.1543  decode.d2.loss_mask: 0.2391  decode.d2.loss_dice: 0.2553  decode.d3.loss_cls: 0.1116  decode.d3.loss_mask: 0.2381  decode.d3.loss_dice: 0.2628  decode.d4.loss_cls: 0.1139  decode.d4.loss_mask: 0.2443  decode.d4.loss_dice: 0.2623  decode.d5.loss_cls: 0.1156  decode.d5.loss_mask: 0.2404  decode.d5.loss_dice: 0.2627  decode.d6.loss_cls: 0.1514  decode.d6.loss_mask: 0.2455  decode.d6.loss_dice: 0.2586  decode.d7.loss_cls: 0.1656  decode.d7.loss_mask: 0.2402  decode.d7.loss_dice: 0.2583  decode.d8.loss_cls: 0.1419  decode.d8.loss_mask: 0.2411  decode.d8.loss_dice: 0.2520
07/30 20:39:34 - mmengine - INFO - Iter(train) [32900/80000]  base_lr: 6.2079e-05 lr: 6.2079e-06  eta: 5:42:32  time: 0.4377  data_time: 0.0095  memory: 5279  grad_norm: 67.6406  loss: 7.4407  decode.loss_cls: 0.1639  decode.loss_mask: 0.2233  decode.loss_dice: 0.2551  decode.d0.loss_cls: 1.0761  decode.d0.loss_mask: 0.2383  decode.d0.loss_dice: 0.2880  decode.d1.loss_cls: 0.1821  decode.d1.loss_mask: 0.2366  decode.d1.loss_dice: 0.2649  decode.d2.loss_cls: 0.2118  decode.d2.loss_mask: 0.2239  decode.d2.loss_dice: 0.2536  decode.d3.loss_cls: 0.1830  decode.d3.loss_mask: 0.2265  decode.d3.loss_dice: 0.2404  decode.d4.loss_cls: 0.1747  decode.d4.loss_mask: 0.2249  decode.d4.loss_dice: 0.2412  decode.d5.loss_cls: 0.1406  decode.d5.loss_mask: 0.2243  decode.d5.loss_dice: 0.2438  decode.d6.loss_cls: 0.1717  decode.d6.loss_mask: 0.2216  decode.d6.loss_dice: 0.2400  decode.d7.loss_cls: 0.1642  decode.d7.loss_mask: 0.2242  decode.d7.loss_dice: 0.2380  decode.d8.loss_cls: 0.1774  decode.d8.loss_mask: 0.2256  decode.d8.loss_dice: 0.2608
07/30 20:39:56 - mmengine - INFO - Iter(train) [32950/80000]  base_lr: 6.2019e-05 lr: 6.2019e-06  eta: 5:42:10  time: 0.4371  data_time: 0.0095  memory: 5278  grad_norm: 42.1639  loss: 7.5721  decode.loss_cls: 0.1647  decode.loss_mask: 0.2325  decode.loss_dice: 0.2813  decode.d0.loss_cls: 0.9383  decode.d0.loss_mask: 0.2352  decode.d0.loss_dice: 0.2645  decode.d1.loss_cls: 0.1911  decode.d1.loss_mask: 0.2299  decode.d1.loss_dice: 0.2926  decode.d2.loss_cls: 0.1791  decode.d2.loss_mask: 0.2312  decode.d2.loss_dice: 0.2681  decode.d3.loss_cls: 0.1645  decode.d3.loss_mask: 0.2261  decode.d3.loss_dice: 0.2768  decode.d4.loss_cls: 0.1864  decode.d4.loss_mask: 0.2285  decode.d4.loss_dice: 0.2677  decode.d5.loss_cls: 0.2072  decode.d5.loss_mask: 0.2287  decode.d5.loss_dice: 0.2842  decode.d6.loss_cls: 0.1702  decode.d6.loss_mask: 0.2303  decode.d6.loss_dice: 0.2668  decode.d7.loss_cls: 0.1448  decode.d7.loss_mask: 0.2294  decode.d7.loss_dice: 0.2640  decode.d8.loss_cls: 0.1961  decode.d8.loss_mask: 0.2305  decode.d8.loss_dice: 0.2612
07/30 20:40:18 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 20:40:18 - mmengine - INFO - Iter(train) [33000/80000]  base_lr: 6.1960e-05 lr: 6.1960e-06  eta: 5:41:48  time: 0.4381  data_time: 0.0093  memory: 5227  grad_norm: 40.8021  loss: 5.7653  decode.loss_cls: 0.0622  decode.loss_mask: 0.2059  decode.loss_dice: 0.2311  decode.d0.loss_cls: 0.9185  decode.d0.loss_mask: 0.2112  decode.d0.loss_dice: 0.2352  decode.d1.loss_cls: 0.0415  decode.d1.loss_mask: 0.2110  decode.d1.loss_dice: 0.2430  decode.d2.loss_cls: 0.1161  decode.d2.loss_mask: 0.2080  decode.d2.loss_dice: 0.2246  decode.d3.loss_cls: 0.0546  decode.d3.loss_mask: 0.2038  decode.d3.loss_dice: 0.2261  decode.d4.loss_cls: 0.0351  decode.d4.loss_mask: 0.2060  decode.d4.loss_dice: 0.2267  decode.d5.loss_cls: 0.0406  decode.d5.loss_mask: 0.2074  decode.d5.loss_dice: 0.2278  decode.d6.loss_cls: 0.0342  decode.d6.loss_mask: 0.2064  decode.d6.loss_dice: 0.2243  decode.d7.loss_cls: 0.0406  decode.d7.loss_mask: 0.2084  decode.d7.loss_dice: 0.2274  decode.d8.loss_cls: 0.0535  decode.d8.loss_mask: 0.2093  decode.d8.loss_dice: 0.2249
07/30 20:40:39 - mmengine - INFO - Iter(train) [33050/80000]  base_lr: 6.1901e-05 lr: 6.1901e-06  eta: 5:41:27  time: 0.4376  data_time: 0.0093  memory: 5279  grad_norm: 39.6729  loss: 6.0729  decode.loss_cls: 0.0837  decode.loss_mask: 0.2134  decode.loss_dice: 0.2218  decode.d0.loss_cls: 0.9350  decode.d0.loss_mask: 0.2203  decode.d0.loss_dice: 0.2291  decode.d1.loss_cls: 0.0748  decode.d1.loss_mask: 0.2095  decode.d1.loss_dice: 0.2254  decode.d2.loss_cls: 0.0774  decode.d2.loss_mask: 0.2117  decode.d2.loss_dice: 0.2207  decode.d3.loss_cls: 0.0702  decode.d3.loss_mask: 0.2105  decode.d3.loss_dice: 0.2288  decode.d4.loss_cls: 0.0834  decode.d4.loss_mask: 0.2130  decode.d4.loss_dice: 0.2239  decode.d5.loss_cls: 0.0945  decode.d5.loss_mask: 0.2118  decode.d5.loss_dice: 0.2199  decode.d6.loss_cls: 0.0944  decode.d6.loss_mask: 0.2112  decode.d6.loss_dice: 0.2229  decode.d7.loss_cls: 0.1103  decode.d7.loss_mask: 0.2142  decode.d7.loss_dice: 0.2262  decode.d8.loss_cls: 0.0723  decode.d8.loss_mask: 0.2127  decode.d8.loss_dice: 0.2298
07/30 20:41:01 - mmengine - INFO - Iter(train) [33100/80000]  base_lr: 6.1841e-05 lr: 6.1841e-06  eta: 5:41:05  time: 0.4387  data_time: 0.0094  memory: 5278  grad_norm: 95.8715  loss: 7.7115  decode.loss_cls: 0.1229  decode.loss_mask: 0.2804  decode.loss_dice: 0.2614  decode.d0.loss_cls: 0.9645  decode.d0.loss_mask: 0.2865  decode.d0.loss_dice: 0.2938  decode.d1.loss_cls: 0.1386  decode.d1.loss_mask: 0.2813  decode.d1.loss_dice: 0.2639  decode.d2.loss_cls: 0.1055  decode.d2.loss_mask: 0.2781  decode.d2.loss_dice: 0.2707  decode.d3.loss_cls: 0.0882  decode.d3.loss_mask: 0.2820  decode.d3.loss_dice: 0.2669  decode.d4.loss_cls: 0.1107  decode.d4.loss_mask: 0.2793  decode.d4.loss_dice: 0.2658  decode.d5.loss_cls: 0.1689  decode.d5.loss_mask: 0.2796  decode.d5.loss_dice: 0.2647  decode.d6.loss_cls: 0.2010  decode.d6.loss_mask: 0.2826  decode.d6.loss_dice: 0.2730  decode.d7.loss_cls: 0.1693  decode.d7.loss_mask: 0.2789  decode.d7.loss_dice: 0.2796  decode.d8.loss_cls: 0.1314  decode.d8.loss_mask: 0.2767  decode.d8.loss_dice: 0.2654
07/30 20:41:23 - mmengine - INFO - Iter(train) [33150/80000]  base_lr: 6.1782e-05 lr: 6.1782e-06  eta: 5:40:43  time: 0.4386  data_time: 0.0095  memory: 5279  grad_norm: 76.9479  loss: 10.5198  decode.loss_cls: 0.3507  decode.loss_mask: 0.2666  decode.loss_dice: 0.3360  decode.d0.loss_cls: 1.1311  decode.d0.loss_mask: 0.2776  decode.d0.loss_dice: 0.3975  decode.d1.loss_cls: 0.3950  decode.d1.loss_mask: 0.2682  decode.d1.loss_dice: 0.3578  decode.d2.loss_cls: 0.3586  decode.d2.loss_mask: 0.2673  decode.d2.loss_dice: 0.3347  decode.d3.loss_cls: 0.3337  decode.d3.loss_mask: 0.2708  decode.d3.loss_dice: 0.3378  decode.d4.loss_cls: 0.3279  decode.d4.loss_mask: 0.2635  decode.d4.loss_dice: 0.3597  decode.d5.loss_cls: 0.3584  decode.d5.loss_mask: 0.2627  decode.d5.loss_dice: 0.3489  decode.d6.loss_cls: 0.3344  decode.d6.loss_mask: 0.2656  decode.d6.loss_dice: 0.3584  decode.d7.loss_cls: 0.3556  decode.d7.loss_mask: 0.2695  decode.d7.loss_dice: 0.3835  decode.d8.loss_cls: 0.3355  decode.d8.loss_mask: 0.2671  decode.d8.loss_dice: 0.3460
07/30 20:41:45 - mmengine - INFO - Iter(train) [33200/80000]  base_lr: 6.1723e-05 lr: 6.1723e-06  eta: 5:40:22  time: 0.4373  data_time: 0.0095  memory: 5261  grad_norm: 62.2298  loss: 8.6217  decode.loss_cls: 0.1971  decode.loss_mask: 0.2585  decode.loss_dice: 0.3150  decode.d0.loss_cls: 0.9478  decode.d0.loss_mask: 0.2768  decode.d0.loss_dice: 0.3204  decode.d1.loss_cls: 0.2437  decode.d1.loss_mask: 0.2630  decode.d1.loss_dice: 0.3177  decode.d2.loss_cls: 0.1816  decode.d2.loss_mask: 0.2544  decode.d2.loss_dice: 0.2995  decode.d3.loss_cls: 0.2334  decode.d3.loss_mask: 0.2569  decode.d3.loss_dice: 0.3205  decode.d4.loss_cls: 0.2009  decode.d4.loss_mask: 0.2549  decode.d4.loss_dice: 0.3179  decode.d5.loss_cls: 0.2344  decode.d5.loss_mask: 0.2566  decode.d5.loss_dice: 0.3097  decode.d6.loss_cls: 0.2056  decode.d6.loss_mask: 0.2566  decode.d6.loss_dice: 0.3022  decode.d7.loss_cls: 0.2241  decode.d7.loss_mask: 0.2544  decode.d7.loss_dice: 0.3015  decode.d8.loss_cls: 0.2487  decode.d8.loss_mask: 0.2571  decode.d8.loss_dice: 0.3106
07/30 20:42:07 - mmengine - INFO - Iter(train) [33250/80000]  base_lr: 6.1663e-05 lr: 6.1663e-06  eta: 5:40:00  time: 0.4373  data_time: 0.0095  memory: 5245  grad_norm: 58.4132  loss: 6.1046  decode.loss_cls: 0.0607  decode.loss_mask: 0.2382  decode.loss_dice: 0.2109  decode.d0.loss_cls: 0.9252  decode.d0.loss_mask: 0.2431  decode.d0.loss_dice: 0.2152  decode.d1.loss_cls: 0.0820  decode.d1.loss_mask: 0.2404  decode.d1.loss_dice: 0.2181  decode.d2.loss_cls: 0.0540  decode.d2.loss_mask: 0.2375  decode.d2.loss_dice: 0.2202  decode.d3.loss_cls: 0.0891  decode.d3.loss_mask: 0.2321  decode.d3.loss_dice: 0.2109  decode.d4.loss_cls: 0.1062  decode.d4.loss_mask: 0.2389  decode.d4.loss_dice: 0.2144  decode.d5.loss_cls: 0.0571  decode.d5.loss_mask: 0.2379  decode.d5.loss_dice: 0.2103  decode.d6.loss_cls: 0.1020  decode.d6.loss_mask: 0.2424  decode.d6.loss_dice: 0.2148  decode.d7.loss_cls: 0.0445  decode.d7.loss_mask: 0.2393  decode.d7.loss_dice: 0.2154  decode.d8.loss_cls: 0.0489  decode.d8.loss_mask: 0.2398  decode.d8.loss_dice: 0.2149
07/30 20:42:29 - mmengine - INFO - Iter(train) [33300/80000]  base_lr: 6.1604e-05 lr: 6.1604e-06  eta: 5:39:38  time: 0.4374  data_time: 0.0097  memory: 5227  grad_norm: 101.6184  loss: 7.3341  decode.loss_cls: 0.1501  decode.loss_mask: 0.2507  decode.loss_dice: 0.2722  decode.d0.loss_cls: 0.9246  decode.d0.loss_mask: 0.2560  decode.d0.loss_dice: 0.2757  decode.d1.loss_cls: 0.1444  decode.d1.loss_mask: 0.2497  decode.d1.loss_dice: 0.2754  decode.d2.loss_cls: 0.1109  decode.d2.loss_mask: 0.2503  decode.d2.loss_dice: 0.2742  decode.d3.loss_cls: 0.1062  decode.d3.loss_mask: 0.2508  decode.d3.loss_dice: 0.2747  decode.d4.loss_cls: 0.1193  decode.d4.loss_mask: 0.2507  decode.d4.loss_dice: 0.2754  decode.d5.loss_cls: 0.1070  decode.d5.loss_mask: 0.2493  decode.d5.loss_dice: 0.2756  decode.d6.loss_cls: 0.1240  decode.d6.loss_mask: 0.2480  decode.d6.loss_dice: 0.2756  decode.d7.loss_cls: 0.1361  decode.d7.loss_mask: 0.2516  decode.d7.loss_dice: 0.2807  decode.d8.loss_cls: 0.1480  decode.d8.loss_mask: 0.2513  decode.d8.loss_dice: 0.2759
07/30 20:42:51 - mmengine - INFO - Iter(train) [33350/80000]  base_lr: 6.1545e-05 lr: 6.1545e-06  eta: 5:39:16  time: 0.4387  data_time: 0.0097  memory: 5265  grad_norm: 81.3026  loss: 8.8383  decode.loss_cls: 0.1434  decode.loss_mask: 0.2738  decode.loss_dice: 0.3404  decode.d0.loss_cls: 1.0604  decode.d0.loss_mask: 0.2781  decode.d0.loss_dice: 0.3533  decode.d1.loss_cls: 0.1801  decode.d1.loss_mask: 0.2697  decode.d1.loss_dice: 0.3597  decode.d2.loss_cls: 0.1392  decode.d2.loss_mask: 0.2726  decode.d2.loss_dice: 0.3499  decode.d3.loss_cls: 0.1349  decode.d3.loss_mask: 0.2739  decode.d3.loss_dice: 0.3365  decode.d4.loss_cls: 0.1888  decode.d4.loss_mask: 0.2686  decode.d4.loss_dice: 0.3526  decode.d5.loss_cls: 0.2082  decode.d5.loss_mask: 0.2694  decode.d5.loss_dice: 0.3588  decode.d6.loss_cls: 0.2458  decode.d6.loss_mask: 0.2709  decode.d6.loss_dice: 0.3479  decode.d7.loss_cls: 0.1547  decode.d7.loss_mask: 0.2716  decode.d7.loss_dice: 0.3556  decode.d8.loss_cls: 0.1513  decode.d8.loss_mask: 0.2762  decode.d8.loss_dice: 0.3522
07/30 20:43:13 - mmengine - INFO - Iter(train) [33400/80000]  base_lr: 6.1485e-05 lr: 6.1485e-06  eta: 5:38:55  time: 0.4381  data_time: 0.0096  memory: 5261  grad_norm: 69.3751  loss: 6.8994  decode.loss_cls: 0.0733  decode.loss_mask: 0.2642  decode.loss_dice: 0.2421  decode.d0.loss_cls: 1.0790  decode.d0.loss_mask: 0.2723  decode.d0.loss_dice: 0.2537  decode.d1.loss_cls: 0.1024  decode.d1.loss_mask: 0.2658  decode.d1.loss_dice: 0.2501  decode.d2.loss_cls: 0.0939  decode.d2.loss_mask: 0.2648  decode.d2.loss_dice: 0.2463  decode.d3.loss_cls: 0.0735  decode.d3.loss_mask: 0.2629  decode.d3.loss_dice: 0.2476  decode.d4.loss_cls: 0.0764  decode.d4.loss_mask: 0.2630  decode.d4.loss_dice: 0.2592  decode.d5.loss_cls: 0.0792  decode.d5.loss_mask: 0.2635  decode.d5.loss_dice: 0.2467  decode.d6.loss_cls: 0.0592  decode.d6.loss_mask: 0.2644  decode.d6.loss_dice: 0.2455  decode.d7.loss_cls: 0.0624  decode.d7.loss_mask: 0.2618  decode.d7.loss_dice: 0.2456  decode.d8.loss_cls: 0.0649  decode.d8.loss_mask: 0.2660  decode.d8.loss_dice: 0.2497
07/30 20:43:35 - mmengine - INFO - Iter(train) [33450/80000]  base_lr: 6.1426e-05 lr: 6.1426e-06  eta: 5:38:33  time: 0.4358  data_time: 0.0093  memory: 5278  grad_norm: 72.9385  loss: 8.3846  decode.loss_cls: 0.2113  decode.loss_mask: 0.2689  decode.loss_dice: 0.2667  decode.d0.loss_cls: 1.0040  decode.d0.loss_mask: 0.2747  decode.d0.loss_dice: 0.2942  decode.d1.loss_cls: 0.2135  decode.d1.loss_mask: 0.2656  decode.d1.loss_dice: 0.3051  decode.d2.loss_cls: 0.2097  decode.d2.loss_mask: 0.2652  decode.d2.loss_dice: 0.2986  decode.d3.loss_cls: 0.1594  decode.d3.loss_mask: 0.2720  decode.d3.loss_dice: 0.3115  decode.d4.loss_cls: 0.1630  decode.d4.loss_mask: 0.2710  decode.d4.loss_dice: 0.2978  decode.d5.loss_cls: 0.2076  decode.d5.loss_mask: 0.2743  decode.d5.loss_dice: 0.3046  decode.d6.loss_cls: 0.1877  decode.d6.loss_mask: 0.2713  decode.d6.loss_dice: 0.2818  decode.d7.loss_cls: 0.1885  decode.d7.loss_mask: 0.2691  decode.d7.loss_dice: 0.2650  decode.d8.loss_cls: 0.2224  decode.d8.loss_mask: 0.2690  decode.d8.loss_dice: 0.2909
07/30 20:43:57 - mmengine - INFO - Iter(train) [33500/80000]  base_lr: 6.1367e-05 lr: 6.1367e-06  eta: 5:38:11  time: 0.4367  data_time: 0.0094  memory: 5279  grad_norm: 52.7220  loss: 7.2470  decode.loss_cls: 0.1426  decode.loss_mask: 0.2575  decode.loss_dice: 0.2647  decode.d0.loss_cls: 1.0059  decode.d0.loss_mask: 0.2607  decode.d0.loss_dice: 0.2920  decode.d1.loss_cls: 0.1318  decode.d1.loss_mask: 0.2577  decode.d1.loss_dice: 0.2727  decode.d2.loss_cls: 0.0577  decode.d2.loss_mask: 0.2573  decode.d2.loss_dice: 0.2661  decode.d3.loss_cls: 0.0891  decode.d3.loss_mask: 0.2566  decode.d3.loss_dice: 0.2685  decode.d4.loss_cls: 0.1062  decode.d4.loss_mask: 0.2559  decode.d4.loss_dice: 0.2621  decode.d5.loss_cls: 0.0729  decode.d5.loss_mask: 0.2588  decode.d5.loss_dice: 0.2711  decode.d6.loss_cls: 0.1328  decode.d6.loss_mask: 0.2574  decode.d6.loss_dice: 0.2563  decode.d7.loss_cls: 0.1341  decode.d7.loss_mask: 0.2564  decode.d7.loss_dice: 0.2695  decode.d8.loss_cls: 0.1214  decode.d8.loss_mask: 0.2524  decode.d8.loss_dice: 0.2586
07/30 20:44:18 - mmengine - INFO - Iter(train) [33550/80000]  base_lr: 6.1307e-05 lr: 6.1307e-06  eta: 5:37:49  time: 0.4381  data_time: 0.0097  memory: 5265  grad_norm: 125.8764  loss: 7.8599  decode.loss_cls: 0.1235  decode.loss_mask: 0.2459  decode.loss_dice: 0.2724  decode.d0.loss_cls: 0.9957  decode.d0.loss_mask: 0.2477  decode.d0.loss_dice: 0.3058  decode.d1.loss_cls: 0.2524  decode.d1.loss_mask: 0.2464  decode.d1.loss_dice: 0.2999  decode.d2.loss_cls: 0.1984  decode.d2.loss_mask: 0.2440  decode.d2.loss_dice: 0.2988  decode.d3.loss_cls: 0.1639  decode.d3.loss_mask: 0.2475  decode.d3.loss_dice: 0.2826  decode.d4.loss_cls: 0.1636  decode.d4.loss_mask: 0.2464  decode.d4.loss_dice: 0.2933  decode.d5.loss_cls: 0.1407  decode.d5.loss_mask: 0.2462  decode.d5.loss_dice: 0.2860  decode.d6.loss_cls: 0.1360  decode.d6.loss_mask: 0.2472  decode.d6.loss_dice: 0.2799  decode.d7.loss_cls: 0.1743  decode.d7.loss_mask: 0.2462  decode.d7.loss_dice: 0.2980  decode.d8.loss_cls: 0.1439  decode.d8.loss_mask: 0.2430  decode.d8.loss_dice: 0.2904
07/30 20:44:40 - mmengine - INFO - Iter(train) [33600/80000]  base_lr: 6.1248e-05 lr: 6.1248e-06  eta: 5:37:28  time: 0.4370  data_time: 0.0095  memory: 5261  grad_norm: 81.0664  loss: 7.3963  decode.loss_cls: 0.1634  decode.loss_mask: 0.2174  decode.loss_dice: 0.2698  decode.d0.loss_cls: 1.0031  decode.d0.loss_mask: 0.2228  decode.d0.loss_dice: 0.2923  decode.d1.loss_cls: 0.2233  decode.d1.loss_mask: 0.2202  decode.d1.loss_dice: 0.2753  decode.d2.loss_cls: 0.1649  decode.d2.loss_mask: 0.2180  decode.d2.loss_dice: 0.2533  decode.d3.loss_cls: 0.1492  decode.d3.loss_mask: 0.2178  decode.d3.loss_dice: 0.2655  decode.d4.loss_cls: 0.1417  decode.d4.loss_mask: 0.2204  decode.d4.loss_dice: 0.2738  decode.d5.loss_cls: 0.1536  decode.d5.loss_mask: 0.2182  decode.d5.loss_dice: 0.2597  decode.d6.loss_cls: 0.1524  decode.d6.loss_mask: 0.2189  decode.d6.loss_dice: 0.2779  decode.d7.loss_cls: 0.2096  decode.d7.loss_mask: 0.2170  decode.d7.loss_dice: 0.2460  decode.d8.loss_cls: 0.1714  decode.d8.loss_mask: 0.2163  decode.d8.loss_dice: 0.2633
07/30 20:45:02 - mmengine - INFO - Iter(train) [33650/80000]  base_lr: 6.1188e-05 lr: 6.1188e-06  eta: 5:37:06  time: 0.4375  data_time: 0.0096  memory: 5279  grad_norm: 70.7885  loss: 7.5459  decode.loss_cls: 0.1401  decode.loss_mask: 0.2361  decode.loss_dice: 0.2668  decode.d0.loss_cls: 0.9476  decode.d0.loss_mask: 0.2375  decode.d0.loss_dice: 0.2595  decode.d1.loss_cls: 0.2299  decode.d1.loss_mask: 0.2410  decode.d1.loss_dice: 0.2464  decode.d2.loss_cls: 0.1974  decode.d2.loss_mask: 0.2320  decode.d2.loss_dice: 0.2398  decode.d3.loss_cls: 0.2314  decode.d3.loss_mask: 0.2312  decode.d3.loss_dice: 0.2327  decode.d4.loss_cls: 0.1873  decode.d4.loss_mask: 0.2335  decode.d4.loss_dice: 0.2483  decode.d5.loss_cls: 0.2082  decode.d5.loss_mask: 0.2363  decode.d5.loss_dice: 0.2495  decode.d6.loss_cls: 0.2217  decode.d6.loss_mask: 0.2300  decode.d6.loss_dice: 0.2341  decode.d7.loss_cls: 0.2007  decode.d7.loss_mask: 0.2341  decode.d7.loss_dice: 0.2484  decode.d8.loss_cls: 0.1713  decode.d8.loss_mask: 0.2343  decode.d8.loss_dice: 0.2388
07/30 20:45:24 - mmengine - INFO - Iter(train) [33700/80000]  base_lr: 6.1129e-05 lr: 6.1129e-06  eta: 5:36:44  time: 0.4371  data_time: 0.0094  memory: 5229  grad_norm: 104.6481  loss: 7.3036  decode.loss_cls: 0.1904  decode.loss_mask: 0.2284  decode.loss_dice: 0.2777  decode.d0.loss_cls: 0.9881  decode.d0.loss_mask: 0.2393  decode.d0.loss_dice: 0.2964  decode.d1.loss_cls: 0.0620  decode.d1.loss_mask: 0.2318  decode.d1.loss_dice: 0.2995  decode.d2.loss_cls: 0.1373  decode.d2.loss_mask: 0.2276  decode.d2.loss_dice: 0.2671  decode.d3.loss_cls: 0.1094  decode.d3.loss_mask: 0.2279  decode.d3.loss_dice: 0.2696  decode.d4.loss_cls: 0.1378  decode.d4.loss_mask: 0.2232  decode.d4.loss_dice: 0.2693  decode.d5.loss_cls: 0.1081  decode.d5.loss_mask: 0.2314  decode.d5.loss_dice: 0.2746  decode.d6.loss_cls: 0.1547  decode.d6.loss_mask: 0.2247  decode.d6.loss_dice: 0.2638  decode.d7.loss_cls: 0.1767  decode.d7.loss_mask: 0.2208  decode.d7.loss_dice: 0.2629  decode.d8.loss_cls: 0.2011  decode.d8.loss_mask: 0.2258  decode.d8.loss_dice: 0.2759
07/30 20:45:46 - mmengine - INFO - Iter(train) [33750/80000]  base_lr: 6.1070e-05 lr: 6.1070e-06  eta: 5:36:22  time: 0.4368  data_time: 0.0094  memory: 5244  grad_norm: 77.4055  loss: 8.1443  decode.loss_cls: 0.2581  decode.loss_mask: 0.2153  decode.loss_dice: 0.3326  decode.d0.loss_cls: 0.8750  decode.d0.loss_mask: 0.2231  decode.d0.loss_dice: 0.3044  decode.d1.loss_cls: 0.1991  decode.d1.loss_mask: 0.2180  decode.d1.loss_dice: 0.3363  decode.d2.loss_cls: 0.2075  decode.d2.loss_mask: 0.2105  decode.d2.loss_dice: 0.3045  decode.d3.loss_cls: 0.2087  decode.d3.loss_mask: 0.2105  decode.d3.loss_dice: 0.2959  decode.d4.loss_cls: 0.1631  decode.d4.loss_mask: 0.2193  decode.d4.loss_dice: 0.3083  decode.d5.loss_cls: 0.2283  decode.d5.loss_mask: 0.2222  decode.d5.loss_dice: 0.3081  decode.d6.loss_cls: 0.2532  decode.d6.loss_mask: 0.2118  decode.d6.loss_dice: 0.3202  decode.d7.loss_cls: 0.2219  decode.d7.loss_mask: 0.2091  decode.d7.loss_dice: 0.3332  decode.d8.loss_cls: 0.2094  decode.d8.loss_mask: 0.2153  decode.d8.loss_dice: 0.3214
07/30 20:46:08 - mmengine - INFO - Iter(train) [33800/80000]  base_lr: 6.1010e-05 lr: 6.1010e-06  eta: 5:36:01  time: 0.4369  data_time: 0.0096  memory: 5305  grad_norm: 47.3445  loss: 7.4436  decode.loss_cls: 0.2091  decode.loss_mask: 0.2378  decode.loss_dice: 0.2679  decode.d0.loss_cls: 0.8122  decode.d0.loss_mask: 0.2472  decode.d0.loss_dice: 0.3192  decode.d1.loss_cls: 0.1239  decode.d1.loss_mask: 0.2383  decode.d1.loss_dice: 0.2774  decode.d2.loss_cls: 0.1409  decode.d2.loss_mask: 0.2400  decode.d2.loss_dice: 0.2778  decode.d3.loss_cls: 0.1436  decode.d3.loss_mask: 0.2386  decode.d3.loss_dice: 0.2823  decode.d4.loss_cls: 0.1195  decode.d4.loss_mask: 0.2393  decode.d4.loss_dice: 0.2847  decode.d5.loss_cls: 0.1660  decode.d5.loss_mask: 0.2432  decode.d5.loss_dice: 0.2866  decode.d6.loss_cls: 0.1346  decode.d6.loss_mask: 0.2434  decode.d6.loss_dice: 0.2794  decode.d7.loss_cls: 0.2096  decode.d7.loss_mask: 0.2396  decode.d7.loss_dice: 0.2827  decode.d8.loss_cls: 0.1334  decode.d8.loss_mask: 0.2392  decode.d8.loss_dice: 0.2865
07/30 20:46:30 - mmengine - INFO - Iter(train) [33850/80000]  base_lr: 6.0951e-05 lr: 6.0951e-06  eta: 5:35:39  time: 0.4367  data_time: 0.0095  memory: 5244  grad_norm: 77.0091  loss: 6.6535  decode.loss_cls: 0.0638  decode.loss_mask: 0.2693  decode.loss_dice: 0.2701  decode.d0.loss_cls: 0.7653  decode.d0.loss_mask: 0.2780  decode.d0.loss_dice: 0.2696  decode.d1.loss_cls: 0.0560  decode.d1.loss_mask: 0.2762  decode.d1.loss_dice: 0.2634  decode.d2.loss_cls: 0.0360  decode.d2.loss_mask: 0.2710  decode.d2.loss_dice: 0.2671  decode.d3.loss_cls: 0.0494  decode.d3.loss_mask: 0.2682  decode.d3.loss_dice: 0.2696  decode.d4.loss_cls: 0.0492  decode.d4.loss_mask: 0.2693  decode.d4.loss_dice: 0.2744  decode.d5.loss_cls: 0.0520  decode.d5.loss_mask: 0.2722  decode.d5.loss_dice: 0.2747  decode.d6.loss_cls: 0.0594  decode.d6.loss_mask: 0.2702  decode.d6.loss_dice: 0.2660  decode.d7.loss_cls: 0.0614  decode.d7.loss_mask: 0.2700  decode.d7.loss_dice: 0.2660  decode.d8.loss_cls: 0.0623  decode.d8.loss_mask: 0.2699  decode.d8.loss_dice: 0.2634
07/30 20:46:51 - mmengine - INFO - Iter(train) [33900/80000]  base_lr: 6.0891e-05 lr: 6.0891e-06  eta: 5:35:17  time: 0.4378  data_time: 0.0095  memory: 5244  grad_norm: 74.7396  loss: 7.7047  decode.loss_cls: 0.1568  decode.loss_mask: 0.2231  decode.loss_dice: 0.2943  decode.d0.loss_cls: 0.9003  decode.d0.loss_mask: 0.2290  decode.d0.loss_dice: 0.3307  decode.d1.loss_cls: 0.1707  decode.d1.loss_mask: 0.2257  decode.d1.loss_dice: 0.3119  decode.d2.loss_cls: 0.1371  decode.d2.loss_mask: 0.2261  decode.d2.loss_dice: 0.2805  decode.d3.loss_cls: 0.1507  decode.d3.loss_mask: 0.2243  decode.d3.loss_dice: 0.3011  decode.d4.loss_cls: 0.1318  decode.d4.loss_mask: 0.2242  decode.d4.loss_dice: 0.3150  decode.d5.loss_cls: 0.2222  decode.d5.loss_mask: 0.2226  decode.d5.loss_dice: 0.3190  decode.d6.loss_cls: 0.1857  decode.d6.loss_mask: 0.2224  decode.d6.loss_dice: 0.2814  decode.d7.loss_cls: 0.1931  decode.d7.loss_mask: 0.2260  decode.d7.loss_dice: 0.2763  decode.d8.loss_cls: 0.1934  decode.d8.loss_mask: 0.2251  decode.d8.loss_dice: 0.3043
07/30 20:47:13 - mmengine - INFO - Iter(train) [33950/80000]  base_lr: 6.0832e-05 lr: 6.0832e-06  eta: 5:34:55  time: 0.4376  data_time: 0.0096  memory: 5244  grad_norm: 73.8758  loss: 7.2656  decode.loss_cls: 0.1573  decode.loss_mask: 0.2519  decode.loss_dice: 0.2233  decode.d0.loss_cls: 1.0431  decode.d0.loss_mask: 0.2574  decode.d0.loss_dice: 0.2675  decode.d1.loss_cls: 0.2068  decode.d1.loss_mask: 0.2562  decode.d1.loss_dice: 0.2261  decode.d2.loss_cls: 0.1328  decode.d2.loss_mask: 0.2460  decode.d2.loss_dice: 0.2203  decode.d3.loss_cls: 0.1515  decode.d3.loss_mask: 0.2470  decode.d3.loss_dice: 0.2281  decode.d4.loss_cls: 0.1726  decode.d4.loss_mask: 0.2458  decode.d4.loss_dice: 0.2212  decode.d5.loss_cls: 0.1775  decode.d5.loss_mask: 0.2477  decode.d5.loss_dice: 0.2138  decode.d6.loss_cls: 0.1453  decode.d6.loss_mask: 0.2516  decode.d6.loss_dice: 0.2277  decode.d7.loss_cls: 0.1362  decode.d7.loss_mask: 0.2500  decode.d7.loss_dice: 0.2511  decode.d8.loss_cls: 0.1247  decode.d8.loss_mask: 0.2520  decode.d8.loss_dice: 0.2334
07/30 20:47:35 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 20:47:35 - mmengine - INFO - Iter(train) [34000/80000]  base_lr: 6.0772e-05 lr: 6.0772e-06  eta: 5:34:34  time: 0.4371  data_time: 0.0096  memory: 5265  grad_norm: 61.0745  loss: 7.6877  decode.loss_cls: 0.1236  decode.loss_mask: 0.3019  decode.loss_dice: 0.2495  decode.d0.loss_cls: 0.8698  decode.d0.loss_mask: 0.3215  decode.d0.loss_dice: 0.2750  decode.d1.loss_cls: 0.0918  decode.d1.loss_mask: 0.3137  decode.d1.loss_dice: 0.2625  decode.d2.loss_cls: 0.0955  decode.d2.loss_mask: 0.3147  decode.d2.loss_dice: 0.2656  decode.d3.loss_cls: 0.1441  decode.d3.loss_mask: 0.3025  decode.d3.loss_dice: 0.2559  decode.d4.loss_cls: 0.1364  decode.d4.loss_mask: 0.3006  decode.d4.loss_dice: 0.2533  decode.d5.loss_cls: 0.1335  decode.d5.loss_mask: 0.3008  decode.d5.loss_dice: 0.2493  decode.d6.loss_cls: 0.1460  decode.d6.loss_mask: 0.3009  decode.d6.loss_dice: 0.2536  decode.d7.loss_cls: 0.1538  decode.d7.loss_mask: 0.3058  decode.d7.loss_dice: 0.2759  decode.d8.loss_cls: 0.1273  decode.d8.loss_mask: 0.3036  decode.d8.loss_dice: 0.2593
07/30 20:47:57 - mmengine - INFO - Iter(train) [34050/80000]  base_lr: 6.0713e-05 lr: 6.0713e-06  eta: 5:34:12  time: 0.4367  data_time: 0.0093  memory: 5245  grad_norm: 46.8846  loss: 7.6814  decode.loss_cls: 0.1020  decode.loss_mask: 0.2213  decode.loss_dice: 0.3115  decode.d0.loss_cls: 1.0105  decode.d0.loss_mask: 0.2409  decode.d0.loss_dice: 0.3268  decode.d1.loss_cls: 0.2522  decode.d1.loss_mask: 0.2211  decode.d1.loss_dice: 0.3090  decode.d2.loss_cls: 0.1963  decode.d2.loss_mask: 0.2209  decode.d2.loss_dice: 0.3045  decode.d3.loss_cls: 0.1135  decode.d3.loss_mask: 0.2212  decode.d3.loss_dice: 0.2972  decode.d4.loss_cls: 0.0630  decode.d4.loss_mask: 0.2450  decode.d4.loss_dice: 0.3419  decode.d5.loss_cls: 0.0873  decode.d5.loss_mask: 0.2241  decode.d5.loss_dice: 0.3366  decode.d6.loss_cls: 0.0883  decode.d6.loss_mask: 0.2468  decode.d6.loss_dice: 0.3380  decode.d7.loss_cls: 0.1401  decode.d7.loss_mask: 0.2425  decode.d7.loss_dice: 0.3425  decode.d8.loss_cls: 0.0311  decode.d8.loss_mask: 0.2471  decode.d8.loss_dice: 0.3582
07/30 20:48:19 - mmengine - INFO - Iter(train) [34100/80000]  base_lr: 6.0653e-05 lr: 6.0653e-06  eta: 5:33:50  time: 0.4366  data_time: 0.0093  memory: 5245  grad_norm: 36.8867  loss: 6.2474  decode.loss_cls: 0.0397  decode.loss_mask: 0.2396  decode.loss_dice: 0.2632  decode.d0.loss_cls: 0.8622  decode.d0.loss_mask: 0.2479  decode.d0.loss_dice: 0.2632  decode.d1.loss_cls: 0.0269  decode.d1.loss_mask: 0.2466  decode.d1.loss_dice: 0.2642  decode.d2.loss_cls: 0.0265  decode.d2.loss_mask: 0.2408  decode.d2.loss_dice: 0.2655  decode.d3.loss_cls: 0.0315  decode.d3.loss_mask: 0.2398  decode.d3.loss_dice: 0.2653  decode.d4.loss_cls: 0.0301  decode.d4.loss_mask: 0.2383  decode.d4.loss_dice: 0.2626  decode.d5.loss_cls: 0.0314  decode.d5.loss_mask: 0.2355  decode.d5.loss_dice: 0.2544  decode.d6.loss_cls: 0.0366  decode.d6.loss_mask: 0.2410  decode.d6.loss_dice: 0.2601  decode.d7.loss_cls: 0.0418  decode.d7.loss_mask: 0.2428  decode.d7.loss_dice: 0.2608  decode.d8.loss_cls: 0.0855  decode.d8.loss_mask: 0.2374  decode.d8.loss_dice: 0.2662
07/30 20:48:41 - mmengine - INFO - Iter(train) [34150/80000]  base_lr: 6.0594e-05 lr: 6.0594e-06  eta: 5:33:28  time: 0.4371  data_time: 0.0096  memory: 5245  grad_norm: 69.8455  loss: 7.0724  decode.loss_cls: 0.1120  decode.loss_mask: 0.2198  decode.loss_dice: 0.2326  decode.d0.loss_cls: 1.1359  decode.d0.loss_mask: 0.2240  decode.d0.loss_dice: 0.2496  decode.d1.loss_cls: 0.2271  decode.d1.loss_mask: 0.2211  decode.d1.loss_dice: 0.2236  decode.d2.loss_cls: 0.1062  decode.d2.loss_mask: 0.2198  decode.d2.loss_dice: 0.2257  decode.d3.loss_cls: 0.1051  decode.d3.loss_mask: 0.2232  decode.d3.loss_dice: 0.2373  decode.d4.loss_cls: 0.1828  decode.d4.loss_mask: 0.2276  decode.d4.loss_dice: 0.2481  decode.d5.loss_cls: 0.1991  decode.d5.loss_mask: 0.2262  decode.d5.loss_dice: 0.2394  decode.d6.loss_cls: 0.1299  decode.d6.loss_mask: 0.2204  decode.d6.loss_dice: 0.2558  decode.d7.loss_cls: 0.1525  decode.d7.loss_mask: 0.2213  decode.d7.loss_dice: 0.2213  decode.d8.loss_cls: 0.1225  decode.d8.loss_mask: 0.2224  decode.d8.loss_dice: 0.2401
07/30 20:49:03 - mmengine - INFO - Iter(train) [34200/80000]  base_lr: 6.0534e-05 lr: 6.0534e-06  eta: 5:33:07  time: 0.4369  data_time: 0.0093  memory: 5244  grad_norm: 85.1904  loss: 8.1585  decode.loss_cls: 0.1127  decode.loss_mask: 0.2953  decode.loss_dice: 0.3205  decode.d0.loss_cls: 0.8810  decode.d0.loss_mask: 0.3021  decode.d0.loss_dice: 0.3229  decode.d1.loss_cls: 0.0959  decode.d1.loss_mask: 0.3067  decode.d1.loss_dice: 0.3271  decode.d2.loss_cls: 0.1732  decode.d2.loss_mask: 0.3012  decode.d2.loss_dice: 0.3403  decode.d3.loss_cls: 0.1225  decode.d3.loss_mask: 0.2985  decode.d3.loss_dice: 0.3313  decode.d4.loss_cls: 0.1113  decode.d4.loss_mask: 0.2998  decode.d4.loss_dice: 0.3314  decode.d5.loss_cls: 0.1067  decode.d5.loss_mask: 0.2973  decode.d5.loss_dice: 0.3236  decode.d6.loss_cls: 0.0838  decode.d6.loss_mask: 0.2959  decode.d6.loss_dice: 0.3184  decode.d7.loss_cls: 0.1014  decode.d7.loss_mask: 0.2917  decode.d7.loss_dice: 0.3343  decode.d8.loss_cls: 0.1048  decode.d8.loss_mask: 0.2976  decode.d8.loss_dice: 0.3293
07/30 20:49:25 - mmengine - INFO - Iter(train) [34250/80000]  base_lr: 6.0475e-05 lr: 6.0475e-06  eta: 5:32:45  time: 0.4374  data_time: 0.0096  memory: 5244  grad_norm: 69.0225  loss: 8.1018  decode.loss_cls: 0.2019  decode.loss_mask: 0.2269  decode.loss_dice: 0.2825  decode.d0.loss_cls: 1.0563  decode.d0.loss_mask: 0.2362  decode.d0.loss_dice: 0.3207  decode.d1.loss_cls: 0.2387  decode.d1.loss_mask: 0.2305  decode.d1.loss_dice: 0.2928  decode.d2.loss_cls: 0.2265  decode.d2.loss_mask: 0.2282  decode.d2.loss_dice: 0.2940  decode.d3.loss_cls: 0.2120  decode.d3.loss_mask: 0.2254  decode.d3.loss_dice: 0.2829  decode.d4.loss_cls: 0.2055  decode.d4.loss_mask: 0.2267  decode.d4.loss_dice: 0.2883  decode.d5.loss_cls: 0.1848  decode.d5.loss_mask: 0.2271  decode.d5.loss_dice: 0.2898  decode.d6.loss_cls: 0.1871  decode.d6.loss_mask: 0.2277  decode.d6.loss_dice: 0.2972  decode.d7.loss_cls: 0.1701  decode.d7.loss_mask: 0.2266  decode.d7.loss_dice: 0.3044  decode.d8.loss_cls: 0.1806  decode.d8.loss_mask: 0.2267  decode.d8.loss_dice: 0.3039
07/30 20:49:46 - mmengine - INFO - Iter(train) [34300/80000]  base_lr: 6.0416e-05 lr: 6.0416e-06  eta: 5:32:23  time: 0.4365  data_time: 0.0094  memory: 5304  grad_norm: 71.1164  loss: 7.4836  decode.loss_cls: 0.1786  decode.loss_mask: 0.2431  decode.loss_dice: 0.2370  decode.d0.loss_cls: 1.0401  decode.d0.loss_mask: 0.2582  decode.d0.loss_dice: 0.2754  decode.d1.loss_cls: 0.1805  decode.d1.loss_mask: 0.2484  decode.d1.loss_dice: 0.2638  decode.d2.loss_cls: 0.1702  decode.d2.loss_mask: 0.2482  decode.d2.loss_dice: 0.2457  decode.d3.loss_cls: 0.1351  decode.d3.loss_mask: 0.2460  decode.d3.loss_dice: 0.2521  decode.d4.loss_cls: 0.1407  decode.d4.loss_mask: 0.2469  decode.d4.loss_dice: 0.2470  decode.d5.loss_cls: 0.1600  decode.d5.loss_mask: 0.2458  decode.d5.loss_dice: 0.2494  decode.d6.loss_cls: 0.1518  decode.d6.loss_mask: 0.2442  decode.d6.loss_dice: 0.2401  decode.d7.loss_cls: 0.1734  decode.d7.loss_mask: 0.2435  decode.d7.loss_dice: 0.2459  decode.d8.loss_cls: 0.1799  decode.d8.loss_mask: 0.2443  decode.d8.loss_dice: 0.2486
07/30 20:50:08 - mmengine - INFO - Iter(train) [34350/80000]  base_lr: 6.0356e-05 lr: 6.0356e-06  eta: 5:32:01  time: 0.4372  data_time: 0.0095  memory: 5229  grad_norm: 89.5811  loss: 9.8930  decode.loss_cls: 0.3415  decode.loss_mask: 0.2289  decode.loss_dice: 0.3103  decode.d0.loss_cls: 1.1228  decode.d0.loss_mask: 0.2392  decode.d0.loss_dice: 0.3258  decode.d1.loss_cls: 0.5376  decode.d1.loss_mask: 0.2272  decode.d1.loss_dice: 0.2950  decode.d2.loss_cls: 0.3686  decode.d2.loss_mask: 0.2353  decode.d2.loss_dice: 0.2914  decode.d3.loss_cls: 0.3474  decode.d3.loss_mask: 0.2352  decode.d3.loss_dice: 0.3116  decode.d4.loss_cls: 0.3786  decode.d4.loss_mask: 0.2310  decode.d4.loss_dice: 0.3022  decode.d5.loss_cls: 0.3337  decode.d5.loss_mask: 0.2269  decode.d5.loss_dice: 0.3051  decode.d6.loss_cls: 0.3610  decode.d6.loss_mask: 0.2290  decode.d6.loss_dice: 0.3129  decode.d7.loss_cls: 0.3869  decode.d7.loss_mask: 0.2276  decode.d7.loss_dice: 0.3141  decode.d8.loss_cls: 0.3405  decode.d8.loss_mask: 0.2261  decode.d8.loss_dice: 0.3000
07/30 20:50:30 - mmengine - INFO - Iter(train) [34400/80000]  base_lr: 6.0297e-05 lr: 6.0297e-06  eta: 5:31:40  time: 0.4361  data_time: 0.0095  memory: 5261  grad_norm: 55.1748  loss: 6.5988  decode.loss_cls: 0.0786  decode.loss_mask: 0.2676  decode.loss_dice: 0.2215  decode.d0.loss_cls: 0.8990  decode.d0.loss_mask: 0.2664  decode.d0.loss_dice: 0.2336  decode.d1.loss_cls: 0.1293  decode.d1.loss_mask: 0.2676  decode.d1.loss_dice: 0.2293  decode.d2.loss_cls: 0.0969  decode.d2.loss_mask: 0.2669  decode.d2.loss_dice: 0.2233  decode.d3.loss_cls: 0.0849  decode.d3.loss_mask: 0.2651  decode.d3.loss_dice: 0.2230  decode.d4.loss_cls: 0.0926  decode.d4.loss_mask: 0.2660  decode.d4.loss_dice: 0.2202  decode.d5.loss_cls: 0.0887  decode.d5.loss_mask: 0.2645  decode.d5.loss_dice: 0.2233  decode.d6.loss_cls: 0.0778  decode.d6.loss_mask: 0.2657  decode.d6.loss_dice: 0.2208  decode.d7.loss_cls: 0.0681  decode.d7.loss_mask: 0.2646  decode.d7.loss_dice: 0.2306  decode.d8.loss_cls: 0.0659  decode.d8.loss_mask: 0.2677  decode.d8.loss_dice: 0.2293
07/30 20:50:52 - mmengine - INFO - Iter(train) [34450/80000]  base_lr: 6.0237e-05 lr: 6.0237e-06  eta: 5:31:18  time: 0.4373  data_time: 0.0094  memory: 5265  grad_norm: 56.5564  loss: 7.1429  decode.loss_cls: 0.1227  decode.loss_mask: 0.2516  decode.loss_dice: 0.2740  decode.d0.loss_cls: 1.0133  decode.d0.loss_mask: 0.2533  decode.d0.loss_dice: 0.2616  decode.d1.loss_cls: 0.1589  decode.d1.loss_mask: 0.2515  decode.d1.loss_dice: 0.2667  decode.d2.loss_cls: 0.1027  decode.d2.loss_mask: 0.2525  decode.d2.loss_dice: 0.2636  decode.d3.loss_cls: 0.0837  decode.d3.loss_mask: 0.2498  decode.d3.loss_dice: 0.2540  decode.d4.loss_cls: 0.0602  decode.d4.loss_mask: 0.2502  decode.d4.loss_dice: 0.2843  decode.d5.loss_cls: 0.0589  decode.d5.loss_mask: 0.2455  decode.d5.loss_dice: 0.2869  decode.d6.loss_cls: 0.1206  decode.d6.loss_mask: 0.2512  decode.d6.loss_dice: 0.2567  decode.d7.loss_cls: 0.1134  decode.d7.loss_mask: 0.2485  decode.d7.loss_dice: 0.2592  decode.d8.loss_cls: 0.1248  decode.d8.loss_mask: 0.2520  decode.d8.loss_dice: 0.2707
07/30 20:51:14 - mmengine - INFO - Iter(train) [34500/80000]  base_lr: 6.0178e-05 lr: 6.0178e-06  eta: 5:30:56  time: 0.4373  data_time: 0.0094  memory: 5246  grad_norm: 64.3564  loss: 8.5342  decode.loss_cls: 0.2530  decode.loss_mask: 0.2366  decode.loss_dice: 0.3096  decode.d0.loss_cls: 1.0675  decode.d0.loss_mask: 0.2427  decode.d0.loss_dice: 0.3368  decode.d1.loss_cls: 0.2259  decode.d1.loss_mask: 0.2413  decode.d1.loss_dice: 0.3043  decode.d2.loss_cls: 0.2339  decode.d2.loss_mask: 0.2371  decode.d2.loss_dice: 0.3146  decode.d3.loss_cls: 0.1674  decode.d3.loss_mask: 0.2365  decode.d3.loss_dice: 0.3043  decode.d4.loss_cls: 0.2036  decode.d4.loss_mask: 0.2355  decode.d4.loss_dice: 0.3073  decode.d5.loss_cls: 0.2427  decode.d5.loss_mask: 0.2356  decode.d5.loss_dice: 0.3192  decode.d6.loss_cls: 0.2155  decode.d6.loss_mask: 0.2337  decode.d6.loss_dice: 0.2968  decode.d7.loss_cls: 0.1923  decode.d7.loss_mask: 0.2365  decode.d7.loss_dice: 0.3451  decode.d8.loss_cls: 0.2102  decode.d8.loss_mask: 0.2367  decode.d8.loss_dice: 0.3120
07/30 20:51:36 - mmengine - INFO - Iter(train) [34550/80000]  base_lr: 6.0118e-05 lr: 6.0118e-06  eta: 5:30:34  time: 0.4372  data_time: 0.0094  memory: 5265  grad_norm: 85.4798  loss: 9.1741  decode.loss_cls: 0.2386  decode.loss_mask: 0.2263  decode.loss_dice: 0.3474  decode.d0.loss_cls: 1.1765  decode.d0.loss_mask: 0.2311  decode.d0.loss_dice: 0.3534  decode.d1.loss_cls: 0.2997  decode.d1.loss_mask: 0.2249  decode.d1.loss_dice: 0.3292  decode.d2.loss_cls: 0.2301  decode.d2.loss_mask: 0.2262  decode.d2.loss_dice: 0.3477  decode.d3.loss_cls: 0.2912  decode.d3.loss_mask: 0.2241  decode.d3.loss_dice: 0.3139  decode.d4.loss_cls: 0.2776  decode.d4.loss_mask: 0.2267  decode.d4.loss_dice: 0.3373  decode.d5.loss_cls: 0.2080  decode.d5.loss_mask: 0.2246  decode.d5.loss_dice: 0.3660  decode.d6.loss_cls: 0.2308  decode.d6.loss_mask: 0.2282  decode.d6.loss_dice: 0.3685  decode.d7.loss_cls: 0.2373  decode.d7.loss_mask: 0.2237  decode.d7.loss_dice: 0.3486  decode.d8.loss_cls: 0.2597  decode.d8.loss_mask: 0.2249  decode.d8.loss_dice: 0.3520
07/30 20:51:58 - mmengine - INFO - Iter(train) [34600/80000]  base_lr: 6.0058e-05 lr: 6.0058e-06  eta: 5:30:13  time: 0.4376  data_time: 0.0094  memory: 5261  grad_norm: 40.4037  loss: 5.7968  decode.loss_cls: 0.0153  decode.loss_mask: 0.2420  decode.loss_dice: 0.2299  decode.d0.loss_cls: 0.8473  decode.d0.loss_mask: 0.2529  decode.d0.loss_dice: 0.2391  decode.d1.loss_cls: 0.0255  decode.d1.loss_mask: 0.2452  decode.d1.loss_dice: 0.2349  decode.d2.loss_cls: 0.0150  decode.d2.loss_mask: 0.2409  decode.d2.loss_dice: 0.2304  decode.d3.loss_cls: 0.0194  decode.d3.loss_mask: 0.2447  decode.d3.loss_dice: 0.2308  decode.d4.loss_cls: 0.0238  decode.d4.loss_mask: 0.2443  decode.d4.loss_dice: 0.2324  decode.d5.loss_cls: 0.0191  decode.d5.loss_mask: 0.2422  decode.d5.loss_dice: 0.2310  decode.d6.loss_cls: 0.0255  decode.d6.loss_mask: 0.2411  decode.d6.loss_dice: 0.2316  decode.d7.loss_cls: 0.0208  decode.d7.loss_mask: 0.2413  decode.d7.loss_dice: 0.2351  decode.d8.loss_cls: 0.0204  decode.d8.loss_mask: 0.2412  decode.d8.loss_dice: 0.2337
07/30 20:52:20 - mmengine - INFO - Iter(train) [34650/80000]  base_lr: 5.9999e-05 lr: 5.9999e-06  eta: 5:29:51  time: 0.4379  data_time: 0.0094  memory: 5246  grad_norm: 68.9269  loss: 6.9809  decode.loss_cls: 0.0630  decode.loss_mask: 0.2853  decode.loss_dice: 0.2480  decode.d0.loss_cls: 0.9249  decode.d0.loss_mask: 0.2986  decode.d0.loss_dice: 0.2842  decode.d1.loss_cls: 0.0628  decode.d1.loss_mask: 0.2879  decode.d1.loss_dice: 0.2636  decode.d2.loss_cls: 0.1101  decode.d2.loss_mask: 0.2882  decode.d2.loss_dice: 0.2628  decode.d3.loss_cls: 0.0646  decode.d3.loss_mask: 0.2852  decode.d3.loss_dice: 0.2454  decode.d4.loss_cls: 0.0633  decode.d4.loss_mask: 0.2837  decode.d4.loss_dice: 0.2687  decode.d5.loss_cls: 0.0634  decode.d5.loss_mask: 0.2863  decode.d5.loss_dice: 0.2482  decode.d6.loss_cls: 0.0642  decode.d6.loss_mask: 0.2803  decode.d6.loss_dice: 0.2470  decode.d7.loss_cls: 0.0597  decode.d7.loss_mask: 0.2827  decode.d7.loss_dice: 0.2490  decode.d8.loss_cls: 0.0774  decode.d8.loss_mask: 0.2857  decode.d8.loss_dice: 0.2467
07/30 20:52:41 - mmengine - INFO - Iter(train) [34700/80000]  base_lr: 5.9939e-05 lr: 5.9939e-06  eta: 5:29:29  time: 0.4371  data_time: 0.0094  memory: 5244  grad_norm: 66.5294  loss: 8.4785  decode.loss_cls: 0.1428  decode.loss_mask: 0.2838  decode.loss_dice: 0.2902  decode.d0.loss_cls: 0.9517  decode.d0.loss_mask: 0.2989  decode.d0.loss_dice: 0.3202  decode.d1.loss_cls: 0.2647  decode.d1.loss_mask: 0.2893  decode.d1.loss_dice: 0.2991  decode.d2.loss_cls: 0.1505  decode.d2.loss_mask: 0.2818  decode.d2.loss_dice: 0.3205  decode.d3.loss_cls: 0.1280  decode.d3.loss_mask: 0.2841  decode.d3.loss_dice: 0.3171  decode.d4.loss_cls: 0.2113  decode.d4.loss_mask: 0.2847  decode.d4.loss_dice: 0.3032  decode.d5.loss_cls: 0.2113  decode.d5.loss_mask: 0.2819  decode.d5.loss_dice: 0.2950  decode.d6.loss_cls: 0.1623  decode.d6.loss_mask: 0.2862  decode.d6.loss_dice: 0.2969  decode.d7.loss_cls: 0.1828  decode.d7.loss_mask: 0.2861  decode.d7.loss_dice: 0.3025  decode.d8.loss_cls: 0.1694  decode.d8.loss_mask: 0.2869  decode.d8.loss_dice: 0.2952
07/30 20:53:03 - mmengine - INFO - Iter(train) [34750/80000]  base_lr: 5.9880e-05 lr: 5.9880e-06  eta: 5:29:07  time: 0.4369  data_time: 0.0094  memory: 5265  grad_norm: 94.4585  loss: 7.2166  decode.loss_cls: 0.1685  decode.loss_mask: 0.2313  decode.loss_dice: 0.2372  decode.d0.loss_cls: 0.9606  decode.d0.loss_mask: 0.2376  decode.d0.loss_dice: 0.2655  decode.d1.loss_cls: 0.1449  decode.d1.loss_mask: 0.2373  decode.d1.loss_dice: 0.2442  decode.d2.loss_cls: 0.1706  decode.d2.loss_mask: 0.2326  decode.d2.loss_dice: 0.2462  decode.d3.loss_cls: 0.1911  decode.d3.loss_mask: 0.2323  decode.d3.loss_dice: 0.2355  decode.d4.loss_cls: 0.1743  decode.d4.loss_mask: 0.2350  decode.d4.loss_dice: 0.2408  decode.d5.loss_cls: 0.1414  decode.d5.loss_mask: 0.2346  decode.d5.loss_dice: 0.2441  decode.d6.loss_cls: 0.1542  decode.d6.loss_mask: 0.2350  decode.d6.loss_dice: 0.2422  decode.d7.loss_cls: 0.1780  decode.d7.loss_mask: 0.2354  decode.d7.loss_dice: 0.2457  decode.d8.loss_cls: 0.1552  decode.d8.loss_mask: 0.2325  decode.d8.loss_dice: 0.2326
07/30 20:53:25 - mmengine - INFO - Iter(train) [34800/80000]  base_lr: 5.9820e-05 lr: 5.9820e-06  eta: 5:28:46  time: 0.4370  data_time: 0.0095  memory: 5279  grad_norm: 71.2331  loss: 6.7350  decode.loss_cls: 0.0797  decode.loss_mask: 0.2352  decode.loss_dice: 0.2800  decode.d0.loss_cls: 0.8055  decode.d0.loss_mask: 0.2404  decode.d0.loss_dice: 0.2954  decode.d1.loss_cls: 0.1264  decode.d1.loss_mask: 0.2359  decode.d1.loss_dice: 0.2460  decode.d2.loss_cls: 0.0984  decode.d2.loss_mask: 0.2364  decode.d2.loss_dice: 0.2499  decode.d3.loss_cls: 0.0556  decode.d3.loss_mask: 0.2358  decode.d3.loss_dice: 0.3006  decode.d4.loss_cls: 0.1145  decode.d4.loss_mask: 0.2334  decode.d4.loss_dice: 0.2425  decode.d5.loss_cls: 0.1312  decode.d5.loss_mask: 0.2342  decode.d5.loss_dice: 0.2548  decode.d6.loss_cls: 0.1235  decode.d6.loss_mask: 0.2339  decode.d6.loss_dice: 0.2570  decode.d7.loss_cls: 0.1195  decode.d7.loss_mask: 0.2368  decode.d7.loss_dice: 0.2545  decode.d8.loss_cls: 0.0775  decode.d8.loss_mask: 0.2347  decode.d8.loss_dice: 0.2656
07/30 20:53:47 - mmengine - INFO - Iter(train) [34850/80000]  base_lr: 5.9761e-05 lr: 5.9761e-06  eta: 5:28:24  time: 0.4382  data_time: 0.0097  memory: 5265  grad_norm: 57.1811  loss: 8.1513  decode.loss_cls: 0.1586  decode.loss_mask: 0.2252  decode.loss_dice: 0.2716  decode.d0.loss_cls: 1.1244  decode.d0.loss_mask: 0.2371  decode.d0.loss_dice: 0.2873  decode.d1.loss_cls: 0.2788  decode.d1.loss_mask: 0.2269  decode.d1.loss_dice: 0.2758  decode.d2.loss_cls: 0.2205  decode.d2.loss_mask: 0.2314  decode.d2.loss_dice: 0.2709  decode.d3.loss_cls: 0.2337  decode.d3.loss_mask: 0.2275  decode.d3.loss_dice: 0.2734  decode.d4.loss_cls: 0.2616  decode.d4.loss_mask: 0.2320  decode.d4.loss_dice: 0.2844  decode.d5.loss_cls: 0.1655  decode.d5.loss_mask: 0.2247  decode.d5.loss_dice: 0.2677  decode.d6.loss_cls: 0.2552  decode.d6.loss_mask: 0.2334  decode.d6.loss_dice: 0.2728  decode.d7.loss_cls: 0.1864  decode.d7.loss_mask: 0.2257  decode.d7.loss_dice: 0.2652  decode.d8.loss_cls: 0.2181  decode.d8.loss_mask: 0.2297  decode.d8.loss_dice: 0.2862
07/30 20:54:09 - mmengine - INFO - Iter(train) [34900/80000]  base_lr: 5.9701e-05 lr: 5.9701e-06  eta: 5:28:02  time: 0.4367  data_time: 0.0095  memory: 5261  grad_norm: 134.8836  loss: 9.2266  decode.loss_cls: 0.3147  decode.loss_mask: 0.2509  decode.loss_dice: 0.3140  decode.d0.loss_cls: 0.9811  decode.d0.loss_mask: 0.2577  decode.d0.loss_dice: 0.3312  decode.d1.loss_cls: 0.3501  decode.d1.loss_mask: 0.2457  decode.d1.loss_dice: 0.2767  decode.d2.loss_cls: 0.3025  decode.d2.loss_mask: 0.2451  decode.d2.loss_dice: 0.3028  decode.d3.loss_cls: 0.2969  decode.d3.loss_mask: 0.2491  decode.d3.loss_dice: 0.2993  decode.d4.loss_cls: 0.2834  decode.d4.loss_mask: 0.2500  decode.d4.loss_dice: 0.2856  decode.d5.loss_cls: 0.2616  decode.d5.loss_mask: 0.2516  decode.d5.loss_dice: 0.2960  decode.d6.loss_cls: 0.2863  decode.d6.loss_mask: 0.2565  decode.d6.loss_dice: 0.3046  decode.d7.loss_cls: 0.3206  decode.d7.loss_mask: 0.2506  decode.d7.loss_dice: 0.2968  decode.d8.loss_cls: 0.3060  decode.d8.loss_mask: 0.2478  decode.d8.loss_dice: 0.3114
07/30 20:54:31 - mmengine - INFO - Iter(train) [34950/80000]  base_lr: 5.9642e-05 lr: 5.9642e-06  eta: 5:27:41  time: 0.4367  data_time: 0.0094  memory: 5261  grad_norm: 52.1606  loss: 6.9163  decode.loss_cls: 0.1280  decode.loss_mask: 0.2438  decode.loss_dice: 0.2346  decode.d0.loss_cls: 0.9090  decode.d0.loss_mask: 0.2497  decode.d0.loss_dice: 0.2332  decode.d1.loss_cls: 0.1754  decode.d1.loss_mask: 0.2428  decode.d1.loss_dice: 0.2274  decode.d2.loss_cls: 0.1313  decode.d2.loss_mask: 0.2448  decode.d2.loss_dice: 0.2339  decode.d3.loss_cls: 0.1285  decode.d3.loss_mask: 0.2439  decode.d3.loss_dice: 0.2356  decode.d4.loss_cls: 0.1500  decode.d4.loss_mask: 0.2436  decode.d4.loss_dice: 0.2266  decode.d5.loss_cls: 0.1433  decode.d5.loss_mask: 0.2419  decode.d5.loss_dice: 0.2298  decode.d6.loss_cls: 0.1289  decode.d6.loss_mask: 0.2448  decode.d6.loss_dice: 0.2313  decode.d7.loss_cls: 0.1323  decode.d7.loss_mask: 0.2436  decode.d7.loss_dice: 0.2356  decode.d8.loss_cls: 0.1242  decode.d8.loss_mask: 0.2426  decode.d8.loss_dice: 0.2356
07/30 20:54:53 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 20:54:53 - mmengine - INFO - Iter(train) [35000/80000]  base_lr: 5.9582e-05 lr: 5.9582e-06  eta: 5:27:19  time: 0.4384  data_time: 0.0095  memory: 5277  grad_norm: 46.2336  loss: 7.1001  decode.loss_cls: 0.1614  decode.loss_mask: 0.2091  decode.loss_dice: 0.2471  decode.d0.loss_cls: 1.0062  decode.d0.loss_mask: 0.2071  decode.d0.loss_dice: 0.2574  decode.d1.loss_cls: 0.2574  decode.d1.loss_mask: 0.2028  decode.d1.loss_dice: 0.2445  decode.d2.loss_cls: 0.2068  decode.d2.loss_mask: 0.2039  decode.d2.loss_dice: 0.2453  decode.d3.loss_cls: 0.1616  decode.d3.loss_mask: 0.2046  decode.d3.loss_dice: 0.2410  decode.d4.loss_cls: 0.1662  decode.d4.loss_mask: 0.2031  decode.d4.loss_dice: 0.2373  decode.d5.loss_cls: 0.1681  decode.d5.loss_mask: 0.2073  decode.d5.loss_dice: 0.2533  decode.d6.loss_cls: 0.1199  decode.d6.loss_mask: 0.2046  decode.d6.loss_dice: 0.2491  decode.d7.loss_cls: 0.1633  decode.d7.loss_mask: 0.2049  decode.d7.loss_dice: 0.2558  decode.d8.loss_cls: 0.1626  decode.d8.loss_mask: 0.2025  decode.d8.loss_dice: 0.2457
07/30 20:54:53 - mmengine - INFO - Saving checkpoint at 35000 iterations
07/30 20:55:17 - mmengine - INFO - Iter(train) [35050/80000]  base_lr: 5.9522e-05 lr: 5.9522e-06  eta: 5:27:00  time: 0.4375  data_time: 0.0094  memory: 5279  grad_norm: 79.1130  loss: 8.0597  decode.loss_cls: 0.1952  decode.loss_mask: 0.2121  decode.loss_dice: 0.2797  decode.d0.loss_cls: 1.1066  decode.d0.loss_mask: 0.2177  decode.d0.loss_dice: 0.3010  decode.d1.loss_cls: 0.2343  decode.d1.loss_mask: 0.2158  decode.d1.loss_dice: 0.3168  decode.d2.loss_cls: 0.2191  decode.d2.loss_mask: 0.2141  decode.d2.loss_dice: 0.2910  decode.d3.loss_cls: 0.2245  decode.d3.loss_mask: 0.2153  decode.d3.loss_dice: 0.2872  decode.d4.loss_cls: 0.2427  decode.d4.loss_mask: 0.2143  decode.d4.loss_dice: 0.2840  decode.d5.loss_cls: 0.2327  decode.d5.loss_mask: 0.2138  decode.d5.loss_dice: 0.2668  decode.d6.loss_cls: 0.2223  decode.d6.loss_mask: 0.2086  decode.d6.loss_dice: 0.2903  decode.d7.loss_cls: 0.1894  decode.d7.loss_mask: 0.2114  decode.d7.loss_dice: 0.2874  decode.d8.loss_cls: 0.1626  decode.d8.loss_mask: 0.2137  decode.d8.loss_dice: 0.2892
07/30 20:55:39 - mmengine - INFO - Iter(train) [35100/80000]  base_lr: 5.9463e-05 lr: 5.9463e-06  eta: 5:26:38  time: 0.4375  data_time: 0.0097  memory: 5305  grad_norm: 69.6086  loss: 6.9070  decode.loss_cls: 0.1265  decode.loss_mask: 0.2355  decode.loss_dice: 0.2762  decode.d0.loss_cls: 0.8656  decode.d0.loss_mask: 0.2373  decode.d0.loss_dice: 0.2529  decode.d1.loss_cls: 0.1377  decode.d1.loss_mask: 0.2370  decode.d1.loss_dice: 0.2906  decode.d2.loss_cls: 0.1224  decode.d2.loss_mask: 0.2323  decode.d2.loss_dice: 0.2548  decode.d3.loss_cls: 0.1273  decode.d3.loss_mask: 0.2328  decode.d3.loss_dice: 0.2590  decode.d4.loss_cls: 0.1067  decode.d4.loss_mask: 0.2338  decode.d4.loss_dice: 0.2694  decode.d5.loss_cls: 0.0985  decode.d5.loss_mask: 0.2319  decode.d5.loss_dice: 0.2744  decode.d6.loss_cls: 0.1011  decode.d6.loss_mask: 0.2313  decode.d6.loss_dice: 0.2638  decode.d7.loss_cls: 0.1040  decode.d7.loss_mask: 0.2355  decode.d7.loss_dice: 0.2635  decode.d8.loss_cls: 0.0916  decode.d8.loss_mask: 0.2353  decode.d8.loss_dice: 0.2783
07/30 20:56:01 - mmengine - INFO - Iter(train) [35150/80000]  base_lr: 5.9403e-05 lr: 5.9403e-06  eta: 5:26:16  time: 0.4383  data_time: 0.0096  memory: 5265  grad_norm: 99.2912  loss: 6.2106  decode.loss_cls: 0.0169  decode.loss_mask: 0.2438  decode.loss_dice: 0.2498  decode.d0.loss_cls: 0.9053  decode.d0.loss_mask: 0.2480  decode.d0.loss_dice: 0.2506  decode.d1.loss_cls: 0.1661  decode.d1.loss_mask: 0.2404  decode.d1.loss_dice: 0.2546  decode.d2.loss_cls: 0.0687  decode.d2.loss_mask: 0.2448  decode.d2.loss_dice: 0.2513  decode.d3.loss_cls: 0.0219  decode.d3.loss_mask: 0.2437  decode.d3.loss_dice: 0.2449  decode.d4.loss_cls: 0.0201  decode.d4.loss_mask: 0.2423  decode.d4.loss_dice: 0.2509  decode.d5.loss_cls: 0.0271  decode.d5.loss_mask: 0.2411  decode.d5.loss_dice: 0.2477  decode.d6.loss_cls: 0.0218  decode.d6.loss_mask: 0.2421  decode.d6.loss_dice: 0.2492  decode.d7.loss_cls: 0.0210  decode.d7.loss_mask: 0.2438  decode.d7.loss_dice: 0.2501  decode.d8.loss_cls: 0.0127  decode.d8.loss_mask: 0.2411  decode.d8.loss_dice: 0.2488
07/30 20:56:23 - mmengine - INFO - Iter(train) [35200/80000]  base_lr: 5.9344e-05 lr: 5.9344e-06  eta: 5:25:55  time: 0.4374  data_time: 0.0096  memory: 5277  grad_norm: 78.9871  loss: 8.6443  decode.loss_cls: 0.2558  decode.loss_mask: 0.2455  decode.loss_dice: 0.2826  decode.d0.loss_cls: 1.0053  decode.d0.loss_mask: 0.2661  decode.d0.loss_dice: 0.3006  decode.d1.loss_cls: 0.2111  decode.d1.loss_mask: 0.2506  decode.d1.loss_dice: 0.2740  decode.d2.loss_cls: 0.2190  decode.d2.loss_mask: 0.2486  decode.d2.loss_dice: 0.2871  decode.d3.loss_cls: 0.2821  decode.d3.loss_mask: 0.2483  decode.d3.loss_dice: 0.2677  decode.d4.loss_cls: 0.2373  decode.d4.loss_mask: 0.2486  decode.d4.loss_dice: 0.2893  decode.d5.loss_cls: 0.2426  decode.d5.loss_mask: 0.2501  decode.d5.loss_dice: 0.2970  decode.d6.loss_cls: 0.2704  decode.d6.loss_mask: 0.2473  decode.d6.loss_dice: 0.2885  decode.d7.loss_cls: 0.2945  decode.d7.loss_mask: 0.2455  decode.d7.loss_dice: 0.2724  decode.d8.loss_cls: 0.2831  decode.d8.loss_mask: 0.2428  decode.d8.loss_dice: 0.2904
07/30 20:56:45 - mmengine - INFO - Iter(train) [35250/80000]  base_lr: 5.9284e-05 lr: 5.9284e-06  eta: 5:25:33  time: 0.4368  data_time: 0.0094  memory: 5226  grad_norm: 85.6657  loss: 8.5202  decode.loss_cls: 0.2004  decode.loss_mask: 0.2299  decode.loss_dice: 0.2999  decode.d0.loss_cls: 1.1326  decode.d0.loss_mask: 0.2361  decode.d0.loss_dice: 0.3124  decode.d1.loss_cls: 0.2725  decode.d1.loss_mask: 0.2303  decode.d1.loss_dice: 0.2872  decode.d2.loss_cls: 0.2568  decode.d2.loss_mask: 0.2312  decode.d2.loss_dice: 0.3038  decode.d3.loss_cls: 0.2924  decode.d3.loss_mask: 0.2299  decode.d3.loss_dice: 0.2995  decode.d4.loss_cls: 0.2604  decode.d4.loss_mask: 0.2270  decode.d4.loss_dice: 0.3142  decode.d5.loss_cls: 0.1857  decode.d5.loss_mask: 0.2302  decode.d5.loss_dice: 0.2905  decode.d6.loss_cls: 0.1822  decode.d6.loss_mask: 0.2304  decode.d6.loss_dice: 0.3073  decode.d7.loss_cls: 0.1934  decode.d7.loss_mask: 0.2334  decode.d7.loss_dice: 0.3142  decode.d8.loss_cls: 0.1917  decode.d8.loss_mask: 0.2313  decode.d8.loss_dice: 0.3134
07/30 20:57:06 - mmengine - INFO - Iter(train) [35300/80000]  base_lr: 5.9224e-05 lr: 5.9224e-06  eta: 5:25:11  time: 0.4379  data_time: 0.0094  memory: 5265  grad_norm: 36.7097  loss: 7.0135  decode.loss_cls: 0.0896  decode.loss_mask: 0.2416  decode.loss_dice: 0.2579  decode.d0.loss_cls: 1.0618  decode.d0.loss_mask: 0.2298  decode.d0.loss_dice: 0.2635  decode.d1.loss_cls: 0.1779  decode.d1.loss_mask: 0.2302  decode.d1.loss_dice: 0.2422  decode.d2.loss_cls: 0.1769  decode.d2.loss_mask: 0.2041  decode.d2.loss_dice: 0.2301  decode.d3.loss_cls: 0.1794  decode.d3.loss_mask: 0.2140  decode.d3.loss_dice: 0.2511  decode.d4.loss_cls: 0.1894  decode.d4.loss_mask: 0.2204  decode.d4.loss_dice: 0.2531  decode.d5.loss_cls: 0.0728  decode.d5.loss_mask: 0.2559  decode.d5.loss_dice: 0.2474  decode.d6.loss_cls: 0.0781  decode.d6.loss_mask: 0.2490  decode.d6.loss_dice: 0.2580  decode.d7.loss_cls: 0.0688  decode.d7.loss_mask: 0.2445  decode.d7.loss_dice: 0.2538  decode.d8.loss_cls: 0.0710  decode.d8.loss_mask: 0.2422  decode.d8.loss_dice: 0.2591
07/30 20:57:28 - mmengine - INFO - Iter(train) [35350/80000]  base_lr: 5.9165e-05 lr: 5.9165e-06  eta: 5:24:49  time: 0.4380  data_time: 0.0096  memory: 5279  grad_norm: 163.9392  loss: 13.0209  decode.loss_cls: 0.3755  decode.loss_mask: 0.4709  decode.loss_dice: 0.3314  decode.d0.loss_cls: 1.2742  decode.d0.loss_mask: 0.3898  decode.d0.loss_dice: 0.3943  decode.d1.loss_cls: 0.4448  decode.d1.loss_mask: 0.4309  decode.d1.loss_dice: 0.3566  decode.d2.loss_cls: 0.4525  decode.d2.loss_mask: 0.4633  decode.d2.loss_dice: 0.3482  decode.d3.loss_cls: 0.4714  decode.d3.loss_mask: 0.4376  decode.d3.loss_dice: 0.3540  decode.d4.loss_cls: 0.4417  decode.d4.loss_mask: 0.4452  decode.d4.loss_dice: 0.3402  decode.d5.loss_cls: 0.5021  decode.d5.loss_mask: 0.4119  decode.d5.loss_dice: 0.3324  decode.d6.loss_cls: 0.4416  decode.d6.loss_mask: 0.3703  decode.d6.loss_dice: 0.3384  decode.d7.loss_cls: 0.3849  decode.d7.loss_mask: 0.4860  decode.d7.loss_dice: 0.3399  decode.d8.loss_cls: 0.3696  decode.d8.loss_mask: 0.4637  decode.d8.loss_dice: 0.3575
07/30 20:57:50 - mmengine - INFO - Iter(train) [35400/80000]  base_lr: 5.9105e-05 lr: 5.9105e-06  eta: 5:24:28  time: 0.4372  data_time: 0.0095  memory: 5278  grad_norm: 42.4049  loss: 6.5112  decode.loss_cls: 0.0285  decode.loss_mask: 0.2472  decode.loss_dice: 0.2725  decode.d0.loss_cls: 0.9459  decode.d0.loss_mask: 0.2559  decode.d0.loss_dice: 0.2838  decode.d1.loss_cls: 0.0612  decode.d1.loss_mask: 0.2501  decode.d1.loss_dice: 0.2692  decode.d2.loss_cls: 0.0447  decode.d2.loss_mask: 0.2486  decode.d2.loss_dice: 0.2711  decode.d3.loss_cls: 0.0804  decode.d3.loss_mask: 0.2477  decode.d3.loss_dice: 0.2703  decode.d4.loss_cls: 0.0386  decode.d4.loss_mask: 0.2496  decode.d4.loss_dice: 0.2725  decode.d5.loss_cls: 0.0324  decode.d5.loss_mask: 0.2473  decode.d5.loss_dice: 0.2677  decode.d6.loss_cls: 0.0292  decode.d6.loss_mask: 0.2459  decode.d6.loss_dice: 0.2662  decode.d7.loss_cls: 0.0310  decode.d7.loss_mask: 0.2456  decode.d7.loss_dice: 0.2630  decode.d8.loss_cls: 0.0290  decode.d8.loss_mask: 0.2462  decode.d8.loss_dice: 0.2699
07/30 20:58:12 - mmengine - INFO - Iter(train) [35450/80000]  base_lr: 5.9046e-05 lr: 5.9046e-06  eta: 5:24:06  time: 0.4375  data_time: 0.0095  memory: 5279  grad_norm: 54.4360  loss: 6.7681  decode.loss_cls: 0.0960  decode.loss_mask: 0.2393  decode.loss_dice: 0.2440  decode.d0.loss_cls: 0.7710  decode.d0.loss_mask: 0.2464  decode.d0.loss_dice: 0.2638  decode.d1.loss_cls: 0.1458  decode.d1.loss_mask: 0.2382  decode.d1.loss_dice: 0.2562  decode.d2.loss_cls: 0.1171  decode.d2.loss_mask: 0.2395  decode.d2.loss_dice: 0.2625  decode.d3.loss_cls: 0.1116  decode.d3.loss_mask: 0.2408  decode.d3.loss_dice: 0.2408  decode.d4.loss_cls: 0.1306  decode.d4.loss_mask: 0.2421  decode.d4.loss_dice: 0.2505  decode.d5.loss_cls: 0.1134  decode.d5.loss_mask: 0.2412  decode.d5.loss_dice: 0.2494  decode.d6.loss_cls: 0.1212  decode.d6.loss_mask: 0.2428  decode.d6.loss_dice: 0.2455  decode.d7.loss_cls: 0.1436  decode.d7.loss_mask: 0.2410  decode.d7.loss_dice: 0.2423  decode.d8.loss_cls: 0.0983  decode.d8.loss_mask: 0.2405  decode.d8.loss_dice: 0.2525
07/30 20:58:34 - mmengine - INFO - Iter(train) [35500/80000]  base_lr: 5.8986e-05 lr: 5.8986e-06  eta: 5:23:44  time: 0.4370  data_time: 0.0097  memory: 5246  grad_norm: 71.0769  loss: 7.1030  decode.loss_cls: 0.0621  decode.loss_mask: 0.2621  decode.loss_dice: 0.3023  decode.d0.loss_cls: 0.8172  decode.d0.loss_mask: 0.2764  decode.d0.loss_dice: 0.2998  decode.d1.loss_cls: 0.0931  decode.d1.loss_mask: 0.2692  decode.d1.loss_dice: 0.3043  decode.d2.loss_cls: 0.0904  decode.d2.loss_mask: 0.2601  decode.d2.loss_dice: 0.2915  decode.d3.loss_cls: 0.0712  decode.d3.loss_mask: 0.2639  decode.d3.loss_dice: 0.2959  decode.d4.loss_cls: 0.0583  decode.d4.loss_mask: 0.2630  decode.d4.loss_dice: 0.2994  decode.d5.loss_cls: 0.1033  decode.d5.loss_mask: 0.2634  decode.d5.loss_dice: 0.2928  decode.d6.loss_cls: 0.0553  decode.d6.loss_mask: 0.2623  decode.d6.loss_dice: 0.2997  decode.d7.loss_cls: 0.0621  decode.d7.loss_mask: 0.2624  decode.d7.loss_dice: 0.2918  decode.d8.loss_cls: 0.0693  decode.d8.loss_mask: 0.2643  decode.d8.loss_dice: 0.2961
07/30 20:58:56 - mmengine - INFO - Iter(train) [35550/80000]  base_lr: 5.8926e-05 lr: 5.8926e-06  eta: 5:23:22  time: 0.4376  data_time: 0.0095  memory: 5265  grad_norm: 78.5383  loss: 7.9401  decode.loss_cls: 0.2980  decode.loss_mask: 0.1936  decode.loss_dice: 0.2035  decode.d0.loss_cls: 1.1067  decode.d0.loss_mask: 0.1943  decode.d0.loss_dice: 0.2110  decode.d1.loss_cls: 0.3308  decode.d1.loss_mask: 0.1833  decode.d1.loss_dice: 0.2082  decode.d2.loss_cls: 0.3006  decode.d2.loss_mask: 0.1850  decode.d2.loss_dice: 0.2207  decode.d3.loss_cls: 0.2560  decode.d3.loss_mask: 0.2314  decode.d3.loss_dice: 0.2449  decode.d4.loss_cls: 0.2971  decode.d4.loss_mask: 0.2205  decode.d4.loss_dice: 0.2505  decode.d5.loss_cls: 0.2799  decode.d5.loss_mask: 0.2404  decode.d5.loss_dice: 0.2349  decode.d6.loss_cls: 0.3028  decode.d6.loss_mask: 0.1813  decode.d6.loss_dice: 0.2138  decode.d7.loss_cls: 0.2814  decode.d7.loss_mask: 0.1788  decode.d7.loss_dice: 0.2122  decode.d8.loss_cls: 0.2898  decode.d8.loss_mask: 0.1846  decode.d8.loss_dice: 0.2040
07/30 20:59:18 - mmengine - INFO - Iter(train) [35600/80000]  base_lr: 5.8867e-05 lr: 5.8867e-06  eta: 5:23:01  time: 0.4384  data_time: 0.0096  memory: 5279  grad_norm: 62.8615  loss: 6.8982  decode.loss_cls: 0.1471  decode.loss_mask: 0.2217  decode.loss_dice: 0.2550  decode.d0.loss_cls: 0.8470  decode.d0.loss_mask: 0.2286  decode.d0.loss_dice: 0.2864  decode.d1.loss_cls: 0.1432  decode.d1.loss_mask: 0.2238  decode.d1.loss_dice: 0.2789  decode.d2.loss_cls: 0.0878  decode.d2.loss_mask: 0.2233  decode.d2.loss_dice: 0.2845  decode.d3.loss_cls: 0.0660  decode.d3.loss_mask: 0.2231  decode.d3.loss_dice: 0.2946  decode.d4.loss_cls: 0.0869  decode.d4.loss_mask: 0.2228  decode.d4.loss_dice: 0.2834  decode.d5.loss_cls: 0.0730  decode.d5.loss_mask: 0.2230  decode.d5.loss_dice: 0.2685  decode.d6.loss_cls: 0.1072  decode.d6.loss_mask: 0.2230  decode.d6.loss_dice: 0.2815  decode.d7.loss_cls: 0.1059  decode.d7.loss_mask: 0.2224  decode.d7.loss_dice: 0.2776  decode.d8.loss_cls: 0.2159  decode.d8.loss_mask: 0.2249  decode.d8.loss_dice: 0.2709
07/30 20:59:40 - mmengine - INFO - Iter(train) [35650/80000]  base_lr: 5.8807e-05 lr: 5.8807e-06  eta: 5:22:39  time: 0.4374  data_time: 0.0097  memory: 5244  grad_norm: 80.1167  loss: 8.0841  decode.loss_cls: 0.2165  decode.loss_mask: 0.2417  decode.loss_dice: 0.2570  decode.d0.loss_cls: 0.9593  decode.d0.loss_mask: 0.2526  decode.d0.loss_dice: 0.2689  decode.d1.loss_cls: 0.2899  decode.d1.loss_mask: 0.2463  decode.d1.loss_dice: 0.2884  decode.d2.loss_cls: 0.2351  decode.d2.loss_mask: 0.2461  decode.d2.loss_dice: 0.2671  decode.d3.loss_cls: 0.1813  decode.d3.loss_mask: 0.2446  decode.d3.loss_dice: 0.2569  decode.d4.loss_cls: 0.1553  decode.d4.loss_mask: 0.2435  decode.d4.loss_dice: 0.2702  decode.d5.loss_cls: 0.1721  decode.d5.loss_mask: 0.2443  decode.d5.loss_dice: 0.2660  decode.d6.loss_cls: 0.2416  decode.d6.loss_mask: 0.2446  decode.d6.loss_dice: 0.2651  decode.d7.loss_cls: 0.2810  decode.d7.loss_mask: 0.2445  decode.d7.loss_dice: 0.2611  decode.d8.loss_cls: 0.2374  decode.d8.loss_mask: 0.2461  decode.d8.loss_dice: 0.2597
07/30 21:00:02 - mmengine - INFO - Iter(train) [35700/80000]  base_lr: 5.8747e-05 lr: 5.8747e-06  eta: 5:22:17  time: 0.4383  data_time: 0.0097  memory: 5245  grad_norm: 52.7792  loss: 7.4830  decode.loss_cls: 0.1406  decode.loss_mask: 0.2562  decode.loss_dice: 0.2663  decode.d0.loss_cls: 0.9891  decode.d0.loss_mask: 0.2695  decode.d0.loss_dice: 0.2742  decode.d1.loss_cls: 0.1687  decode.d1.loss_mask: 0.2591  decode.d1.loss_dice: 0.2714  decode.d2.loss_cls: 0.1505  decode.d2.loss_mask: 0.2602  decode.d2.loss_dice: 0.2618  decode.d3.loss_cls: 0.1214  decode.d3.loss_mask: 0.2618  decode.d3.loss_dice: 0.2683  decode.d4.loss_cls: 0.1418  decode.d4.loss_mask: 0.2601  decode.d4.loss_dice: 0.2596  decode.d5.loss_cls: 0.1124  decode.d5.loss_mask: 0.2595  decode.d5.loss_dice: 0.2629  decode.d6.loss_cls: 0.1024  decode.d6.loss_mask: 0.2609  decode.d6.loss_dice: 0.2837  decode.d7.loss_cls: 0.1298  decode.d7.loss_mask: 0.2625  decode.d7.loss_dice: 0.2666  decode.d8.loss_cls: 0.1385  decode.d8.loss_mask: 0.2608  decode.d8.loss_dice: 0.2621
07/30 21:00:23 - mmengine - INFO - Iter(train) [35750/80000]  base_lr: 5.8688e-05 lr: 5.8688e-06  eta: 5:21:55  time: 0.4379  data_time: 0.0098  memory: 5244  grad_norm: 29.1433  loss: 5.5837  decode.loss_cls: 0.0023  decode.loss_mask: 0.2458  decode.loss_dice: 0.2159  decode.d0.loss_cls: 0.8567  decode.d0.loss_mask: 0.2534  decode.d0.loss_dice: 0.2155  decode.d1.loss_cls: 0.0101  decode.d1.loss_mask: 0.2507  decode.d1.loss_dice: 0.2266  decode.d2.loss_cls: 0.0073  decode.d2.loss_mask: 0.2524  decode.d2.loss_dice: 0.2241  decode.d3.loss_cls: 0.0052  decode.d3.loss_mask: 0.2493  decode.d3.loss_dice: 0.2185  decode.d4.loss_cls: 0.0059  decode.d4.loss_mask: 0.2450  decode.d4.loss_dice: 0.2170  decode.d5.loss_cls: 0.0041  decode.d5.loss_mask: 0.2478  decode.d5.loss_dice: 0.2201  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.2480  decode.d6.loss_dice: 0.2228  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.2439  decode.d7.loss_dice: 0.2185  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.2476  decode.d8.loss_dice: 0.2190
07/30 21:00:45 - mmengine - INFO - Iter(train) [35800/80000]  base_lr: 5.8628e-05 lr: 5.8628e-06  eta: 5:21:34  time: 0.4376  data_time: 0.0097  memory: 5265  grad_norm: 46.7954  loss: 7.9693  decode.loss_cls: 0.2125  decode.loss_mask: 0.2680  decode.loss_dice: 0.2916  decode.d0.loss_cls: 0.8741  decode.d0.loss_mask: 0.2749  decode.d0.loss_dice: 0.2665  decode.d1.loss_cls: 0.1301  decode.d1.loss_mask: 0.2742  decode.d1.loss_dice: 0.2581  decode.d2.loss_cls: 0.1745  decode.d2.loss_mask: 0.2713  decode.d2.loss_dice: 0.2660  decode.d3.loss_cls: 0.1529  decode.d3.loss_mask: 0.2675  decode.d3.loss_dice: 0.2892  decode.d4.loss_cls: 0.2005  decode.d4.loss_mask: 0.2684  decode.d4.loss_dice: 0.2695  decode.d5.loss_cls: 0.1654  decode.d5.loss_mask: 0.2690  decode.d5.loss_dice: 0.2823  decode.d6.loss_cls: 0.1813  decode.d6.loss_mask: 0.2720  decode.d6.loss_dice: 0.2905  decode.d7.loss_cls: 0.2062  decode.d7.loss_mask: 0.2685  decode.d7.loss_dice: 0.2792  decode.d8.loss_cls: 0.2104  decode.d8.loss_mask: 0.2684  decode.d8.loss_dice: 0.2664
07/30 21:01:07 - mmengine - INFO - Iter(train) [35850/80000]  base_lr: 5.8568e-05 lr: 5.8568e-06  eta: 5:21:12  time: 0.4375  data_time: 0.0096  memory: 5278  grad_norm: 99.0619  loss: 7.4095  decode.loss_cls: 0.1723  decode.loss_mask: 0.2484  decode.loss_dice: 0.2493  decode.d0.loss_cls: 0.9147  decode.d0.loss_mask: 0.2506  decode.d0.loss_dice: 0.2588  decode.d1.loss_cls: 0.1682  decode.d1.loss_mask: 0.2461  decode.d1.loss_dice: 0.2501  decode.d2.loss_cls: 0.1946  decode.d2.loss_mask: 0.2438  decode.d2.loss_dice: 0.2448  decode.d3.loss_cls: 0.1691  decode.d3.loss_mask: 0.2463  decode.d3.loss_dice: 0.2455  decode.d4.loss_cls: 0.2055  decode.d4.loss_mask: 0.2461  decode.d4.loss_dice: 0.2400  decode.d5.loss_cls: 0.2028  decode.d5.loss_mask: 0.2484  decode.d5.loss_dice: 0.2410  decode.d6.loss_cls: 0.1481  decode.d6.loss_mask: 0.2455  decode.d6.loss_dice: 0.2442  decode.d7.loss_cls: 0.1542  decode.d7.loss_mask: 0.2467  decode.d7.loss_dice: 0.2540  decode.d8.loss_cls: 0.1355  decode.d8.loss_mask: 0.2474  decode.d8.loss_dice: 0.2474
07/30 21:01:29 - mmengine - INFO - Iter(train) [35900/80000]  base_lr: 5.8508e-05 lr: 5.8508e-06  eta: 5:20:50  time: 0.4389  data_time: 0.0093  memory: 5246  grad_norm: 37.6241  loss: 6.8724  decode.loss_cls: 0.0979  decode.loss_mask: 0.2230  decode.loss_dice: 0.2528  decode.d0.loss_cls: 0.9071  decode.d0.loss_mask: 0.2240  decode.d0.loss_dice: 0.2570  decode.d1.loss_cls: 0.1755  decode.d1.loss_mask: 0.2278  decode.d1.loss_dice: 0.2665  decode.d2.loss_cls: 0.1311  decode.d2.loss_mask: 0.2250  decode.d2.loss_dice: 0.2491  decode.d3.loss_cls: 0.1200  decode.d3.loss_mask: 0.2265  decode.d3.loss_dice: 0.2310  decode.d4.loss_cls: 0.1083  decode.d4.loss_mask: 0.2310  decode.d4.loss_dice: 0.2496  decode.d5.loss_cls: 0.1075  decode.d5.loss_mask: 0.2286  decode.d5.loss_dice: 0.2509  decode.d6.loss_cls: 0.1809  decode.d6.loss_mask: 0.2258  decode.d6.loss_dice: 0.2351  decode.d7.loss_cls: 0.1283  decode.d7.loss_mask: 0.2229  decode.d7.loss_dice: 0.2589  decode.d8.loss_cls: 0.1448  decode.d8.loss_mask: 0.2274  decode.d8.loss_dice: 0.2581
07/30 21:01:51 - mmengine - INFO - Iter(train) [35950/80000]  base_lr: 5.8449e-05 lr: 5.8449e-06  eta: 5:20:29  time: 0.4404  data_time: 0.0095  memory: 5277  grad_norm: 25.2808  loss: 6.3628  decode.loss_cls: 0.1447  decode.loss_mask: 0.1933  decode.loss_dice: 0.2493  decode.d0.loss_cls: 1.0712  decode.d0.loss_mask: 0.1943  decode.d0.loss_dice: 0.2388  decode.d1.loss_cls: 0.1112  decode.d1.loss_mask: 0.1914  decode.d1.loss_dice: 0.2405  decode.d2.loss_cls: 0.1108  decode.d2.loss_mask: 0.1946  decode.d2.loss_dice: 0.2414  decode.d3.loss_cls: 0.1125  decode.d3.loss_mask: 0.1918  decode.d3.loss_dice: 0.2435  decode.d4.loss_cls: 0.0817  decode.d4.loss_mask: 0.1918  decode.d4.loss_dice: 0.2398  decode.d5.loss_cls: 0.0898  decode.d5.loss_mask: 0.1915  decode.d5.loss_dice: 0.2398  decode.d6.loss_cls: 0.0732  decode.d6.loss_mask: 0.1914  decode.d6.loss_dice: 0.2527  decode.d7.loss_cls: 0.1072  decode.d7.loss_mask: 0.1903  decode.d7.loss_dice: 0.2425  decode.d8.loss_cls: 0.0980  decode.d8.loss_mask: 0.1925  decode.d8.loss_dice: 0.2514
07/30 21:02:13 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 21:02:13 - mmengine - INFO - Iter(train) [36000/80000]  base_lr: 5.8389e-05 lr: 5.8389e-06  eta: 5:20:07  time: 0.4417  data_time: 0.0097  memory: 5322  grad_norm: 55.7103  loss: 6.9837  decode.loss_cls: 0.0703  decode.loss_mask: 0.2272  decode.loss_dice: 0.2695  decode.d0.loss_cls: 0.9284  decode.d0.loss_mask: 0.2373  decode.d0.loss_dice: 0.3041  decode.d1.loss_cls: 0.1811  decode.d1.loss_mask: 0.2265  decode.d1.loss_dice: 0.2853  decode.d2.loss_cls: 0.1311  decode.d2.loss_mask: 0.2297  decode.d2.loss_dice: 0.2978  decode.d3.loss_cls: 0.0809  decode.d3.loss_mask: 0.2295  decode.d3.loss_dice: 0.2961  decode.d4.loss_cls: 0.0818  decode.d4.loss_mask: 0.2262  decode.d4.loss_dice: 0.2986  decode.d5.loss_cls: 0.0739  decode.d5.loss_mask: 0.2266  decode.d5.loss_dice: 0.2935  decode.d6.loss_cls: 0.0549  decode.d6.loss_mask: 0.2331  decode.d6.loss_dice: 0.2882  decode.d7.loss_cls: 0.0779  decode.d7.loss_mask: 0.2278  decode.d7.loss_dice: 0.2942  decode.d8.loss_cls: 0.0850  decode.d8.loss_mask: 0.2278  decode.d8.loss_dice: 0.2995
07/30 21:02:35 - mmengine - INFO - Iter(train) [36050/80000]  base_lr: 5.8329e-05 lr: 5.8329e-06  eta: 5:19:45  time: 0.4415  data_time: 0.0094  memory: 5265  grad_norm: 26.0846  loss: 5.8581  decode.loss_cls: 0.1023  decode.loss_mask: 0.1815  decode.loss_dice: 0.2226  decode.d0.loss_cls: 0.9204  decode.d0.loss_mask: 0.1746  decode.d0.loss_dice: 0.2282  decode.d1.loss_cls: 0.1240  decode.d1.loss_mask: 0.1766  decode.d1.loss_dice: 0.2220  decode.d2.loss_cls: 0.1012  decode.d2.loss_mask: 0.1757  decode.d2.loss_dice: 0.2224  decode.d3.loss_cls: 0.1069  decode.d3.loss_mask: 0.1749  decode.d3.loss_dice: 0.2247  decode.d4.loss_cls: 0.1056  decode.d4.loss_mask: 0.1727  decode.d4.loss_dice: 0.2229  decode.d5.loss_cls: 0.0985  decode.d5.loss_mask: 0.1749  decode.d5.loss_dice: 0.2212  decode.d6.loss_cls: 0.0988  decode.d6.loss_mask: 0.1733  decode.d6.loss_dice: 0.2193  decode.d7.loss_cls: 0.1008  decode.d7.loss_mask: 0.1751  decode.d7.loss_dice: 0.2264  decode.d8.loss_cls: 0.0958  decode.d8.loss_mask: 0.1798  decode.d8.loss_dice: 0.2351
07/30 21:02:57 - mmengine - INFO - Iter(train) [36100/80000]  base_lr: 5.8270e-05 lr: 5.8270e-06  eta: 5:19:24  time: 0.4383  data_time: 0.0094  memory: 5304  grad_norm: 105.0477  loss: 7.5066  decode.loss_cls: 0.2009  decode.loss_mask: 0.2231  decode.loss_dice: 0.2580  decode.d0.loss_cls: 0.9545  decode.d0.loss_mask: 0.2248  decode.d0.loss_dice: 0.2731  decode.d1.loss_cls: 0.1707  decode.d1.loss_mask: 0.2183  decode.d1.loss_dice: 0.2700  decode.d2.loss_cls: 0.1735  decode.d2.loss_mask: 0.2302  decode.d2.loss_dice: 0.2943  decode.d3.loss_cls: 0.1823  decode.d3.loss_mask: 0.2219  decode.d3.loss_dice: 0.2472  decode.d4.loss_cls: 0.1601  decode.d4.loss_mask: 0.2363  decode.d4.loss_dice: 0.2795  decode.d5.loss_cls: 0.1541  decode.d5.loss_mask: 0.2390  decode.d5.loss_dice: 0.2690  decode.d6.loss_cls: 0.1656  decode.d6.loss_mask: 0.2233  decode.d6.loss_dice: 0.2735  decode.d7.loss_cls: 0.2115  decode.d7.loss_mask: 0.2209  decode.d7.loss_dice: 0.2529  decode.d8.loss_cls: 0.1956  decode.d8.loss_mask: 0.2260  decode.d8.loss_dice: 0.2567
07/30 21:03:19 - mmengine - INFO - Iter(train) [36150/80000]  base_lr: 5.8210e-05 lr: 5.8210e-06  eta: 5:19:02  time: 0.4381  data_time: 0.0094  memory: 5244  grad_norm: 66.1738  loss: 8.3412  decode.loss_cls: 0.2512  decode.loss_mask: 0.2369  decode.loss_dice: 0.2724  decode.d0.loss_cls: 1.0474  decode.d0.loss_mask: 0.2487  decode.d0.loss_dice: 0.2970  decode.d1.loss_cls: 0.2699  decode.d1.loss_mask: 0.2439  decode.d1.loss_dice: 0.2610  decode.d2.loss_cls: 0.2072  decode.d2.loss_mask: 0.2402  decode.d2.loss_dice: 0.2738  decode.d3.loss_cls: 0.2163  decode.d3.loss_mask: 0.2423  decode.d3.loss_dice: 0.2539  decode.d4.loss_cls: 0.2706  decode.d4.loss_mask: 0.2411  decode.d4.loss_dice: 0.2821  decode.d5.loss_cls: 0.2053  decode.d5.loss_mask: 0.2384  decode.d5.loss_dice: 0.2620  decode.d6.loss_cls: 0.2447  decode.d6.loss_mask: 0.2402  decode.d6.loss_dice: 0.2790  decode.d7.loss_cls: 0.2893  decode.d7.loss_mask: 0.2368  decode.d7.loss_dice: 0.2752  decode.d8.loss_cls: 0.2024  decode.d8.loss_mask: 0.2366  decode.d8.loss_dice: 0.2756
07/30 21:03:41 - mmengine - INFO - Iter(train) [36200/80000]  base_lr: 5.8150e-05 lr: 5.8150e-06  eta: 5:18:41  time: 0.4383  data_time: 0.0095  memory: 5246  grad_norm: 93.4460  loss: 8.3248  decode.loss_cls: 0.2013  decode.loss_mask: 0.2144  decode.loss_dice: 0.3158  decode.d0.loss_cls: 1.1131  decode.d0.loss_mask: 0.2155  decode.d0.loss_dice: 0.3307  decode.d1.loss_cls: 0.2942  decode.d1.loss_mask: 0.2168  decode.d1.loss_dice: 0.3016  decode.d2.loss_cls: 0.2401  decode.d2.loss_mask: 0.2182  decode.d2.loss_dice: 0.2983  decode.d3.loss_cls: 0.2215  decode.d3.loss_mask: 0.2162  decode.d3.loss_dice: 0.3206  decode.d4.loss_cls: 0.2146  decode.d4.loss_mask: 0.2156  decode.d4.loss_dice: 0.3019  decode.d5.loss_cls: 0.1652  decode.d5.loss_mask: 0.2144  decode.d5.loss_dice: 0.2990  decode.d6.loss_cls: 0.2027  decode.d6.loss_mask: 0.2163  decode.d6.loss_dice: 0.3192  decode.d7.loss_cls: 0.2054  decode.d7.loss_mask: 0.2154  decode.d7.loss_dice: 0.3085  decode.d8.loss_cls: 0.2090  decode.d8.loss_mask: 0.2157  decode.d8.loss_dice: 0.3035
07/30 21:04:03 - mmengine - INFO - Iter(train) [36250/80000]  base_lr: 5.8090e-05 lr: 5.8090e-06  eta: 5:18:19  time: 0.4412  data_time: 0.0095  memory: 5265  grad_norm: 57.7991  loss: 6.9806  decode.loss_cls: 0.1220  decode.loss_mask: 0.1999  decode.loss_dice: 0.2768  decode.d0.loss_cls: 1.0904  decode.d0.loss_mask: 0.2003  decode.d0.loss_dice: 0.2907  decode.d1.loss_cls: 0.0773  decode.d1.loss_mask: 0.2022  decode.d1.loss_dice: 0.2874  decode.d2.loss_cls: 0.0810  decode.d2.loss_mask: 0.2014  decode.d2.loss_dice: 0.2795  decode.d3.loss_cls: 0.1256  decode.d3.loss_mask: 0.2029  decode.d3.loss_dice: 0.2758  decode.d4.loss_cls: 0.1157  decode.d4.loss_mask: 0.1993  decode.d4.loss_dice: 0.2803  decode.d5.loss_cls: 0.1240  decode.d5.loss_mask: 0.2035  decode.d5.loss_dice: 0.2871  decode.d6.loss_cls: 0.1399  decode.d6.loss_mask: 0.2017  decode.d6.loss_dice: 0.2790  decode.d7.loss_cls: 0.1364  decode.d7.loss_mask: 0.2022  decode.d7.loss_dice: 0.2829  decode.d8.loss_cls: 0.1273  decode.d8.loss_mask: 0.2048  decode.d8.loss_dice: 0.2835
07/30 21:04:25 - mmengine - INFO - Iter(train) [36300/80000]  base_lr: 5.8031e-05 lr: 5.8031e-06  eta: 5:17:57  time: 0.4408  data_time: 0.0094  memory: 5246  grad_norm: 118.6246  loss: 6.0884  decode.loss_cls: 0.0955  decode.loss_mask: 0.1584  decode.loss_dice: 0.2384  decode.d0.loss_cls: 1.0811  decode.d0.loss_mask: 0.1628  decode.d0.loss_dice: 0.2592  decode.d1.loss_cls: 0.1141  decode.d1.loss_mask: 0.1589  decode.d1.loss_dice: 0.2377  decode.d2.loss_cls: 0.1274  decode.d2.loss_mask: 0.1609  decode.d2.loss_dice: 0.2377  decode.d3.loss_cls: 0.0893  decode.d3.loss_mask: 0.1594  decode.d3.loss_dice: 0.2364  decode.d4.loss_cls: 0.1064  decode.d4.loss_mask: 0.1601  decode.d4.loss_dice: 0.2456  decode.d5.loss_cls: 0.0916  decode.d5.loss_mask: 0.1578  decode.d5.loss_dice: 0.2396  decode.d6.loss_cls: 0.1086  decode.d6.loss_mask: 0.1595  decode.d6.loss_dice: 0.2456  decode.d7.loss_cls: 0.0911  decode.d7.loss_mask: 0.1576  decode.d7.loss_dice: 0.2387  decode.d8.loss_cls: 0.1731  decode.d8.loss_mask: 0.1586  decode.d8.loss_dice: 0.2374
07/30 21:04:47 - mmengine - INFO - Iter(train) [36350/80000]  base_lr: 5.7971e-05 lr: 5.7971e-06  eta: 5:17:36  time: 0.4373  data_time: 0.0097  memory: 5246  grad_norm: 78.0124  loss: 6.6904  decode.loss_cls: 0.0795  decode.loss_mask: 0.2158  decode.loss_dice: 0.2594  decode.d0.loss_cls: 0.8597  decode.d0.loss_mask: 0.2278  decode.d0.loss_dice: 0.2661  decode.d1.loss_cls: 0.0705  decode.d1.loss_mask: 0.2275  decode.d1.loss_dice: 0.2983  decode.d2.loss_cls: 0.1380  decode.d2.loss_mask: 0.2196  decode.d2.loss_dice: 0.2640  decode.d3.loss_cls: 0.1330  decode.d3.loss_mask: 0.2194  decode.d3.loss_dice: 0.2608  decode.d4.loss_cls: 0.1158  decode.d4.loss_mask: 0.2232  decode.d4.loss_dice: 0.2690  decode.d5.loss_cls: 0.1089  decode.d5.loss_mask: 0.2185  decode.d5.loss_dice: 0.2596  decode.d6.loss_cls: 0.1162  decode.d6.loss_mask: 0.2193  decode.d6.loss_dice: 0.2563  decode.d7.loss_cls: 0.0743  decode.d7.loss_mask: 0.2208  decode.d7.loss_dice: 0.2806  decode.d8.loss_cls: 0.1004  decode.d8.loss_mask: 0.2175  decode.d8.loss_dice: 0.2704
07/30 21:05:09 - mmengine - INFO - Iter(train) [36400/80000]  base_lr: 5.7911e-05 lr: 5.7911e-06  eta: 5:17:14  time: 0.4387  data_time: 0.0097  memory: 5279  grad_norm: 50.4342  loss: 7.3440  decode.loss_cls: 0.1249  decode.loss_mask: 0.2480  decode.loss_dice: 0.2845  decode.d0.loss_cls: 1.0204  decode.d0.loss_mask: 0.2497  decode.d0.loss_dice: 0.2715  decode.d1.loss_cls: 0.1391  decode.d1.loss_mask: 0.2444  decode.d1.loss_dice: 0.2446  decode.d2.loss_cls: 0.1319  decode.d2.loss_mask: 0.2441  decode.d2.loss_dice: 0.2534  decode.d3.loss_cls: 0.1334  decode.d3.loss_mask: 0.2453  decode.d3.loss_dice: 0.2546  decode.d4.loss_cls: 0.1514  decode.d4.loss_mask: 0.2467  decode.d4.loss_dice: 0.2731  decode.d5.loss_cls: 0.1172  decode.d5.loss_mask: 0.2424  decode.d5.loss_dice: 0.2524  decode.d6.loss_cls: 0.1220  decode.d6.loss_mask: 0.2455  decode.d6.loss_dice: 0.2661  decode.d7.loss_cls: 0.1705  decode.d7.loss_mask: 0.2454  decode.d7.loss_dice: 0.2728  decode.d8.loss_cls: 0.1353  decode.d8.loss_mask: 0.2493  decode.d8.loss_dice: 0.2642
07/30 21:05:31 - mmengine - INFO - Iter(train) [36450/80000]  base_lr: 5.7851e-05 lr: 5.7851e-06  eta: 5:16:52  time: 0.4404  data_time: 0.0096  memory: 5246  grad_norm: 69.2521  loss: 6.4084  decode.loss_cls: 0.0707  decode.loss_mask: 0.2065  decode.loss_dice: 0.2705  decode.d0.loss_cls: 0.9373  decode.d0.loss_mask: 0.2257  decode.d0.loss_dice: 0.2963  decode.d1.loss_cls: 0.0769  decode.d1.loss_mask: 0.2017  decode.d1.loss_dice: 0.2856  decode.d2.loss_cls: 0.0800  decode.d2.loss_mask: 0.2070  decode.d2.loss_dice: 0.2683  decode.d3.loss_cls: 0.0641  decode.d3.loss_mask: 0.2091  decode.d3.loss_dice: 0.2703  decode.d4.loss_cls: 0.0584  decode.d4.loss_mask: 0.2103  decode.d4.loss_dice: 0.2750  decode.d5.loss_cls: 0.0668  decode.d5.loss_mask: 0.2044  decode.d5.loss_dice: 0.2763  decode.d6.loss_cls: 0.0838  decode.d6.loss_mask: 0.2052  decode.d6.loss_dice: 0.2866  decode.d7.loss_cls: 0.0217  decode.d7.loss_mask: 0.2232  decode.d7.loss_dice: 0.2844  decode.d8.loss_cls: 0.0676  decode.d8.loss_mask: 0.2070  decode.d8.loss_dice: 0.2677
07/30 21:05:53 - mmengine - INFO - Iter(train) [36500/80000]  base_lr: 5.7792e-05 lr: 5.7792e-06  eta: 5:16:31  time: 0.4404  data_time: 0.0097  memory: 5278  grad_norm: 103.0416  loss: 7.6238  decode.loss_cls: 0.1105  decode.loss_mask: 0.2523  decode.loss_dice: 0.3140  decode.d0.loss_cls: 0.8465  decode.d0.loss_mask: 0.2642  decode.d0.loss_dice: 0.3251  decode.d1.loss_cls: 0.1012  decode.d1.loss_mask: 0.2576  decode.d1.loss_dice: 0.3173  decode.d2.loss_cls: 0.1241  decode.d2.loss_mask: 0.2532  decode.d2.loss_dice: 0.3124  decode.d3.loss_cls: 0.1030  decode.d3.loss_mask: 0.2537  decode.d3.loss_dice: 0.3067  decode.d4.loss_cls: 0.1403  decode.d4.loss_mask: 0.2519  decode.d4.loss_dice: 0.3101  decode.d5.loss_cls: 0.1407  decode.d5.loss_mask: 0.2518  decode.d5.loss_dice: 0.3096  decode.d6.loss_cls: 0.1446  decode.d6.loss_mask: 0.2493  decode.d6.loss_dice: 0.3077  decode.d7.loss_cls: 0.1295  decode.d7.loss_mask: 0.2525  decode.d7.loss_dice: 0.3081  decode.d8.loss_cls: 0.1354  decode.d8.loss_mask: 0.2495  decode.d8.loss_dice: 0.3010
07/30 21:06:15 - mmengine - INFO - Iter(train) [36550/80000]  base_lr: 5.7732e-05 lr: 5.7732e-06  eta: 5:16:09  time: 0.4387  data_time: 0.0097  memory: 5245  grad_norm: 69.0411  loss: 6.6895  decode.loss_cls: 0.1424  decode.loss_mask: 0.2222  decode.loss_dice: 0.2456  decode.d0.loss_cls: 0.8088  decode.d0.loss_mask: 0.2342  decode.d0.loss_dice: 0.2619  decode.d1.loss_cls: 0.1324  decode.d1.loss_mask: 0.2302  decode.d1.loss_dice: 0.2560  decode.d2.loss_cls: 0.1407  decode.d2.loss_mask: 0.2239  decode.d2.loss_dice: 0.2565  decode.d3.loss_cls: 0.1220  decode.d3.loss_mask: 0.2208  decode.d3.loss_dice: 0.2495  decode.d4.loss_cls: 0.1020  decode.d4.loss_mask: 0.2209  decode.d4.loss_dice: 0.2530  decode.d5.loss_cls: 0.1546  decode.d5.loss_mask: 0.2236  decode.d5.loss_dice: 0.2477  decode.d6.loss_cls: 0.0944  decode.d6.loss_mask: 0.2228  decode.d6.loss_dice: 0.2577  decode.d7.loss_cls: 0.1172  decode.d7.loss_mask: 0.2225  decode.d7.loss_dice: 0.2520  decode.d8.loss_cls: 0.1071  decode.d8.loss_mask: 0.2195  decode.d8.loss_dice: 0.2472
07/30 21:06:37 - mmengine - INFO - Iter(train) [36600/80000]  base_lr: 5.7672e-05 lr: 5.7672e-06  eta: 5:15:47  time: 0.4398  data_time: 0.0096  memory: 5241  grad_norm: 40.4429  loss: 6.4516  decode.loss_cls: 0.0755  decode.loss_mask: 0.2186  decode.loss_dice: 0.2679  decode.d0.loss_cls: 0.9637  decode.d0.loss_mask: 0.2239  decode.d0.loss_dice: 0.2647  decode.d1.loss_cls: 0.0497  decode.d1.loss_mask: 0.2313  decode.d1.loss_dice: 0.2907  decode.d2.loss_cls: 0.0402  decode.d2.loss_mask: 0.2247  decode.d2.loss_dice: 0.2652  decode.d3.loss_cls: 0.0350  decode.d3.loss_mask: 0.2257  decode.d3.loss_dice: 0.2769  decode.d4.loss_cls: 0.0951  decode.d4.loss_mask: 0.2241  decode.d4.loss_dice: 0.2732  decode.d5.loss_cls: 0.0740  decode.d5.loss_mask: 0.2187  decode.d5.loss_dice: 0.2731  decode.d6.loss_cls: 0.0610  decode.d6.loss_mask: 0.2183  decode.d6.loss_dice: 0.2677  decode.d7.loss_cls: 0.0648  decode.d7.loss_mask: 0.2202  decode.d7.loss_dice: 0.2734  decode.d8.loss_cls: 0.0408  decode.d8.loss_mask: 0.2182  decode.d8.loss_dice: 0.2754
07/30 21:06:59 - mmengine - INFO - Iter(train) [36650/80000]  base_lr: 5.7612e-05 lr: 5.7612e-06  eta: 5:15:26  time: 0.4381  data_time: 0.0096  memory: 5305  grad_norm: 98.9649  loss: 6.8881  decode.loss_cls: 0.1739  decode.loss_mask: 0.1929  decode.loss_dice: 0.2393  decode.d0.loss_cls: 1.0011  decode.d0.loss_mask: 0.2016  decode.d0.loss_dice: 0.2909  decode.d1.loss_cls: 0.2355  decode.d1.loss_mask: 0.1934  decode.d1.loss_dice: 0.2295  decode.d2.loss_cls: 0.1863  decode.d2.loss_mask: 0.1930  decode.d2.loss_dice: 0.2547  decode.d3.loss_cls: 0.1212  decode.d3.loss_mask: 0.1927  decode.d3.loss_dice: 0.2422  decode.d4.loss_cls: 0.1211  decode.d4.loss_mask: 0.1948  decode.d4.loss_dice: 0.2573  decode.d5.loss_cls: 0.1495  decode.d5.loss_mask: 0.1931  decode.d5.loss_dice: 0.2592  decode.d6.loss_cls: 0.1409  decode.d6.loss_mask: 0.1934  decode.d6.loss_dice: 0.2598  decode.d7.loss_cls: 0.1363  decode.d7.loss_mask: 0.1938  decode.d7.loss_dice: 0.2551  decode.d8.loss_cls: 0.1475  decode.d8.loss_mask: 0.1937  decode.d8.loss_dice: 0.2444
07/30 21:07:21 - mmengine - INFO - Iter(train) [36700/80000]  base_lr: 5.7552e-05 lr: 5.7552e-06  eta: 5:15:04  time: 0.4402  data_time: 0.0096  memory: 5279  grad_norm: 54.0081  loss: 5.3490  decode.loss_cls: 0.0265  decode.loss_mask: 0.1941  decode.loss_dice: 0.2142  decode.d0.loss_cls: 0.9613  decode.d0.loss_mask: 0.1962  decode.d0.loss_dice: 0.2225  decode.d1.loss_cls: 0.0634  decode.d1.loss_mask: 0.1920  decode.d1.loss_dice: 0.2183  decode.d2.loss_cls: 0.0200  decode.d2.loss_mask: 0.1968  decode.d2.loss_dice: 0.2174  decode.d3.loss_cls: 0.0241  decode.d3.loss_mask: 0.1964  decode.d3.loss_dice: 0.2189  decode.d4.loss_cls: 0.0139  decode.d4.loss_mask: 0.1988  decode.d4.loss_dice: 0.2234  decode.d5.loss_cls: 0.0138  decode.d5.loss_mask: 0.1974  decode.d5.loss_dice: 0.2238  decode.d6.loss_cls: 0.0181  decode.d6.loss_mask: 0.1986  decode.d6.loss_dice: 0.2236  decode.d7.loss_cls: 0.0251  decode.d7.loss_mask: 0.1956  decode.d7.loss_dice: 0.2154  decode.d8.loss_cls: 0.0303  decode.d8.loss_mask: 0.1946  decode.d8.loss_dice: 0.2146
07/30 21:07:43 - mmengine - INFO - Iter(train) [36750/80000]  base_lr: 5.7493e-05 lr: 5.7493e-06  eta: 5:14:42  time: 0.4392  data_time: 0.0095  memory: 5304  grad_norm: 46.3789  loss: 7.3841  decode.loss_cls: 0.2171  decode.loss_mask: 0.2086  decode.loss_dice: 0.2535  decode.d0.loss_cls: 0.8738  decode.d0.loss_mask: 0.2125  decode.d0.loss_dice: 0.2691  decode.d1.loss_cls: 0.2820  decode.d1.loss_mask: 0.2068  decode.d1.loss_dice: 0.2463  decode.d2.loss_cls: 0.1878  decode.d2.loss_mask: 0.2060  decode.d2.loss_dice: 0.2394  decode.d3.loss_cls: 0.2288  decode.d3.loss_mask: 0.2047  decode.d3.loss_dice: 0.2489  decode.d4.loss_cls: 0.2236  decode.d4.loss_mask: 0.2071  decode.d4.loss_dice: 0.2423  decode.d5.loss_cls: 0.2249  decode.d5.loss_mask: 0.2045  decode.d5.loss_dice: 0.2485  decode.d6.loss_cls: 0.2007  decode.d6.loss_mask: 0.2071  decode.d6.loss_dice: 0.2526  decode.d7.loss_cls: 0.1905  decode.d7.loss_mask: 0.2094  decode.d7.loss_dice: 0.2351  decode.d8.loss_cls: 0.1996  decode.d8.loss_mask: 0.2068  decode.d8.loss_dice: 0.2459
07/30 21:08:05 - mmengine - INFO - Iter(train) [36800/80000]  base_lr: 5.7433e-05 lr: 5.7433e-06  eta: 5:14:21  time: 0.4398  data_time: 0.0096  memory: 5246  grad_norm: 143.6623  loss: 8.2570  decode.loss_cls: 0.2335  decode.loss_mask: 0.2502  decode.loss_dice: 0.3113  decode.d0.loss_cls: 0.9917  decode.d0.loss_mask: 0.2596  decode.d0.loss_dice: 0.2994  decode.d1.loss_cls: 0.2232  decode.d1.loss_mask: 0.2479  decode.d1.loss_dice: 0.2433  decode.d2.loss_cls: 0.2781  decode.d2.loss_mask: 0.2471  decode.d2.loss_dice: 0.2451  decode.d3.loss_cls: 0.1504  decode.d3.loss_mask: 0.2725  decode.d3.loss_dice: 0.3003  decode.d4.loss_cls: 0.1483  decode.d4.loss_mask: 0.3275  decode.d4.loss_dice: 0.2767  decode.d5.loss_cls: 0.1547  decode.d5.loss_mask: 0.3092  decode.d5.loss_dice: 0.3229  decode.d6.loss_cls: 0.1320  decode.d6.loss_mask: 0.2849  decode.d6.loss_dice: 0.2969  decode.d7.loss_cls: 0.1723  decode.d7.loss_mask: 0.2796  decode.d7.loss_dice: 0.2919  decode.d8.loss_cls: 0.1556  decode.d8.loss_mask: 0.2840  decode.d8.loss_dice: 0.2672
07/30 21:08:27 - mmengine - INFO - Iter(train) [36850/80000]  base_lr: 5.7373e-05 lr: 5.7373e-06  eta: 5:13:59  time: 0.4378  data_time: 0.0095  memory: 5229  grad_norm: 38.6899  loss: 6.2224  decode.loss_cls: 0.0253  decode.loss_mask: 0.2404  decode.loss_dice: 0.2635  decode.d0.loss_cls: 0.8647  decode.d0.loss_mask: 0.2464  decode.d0.loss_dice: 0.2902  decode.d1.loss_cls: 0.0887  decode.d1.loss_mask: 0.2407  decode.d1.loss_dice: 0.2723  decode.d2.loss_cls: 0.0165  decode.d2.loss_mask: 0.2378  decode.d2.loss_dice: 0.2621  decode.d3.loss_cls: 0.0253  decode.d3.loss_mask: 0.2355  decode.d3.loss_dice: 0.2491  decode.d4.loss_cls: 0.0350  decode.d4.loss_mask: 0.2389  decode.d4.loss_dice: 0.2490  decode.d5.loss_cls: 0.0919  decode.d5.loss_mask: 0.2394  decode.d5.loss_dice: 0.2543  decode.d6.loss_cls: 0.0337  decode.d6.loss_mask: 0.2399  decode.d6.loss_dice: 0.2490  decode.d7.loss_cls: 0.0303  decode.d7.loss_mask: 0.2377  decode.d7.loss_dice: 0.2534  decode.d8.loss_cls: 0.0364  decode.d8.loss_mask: 0.2399  decode.d8.loss_dice: 0.2350
07/30 21:08:49 - mmengine - INFO - Iter(train) [36900/80000]  base_lr: 5.7313e-05 lr: 5.7313e-06  eta: 5:13:37  time: 0.4369  data_time: 0.0095  memory: 5279  grad_norm: 59.9627  loss: 6.8997  decode.loss_cls: 0.1203  decode.loss_mask: 0.2593  decode.loss_dice: 0.2379  decode.d0.loss_cls: 0.9386  decode.d0.loss_mask: 0.2641  decode.d0.loss_dice: 0.2454  decode.d1.loss_cls: 0.0911  decode.d1.loss_mask: 0.2623  decode.d1.loss_dice: 0.2550  decode.d2.loss_cls: 0.0892  decode.d2.loss_mask: 0.2587  decode.d2.loss_dice: 0.2285  decode.d3.loss_cls: 0.1291  decode.d3.loss_mask: 0.2598  decode.d3.loss_dice: 0.2215  decode.d4.loss_cls: 0.1175  decode.d4.loss_mask: 0.2641  decode.d4.loss_dice: 0.2282  decode.d5.loss_cls: 0.1315  decode.d5.loss_mask: 0.2611  decode.d5.loss_dice: 0.2259  decode.d6.loss_cls: 0.1258  decode.d6.loss_mask: 0.2599  decode.d6.loss_dice: 0.2308  decode.d7.loss_cls: 0.1110  decode.d7.loss_mask: 0.2606  decode.d7.loss_dice: 0.2267  decode.d8.loss_cls: 0.0781  decode.d8.loss_mask: 0.2629  decode.d8.loss_dice: 0.2548
07/30 21:09:11 - mmengine - INFO - Iter(train) [36950/80000]  base_lr: 5.7253e-05 lr: 5.7253e-06  eta: 5:13:16  time: 0.4379  data_time: 0.0096  memory: 5278  grad_norm: 121.7649  loss: 8.2749  decode.loss_cls: 0.3281  decode.loss_mask: 0.2303  decode.loss_dice: 0.2713  decode.d0.loss_cls: 0.9984  decode.d0.loss_mask: 0.2353  decode.d0.loss_dice: 0.2689  decode.d1.loss_cls: 0.2803  decode.d1.loss_mask: 0.2325  decode.d1.loss_dice: 0.2607  decode.d2.loss_cls: 0.2472  decode.d2.loss_mask: 0.2299  decode.d2.loss_dice: 0.2455  decode.d3.loss_cls: 0.2518  decode.d3.loss_mask: 0.2256  decode.d3.loss_dice: 0.2372  decode.d4.loss_cls: 0.2411  decode.d4.loss_mask: 0.2280  decode.d4.loss_dice: 0.2395  decode.d5.loss_cls: 0.2366  decode.d5.loss_mask: 0.2291  decode.d5.loss_dice: 0.2688  decode.d6.loss_cls: 0.2451  decode.d6.loss_mask: 0.2266  decode.d6.loss_dice: 0.2391  decode.d7.loss_cls: 0.3057  decode.d7.loss_mask: 0.2293  decode.d7.loss_dice: 0.2587  decode.d8.loss_cls: 0.2908  decode.d8.loss_mask: 0.2283  decode.d8.loss_dice: 0.2647
07/30 21:09:33 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 21:09:33 - mmengine - INFO - Iter(train) [37000/80000]  base_lr: 5.7193e-05 lr: 5.7193e-06  eta: 5:12:54  time: 0.4406  data_time: 0.0095  memory: 5305  grad_norm: 48.8923  loss: 5.7102  decode.loss_cls: 0.0296  decode.loss_mask: 0.2091  decode.loss_dice: 0.2356  decode.d0.loss_cls: 0.8413  decode.d0.loss_mask: 0.2205  decode.d0.loss_dice: 0.2458  decode.d1.loss_cls: 0.0327  decode.d1.loss_mask: 0.2226  decode.d1.loss_dice: 0.2317  decode.d2.loss_cls: 0.0367  decode.d2.loss_mask: 0.2154  decode.d2.loss_dice: 0.2345  decode.d3.loss_cls: 0.0326  decode.d3.loss_mask: 0.2125  decode.d3.loss_dice: 0.2354  decode.d4.loss_cls: 0.0671  decode.d4.loss_mask: 0.2160  decode.d4.loss_dice: 0.2337  decode.d5.loss_cls: 0.0668  decode.d5.loss_mask: 0.2114  decode.d5.loss_dice: 0.2329  decode.d6.loss_cls: 0.0385  decode.d6.loss_mask: 0.2130  decode.d6.loss_dice: 0.2342  decode.d7.loss_cls: 0.0359  decode.d7.loss_mask: 0.2104  decode.d7.loss_dice: 0.2332  decode.d8.loss_cls: 0.0338  decode.d8.loss_mask: 0.2113  decode.d8.loss_dice: 0.2358
07/30 21:09:55 - mmengine - INFO - Iter(train) [37050/80000]  base_lr: 5.7133e-05 lr: 5.7133e-06  eta: 5:12:33  time: 0.4388  data_time: 0.0098  memory: 5261  grad_norm: 57.9858  loss: 7.9824  decode.loss_cls: 0.0819  decode.loss_mask: 0.3257  decode.loss_dice: 0.2907  decode.d0.loss_cls: 0.8636  decode.d0.loss_mask: 0.3399  decode.d0.loss_dice: 0.2752  decode.d1.loss_cls: 0.1736  decode.d1.loss_mask: 0.3320  decode.d1.loss_dice: 0.2756  decode.d2.loss_cls: 0.1287  decode.d2.loss_mask: 0.3249  decode.d2.loss_dice: 0.2782  decode.d3.loss_cls: 0.1133  decode.d3.loss_mask: 0.3267  decode.d3.loss_dice: 0.2829  decode.d4.loss_cls: 0.0816  decode.d4.loss_mask: 0.3240  decode.d4.loss_dice: 0.2931  decode.d5.loss_cls: 0.0931  decode.d5.loss_mask: 0.3266  decode.d5.loss_dice: 0.2748  decode.d6.loss_cls: 0.1286  decode.d6.loss_mask: 0.3233  decode.d6.loss_dice: 0.2779  decode.d7.loss_cls: 0.0907  decode.d7.loss_mask: 0.3256  decode.d7.loss_dice: 0.2879  decode.d8.loss_cls: 0.1322  decode.d8.loss_mask: 0.3272  decode.d8.loss_dice: 0.2828
07/30 21:10:17 - mmengine - INFO - Iter(train) [37100/80000]  base_lr: 5.7074e-05 lr: 5.7074e-06  eta: 5:12:11  time: 0.4399  data_time: 0.0095  memory: 5246  grad_norm: 106.5304  loss: 8.7452  decode.loss_cls: 0.1943  decode.loss_mask: 0.2606  decode.loss_dice: 0.3128  decode.d0.loss_cls: 1.0490  decode.d0.loss_mask: 0.2576  decode.d0.loss_dice: 0.3449  decode.d1.loss_cls: 0.2883  decode.d1.loss_mask: 0.2492  decode.d1.loss_dice: 0.2970  decode.d2.loss_cls: 0.2431  decode.d2.loss_mask: 0.2408  decode.d2.loss_dice: 0.2976  decode.d3.loss_cls: 0.2048  decode.d3.loss_mask: 0.2387  decode.d3.loss_dice: 0.2876  decode.d4.loss_cls: 0.1674  decode.d4.loss_mask: 0.2387  decode.d4.loss_dice: 0.3127  decode.d5.loss_cls: 0.2202  decode.d5.loss_mask: 0.2434  decode.d5.loss_dice: 0.2981  decode.d6.loss_cls: 0.2892  decode.d6.loss_mask: 0.2667  decode.d6.loss_dice: 0.3378  decode.d7.loss_cls: 0.2327  decode.d7.loss_mask: 0.2654  decode.d7.loss_dice: 0.3119  decode.d8.loss_cls: 0.2447  decode.d8.loss_mask: 0.2546  decode.d8.loss_dice: 0.2952
07/30 21:10:39 - mmengine - INFO - Iter(train) [37150/80000]  base_lr: 5.7014e-05 lr: 5.7014e-06  eta: 5:11:49  time: 0.4413  data_time: 0.0096  memory: 5227  grad_norm: 52.3987  loss: 6.8512  decode.loss_cls: 0.0945  decode.loss_mask: 0.2307  decode.loss_dice: 0.2858  decode.d0.loss_cls: 1.0239  decode.d0.loss_mask: 0.2338  decode.d0.loss_dice: 0.2778  decode.d1.loss_cls: 0.0880  decode.d1.loss_mask: 0.2314  decode.d1.loss_dice: 0.2769  decode.d2.loss_cls: 0.0680  decode.d2.loss_mask: 0.2275  decode.d2.loss_dice: 0.2748  decode.d3.loss_cls: 0.0621  decode.d3.loss_mask: 0.2323  decode.d3.loss_dice: 0.2746  decode.d4.loss_cls: 0.0530  decode.d4.loss_mask: 0.2321  decode.d4.loss_dice: 0.2752  decode.d5.loss_cls: 0.0793  decode.d5.loss_mask: 0.2344  decode.d5.loss_dice: 0.2781  decode.d6.loss_cls: 0.0875  decode.d6.loss_mask: 0.2326  decode.d6.loss_dice: 0.2752  decode.d7.loss_cls: 0.1022  decode.d7.loss_mask: 0.2303  decode.d7.loss_dice: 0.2750  decode.d8.loss_cls: 0.1105  decode.d8.loss_mask: 0.2296  decode.d8.loss_dice: 0.2744
07/30 21:11:01 - mmengine - INFO - Iter(train) [37200/80000]  base_lr: 5.6954e-05 lr: 5.6954e-06  eta: 5:11:28  time: 0.4402  data_time: 0.0096  memory: 5244  grad_norm: 138.5514  loss: 8.6239  decode.loss_cls: 0.2566  decode.loss_mask: 0.2345  decode.loss_dice: 0.3216  decode.d0.loss_cls: 1.0685  decode.d0.loss_mask: 0.2389  decode.d0.loss_dice: 0.2906  decode.d1.loss_cls: 0.3108  decode.d1.loss_mask: 0.2323  decode.d1.loss_dice: 0.2746  decode.d2.loss_cls: 0.2646  decode.d2.loss_mask: 0.2323  decode.d2.loss_dice: 0.2969  decode.d3.loss_cls: 0.2045  decode.d3.loss_mask: 0.2362  decode.d3.loss_dice: 0.3353  decode.d4.loss_cls: 0.2123  decode.d4.loss_mask: 0.2369  decode.d4.loss_dice: 0.3344  decode.d5.loss_cls: 0.2025  decode.d5.loss_mask: 0.2427  decode.d5.loss_dice: 0.3333  decode.d6.loss_cls: 0.1693  decode.d6.loss_mask: 0.2377  decode.d6.loss_dice: 0.3346  decode.d7.loss_cls: 0.2251  decode.d7.loss_mask: 0.2353  decode.d7.loss_dice: 0.2924  decode.d8.loss_cls: 0.2346  decode.d8.loss_mask: 0.2333  decode.d8.loss_dice: 0.3013
07/30 21:11:23 - mmengine - INFO - Iter(train) [37250/80000]  base_lr: 5.6894e-05 lr: 5.6894e-06  eta: 5:11:06  time: 0.4380  data_time: 0.0095  memory: 5261  grad_norm: 41.1251  loss: 5.7414  decode.loss_cls: 0.0274  decode.loss_mask: 0.2364  decode.loss_dice: 0.2284  decode.d0.loss_cls: 0.8821  decode.d0.loss_mask: 0.2481  decode.d0.loss_dice: 0.2201  decode.d1.loss_cls: 0.0175  decode.d1.loss_mask: 0.2395  decode.d1.loss_dice: 0.2307  decode.d2.loss_cls: 0.0161  decode.d2.loss_mask: 0.2378  decode.d2.loss_dice: 0.2286  decode.d3.loss_cls: 0.0253  decode.d3.loss_mask: 0.2322  decode.d3.loss_dice: 0.2233  decode.d4.loss_cls: 0.0215  decode.d4.loss_mask: 0.2334  decode.d4.loss_dice: 0.2297  decode.d5.loss_cls: 0.0291  decode.d5.loss_mask: 0.2321  decode.d5.loss_dice: 0.2256  decode.d6.loss_cls: 0.0330  decode.d6.loss_mask: 0.2353  decode.d6.loss_dice: 0.2270  decode.d7.loss_cls: 0.0301  decode.d7.loss_mask: 0.2367  decode.d7.loss_dice: 0.2286  decode.d8.loss_cls: 0.0262  decode.d8.loss_mask: 0.2338  decode.d8.loss_dice: 0.2258
07/30 21:11:45 - mmengine - INFO - Iter(train) [37300/80000]  base_lr: 5.6834e-05 lr: 5.6834e-06  eta: 5:10:44  time: 0.4389  data_time: 0.0096  memory: 5279  grad_norm: 63.5757  loss: 6.1243  decode.loss_cls: 0.0316  decode.loss_mask: 0.2046  decode.loss_dice: 0.2438  decode.d0.loss_cls: 1.0032  decode.d0.loss_mask: 0.2118  decode.d0.loss_dice: 0.2525  decode.d1.loss_cls: 0.0993  decode.d1.loss_mask: 0.2052  decode.d1.loss_dice: 0.2384  decode.d2.loss_cls: 0.1195  decode.d2.loss_mask: 0.2070  decode.d2.loss_dice: 0.2432  decode.d3.loss_cls: 0.0965  decode.d3.loss_mask: 0.2062  decode.d3.loss_dice: 0.2426  decode.d4.loss_cls: 0.0730  decode.d4.loss_mask: 0.2072  decode.d4.loss_dice: 0.2387  decode.d5.loss_cls: 0.0696  decode.d5.loss_mask: 0.2071  decode.d5.loss_dice: 0.2401  decode.d6.loss_cls: 0.0645  decode.d6.loss_mask: 0.2071  decode.d6.loss_dice: 0.2413  decode.d7.loss_cls: 0.0512  decode.d7.loss_mask: 0.2037  decode.d7.loss_dice: 0.2375  decode.d8.loss_cls: 0.0423  decode.d8.loss_mask: 0.2006  decode.d8.loss_dice: 0.2350
07/30 21:12:07 - mmengine - INFO - Iter(train) [37350/80000]  base_lr: 5.6774e-05 lr: 5.6774e-06  eta: 5:10:22  time: 0.4379  data_time: 0.0094  memory: 5279  grad_norm: 66.2144  loss: 8.4153  decode.loss_cls: 0.1600  decode.loss_mask: 0.2462  decode.loss_dice: 0.3128  decode.d0.loss_cls: 1.2012  decode.d0.loss_mask: 0.2466  decode.d0.loss_dice: 0.3027  decode.d1.loss_cls: 0.1864  decode.d1.loss_mask: 0.2451  decode.d1.loss_dice: 0.2889  decode.d2.loss_cls: 0.2324  decode.d2.loss_mask: 0.2465  decode.d2.loss_dice: 0.3127  decode.d3.loss_cls: 0.2410  decode.d3.loss_mask: 0.2475  decode.d3.loss_dice: 0.3046  decode.d4.loss_cls: 0.1688  decode.d4.loss_mask: 0.2448  decode.d4.loss_dice: 0.3226  decode.d5.loss_cls: 0.1425  decode.d5.loss_mask: 0.2431  decode.d5.loss_dice: 0.3128  decode.d6.loss_cls: 0.1870  decode.d6.loss_mask: 0.2485  decode.d6.loss_dice: 0.3266  decode.d7.loss_cls: 0.1826  decode.d7.loss_mask: 0.2425  decode.d7.loss_dice: 0.3172  decode.d8.loss_cls: 0.1427  decode.d8.loss_mask: 0.2454  decode.d8.loss_dice: 0.3132
07/30 21:12:29 - mmengine - INFO - Iter(train) [37400/80000]  base_lr: 5.6714e-05 lr: 5.6714e-06  eta: 5:10:01  time: 0.4380  data_time: 0.0096  memory: 5265  grad_norm: 46.0806  loss: 7.2523  decode.loss_cls: 0.1829  decode.loss_mask: 0.2129  decode.loss_dice: 0.2558  decode.d0.loss_cls: 0.9806  decode.d0.loss_mask: 0.2200  decode.d0.loss_dice: 0.2752  decode.d1.loss_cls: 0.1856  decode.d1.loss_mask: 0.2177  decode.d1.loss_dice: 0.2642  decode.d2.loss_cls: 0.1697  decode.d2.loss_mask: 0.2155  decode.d2.loss_dice: 0.2588  decode.d3.loss_cls: 0.1540  decode.d3.loss_mask: 0.2169  decode.d3.loss_dice: 0.2440  decode.d4.loss_cls: 0.1534  decode.d4.loss_mask: 0.2139  decode.d4.loss_dice: 0.2587  decode.d5.loss_cls: 0.1566  decode.d5.loss_mask: 0.2161  decode.d5.loss_dice: 0.2567  decode.d6.loss_cls: 0.2032  decode.d6.loss_mask: 0.2141  decode.d6.loss_dice: 0.2580  decode.d7.loss_cls: 0.1750  decode.d7.loss_mask: 0.2160  decode.d7.loss_dice: 0.2506  decode.d8.loss_cls: 0.1591  decode.d8.loss_mask: 0.2134  decode.d8.loss_dice: 0.2538
07/30 21:12:51 - mmengine - INFO - Iter(train) [37450/80000]  base_lr: 5.6654e-05 lr: 5.6654e-06  eta: 5:09:39  time: 0.4386  data_time: 0.0097  memory: 5245  grad_norm: 81.0073  loss: 7.2035  decode.loss_cls: 0.1366  decode.loss_mask: 0.2330  decode.loss_dice: 0.2752  decode.d0.loss_cls: 0.8955  decode.d0.loss_mask: 0.2367  decode.d0.loss_dice: 0.2803  decode.d1.loss_cls: 0.1455  decode.d1.loss_mask: 0.2341  decode.d1.loss_dice: 0.2685  decode.d2.loss_cls: 0.1456  decode.d2.loss_mask: 0.2320  decode.d2.loss_dice: 0.2692  decode.d3.loss_cls: 0.1080  decode.d3.loss_mask: 0.2325  decode.d3.loss_dice: 0.2770  decode.d4.loss_cls: 0.1402  decode.d4.loss_mask: 0.2310  decode.d4.loss_dice: 0.2709  decode.d5.loss_cls: 0.1644  decode.d5.loss_mask: 0.2355  decode.d5.loss_dice: 0.2712  decode.d6.loss_cls: 0.1300  decode.d6.loss_mask: 0.2354  decode.d6.loss_dice: 0.2676  decode.d7.loss_cls: 0.1277  decode.d7.loss_mask: 0.2367  decode.d7.loss_dice: 0.2934  decode.d8.loss_cls: 0.1320  decode.d8.loss_mask: 0.2339  decode.d8.loss_dice: 0.2639
07/30 21:13:13 - mmengine - INFO - Iter(train) [37500/80000]  base_lr: 5.6594e-05 lr: 5.6594e-06  eta: 5:09:17  time: 0.4389  data_time: 0.0097  memory: 5278  grad_norm: 51.7964  loss: 7.0989  decode.loss_cls: 0.1060  decode.loss_mask: 0.2691  decode.loss_dice: 0.2510  decode.d0.loss_cls: 0.8880  decode.d0.loss_mask: 0.2799  decode.d0.loss_dice: 0.2587  decode.d1.loss_cls: 0.0628  decode.d1.loss_mask: 0.2701  decode.d1.loss_dice: 0.2505  decode.d2.loss_cls: 0.0874  decode.d2.loss_mask: 0.2685  decode.d2.loss_dice: 0.2678  decode.d3.loss_cls: 0.1071  decode.d3.loss_mask: 0.2695  decode.d3.loss_dice: 0.2821  decode.d4.loss_cls: 0.1311  decode.d4.loss_mask: 0.2698  decode.d4.loss_dice: 0.2491  decode.d5.loss_cls: 0.1064  decode.d5.loss_mask: 0.2708  decode.d5.loss_dice: 0.2514  decode.d6.loss_cls: 0.1013  decode.d6.loss_mask: 0.2709  decode.d6.loss_dice: 0.2538  decode.d7.loss_cls: 0.1039  decode.d7.loss_mask: 0.2719  decode.d7.loss_dice: 0.2551  decode.d8.loss_cls: 0.1156  decode.d8.loss_mask: 0.2720  decode.d8.loss_dice: 0.2575
07/30 21:13:35 - mmengine - INFO - Iter(train) [37550/80000]  base_lr: 5.6535e-05 lr: 5.6535e-06  eta: 5:08:56  time: 0.4389  data_time: 0.0095  memory: 5246  grad_norm: 68.1965  loss: 6.0733  decode.loss_cls: 0.1334  decode.loss_mask: 0.1986  decode.loss_dice: 0.2066  decode.d0.loss_cls: 0.8585  decode.d0.loss_mask: 0.1971  decode.d0.loss_dice: 0.2684  decode.d1.loss_cls: 0.1581  decode.d1.loss_mask: 0.1963  decode.d1.loss_dice: 0.2111  decode.d2.loss_cls: 0.1032  decode.d2.loss_mask: 0.1949  decode.d2.loss_dice: 0.2404  decode.d3.loss_cls: 0.1002  decode.d3.loss_mask: 0.1978  decode.d3.loss_dice: 0.2237  decode.d4.loss_cls: 0.1015  decode.d4.loss_mask: 0.1945  decode.d4.loss_dice: 0.2226  decode.d5.loss_cls: 0.0904  decode.d5.loss_mask: 0.1936  decode.d5.loss_dice: 0.2172  decode.d6.loss_cls: 0.0911  decode.d6.loss_mask: 0.1974  decode.d6.loss_dice: 0.2450  decode.d7.loss_cls: 0.1095  decode.d7.loss_mask: 0.1986  decode.d7.loss_dice: 0.2035  decode.d8.loss_cls: 0.1093  decode.d8.loss_mask: 0.1967  decode.d8.loss_dice: 0.2140
07/30 21:13:57 - mmengine - INFO - Iter(train) [37600/80000]  base_lr: 5.6475e-05 lr: 5.6475e-06  eta: 5:08:34  time: 0.4374  data_time: 0.0096  memory: 5277  grad_norm: 81.7464  loss: 7.3159  decode.loss_cls: 0.0896  decode.loss_mask: 0.2496  decode.loss_dice: 0.2986  decode.d0.loss_cls: 0.8893  decode.d0.loss_mask: 0.2269  decode.d0.loss_dice: 0.2698  decode.d1.loss_cls: 0.2197  decode.d1.loss_mask: 0.2289  decode.d1.loss_dice: 0.2767  decode.d2.loss_cls: 0.2011  decode.d2.loss_mask: 0.2350  decode.d2.loss_dice: 0.2467  decode.d3.loss_cls: 0.1917  decode.d3.loss_mask: 0.2323  decode.d3.loss_dice: 0.2694  decode.d4.loss_cls: 0.1084  decode.d4.loss_mask: 0.2499  decode.d4.loss_dice: 0.2938  decode.d5.loss_cls: 0.0887  decode.d5.loss_mask: 0.2420  decode.d5.loss_dice: 0.2883  decode.d6.loss_cls: 0.1219  decode.d6.loss_mask: 0.2516  decode.d6.loss_dice: 0.2927  decode.d7.loss_cls: 0.1065  decode.d7.loss_mask: 0.2502  decode.d7.loss_dice: 0.2966  decode.d8.loss_cls: 0.0720  decode.d8.loss_mask: 0.2462  decode.d8.loss_dice: 0.2819
07/30 21:14:18 - mmengine - INFO - Iter(train) [37650/80000]  base_lr: 5.6415e-05 lr: 5.6415e-06  eta: 5:08:12  time: 0.4382  data_time: 0.0096  memory: 5245  grad_norm: 58.3789  loss: 6.7628  decode.loss_cls: 0.0832  decode.loss_mask: 0.2337  decode.loss_dice: 0.2629  decode.d0.loss_cls: 0.9173  decode.d0.loss_mask: 0.2387  decode.d0.loss_dice: 0.2549  decode.d1.loss_cls: 0.1712  decode.d1.loss_mask: 0.2338  decode.d1.loss_dice: 0.2550  decode.d2.loss_cls: 0.0975  decode.d2.loss_mask: 0.2340  decode.d2.loss_dice: 0.2573  decode.d3.loss_cls: 0.1080  decode.d3.loss_mask: 0.2344  decode.d3.loss_dice: 0.2533  decode.d4.loss_cls: 0.1061  decode.d4.loss_mask: 0.2321  decode.d4.loss_dice: 0.2450  decode.d5.loss_cls: 0.0696  decode.d5.loss_mask: 0.2359  decode.d5.loss_dice: 0.2495  decode.d6.loss_cls: 0.0848  decode.d6.loss_mask: 0.2371  decode.d6.loss_dice: 0.2544  decode.d7.loss_cls: 0.1463  decode.d7.loss_mask: 0.2338  decode.d7.loss_dice: 0.2483  decode.d8.loss_cls: 0.1016  decode.d8.loss_mask: 0.2329  decode.d8.loss_dice: 0.2500
07/30 21:14:40 - mmengine - INFO - Iter(train) [37700/80000]  base_lr: 5.6355e-05 lr: 5.6355e-06  eta: 5:07:50  time: 0.4379  data_time: 0.0097  memory: 5244  grad_norm: 89.9306  loss: 9.7834  decode.loss_cls: 0.3190  decode.loss_mask: 0.3003  decode.loss_dice: 0.3301  decode.d0.loss_cls: 0.9577  decode.d0.loss_mask: 0.3160  decode.d0.loss_dice: 0.3300  decode.d1.loss_cls: 0.2183  decode.d1.loss_mask: 0.2970  decode.d1.loss_dice: 0.3319  decode.d2.loss_cls: 0.2484  decode.d2.loss_mask: 0.3024  decode.d2.loss_dice: 0.3337  decode.d3.loss_cls: 0.2318  decode.d3.loss_mask: 0.3046  decode.d3.loss_dice: 0.3260  decode.d4.loss_cls: 0.2913  decode.d4.loss_mask: 0.3015  decode.d4.loss_dice: 0.3339  decode.d5.loss_cls: 0.3202  decode.d5.loss_mask: 0.3096  decode.d5.loss_dice: 0.3328  decode.d6.loss_cls: 0.2941  decode.d6.loss_mask: 0.3020  decode.d6.loss_dice: 0.3294  decode.d7.loss_cls: 0.2848  decode.d7.loss_mask: 0.3082  decode.d7.loss_dice: 0.3271  decode.d8.loss_cls: 0.2777  decode.d8.loss_mask: 0.3030  decode.d8.loss_dice: 0.3203
07/30 21:15:02 - mmengine - INFO - Iter(train) [37750/80000]  base_lr: 5.6295e-05 lr: 5.6295e-06  eta: 5:07:29  time: 0.4378  data_time: 0.0097  memory: 5277  grad_norm: 50.7006  loss: 8.1981  decode.loss_cls: 0.1532  decode.loss_mask: 0.2909  decode.loss_dice: 0.2940  decode.d0.loss_cls: 0.9548  decode.d0.loss_mask: 0.3043  decode.d0.loss_dice: 0.3497  decode.d1.loss_cls: 0.1274  decode.d1.loss_mask: 0.2997  decode.d1.loss_dice: 0.3138  decode.d2.loss_cls: 0.1174  decode.d2.loss_mask: 0.2979  decode.d2.loss_dice: 0.3178  decode.d3.loss_cls: 0.1122  decode.d3.loss_mask: 0.2965  decode.d3.loss_dice: 0.3105  decode.d4.loss_cls: 0.1343  decode.d4.loss_mask: 0.2955  decode.d4.loss_dice: 0.3037  decode.d5.loss_cls: 0.1214  decode.d5.loss_mask: 0.2960  decode.d5.loss_dice: 0.2958  decode.d6.loss_cls: 0.1289  decode.d6.loss_mask: 0.3006  decode.d6.loss_dice: 0.3156  decode.d7.loss_cls: 0.1246  decode.d7.loss_mask: 0.2926  decode.d7.loss_dice: 0.3079  decode.d8.loss_cls: 0.1519  decode.d8.loss_mask: 0.2927  decode.d8.loss_dice: 0.2965
07/30 21:15:24 - mmengine - INFO - Iter(train) [37800/80000]  base_lr: 5.6235e-05 lr: 5.6235e-06  eta: 5:07:07  time: 0.4372  data_time: 0.0098  memory: 5279  grad_norm: 99.7030  loss: 6.9580  decode.loss_cls: 0.0595  decode.loss_mask: 0.2609  decode.loss_dice: 0.2699  decode.d0.loss_cls: 1.0020  decode.d0.loss_mask: 0.2672  decode.d0.loss_dice: 0.2778  decode.d1.loss_cls: 0.1074  decode.d1.loss_mask: 0.2689  decode.d1.loss_dice: 0.2882  decode.d2.loss_cls: 0.0589  decode.d2.loss_mask: 0.2658  decode.d2.loss_dice: 0.2836  decode.d3.loss_cls: 0.0676  decode.d3.loss_mask: 0.2622  decode.d3.loss_dice: 0.2728  decode.d4.loss_cls: 0.0478  decode.d4.loss_mask: 0.2591  decode.d4.loss_dice: 0.2802  decode.d5.loss_cls: 0.0491  decode.d5.loss_mask: 0.2620  decode.d5.loss_dice: 0.2784  decode.d6.loss_cls: 0.0614  decode.d6.loss_mask: 0.2593  decode.d6.loss_dice: 0.2740  decode.d7.loss_cls: 0.0520  decode.d7.loss_mask: 0.2592  decode.d7.loss_dice: 0.2750  decode.d8.loss_cls: 0.0514  decode.d8.loss_mask: 0.2598  decode.d8.loss_dice: 0.2764
07/30 21:15:46 - mmengine - INFO - Iter(train) [37850/80000]  base_lr: 5.6175e-05 lr: 5.6175e-06  eta: 5:06:45  time: 0.4382  data_time: 0.0097  memory: 5244  grad_norm: 105.8154  loss: 7.8150  decode.loss_cls: 0.1878  decode.loss_mask: 0.2232  decode.loss_dice: 0.3010  decode.d0.loss_cls: 0.9363  decode.d0.loss_mask: 0.2349  decode.d0.loss_dice: 0.3262  decode.d1.loss_cls: 0.1971  decode.d1.loss_mask: 0.2221  decode.d1.loss_dice: 0.2982  decode.d2.loss_cls: 0.1695  decode.d2.loss_mask: 0.2274  decode.d2.loss_dice: 0.3228  decode.d3.loss_cls: 0.1670  decode.d3.loss_mask: 0.2252  decode.d3.loss_dice: 0.3020  decode.d4.loss_cls: 0.2215  decode.d4.loss_mask: 0.2228  decode.d4.loss_dice: 0.2754  decode.d5.loss_cls: 0.2034  decode.d5.loss_mask: 0.2307  decode.d5.loss_dice: 0.2796  decode.d6.loss_cls: 0.1639  decode.d6.loss_mask: 0.2253  decode.d6.loss_dice: 0.2960  decode.d7.loss_cls: 0.1809  decode.d7.loss_mask: 0.2237  decode.d7.loss_dice: 0.2636  decode.d8.loss_cls: 0.1623  decode.d8.loss_mask: 0.2290  decode.d8.loss_dice: 0.2962
07/30 21:16:08 - mmengine - INFO - Iter(train) [37900/80000]  base_lr: 5.6115e-05 lr: 5.6115e-06  eta: 5:06:23  time: 0.4395  data_time: 0.0096  memory: 5278  grad_norm: 25.7971  loss: 5.9546  decode.loss_cls: 0.1041  decode.loss_mask: 0.1829  decode.loss_dice: 0.2499  decode.d0.loss_cls: 0.8665  decode.d0.loss_mask: 0.1880  decode.d0.loss_dice: 0.2965  decode.d1.loss_cls: 0.0669  decode.d1.loss_mask: 0.1814  decode.d1.loss_dice: 0.2533  decode.d2.loss_cls: 0.0632  decode.d2.loss_mask: 0.1779  decode.d2.loss_dice: 0.2513  decode.d3.loss_cls: 0.1042  decode.d3.loss_mask: 0.1773  decode.d3.loss_dice: 0.2380  decode.d4.loss_cls: 0.0681  decode.d4.loss_mask: 0.1777  decode.d4.loss_dice: 0.2632  decode.d5.loss_cls: 0.0683  decode.d5.loss_mask: 0.1808  decode.d5.loss_dice: 0.2536  decode.d6.loss_cls: 0.0858  decode.d6.loss_mask: 0.1820  decode.d6.loss_dice: 0.2554  decode.d7.loss_cls: 0.0783  decode.d7.loss_mask: 0.1807  decode.d7.loss_dice: 0.2615  decode.d8.loss_cls: 0.0627  decode.d8.loss_mask: 0.1786  decode.d8.loss_dice: 0.2566
07/30 21:16:30 - mmengine - INFO - Iter(train) [37950/80000]  base_lr: 5.6055e-05 lr: 5.6055e-06  eta: 5:06:02  time: 0.4389  data_time: 0.0097  memory: 5265  grad_norm: 70.5768  loss: 9.0173  decode.loss_cls: 0.2421  decode.loss_mask: 0.3089  decode.loss_dice: 0.2924  decode.d0.loss_cls: 0.9532  decode.d0.loss_mask: 0.3195  decode.d0.loss_dice: 0.3116  decode.d1.loss_cls: 0.2558  decode.d1.loss_mask: 0.2852  decode.d1.loss_dice: 0.2824  decode.d2.loss_cls: 0.2387  decode.d2.loss_mask: 0.2885  decode.d2.loss_dice: 0.2707  decode.d3.loss_cls: 0.2361  decode.d3.loss_mask: 0.2827  decode.d3.loss_dice: 0.2688  decode.d4.loss_cls: 0.2918  decode.d4.loss_mask: 0.2785  decode.d4.loss_dice: 0.2655  decode.d5.loss_cls: 0.2714  decode.d5.loss_mask: 0.2833  decode.d5.loss_dice: 0.2709  decode.d6.loss_cls: 0.2619  decode.d6.loss_mask: 0.2891  decode.d6.loss_dice: 0.2934  decode.d7.loss_cls: 0.2697  decode.d7.loss_mask: 0.2793  decode.d7.loss_dice: 0.2981  decode.d8.loss_cls: 0.2681  decode.d8.loss_mask: 0.2790  decode.d8.loss_dice: 0.2807
07/30 21:16:52 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 21:16:52 - mmengine - INFO - Iter(train) [38000/80000]  base_lr: 5.5995e-05 lr: 5.5995e-06  eta: 5:05:40  time: 0.4396  data_time: 0.0096  memory: 5265  grad_norm: 76.8274  loss: 7.1030  decode.loss_cls: 0.1629  decode.loss_mask: 0.2153  decode.loss_dice: 0.2527  decode.d0.loss_cls: 1.0779  decode.d0.loss_mask: 0.2257  decode.d0.loss_dice: 0.2648  decode.d1.loss_cls: 0.1453  decode.d1.loss_mask: 0.2162  decode.d1.loss_dice: 0.2590  decode.d2.loss_cls: 0.1297  decode.d2.loss_mask: 0.2175  decode.d2.loss_dice: 0.2562  decode.d3.loss_cls: 0.1197  decode.d3.loss_mask: 0.2157  decode.d3.loss_dice: 0.2591  decode.d4.loss_cls: 0.1254  decode.d4.loss_mask: 0.2176  decode.d4.loss_dice: 0.2563  decode.d5.loss_cls: 0.1414  decode.d5.loss_mask: 0.2142  decode.d5.loss_dice: 0.2574  decode.d6.loss_cls: 0.1546  decode.d6.loss_mask: 0.2152  decode.d6.loss_dice: 0.2541  decode.d7.loss_cls: 0.1231  decode.d7.loss_mask: 0.2127  decode.d7.loss_dice: 0.2636  decode.d8.loss_cls: 0.1726  decode.d8.loss_mask: 0.2160  decode.d8.loss_dice: 0.2611
07/30 21:17:14 - mmengine - INFO - Iter(train) [38050/80000]  base_lr: 5.5935e-05 lr: 5.5935e-06  eta: 5:05:18  time: 0.4378  data_time: 0.0095  memory: 5265  grad_norm: 65.8608  loss: 7.2656  decode.loss_cls: 0.1970  decode.loss_mask: 0.2356  decode.loss_dice: 0.2245  decode.d0.loss_cls: 0.8765  decode.d0.loss_mask: 0.2399  decode.d0.loss_dice: 0.2664  decode.d1.loss_cls: 0.1851  decode.d1.loss_mask: 0.2381  decode.d1.loss_dice: 0.2427  decode.d2.loss_cls: 0.1555  decode.d2.loss_mask: 0.2391  decode.d2.loss_dice: 0.2451  decode.d3.loss_cls: 0.1846  decode.d3.loss_mask: 0.2362  decode.d3.loss_dice: 0.2415  decode.d4.loss_cls: 0.1643  decode.d4.loss_mask: 0.2352  decode.d4.loss_dice: 0.2366  decode.d5.loss_cls: 0.1965  decode.d5.loss_mask: 0.2330  decode.d5.loss_dice: 0.2286  decode.d6.loss_cls: 0.1735  decode.d6.loss_mask: 0.2335  decode.d6.loss_dice: 0.2473  decode.d7.loss_cls: 0.1912  decode.d7.loss_mask: 0.2339  decode.d7.loss_dice: 0.2513  decode.d8.loss_cls: 0.1605  decode.d8.loss_mask: 0.2362  decode.d8.loss_dice: 0.2364
07/30 21:17:36 - mmengine - INFO - Iter(train) [38100/80000]  base_lr: 5.5875e-05 lr: 5.5875e-06  eta: 5:04:56  time: 0.4374  data_time: 0.0094  memory: 5261  grad_norm: 69.5748  loss: 7.6840  decode.loss_cls: 0.1830  decode.loss_mask: 0.2183  decode.loss_dice: 0.2707  decode.d0.loss_cls: 0.9406  decode.d0.loss_mask: 0.2223  decode.d0.loss_dice: 0.2779  decode.d1.loss_cls: 0.2417  decode.d1.loss_mask: 0.2194  decode.d1.loss_dice: 0.2728  decode.d2.loss_cls: 0.2449  decode.d2.loss_mask: 0.2182  decode.d2.loss_dice: 0.2703  decode.d3.loss_cls: 0.1974  decode.d3.loss_mask: 0.2170  decode.d3.loss_dice: 0.2732  decode.d4.loss_cls: 0.2030  decode.d4.loss_mask: 0.2171  decode.d4.loss_dice: 0.2703  decode.d5.loss_cls: 0.2085  decode.d5.loss_mask: 0.2159  decode.d5.loss_dice: 0.2759  decode.d6.loss_cls: 0.1796  decode.d6.loss_mask: 0.2174  decode.d6.loss_dice: 0.2609  decode.d7.loss_cls: 0.2080  decode.d7.loss_mask: 0.2146  decode.d7.loss_dice: 0.2693  decode.d8.loss_cls: 0.1932  decode.d8.loss_mask: 0.2166  decode.d8.loss_dice: 0.2659
07/30 21:17:58 - mmengine - INFO - Iter(train) [38150/80000]  base_lr: 5.5815e-05 lr: 5.5815e-06  eta: 5:04:35  time: 0.4378  data_time: 0.0097  memory: 5244  grad_norm: 130.7627  loss: 7.4014  decode.loss_cls: 0.1776  decode.loss_mask: 0.2401  decode.loss_dice: 0.2330  decode.d0.loss_cls: 0.9467  decode.d0.loss_mask: 0.2440  decode.d0.loss_dice: 0.2535  decode.d1.loss_cls: 0.2174  decode.d1.loss_mask: 0.2406  decode.d1.loss_dice: 0.2442  decode.d2.loss_cls: 0.1869  decode.d2.loss_mask: 0.2417  decode.d2.loss_dice: 0.2345  decode.d3.loss_cls: 0.2122  decode.d3.loss_mask: 0.2397  decode.d3.loss_dice: 0.2394  decode.d4.loss_cls: 0.1738  decode.d4.loss_mask: 0.2393  decode.d4.loss_dice: 0.2383  decode.d5.loss_cls: 0.1552  decode.d5.loss_mask: 0.2416  decode.d5.loss_dice: 0.2444  decode.d6.loss_cls: 0.1473  decode.d6.loss_mask: 0.2380  decode.d6.loss_dice: 0.2448  decode.d7.loss_cls: 0.1805  decode.d7.loss_mask: 0.2401  decode.d7.loss_dice: 0.2414  decode.d8.loss_cls: 0.1756  decode.d8.loss_mask: 0.2392  decode.d8.loss_dice: 0.2503
07/30 21:18:20 - mmengine - INFO - Iter(train) [38200/80000]  base_lr: 5.5755e-05 lr: 5.5755e-06  eta: 5:04:13  time: 0.4396  data_time: 0.0096  memory: 5278  grad_norm: 33.7617  loss: 6.7851  decode.loss_cls: 0.0672  decode.loss_mask: 0.2367  decode.loss_dice: 0.2663  decode.d0.loss_cls: 1.0613  decode.d0.loss_mask: 0.2346  decode.d0.loss_dice: 0.2558  decode.d1.loss_cls: 0.0587  decode.d1.loss_mask: 0.2364  decode.d1.loss_dice: 0.2635  decode.d2.loss_cls: 0.0755  decode.d2.loss_mask: 0.2365  decode.d2.loss_dice: 0.2593  decode.d3.loss_cls: 0.0765  decode.d3.loss_mask: 0.2378  decode.d3.loss_dice: 0.2542  decode.d4.loss_cls: 0.1176  decode.d4.loss_mask: 0.2371  decode.d4.loss_dice: 0.2572  decode.d5.loss_cls: 0.0665  decode.d5.loss_mask: 0.2337  decode.d5.loss_dice: 0.2641  decode.d6.loss_cls: 0.1107  decode.d6.loss_mask: 0.2347  decode.d6.loss_dice: 0.2573  decode.d7.loss_cls: 0.1140  decode.d7.loss_mask: 0.2372  decode.d7.loss_dice: 0.2540  decode.d8.loss_cls: 0.0962  decode.d8.loss_mask: 0.2331  decode.d8.loss_dice: 0.2516
07/30 21:18:42 - mmengine - INFO - Iter(train) [38250/80000]  base_lr: 5.5695e-05 lr: 5.5695e-06  eta: 5:03:51  time: 0.4387  data_time: 0.0095  memory: 5261  grad_norm: 38.5105  loss: 5.7082  decode.loss_cls: 0.0356  decode.loss_mask: 0.2023  decode.loss_dice: 0.2181  decode.d0.loss_cls: 0.9594  decode.d0.loss_mask: 0.2084  decode.d0.loss_dice: 0.2360  decode.d1.loss_cls: 0.0952  decode.d1.loss_mask: 0.2047  decode.d1.loss_dice: 0.2308  decode.d2.loss_cls: 0.0593  decode.d2.loss_mask: 0.2056  decode.d2.loss_dice: 0.2261  decode.d3.loss_cls: 0.0525  decode.d3.loss_mask: 0.2039  decode.d3.loss_dice: 0.2355  decode.d4.loss_cls: 0.0534  decode.d4.loss_mask: 0.2042  decode.d4.loss_dice: 0.2294  decode.d5.loss_cls: 0.0464  decode.d5.loss_mask: 0.2000  decode.d5.loss_dice: 0.2386  decode.d6.loss_cls: 0.0262  decode.d6.loss_mask: 0.2020  decode.d6.loss_dice: 0.2256  decode.d7.loss_cls: 0.0243  decode.d7.loss_mask: 0.2020  decode.d7.loss_dice: 0.2260  decode.d8.loss_cls: 0.0303  decode.d8.loss_mask: 0.2016  decode.d8.loss_dice: 0.2247
07/30 21:19:04 - mmengine - INFO - Iter(train) [38300/80000]  base_lr: 5.5635e-05 lr: 5.5635e-06  eta: 5:03:30  time: 0.4392  data_time: 0.0095  memory: 5277  grad_norm: 40.5518  loss: 6.1086  decode.loss_cls: 0.1275  decode.loss_mask: 0.1782  decode.loss_dice: 0.2312  decode.d0.loss_cls: 0.9542  decode.d0.loss_mask: 0.1749  decode.d0.loss_dice: 0.2659  decode.d1.loss_cls: 0.1275  decode.d1.loss_mask: 0.1745  decode.d1.loss_dice: 0.2493  decode.d2.loss_cls: 0.1202  decode.d2.loss_mask: 0.1758  decode.d2.loss_dice: 0.2338  decode.d3.loss_cls: 0.1018  decode.d3.loss_mask: 0.1740  decode.d3.loss_dice: 0.2519  decode.d4.loss_cls: 0.1254  decode.d4.loss_mask: 0.1745  decode.d4.loss_dice: 0.2407  decode.d5.loss_cls: 0.0935  decode.d5.loss_mask: 0.1733  decode.d5.loss_dice: 0.2272  decode.d6.loss_cls: 0.0836  decode.d6.loss_mask: 0.1740  decode.d6.loss_dice: 0.2523  decode.d7.loss_cls: 0.0890  decode.d7.loss_mask: 0.1771  decode.d7.loss_dice: 0.2323  decode.d8.loss_cls: 0.0821  decode.d8.loss_mask: 0.1758  decode.d8.loss_dice: 0.2673
07/30 21:19:26 - mmengine - INFO - Iter(train) [38350/80000]  base_lr: 5.5575e-05 lr: 5.5575e-06  eta: 5:03:08  time: 0.4403  data_time: 0.0098  memory: 5337  grad_norm: 85.3019  loss: 7.0291  decode.loss_cls: 0.1287  decode.loss_mask: 0.2176  decode.loss_dice: 0.2548  decode.d0.loss_cls: 0.9214  decode.d0.loss_mask: 0.2089  decode.d0.loss_dice: 0.2747  decode.d1.loss_cls: 0.2523  decode.d1.loss_mask: 0.1992  decode.d1.loss_dice: 0.2566  decode.d2.loss_cls: 0.1705  decode.d2.loss_mask: 0.2032  decode.d2.loss_dice: 0.2614  decode.d3.loss_cls: 0.1353  decode.d3.loss_mask: 0.2138  decode.d3.loss_dice: 0.2753  decode.d4.loss_cls: 0.1301  decode.d4.loss_mask: 0.2235  decode.d4.loss_dice: 0.2881  decode.d5.loss_cls: 0.1399  decode.d5.loss_mask: 0.2021  decode.d5.loss_dice: 0.2664  decode.d6.loss_cls: 0.1513  decode.d6.loss_mask: 0.1959  decode.d6.loss_dice: 0.2490  decode.d7.loss_cls: 0.1402  decode.d7.loss_mask: 0.1987  decode.d7.loss_dice: 0.2446  decode.d8.loss_cls: 0.1425  decode.d8.loss_mask: 0.2162  decode.d8.loss_dice: 0.2668
07/30 21:19:47 - mmengine - INFO - Iter(train) [38400/80000]  base_lr: 5.5515e-05 lr: 5.5515e-06  eta: 5:02:46  time: 0.4378  data_time: 0.0095  memory: 5244  grad_norm: 117.0118  loss: 7.4157  decode.loss_cls: 0.1843  decode.loss_mask: 0.2392  decode.loss_dice: 0.3125  decode.d0.loss_cls: 0.9820  decode.d0.loss_mask: 0.2465  decode.d0.loss_dice: 0.2857  decode.d1.loss_cls: 0.1189  decode.d1.loss_mask: 0.2418  decode.d1.loss_dice: 0.3174  decode.d2.loss_cls: 0.0737  decode.d2.loss_mask: 0.2384  decode.d2.loss_dice: 0.3225  decode.d3.loss_cls: 0.0974  decode.d3.loss_mask: 0.2402  decode.d3.loss_dice: 0.3015  decode.d4.loss_cls: 0.0721  decode.d4.loss_mask: 0.2375  decode.d4.loss_dice: 0.2997  decode.d5.loss_cls: 0.0761  decode.d5.loss_mask: 0.2404  decode.d5.loss_dice: 0.3193  decode.d6.loss_cls: 0.1223  decode.d6.loss_mask: 0.2405  decode.d6.loss_dice: 0.3240  decode.d7.loss_cls: 0.0973  decode.d7.loss_mask: 0.2404  decode.d7.loss_dice: 0.3217  decode.d8.loss_cls: 0.1201  decode.d8.loss_mask: 0.2374  decode.d8.loss_dice: 0.2651
07/30 21:20:10 - mmengine - INFO - Iter(train) [38450/80000]  base_lr: 5.5455e-05 lr: 5.5455e-06  eta: 5:02:24  time: 0.4563  data_time: 0.0095  memory: 5244  grad_norm: 63.8398  loss: 6.5047  decode.loss_cls: 0.1450  decode.loss_mask: 0.1755  decode.loss_dice: 0.2377  decode.d0.loss_cls: 1.0068  decode.d0.loss_mask: 0.1883  decode.d0.loss_dice: 0.2533  decode.d1.loss_cls: 0.1594  decode.d1.loss_mask: 0.1875  decode.d1.loss_dice: 0.2466  decode.d2.loss_cls: 0.1583  decode.d2.loss_mask: 0.1762  decode.d2.loss_dice: 0.2330  decode.d3.loss_cls: 0.1456  decode.d3.loss_mask: 0.1780  decode.d3.loss_dice: 0.2422  decode.d4.loss_cls: 0.1502  decode.d4.loss_mask: 0.1763  decode.d4.loss_dice: 0.2456  decode.d5.loss_cls: 0.0830  decode.d5.loss_mask: 0.1815  decode.d5.loss_dice: 0.2464  decode.d6.loss_cls: 0.1468  decode.d6.loss_mask: 0.1783  decode.d6.loss_dice: 0.2399  decode.d7.loss_cls: 0.1516  decode.d7.loss_mask: 0.1768  decode.d7.loss_dice: 0.2330  decode.d8.loss_cls: 0.1527  decode.d8.loss_mask: 0.1771  decode.d8.loss_dice: 0.2325
07/30 21:20:31 - mmengine - INFO - Iter(train) [38500/80000]  base_lr: 5.5395e-05 lr: 5.5395e-06  eta: 5:02:03  time: 0.4384  data_time: 0.0095  memory: 5265  grad_norm: 67.8083  loss: 6.4384  decode.loss_cls: 0.0755  decode.loss_mask: 0.2328  decode.loss_dice: 0.2620  decode.d0.loss_cls: 0.9031  decode.d0.loss_mask: 0.2437  decode.d0.loss_dice: 0.2712  decode.d1.loss_cls: 0.0644  decode.d1.loss_mask: 0.2376  decode.d1.loss_dice: 0.2741  decode.d2.loss_cls: 0.0753  decode.d2.loss_mask: 0.2348  decode.d2.loss_dice: 0.2594  decode.d3.loss_cls: 0.0632  decode.d3.loss_mask: 0.2331  decode.d3.loss_dice: 0.2570  decode.d4.loss_cls: 0.0688  decode.d4.loss_mask: 0.2320  decode.d4.loss_dice: 0.2537  decode.d5.loss_cls: 0.0700  decode.d5.loss_mask: 0.2313  decode.d5.loss_dice: 0.2546  decode.d6.loss_cls: 0.0599  decode.d6.loss_mask: 0.2311  decode.d6.loss_dice: 0.2464  decode.d7.loss_cls: 0.0634  decode.d7.loss_mask: 0.2319  decode.d7.loss_dice: 0.2553  decode.d8.loss_cls: 0.0647  decode.d8.loss_mask: 0.2317  decode.d8.loss_dice: 0.2567
07/30 21:20:53 - mmengine - INFO - Iter(train) [38550/80000]  base_lr: 5.5334e-05 lr: 5.5334e-06  eta: 5:01:41  time: 0.4378  data_time: 0.0096  memory: 5261  grad_norm: 46.9135  loss: 7.1099  decode.loss_cls: 0.1597  decode.loss_mask: 0.2430  decode.loss_dice: 0.2594  decode.d0.loss_cls: 0.8492  decode.d0.loss_mask: 0.2500  decode.d0.loss_dice: 0.2729  decode.d1.loss_cls: 0.2002  decode.d1.loss_mask: 0.2410  decode.d1.loss_dice: 0.2658  decode.d2.loss_cls: 0.1481  decode.d2.loss_mask: 0.2433  decode.d2.loss_dice: 0.2717  decode.d3.loss_cls: 0.1108  decode.d3.loss_mask: 0.2440  decode.d3.loss_dice: 0.2704  decode.d4.loss_cls: 0.1131  decode.d4.loss_mask: 0.2443  decode.d4.loss_dice: 0.2703  decode.d5.loss_cls: 0.1077  decode.d5.loss_mask: 0.2421  decode.d5.loss_dice: 0.2802  decode.d6.loss_cls: 0.1148  decode.d6.loss_mask: 0.2436  decode.d6.loss_dice: 0.2483  decode.d7.loss_cls: 0.1163  decode.d7.loss_mask: 0.2435  decode.d7.loss_dice: 0.2458  decode.d8.loss_cls: 0.1178  decode.d8.loss_mask: 0.2412  decode.d8.loss_dice: 0.2514
07/30 21:21:15 - mmengine - INFO - Iter(train) [38600/80000]  base_lr: 5.5274e-05 lr: 5.5274e-06  eta: 5:01:19  time: 0.4387  data_time: 0.0096  memory: 5305  grad_norm: 65.9498  loss: 6.6313  decode.loss_cls: 0.0863  decode.loss_mask: 0.2099  decode.loss_dice: 0.2712  decode.d0.loss_cls: 0.8911  decode.d0.loss_mask: 0.2178  decode.d0.loss_dice: 0.2985  decode.d1.loss_cls: 0.1086  decode.d1.loss_mask: 0.2109  decode.d1.loss_dice: 0.2828  decode.d2.loss_cls: 0.0799  decode.d2.loss_mask: 0.2130  decode.d2.loss_dice: 0.2738  decode.d3.loss_cls: 0.0857  decode.d3.loss_mask: 0.2122  decode.d3.loss_dice: 0.2681  decode.d4.loss_cls: 0.0955  decode.d4.loss_mask: 0.2106  decode.d4.loss_dice: 0.2706  decode.d5.loss_cls: 0.0919  decode.d5.loss_mask: 0.2121  decode.d5.loss_dice: 0.2820  decode.d6.loss_cls: 0.1151  decode.d6.loss_mask: 0.2098  decode.d6.loss_dice: 0.2758  decode.d7.loss_cls: 0.0983  decode.d7.loss_mask: 0.2119  decode.d7.loss_dice: 0.2775  decode.d8.loss_cls: 0.0940  decode.d8.loss_mask: 0.2069  decode.d8.loss_dice: 0.2694
07/30 21:21:37 - mmengine - INFO - Iter(train) [38650/80000]  base_lr: 5.5214e-05 lr: 5.5214e-06  eta: 5:00:57  time: 0.4375  data_time: 0.0093  memory: 5246  grad_norm: 80.4676  loss: 8.1562  decode.loss_cls: 0.2386  decode.loss_mask: 0.1942  decode.loss_dice: 0.3153  decode.d0.loss_cls: 1.0233  decode.d0.loss_mask: 0.2024  decode.d0.loss_dice: 0.3054  decode.d1.loss_cls: 0.2580  decode.d1.loss_mask: 0.1918  decode.d1.loss_dice: 0.2977  decode.d2.loss_cls: 0.2419  decode.d2.loss_mask: 0.1919  decode.d2.loss_dice: 0.2974  decode.d3.loss_cls: 0.2305  decode.d3.loss_mask: 0.1959  decode.d3.loss_dice: 0.3046  decode.d4.loss_cls: 0.3125  decode.d4.loss_mask: 0.1919  decode.d4.loss_dice: 0.2900  decode.d5.loss_cls: 0.2515  decode.d5.loss_mask: 0.1959  decode.d5.loss_dice: 0.3104  decode.d6.loss_cls: 0.2136  decode.d6.loss_mask: 0.1936  decode.d6.loss_dice: 0.2965  decode.d7.loss_cls: 0.2228  decode.d7.loss_mask: 0.1962  decode.d7.loss_dice: 0.2877  decode.d8.loss_cls: 0.2210  decode.d8.loss_mask: 0.1917  decode.d8.loss_dice: 0.2920
07/30 21:21:59 - mmengine - INFO - Iter(train) [38700/80000]  base_lr: 5.5154e-05 lr: 5.5154e-06  eta: 5:00:36  time: 0.4379  data_time: 0.0094  memory: 5241  grad_norm: 61.7762  loss: 7.7916  decode.loss_cls: 0.0724  decode.loss_mask: 0.3194  decode.loss_dice: 0.2797  decode.d0.loss_cls: 0.9844  decode.d0.loss_mask: 0.3240  decode.d0.loss_dice: 0.2785  decode.d1.loss_cls: 0.0998  decode.d1.loss_mask: 0.3243  decode.d1.loss_dice: 0.2901  decode.d2.loss_cls: 0.0811  decode.d2.loss_mask: 0.3239  decode.d2.loss_dice: 0.2776  decode.d3.loss_cls: 0.0778  decode.d3.loss_mask: 0.3314  decode.d3.loss_dice: 0.2749  decode.d4.loss_cls: 0.0832  decode.d4.loss_mask: 0.3262  decode.d4.loss_dice: 0.2702  decode.d5.loss_cls: 0.0720  decode.d5.loss_mask: 0.3245  decode.d5.loss_dice: 0.2799  decode.d6.loss_cls: 0.0992  decode.d6.loss_mask: 0.3236  decode.d6.loss_dice: 0.2812  decode.d7.loss_cls: 0.1022  decode.d7.loss_mask: 0.3225  decode.d7.loss_dice: 0.2886  decode.d8.loss_cls: 0.0696  decode.d8.loss_mask: 0.3241  decode.d8.loss_dice: 0.2850
07/30 21:22:21 - mmengine - INFO - Iter(train) [38750/80000]  base_lr: 5.5094e-05 lr: 5.5094e-06  eta: 5:00:14  time: 0.4403  data_time: 0.0095  memory: 5246  grad_norm: 135.2976  loss: 7.8645  decode.loss_cls: 0.1847  decode.loss_mask: 0.2158  decode.loss_dice: 0.2564  decode.d0.loss_cls: 1.2022  decode.d0.loss_mask: 0.2220  decode.d0.loss_dice: 0.2785  decode.d1.loss_cls: 0.2998  decode.d1.loss_mask: 0.2147  decode.d1.loss_dice: 0.2712  decode.d2.loss_cls: 0.2016  decode.d2.loss_mask: 0.2162  decode.d2.loss_dice: 0.2566  decode.d3.loss_cls: 0.2284  decode.d3.loss_mask: 0.2144  decode.d3.loss_dice: 0.2572  decode.d4.loss_cls: 0.2020  decode.d4.loss_mask: 0.2141  decode.d4.loss_dice: 0.2659  decode.d5.loss_cls: 0.2044  decode.d5.loss_mask: 0.2154  decode.d5.loss_dice: 0.2576  decode.d6.loss_cls: 0.2120  decode.d6.loss_mask: 0.2127  decode.d6.loss_dice: 0.2579  decode.d7.loss_cls: 0.1543  decode.d7.loss_mask: 0.2176  decode.d7.loss_dice: 0.2777  decode.d8.loss_cls: 0.1572  decode.d8.loss_mask: 0.2199  decode.d8.loss_dice: 0.2762
07/30 21:22:43 - mmengine - INFO - Iter(train) [38800/80000]  base_lr: 5.5034e-05 lr: 5.5034e-06  eta: 4:59:52  time: 0.4385  data_time: 0.0094  memory: 5244  grad_norm: 102.3660  loss: 7.5618  decode.loss_cls: 0.0773  decode.loss_mask: 0.2485  decode.loss_dice: 0.2799  decode.d0.loss_cls: 0.9429  decode.d0.loss_mask: 0.2581  decode.d0.loss_dice: 0.3299  decode.d1.loss_cls: 0.2133  decode.d1.loss_mask: 0.2563  decode.d1.loss_dice: 0.2933  decode.d2.loss_cls: 0.2018  decode.d2.loss_mask: 0.2530  decode.d2.loss_dice: 0.2936  decode.d3.loss_cls: 0.1201  decode.d3.loss_mask: 0.2581  decode.d3.loss_dice: 0.3003  decode.d4.loss_cls: 0.1447  decode.d4.loss_mask: 0.2578  decode.d4.loss_dice: 0.2960  decode.d5.loss_cls: 0.1427  decode.d5.loss_mask: 0.2521  decode.d5.loss_dice: 0.2882  decode.d6.loss_cls: 0.1012  decode.d6.loss_mask: 0.2518  decode.d6.loss_dice: 0.2789  decode.d7.loss_cls: 0.1167  decode.d7.loss_mask: 0.2523  decode.d7.loss_dice: 0.2828  decode.d8.loss_cls: 0.0742  decode.d8.loss_mask: 0.2518  decode.d8.loss_dice: 0.2444
07/30 21:23:05 - mmengine - INFO - Iter(train) [38850/80000]  base_lr: 5.4974e-05 lr: 5.4974e-06  eta: 4:59:31  time: 0.4385  data_time: 0.0095  memory: 5261  grad_norm: 37.4621  loss: 6.0691  decode.loss_cls: 0.0086  decode.loss_mask: 0.2238  decode.loss_dice: 0.2546  decode.d0.loss_cls: 1.0689  decode.d0.loss_mask: 0.2262  decode.d0.loss_dice: 0.2455  decode.d1.loss_cls: 0.0905  decode.d1.loss_mask: 0.2221  decode.d1.loss_dice: 0.2590  decode.d2.loss_cls: 0.0116  decode.d2.loss_mask: 0.2241  decode.d2.loss_dice: 0.2556  decode.d3.loss_cls: 0.0088  decode.d3.loss_mask: 0.2242  decode.d3.loss_dice: 0.2491  decode.d4.loss_cls: 0.0713  decode.d4.loss_mask: 0.2194  decode.d4.loss_dice: 0.2622  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.2235  decode.d5.loss_dice: 0.2522  decode.d6.loss_cls: 0.0142  decode.d6.loss_mask: 0.2196  decode.d6.loss_dice: 0.2489  decode.d7.loss_cls: 0.0113  decode.d7.loss_mask: 0.2236  decode.d7.loss_dice: 0.2579  decode.d8.loss_cls: 0.0113  decode.d8.loss_mask: 0.2232  decode.d8.loss_dice: 0.2490
07/30 21:23:27 - mmengine - INFO - Iter(train) [38900/80000]  base_lr: 5.4914e-05 lr: 5.4914e-06  eta: 4:59:09  time: 0.4386  data_time: 0.0097  memory: 5265  grad_norm: 65.1227  loss: 7.0775  decode.loss_cls: 0.0821  decode.loss_mask: 0.2709  decode.loss_dice: 0.2438  decode.d0.loss_cls: 0.9407  decode.d0.loss_mask: 0.2771  decode.d0.loss_dice: 0.2515  decode.d1.loss_cls: 0.1533  decode.d1.loss_mask: 0.2750  decode.d1.loss_dice: 0.2472  decode.d2.loss_cls: 0.1148  decode.d2.loss_mask: 0.2723  decode.d2.loss_dice: 0.2459  decode.d3.loss_cls: 0.1275  decode.d3.loss_mask: 0.2708  decode.d3.loss_dice: 0.2379  decode.d4.loss_cls: 0.1257  decode.d4.loss_mask: 0.2691  decode.d4.loss_dice: 0.2432  decode.d5.loss_cls: 0.1026  decode.d5.loss_mask: 0.2694  decode.d5.loss_dice: 0.2399  decode.d6.loss_cls: 0.0967  decode.d6.loss_mask: 0.2715  decode.d6.loss_dice: 0.2408  decode.d7.loss_cls: 0.0937  decode.d7.loss_mask: 0.2671  decode.d7.loss_dice: 0.2418  decode.d8.loss_cls: 0.0847  decode.d8.loss_mask: 0.2693  decode.d8.loss_dice: 0.2512
07/30 21:23:49 - mmengine - INFO - Iter(train) [38950/80000]  base_lr: 5.4854e-05 lr: 5.4854e-06  eta: 4:58:47  time: 0.4392  data_time: 0.0095  memory: 5227  grad_norm: 31.6559  loss: 5.7819  decode.loss_cls: 0.0245  decode.loss_mask: 0.1975  decode.loss_dice: 0.2295  decode.d0.loss_cls: 0.9668  decode.d0.loss_mask: 0.2012  decode.d0.loss_dice: 0.2388  decode.d1.loss_cls: 0.1474  decode.d1.loss_mask: 0.1977  decode.d1.loss_dice: 0.2208  decode.d2.loss_cls: 0.0939  decode.d2.loss_mask: 0.1993  decode.d2.loss_dice: 0.2159  decode.d3.loss_cls: 0.0605  decode.d3.loss_mask: 0.1991  decode.d3.loss_dice: 0.2276  decode.d4.loss_cls: 0.0908  decode.d4.loss_mask: 0.1963  decode.d4.loss_dice: 0.2226  decode.d5.loss_cls: 0.0682  decode.d5.loss_mask: 0.1985  decode.d5.loss_dice: 0.2296  decode.d6.loss_cls: 0.0238  decode.d6.loss_mask: 0.1991  decode.d6.loss_dice: 0.2277  decode.d7.loss_cls: 0.0305  decode.d7.loss_mask: 0.1967  decode.d7.loss_dice: 0.2323  decode.d8.loss_cls: 0.0216  decode.d8.loss_mask: 0.1976  decode.d8.loss_dice: 0.2261
07/30 21:24:11 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 21:24:11 - mmengine - INFO - Iter(train) [39000/80000]  base_lr: 5.4794e-05 lr: 5.4794e-06  eta: 4:58:25  time: 0.4398  data_time: 0.0096  memory: 5265  grad_norm: 123.5867  loss: 8.6153  decode.loss_cls: 0.2598  decode.loss_mask: 0.2078  decode.loss_dice: 0.2718  decode.d0.loss_cls: 0.9521  decode.d0.loss_mask: 0.2415  decode.d0.loss_dice: 0.3514  decode.d1.loss_cls: 0.3427  decode.d1.loss_mask: 0.2143  decode.d1.loss_dice: 0.2964  decode.d2.loss_cls: 0.3194  decode.d2.loss_mask: 0.2095  decode.d2.loss_dice: 0.2773  decode.d3.loss_cls: 0.3051  decode.d3.loss_mask: 0.2185  decode.d3.loss_dice: 0.3050  decode.d4.loss_cls: 0.3312  decode.d4.loss_mask: 0.2188  decode.d4.loss_dice: 0.3128  decode.d5.loss_cls: 0.2593  decode.d5.loss_mask: 0.2118  decode.d5.loss_dice: 0.2956  decode.d6.loss_cls: 0.2528  decode.d6.loss_mask: 0.2093  decode.d6.loss_dice: 0.2845  decode.d7.loss_cls: 0.2180  decode.d7.loss_mask: 0.2128  decode.d7.loss_dice: 0.2982  decode.d8.loss_cls: 0.2656  decode.d8.loss_mask: 0.2083  decode.d8.loss_dice: 0.2634
07/30 21:24:33 - mmengine - INFO - Iter(train) [39050/80000]  base_lr: 5.4733e-05 lr: 5.4733e-06  eta: 4:58:04  time: 0.4391  data_time: 0.0095  memory: 5244  grad_norm: 43.4520  loss: 6.3652  decode.loss_cls: 0.0913  decode.loss_mask: 0.1990  decode.loss_dice: 0.2323  decode.d0.loss_cls: 0.9425  decode.d0.loss_mask: 0.2067  decode.d0.loss_dice: 0.2559  decode.d1.loss_cls: 0.1816  decode.d1.loss_mask: 0.1993  decode.d1.loss_dice: 0.2303  decode.d2.loss_cls: 0.1385  decode.d2.loss_mask: 0.2010  decode.d2.loss_dice: 0.2391  decode.d3.loss_cls: 0.1112  decode.d3.loss_mask: 0.1969  decode.d3.loss_dice: 0.2271  decode.d4.loss_cls: 0.1031  decode.d4.loss_mask: 0.1994  decode.d4.loss_dice: 0.2323  decode.d5.loss_cls: 0.1078  decode.d5.loss_mask: 0.2000  decode.d5.loss_dice: 0.2396  decode.d6.loss_cls: 0.1126  decode.d6.loss_mask: 0.1996  decode.d6.loss_dice: 0.2322  decode.d7.loss_cls: 0.1138  decode.d7.loss_mask: 0.1995  decode.d7.loss_dice: 0.2347  decode.d8.loss_cls: 0.1154  decode.d8.loss_mask: 0.1965  decode.d8.loss_dice: 0.2263
07/30 21:24:55 - mmengine - INFO - Iter(train) [39100/80000]  base_lr: 5.4673e-05 lr: 5.4673e-06  eta: 4:57:42  time: 0.4381  data_time: 0.0096  memory: 5246  grad_norm: 88.5747  loss: 6.3477  decode.loss_cls: 0.0814  decode.loss_mask: 0.2285  decode.loss_dice: 0.2230  decode.d0.loss_cls: 0.8885  decode.d0.loss_mask: 0.2358  decode.d0.loss_dice: 0.2427  decode.d1.loss_cls: 0.1249  decode.d1.loss_mask: 0.2298  decode.d1.loss_dice: 0.2248  decode.d2.loss_cls: 0.1270  decode.d2.loss_mask: 0.2310  decode.d2.loss_dice: 0.2280  decode.d3.loss_cls: 0.1111  decode.d3.loss_mask: 0.2307  decode.d3.loss_dice: 0.2260  decode.d4.loss_cls: 0.1053  decode.d4.loss_mask: 0.2278  decode.d4.loss_dice: 0.2242  decode.d5.loss_cls: 0.0898  decode.d5.loss_mask: 0.2295  decode.d5.loss_dice: 0.2285  decode.d6.loss_cls: 0.0800  decode.d6.loss_mask: 0.2272  decode.d6.loss_dice: 0.2258  decode.d7.loss_cls: 0.0858  decode.d7.loss_mask: 0.2272  decode.d7.loss_dice: 0.2188  decode.d8.loss_cls: 0.0948  decode.d8.loss_mask: 0.2281  decode.d8.loss_dice: 0.2216
07/30 21:25:17 - mmengine - INFO - Iter(train) [39150/80000]  base_lr: 5.4613e-05 lr: 5.4613e-06  eta: 4:57:20  time: 0.4400  data_time: 0.0097  memory: 5265  grad_norm: 54.3818  loss: 7.3274  decode.loss_cls: 0.1046  decode.loss_mask: 0.2404  decode.loss_dice: 0.2607  decode.d0.loss_cls: 1.0428  decode.d0.loss_mask: 0.2500  decode.d0.loss_dice: 0.2803  decode.d1.loss_cls: 0.1942  decode.d1.loss_mask: 0.2450  decode.d1.loss_dice: 0.2698  decode.d2.loss_cls: 0.1556  decode.d2.loss_mask: 0.2403  decode.d2.loss_dice: 0.2504  decode.d3.loss_cls: 0.1273  decode.d3.loss_mask: 0.2418  decode.d3.loss_dice: 0.2582  decode.d4.loss_cls: 0.1228  decode.d4.loss_mask: 0.2423  decode.d4.loss_dice: 0.2543  decode.d5.loss_cls: 0.1053  decode.d5.loss_mask: 0.2405  decode.d5.loss_dice: 0.2744  decode.d6.loss_cls: 0.1691  decode.d6.loss_mask: 0.2373  decode.d6.loss_dice: 0.2525  decode.d7.loss_cls: 0.1572  decode.d7.loss_mask: 0.2417  decode.d7.loss_dice: 0.2531  decode.d8.loss_cls: 0.1160  decode.d8.loss_mask: 0.2370  decode.d8.loss_dice: 0.2625
07/30 21:25:39 - mmengine - INFO - Iter(train) [39200/80000]  base_lr: 5.4553e-05 lr: 5.4553e-06  eta: 4:56:59  time: 0.4383  data_time: 0.0095  memory: 5279  grad_norm: 86.0042  loss: 7.1174  decode.loss_cls: 0.1005  decode.loss_mask: 0.2613  decode.loss_dice: 0.2706  decode.d0.loss_cls: 0.8153  decode.d0.loss_mask: 0.2701  decode.d0.loss_dice: 0.2867  decode.d1.loss_cls: 0.1456  decode.d1.loss_mask: 0.2654  decode.d1.loss_dice: 0.2557  decode.d2.loss_cls: 0.0796  decode.d2.loss_mask: 0.2616  decode.d2.loss_dice: 0.2807  decode.d3.loss_cls: 0.1044  decode.d3.loss_mask: 0.2608  decode.d3.loss_dice: 0.2621  decode.d4.loss_cls: 0.1422  decode.d4.loss_mask: 0.2611  decode.d4.loss_dice: 0.2579  decode.d5.loss_cls: 0.0918  decode.d5.loss_mask: 0.2619  decode.d5.loss_dice: 0.2792  decode.d6.loss_cls: 0.1139  decode.d6.loss_mask: 0.2586  decode.d6.loss_dice: 0.2586  decode.d7.loss_cls: 0.1201  decode.d7.loss_mask: 0.2632  decode.d7.loss_dice: 0.2576  decode.d8.loss_cls: 0.1001  decode.d8.loss_mask: 0.2612  decode.d8.loss_dice: 0.2697
07/30 21:26:01 - mmengine - INFO - Iter(train) [39250/80000]  base_lr: 5.4493e-05 lr: 5.4493e-06  eta: 4:56:37  time: 0.4377  data_time: 0.0095  memory: 5261  grad_norm: 40.9742  loss: 6.3887  decode.loss_cls: 0.0787  decode.loss_mask: 0.2201  decode.loss_dice: 0.2587  decode.d0.loss_cls: 0.9683  decode.d0.loss_mask: 0.2279  decode.d0.loss_dice: 0.2680  decode.d1.loss_cls: 0.0358  decode.d1.loss_mask: 0.2261  decode.d1.loss_dice: 0.2580  decode.d2.loss_cls: 0.0748  decode.d2.loss_mask: 0.2254  decode.d2.loss_dice: 0.2444  decode.d3.loss_cls: 0.0849  decode.d3.loss_mask: 0.2265  decode.d3.loss_dice: 0.2596  decode.d4.loss_cls: 0.0762  decode.d4.loss_mask: 0.2238  decode.d4.loss_dice: 0.2528  decode.d5.loss_cls: 0.0689  decode.d5.loss_mask: 0.2201  decode.d5.loss_dice: 0.2750  decode.d6.loss_cls: 0.0521  decode.d6.loss_mask: 0.2246  decode.d6.loss_dice: 0.2668  decode.d7.loss_cls: 0.0609  decode.d7.loss_mask: 0.2226  decode.d7.loss_dice: 0.2529  decode.d8.loss_cls: 0.0738  decode.d8.loss_mask: 0.2245  decode.d8.loss_dice: 0.2365
07/30 21:26:23 - mmengine - INFO - Iter(train) [39300/80000]  base_lr: 5.4433e-05 lr: 5.4433e-06  eta: 4:56:15  time: 0.4388  data_time: 0.0097  memory: 5265  grad_norm: 74.2085  loss: 7.0630  decode.loss_cls: 0.1133  decode.loss_mask: 0.2387  decode.loss_dice: 0.2620  decode.d0.loss_cls: 0.9828  decode.d0.loss_mask: 0.2431  decode.d0.loss_dice: 0.2613  decode.d1.loss_cls: 0.2198  decode.d1.loss_mask: 0.2342  decode.d1.loss_dice: 0.2594  decode.d2.loss_cls: 0.1298  decode.d2.loss_mask: 0.2364  decode.d2.loss_dice: 0.2575  decode.d3.loss_cls: 0.1448  decode.d3.loss_mask: 0.2326  decode.d3.loss_dice: 0.2553  decode.d4.loss_cls: 0.1210  decode.d4.loss_mask: 0.2330  decode.d4.loss_dice: 0.2519  decode.d5.loss_cls: 0.1174  decode.d5.loss_mask: 0.2321  decode.d5.loss_dice: 0.2566  decode.d6.loss_cls: 0.1031  decode.d6.loss_mask: 0.2339  decode.d6.loss_dice: 0.2549  decode.d7.loss_cls: 0.1070  decode.d7.loss_mask: 0.2358  decode.d7.loss_dice: 0.2593  decode.d8.loss_cls: 0.0932  decode.d8.loss_mask: 0.2367  decode.d8.loss_dice: 0.2559
07/30 21:26:45 - mmengine - INFO - Iter(train) [39350/80000]  base_lr: 5.4372e-05 lr: 5.4372e-06  eta: 4:55:53  time: 0.4392  data_time: 0.0096  memory: 5278  grad_norm: 56.4561  loss: 7.3886  decode.loss_cls: 0.0881  decode.loss_mask: 0.2311  decode.loss_dice: 0.2787  decode.d0.loss_cls: 1.0511  decode.d0.loss_mask: 0.2307  decode.d0.loss_dice: 0.2766  decode.d1.loss_cls: 0.1563  decode.d1.loss_mask: 0.2309  decode.d1.loss_dice: 0.2713  decode.d2.loss_cls: 0.1632  decode.d2.loss_mask: 0.2330  decode.d2.loss_dice: 0.2680  decode.d3.loss_cls: 0.1665  decode.d3.loss_mask: 0.2338  decode.d3.loss_dice: 0.2752  decode.d4.loss_cls: 0.1210  decode.d4.loss_mask: 0.2363  decode.d4.loss_dice: 0.2836  decode.d5.loss_cls: 0.1310  decode.d5.loss_mask: 0.2326  decode.d5.loss_dice: 0.2833  decode.d6.loss_cls: 0.1139  decode.d6.loss_mask: 0.2317  decode.d6.loss_dice: 0.2865  decode.d7.loss_cls: 0.0994  decode.d7.loss_mask: 0.2356  decode.d7.loss_dice: 0.2901  decode.d8.loss_cls: 0.1700  decode.d8.loss_mask: 0.2321  decode.d8.loss_dice: 0.2869
07/30 21:27:06 - mmengine - INFO - Iter(train) [39400/80000]  base_lr: 5.4312e-05 lr: 5.4312e-06  eta: 4:55:32  time: 0.4392  data_time: 0.0096  memory: 5279  grad_norm: 48.5499  loss: 7.5410  decode.loss_cls: 0.2917  decode.loss_mask: 0.2100  decode.loss_dice: 0.2208  decode.d0.loss_cls: 1.1810  decode.d0.loss_mask: 0.2096  decode.d0.loss_dice: 0.2365  decode.d1.loss_cls: 0.2347  decode.d1.loss_mask: 0.2043  decode.d1.loss_dice: 0.2065  decode.d2.loss_cls: 0.2010  decode.d2.loss_mask: 0.2069  decode.d2.loss_dice: 0.2221  decode.d3.loss_cls: 0.1771  decode.d3.loss_mask: 0.2110  decode.d3.loss_dice: 0.2321  decode.d4.loss_cls: 0.2055  decode.d4.loss_mask: 0.2106  decode.d4.loss_dice: 0.2353  decode.d5.loss_cls: 0.2138  decode.d5.loss_mask: 0.2087  decode.d5.loss_dice: 0.2150  decode.d6.loss_cls: 0.2318  decode.d6.loss_mask: 0.2081  decode.d6.loss_dice: 0.2338  decode.d7.loss_cls: 0.2302  decode.d7.loss_mask: 0.2058  decode.d7.loss_dice: 0.2328  decode.d8.loss_cls: 0.2223  decode.d8.loss_mask: 0.2057  decode.d8.loss_dice: 0.2363
07/30 21:27:28 - mmengine - INFO - Iter(train) [39450/80000]  base_lr: 5.4252e-05 lr: 5.4252e-06  eta: 4:55:10  time: 0.4384  data_time: 0.0096  memory: 5279  grad_norm: 38.2287  loss: 6.2357  decode.loss_cls: 0.0932  decode.loss_mask: 0.2158  decode.loss_dice: 0.2469  decode.d0.loss_cls: 0.8919  decode.d0.loss_mask: 0.2169  decode.d0.loss_dice: 0.2449  decode.d1.loss_cls: 0.0874  decode.d1.loss_mask: 0.2110  decode.d1.loss_dice: 0.2418  decode.d2.loss_cls: 0.0891  decode.d2.loss_mask: 0.2093  decode.d2.loss_dice: 0.2476  decode.d3.loss_cls: 0.0742  decode.d3.loss_mask: 0.2114  decode.d3.loss_dice: 0.2457  decode.d4.loss_cls: 0.0831  decode.d4.loss_mask: 0.2131  decode.d4.loss_dice: 0.2541  decode.d5.loss_cls: 0.0628  decode.d5.loss_mask: 0.2120  decode.d5.loss_dice: 0.2487  decode.d6.loss_cls: 0.0750  decode.d6.loss_mask: 0.2125  decode.d6.loss_dice: 0.2558  decode.d7.loss_cls: 0.0696  decode.d7.loss_mask: 0.2127  decode.d7.loss_dice: 0.2535  decode.d8.loss_cls: 0.0881  decode.d8.loss_mask: 0.2135  decode.d8.loss_dice: 0.2542
07/30 21:27:50 - mmengine - INFO - Iter(train) [39500/80000]  base_lr: 5.4192e-05 lr: 5.4192e-06  eta: 4:54:48  time: 0.4387  data_time: 0.0097  memory: 5227  grad_norm: 47.8096  loss: 5.8483  decode.loss_cls: 0.0753  decode.loss_mask: 0.2088  decode.loss_dice: 0.2289  decode.d0.loss_cls: 0.8982  decode.d0.loss_mask: 0.2084  decode.d0.loss_dice: 0.2251  decode.d1.loss_cls: 0.0502  decode.d1.loss_mask: 0.2164  decode.d1.loss_dice: 0.2206  decode.d2.loss_cls: 0.0327  decode.d2.loss_mask: 0.2110  decode.d2.loss_dice: 0.2247  decode.d3.loss_cls: 0.0823  decode.d3.loss_mask: 0.2095  decode.d3.loss_dice: 0.2308  decode.d4.loss_cls: 0.0716  decode.d4.loss_mask: 0.2108  decode.d4.loss_dice: 0.2409  decode.d5.loss_cls: 0.0628  decode.d5.loss_mask: 0.2097  decode.d5.loss_dice: 0.2274  decode.d6.loss_cls: 0.0463  decode.d6.loss_mask: 0.2105  decode.d6.loss_dice: 0.2411  decode.d7.loss_cls: 0.0348  decode.d7.loss_mask: 0.2098  decode.d7.loss_dice: 0.2431  decode.d8.loss_cls: 0.0747  decode.d8.loss_mask: 0.2105  decode.d8.loss_dice: 0.2314
07/30 21:28:12 - mmengine - INFO - Iter(train) [39550/80000]  base_lr: 5.4132e-05 lr: 5.4132e-06  eta: 4:54:26  time: 0.4397  data_time: 0.0097  memory: 5261  grad_norm: 72.5393  loss: 7.4979  decode.loss_cls: 0.1610  decode.loss_mask: 0.2351  decode.loss_dice: 0.2581  decode.d0.loss_cls: 1.0095  decode.d0.loss_mask: 0.2392  decode.d0.loss_dice: 0.2617  decode.d1.loss_cls: 0.2596  decode.d1.loss_mask: 0.2370  decode.d1.loss_dice: 0.2605  decode.d2.loss_cls: 0.1626  decode.d2.loss_mask: 0.2379  decode.d2.loss_dice: 0.2641  decode.d3.loss_cls: 0.1750  decode.d3.loss_mask: 0.2340  decode.d3.loss_dice: 0.2692  decode.d4.loss_cls: 0.1587  decode.d4.loss_mask: 0.2359  decode.d4.loss_dice: 0.2608  decode.d5.loss_cls: 0.1122  decode.d5.loss_mask: 0.2394  decode.d5.loss_dice: 0.2890  decode.d6.loss_cls: 0.1718  decode.d6.loss_mask: 0.2354  decode.d6.loss_dice: 0.2632  decode.d7.loss_cls: 0.1181  decode.d7.loss_mask: 0.2385  decode.d7.loss_dice: 0.2659  decode.d8.loss_cls: 0.1337  decode.d8.loss_mask: 0.2376  decode.d8.loss_dice: 0.2730
07/30 21:28:34 - mmengine - INFO - Iter(train) [39600/80000]  base_lr: 5.4071e-05 lr: 5.4071e-06  eta: 4:54:05  time: 0.4384  data_time: 0.0096  memory: 5265  grad_norm: 40.4313  loss: 6.5673  decode.loss_cls: 0.0905  decode.loss_mask: 0.2487  decode.loss_dice: 0.2496  decode.d0.loss_cls: 0.8892  decode.d0.loss_mask: 0.2576  decode.d0.loss_dice: 0.2701  decode.d1.loss_cls: 0.0661  decode.d1.loss_mask: 0.2493  decode.d1.loss_dice: 0.2533  decode.d2.loss_cls: 0.0474  decode.d2.loss_mask: 0.2479  decode.d2.loss_dice: 0.2548  decode.d3.loss_cls: 0.0488  decode.d3.loss_mask: 0.2470  decode.d3.loss_dice: 0.2558  decode.d4.loss_cls: 0.0832  decode.d4.loss_mask: 0.2467  decode.d4.loss_dice: 0.2500  decode.d5.loss_cls: 0.0851  decode.d5.loss_mask: 0.2459  decode.d5.loss_dice: 0.2414  decode.d6.loss_cls: 0.0731  decode.d6.loss_mask: 0.2492  decode.d6.loss_dice: 0.2528  decode.d7.loss_cls: 0.0831  decode.d7.loss_mask: 0.2499  decode.d7.loss_dice: 0.2522  decode.d8.loss_cls: 0.0864  decode.d8.loss_mask: 0.2460  decode.d8.loss_dice: 0.2460
07/30 21:28:56 - mmengine - INFO - Iter(train) [39650/80000]  base_lr: 5.4011e-05 lr: 5.4011e-06  eta: 4:53:43  time: 0.4389  data_time: 0.0095  memory: 5305  grad_norm: 66.4745  loss: 8.2525  decode.loss_cls: 0.1467  decode.loss_mask: 0.2515  decode.loss_dice: 0.3429  decode.d0.loss_cls: 0.9343  decode.d0.loss_mask: 0.2519  decode.d0.loss_dice: 0.3291  decode.d1.loss_cls: 0.1890  decode.d1.loss_mask: 0.2512  decode.d1.loss_dice: 0.3270  decode.d2.loss_cls: 0.1624  decode.d2.loss_mask: 0.2513  decode.d2.loss_dice: 0.3156  decode.d3.loss_cls: 0.1742  decode.d3.loss_mask: 0.2517  decode.d3.loss_dice: 0.3337  decode.d4.loss_cls: 0.2254  decode.d4.loss_mask: 0.2499  decode.d4.loss_dice: 0.2651  decode.d5.loss_cls: 0.1939  decode.d5.loss_mask: 0.2522  decode.d5.loss_dice: 0.2942  decode.d6.loss_cls: 0.2078  decode.d6.loss_mask: 0.2499  decode.d6.loss_dice: 0.3116  decode.d7.loss_cls: 0.1806  decode.d7.loss_mask: 0.2519  decode.d7.loss_dice: 0.3264  decode.d8.loss_cls: 0.1612  decode.d8.loss_mask: 0.2490  decode.d8.loss_dice: 0.3210
07/30 21:29:18 - mmengine - INFO - Iter(train) [39700/80000]  base_lr: 5.3951e-05 lr: 5.3951e-06  eta: 4:53:21  time: 0.4396  data_time: 0.0096  memory: 5246  grad_norm: 76.7838  loss: 8.0221  decode.loss_cls: 0.1066  decode.loss_mask: 0.2631  decode.loss_dice: 0.3424  decode.d0.loss_cls: 0.9866  decode.d0.loss_mask: 0.2685  decode.d0.loss_dice: 0.3552  decode.d1.loss_cls: 0.1418  decode.d1.loss_mask: 0.2631  decode.d1.loss_dice: 0.3499  decode.d2.loss_cls: 0.1132  decode.d2.loss_mask: 0.2627  decode.d2.loss_dice: 0.3511  decode.d3.loss_cls: 0.1381  decode.d3.loss_mask: 0.2600  decode.d3.loss_dice: 0.3275  decode.d4.loss_cls: 0.0880  decode.d4.loss_mask: 0.2641  decode.d4.loss_dice: 0.3343  decode.d5.loss_cls: 0.0818  decode.d5.loss_mask: 0.2630  decode.d5.loss_dice: 0.3288  decode.d6.loss_cls: 0.0849  decode.d6.loss_mask: 0.2603  decode.d6.loss_dice: 0.3476  decode.d7.loss_cls: 0.1420  decode.d7.loss_mask: 0.2634  decode.d7.loss_dice: 0.3350  decode.d8.loss_cls: 0.0747  decode.d8.loss_mask: 0.2619  decode.d8.loss_dice: 0.3623
07/30 21:29:40 - mmengine - INFO - Iter(train) [39750/80000]  base_lr: 5.3891e-05 lr: 5.3891e-06  eta: 4:53:00  time: 0.4383  data_time: 0.0097  memory: 5246  grad_norm: 61.3165  loss: 8.3005  decode.loss_cls: 0.1873  decode.loss_mask: 0.2435  decode.loss_dice: 0.2936  decode.d0.loss_cls: 0.9294  decode.d0.loss_mask: 0.2592  decode.d0.loss_dice: 0.2862  decode.d1.loss_cls: 0.2939  decode.d1.loss_mask: 0.2406  decode.d1.loss_dice: 0.2768  decode.d2.loss_cls: 0.2941  decode.d2.loss_mask: 0.2494  decode.d2.loss_dice: 0.2733  decode.d3.loss_cls: 0.2103  decode.d3.loss_mask: 0.2496  decode.d3.loss_dice: 0.2873  decode.d4.loss_cls: 0.2482  decode.d4.loss_mask: 0.2428  decode.d4.loss_dice: 0.2858  decode.d5.loss_cls: 0.2139  decode.d5.loss_mask: 0.2407  decode.d5.loss_dice: 0.2897  decode.d6.loss_cls: 0.1860  decode.d6.loss_mask: 0.2430  decode.d6.loss_dice: 0.2871  decode.d7.loss_cls: 0.2066  decode.d7.loss_mask: 0.2427  decode.d7.loss_dice: 0.2849  decode.d8.loss_cls: 0.2122  decode.d8.loss_mask: 0.2504  decode.d8.loss_dice: 0.2919
07/30 21:30:02 - mmengine - INFO - Iter(train) [39800/80000]  base_lr: 5.3830e-05 lr: 5.3830e-06  eta: 4:52:38  time: 0.4384  data_time: 0.0097  memory: 5245  grad_norm: 59.3854  loss: 9.1859  decode.loss_cls: 0.2580  decode.loss_mask: 0.3021  decode.loss_dice: 0.2814  decode.d0.loss_cls: 1.1628  decode.d0.loss_mask: 0.3127  decode.d0.loss_dice: 0.2836  decode.d1.loss_cls: 0.1798  decode.d1.loss_mask: 0.3086  decode.d1.loss_dice: 0.3037  decode.d2.loss_cls: 0.2163  decode.d2.loss_mask: 0.3072  decode.d2.loss_dice: 0.2807  decode.d3.loss_cls: 0.2175  decode.d3.loss_mask: 0.3068  decode.d3.loss_dice: 0.2964  decode.d4.loss_cls: 0.2605  decode.d4.loss_mask: 0.3074  decode.d4.loss_dice: 0.2742  decode.d5.loss_cls: 0.2491  decode.d5.loss_mask: 0.3086  decode.d5.loss_dice: 0.2798  decode.d6.loss_cls: 0.2446  decode.d6.loss_mask: 0.2999  decode.d6.loss_dice: 0.2857  decode.d7.loss_cls: 0.2563  decode.d7.loss_mask: 0.3057  decode.d7.loss_dice: 0.2887  decode.d8.loss_cls: 0.2291  decode.d8.loss_mask: 0.3005  decode.d8.loss_dice: 0.2781
07/30 21:30:24 - mmengine - INFO - Iter(train) [39850/80000]  base_lr: 5.3770e-05 lr: 5.3770e-06  eta: 4:52:16  time: 0.4380  data_time: 0.0096  memory: 5265  grad_norm: 79.7202  loss: 7.4069  decode.loss_cls: 0.1272  decode.loss_mask: 0.2440  decode.loss_dice: 0.2886  decode.d0.loss_cls: 1.0086  decode.d0.loss_mask: 0.2448  decode.d0.loss_dice: 0.2828  decode.d1.loss_cls: 0.1255  decode.d1.loss_mask: 0.2403  decode.d1.loss_dice: 0.2898  decode.d2.loss_cls: 0.0952  decode.d2.loss_mask: 0.2413  decode.d2.loss_dice: 0.2873  decode.d3.loss_cls: 0.0961  decode.d3.loss_mask: 0.2392  decode.d3.loss_dice: 0.2844  decode.d4.loss_cls: 0.1093  decode.d4.loss_mask: 0.2394  decode.d4.loss_dice: 0.2904  decode.d5.loss_cls: 0.1041  decode.d5.loss_mask: 0.2397  decode.d5.loss_dice: 0.2896  decode.d6.loss_cls: 0.1330  decode.d6.loss_mask: 0.2383  decode.d6.loss_dice: 0.2782  decode.d7.loss_cls: 0.1914  decode.d7.loss_mask: 0.2422  decode.d7.loss_dice: 0.2898  decode.d8.loss_cls: 0.1412  decode.d8.loss_mask: 0.2389  decode.d8.loss_dice: 0.2860
07/30 21:30:46 - mmengine - INFO - Iter(train) [39900/80000]  base_lr: 5.3710e-05 lr: 5.3710e-06  eta: 4:51:54  time: 0.4396  data_time: 0.0097  memory: 5305  grad_norm: 97.6174  loss: 7.4795  decode.loss_cls: 0.1933  decode.loss_mask: 0.2211  decode.loss_dice: 0.2544  decode.d0.loss_cls: 1.0008  decode.d0.loss_mask: 0.2255  decode.d0.loss_dice: 0.3048  decode.d1.loss_cls: 0.1497  decode.d1.loss_mask: 0.2221  decode.d1.loss_dice: 0.2772  decode.d2.loss_cls: 0.1301  decode.d2.loss_mask: 0.2211  decode.d2.loss_dice: 0.2719  decode.d3.loss_cls: 0.1815  decode.d3.loss_mask: 0.2210  decode.d3.loss_dice: 0.2708  decode.d4.loss_cls: 0.1623  decode.d4.loss_mask: 0.2169  decode.d4.loss_dice: 0.2691  decode.d5.loss_cls: 0.1656  decode.d5.loss_mask: 0.2231  decode.d5.loss_dice: 0.2772  decode.d6.loss_cls: 0.1986  decode.d6.loss_mask: 0.2180  decode.d6.loss_dice: 0.2833  decode.d7.loss_cls: 0.1522  decode.d7.loss_mask: 0.2192  decode.d7.loss_dice: 0.2685  decode.d8.loss_cls: 0.2026  decode.d8.loss_mask: 0.2196  decode.d8.loss_dice: 0.2578
07/30 21:31:08 - mmengine - INFO - Iter(train) [39950/80000]  base_lr: 5.3650e-05 lr: 5.3650e-06  eta: 4:51:33  time: 0.4404  data_time: 0.0098  memory: 5245  grad_norm: 99.7661  loss: 9.1714  decode.loss_cls: 0.1419  decode.loss_mask: 0.3505  decode.loss_dice: 0.2910  decode.d0.loss_cls: 0.9655  decode.d0.loss_mask: 0.3580  decode.d0.loss_dice: 0.2953  decode.d1.loss_cls: 0.2301  decode.d1.loss_mask: 0.3521  decode.d1.loss_dice: 0.3152  decode.d2.loss_cls: 0.2003  decode.d2.loss_mask: 0.3550  decode.d2.loss_dice: 0.3216  decode.d3.loss_cls: 0.2222  decode.d3.loss_mask: 0.3449  decode.d3.loss_dice: 0.2898  decode.d4.loss_cls: 0.1465  decode.d4.loss_mask: 0.3503  decode.d4.loss_dice: 0.3011  decode.d5.loss_cls: 0.2234  decode.d5.loss_mask: 0.3515  decode.d5.loss_dice: 0.2957  decode.d6.loss_cls: 0.1825  decode.d6.loss_mask: 0.3586  decode.d6.loss_dice: 0.3025  decode.d7.loss_cls: 0.1747  decode.d7.loss_mask: 0.3533  decode.d7.loss_dice: 0.2934  decode.d8.loss_cls: 0.1556  decode.d8.loss_mask: 0.3512  decode.d8.loss_dice: 0.2977
07/30 21:31:30 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 21:31:30 - mmengine - INFO - Iter(train) [40000/80000]  base_lr: 5.3589e-05 lr: 5.3589e-06  eta: 4:51:11  time: 0.4388  data_time: 0.0097  memory: 5245  grad_norm: 64.7594  loss: 8.5774  decode.loss_cls: 0.1738  decode.loss_mask: 0.2865  decode.loss_dice: 0.2725  decode.d0.loss_cls: 1.0076  decode.d0.loss_mask: 0.2932  decode.d0.loss_dice: 0.3235  decode.d1.loss_cls: 0.3163  decode.d1.loss_mask: 0.2813  decode.d1.loss_dice: 0.2685  decode.d2.loss_cls: 0.2451  decode.d2.loss_mask: 0.2848  decode.d2.loss_dice: 0.2638  decode.d3.loss_cls: 0.1878  decode.d3.loss_mask: 0.2796  decode.d3.loss_dice: 0.2585  decode.d4.loss_cls: 0.2249  decode.d4.loss_mask: 0.2813  decode.d4.loss_dice: 0.2619  decode.d5.loss_cls: 0.2447  decode.d5.loss_mask: 0.2761  decode.d5.loss_dice: 0.2826  decode.d6.loss_cls: 0.1737  decode.d6.loss_mask: 0.2775  decode.d6.loss_dice: 0.2716  decode.d7.loss_cls: 0.2165  decode.d7.loss_mask: 0.2819  decode.d7.loss_dice: 0.2601  decode.d8.loss_cls: 0.2388  decode.d8.loss_mask: 0.2795  decode.d8.loss_dice: 0.2634
07/30 21:31:30 - mmengine - INFO - Saving checkpoint at 40000 iterations
07/30 21:31:54 - mmengine - INFO - Iter(train) [40050/80000]  base_lr: 5.3529e-05 lr: 5.3529e-06  eta: 4:50:51  time: 0.4370  data_time: 0.0096  memory: 5265  grad_norm: 108.9879  loss: 8.5372  decode.loss_cls: 0.1977  decode.loss_mask: 0.2771  decode.loss_dice: 0.3018  decode.d0.loss_cls: 0.9477  decode.d0.loss_mask: 0.2844  decode.d0.loss_dice: 0.3346  decode.d1.loss_cls: 0.1870  decode.d1.loss_mask: 0.2841  decode.d1.loss_dice: 0.3154  decode.d2.loss_cls: 0.1568  decode.d2.loss_mask: 0.2791  decode.d2.loss_dice: 0.3169  decode.d3.loss_cls: 0.2359  decode.d3.loss_mask: 0.2761  decode.d3.loss_dice: 0.3187  decode.d4.loss_cls: 0.1460  decode.d4.loss_mask: 0.2745  decode.d4.loss_dice: 0.3046  decode.d5.loss_cls: 0.1671  decode.d5.loss_mask: 0.2766  decode.d5.loss_dice: 0.3154  decode.d6.loss_cls: 0.1718  decode.d6.loss_mask: 0.2797  decode.d6.loss_dice: 0.3106  decode.d7.loss_cls: 0.2220  decode.d7.loss_mask: 0.2746  decode.d7.loss_dice: 0.2989  decode.d8.loss_cls: 0.2104  decode.d8.loss_mask: 0.2751  decode.d8.loss_dice: 0.2966
07/30 21:32:16 - mmengine - INFO - Iter(train) [40100/80000]  base_lr: 5.3469e-05 lr: 5.3469e-06  eta: 4:50:29  time: 0.4371  data_time: 0.0094  memory: 5245  grad_norm: 68.4329  loss: 8.7809  decode.loss_cls: 0.2257  decode.loss_mask: 0.2627  decode.loss_dice: 0.2694  decode.d0.loss_cls: 1.0526  decode.d0.loss_mask: 0.2847  decode.d0.loss_dice: 0.2823  decode.d1.loss_cls: 0.2291  decode.d1.loss_mask: 0.2707  decode.d1.loss_dice: 0.2933  decode.d2.loss_cls: 0.2661  decode.d2.loss_mask: 0.2675  decode.d2.loss_dice: 0.2830  decode.d3.loss_cls: 0.2587  decode.d3.loss_mask: 0.2647  decode.d3.loss_dice: 0.2887  decode.d4.loss_cls: 0.2640  decode.d4.loss_mask: 0.2668  decode.d4.loss_dice: 0.2801  decode.d5.loss_cls: 0.2117  decode.d5.loss_mask: 0.2641  decode.d5.loss_dice: 0.2886  decode.d6.loss_cls: 0.2623  decode.d6.loss_mask: 0.2672  decode.d6.loss_dice: 0.2740  decode.d7.loss_cls: 0.2520  decode.d7.loss_mask: 0.2660  decode.d7.loss_dice: 0.2892  decode.d8.loss_cls: 0.2569  decode.d8.loss_mask: 0.2656  decode.d8.loss_dice: 0.2731
07/30 21:32:38 - mmengine - INFO - Iter(train) [40150/80000]  base_lr: 5.3408e-05 lr: 5.3408e-06  eta: 4:50:08  time: 0.4416  data_time: 0.0097  memory: 5261  grad_norm: 109.4908  loss: 7.1200  decode.loss_cls: 0.1483  decode.loss_mask: 0.2159  decode.loss_dice: 0.2495  decode.d0.loss_cls: 1.0459  decode.d0.loss_mask: 0.2243  decode.d0.loss_dice: 0.2600  decode.d1.loss_cls: 0.1540  decode.d1.loss_mask: 0.2181  decode.d1.loss_dice: 0.2515  decode.d2.loss_cls: 0.1907  decode.d2.loss_mask: 0.2184  decode.d2.loss_dice: 0.2494  decode.d3.loss_cls: 0.1434  decode.d3.loss_mask: 0.2202  decode.d3.loss_dice: 0.2509  decode.d4.loss_cls: 0.1537  decode.d4.loss_mask: 0.2169  decode.d4.loss_dice: 0.2475  decode.d5.loss_cls: 0.1265  decode.d5.loss_mask: 0.2187  decode.d5.loss_dice: 0.2525  decode.d6.loss_cls: 0.1441  decode.d6.loss_mask: 0.2184  decode.d6.loss_dice: 0.2505  decode.d7.loss_cls: 0.1515  decode.d7.loss_mask: 0.2195  decode.d7.loss_dice: 0.2503  decode.d8.loss_cls: 0.1699  decode.d8.loss_mask: 0.2142  decode.d8.loss_dice: 0.2453
07/30 21:33:00 - mmengine - INFO - Iter(train) [40200/80000]  base_lr: 5.3348e-05 lr: 5.3348e-06  eta: 4:49:46  time: 0.4386  data_time: 0.0097  memory: 5265  grad_norm: 46.3692  loss: 7.0923  decode.loss_cls: 0.0872  decode.loss_mask: 0.2681  decode.loss_dice: 0.2676  decode.d0.loss_cls: 0.8742  decode.d0.loss_mask: 0.2821  decode.d0.loss_dice: 0.2527  decode.d1.loss_cls: 0.1349  decode.d1.loss_mask: 0.2755  decode.d1.loss_dice: 0.2663  decode.d2.loss_cls: 0.0947  decode.d2.loss_mask: 0.2745  decode.d2.loss_dice: 0.2612  decode.d3.loss_cls: 0.1008  decode.d3.loss_mask: 0.2676  decode.d3.loss_dice: 0.2630  decode.d4.loss_cls: 0.0895  decode.d4.loss_mask: 0.2717  decode.d4.loss_dice: 0.2577  decode.d5.loss_cls: 0.0982  decode.d5.loss_mask: 0.2713  decode.d5.loss_dice: 0.2525  decode.d6.loss_cls: 0.0948  decode.d6.loss_mask: 0.2684  decode.d6.loss_dice: 0.2577  decode.d7.loss_cls: 0.0935  decode.d7.loss_mask: 0.2701  decode.d7.loss_dice: 0.2809  decode.d8.loss_cls: 0.0850  decode.d8.loss_mask: 0.2701  decode.d8.loss_dice: 0.2605
07/30 21:33:22 - mmengine - INFO - Iter(train) [40250/80000]  base_lr: 5.3288e-05 lr: 5.3288e-06  eta: 4:49:24  time: 0.4387  data_time: 0.0098  memory: 5245  grad_norm: 138.6665  loss: 7.5464  decode.loss_cls: 0.1299  decode.loss_mask: 0.2236  decode.loss_dice: 0.2785  decode.d0.loss_cls: 1.0831  decode.d0.loss_mask: 0.2197  decode.d0.loss_dice: 0.3142  decode.d1.loss_cls: 0.2390  decode.d1.loss_mask: 0.2234  decode.d1.loss_dice: 0.2795  decode.d2.loss_cls: 0.1679  decode.d2.loss_mask: 0.2170  decode.d2.loss_dice: 0.2692  decode.d3.loss_cls: 0.1558  decode.d3.loss_mask: 0.2174  decode.d3.loss_dice: 0.2906  decode.d4.loss_cls: 0.1225  decode.d4.loss_mask: 0.2226  decode.d4.loss_dice: 0.2895  decode.d5.loss_cls: 0.1417  decode.d5.loss_mask: 0.2257  decode.d5.loss_dice: 0.2698  decode.d6.loss_cls: 0.1807  decode.d6.loss_mask: 0.2280  decode.d6.loss_dice: 0.2817  decode.d7.loss_cls: 0.1471  decode.d7.loss_mask: 0.2236  decode.d7.loss_dice: 0.2650  decode.d8.loss_cls: 0.1452  decode.d8.loss_mask: 0.2228  decode.d8.loss_dice: 0.2719
07/30 21:33:44 - mmengine - INFO - Iter(train) [40300/80000]  base_lr: 5.3227e-05 lr: 5.3227e-06  eta: 4:49:02  time: 0.4399  data_time: 0.0097  memory: 5265  grad_norm: 44.1845  loss: 7.1352  decode.loss_cls: 0.1937  decode.loss_mask: 0.2188  decode.loss_dice: 0.2371  decode.d0.loss_cls: 0.8941  decode.d0.loss_mask: 0.2246  decode.d0.loss_dice: 0.2352  decode.d1.loss_cls: 0.1872  decode.d1.loss_mask: 0.2152  decode.d1.loss_dice: 0.2338  decode.d2.loss_cls: 0.1447  decode.d2.loss_mask: 0.2194  decode.d2.loss_dice: 0.2412  decode.d3.loss_cls: 0.1610  decode.d3.loss_mask: 0.2201  decode.d3.loss_dice: 0.2382  decode.d4.loss_cls: 0.1894  decode.d4.loss_mask: 0.2174  decode.d4.loss_dice: 0.2294  decode.d5.loss_cls: 0.1820  decode.d5.loss_mask: 0.2204  decode.d5.loss_dice: 0.2384  decode.d6.loss_cls: 0.1999  decode.d6.loss_mask: 0.2204  decode.d6.loss_dice: 0.2319  decode.d7.loss_cls: 0.2197  decode.d7.loss_mask: 0.2184  decode.d7.loss_dice: 0.2317  decode.d8.loss_cls: 0.2288  decode.d8.loss_mask: 0.2201  decode.d8.loss_dice: 0.2228
07/30 21:34:06 - mmengine - INFO - Iter(train) [40350/80000]  base_lr: 5.3167e-05 lr: 5.3167e-06  eta: 4:48:41  time: 0.4388  data_time: 0.0096  memory: 5304  grad_norm: 127.1204  loss: 8.0271  decode.loss_cls: 0.0690  decode.loss_mask: 0.3298  decode.loss_dice: 0.3115  decode.d0.loss_cls: 0.9616  decode.d0.loss_mask: 0.3231  decode.d0.loss_dice: 0.3006  decode.d1.loss_cls: 0.0835  decode.d1.loss_mask: 0.3242  decode.d1.loss_dice: 0.2976  decode.d2.loss_cls: 0.0794  decode.d2.loss_mask: 0.3315  decode.d2.loss_dice: 0.3233  decode.d3.loss_cls: 0.0921  decode.d3.loss_mask: 0.3194  decode.d3.loss_dice: 0.2940  decode.d4.loss_cls: 0.1079  decode.d4.loss_mask: 0.3250  decode.d4.loss_dice: 0.2946  decode.d5.loss_cls: 0.1003  decode.d5.loss_mask: 0.3260  decode.d5.loss_dice: 0.3035  decode.d6.loss_cls: 0.0743  decode.d6.loss_mask: 0.3282  decode.d6.loss_dice: 0.2998  decode.d7.loss_cls: 0.0787  decode.d7.loss_mask: 0.3263  decode.d7.loss_dice: 0.2910  decode.d8.loss_cls: 0.0982  decode.d8.loss_mask: 0.3286  decode.d8.loss_dice: 0.3041
07/30 21:34:28 - mmengine - INFO - Iter(train) [40400/80000]  base_lr: 5.3107e-05 lr: 5.3107e-06  eta: 4:48:19  time: 0.4385  data_time: 0.0097  memory: 5277  grad_norm: 59.2178  loss: 6.8801  decode.loss_cls: 0.0778  decode.loss_mask: 0.2544  decode.loss_dice: 0.2723  decode.d0.loss_cls: 0.9546  decode.d0.loss_mask: 0.2557  decode.d0.loss_dice: 0.3048  decode.d1.loss_cls: 0.0844  decode.d1.loss_mask: 0.2600  decode.d1.loss_dice: 0.2722  decode.d2.loss_cls: 0.0843  decode.d2.loss_mask: 0.2543  decode.d2.loss_dice: 0.2741  decode.d3.loss_cls: 0.0558  decode.d3.loss_mask: 0.2585  decode.d3.loss_dice: 0.2882  decode.d4.loss_cls: 0.0734  decode.d4.loss_mask: 0.2564  decode.d4.loss_dice: 0.2853  decode.d5.loss_cls: 0.0386  decode.d5.loss_mask: 0.2548  decode.d5.loss_dice: 0.3082  decode.d6.loss_cls: 0.0438  decode.d6.loss_mask: 0.2574  decode.d6.loss_dice: 0.2862  decode.d7.loss_cls: 0.0335  decode.d7.loss_mask: 0.2573  decode.d7.loss_dice: 0.2625  decode.d8.loss_cls: 0.0344  decode.d8.loss_mask: 0.2542  decode.d8.loss_dice: 0.2824
07/30 21:34:50 - mmengine - INFO - Iter(train) [40450/80000]  base_lr: 5.3046e-05 lr: 5.3046e-06  eta: 4:47:57  time: 0.4409  data_time: 0.0095  memory: 5229  grad_norm: 82.7250  loss: 5.3475  decode.loss_cls: 0.0812  decode.loss_mask: 0.1724  decode.loss_dice: 0.1937  decode.d0.loss_cls: 0.9150  decode.d0.loss_mask: 0.1842  decode.d0.loss_dice: 0.2185  decode.d1.loss_cls: 0.0792  decode.d1.loss_mask: 0.1771  decode.d1.loss_dice: 0.2020  decode.d2.loss_cls: 0.0540  decode.d2.loss_mask: 0.1710  decode.d2.loss_dice: 0.1908  decode.d3.loss_cls: 0.0678  decode.d3.loss_mask: 0.1732  decode.d3.loss_dice: 0.1909  decode.d4.loss_cls: 0.0901  decode.d4.loss_mask: 0.1742  decode.d4.loss_dice: 0.2081  decode.d5.loss_cls: 0.0668  decode.d5.loss_mask: 0.1711  decode.d5.loss_dice: 0.1895  decode.d6.loss_cls: 0.0634  decode.d6.loss_mask: 0.1715  decode.d6.loss_dice: 0.2107  decode.d7.loss_cls: 0.0907  decode.d7.loss_mask: 0.1711  decode.d7.loss_dice: 0.2045  decode.d8.loss_cls: 0.0980  decode.d8.loss_mask: 0.1720  decode.d8.loss_dice: 0.1949
07/30 21:35:12 - mmengine - INFO - Iter(train) [40500/80000]  base_lr: 5.2986e-05 lr: 5.2986e-06  eta: 4:47:36  time: 0.4400  data_time: 0.0096  memory: 5244  grad_norm: 58.7925  loss: 8.9144  decode.loss_cls: 0.3576  decode.loss_mask: 0.2159  decode.loss_dice: 0.2296  decode.d0.loss_cls: 1.1374  decode.d0.loss_mask: 0.2209  decode.d0.loss_dice: 0.2554  decode.d1.loss_cls: 0.3401  decode.d1.loss_mask: 0.2203  decode.d1.loss_dice: 0.2383  decode.d2.loss_cls: 0.3482  decode.d2.loss_mask: 0.2164  decode.d2.loss_dice: 0.2501  decode.d3.loss_cls: 0.3502  decode.d3.loss_mask: 0.2184  decode.d3.loss_dice: 0.2438  decode.d4.loss_cls: 0.3401  decode.d4.loss_mask: 0.2160  decode.d4.loss_dice: 0.2478  decode.d5.loss_cls: 0.3293  decode.d5.loss_mask: 0.2159  decode.d5.loss_dice: 0.2970  decode.d6.loss_cls: 0.3370  decode.d6.loss_mask: 0.2181  decode.d6.loss_dice: 0.2557  decode.d7.loss_cls: 0.3713  decode.d7.loss_mask: 0.2193  decode.d7.loss_dice: 0.2200  decode.d8.loss_cls: 0.3188  decode.d8.loss_mask: 0.2167  decode.d8.loss_dice: 0.2688
07/30 21:35:34 - mmengine - INFO - Iter(train) [40550/80000]  base_lr: 5.2926e-05 lr: 5.2926e-06  eta: 4:47:14  time: 0.4378  data_time: 0.0095  memory: 5261  grad_norm: 93.6502  loss: 6.9554  decode.loss_cls: 0.2082  decode.loss_mask: 0.1863  decode.loss_dice: 0.2469  decode.d0.loss_cls: 0.9445  decode.d0.loss_mask: 0.1888  decode.d0.loss_dice: 0.2509  decode.d1.loss_cls: 0.1746  decode.d1.loss_mask: 0.1901  decode.d1.loss_dice: 0.2570  decode.d2.loss_cls: 0.1737  decode.d2.loss_mask: 0.1843  decode.d2.loss_dice: 0.2427  decode.d3.loss_cls: 0.1714  decode.d3.loss_mask: 0.1875  decode.d3.loss_dice: 0.2400  decode.d4.loss_cls: 0.2115  decode.d4.loss_mask: 0.1954  decode.d4.loss_dice: 0.2512  decode.d5.loss_cls: 0.1819  decode.d5.loss_mask: 0.1936  decode.d5.loss_dice: 0.2451  decode.d6.loss_cls: 0.1582  decode.d6.loss_mask: 0.1936  decode.d6.loss_dice: 0.2492  decode.d7.loss_cls: 0.1559  decode.d7.loss_mask: 0.1991  decode.d7.loss_dice: 0.2458  decode.d8.loss_cls: 0.1679  decode.d8.loss_mask: 0.1983  decode.d8.loss_dice: 0.2617
07/30 21:35:56 - mmengine - INFO - Iter(train) [40600/80000]  base_lr: 5.2865e-05 lr: 5.2865e-06  eta: 4:46:52  time: 0.4388  data_time: 0.0098  memory: 5279  grad_norm: 74.5243  loss: 7.6923  decode.loss_cls: 0.1209  decode.loss_mask: 0.2370  decode.loss_dice: 0.3002  decode.d0.loss_cls: 1.0458  decode.d0.loss_mask: 0.2334  decode.d0.loss_dice: 0.2874  decode.d1.loss_cls: 0.1897  decode.d1.loss_mask: 0.2374  decode.d1.loss_dice: 0.2688  decode.d2.loss_cls: 0.1453  decode.d2.loss_mask: 0.2447  decode.d2.loss_dice: 0.3280  decode.d3.loss_cls: 0.1433  decode.d3.loss_mask: 0.2492  decode.d3.loss_dice: 0.3275  decode.d4.loss_cls: 0.1158  decode.d4.loss_mask: 0.2399  decode.d4.loss_dice: 0.3102  decode.d5.loss_cls: 0.1043  decode.d5.loss_mask: 0.2390  decode.d5.loss_dice: 0.3022  decode.d6.loss_cls: 0.0973  decode.d6.loss_mask: 0.2397  decode.d6.loss_dice: 0.2979  decode.d7.loss_cls: 0.1519  decode.d7.loss_mask: 0.2350  decode.d7.loss_dice: 0.3187  decode.d8.loss_cls: 0.1395  decode.d8.loss_mask: 0.2382  decode.d8.loss_dice: 0.3042
07/30 21:36:18 - mmengine - INFO - Iter(train) [40650/80000]  base_lr: 5.2805e-05 lr: 5.2805e-06  eta: 4:46:31  time: 0.4391  data_time: 0.0098  memory: 5245  grad_norm: 59.1475  loss: 7.1480  decode.loss_cls: 0.1212  decode.loss_mask: 0.2264  decode.loss_dice: 0.2433  decode.d0.loss_cls: 1.0369  decode.d0.loss_mask: 0.2270  decode.d0.loss_dice: 0.2519  decode.d1.loss_cls: 0.1544  decode.d1.loss_mask: 0.2302  decode.d1.loss_dice: 0.2541  decode.d2.loss_cls: 0.1591  decode.d2.loss_mask: 0.2250  decode.d2.loss_dice: 0.2476  decode.d3.loss_cls: 0.1817  decode.d3.loss_mask: 0.2239  decode.d3.loss_dice: 0.2459  decode.d4.loss_cls: 0.1641  decode.d4.loss_mask: 0.2250  decode.d4.loss_dice: 0.2446  decode.d5.loss_cls: 0.1256  decode.d5.loss_mask: 0.2263  decode.d5.loss_dice: 0.2532  decode.d6.loss_cls: 0.1260  decode.d6.loss_mask: 0.2261  decode.d6.loss_dice: 0.2625  decode.d7.loss_cls: 0.1968  decode.d7.loss_mask: 0.2235  decode.d7.loss_dice: 0.2462  decode.d8.loss_cls: 0.1196  decode.d8.loss_mask: 0.2256  decode.d8.loss_dice: 0.2542
07/30 21:36:40 - mmengine - INFO - Iter(train) [40700/80000]  base_lr: 5.2745e-05 lr: 5.2745e-06  eta: 4:46:09  time: 0.4383  data_time: 0.0096  memory: 5245  grad_norm: 51.4541  loss: 6.0355  decode.loss_cls: 0.0829  decode.loss_mask: 0.1936  decode.loss_dice: 0.2418  decode.d0.loss_cls: 1.0437  decode.d0.loss_mask: 0.1976  decode.d0.loss_dice: 0.2593  decode.d1.loss_cls: 0.0795  decode.d1.loss_mask: 0.1951  decode.d1.loss_dice: 0.2405  decode.d2.loss_cls: 0.0642  decode.d2.loss_mask: 0.1928  decode.d2.loss_dice: 0.2323  decode.d3.loss_cls: 0.0435  decode.d3.loss_mask: 0.1931  decode.d3.loss_dice: 0.2464  decode.d4.loss_cls: 0.0593  decode.d4.loss_mask: 0.1924  decode.d4.loss_dice: 0.2576  decode.d5.loss_cls: 0.0667  decode.d5.loss_mask: 0.1924  decode.d5.loss_dice: 0.2416  decode.d6.loss_cls: 0.0491  decode.d6.loss_mask: 0.1929  decode.d6.loss_dice: 0.2359  decode.d7.loss_cls: 0.0629  decode.d7.loss_mask: 0.1959  decode.d7.loss_dice: 0.2664  decode.d8.loss_cls: 0.0770  decode.d8.loss_mask: 0.1960  decode.d8.loss_dice: 0.2432
07/30 21:37:01 - mmengine - INFO - Iter(train) [40750/80000]  base_lr: 5.2684e-05 lr: 5.2684e-06  eta: 4:45:47  time: 0.4391  data_time: 0.0095  memory: 5261  grad_norm: 93.6375  loss: 6.8464  decode.loss_cls: 0.1369  decode.loss_mask: 0.2039  decode.loss_dice: 0.2221  decode.d0.loss_cls: 0.9501  decode.d0.loss_mask: 0.2127  decode.d0.loss_dice: 0.2211  decode.d1.loss_cls: 0.2276  decode.d1.loss_mask: 0.2065  decode.d1.loss_dice: 0.2219  decode.d2.loss_cls: 0.2000  decode.d2.loss_mask: 0.2058  decode.d2.loss_dice: 0.2193  decode.d3.loss_cls: 0.1739  decode.d3.loss_mask: 0.2059  decode.d3.loss_dice: 0.2180  decode.d4.loss_cls: 0.1758  decode.d4.loss_mask: 0.2057  decode.d4.loss_dice: 0.2214  decode.d5.loss_cls: 0.1940  decode.d5.loss_mask: 0.2057  decode.d5.loss_dice: 0.2185  decode.d6.loss_cls: 0.1586  decode.d6.loss_mask: 0.2051  decode.d6.loss_dice: 0.2233  decode.d7.loss_cls: 0.1863  decode.d7.loss_mask: 0.2054  decode.d7.loss_dice: 0.2187  decode.d8.loss_cls: 0.1726  decode.d8.loss_mask: 0.2039  decode.d8.loss_dice: 0.2261
07/30 21:37:23 - mmengine - INFO - Iter(train) [40800/80000]  base_lr: 5.2624e-05 lr: 5.2624e-06  eta: 4:45:25  time: 0.4393  data_time: 0.0098  memory: 5261  grad_norm: 54.9247  loss: 7.6972  decode.loss_cls: 0.1805  decode.loss_mask: 0.2325  decode.loss_dice: 0.2662  decode.d0.loss_cls: 1.0653  decode.d0.loss_mask: 0.2398  decode.d0.loss_dice: 0.2698  decode.d1.loss_cls: 0.1982  decode.d1.loss_mask: 0.2356  decode.d1.loss_dice: 0.2716  decode.d2.loss_cls: 0.1729  decode.d2.loss_mask: 0.2339  decode.d2.loss_dice: 0.2710  decode.d3.loss_cls: 0.2175  decode.d3.loss_mask: 0.2330  decode.d3.loss_dice: 0.2656  decode.d4.loss_cls: 0.1726  decode.d4.loss_mask: 0.2346  decode.d4.loss_dice: 0.2597  decode.d5.loss_cls: 0.1769  decode.d5.loss_mask: 0.2338  decode.d5.loss_dice: 0.2628  decode.d6.loss_cls: 0.1557  decode.d6.loss_mask: 0.2380  decode.d6.loss_dice: 0.2714  decode.d7.loss_cls: 0.1622  decode.d7.loss_mask: 0.2351  decode.d7.loss_dice: 0.2733  decode.d8.loss_cls: 0.1681  decode.d8.loss_mask: 0.2352  decode.d8.loss_dice: 0.2644
07/30 21:37:45 - mmengine - INFO - Iter(train) [40850/80000]  base_lr: 5.2563e-05 lr: 5.2563e-06  eta: 4:45:04  time: 0.4395  data_time: 0.0096  memory: 5246  grad_norm: 58.4118  loss: 5.2995  decode.loss_cls: 0.0261  decode.loss_mask: 0.1898  decode.loss_dice: 0.2235  decode.d0.loss_cls: 0.9268  decode.d0.loss_mask: 0.1964  decode.d0.loss_dice: 0.2244  decode.d1.loss_cls: 0.0285  decode.d1.loss_mask: 0.1933  decode.d1.loss_dice: 0.2268  decode.d2.loss_cls: 0.0223  decode.d2.loss_mask: 0.1897  decode.d2.loss_dice: 0.2304  decode.d3.loss_cls: 0.0259  decode.d3.loss_mask: 0.1902  decode.d3.loss_dice: 0.2208  decode.d4.loss_cls: 0.0258  decode.d4.loss_mask: 0.1904  decode.d4.loss_dice: 0.2175  decode.d5.loss_cls: 0.0221  decode.d5.loss_mask: 0.1914  decode.d5.loss_dice: 0.2213  decode.d6.loss_cls: 0.0298  decode.d6.loss_mask: 0.1927  decode.d6.loss_dice: 0.2241  decode.d7.loss_cls: 0.0271  decode.d7.loss_mask: 0.1904  decode.d7.loss_dice: 0.2201  decode.d8.loss_cls: 0.0214  decode.d8.loss_mask: 0.1911  decode.d8.loss_dice: 0.2194
07/30 21:38:07 - mmengine - INFO - Iter(train) [40900/80000]  base_lr: 5.2503e-05 lr: 5.2503e-06  eta: 4:44:42  time: 0.4384  data_time: 0.0091  memory: 5265  grad_norm: 36.0331  loss: 5.8703  decode.loss_cls: 0.0125  decode.loss_mask: 0.2452  decode.loss_dice: 0.2456  decode.d0.loss_cls: 0.8848  decode.d0.loss_mask: 0.2392  decode.d0.loss_dice: 0.2328  decode.d1.loss_cls: 0.0304  decode.d1.loss_mask: 0.2413  decode.d1.loss_dice: 0.2373  decode.d2.loss_cls: 0.0265  decode.d2.loss_mask: 0.2402  decode.d2.loss_dice: 0.2405  decode.d3.loss_cls: 0.0164  decode.d3.loss_mask: 0.2431  decode.d3.loss_dice: 0.2398  decode.d4.loss_cls: 0.0159  decode.d4.loss_mask: 0.2416  decode.d4.loss_dice: 0.2448  decode.d5.loss_cls: 0.0148  decode.d5.loss_mask: 0.2442  decode.d5.loss_dice: 0.2389  decode.d6.loss_cls: 0.0162  decode.d6.loss_mask: 0.2478  decode.d6.loss_dice: 0.2418  decode.d7.loss_cls: 0.0138  decode.d7.loss_mask: 0.2454  decode.d7.loss_dice: 0.2360  decode.d8.loss_cls: 0.0119  decode.d8.loss_mask: 0.2453  decode.d8.loss_dice: 0.2361
07/30 21:38:29 - mmengine - INFO - Iter(train) [40950/80000]  base_lr: 5.2442e-05 lr: 5.2442e-06  eta: 4:44:20  time: 0.4388  data_time: 0.0092  memory: 5265  grad_norm: 37.5866  loss: 6.7770  decode.loss_cls: 0.0587  decode.loss_mask: 0.2553  decode.loss_dice: 0.2861  decode.d0.loss_cls: 0.8959  decode.d0.loss_mask: 0.2648  decode.d0.loss_dice: 0.2814  decode.d1.loss_cls: 0.0293  decode.d1.loss_mask: 0.2622  decode.d1.loss_dice: 0.2837  decode.d2.loss_cls: 0.0208  decode.d2.loss_mask: 0.2581  decode.d2.loss_dice: 0.2983  decode.d3.loss_cls: 0.0488  decode.d3.loss_mask: 0.2570  decode.d3.loss_dice: 0.2644  decode.d4.loss_cls: 0.0233  decode.d4.loss_mask: 0.2581  decode.d4.loss_dice: 0.2889  decode.d5.loss_cls: 0.0483  decode.d5.loss_mask: 0.2563  decode.d5.loss_dice: 0.2840  decode.d6.loss_cls: 0.1093  decode.d6.loss_mask: 0.2577  decode.d6.loss_dice: 0.2878  decode.d7.loss_cls: 0.0550  decode.d7.loss_mask: 0.2602  decode.d7.loss_dice: 0.2900  decode.d8.loss_cls: 0.0599  decode.d8.loss_mask: 0.2583  decode.d8.loss_dice: 0.2748
07/30 21:38:51 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 21:38:51 - mmengine - INFO - Iter(train) [41000/80000]  base_lr: 5.2382e-05 lr: 5.2382e-06  eta: 4:43:58  time: 0.4387  data_time: 0.0096  memory: 5279  grad_norm: 147.5468  loss: 10.3017  decode.loss_cls: 0.2981  decode.loss_mask: 0.2282  decode.loss_dice: 0.3534  decode.d0.loss_cls: 1.0823  decode.d0.loss_mask: 0.2337  decode.d0.loss_dice: 0.4123  decode.d1.loss_cls: 0.5037  decode.d1.loss_mask: 0.2166  decode.d1.loss_dice: 0.3347  decode.d2.loss_cls: 0.4216  decode.d2.loss_mask: 0.2324  decode.d2.loss_dice: 0.3262  decode.d3.loss_cls: 0.4239  decode.d3.loss_mask: 0.2295  decode.d3.loss_dice: 0.3193  decode.d4.loss_cls: 0.3495  decode.d4.loss_mask: 0.2372  decode.d4.loss_dice: 0.3430  decode.d5.loss_cls: 0.3549  decode.d5.loss_mask: 0.2259  decode.d5.loss_dice: 0.3314  decode.d6.loss_cls: 0.3521  decode.d6.loss_mask: 0.2252  decode.d6.loss_dice: 0.3259  decode.d7.loss_cls: 0.3954  decode.d7.loss_mask: 0.2238  decode.d7.loss_dice: 0.3498  decode.d8.loss_cls: 0.3412  decode.d8.loss_mask: 0.2390  decode.d8.loss_dice: 0.3914
07/30 21:39:13 - mmengine - INFO - Iter(train) [41050/80000]  base_lr: 5.2322e-05 lr: 5.2322e-06  eta: 4:43:37  time: 0.4394  data_time: 0.0095  memory: 5245  grad_norm: 57.8231  loss: 6.1150  decode.loss_cls: 0.0373  decode.loss_mask: 0.2536  decode.loss_dice: 0.2257  decode.d0.loss_cls: 0.9505  decode.d0.loss_mask: 0.2398  decode.d0.loss_dice: 0.2307  decode.d1.loss_cls: 0.0877  decode.d1.loss_mask: 0.2563  decode.d1.loss_dice: 0.2301  decode.d2.loss_cls: 0.0401  decode.d2.loss_mask: 0.2530  decode.d2.loss_dice: 0.2298  decode.d3.loss_cls: 0.0247  decode.d3.loss_mask: 0.2543  decode.d3.loss_dice: 0.2270  decode.d4.loss_cls: 0.0270  decode.d4.loss_mask: 0.2578  decode.d4.loss_dice: 0.2266  decode.d5.loss_cls: 0.0340  decode.d5.loss_mask: 0.2554  decode.d5.loss_dice: 0.2287  decode.d6.loss_cls: 0.0313  decode.d6.loss_mask: 0.2542  decode.d6.loss_dice: 0.2303  decode.d7.loss_cls: 0.0324  decode.d7.loss_mask: 0.2527  decode.d7.loss_dice: 0.2287  decode.d8.loss_cls: 0.0377  decode.d8.loss_mask: 0.2483  decode.d8.loss_dice: 0.2294
07/30 21:39:35 - mmengine - INFO - Iter(train) [41100/80000]  base_lr: 5.2261e-05 lr: 5.2261e-06  eta: 4:43:15  time: 0.4379  data_time: 0.0095  memory: 5246  grad_norm: 58.4472  loss: 7.2919  decode.loss_cls: 0.1750  decode.loss_mask: 0.2253  decode.loss_dice: 0.2577  decode.d0.loss_cls: 0.9239  decode.d0.loss_mask: 0.2159  decode.d0.loss_dice: 0.2554  decode.d1.loss_cls: 0.2017  decode.d1.loss_mask: 0.2194  decode.d1.loss_dice: 0.2526  decode.d2.loss_cls: 0.2089  decode.d2.loss_mask: 0.2214  decode.d2.loss_dice: 0.2583  decode.d3.loss_cls: 0.1515  decode.d3.loss_mask: 0.2213  decode.d3.loss_dice: 0.2603  decode.d4.loss_cls: 0.1866  decode.d4.loss_mask: 0.2159  decode.d4.loss_dice: 0.2437  decode.d5.loss_cls: 0.1445  decode.d5.loss_mask: 0.2185  decode.d5.loss_dice: 0.2563  decode.d6.loss_cls: 0.1322  decode.d6.loss_mask: 0.2224  decode.d6.loss_dice: 0.2596  decode.d7.loss_cls: 0.1902  decode.d7.loss_mask: 0.2292  decode.d7.loss_dice: 0.2665  decode.d8.loss_cls: 0.2187  decode.d8.loss_mask: 0.2215  decode.d8.loss_dice: 0.2377
07/30 21:39:57 - mmengine - INFO - Iter(train) [41150/80000]  base_lr: 5.2201e-05 lr: 5.2201e-06  eta: 4:42:53  time: 0.4406  data_time: 0.0095  memory: 5265  grad_norm: 84.0157  loss: 6.6781  decode.loss_cls: 0.1345  decode.loss_mask: 0.2055  decode.loss_dice: 0.2539  decode.d0.loss_cls: 0.8409  decode.d0.loss_mask: 0.2043  decode.d0.loss_dice: 0.2807  decode.d1.loss_cls: 0.1520  decode.d1.loss_mask: 0.2137  decode.d1.loss_dice: 0.2731  decode.d2.loss_cls: 0.1328  decode.d2.loss_mask: 0.2080  decode.d2.loss_dice: 0.2604  decode.d3.loss_cls: 0.1382  decode.d3.loss_mask: 0.2080  decode.d3.loss_dice: 0.2655  decode.d4.loss_cls: 0.1123  decode.d4.loss_mask: 0.2111  decode.d4.loss_dice: 0.2573  decode.d5.loss_cls: 0.1114  decode.d5.loss_mask: 0.2112  decode.d5.loss_dice: 0.2475  decode.d6.loss_cls: 0.1120  decode.d6.loss_mask: 0.2059  decode.d6.loss_dice: 0.2523  decode.d7.loss_cls: 0.1224  decode.d7.loss_mask: 0.2060  decode.d7.loss_dice: 0.2500  decode.d8.loss_cls: 0.1319  decode.d8.loss_mask: 0.2074  decode.d8.loss_dice: 0.2681
07/30 21:40:19 - mmengine - INFO - Iter(train) [41200/80000]  base_lr: 5.2140e-05 lr: 5.2140e-06  eta: 4:42:31  time: 0.4399  data_time: 0.0096  memory: 5277  grad_norm: 187.1479  loss: 7.7492  decode.loss_cls: 0.1596  decode.loss_mask: 0.2431  decode.loss_dice: 0.2707  decode.d0.loss_cls: 0.9982  decode.d0.loss_mask: 0.2487  decode.d0.loss_dice: 0.3015  decode.d1.loss_cls: 0.1536  decode.d1.loss_mask: 0.2499  decode.d1.loss_dice: 0.2968  decode.d2.loss_cls: 0.1622  decode.d2.loss_mask: 0.2461  decode.d2.loss_dice: 0.2725  decode.d3.loss_cls: 0.1586  decode.d3.loss_mask: 0.2541  decode.d3.loss_dice: 0.2843  decode.d4.loss_cls: 0.1661  decode.d4.loss_mask: 0.2570  decode.d4.loss_dice: 0.2913  decode.d5.loss_cls: 0.1585  decode.d5.loss_mask: 0.2493  decode.d5.loss_dice: 0.2986  decode.d6.loss_cls: 0.1571  decode.d6.loss_mask: 0.2445  decode.d6.loss_dice: 0.2638  decode.d7.loss_cls: 0.1533  decode.d7.loss_mask: 0.2452  decode.d7.loss_dice: 0.3134  decode.d8.loss_cls: 0.1356  decode.d8.loss_mask: 0.2376  decode.d8.loss_dice: 0.2781
07/30 21:40:41 - mmengine - INFO - Iter(train) [41250/80000]  base_lr: 5.2080e-05 lr: 5.2080e-06  eta: 4:42:10  time: 0.4386  data_time: 0.0095  memory: 5278  grad_norm: 31.3602  loss: 5.8469  decode.loss_cls: 0.0785  decode.loss_mask: 0.2159  decode.loss_dice: 0.2180  decode.d0.loss_cls: 0.8025  decode.d0.loss_mask: 0.2216  decode.d0.loss_dice: 0.2347  decode.d1.loss_cls: 0.0758  decode.d1.loss_mask: 0.2191  decode.d1.loss_dice: 0.2308  decode.d2.loss_cls: 0.0688  decode.d2.loss_mask: 0.2174  decode.d2.loss_dice: 0.2238  decode.d3.loss_cls: 0.0554  decode.d3.loss_mask: 0.2172  decode.d3.loss_dice: 0.2236  decode.d4.loss_cls: 0.0909  decode.d4.loss_mask: 0.2160  decode.d4.loss_dice: 0.2279  decode.d5.loss_cls: 0.0688  decode.d5.loss_mask: 0.2186  decode.d5.loss_dice: 0.2199  decode.d6.loss_cls: 0.0667  decode.d6.loss_mask: 0.2160  decode.d6.loss_dice: 0.2128  decode.d7.loss_cls: 0.0539  decode.d7.loss_mask: 0.2180  decode.d7.loss_dice: 0.2186  decode.d8.loss_cls: 0.0751  decode.d8.loss_mask: 0.2197  decode.d8.loss_dice: 0.2208
07/30 21:41:03 - mmengine - INFO - Iter(train) [41300/80000]  base_lr: 5.2019e-05 lr: 5.2019e-06  eta: 4:41:48  time: 0.4394  data_time: 0.0095  memory: 5265  grad_norm: 62.5467  loss: 7.7336  decode.loss_cls: 0.1581  decode.loss_mask: 0.2231  decode.loss_dice: 0.3164  decode.d0.loss_cls: 0.9141  decode.d0.loss_mask: 0.2313  decode.d0.loss_dice: 0.3455  decode.d1.loss_cls: 0.1720  decode.d1.loss_mask: 0.2263  decode.d1.loss_dice: 0.2908  decode.d2.loss_cls: 0.1974  decode.d2.loss_mask: 0.2232  decode.d2.loss_dice: 0.3031  decode.d3.loss_cls: 0.1578  decode.d3.loss_mask: 0.2215  decode.d3.loss_dice: 0.3218  decode.d4.loss_cls: 0.1436  decode.d4.loss_mask: 0.2220  decode.d4.loss_dice: 0.3345  decode.d5.loss_cls: 0.1451  decode.d5.loss_mask: 0.2237  decode.d5.loss_dice: 0.3219  decode.d6.loss_cls: 0.1644  decode.d6.loss_mask: 0.2259  decode.d6.loss_dice: 0.3136  decode.d7.loss_cls: 0.1526  decode.d7.loss_mask: 0.2232  decode.d7.loss_dice: 0.2978  decode.d8.loss_cls: 0.1405  decode.d8.loss_mask: 0.2236  decode.d8.loss_dice: 0.2987
07/30 21:41:25 - mmengine - INFO - Iter(train) [41350/80000]  base_lr: 5.1959e-05 lr: 5.1959e-06  eta: 4:41:26  time: 0.4401  data_time: 0.0095  memory: 5244  grad_norm: 39.6696  loss: 7.1106  decode.loss_cls: 0.1589  decode.loss_mask: 0.1981  decode.loss_dice: 0.2576  decode.d0.loss_cls: 1.1885  decode.d0.loss_mask: 0.2022  decode.d0.loss_dice: 0.2481  decode.d1.loss_cls: 0.1847  decode.d1.loss_mask: 0.2013  decode.d1.loss_dice: 0.2463  decode.d2.loss_cls: 0.1574  decode.d2.loss_mask: 0.1973  decode.d2.loss_dice: 0.2403  decode.d3.loss_cls: 0.1314  decode.d3.loss_mask: 0.1952  decode.d3.loss_dice: 0.2437  decode.d4.loss_cls: 0.1745  decode.d4.loss_mask: 0.1963  decode.d4.loss_dice: 0.2461  decode.d5.loss_cls: 0.1549  decode.d5.loss_mask: 0.1965  decode.d5.loss_dice: 0.2421  decode.d6.loss_cls: 0.1848  decode.d6.loss_mask: 0.1939  decode.d6.loss_dice: 0.2420  decode.d7.loss_cls: 0.1711  decode.d7.loss_mask: 0.1954  decode.d7.loss_dice: 0.2614  decode.d8.loss_cls: 0.1526  decode.d8.loss_mask: 0.1948  decode.d8.loss_dice: 0.2534
07/30 21:41:47 - mmengine - INFO - Iter(train) [41400/80000]  base_lr: 5.1898e-05 lr: 5.1898e-06  eta: 4:41:05  time: 0.4397  data_time: 0.0094  memory: 5246  grad_norm: 55.6631  loss: 7.0924  decode.loss_cls: 0.0867  decode.loss_mask: 0.2034  decode.loss_dice: 0.2808  decode.d0.loss_cls: 0.8527  decode.d0.loss_mask: 0.2032  decode.d0.loss_dice: 0.3099  decode.d1.loss_cls: 0.1719  decode.d1.loss_mask: 0.2028  decode.d1.loss_dice: 0.2791  decode.d2.loss_cls: 0.1548  decode.d2.loss_mask: 0.2037  decode.d2.loss_dice: 0.2762  decode.d3.loss_cls: 0.1552  decode.d3.loss_mask: 0.2047  decode.d3.loss_dice: 0.2810  decode.d4.loss_cls: 0.1537  decode.d4.loss_mask: 0.2007  decode.d4.loss_dice: 0.2801  decode.d5.loss_cls: 0.1343  decode.d5.loss_mask: 0.2005  decode.d5.loss_dice: 0.2772  decode.d6.loss_cls: 0.1877  decode.d6.loss_mask: 0.2023  decode.d6.loss_dice: 0.2735  decode.d7.loss_cls: 0.1384  decode.d7.loss_mask: 0.2053  decode.d7.loss_dice: 0.2694  decode.d8.loss_cls: 0.2116  decode.d8.loss_mask: 0.2104  decode.d8.loss_dice: 0.2813
07/30 21:42:09 - mmengine - INFO - Iter(train) [41450/80000]  base_lr: 5.1838e-05 lr: 5.1838e-06  eta: 4:40:43  time: 0.4393  data_time: 0.0094  memory: 5245  grad_norm: 42.9506  loss: 6.4130  decode.loss_cls: 0.0567  decode.loss_mask: 0.2252  decode.loss_dice: 0.2557  decode.d0.loss_cls: 0.8138  decode.d0.loss_mask: 0.2241  decode.d0.loss_dice: 0.2772  decode.d1.loss_cls: 0.1643  decode.d1.loss_mask: 0.2191  decode.d1.loss_dice: 0.2263  decode.d2.loss_cls: 0.1378  decode.d2.loss_mask: 0.2181  decode.d2.loss_dice: 0.2450  decode.d3.loss_cls: 0.1303  decode.d3.loss_mask: 0.2251  decode.d3.loss_dice: 0.2581  decode.d4.loss_cls: 0.1387  decode.d4.loss_mask: 0.2172  decode.d4.loss_dice: 0.2317  decode.d5.loss_cls: 0.0788  decode.d5.loss_mask: 0.2230  decode.d5.loss_dice: 0.2514  decode.d6.loss_cls: 0.0494  decode.d6.loss_mask: 0.2262  decode.d6.loss_dice: 0.2527  decode.d7.loss_cls: 0.0627  decode.d7.loss_mask: 0.2258  decode.d7.loss_dice: 0.2486  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.2253  decode.d8.loss_dice: 0.2473
07/30 21:42:31 - mmengine - INFO - Iter(train) [41500/80000]  base_lr: 5.1777e-05 lr: 5.1777e-06  eta: 4:40:21  time: 0.4396  data_time: 0.0095  memory: 5261  grad_norm: 49.6072  loss: 7.2627  decode.loss_cls: 0.1497  decode.loss_mask: 0.2466  decode.loss_dice: 0.2762  decode.d0.loss_cls: 1.0362  decode.d0.loss_mask: 0.2484  decode.d0.loss_dice: 0.2808  decode.d1.loss_cls: 0.0928  decode.d1.loss_mask: 0.2461  decode.d1.loss_dice: 0.2801  decode.d2.loss_cls: 0.0827  decode.d2.loss_mask: 0.2426  decode.d2.loss_dice: 0.2664  decode.d3.loss_cls: 0.0747  decode.d3.loss_mask: 0.2549  decode.d3.loss_dice: 0.2897  decode.d4.loss_cls: 0.1200  decode.d4.loss_mask: 0.2447  decode.d4.loss_dice: 0.2797  decode.d5.loss_cls: 0.1062  decode.d5.loss_mask: 0.2584  decode.d5.loss_dice: 0.2866  decode.d6.loss_cls: 0.0717  decode.d6.loss_mask: 0.2520  decode.d6.loss_dice: 0.2867  decode.d7.loss_cls: 0.0831  decode.d7.loss_mask: 0.2605  decode.d7.loss_dice: 0.2870  decode.d8.loss_cls: 0.1337  decode.d8.loss_mask: 0.2488  decode.d8.loss_dice: 0.2756
07/30 21:42:53 - mmengine - INFO - Iter(train) [41550/80000]  base_lr: 5.1717e-05 lr: 5.1717e-06  eta: 4:39:59  time: 0.4399  data_time: 0.0096  memory: 5322  grad_norm: 95.8040  loss: 8.4041  decode.loss_cls: 0.3642  decode.loss_mask: 0.1899  decode.loss_dice: 0.2629  decode.d0.loss_cls: 0.9656  decode.d0.loss_mask: 0.1947  decode.d0.loss_dice: 0.2736  decode.d1.loss_cls: 0.3375  decode.d1.loss_mask: 0.1908  decode.d1.loss_dice: 0.2680  decode.d2.loss_cls: 0.2720  decode.d2.loss_mask: 0.1903  decode.d2.loss_dice: 0.2547  decode.d3.loss_cls: 0.2965  decode.d3.loss_mask: 0.1911  decode.d3.loss_dice: 0.2562  decode.d4.loss_cls: 0.3087  decode.d4.loss_mask: 0.1918  decode.d4.loss_dice: 0.2731  decode.d5.loss_cls: 0.3167  decode.d5.loss_mask: 0.1924  decode.d5.loss_dice: 0.2765  decode.d6.loss_cls: 0.3172  decode.d6.loss_mask: 0.1908  decode.d6.loss_dice: 0.2639  decode.d7.loss_cls: 0.3304  decode.d7.loss_mask: 0.1897  decode.d7.loss_dice: 0.2607  decode.d8.loss_cls: 0.3194  decode.d8.loss_mask: 0.1932  decode.d8.loss_dice: 0.2713
07/30 21:43:15 - mmengine - INFO - Iter(train) [41600/80000]  base_lr: 5.1656e-05 lr: 5.1656e-06  eta: 4:39:38  time: 0.4384  data_time: 0.0094  memory: 5246  grad_norm: 95.7194  loss: 6.3003  decode.loss_cls: 0.1152  decode.loss_mask: 0.2185  decode.loss_dice: 0.2385  decode.d0.loss_cls: 0.8497  decode.d0.loss_mask: 0.2240  decode.d0.loss_dice: 0.2675  decode.d1.loss_cls: 0.1054  decode.d1.loss_mask: 0.2196  decode.d1.loss_dice: 0.2421  decode.d2.loss_cls: 0.0586  decode.d2.loss_mask: 0.2231  decode.d2.loss_dice: 0.2532  decode.d3.loss_cls: 0.0637  decode.d3.loss_mask: 0.2235  decode.d3.loss_dice: 0.2434  decode.d4.loss_cls: 0.1001  decode.d4.loss_mask: 0.2168  decode.d4.loss_dice: 0.2477  decode.d5.loss_cls: 0.0761  decode.d5.loss_mask: 0.2255  decode.d5.loss_dice: 0.2502  decode.d6.loss_cls: 0.0698  decode.d6.loss_mask: 0.2219  decode.d6.loss_dice: 0.2439  decode.d7.loss_cls: 0.1019  decode.d7.loss_mask: 0.2156  decode.d7.loss_dice: 0.2364  decode.d8.loss_cls: 0.0838  decode.d8.loss_mask: 0.2213  decode.d8.loss_dice: 0.2433
07/30 21:43:37 - mmengine - INFO - Iter(train) [41650/80000]  base_lr: 5.1596e-05 lr: 5.1596e-06  eta: 4:39:16  time: 0.4394  data_time: 0.0095  memory: 5277  grad_norm: 112.6184  loss: 5.5776  decode.loss_cls: 0.0532  decode.loss_mask: 0.1853  decode.loss_dice: 0.2113  decode.d0.loss_cls: 1.0476  decode.d0.loss_mask: 0.1865  decode.d0.loss_dice: 0.2102  decode.d1.loss_cls: 0.0568  decode.d1.loss_mask: 0.1865  decode.d1.loss_dice: 0.2139  decode.d2.loss_cls: 0.0560  decode.d2.loss_mask: 0.1873  decode.d2.loss_dice: 0.2167  decode.d3.loss_cls: 0.0572  decode.d3.loss_mask: 0.1876  decode.d3.loss_dice: 0.2128  decode.d4.loss_cls: 0.0628  decode.d4.loss_mask: 0.1859  decode.d4.loss_dice: 0.2157  decode.d5.loss_cls: 0.0595  decode.d5.loss_mask: 0.1856  decode.d5.loss_dice: 0.2116  decode.d6.loss_cls: 0.0603  decode.d6.loss_mask: 0.1857  decode.d6.loss_dice: 0.2118  decode.d7.loss_cls: 0.0683  decode.d7.loss_mask: 0.1861  decode.d7.loss_dice: 0.2132  decode.d8.loss_cls: 0.0667  decode.d8.loss_mask: 0.1844  decode.d8.loss_dice: 0.2113
07/30 21:43:59 - mmengine - INFO - Iter(train) [41700/80000]  base_lr: 5.1535e-05 lr: 5.1535e-06  eta: 4:38:54  time: 0.4394  data_time: 0.0095  memory: 5244  grad_norm: 55.6671  loss: 6.9614  decode.loss_cls: 0.1541  decode.loss_mask: 0.2367  decode.loss_dice: 0.2221  decode.d0.loss_cls: 0.8986  decode.d0.loss_mask: 0.2432  decode.d0.loss_dice: 0.2399  decode.d1.loss_cls: 0.1907  decode.d1.loss_mask: 0.2305  decode.d1.loss_dice: 0.2179  decode.d2.loss_cls: 0.1251  decode.d2.loss_mask: 0.2356  decode.d2.loss_dice: 0.2217  decode.d3.loss_cls: 0.1630  decode.d3.loss_mask: 0.2345  decode.d3.loss_dice: 0.2385  decode.d4.loss_cls: 0.1793  decode.d4.loss_mask: 0.2377  decode.d4.loss_dice: 0.2223  decode.d5.loss_cls: 0.1514  decode.d5.loss_mask: 0.2369  decode.d5.loss_dice: 0.2148  decode.d6.loss_cls: 0.1808  decode.d6.loss_mask: 0.2369  decode.d6.loss_dice: 0.2261  decode.d7.loss_cls: 0.1516  decode.d7.loss_mask: 0.2372  decode.d7.loss_dice: 0.2190  decode.d8.loss_cls: 0.1490  decode.d8.loss_mask: 0.2380  decode.d8.loss_dice: 0.2284
07/30 21:44:21 - mmengine - INFO - Iter(train) [41750/80000]  base_lr: 5.1475e-05 lr: 5.1475e-06  eta: 4:38:32  time: 0.4398  data_time: 0.0097  memory: 5265  grad_norm: 59.1446  loss: 7.3094  decode.loss_cls: 0.1662  decode.loss_mask: 0.2062  decode.loss_dice: 0.2640  decode.d0.loss_cls: 0.9746  decode.d0.loss_mask: 0.2125  decode.d0.loss_dice: 0.3045  decode.d1.loss_cls: 0.1876  decode.d1.loss_mask: 0.2086  decode.d1.loss_dice: 0.2743  decode.d2.loss_cls: 0.1736  decode.d2.loss_mask: 0.2220  decode.d2.loss_dice: 0.2765  decode.d3.loss_cls: 0.1667  decode.d3.loss_mask: 0.2141  decode.d3.loss_dice: 0.2806  decode.d4.loss_cls: 0.1397  decode.d4.loss_mask: 0.2103  decode.d4.loss_dice: 0.2909  decode.d5.loss_cls: 0.1043  decode.d5.loss_mask: 0.2137  decode.d5.loss_dice: 0.2813  decode.d6.loss_cls: 0.1451  decode.d6.loss_mask: 0.2066  decode.d6.loss_dice: 0.2908  decode.d7.loss_cls: 0.1514  decode.d7.loss_mask: 0.2086  decode.d7.loss_dice: 0.2898  decode.d8.loss_cls: 0.1548  decode.d8.loss_mask: 0.2113  decode.d8.loss_dice: 0.2790
07/30 21:44:43 - mmengine - INFO - Iter(train) [41800/80000]  base_lr: 5.1414e-05 lr: 5.1414e-06  eta: 4:38:11  time: 0.4402  data_time: 0.0100  memory: 5277  grad_norm: 198.8099  loss: 8.1584  decode.loss_cls: 0.2075  decode.loss_mask: 0.2832  decode.loss_dice: 0.2688  decode.d0.loss_cls: 0.9678  decode.d0.loss_mask: 0.3080  decode.d0.loss_dice: 0.2867  decode.d1.loss_cls: 0.2021  decode.d1.loss_mask: 0.2336  decode.d1.loss_dice: 0.2574  decode.d2.loss_cls: 0.2059  decode.d2.loss_mask: 0.2282  decode.d2.loss_dice: 0.2550  decode.d3.loss_cls: 0.1042  decode.d3.loss_mask: 0.2973  decode.d3.loss_dice: 0.2899  decode.d4.loss_cls: 0.1470  decode.d4.loss_mask: 0.2903  decode.d4.loss_dice: 0.2962  decode.d5.loss_cls: 0.1282  decode.d5.loss_mask: 0.2953  decode.d5.loss_dice: 0.2644  decode.d6.loss_cls: 0.1892  decode.d6.loss_mask: 0.3072  decode.d6.loss_dice: 0.3022  decode.d7.loss_cls: 0.2010  decode.d7.loss_mask: 0.3026  decode.d7.loss_dice: 0.2818  decode.d8.loss_cls: 0.2053  decode.d8.loss_mask: 0.2874  decode.d8.loss_dice: 0.2647
07/30 21:45:05 - mmengine - INFO - Iter(train) [41850/80000]  base_lr: 5.1353e-05 lr: 5.1353e-06  eta: 4:37:49  time: 0.4387  data_time: 0.0093  memory: 5277  grad_norm: 128.1590  loss: 7.6016  decode.loss_cls: 0.2424  decode.loss_mask: 0.1846  decode.loss_dice: 0.2535  decode.d0.loss_cls: 1.0990  decode.d0.loss_mask: 0.1944  decode.d0.loss_dice: 0.2835  decode.d1.loss_cls: 0.2693  decode.d1.loss_mask: 0.1892  decode.d1.loss_dice: 0.2622  decode.d2.loss_cls: 0.1937  decode.d2.loss_mask: 0.1869  decode.d2.loss_dice: 0.2471  decode.d3.loss_cls: 0.2322  decode.d3.loss_mask: 0.1873  decode.d3.loss_dice: 0.2482  decode.d4.loss_cls: 0.2264  decode.d4.loss_mask: 0.1875  decode.d4.loss_dice: 0.2535  decode.d5.loss_cls: 0.2641  decode.d5.loss_mask: 0.1887  decode.d5.loss_dice: 0.2533  decode.d6.loss_cls: 0.2167  decode.d6.loss_mask: 0.1864  decode.d6.loss_dice: 0.2552  decode.d7.loss_cls: 0.2188  decode.d7.loss_mask: 0.1860  decode.d7.loss_dice: 0.2422  decode.d8.loss_cls: 0.2106  decode.d8.loss_mask: 0.1853  decode.d8.loss_dice: 0.2533
07/30 21:45:27 - mmengine - INFO - Iter(train) [41900/80000]  base_lr: 5.1293e-05 lr: 5.1293e-06  eta: 4:37:27  time: 0.4393  data_time: 0.0092  memory: 5245  grad_norm: 29.6627  loss: 5.2926  decode.loss_cls: 0.0312  decode.loss_mask: 0.1641  decode.loss_dice: 0.2447  decode.d0.loss_cls: 0.9399  decode.d0.loss_mask: 0.1685  decode.d0.loss_dice: 0.2537  decode.d1.loss_cls: 0.0330  decode.d1.loss_mask: 0.1650  decode.d1.loss_dice: 0.2460  decode.d2.loss_cls: 0.0235  decode.d2.loss_mask: 0.1640  decode.d2.loss_dice: 0.2402  decode.d3.loss_cls: 0.0248  decode.d3.loss_mask: 0.1646  decode.d3.loss_dice: 0.2337  decode.d4.loss_cls: 0.0385  decode.d4.loss_mask: 0.1621  decode.d4.loss_dice: 0.2341  decode.d5.loss_cls: 0.0222  decode.d5.loss_mask: 0.1641  decode.d5.loss_dice: 0.2410  decode.d6.loss_cls: 0.0773  decode.d6.loss_mask: 0.1604  decode.d6.loss_dice: 0.2337  decode.d7.loss_cls: 0.0207  decode.d7.loss_mask: 0.1657  decode.d7.loss_dice: 0.2509  decode.d8.loss_cls: 0.0208  decode.d8.loss_mask: 0.1630  decode.d8.loss_dice: 0.2414
07/30 21:45:49 - mmengine - INFO - Iter(train) [41950/80000]  base_lr: 5.1232e-05 lr: 5.1232e-06  eta: 4:37:05  time: 0.4419  data_time: 0.0095  memory: 5265  grad_norm: 82.6673  loss: 8.6026  decode.loss_cls: 0.2120  decode.loss_mask: 0.2376  decode.loss_dice: 0.2789  decode.d0.loss_cls: 1.1789  decode.d0.loss_mask: 0.2435  decode.d0.loss_dice: 0.2854  decode.d1.loss_cls: 0.2736  decode.d1.loss_mask: 0.2369  decode.d1.loss_dice: 0.2624  decode.d2.loss_cls: 0.3224  decode.d2.loss_mask: 0.2361  decode.d2.loss_dice: 0.2718  decode.d3.loss_cls: 0.2982  decode.d3.loss_mask: 0.2360  decode.d3.loss_dice: 0.2561  decode.d4.loss_cls: 0.2524  decode.d4.loss_mask: 0.2404  decode.d4.loss_dice: 0.2733  decode.d5.loss_cls: 0.3035  decode.d5.loss_mask: 0.2371  decode.d5.loss_dice: 0.2603  decode.d6.loss_cls: 0.1792  decode.d6.loss_mask: 0.2878  decode.d6.loss_dice: 0.2838  decode.d7.loss_cls: 0.2145  decode.d7.loss_mask: 0.2418  decode.d7.loss_dice: 0.2699  decode.d8.loss_cls: 0.2354  decode.d8.loss_mask: 0.2372  decode.d8.loss_dice: 0.2564
07/30 21:46:11 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 21:46:11 - mmengine - INFO - Iter(train) [42000/80000]  base_lr: 5.1172e-05 lr: 5.1172e-06  eta: 4:36:44  time: 0.4393  data_time: 0.0096  memory: 5244  grad_norm: 46.0808  loss: 6.1861  decode.loss_cls: 0.1236  decode.loss_mask: 0.1895  decode.loss_dice: 0.2322  decode.d0.loss_cls: 0.9180  decode.d0.loss_mask: 0.1904  decode.d0.loss_dice: 0.2588  decode.d1.loss_cls: 0.1149  decode.d1.loss_mask: 0.1873  decode.d1.loss_dice: 0.2275  decode.d2.loss_cls: 0.1373  decode.d2.loss_mask: 0.1884  decode.d2.loss_dice: 0.2296  decode.d3.loss_cls: 0.1088  decode.d3.loss_mask: 0.1889  decode.d3.loss_dice: 0.2267  decode.d4.loss_cls: 0.1305  decode.d4.loss_mask: 0.1842  decode.d4.loss_dice: 0.2325  decode.d5.loss_cls: 0.1253  decode.d5.loss_mask: 0.1865  decode.d5.loss_dice: 0.2296  decode.d6.loss_cls: 0.1171  decode.d6.loss_mask: 0.1833  decode.d6.loss_dice: 0.2208  decode.d7.loss_cls: 0.1019  decode.d7.loss_mask: 0.1857  decode.d7.loss_dice: 0.2330  decode.d8.loss_cls: 0.1198  decode.d8.loss_mask: 0.1848  decode.d8.loss_dice: 0.2291
07/30 21:46:33 - mmengine - INFO - Iter(train) [42050/80000]  base_lr: 5.1111e-05 lr: 5.1111e-06  eta: 4:36:22  time: 0.4379  data_time: 0.0096  memory: 5246  grad_norm: 90.5775  loss: 8.2398  decode.loss_cls: 0.1856  decode.loss_mask: 0.2361  decode.loss_dice: 0.3221  decode.d0.loss_cls: 1.0144  decode.d0.loss_mask: 0.2401  decode.d0.loss_dice: 0.2903  decode.d1.loss_cls: 0.2688  decode.d1.loss_mask: 0.2357  decode.d1.loss_dice: 0.2893  decode.d2.loss_cls: 0.2078  decode.d2.loss_mask: 0.2330  decode.d2.loss_dice: 0.2730  decode.d3.loss_cls: 0.2984  decode.d3.loss_mask: 0.2332  decode.d3.loss_dice: 0.3048  decode.d4.loss_cls: 0.1873  decode.d4.loss_mask: 0.2359  decode.d4.loss_dice: 0.2803  decode.d5.loss_cls: 0.1922  decode.d5.loss_mask: 0.2379  decode.d5.loss_dice: 0.2888  decode.d6.loss_cls: 0.1875  decode.d6.loss_mask: 0.2353  decode.d6.loss_dice: 0.2729  decode.d7.loss_cls: 0.2450  decode.d7.loss_mask: 0.2327  decode.d7.loss_dice: 0.2924  decode.d8.loss_cls: 0.2021  decode.d8.loss_mask: 0.2370  decode.d8.loss_dice: 0.2799
07/30 21:46:55 - mmengine - INFO - Iter(train) [42100/80000]  base_lr: 5.1050e-05 lr: 5.1050e-06  eta: 4:36:00  time: 0.4381  data_time: 0.0096  memory: 5227  grad_norm: 90.3634  loss: 7.7337  decode.loss_cls: 0.1647  decode.loss_mask: 0.2206  decode.loss_dice: 0.3294  decode.d0.loss_cls: 0.8845  decode.d0.loss_mask: 0.2223  decode.d0.loss_dice: 0.3433  decode.d1.loss_cls: 0.1762  decode.d1.loss_mask: 0.2231  decode.d1.loss_dice: 0.3245  decode.d2.loss_cls: 0.1685  decode.d2.loss_mask: 0.2210  decode.d2.loss_dice: 0.3032  decode.d3.loss_cls: 0.0995  decode.d3.loss_mask: 0.2207  decode.d3.loss_dice: 0.3090  decode.d4.loss_cls: 0.1554  decode.d4.loss_mask: 0.2210  decode.d4.loss_dice: 0.3371  decode.d5.loss_cls: 0.1422  decode.d5.loss_mask: 0.2190  decode.d5.loss_dice: 0.3223  decode.d6.loss_cls: 0.1180  decode.d6.loss_mask: 0.2179  decode.d6.loss_dice: 0.3236  decode.d7.loss_cls: 0.1715  decode.d7.loss_mask: 0.2203  decode.d7.loss_dice: 0.3248  decode.d8.loss_cls: 0.1715  decode.d8.loss_mask: 0.2208  decode.d8.loss_dice: 0.3579
07/30 21:47:17 - mmengine - INFO - Iter(train) [42150/80000]  base_lr: 5.0990e-05 lr: 5.0990e-06  eta: 4:35:38  time: 0.4393  data_time: 0.0096  memory: 5277  grad_norm: 49.8763  loss: 6.0674  decode.loss_cls: 0.0286  decode.loss_mask: 0.2266  decode.loss_dice: 0.2393  decode.d0.loss_cls: 0.9565  decode.d0.loss_mask: 0.2303  decode.d0.loss_dice: 0.2382  decode.d1.loss_cls: 0.0801  decode.d1.loss_mask: 0.2251  decode.d1.loss_dice: 0.2333  decode.d2.loss_cls: 0.0485  decode.d2.loss_mask: 0.2311  decode.d2.loss_dice: 0.2346  decode.d3.loss_cls: 0.0486  decode.d3.loss_mask: 0.2274  decode.d3.loss_dice: 0.2346  decode.d4.loss_cls: 0.0897  decode.d4.loss_mask: 0.2281  decode.d4.loss_dice: 0.2390  decode.d5.loss_cls: 0.0443  decode.d5.loss_mask: 0.2294  decode.d5.loss_dice: 0.2408  decode.d6.loss_cls: 0.0411  decode.d6.loss_mask: 0.2286  decode.d6.loss_dice: 0.2332  decode.d7.loss_cls: 0.0463  decode.d7.loss_mask: 0.2299  decode.d7.loss_dice: 0.2324  decode.d8.loss_cls: 0.0409  decode.d8.loss_mask: 0.2268  decode.d8.loss_dice: 0.2340
07/30 21:47:39 - mmengine - INFO - Iter(train) [42200/80000]  base_lr: 5.0929e-05 lr: 5.0929e-06  eta: 4:35:17  time: 0.4380  data_time: 0.0096  memory: 5265  grad_norm: 157.1567  loss: 9.3519  decode.loss_cls: 0.3007  decode.loss_mask: 0.2537  decode.loss_dice: 0.2878  decode.d0.loss_cls: 1.0545  decode.d0.loss_mask: 0.2735  decode.d0.loss_dice: 0.3083  decode.d1.loss_cls: 0.3220  decode.d1.loss_mask: 0.2580  decode.d1.loss_dice: 0.2993  decode.d2.loss_cls: 0.2914  decode.d2.loss_mask: 0.2549  decode.d2.loss_dice: 0.2955  decode.d3.loss_cls: 0.3205  decode.d3.loss_mask: 0.2533  decode.d3.loss_dice: 0.2850  decode.d4.loss_cls: 0.2960  decode.d4.loss_mask: 0.2674  decode.d4.loss_dice: 0.2839  decode.d5.loss_cls: 0.2993  decode.d5.loss_mask: 0.2572  decode.d5.loss_dice: 0.2770  decode.d6.loss_cls: 0.2981  decode.d6.loss_mask: 0.2655  decode.d6.loss_dice: 0.3049  decode.d7.loss_cls: 0.3217  decode.d7.loss_mask: 0.2532  decode.d7.loss_dice: 0.2955  decode.d8.loss_cls: 0.3267  decode.d8.loss_mask: 0.2532  decode.d8.loss_dice: 0.2937
07/30 21:48:01 - mmengine - INFO - Iter(train) [42250/80000]  base_lr: 5.0869e-05 lr: 5.0869e-06  eta: 4:34:55  time: 0.4376  data_time: 0.0097  memory: 5279  grad_norm: 122.3373  loss: 8.0725  decode.loss_cls: 0.1683  decode.loss_mask: 0.2908  decode.loss_dice: 0.2869  decode.d0.loss_cls: 0.9903  decode.d0.loss_mask: 0.3111  decode.d0.loss_dice: 0.2916  decode.d1.loss_cls: 0.1705  decode.d1.loss_mask: 0.2861  decode.d1.loss_dice: 0.2847  decode.d2.loss_cls: 0.1407  decode.d2.loss_mask: 0.2852  decode.d2.loss_dice: 0.3019  decode.d3.loss_cls: 0.1715  decode.d3.loss_mask: 0.2850  decode.d3.loss_dice: 0.2828  decode.d4.loss_cls: 0.1146  decode.d4.loss_mask: 0.2876  decode.d4.loss_dice: 0.2915  decode.d5.loss_cls: 0.1161  decode.d5.loss_mask: 0.2873  decode.d5.loss_dice: 0.2711  decode.d6.loss_cls: 0.1433  decode.d6.loss_mask: 0.2841  decode.d6.loss_dice: 0.2988  decode.d7.loss_cls: 0.1508  decode.d7.loss_mask: 0.2874  decode.d7.loss_dice: 0.2892  decode.d8.loss_cls: 0.1215  decode.d8.loss_mask: 0.2834  decode.d8.loss_dice: 0.2984
07/30 21:48:22 - mmengine - INFO - Iter(train) [42300/80000]  base_lr: 5.0808e-05 lr: 5.0808e-06  eta: 4:34:33  time: 0.4369  data_time: 0.0097  memory: 5246  grad_norm: 73.6927  loss: 7.4075  decode.loss_cls: 0.1163  decode.loss_mask: 0.2419  decode.loss_dice: 0.2583  decode.d0.loss_cls: 0.9564  decode.d0.loss_mask: 0.2395  decode.d0.loss_dice: 0.2849  decode.d1.loss_cls: 0.1695  decode.d1.loss_mask: 0.2384  decode.d1.loss_dice: 0.2762  decode.d2.loss_cls: 0.2008  decode.d2.loss_mask: 0.2284  decode.d2.loss_dice: 0.2509  decode.d3.loss_cls: 0.1421  decode.d3.loss_mask: 0.2440  decode.d3.loss_dice: 0.2698  decode.d4.loss_cls: 0.1438  decode.d4.loss_mask: 0.2504  decode.d4.loss_dice: 0.2705  decode.d5.loss_cls: 0.1558  decode.d5.loss_mask: 0.2488  decode.d5.loss_dice: 0.2626  decode.d6.loss_cls: 0.1348  decode.d6.loss_mask: 0.2508  decode.d6.loss_dice: 0.2585  decode.d7.loss_cls: 0.1387  decode.d7.loss_mask: 0.2500  decode.d7.loss_dice: 0.2563  decode.d8.loss_cls: 0.1961  decode.d8.loss_mask: 0.2356  decode.d8.loss_dice: 0.2374
07/30 21:48:44 - mmengine - INFO - Iter(train) [42350/80000]  base_lr: 5.0747e-05 lr: 5.0747e-06  eta: 4:34:11  time: 0.4390  data_time: 0.0097  memory: 5265  grad_norm: 68.2726  loss: 6.8328  decode.loss_cls: 0.0662  decode.loss_mask: 0.2670  decode.loss_dice: 0.2541  decode.d0.loss_cls: 0.8268  decode.d0.loss_mask: 0.2692  decode.d0.loss_dice: 0.2596  decode.d1.loss_cls: 0.1078  decode.d1.loss_mask: 0.2695  decode.d1.loss_dice: 0.2564  decode.d2.loss_cls: 0.0484  decode.d2.loss_mask: 0.2669  decode.d2.loss_dice: 0.2508  decode.d3.loss_cls: 0.0699  decode.d3.loss_mask: 0.2667  decode.d3.loss_dice: 0.2510  decode.d4.loss_cls: 0.0487  decode.d4.loss_mask: 0.2664  decode.d4.loss_dice: 0.2558  decode.d5.loss_cls: 0.0702  decode.d5.loss_mask: 0.2660  decode.d5.loss_dice: 0.2777  decode.d6.loss_cls: 0.1652  decode.d6.loss_mask: 0.2672  decode.d6.loss_dice: 0.2420  decode.d7.loss_cls: 0.1275  decode.d7.loss_mask: 0.2691  decode.d7.loss_dice: 0.2531  decode.d8.loss_cls: 0.0744  decode.d8.loss_mask: 0.2665  decode.d8.loss_dice: 0.2526
07/30 21:49:06 - mmengine - INFO - Iter(train) [42400/80000]  base_lr: 5.0687e-05 lr: 5.0687e-06  eta: 4:33:50  time: 0.4399  data_time: 0.0097  memory: 5261  grad_norm: 56.7774  loss: 5.7944  decode.loss_cls: 0.0633  decode.loss_mask: 0.2010  decode.loss_dice: 0.2168  decode.d0.loss_cls: 1.0218  decode.d0.loss_mask: 0.1985  decode.d0.loss_dice: 0.2042  decode.d1.loss_cls: 0.1272  decode.d1.loss_mask: 0.2047  decode.d1.loss_dice: 0.2224  decode.d2.loss_cls: 0.1005  decode.d2.loss_mask: 0.2011  decode.d2.loss_dice: 0.2017  decode.d3.loss_cls: 0.0636  decode.d3.loss_mask: 0.2001  decode.d3.loss_dice: 0.2157  decode.d4.loss_cls: 0.0648  decode.d4.loss_mask: 0.2000  decode.d4.loss_dice: 0.2046  decode.d5.loss_cls: 0.0596  decode.d5.loss_mask: 0.2018  decode.d5.loss_dice: 0.2031  decode.d6.loss_cls: 0.0548  decode.d6.loss_mask: 0.1971  decode.d6.loss_dice: 0.2115  decode.d7.loss_cls: 0.0722  decode.d7.loss_mask: 0.1977  decode.d7.loss_dice: 0.2005  decode.d8.loss_cls: 0.0682  decode.d8.loss_mask: 0.1984  decode.d8.loss_dice: 0.2175
07/30 21:49:28 - mmengine - INFO - Iter(train) [42450/80000]  base_lr: 5.0626e-05 lr: 5.0626e-06  eta: 4:33:28  time: 0.4387  data_time: 0.0095  memory: 5265  grad_norm: 64.5534  loss: 6.8459  decode.loss_cls: 0.1131  decode.loss_mask: 0.2161  decode.loss_dice: 0.2573  decode.d0.loss_cls: 0.8341  decode.d0.loss_mask: 0.2155  decode.d0.loss_dice: 0.2687  decode.d1.loss_cls: 0.1931  decode.d1.loss_mask: 0.2172  decode.d1.loss_dice: 0.2794  decode.d2.loss_cls: 0.1947  decode.d2.loss_mask: 0.2167  decode.d2.loss_dice: 0.2371  decode.d3.loss_cls: 0.1670  decode.d3.loss_mask: 0.2145  decode.d3.loss_dice: 0.2592  decode.d4.loss_cls: 0.1754  decode.d4.loss_mask: 0.2143  decode.d4.loss_dice: 0.2456  decode.d5.loss_cls: 0.1509  decode.d5.loss_mask: 0.2134  decode.d5.loss_dice: 0.2294  decode.d6.loss_cls: 0.1099  decode.d6.loss_mask: 0.2163  decode.d6.loss_dice: 0.2358  decode.d7.loss_cls: 0.1318  decode.d7.loss_mask: 0.2139  decode.d7.loss_dice: 0.2545  decode.d8.loss_cls: 0.1122  decode.d8.loss_mask: 0.2132  decode.d8.loss_dice: 0.2453
07/30 21:49:50 - mmengine - INFO - Iter(train) [42500/80000]  base_lr: 5.0565e-05 lr: 5.0565e-06  eta: 4:33:06  time: 0.4386  data_time: 0.0095  memory: 5277  grad_norm: 47.7861  loss: 7.0771  decode.loss_cls: 0.0334  decode.loss_mask: 0.3227  decode.loss_dice: 0.2927  decode.d0.loss_cls: 0.9522  decode.d0.loss_mask: 0.2436  decode.d0.loss_dice: 0.2672  decode.d1.loss_cls: 0.0942  decode.d1.loss_mask: 0.2400  decode.d1.loss_dice: 0.2688  decode.d2.loss_cls: 0.1341  decode.d2.loss_mask: 0.2301  decode.d2.loss_dice: 0.2647  decode.d3.loss_cls: 0.1140  decode.d3.loss_mask: 0.2296  decode.d3.loss_dice: 0.2566  decode.d4.loss_cls: 0.1028  decode.d4.loss_mask: 0.2301  decode.d4.loss_dice: 0.2654  decode.d5.loss_cls: 0.0944  decode.d5.loss_mask: 0.2278  decode.d5.loss_dice: 0.2622  decode.d6.loss_cls: 0.1203  decode.d6.loss_mask: 0.2311  decode.d6.loss_dice: 0.2771  decode.d7.loss_cls: 0.1247  decode.d7.loss_mask: 0.2371  decode.d7.loss_dice: 0.2718  decode.d8.loss_cls: 0.1386  decode.d8.loss_mask: 0.2654  decode.d8.loss_dice: 0.2843
07/30 21:50:12 - mmengine - INFO - Iter(train) [42550/80000]  base_lr: 5.0505e-05 lr: 5.0505e-06  eta: 4:32:44  time: 0.4397  data_time: 0.0096  memory: 5277  grad_norm: 56.9867  loss: 5.8563  decode.loss_cls: 0.0704  decode.loss_mask: 0.1979  decode.loss_dice: 0.2301  decode.d0.loss_cls: 0.8629  decode.d0.loss_mask: 0.2103  decode.d0.loss_dice: 0.2518  decode.d1.loss_cls: 0.0902  decode.d1.loss_mask: 0.1988  decode.d1.loss_dice: 0.2309  decode.d2.loss_cls: 0.0637  decode.d2.loss_mask: 0.2043  decode.d2.loss_dice: 0.2434  decode.d3.loss_cls: 0.0652  decode.d3.loss_mask: 0.1957  decode.d3.loss_dice: 0.2270  decode.d4.loss_cls: 0.0561  decode.d4.loss_mask: 0.1994  decode.d4.loss_dice: 0.2487  decode.d5.loss_cls: 0.0877  decode.d5.loss_mask: 0.1987  decode.d5.loss_dice: 0.2330  decode.d6.loss_cls: 0.0759  decode.d6.loss_mask: 0.1973  decode.d6.loss_dice: 0.2326  decode.d7.loss_cls: 0.0724  decode.d7.loss_mask: 0.1949  decode.d7.loss_dice: 0.2268  decode.d8.loss_cls: 0.0551  decode.d8.loss_mask: 0.1967  decode.d8.loss_dice: 0.2386
07/30 21:50:34 - mmengine - INFO - Iter(train) [42600/80000]  base_lr: 5.0444e-05 lr: 5.0444e-06  eta: 4:32:23  time: 0.4394  data_time: 0.0097  memory: 5244  grad_norm: 51.8717  loss: 7.2854  decode.loss_cls: 0.1976  decode.loss_mask: 0.2445  decode.loss_dice: 0.2547  decode.d0.loss_cls: 0.8631  decode.d0.loss_mask: 0.2489  decode.d0.loss_dice: 0.2497  decode.d1.loss_cls: 0.2437  decode.d1.loss_mask: 0.2442  decode.d1.loss_dice: 0.2416  decode.d2.loss_cls: 0.1354  decode.d2.loss_mask: 0.2466  decode.d2.loss_dice: 0.2524  decode.d3.loss_cls: 0.1224  decode.d3.loss_mask: 0.2433  decode.d3.loss_dice: 0.2532  decode.d4.loss_cls: 0.1507  decode.d4.loss_mask: 0.2464  decode.d4.loss_dice: 0.2507  decode.d5.loss_cls: 0.1502  decode.d5.loss_mask: 0.2470  decode.d5.loss_dice: 0.2489  decode.d6.loss_cls: 0.1330  decode.d6.loss_mask: 0.2411  decode.d6.loss_dice: 0.2462  decode.d7.loss_cls: 0.1921  decode.d7.loss_mask: 0.2447  decode.d7.loss_dice: 0.2440  decode.d8.loss_cls: 0.1450  decode.d8.loss_mask: 0.2454  decode.d8.loss_dice: 0.2589
07/30 21:50:56 - mmengine - INFO - Iter(train) [42650/80000]  base_lr: 5.0383e-05 lr: 5.0383e-06  eta: 4:32:01  time: 0.4388  data_time: 0.0096  memory: 5261  grad_norm: 50.4217  loss: 6.8396  decode.loss_cls: 0.1101  decode.loss_mask: 0.2248  decode.loss_dice: 0.2579  decode.d0.loss_cls: 1.0224  decode.d0.loss_mask: 0.2153  decode.d0.loss_dice: 0.2556  decode.d1.loss_cls: 0.1197  decode.d1.loss_mask: 0.2290  decode.d1.loss_dice: 0.2833  decode.d2.loss_cls: 0.1821  decode.d2.loss_mask: 0.2219  decode.d2.loss_dice: 0.2464  decode.d3.loss_cls: 0.1240  decode.d3.loss_mask: 0.2232  decode.d3.loss_dice: 0.2663  decode.d4.loss_cls: 0.0959  decode.d4.loss_mask: 0.2174  decode.d4.loss_dice: 0.2427  decode.d5.loss_cls: 0.0829  decode.d5.loss_mask: 0.2183  decode.d5.loss_dice: 0.2379  decode.d6.loss_cls: 0.0834  decode.d6.loss_mask: 0.2183  decode.d6.loss_dice: 0.2595  decode.d7.loss_cls: 0.1364  decode.d7.loss_mask: 0.2173  decode.d7.loss_dice: 0.2523  decode.d8.loss_cls: 0.1083  decode.d8.loss_mask: 0.2153  decode.d8.loss_dice: 0.2720
07/30 21:51:18 - mmengine - INFO - Iter(train) [42700/80000]  base_lr: 5.0322e-05 lr: 5.0322e-06  eta: 4:31:39  time: 0.4389  data_time: 0.0097  memory: 5227  grad_norm: 42.8307  loss: 5.9833  decode.loss_cls: 0.0369  decode.loss_mask: 0.2215  decode.loss_dice: 0.2671  decode.d0.loss_cls: 0.8393  decode.d0.loss_mask: 0.2219  decode.d0.loss_dice: 0.2360  decode.d1.loss_cls: 0.0790  decode.d1.loss_mask: 0.2192  decode.d1.loss_dice: 0.2552  decode.d2.loss_cls: 0.0359  decode.d2.loss_mask: 0.2199  decode.d2.loss_dice: 0.2611  decode.d3.loss_cls: 0.0407  decode.d3.loss_mask: 0.2204  decode.d3.loss_dice: 0.2444  decode.d4.loss_cls: 0.0383  decode.d4.loss_mask: 0.2213  decode.d4.loss_dice: 0.2365  decode.d5.loss_cls: 0.0427  decode.d5.loss_mask: 0.2199  decode.d5.loss_dice: 0.2578  decode.d6.loss_cls: 0.0411  decode.d6.loss_mask: 0.2217  decode.d6.loss_dice: 0.2644  decode.d7.loss_cls: 0.0364  decode.d7.loss_mask: 0.2188  decode.d7.loss_dice: 0.2552  decode.d8.loss_cls: 0.0642  decode.d8.loss_mask: 0.2200  decode.d8.loss_dice: 0.2465
07/30 21:51:40 - mmengine - INFO - Iter(train) [42750/80000]  base_lr: 5.0262e-05 lr: 5.0262e-06  eta: 4:31:17  time: 0.4398  data_time: 0.0096  memory: 5265  grad_norm: 89.0156  loss: 8.0886  decode.loss_cls: 0.1188  decode.loss_mask: 0.3074  decode.loss_dice: 0.2868  decode.d0.loss_cls: 0.9212  decode.d0.loss_mask: 0.3085  decode.d0.loss_dice: 0.3189  decode.d1.loss_cls: 0.1791  decode.d1.loss_mask: 0.3021  decode.d1.loss_dice: 0.2894  decode.d2.loss_cls: 0.1636  decode.d2.loss_mask: 0.3055  decode.d2.loss_dice: 0.3016  decode.d3.loss_cls: 0.1217  decode.d3.loss_mask: 0.3062  decode.d3.loss_dice: 0.3144  decode.d4.loss_cls: 0.0988  decode.d4.loss_mask: 0.3100  decode.d4.loss_dice: 0.2976  decode.d5.loss_cls: 0.1224  decode.d5.loss_mask: 0.3097  decode.d5.loss_dice: 0.2999  decode.d6.loss_cls: 0.1211  decode.d6.loss_mask: 0.3044  decode.d6.loss_dice: 0.2777  decode.d7.loss_cls: 0.1062  decode.d7.loss_mask: 0.3104  decode.d7.loss_dice: 0.2893  decode.d8.loss_cls: 0.1049  decode.d8.loss_mask: 0.3028  decode.d8.loss_dice: 0.2883
07/30 21:52:02 - mmengine - INFO - Iter(train) [42800/80000]  base_lr: 5.0201e-05 lr: 5.0201e-06  eta: 4:30:55  time: 0.4393  data_time: 0.0101  memory: 5261  grad_norm: 50.6031  loss: 6.7961  decode.loss_cls: 0.0943  decode.loss_mask: 0.2883  decode.loss_dice: 0.2275  decode.d0.loss_cls: 0.9465  decode.d0.loss_mask: 0.2866  decode.d0.loss_dice: 0.2285  decode.d1.loss_cls: 0.0852  decode.d1.loss_mask: 0.2861  decode.d1.loss_dice: 0.2324  decode.d2.loss_cls: 0.0940  decode.d2.loss_mask: 0.2841  decode.d2.loss_dice: 0.2213  decode.d3.loss_cls: 0.0745  decode.d3.loss_mask: 0.2865  decode.d3.loss_dice: 0.2198  decode.d4.loss_cls: 0.0778  decode.d4.loss_mask: 0.2873  decode.d4.loss_dice: 0.2181  decode.d5.loss_cls: 0.0779  decode.d5.loss_mask: 0.2859  decode.d5.loss_dice: 0.2220  decode.d6.loss_cls: 0.0813  decode.d6.loss_mask: 0.2883  decode.d6.loss_dice: 0.2282  decode.d7.loss_cls: 0.0769  decode.d7.loss_mask: 0.2863  decode.d7.loss_dice: 0.2243  decode.d8.loss_cls: 0.0827  decode.d8.loss_mask: 0.2836  decode.d8.loss_dice: 0.2200
07/30 21:52:24 - mmengine - INFO - Iter(train) [42850/80000]  base_lr: 5.0140e-05 lr: 5.0140e-06  eta: 4:30:34  time: 0.4388  data_time: 0.0096  memory: 5265  grad_norm: 45.3863  loss: 7.4783  decode.loss_cls: 0.1028  decode.loss_mask: 0.3003  decode.loss_dice: 0.2845  decode.d0.loss_cls: 0.8382  decode.d0.loss_mask: 0.3132  decode.d0.loss_dice: 0.3027  decode.d1.loss_cls: 0.0566  decode.d1.loss_mask: 0.2995  decode.d1.loss_dice: 0.2924  decode.d2.loss_cls: 0.0609  decode.d2.loss_mask: 0.3032  decode.d2.loss_dice: 0.2962  decode.d3.loss_cls: 0.1290  decode.d3.loss_mask: 0.3008  decode.d3.loss_dice: 0.2904  decode.d4.loss_cls: 0.1277  decode.d4.loss_mask: 0.3001  decode.d4.loss_dice: 0.2849  decode.d5.loss_cls: 0.0328  decode.d5.loss_mask: 0.3074  decode.d5.loss_dice: 0.3171  decode.d6.loss_cls: 0.0505  decode.d6.loss_mask: 0.3061  decode.d6.loss_dice: 0.2921  decode.d7.loss_cls: 0.0457  decode.d7.loss_mask: 0.3044  decode.d7.loss_dice: 0.2948  decode.d8.loss_cls: 0.0452  decode.d8.loss_mask: 0.3069  decode.d8.loss_dice: 0.2921
07/30 21:52:46 - mmengine - INFO - Iter(train) [42900/80000]  base_lr: 5.0080e-05 lr: 5.0080e-06  eta: 4:30:12  time: 0.4394  data_time: 0.0095  memory: 5279  grad_norm: 89.1615  loss: 7.3866  decode.loss_cls: 0.1036  decode.loss_mask: 0.2534  decode.loss_dice: 0.3013  decode.d0.loss_cls: 0.9113  decode.d0.loss_mask: 0.2740  decode.d0.loss_dice: 0.3093  decode.d1.loss_cls: 0.1020  decode.d1.loss_mask: 0.2574  decode.d1.loss_dice: 0.3084  decode.d2.loss_cls: 0.0925  decode.d2.loss_mask: 0.2551  decode.d2.loss_dice: 0.3007  decode.d3.loss_cls: 0.0896  decode.d3.loss_mask: 0.2535  decode.d3.loss_dice: 0.2962  decode.d4.loss_cls: 0.1351  decode.d4.loss_mask: 0.2533  decode.d4.loss_dice: 0.2858  decode.d5.loss_cls: 0.0990  decode.d5.loss_mask: 0.2541  decode.d5.loss_dice: 0.2926  decode.d6.loss_cls: 0.1186  decode.d6.loss_mask: 0.2553  decode.d6.loss_dice: 0.2931  decode.d7.loss_cls: 0.1110  decode.d7.loss_mask: 0.2528  decode.d7.loss_dice: 0.2873  decode.d8.loss_cls: 0.0996  decode.d8.loss_mask: 0.2520  decode.d8.loss_dice: 0.2885
07/30 21:53:08 - mmengine - INFO - Iter(train) [42950/80000]  base_lr: 5.0019e-05 lr: 5.0019e-06  eta: 4:29:50  time: 0.4387  data_time: 0.0095  memory: 5246  grad_norm: 47.7487  loss: 8.3143  decode.loss_cls: 0.1664  decode.loss_mask: 0.2902  decode.loss_dice: 0.2821  decode.d0.loss_cls: 0.9675  decode.d0.loss_mask: 0.2813  decode.d0.loss_dice: 0.2901  decode.d1.loss_cls: 0.2048  decode.d1.loss_mask: 0.2732  decode.d1.loss_dice: 0.2900  decode.d2.loss_cls: 0.1779  decode.d2.loss_mask: 0.2898  decode.d2.loss_dice: 0.2924  decode.d3.loss_cls: 0.1774  decode.d3.loss_mask: 0.2866  decode.d3.loss_dice: 0.2947  decode.d4.loss_cls: 0.1805  decode.d4.loss_mask: 0.3029  decode.d4.loss_dice: 0.2800  decode.d5.loss_cls: 0.1698  decode.d5.loss_mask: 0.2927  decode.d5.loss_dice: 0.2923  decode.d6.loss_cls: 0.1641  decode.d6.loss_mask: 0.2910  decode.d6.loss_dice: 0.2844  decode.d7.loss_cls: 0.1543  decode.d7.loss_mask: 0.2922  decode.d7.loss_dice: 0.2865  decode.d8.loss_cls: 0.1698  decode.d8.loss_mask: 0.3047  decode.d8.loss_dice: 0.2847
07/30 21:53:30 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 21:53:30 - mmengine - INFO - Iter(train) [43000/80000]  base_lr: 4.9958e-05 lr: 4.9958e-06  eta: 4:29:28  time: 0.4398  data_time: 0.0096  memory: 5279  grad_norm: 80.4472  loss: 5.9762  decode.loss_cls: 0.0326  decode.loss_mask: 0.2316  decode.loss_dice: 0.2353  decode.d0.loss_cls: 0.9136  decode.d0.loss_mask: 0.2414  decode.d0.loss_dice: 0.2393  decode.d1.loss_cls: 0.0707  decode.d1.loss_mask: 0.2297  decode.d1.loss_dice: 0.2357  decode.d2.loss_cls: 0.0702  decode.d2.loss_mask: 0.2290  decode.d2.loss_dice: 0.2351  decode.d3.loss_cls: 0.0604  decode.d3.loss_mask: 0.2275  decode.d3.loss_dice: 0.2304  decode.d4.loss_cls: 0.0555  decode.d4.loss_mask: 0.2264  decode.d4.loss_dice: 0.2345  decode.d5.loss_cls: 0.0349  decode.d5.loss_mask: 0.2249  decode.d5.loss_dice: 0.2385  decode.d6.loss_cls: 0.0301  decode.d6.loss_mask: 0.2273  decode.d6.loss_dice: 0.2341  decode.d7.loss_cls: 0.0288  decode.d7.loss_mask: 0.2314  decode.d7.loss_dice: 0.2444  decode.d8.loss_cls: 0.0315  decode.d8.loss_mask: 0.2275  decode.d8.loss_dice: 0.2242
07/30 21:53:52 - mmengine - INFO - Iter(train) [43050/80000]  base_lr: 4.9897e-05 lr: 4.9897e-06  eta: 4:29:07  time: 0.4380  data_time: 0.0096  memory: 5244  grad_norm: 51.1510  loss: 6.2471  decode.loss_cls: 0.1019  decode.loss_mask: 0.1871  decode.loss_dice: 0.2135  decode.d0.loss_cls: 1.0576  decode.d0.loss_mask: 0.1935  decode.d0.loss_dice: 0.2213  decode.d1.loss_cls: 0.1147  decode.d1.loss_mask: 0.1919  decode.d1.loss_dice: 0.2260  decode.d2.loss_cls: 0.1404  decode.d2.loss_mask: 0.1906  decode.d2.loss_dice: 0.2139  decode.d3.loss_cls: 0.1574  decode.d3.loss_mask: 0.1888  decode.d3.loss_dice: 0.2141  decode.d4.loss_cls: 0.1531  decode.d4.loss_mask: 0.1880  decode.d4.loss_dice: 0.2117  decode.d5.loss_cls: 0.1596  decode.d5.loss_mask: 0.1900  decode.d5.loss_dice: 0.2169  decode.d6.loss_cls: 0.1182  decode.d6.loss_mask: 0.1876  decode.d6.loss_dice: 0.2091  decode.d7.loss_cls: 0.0976  decode.d7.loss_mask: 0.1892  decode.d7.loss_dice: 0.2153  decode.d8.loss_cls: 0.0979  decode.d8.loss_mask: 0.1880  decode.d8.loss_dice: 0.2120
07/30 21:54:14 - mmengine - INFO - Iter(train) [43100/80000]  base_lr: 4.9837e-05 lr: 4.9837e-06  eta: 4:28:45  time: 0.4385  data_time: 0.0097  memory: 5278  grad_norm: 99.1037  loss: 7.3412  decode.loss_cls: 0.0639  decode.loss_mask: 0.2861  decode.loss_dice: 0.2546  decode.d0.loss_cls: 0.9129  decode.d0.loss_mask: 0.2954  decode.d0.loss_dice: 0.2785  decode.d1.loss_cls: 0.1542  decode.d1.loss_mask: 0.2894  decode.d1.loss_dice: 0.2620  decode.d2.loss_cls: 0.1161  decode.d2.loss_mask: 0.2853  decode.d2.loss_dice: 0.2514  decode.d3.loss_cls: 0.1304  decode.d3.loss_mask: 0.2841  decode.d3.loss_dice: 0.2617  decode.d4.loss_cls: 0.1320  decode.d4.loss_mask: 0.2843  decode.d4.loss_dice: 0.2562  decode.d5.loss_cls: 0.1180  decode.d5.loss_mask: 0.2867  decode.d5.loss_dice: 0.2525  decode.d6.loss_cls: 0.0922  decode.d6.loss_mask: 0.2852  decode.d6.loss_dice: 0.2561  decode.d7.loss_cls: 0.0922  decode.d7.loss_mask: 0.2851  decode.d7.loss_dice: 0.2521  decode.d8.loss_cls: 0.0801  decode.d8.loss_mask: 0.2873  decode.d8.loss_dice: 0.2551
07/30 21:54:36 - mmengine - INFO - Iter(train) [43150/80000]  base_lr: 4.9776e-05 lr: 4.9776e-06  eta: 4:28:23  time: 0.4416  data_time: 0.0099  memory: 5246  grad_norm: 32.6162  loss: 7.2251  decode.loss_cls: 0.1399  decode.loss_mask: 0.2218  decode.loss_dice: 0.2737  decode.d0.loss_cls: 0.9499  decode.d0.loss_mask: 0.2284  decode.d0.loss_dice: 0.2777  decode.d1.loss_cls: 0.1810  decode.d1.loss_mask: 0.2244  decode.d1.loss_dice: 0.2699  decode.d2.loss_cls: 0.2164  decode.d2.loss_mask: 0.2205  decode.d2.loss_dice: 0.2517  decode.d3.loss_cls: 0.1377  decode.d3.loss_mask: 0.2220  decode.d3.loss_dice: 0.2774  decode.d4.loss_cls: 0.1385  decode.d4.loss_mask: 0.2238  decode.d4.loss_dice: 0.2769  decode.d5.loss_cls: 0.1362  decode.d5.loss_mask: 0.2202  decode.d5.loss_dice: 0.2877  decode.d6.loss_cls: 0.1134  decode.d6.loss_mask: 0.2269  decode.d6.loss_dice: 0.2828  decode.d7.loss_cls: 0.1267  decode.d7.loss_mask: 0.2261  decode.d7.loss_dice: 0.2788  decode.d8.loss_cls: 0.0995  decode.d8.loss_mask: 0.2266  decode.d8.loss_dice: 0.2687
07/30 21:54:58 - mmengine - INFO - Iter(train) [43200/80000]  base_lr: 4.9715e-05 lr: 4.9715e-06  eta: 4:28:01  time: 0.4388  data_time: 0.0098  memory: 5229  grad_norm: 84.7895  loss: 7.5293  decode.loss_cls: 0.1927  decode.loss_mask: 0.2503  decode.loss_dice: 0.2571  decode.d0.loss_cls: 0.9190  decode.d0.loss_mask: 0.2507  decode.d0.loss_dice: 0.2399  decode.d1.loss_cls: 0.1436  decode.d1.loss_mask: 0.2488  decode.d1.loss_dice: 0.2404  decode.d2.loss_cls: 0.1955  decode.d2.loss_mask: 0.2474  decode.d2.loss_dice: 0.2481  decode.d3.loss_cls: 0.1830  decode.d3.loss_mask: 0.2473  decode.d3.loss_dice: 0.2291  decode.d4.loss_cls: 0.2186  decode.d4.loss_mask: 0.2492  decode.d4.loss_dice: 0.2425  decode.d5.loss_cls: 0.2007  decode.d5.loss_mask: 0.2469  decode.d5.loss_dice: 0.2399  decode.d6.loss_cls: 0.1932  decode.d6.loss_mask: 0.2506  decode.d6.loss_dice: 0.2392  decode.d7.loss_cls: 0.1739  decode.d7.loss_mask: 0.2499  decode.d7.loss_dice: 0.2416  decode.d8.loss_cls: 0.1723  decode.d8.loss_mask: 0.2509  decode.d8.loss_dice: 0.2670
07/30 21:55:20 - mmengine - INFO - Iter(train) [43250/80000]  base_lr: 4.9654e-05 lr: 4.9654e-06  eta: 4:27:40  time: 0.4388  data_time: 0.0097  memory: 5245  grad_norm: 96.4175  loss: 9.0514  decode.loss_cls: 0.2158  decode.loss_mask: 0.2709  decode.loss_dice: 0.3336  decode.d0.loss_cls: 1.0601  decode.d0.loss_mask: 0.2585  decode.d0.loss_dice: 0.3403  decode.d1.loss_cls: 0.2345  decode.d1.loss_mask: 0.2796  decode.d1.loss_dice: 0.3518  decode.d2.loss_cls: 0.1712  decode.d2.loss_mask: 0.2710  decode.d2.loss_dice: 0.3696  decode.d3.loss_cls: 0.1960  decode.d3.loss_mask: 0.2554  decode.d3.loss_dice: 0.3163  decode.d4.loss_cls: 0.2008  decode.d4.loss_mask: 0.2853  decode.d4.loss_dice: 0.3640  decode.d5.loss_cls: 0.2201  decode.d5.loss_mask: 0.2844  decode.d5.loss_dice: 0.3334  decode.d6.loss_cls: 0.2002  decode.d6.loss_mask: 0.2612  decode.d6.loss_dice: 0.3286  decode.d7.loss_cls: 0.2420  decode.d7.loss_mask: 0.2708  decode.d7.loss_dice: 0.3303  decode.d8.loss_cls: 0.2018  decode.d8.loss_mask: 0.2675  decode.d8.loss_dice: 0.3364
07/30 21:55:41 - mmengine - INFO - Iter(train) [43300/80000]  base_lr: 4.9593e-05 lr: 4.9593e-06  eta: 4:27:18  time: 0.4381  data_time: 0.0098  memory: 5277  grad_norm: 52.9390  loss: 6.9462  decode.loss_cls: 0.0712  decode.loss_mask: 0.2673  decode.loss_dice: 0.2835  decode.d0.loss_cls: 0.8613  decode.d0.loss_mask: 0.2783  decode.d0.loss_dice: 0.2740  decode.d1.loss_cls: 0.0749  decode.d1.loss_mask: 0.2688  decode.d1.loss_dice: 0.2801  decode.d2.loss_cls: 0.0893  decode.d2.loss_mask: 0.2670  decode.d2.loss_dice: 0.2752  decode.d3.loss_cls: 0.0609  decode.d3.loss_mask: 0.2716  decode.d3.loss_dice: 0.2848  decode.d4.loss_cls: 0.0588  decode.d4.loss_mask: 0.2679  decode.d4.loss_dice: 0.2773  decode.d5.loss_cls: 0.0556  decode.d5.loss_mask: 0.2668  decode.d5.loss_dice: 0.2790  decode.d6.loss_cls: 0.0594  decode.d6.loss_mask: 0.2678  decode.d6.loss_dice: 0.2772  decode.d7.loss_cls: 0.0793  decode.d7.loss_mask: 0.2653  decode.d7.loss_dice: 0.2769  decode.d8.loss_cls: 0.0655  decode.d8.loss_mask: 0.2672  decode.d8.loss_dice: 0.2743
07/30 21:56:03 - mmengine - INFO - Iter(train) [43350/80000]  base_lr: 4.9533e-05 lr: 4.9533e-06  eta: 4:26:56  time: 0.4398  data_time: 0.0097  memory: 5279  grad_norm: 31.1243  loss: 5.1476  decode.loss_cls: 0.0628  decode.loss_mask: 0.1644  decode.loss_dice: 0.1897  decode.d0.loss_cls: 0.9484  decode.d0.loss_mask: 0.1667  decode.d0.loss_dice: 0.1716  decode.d1.loss_cls: 0.1110  decode.d1.loss_mask: 0.1644  decode.d1.loss_dice: 0.2156  decode.d2.loss_cls: 0.0919  decode.d2.loss_mask: 0.1624  decode.d2.loss_dice: 0.1926  decode.d3.loss_cls: 0.0566  decode.d3.loss_mask: 0.1637  decode.d3.loss_dice: 0.2096  decode.d4.loss_cls: 0.0606  decode.d4.loss_mask: 0.1626  decode.d4.loss_dice: 0.1924  decode.d5.loss_cls: 0.0709  decode.d5.loss_mask: 0.1618  decode.d5.loss_dice: 0.1841  decode.d6.loss_cls: 0.0492  decode.d6.loss_mask: 0.1633  decode.d6.loss_dice: 0.2074  decode.d7.loss_cls: 0.0418  decode.d7.loss_mask: 0.1644  decode.d7.loss_dice: 0.2055  decode.d8.loss_cls: 0.0360  decode.d8.loss_mask: 0.1653  decode.d8.loss_dice: 0.2109
07/30 21:56:25 - mmengine - INFO - Iter(train) [43400/80000]  base_lr: 4.9472e-05 lr: 4.9472e-06  eta: 4:26:34  time: 0.4391  data_time: 0.0097  memory: 5265  grad_norm: 92.5428  loss: 7.4606  decode.loss_cls: 0.2109  decode.loss_mask: 0.2155  decode.loss_dice: 0.2521  decode.d0.loss_cls: 1.0265  decode.d0.loss_mask: 0.2213  decode.d0.loss_dice: 0.2607  decode.d1.loss_cls: 0.2058  decode.d1.loss_mask: 0.2148  decode.d1.loss_dice: 0.2518  decode.d2.loss_cls: 0.2001  decode.d2.loss_mask: 0.2153  decode.d2.loss_dice: 0.2628  decode.d3.loss_cls: 0.1844  decode.d3.loss_mask: 0.2103  decode.d3.loss_dice: 0.2542  decode.d4.loss_cls: 0.1954  decode.d4.loss_mask: 0.2147  decode.d4.loss_dice: 0.2538  decode.d5.loss_cls: 0.1760  decode.d5.loss_mask: 0.2165  decode.d5.loss_dice: 0.2485  decode.d6.loss_cls: 0.1640  decode.d6.loss_mask: 0.2187  decode.d6.loss_dice: 0.2554  decode.d7.loss_cls: 0.2000  decode.d7.loss_mask: 0.2164  decode.d7.loss_dice: 0.2505  decode.d8.loss_cls: 0.2000  decode.d8.loss_mask: 0.2182  decode.d8.loss_dice: 0.2459
07/30 21:56:47 - mmengine - INFO - Iter(train) [43450/80000]  base_lr: 4.9411e-05 lr: 4.9411e-06  eta: 4:26:13  time: 0.4387  data_time: 0.0097  memory: 5246  grad_norm: 60.8690  loss: 6.6892  decode.loss_cls: 0.1121  decode.loss_mask: 0.2231  decode.loss_dice: 0.2549  decode.d0.loss_cls: 1.0021  decode.d0.loss_mask: 0.2321  decode.d0.loss_dice: 0.2585  decode.d1.loss_cls: 0.1268  decode.d1.loss_mask: 0.2265  decode.d1.loss_dice: 0.2573  decode.d2.loss_cls: 0.1013  decode.d2.loss_mask: 0.2212  decode.d2.loss_dice: 0.2514  decode.d3.loss_cls: 0.0941  decode.d3.loss_mask: 0.2177  decode.d3.loss_dice: 0.2557  decode.d4.loss_cls: 0.0904  decode.d4.loss_mask: 0.2219  decode.d4.loss_dice: 0.2557  decode.d5.loss_cls: 0.0851  decode.d5.loss_mask: 0.2218  decode.d5.loss_dice: 0.2507  decode.d6.loss_cls: 0.1153  decode.d6.loss_mask: 0.2259  decode.d6.loss_dice: 0.2546  decode.d7.loss_cls: 0.0824  decode.d7.loss_mask: 0.2268  decode.d7.loss_dice: 0.2616  decode.d8.loss_cls: 0.0844  decode.d8.loss_mask: 0.2243  decode.d8.loss_dice: 0.2535
07/30 21:57:09 - mmengine - INFO - Iter(train) [43500/80000]  base_lr: 4.9350e-05 lr: 4.9350e-06  eta: 4:25:51  time: 0.4386  data_time: 0.0097  memory: 5305  grad_norm: 131.1745  loss: 7.9622  decode.loss_cls: 0.2330  decode.loss_mask: 0.2055  decode.loss_dice: 0.2465  decode.d0.loss_cls: 0.9867  decode.d0.loss_mask: 0.2157  decode.d0.loss_dice: 0.2946  decode.d1.loss_cls: 0.1942  decode.d1.loss_mask: 0.2095  decode.d1.loss_dice: 0.2671  decode.d2.loss_cls: 0.1654  decode.d2.loss_mask: 0.2053  decode.d2.loss_dice: 0.2505  decode.d3.loss_cls: 0.2159  decode.d3.loss_mask: 0.2098  decode.d3.loss_dice: 0.2787  decode.d4.loss_cls: 0.2749  decode.d4.loss_mask: 0.2061  decode.d4.loss_dice: 0.2809  decode.d5.loss_cls: 0.2519  decode.d5.loss_mask: 0.2068  decode.d5.loss_dice: 0.2866  decode.d6.loss_cls: 0.2886  decode.d6.loss_mask: 0.2075  decode.d6.loss_dice: 0.2454  decode.d7.loss_cls: 0.3111  decode.d7.loss_mask: 0.2062  decode.d7.loss_dice: 0.2775  decode.d8.loss_cls: 0.2852  decode.d8.loss_mask: 0.2056  decode.d8.loss_dice: 0.2493
07/30 21:57:31 - mmengine - INFO - Iter(train) [43550/80000]  base_lr: 4.9289e-05 lr: 4.9289e-06  eta: 4:25:29  time: 0.4408  data_time: 0.0096  memory: 5261  grad_norm: 100.4781  loss: 7.3366  decode.loss_cls: 0.0774  decode.loss_mask: 0.2816  decode.loss_dice: 0.2682  decode.d0.loss_cls: 0.9081  decode.d0.loss_mask: 0.2986  decode.d0.loss_dice: 0.2955  decode.d1.loss_cls: 0.1035  decode.d1.loss_mask: 0.2891  decode.d1.loss_dice: 0.3098  decode.d2.loss_cls: 0.0584  decode.d2.loss_mask: 0.2901  decode.d2.loss_dice: 0.2939  decode.d3.loss_cls: 0.0633  decode.d3.loss_mask: 0.2904  decode.d3.loss_dice: 0.2985  decode.d4.loss_cls: 0.0781  decode.d4.loss_mask: 0.2866  decode.d4.loss_dice: 0.2800  decode.d5.loss_cls: 0.0852  decode.d5.loss_mask: 0.2822  decode.d5.loss_dice: 0.2604  decode.d6.loss_cls: 0.0842  decode.d6.loss_mask: 0.2896  decode.d6.loss_dice: 0.2752  decode.d7.loss_cls: 0.0995  decode.d7.loss_mask: 0.2837  decode.d7.loss_dice: 0.2676  decode.d8.loss_cls: 0.0848  decode.d8.loss_mask: 0.2836  decode.d8.loss_dice: 0.2696
07/30 21:57:53 - mmengine - INFO - Iter(train) [43600/80000]  base_lr: 4.9228e-05 lr: 4.9228e-06  eta: 4:25:07  time: 0.4396  data_time: 0.0098  memory: 5246  grad_norm: 30.4547  loss: 5.4972  decode.loss_cls: 0.0936  decode.loss_mask: 0.1888  decode.loss_dice: 0.1769  decode.d0.loss_cls: 0.9087  decode.d0.loss_mask: 0.1893  decode.d0.loss_dice: 0.2080  decode.d1.loss_cls: 0.0793  decode.d1.loss_mask: 0.1862  decode.d1.loss_dice: 0.2117  decode.d2.loss_cls: 0.0867  decode.d2.loss_mask: 0.1865  decode.d2.loss_dice: 0.2030  decode.d3.loss_cls: 0.0832  decode.d3.loss_mask: 0.1876  decode.d3.loss_dice: 0.2246  decode.d4.loss_cls: 0.0606  decode.d4.loss_mask: 0.1859  decode.d4.loss_dice: 0.1994  decode.d5.loss_cls: 0.0667  decode.d5.loss_mask: 0.1869  decode.d5.loss_dice: 0.2067  decode.d6.loss_cls: 0.0868  decode.d6.loss_mask: 0.1869  decode.d6.loss_dice: 0.1969  decode.d7.loss_cls: 0.0591  decode.d7.loss_mask: 0.1878  decode.d7.loss_dice: 0.2080  decode.d8.loss_cls: 0.0570  decode.d8.loss_mask: 0.1896  decode.d8.loss_dice: 0.2050
07/30 21:58:15 - mmengine - INFO - Iter(train) [43650/80000]  base_lr: 4.9167e-05 lr: 4.9167e-06  eta: 4:24:46  time: 0.4396  data_time: 0.0097  memory: 5245  grad_norm: 65.0960  loss: 5.8909  decode.loss_cls: 0.0643  decode.loss_mask: 0.2383  decode.loss_dice: 0.2127  decode.d0.loss_cls: 0.9049  decode.d0.loss_mask: 0.2435  decode.d0.loss_dice: 0.2117  decode.d1.loss_cls: 0.0485  decode.d1.loss_mask: 0.2376  decode.d1.loss_dice: 0.2210  decode.d2.loss_cls: 0.0394  decode.d2.loss_mask: 0.2363  decode.d2.loss_dice: 0.2147  decode.d3.loss_cls: 0.0448  decode.d3.loss_mask: 0.2364  decode.d3.loss_dice: 0.2123  decode.d4.loss_cls: 0.0362  decode.d4.loss_mask: 0.2366  decode.d4.loss_dice: 0.2200  decode.d5.loss_cls: 0.0481  decode.d5.loss_mask: 0.2396  decode.d5.loss_dice: 0.2139  decode.d6.loss_cls: 0.0515  decode.d6.loss_mask: 0.2408  decode.d6.loss_dice: 0.2125  decode.d7.loss_cls: 0.0567  decode.d7.loss_mask: 0.2398  decode.d7.loss_dice: 0.2159  decode.d8.loss_cls: 0.0608  decode.d8.loss_mask: 0.2398  decode.d8.loss_dice: 0.2122
07/30 21:58:37 - mmengine - INFO - Iter(train) [43700/80000]  base_lr: 4.9107e-05 lr: 4.9107e-06  eta: 4:24:24  time: 0.4385  data_time: 0.0097  memory: 5245  grad_norm: 65.8348  loss: 6.7861  decode.loss_cls: 0.1263  decode.loss_mask: 0.2328  decode.loss_dice: 0.2123  decode.d0.loss_cls: 0.9893  decode.d0.loss_mask: 0.2321  decode.d0.loss_dice: 0.2338  decode.d1.loss_cls: 0.2350  decode.d1.loss_mask: 0.2255  decode.d1.loss_dice: 0.2038  decode.d2.loss_cls: 0.2228  decode.d2.loss_mask: 0.2275  decode.d2.loss_dice: 0.2002  decode.d3.loss_cls: 0.1433  decode.d3.loss_mask: 0.2326  decode.d3.loss_dice: 0.2212  decode.d4.loss_cls: 0.1149  decode.d4.loss_mask: 0.2310  decode.d4.loss_dice: 0.2096  decode.d5.loss_cls: 0.0766  decode.d5.loss_mask: 0.2327  decode.d5.loss_dice: 0.2168  decode.d6.loss_cls: 0.1780  decode.d6.loss_mask: 0.2314  decode.d6.loss_dice: 0.2053  decode.d7.loss_cls: 0.1315  decode.d7.loss_mask: 0.2265  decode.d7.loss_dice: 0.2102  decode.d8.loss_cls: 0.1509  decode.d8.loss_mask: 0.2245  decode.d8.loss_dice: 0.2079
07/30 21:58:59 - mmengine - INFO - Iter(train) [43750/80000]  base_lr: 4.9046e-05 lr: 4.9046e-06  eta: 4:24:02  time: 0.4386  data_time: 0.0097  memory: 5265  grad_norm: 68.5008  loss: 6.9040  decode.loss_cls: 0.0422  decode.loss_mask: 0.2595  decode.loss_dice: 0.2944  decode.d0.loss_cls: 0.9579  decode.d0.loss_mask: 0.2621  decode.d0.loss_dice: 0.3069  decode.d1.loss_cls: 0.0348  decode.d1.loss_mask: 0.2623  decode.d1.loss_dice: 0.2935  decode.d2.loss_cls: 0.0280  decode.d2.loss_mask: 0.2632  decode.d2.loss_dice: 0.2986  decode.d3.loss_cls: 0.0280  decode.d3.loss_mask: 0.2601  decode.d3.loss_dice: 0.2930  decode.d4.loss_cls: 0.0279  decode.d4.loss_mask: 0.2609  decode.d4.loss_dice: 0.3056  decode.d5.loss_cls: 0.0296  decode.d5.loss_mask: 0.2610  decode.d5.loss_dice: 0.3032  decode.d6.loss_cls: 0.0488  decode.d6.loss_mask: 0.2615  decode.d6.loss_dice: 0.3063  decode.d7.loss_cls: 0.0480  decode.d7.loss_mask: 0.2611  decode.d7.loss_dice: 0.2980  decode.d8.loss_cls: 0.0440  decode.d8.loss_mask: 0.2622  decode.d8.loss_dice: 0.3016
07/30 21:59:21 - mmengine - INFO - Iter(train) [43800/80000]  base_lr: 4.8985e-05 lr: 4.8985e-06  eta: 4:23:40  time: 0.4381  data_time: 0.0096  memory: 5227  grad_norm: 49.9820  loss: 7.6716  decode.loss_cls: 0.1408  decode.loss_mask: 0.2515  decode.loss_dice: 0.2734  decode.d0.loss_cls: 0.8397  decode.d0.loss_mask: 0.2607  decode.d0.loss_dice: 0.3220  decode.d1.loss_cls: 0.1227  decode.d1.loss_mask: 0.2568  decode.d1.loss_dice: 0.2922  decode.d2.loss_cls: 0.1642  decode.d2.loss_mask: 0.2546  decode.d2.loss_dice: 0.2912  decode.d3.loss_cls: 0.2075  decode.d3.loss_mask: 0.2523  decode.d3.loss_dice: 0.2797  decode.d4.loss_cls: 0.1924  decode.d4.loss_mask: 0.2514  decode.d4.loss_dice: 0.2669  decode.d5.loss_cls: 0.1598  decode.d5.loss_mask: 0.2499  decode.d5.loss_dice: 0.2829  decode.d6.loss_cls: 0.1695  decode.d6.loss_mask: 0.2502  decode.d6.loss_dice: 0.2835  decode.d7.loss_cls: 0.1956  decode.d7.loss_mask: 0.2525  decode.d7.loss_dice: 0.2485  decode.d8.loss_cls: 0.1462  decode.d8.loss_mask: 0.2498  decode.d8.loss_dice: 0.2632
07/30 21:59:43 - mmengine - INFO - Iter(train) [43850/80000]  base_lr: 4.8924e-05 lr: 4.8924e-06  eta: 4:23:19  time: 0.4390  data_time: 0.0098  memory: 5261  grad_norm: 70.8926  loss: 7.5173  decode.loss_cls: 0.0859  decode.loss_mask: 0.2848  decode.loss_dice: 0.2690  decode.d0.loss_cls: 1.0023  decode.d0.loss_mask: 0.2922  decode.d0.loss_dice: 0.2735  decode.d1.loss_cls: 0.1269  decode.d1.loss_mask: 0.2890  decode.d1.loss_dice: 0.2711  decode.d2.loss_cls: 0.1019  decode.d2.loss_mask: 0.2852  decode.d2.loss_dice: 0.2719  decode.d3.loss_cls: 0.0964  decode.d3.loss_mask: 0.2886  decode.d3.loss_dice: 0.2717  decode.d4.loss_cls: 0.1333  decode.d4.loss_mask: 0.2837  decode.d4.loss_dice: 0.2631  decode.d5.loss_cls: 0.1080  decode.d5.loss_mask: 0.2886  decode.d5.loss_dice: 0.2700  decode.d6.loss_cls: 0.0816  decode.d6.loss_mask: 0.2865  decode.d6.loss_dice: 0.2968  decode.d7.loss_cls: 0.1019  decode.d7.loss_mask: 0.2886  decode.d7.loss_dice: 0.2704  decode.d8.loss_cls: 0.0807  decode.d8.loss_mask: 0.2874  decode.d8.loss_dice: 0.2661
07/30 22:00:05 - mmengine - INFO - Iter(train) [43900/80000]  base_lr: 4.8863e-05 lr: 4.8863e-06  eta: 4:22:57  time: 0.4384  data_time: 0.0098  memory: 5245  grad_norm: 36.2922  loss: 6.1589  decode.loss_cls: 0.0702  decode.loss_mask: 0.2416  decode.loss_dice: 0.2231  decode.d0.loss_cls: 0.8861  decode.d0.loss_mask: 0.2444  decode.d0.loss_dice: 0.2329  decode.d1.loss_cls: 0.0658  decode.d1.loss_mask: 0.2406  decode.d1.loss_dice: 0.2285  decode.d2.loss_cls: 0.0635  decode.d2.loss_mask: 0.2423  decode.d2.loss_dice: 0.2214  decode.d3.loss_cls: 0.0599  decode.d3.loss_mask: 0.2411  decode.d3.loss_dice: 0.2218  decode.d4.loss_cls: 0.0680  decode.d4.loss_mask: 0.2427  decode.d4.loss_dice: 0.2243  decode.d5.loss_cls: 0.0691  decode.d5.loss_mask: 0.2437  decode.d5.loss_dice: 0.2218  decode.d6.loss_cls: 0.0766  decode.d6.loss_mask: 0.2413  decode.d6.loss_dice: 0.2219  decode.d7.loss_cls: 0.0766  decode.d7.loss_mask: 0.2395  decode.d7.loss_dice: 0.2186  decode.d8.loss_cls: 0.0672  decode.d8.loss_mask: 0.2410  decode.d8.loss_dice: 0.2234
07/30 22:00:27 - mmengine - INFO - Iter(train) [43950/80000]  base_lr: 4.8802e-05 lr: 4.8802e-06  eta: 4:22:35  time: 0.4407  data_time: 0.0095  memory: 5279  grad_norm: 37.0161  loss: 6.3076  decode.loss_cls: 0.0102  decode.loss_mask: 0.2160  decode.loss_dice: 0.2903  decode.d0.loss_cls: 0.8858  decode.d0.loss_mask: 0.2202  decode.d0.loss_dice: 0.2858  decode.d1.loss_cls: 0.0175  decode.d1.loss_mask: 0.2182  decode.d1.loss_dice: 0.2913  decode.d2.loss_cls: 0.0605  decode.d2.loss_mask: 0.2163  decode.d2.loss_dice: 0.2810  decode.d3.loss_cls: 0.1268  decode.d3.loss_mask: 0.2111  decode.d3.loss_dice: 0.2640  decode.d4.loss_cls: 0.0745  decode.d4.loss_mask: 0.2148  decode.d4.loss_dice: 0.2857  decode.d5.loss_cls: 0.0106  decode.d5.loss_mask: 0.2137  decode.d5.loss_dice: 0.2851  decode.d6.loss_cls: 0.0566  decode.d6.loss_mask: 0.2150  decode.d6.loss_dice: 0.2799  decode.d7.loss_cls: 0.0672  decode.d7.loss_mask: 0.2167  decode.d7.loss_dice: 0.2795  decode.d8.loss_cls: 0.0100  decode.d8.loss_mask: 0.2178  decode.d8.loss_dice: 0.2855
07/30 22:00:49 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 22:00:49 - mmengine - INFO - Iter(train) [44000/80000]  base_lr: 4.8741e-05 lr: 4.8741e-06  eta: 4:22:13  time: 0.4407  data_time: 0.0097  memory: 5303  grad_norm: 41.7920  loss: 6.4322  decode.loss_cls: 0.1467  decode.loss_mask: 0.1915  decode.loss_dice: 0.2378  decode.d0.loss_cls: 0.8999  decode.d0.loss_mask: 0.1943  decode.d0.loss_dice: 0.2460  decode.d1.loss_cls: 0.1002  decode.d1.loss_mask: 0.1917  decode.d1.loss_dice: 0.2389  decode.d2.loss_cls: 0.1060  decode.d2.loss_mask: 0.1885  decode.d2.loss_dice: 0.2425  decode.d3.loss_cls: 0.0974  decode.d3.loss_mask: 0.1915  decode.d3.loss_dice: 0.2425  decode.d4.loss_cls: 0.1386  decode.d4.loss_mask: 0.1903  decode.d4.loss_dice: 0.2360  decode.d5.loss_cls: 0.1566  decode.d5.loss_mask: 0.1916  decode.d5.loss_dice: 0.2435  decode.d6.loss_cls: 0.1790  decode.d6.loss_mask: 0.1897  decode.d6.loss_dice: 0.2358  decode.d7.loss_cls: 0.1216  decode.d7.loss_mask: 0.1918  decode.d7.loss_dice: 0.2418  decode.d8.loss_cls: 0.1769  decode.d8.loss_mask: 0.1909  decode.d8.loss_dice: 0.2326
07/30 22:01:11 - mmengine - INFO - Iter(train) [44050/80000]  base_lr: 4.8680e-05 lr: 4.8680e-06  eta: 4:21:52  time: 0.4402  data_time: 0.0097  memory: 5265  grad_norm: 46.2550  loss: 6.6867  decode.loss_cls: 0.1221  decode.loss_mask: 0.2169  decode.loss_dice: 0.2278  decode.d0.loss_cls: 0.9924  decode.d0.loss_mask: 0.2218  decode.d0.loss_dice: 0.2438  decode.d1.loss_cls: 0.1099  decode.d1.loss_mask: 0.2174  decode.d1.loss_dice: 0.2270  decode.d2.loss_cls: 0.1075  decode.d2.loss_mask: 0.2201  decode.d2.loss_dice: 0.2272  decode.d3.loss_cls: 0.1479  decode.d3.loss_mask: 0.2177  decode.d3.loss_dice: 0.2241  decode.d4.loss_cls: 0.1424  decode.d4.loss_mask: 0.2170  decode.d4.loss_dice: 0.2230  decode.d5.loss_cls: 0.1581  decode.d5.loss_mask: 0.2167  decode.d5.loss_dice: 0.2237  decode.d6.loss_cls: 0.1586  decode.d6.loss_mask: 0.2130  decode.d6.loss_dice: 0.2196  decode.d7.loss_cls: 0.1577  decode.d7.loss_mask: 0.2161  decode.d7.loss_dice: 0.2303  decode.d8.loss_cls: 0.1392  decode.d8.loss_mask: 0.2182  decode.d8.loss_dice: 0.2295
07/30 22:01:33 - mmengine - INFO - Iter(train) [44100/80000]  base_lr: 4.8619e-05 lr: 4.8619e-06  eta: 4:21:30  time: 0.4386  data_time: 0.0096  memory: 5261  grad_norm: 171.6453  loss: 8.5478  decode.loss_cls: 0.1804  decode.loss_mask: 0.2344  decode.loss_dice: 0.3183  decode.d0.loss_cls: 1.1427  decode.d0.loss_mask: 0.2389  decode.d0.loss_dice: 0.3256  decode.d1.loss_cls: 0.2645  decode.d1.loss_mask: 0.2370  decode.d1.loss_dice: 0.3212  decode.d2.loss_cls: 0.2217  decode.d2.loss_mask: 0.2412  decode.d2.loss_dice: 0.3280  decode.d3.loss_cls: 0.2248  decode.d3.loss_mask: 0.2389  decode.d3.loss_dice: 0.3188  decode.d4.loss_cls: 0.2210  decode.d4.loss_mask: 0.2383  decode.d4.loss_dice: 0.3254  decode.d5.loss_cls: 0.1948  decode.d5.loss_mask: 0.2403  decode.d5.loss_dice: 0.3307  decode.d6.loss_cls: 0.1942  decode.d6.loss_mask: 0.2376  decode.d6.loss_dice: 0.3175  decode.d7.loss_cls: 0.1690  decode.d7.loss_mask: 0.2338  decode.d7.loss_dice: 0.3202  decode.d8.loss_cls: 0.1283  decode.d8.loss_mask: 0.2363  decode.d8.loss_dice: 0.3239
07/30 22:01:55 - mmengine - INFO - Iter(train) [44150/80000]  base_lr: 4.8558e-05 lr: 4.8558e-06  eta: 4:21:08  time: 0.4398  data_time: 0.0098  memory: 5245  grad_norm: 57.6490  loss: 7.9349  decode.loss_cls: 0.1626  decode.loss_mask: 0.2227  decode.loss_dice: 0.3236  decode.d0.loss_cls: 1.0541  decode.d0.loss_mask: 0.2239  decode.d0.loss_dice: 0.3230  decode.d1.loss_cls: 0.1711  decode.d1.loss_mask: 0.2224  decode.d1.loss_dice: 0.3084  decode.d2.loss_cls: 0.2254  decode.d2.loss_mask: 0.2177  decode.d2.loss_dice: 0.2775  decode.d3.loss_cls: 0.1598  decode.d3.loss_mask: 0.2166  decode.d3.loss_dice: 0.3040  decode.d4.loss_cls: 0.2091  decode.d4.loss_mask: 0.2213  decode.d4.loss_dice: 0.3215  decode.d5.loss_cls: 0.1909  decode.d5.loss_mask: 0.2226  decode.d5.loss_dice: 0.3062  decode.d6.loss_cls: 0.1694  decode.d6.loss_mask: 0.2210  decode.d6.loss_dice: 0.2995  decode.d7.loss_cls: 0.1517  decode.d7.loss_mask: 0.2205  decode.d7.loss_dice: 0.2912  decode.d8.loss_cls: 0.1596  decode.d8.loss_mask: 0.2198  decode.d8.loss_dice: 0.3182
07/30 22:02:17 - mmengine - INFO - Iter(train) [44200/80000]  base_lr: 4.8497e-05 lr: 4.8497e-06  eta: 4:20:46  time: 0.4393  data_time: 0.0098  memory: 5278  grad_norm: 59.4144  loss: 7.3431  decode.loss_cls: 0.0852  decode.loss_mask: 0.2368  decode.loss_dice: 0.3094  decode.d0.loss_cls: 0.7603  decode.d0.loss_mask: 0.2418  decode.d0.loss_dice: 0.3079  decode.d1.loss_cls: 0.1625  decode.d1.loss_mask: 0.2392  decode.d1.loss_dice: 0.3209  decode.d2.loss_cls: 0.1428  decode.d2.loss_mask: 0.2373  decode.d2.loss_dice: 0.3179  decode.d3.loss_cls: 0.0966  decode.d3.loss_mask: 0.2349  decode.d3.loss_dice: 0.2890  decode.d4.loss_cls: 0.0935  decode.d4.loss_mask: 0.2347  decode.d4.loss_dice: 0.3143  decode.d5.loss_cls: 0.1158  decode.d5.loss_mask: 0.2348  decode.d5.loss_dice: 0.3247  decode.d6.loss_cls: 0.0967  decode.d6.loss_mask: 0.2339  decode.d6.loss_dice: 0.3114  decode.d7.loss_cls: 0.1665  decode.d7.loss_mask: 0.2358  decode.d7.loss_dice: 0.3458  decode.d8.loss_cls: 0.1078  decode.d8.loss_mask: 0.2365  decode.d8.loss_dice: 0.3087
07/30 22:02:39 - mmengine - INFO - Iter(train) [44250/80000]  base_lr: 4.8436e-05 lr: 4.8436e-06  eta: 4:20:24  time: 0.4393  data_time: 0.0095  memory: 5241  grad_norm: 46.2588  loss: 7.8317  decode.loss_cls: 0.1590  decode.loss_mask: 0.2502  decode.loss_dice: 0.2658  decode.d0.loss_cls: 1.0931  decode.d0.loss_mask: 0.2497  decode.d0.loss_dice: 0.2583  decode.d1.loss_cls: 0.2022  decode.d1.loss_mask: 0.2542  decode.d1.loss_dice: 0.2750  decode.d2.loss_cls: 0.1646  decode.d2.loss_mask: 0.2540  decode.d2.loss_dice: 0.2701  decode.d3.loss_cls: 0.1401  decode.d3.loss_mask: 0.2557  decode.d3.loss_dice: 0.2857  decode.d4.loss_cls: 0.2229  decode.d4.loss_mask: 0.2536  decode.d4.loss_dice: 0.2650  decode.d5.loss_cls: 0.1553  decode.d5.loss_mask: 0.2376  decode.d5.loss_dice: 0.2645  decode.d6.loss_cls: 0.1420  decode.d6.loss_mask: 0.2407  decode.d6.loss_dice: 0.2722  decode.d7.loss_cls: 0.1771  decode.d7.loss_mask: 0.2466  decode.d7.loss_dice: 0.2803  decode.d8.loss_cls: 0.1679  decode.d8.loss_mask: 0.2502  decode.d8.loss_dice: 0.2781
07/30 22:03:01 - mmengine - INFO - Iter(train) [44300/80000]  base_lr: 4.8375e-05 lr: 4.8375e-06  eta: 4:20:03  time: 0.4392  data_time: 0.0097  memory: 5245  grad_norm: 66.0541  loss: 9.5986  decode.loss_cls: 0.3236  decode.loss_mask: 0.2087  decode.loss_dice: 0.3657  decode.d0.loss_cls: 1.1900  decode.d0.loss_mask: 0.2131  decode.d0.loss_dice: 0.3601  decode.d1.loss_cls: 0.3180  decode.d1.loss_mask: 0.2087  decode.d1.loss_dice: 0.3429  decode.d2.loss_cls: 0.3261  decode.d2.loss_mask: 0.2078  decode.d2.loss_dice: 0.3651  decode.d3.loss_cls: 0.3161  decode.d3.loss_mask: 0.2073  decode.d3.loss_dice: 0.3652  decode.d4.loss_cls: 0.2847  decode.d4.loss_mask: 0.2093  decode.d4.loss_dice: 0.3657  decode.d5.loss_cls: 0.2798  decode.d5.loss_mask: 0.2091  decode.d5.loss_dice: 0.3697  decode.d6.loss_cls: 0.3003  decode.d6.loss_mask: 0.2079  decode.d6.loss_dice: 0.3584  decode.d7.loss_cls: 0.2839  decode.d7.loss_mask: 0.2085  decode.d7.loss_dice: 0.3232  decode.d8.loss_cls: 0.2977  decode.d8.loss_mask: 0.2084  decode.d8.loss_dice: 0.3736
07/30 22:03:23 - mmengine - INFO - Iter(train) [44350/80000]  base_lr: 4.8314e-05 lr: 4.8314e-06  eta: 4:19:41  time: 0.4402  data_time: 0.0098  memory: 5303  grad_norm: 31.8731  loss: 6.1451  decode.loss_cls: 0.0262  decode.loss_mask: 0.2246  decode.loss_dice: 0.2721  decode.d0.loss_cls: 0.8602  decode.d0.loss_mask: 0.2319  decode.d0.loss_dice: 0.2775  decode.d1.loss_cls: 0.0960  decode.d1.loss_mask: 0.2274  decode.d1.loss_dice: 0.2592  decode.d2.loss_cls: 0.0292  decode.d2.loss_mask: 0.2234  decode.d2.loss_dice: 0.2645  decode.d3.loss_cls: 0.0357  decode.d3.loss_mask: 0.2249  decode.d3.loss_dice: 0.2740  decode.d4.loss_cls: 0.0572  decode.d4.loss_mask: 0.2241  decode.d4.loss_dice: 0.2539  decode.d5.loss_cls: 0.0315  decode.d5.loss_mask: 0.2231  decode.d5.loss_dice: 0.2713  decode.d6.loss_cls: 0.0297  decode.d6.loss_mask: 0.2222  decode.d6.loss_dice: 0.2759  decode.d7.loss_cls: 0.0334  decode.d7.loss_mask: 0.2230  decode.d7.loss_dice: 0.2647  decode.d8.loss_cls: 0.0253  decode.d8.loss_mask: 0.2233  decode.d8.loss_dice: 0.2597
07/30 22:03:45 - mmengine - INFO - Iter(train) [44400/80000]  base_lr: 4.8254e-05 lr: 4.8254e-06  eta: 4:19:19  time: 0.4401  data_time: 0.0098  memory: 5265  grad_norm: 71.2788  loss: 7.7227  decode.loss_cls: 0.1045  decode.loss_mask: 0.2587  decode.loss_dice: 0.3184  decode.d0.loss_cls: 1.0718  decode.d0.loss_mask: 0.2618  decode.d0.loss_dice: 0.3233  decode.d1.loss_cls: 0.0978  decode.d1.loss_mask: 0.2609  decode.d1.loss_dice: 0.3162  decode.d2.loss_cls: 0.0992  decode.d2.loss_mask: 0.2568  decode.d2.loss_dice: 0.3330  decode.d3.loss_cls: 0.0935  decode.d3.loss_mask: 0.2558  decode.d3.loss_dice: 0.3236  decode.d4.loss_cls: 0.0886  decode.d4.loss_mask: 0.2603  decode.d4.loss_dice: 0.3149  decode.d5.loss_cls: 0.0980  decode.d5.loss_mask: 0.2531  decode.d5.loss_dice: 0.3095  decode.d6.loss_cls: 0.0921  decode.d6.loss_mask: 0.2631  decode.d6.loss_dice: 0.3134  decode.d7.loss_cls: 0.1011  decode.d7.loss_mask: 0.2684  decode.d7.loss_dice: 0.3235  decode.d8.loss_cls: 0.0943  decode.d8.loss_mask: 0.2562  decode.d8.loss_dice: 0.3110
07/30 22:04:07 - mmengine - INFO - Iter(train) [44450/80000]  base_lr: 4.8193e-05 lr: 4.8193e-06  eta: 4:18:57  time: 0.4393  data_time: 0.0096  memory: 5278  grad_norm: 50.3978  loss: 6.3394  decode.loss_cls: 0.0955  decode.loss_mask: 0.2104  decode.loss_dice: 0.2065  decode.d0.loss_cls: 0.9421  decode.d0.loss_mask: 0.2245  decode.d0.loss_dice: 0.2327  decode.d1.loss_cls: 0.1613  decode.d1.loss_mask: 0.2122  decode.d1.loss_dice: 0.2168  decode.d2.loss_cls: 0.1588  decode.d2.loss_mask: 0.2106  decode.d2.loss_dice: 0.2310  decode.d3.loss_cls: 0.1164  decode.d3.loss_mask: 0.2119  decode.d3.loss_dice: 0.2086  decode.d4.loss_cls: 0.1394  decode.d4.loss_mask: 0.2131  decode.d4.loss_dice: 0.2247  decode.d5.loss_cls: 0.1072  decode.d5.loss_mask: 0.2103  decode.d5.loss_dice: 0.1997  decode.d6.loss_cls: 0.1068  decode.d6.loss_mask: 0.2113  decode.d6.loss_dice: 0.2353  decode.d7.loss_cls: 0.0853  decode.d7.loss_mask: 0.2132  decode.d7.loss_dice: 0.2314  decode.d8.loss_cls: 0.0879  decode.d8.loss_mask: 0.2110  decode.d8.loss_dice: 0.2232
07/30 22:04:29 - mmengine - INFO - Iter(train) [44500/80000]  base_lr: 4.8132e-05 lr: 4.8132e-06  eta: 4:18:36  time: 0.4398  data_time: 0.0098  memory: 5261  grad_norm: 74.1022  loss: 8.7850  decode.loss_cls: 0.2565  decode.loss_mask: 0.2794  decode.loss_dice: 0.3319  decode.d0.loss_cls: 1.0479  decode.d0.loss_mask: 0.2862  decode.d0.loss_dice: 0.3328  decode.d1.loss_cls: 0.1670  decode.d1.loss_mask: 0.2828  decode.d1.loss_dice: 0.2976  decode.d2.loss_cls: 0.1569  decode.d2.loss_mask: 0.2767  decode.d2.loss_dice: 0.3407  decode.d3.loss_cls: 0.1433  decode.d3.loss_mask: 0.2802  decode.d3.loss_dice: 0.3412  decode.d4.loss_cls: 0.1613  decode.d4.loss_mask: 0.2858  decode.d4.loss_dice: 0.3358  decode.d5.loss_cls: 0.2089  decode.d5.loss_mask: 0.2766  decode.d5.loss_dice: 0.3221  decode.d6.loss_cls: 0.1740  decode.d6.loss_mask: 0.2815  decode.d6.loss_dice: 0.3255  decode.d7.loss_cls: 0.1901  decode.d7.loss_mask: 0.2800  decode.d7.loss_dice: 0.3201  decode.d8.loss_cls: 0.1763  decode.d8.loss_mask: 0.2821  decode.d8.loss_dice: 0.3439
07/30 22:04:51 - mmengine - INFO - Iter(train) [44550/80000]  base_lr: 4.8070e-05 lr: 4.8070e-06  eta: 4:18:14  time: 0.4398  data_time: 0.0097  memory: 5265  grad_norm: 76.1200  loss: 6.8296  decode.loss_cls: 0.1529  decode.loss_mask: 0.1888  decode.loss_dice: 0.2221  decode.d0.loss_cls: 1.0470  decode.d0.loss_mask: 0.1912  decode.d0.loss_dice: 0.2318  decode.d1.loss_cls: 0.2467  decode.d1.loss_mask: 0.1908  decode.d1.loss_dice: 0.2305  decode.d2.loss_cls: 0.1712  decode.d2.loss_mask: 0.1933  decode.d2.loss_dice: 0.2276  decode.d3.loss_cls: 0.1554  decode.d3.loss_mask: 0.1917  decode.d3.loss_dice: 0.2423  decode.d4.loss_cls: 0.1781  decode.d4.loss_mask: 0.1996  decode.d4.loss_dice: 0.2403  decode.d5.loss_cls: 0.1562  decode.d5.loss_mask: 0.1952  decode.d5.loss_dice: 0.2355  decode.d6.loss_cls: 0.1626  decode.d6.loss_mask: 0.1926  decode.d6.loss_dice: 0.2284  decode.d7.loss_cls: 0.1496  decode.d7.loss_mask: 0.1912  decode.d7.loss_dice: 0.2322  decode.d8.loss_cls: 0.1682  decode.d8.loss_mask: 0.1888  decode.d8.loss_dice: 0.2277
07/30 22:05:13 - mmengine - INFO - Iter(train) [44600/80000]  base_lr: 4.8009e-05 lr: 4.8009e-06  eta: 4:17:52  time: 0.4399  data_time: 0.0097  memory: 5244  grad_norm: 62.3372  loss: 8.4814  decode.loss_cls: 0.2271  decode.loss_mask: 0.2456  decode.loss_dice: 0.3173  decode.d0.loss_cls: 1.0196  decode.d0.loss_mask: 0.2358  decode.d0.loss_dice: 0.3219  decode.d1.loss_cls: 0.2193  decode.d1.loss_mask: 0.2334  decode.d1.loss_dice: 0.2962  decode.d2.loss_cls: 0.2276  decode.d2.loss_mask: 0.2354  decode.d2.loss_dice: 0.2967  decode.d3.loss_cls: 0.2224  decode.d3.loss_mask: 0.2305  decode.d3.loss_dice: 0.2911  decode.d4.loss_cls: 0.2122  decode.d4.loss_mask: 0.2343  decode.d4.loss_dice: 0.2877  decode.d5.loss_cls: 0.2573  decode.d5.loss_mask: 0.2344  decode.d5.loss_dice: 0.3014  decode.d6.loss_cls: 0.2312  decode.d6.loss_mask: 0.2348  decode.d6.loss_dice: 0.3076  decode.d7.loss_cls: 0.2148  decode.d7.loss_mask: 0.2354  decode.d7.loss_dice: 0.3072  decode.d8.loss_cls: 0.2886  decode.d8.loss_mask: 0.2333  decode.d8.loss_dice: 0.2813
07/30 22:05:35 - mmengine - INFO - Iter(train) [44650/80000]  base_lr: 4.7948e-05 lr: 4.7948e-06  eta: 4:17:30  time: 0.4387  data_time: 0.0096  memory: 5245  grad_norm: 98.4479  loss: 7.8611  decode.loss_cls: 0.1918  decode.loss_mask: 0.2539  decode.loss_dice: 0.2942  decode.d0.loss_cls: 1.0462  decode.d0.loss_mask: 0.2429  decode.d0.loss_dice: 0.3233  decode.d1.loss_cls: 0.1868  decode.d1.loss_mask: 0.2292  decode.d1.loss_dice: 0.3075  decode.d2.loss_cls: 0.1537  decode.d2.loss_mask: 0.2256  decode.d2.loss_dice: 0.2616  decode.d3.loss_cls: 0.1817  decode.d3.loss_mask: 0.2255  decode.d3.loss_dice: 0.3074  decode.d4.loss_cls: 0.1590  decode.d4.loss_mask: 0.2262  decode.d4.loss_dice: 0.2485  decode.d5.loss_cls: 0.1773  decode.d5.loss_mask: 0.2237  decode.d5.loss_dice: 0.2511  decode.d6.loss_cls: 0.1868  decode.d6.loss_mask: 0.2244  decode.d6.loss_dice: 0.2976  decode.d7.loss_cls: 0.1868  decode.d7.loss_mask: 0.2290  decode.d7.loss_dice: 0.3067  decode.d8.loss_cls: 0.1757  decode.d8.loss_mask: 0.2260  decode.d8.loss_dice: 0.3108
07/30 22:05:57 - mmengine - INFO - Iter(train) [44700/80000]  base_lr: 4.7887e-05 lr: 4.7887e-06  eta: 4:17:09  time: 0.4401  data_time: 0.0097  memory: 5244  grad_norm: 79.2838  loss: 6.3238  decode.loss_cls: 0.1176  decode.loss_mask: 0.1946  decode.loss_dice: 0.2712  decode.d0.loss_cls: 0.8500  decode.d0.loss_mask: 0.2011  decode.d0.loss_dice: 0.2922  decode.d1.loss_cls: 0.0866  decode.d1.loss_mask: 0.1992  decode.d1.loss_dice: 0.2797  decode.d2.loss_cls: 0.0885  decode.d2.loss_mask: 0.1972  decode.d2.loss_dice: 0.2626  decode.d3.loss_cls: 0.0760  decode.d3.loss_mask: 0.1948  decode.d3.loss_dice: 0.2605  decode.d4.loss_cls: 0.0810  decode.d4.loss_mask: 0.1949  decode.d4.loss_dice: 0.2578  decode.d5.loss_cls: 0.0864  decode.d5.loss_mask: 0.1951  decode.d5.loss_dice: 0.2611  decode.d6.loss_cls: 0.0701  decode.d6.loss_mask: 0.1945  decode.d6.loss_dice: 0.2557  decode.d7.loss_cls: 0.1163  decode.d7.loss_mask: 0.1950  decode.d7.loss_dice: 0.2700  decode.d8.loss_cls: 0.1077  decode.d8.loss_mask: 0.1977  decode.d8.loss_dice: 0.2687
07/30 22:06:19 - mmengine - INFO - Iter(train) [44750/80000]  base_lr: 4.7826e-05 lr: 4.7826e-06  eta: 4:16:47  time: 0.4412  data_time: 0.0099  memory: 5261  grad_norm: 41.9860  loss: 6.1954  decode.loss_cls: 0.0712  decode.loss_mask: 0.2272  decode.loss_dice: 0.2158  decode.d0.loss_cls: 0.7902  decode.d0.loss_mask: 0.2325  decode.d0.loss_dice: 0.2381  decode.d1.loss_cls: 0.1266  decode.d1.loss_mask: 0.2289  decode.d1.loss_dice: 0.2240  decode.d2.loss_cls: 0.0986  decode.d2.loss_mask: 0.2280  decode.d2.loss_dice: 0.2313  decode.d3.loss_cls: 0.0831  decode.d3.loss_mask: 0.2287  decode.d3.loss_dice: 0.2192  decode.d4.loss_cls: 0.0832  decode.d4.loss_mask: 0.2292  decode.d4.loss_dice: 0.2175  decode.d5.loss_cls: 0.0762  decode.d5.loss_mask: 0.2274  decode.d5.loss_dice: 0.2428  decode.d6.loss_cls: 0.0854  decode.d6.loss_mask: 0.2288  decode.d6.loss_dice: 0.2444  decode.d7.loss_cls: 0.0806  decode.d7.loss_mask: 0.2270  decode.d7.loss_dice: 0.2513  decode.d8.loss_cls: 0.0798  decode.d8.loss_mask: 0.2285  decode.d8.loss_dice: 0.2500
07/30 22:06:41 - mmengine - INFO - Iter(train) [44800/80000]  base_lr: 4.7765e-05 lr: 4.7765e-06  eta: 4:16:25  time: 0.4407  data_time: 0.0099  memory: 5278  grad_norm: 36.7633  loss: 6.5609  decode.loss_cls: 0.0345  decode.loss_mask: 0.2466  decode.loss_dice: 0.2734  decode.d0.loss_cls: 0.9543  decode.d0.loss_mask: 0.2510  decode.d0.loss_dice: 0.2689  decode.d1.loss_cls: 0.0709  decode.d1.loss_mask: 0.2450  decode.d1.loss_dice: 0.2665  decode.d2.loss_cls: 0.0280  decode.d2.loss_mask: 0.2435  decode.d2.loss_dice: 0.2747  decode.d3.loss_cls: 0.0300  decode.d3.loss_mask: 0.2460  decode.d3.loss_dice: 0.2518  decode.d4.loss_cls: 0.0361  decode.d4.loss_mask: 0.2403  decode.d4.loss_dice: 0.2691  decode.d5.loss_cls: 0.0660  decode.d5.loss_mask: 0.2425  decode.d5.loss_dice: 0.2805  decode.d6.loss_cls: 0.0783  decode.d6.loss_mask: 0.2476  decode.d6.loss_dice: 0.2885  decode.d7.loss_cls: 0.0412  decode.d7.loss_mask: 0.2424  decode.d7.loss_dice: 0.2829  decode.d8.loss_cls: 0.0391  decode.d8.loss_mask: 0.2476  decode.d8.loss_dice: 0.2739
07/30 22:07:03 - mmengine - INFO - Iter(train) [44850/80000]  base_lr: 4.7704e-05 lr: 4.7704e-06  eta: 4:16:04  time: 0.4390  data_time: 0.0097  memory: 5261  grad_norm: 61.7516  loss: 6.8359  decode.loss_cls: 0.0518  decode.loss_mask: 0.2714  decode.loss_dice: 0.2661  decode.d0.loss_cls: 0.9017  decode.d0.loss_mask: 0.2857  decode.d0.loss_dice: 0.2881  decode.d1.loss_cls: 0.0738  decode.d1.loss_mask: 0.2719  decode.d1.loss_dice: 0.2707  decode.d2.loss_cls: 0.0705  decode.d2.loss_mask: 0.2724  decode.d2.loss_dice: 0.2720  decode.d3.loss_cls: 0.0553  decode.d3.loss_mask: 0.2719  decode.d3.loss_dice: 0.2627  decode.d4.loss_cls: 0.0582  decode.d4.loss_mask: 0.2683  decode.d4.loss_dice: 0.2712  decode.d5.loss_cls: 0.0608  decode.d5.loss_mask: 0.2669  decode.d5.loss_dice: 0.2563  decode.d6.loss_cls: 0.0503  decode.d6.loss_mask: 0.2704  decode.d6.loss_dice: 0.2638  decode.d7.loss_cls: 0.0684  decode.d7.loss_mask: 0.2718  decode.d7.loss_dice: 0.2570  decode.d8.loss_cls: 0.0586  decode.d8.loss_mask: 0.2715  decode.d8.loss_dice: 0.2564
07/30 22:07:25 - mmengine - INFO - Iter(train) [44900/80000]  base_lr: 4.7643e-05 lr: 4.7643e-06  eta: 4:15:42  time: 0.4393  data_time: 0.0096  memory: 5265  grad_norm: 81.7108  loss: 8.8496  decode.loss_cls: 0.1904  decode.loss_mask: 0.2666  decode.loss_dice: 0.3479  decode.d0.loss_cls: 1.0231  decode.d0.loss_mask: 0.2712  decode.d0.loss_dice: 0.4185  decode.d1.loss_cls: 0.1809  decode.d1.loss_mask: 0.2725  decode.d1.loss_dice: 0.3881  decode.d2.loss_cls: 0.1825  decode.d2.loss_mask: 0.2723  decode.d2.loss_dice: 0.3556  decode.d3.loss_cls: 0.1042  decode.d3.loss_mask: 0.2703  decode.d3.loss_dice: 0.3391  decode.d4.loss_cls: 0.1239  decode.d4.loss_mask: 0.2723  decode.d4.loss_dice: 0.3665  decode.d5.loss_cls: 0.1411  decode.d5.loss_mask: 0.2713  decode.d5.loss_dice: 0.3568  decode.d6.loss_cls: 0.1849  decode.d6.loss_mask: 0.2681  decode.d6.loss_dice: 0.3571  decode.d7.loss_cls: 0.2191  decode.d7.loss_mask: 0.2647  decode.d7.loss_dice: 0.3549  decode.d8.loss_cls: 0.1742  decode.d8.loss_mask: 0.2656  decode.d8.loss_dice: 0.3460
07/30 22:07:47 - mmengine - INFO - Iter(train) [44950/80000]  base_lr: 4.7582e-05 lr: 4.7582e-06  eta: 4:15:20  time: 0.4394  data_time: 0.0097  memory: 5265  grad_norm: 68.2956  loss: 7.2434  decode.loss_cls: 0.2388  decode.loss_mask: 0.1879  decode.loss_dice: 0.2403  decode.d0.loss_cls: 0.9701  decode.d0.loss_mask: 0.1945  decode.d0.loss_dice: 0.2373  decode.d1.loss_cls: 0.2215  decode.d1.loss_mask: 0.1896  decode.d1.loss_dice: 0.2458  decode.d2.loss_cls: 0.2533  decode.d2.loss_mask: 0.1952  decode.d2.loss_dice: 0.2339  decode.d3.loss_cls: 0.2020  decode.d3.loss_mask: 0.1839  decode.d3.loss_dice: 0.2361  decode.d4.loss_cls: 0.1826  decode.d4.loss_mask: 0.1864  decode.d4.loss_dice: 0.2385  decode.d5.loss_cls: 0.1967  decode.d5.loss_mask: 0.1876  decode.d5.loss_dice: 0.2435  decode.d6.loss_cls: 0.2133  decode.d6.loss_mask: 0.1888  decode.d6.loss_dice: 0.2394  decode.d7.loss_cls: 0.2276  decode.d7.loss_mask: 0.1912  decode.d7.loss_dice: 0.2502  decode.d8.loss_cls: 0.2115  decode.d8.loss_mask: 0.1983  decode.d8.loss_dice: 0.2578
07/30 22:08:09 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 22:08:09 - mmengine - INFO - Iter(train) [45000/80000]  base_lr: 4.7521e-05 lr: 4.7521e-06  eta: 4:14:58  time: 0.4403  data_time: 0.0098  memory: 5265  grad_norm: 60.0993  loss: 7.7312  decode.loss_cls: 0.1725  decode.loss_mask: 0.2119  decode.loss_dice: 0.2630  decode.d0.loss_cls: 0.9268  decode.d0.loss_mask: 0.2157  decode.d0.loss_dice: 0.2881  decode.d1.loss_cls: 0.1875  decode.d1.loss_mask: 0.2150  decode.d1.loss_dice: 0.2705  decode.d2.loss_cls: 0.2414  decode.d2.loss_mask: 0.2155  decode.d2.loss_dice: 0.2613  decode.d3.loss_cls: 0.2054  decode.d3.loss_mask: 0.2145  decode.d3.loss_dice: 0.2672  decode.d4.loss_cls: 0.2075  decode.d4.loss_mask: 0.2166  decode.d4.loss_dice: 0.2902  decode.d5.loss_cls: 0.2107  decode.d5.loss_mask: 0.2127  decode.d5.loss_dice: 0.2667  decode.d6.loss_cls: 0.2244  decode.d6.loss_mask: 0.2133  decode.d6.loss_dice: 0.2721  decode.d7.loss_cls: 0.2303  decode.d7.loss_mask: 0.2140  decode.d7.loss_dice: 0.3094  decode.d8.loss_cls: 0.2069  decode.d8.loss_mask: 0.2135  decode.d8.loss_dice: 0.2867
07/30 22:08:09 - mmengine - INFO - Saving checkpoint at 45000 iterations
07/30 22:08:33 - mmengine - INFO - Iter(train) [45050/80000]  base_lr: 4.7460e-05 lr: 4.7460e-06  eta: 4:14:38  time: 0.4585  data_time: 0.0097  memory: 5305  grad_norm: 67.6519  loss: 7.6379  decode.loss_cls: 0.1522  decode.loss_mask: 0.2861  decode.loss_dice: 0.2714  decode.d0.loss_cls: 0.7753  decode.d0.loss_mask: 0.2880  decode.d0.loss_dice: 0.2893  decode.d1.loss_cls: 0.1736  decode.d1.loss_mask: 0.2871  decode.d1.loss_dice: 0.2896  decode.d2.loss_cls: 0.1033  decode.d2.loss_mask: 0.2857  decode.d2.loss_dice: 0.3022  decode.d3.loss_cls: 0.1229  decode.d3.loss_mask: 0.2819  decode.d3.loss_dice: 0.3109  decode.d4.loss_cls: 0.0923  decode.d4.loss_mask: 0.2880  decode.d4.loss_dice: 0.3039  decode.d5.loss_cls: 0.0874  decode.d5.loss_mask: 0.2856  decode.d5.loss_dice: 0.2925  decode.d6.loss_cls: 0.1354  decode.d6.loss_mask: 0.2805  decode.d6.loss_dice: 0.2944  decode.d7.loss_cls: 0.1279  decode.d7.loss_mask: 0.2802  decode.d7.loss_dice: 0.2766  decode.d8.loss_cls: 0.1135  decode.d8.loss_mask: 0.2810  decode.d8.loss_dice: 0.2794
07/30 22:08:55 - mmengine - INFO - Iter(train) [45100/80000]  base_lr: 4.7399e-05 lr: 4.7399e-06  eta: 4:14:16  time: 0.4385  data_time: 0.0098  memory: 5245  grad_norm: 57.1947  loss: 7.7843  decode.loss_cls: 0.2023  decode.loss_mask: 0.2372  decode.loss_dice: 0.2433  decode.d0.loss_cls: 1.0075  decode.d0.loss_mask: 0.2288  decode.d0.loss_dice: 0.2577  decode.d1.loss_cls: 0.2689  decode.d1.loss_mask: 0.2214  decode.d1.loss_dice: 0.2538  decode.d2.loss_cls: 0.2064  decode.d2.loss_mask: 0.2260  decode.d2.loss_dice: 0.2599  decode.d3.loss_cls: 0.2173  decode.d3.loss_mask: 0.2234  decode.d3.loss_dice: 0.2570  decode.d4.loss_cls: 0.1971  decode.d4.loss_mask: 0.2337  decode.d4.loss_dice: 0.2559  decode.d5.loss_cls: 0.1852  decode.d5.loss_mask: 0.2344  decode.d5.loss_dice: 0.2625  decode.d6.loss_cls: 0.1983  decode.d6.loss_mask: 0.2337  decode.d6.loss_dice: 0.2534  decode.d7.loss_cls: 0.2071  decode.d7.loss_mask: 0.2371  decode.d7.loss_dice: 0.2573  decode.d8.loss_cls: 0.2420  decode.d8.loss_mask: 0.2292  decode.d8.loss_dice: 0.2463
07/30 22:09:17 - mmengine - INFO - Iter(train) [45150/80000]  base_lr: 4.7338e-05 lr: 4.7338e-06  eta: 4:13:55  time: 0.4398  data_time: 0.0102  memory: 5261  grad_norm: 80.5129  loss: 7.3430  decode.loss_cls: 0.0673  decode.loss_mask: 0.3055  decode.loss_dice: 0.2884  decode.d0.loss_cls: 0.8737  decode.d0.loss_mask: 0.3103  decode.d0.loss_dice: 0.2879  decode.d1.loss_cls: 0.0587  decode.d1.loss_mask: 0.3044  decode.d1.loss_dice: 0.2807  decode.d2.loss_cls: 0.0457  decode.d2.loss_mask: 0.3008  decode.d2.loss_dice: 0.2849  decode.d3.loss_cls: 0.0500  decode.d3.loss_mask: 0.3021  decode.d3.loss_dice: 0.2842  decode.d4.loss_cls: 0.0618  decode.d4.loss_mask: 0.2986  decode.d4.loss_dice: 0.2838  decode.d5.loss_cls: 0.0992  decode.d5.loss_mask: 0.3006  decode.d5.loss_dice: 0.2820  decode.d6.loss_cls: 0.0698  decode.d6.loss_mask: 0.3060  decode.d6.loss_dice: 0.2860  decode.d7.loss_cls: 0.0666  decode.d7.loss_mask: 0.3007  decode.d7.loss_dice: 0.2818  decode.d8.loss_cls: 0.0679  decode.d8.loss_mask: 0.3066  decode.d8.loss_dice: 0.2871
07/30 22:09:39 - mmengine - INFO - Iter(train) [45200/80000]  base_lr: 4.7276e-05 lr: 4.7276e-06  eta: 4:13:33  time: 0.4398  data_time: 0.0098  memory: 5265  grad_norm: 38.1964  loss: 6.3568  decode.loss_cls: 0.1163  decode.loss_mask: 0.1999  decode.loss_dice: 0.2521  decode.d0.loss_cls: 1.0120  decode.d0.loss_mask: 0.2095  decode.d0.loss_dice: 0.2777  decode.d1.loss_cls: 0.1316  decode.d1.loss_mask: 0.2035  decode.d1.loss_dice: 0.2362  decode.d2.loss_cls: 0.1330  decode.d2.loss_mask: 0.2006  decode.d2.loss_dice: 0.2346  decode.d3.loss_cls: 0.0801  decode.d3.loss_mask: 0.1987  decode.d3.loss_dice: 0.2411  decode.d4.loss_cls: 0.1048  decode.d4.loss_mask: 0.2016  decode.d4.loss_dice: 0.2701  decode.d5.loss_cls: 0.0680  decode.d5.loss_mask: 0.2014  decode.d5.loss_dice: 0.2617  decode.d6.loss_cls: 0.0604  decode.d6.loss_mask: 0.1990  decode.d6.loss_dice: 0.2605  decode.d7.loss_cls: 0.0648  decode.d7.loss_mask: 0.2009  decode.d7.loss_dice: 0.2350  decode.d8.loss_cls: 0.0592  decode.d8.loss_mask: 0.1992  decode.d8.loss_dice: 0.2434
07/30 22:10:01 - mmengine - INFO - Iter(train) [45250/80000]  base_lr: 4.7215e-05 lr: 4.7215e-06  eta: 4:13:11  time: 0.4393  data_time: 0.0098  memory: 5246  grad_norm: 88.3602  loss: 6.3887  decode.loss_cls: 0.0876  decode.loss_mask: 0.2175  decode.loss_dice: 0.2409  decode.d0.loss_cls: 0.9012  decode.d0.loss_mask: 0.2301  decode.d0.loss_dice: 0.2706  decode.d1.loss_cls: 0.1278  decode.d1.loss_mask: 0.2192  decode.d1.loss_dice: 0.2456  decode.d2.loss_cls: 0.0788  decode.d2.loss_mask: 0.2211  decode.d2.loss_dice: 0.2460  decode.d3.loss_cls: 0.0795  decode.d3.loss_mask: 0.2201  decode.d3.loss_dice: 0.2420  decode.d4.loss_cls: 0.0772  decode.d4.loss_mask: 0.2220  decode.d4.loss_dice: 0.2381  decode.d5.loss_cls: 0.0837  decode.d5.loss_mask: 0.2176  decode.d5.loss_dice: 0.2331  decode.d6.loss_cls: 0.0986  decode.d6.loss_mask: 0.2197  decode.d6.loss_dice: 0.2393  decode.d7.loss_cls: 0.1015  decode.d7.loss_mask: 0.2232  decode.d7.loss_dice: 0.2461  decode.d8.loss_cls: 0.0923  decode.d8.loss_mask: 0.2231  decode.d8.loss_dice: 0.2450
07/30 22:10:23 - mmengine - INFO - Iter(train) [45300/80000]  base_lr: 4.7154e-05 lr: 4.7154e-06  eta: 4:12:49  time: 0.4402  data_time: 0.0098  memory: 5261  grad_norm: 33.6041  loss: 7.1256  decode.loss_cls: 0.1417  decode.loss_mask: 0.2611  decode.loss_dice: 0.2419  decode.d0.loss_cls: 0.8651  decode.d0.loss_mask: 0.2654  decode.d0.loss_dice: 0.2300  decode.d1.loss_cls: 0.1434  decode.d1.loss_mask: 0.2597  decode.d1.loss_dice: 0.2461  decode.d2.loss_cls: 0.1605  decode.d2.loss_mask: 0.2594  decode.d2.loss_dice: 0.2366  decode.d3.loss_cls: 0.1348  decode.d3.loss_mask: 0.2597  decode.d3.loss_dice: 0.2358  decode.d4.loss_cls: 0.1404  decode.d4.loss_mask: 0.2608  decode.d4.loss_dice: 0.2455  decode.d5.loss_cls: 0.1428  decode.d5.loss_mask: 0.2615  decode.d5.loss_dice: 0.2390  decode.d6.loss_cls: 0.1404  decode.d6.loss_mask: 0.2544  decode.d6.loss_dice: 0.2456  decode.d7.loss_cls: 0.1339  decode.d7.loss_mask: 0.2603  decode.d7.loss_dice: 0.2467  decode.d8.loss_cls: 0.1298  decode.d8.loss_mask: 0.2571  decode.d8.loss_dice: 0.2261
07/30 22:10:45 - mmengine - INFO - Iter(train) [45350/80000]  base_lr: 4.7093e-05 lr: 4.7093e-06  eta: 4:12:28  time: 0.4401  data_time: 0.0099  memory: 5265  grad_norm: 38.6289  loss: 5.8792  decode.loss_cls: 0.0489  decode.loss_mask: 0.2086  decode.loss_dice: 0.2278  decode.d0.loss_cls: 0.8041  decode.d0.loss_mask: 0.2103  decode.d0.loss_dice: 0.2308  decode.d1.loss_cls: 0.1113  decode.d1.loss_mask: 0.2124  decode.d1.loss_dice: 0.2404  decode.d2.loss_cls: 0.1016  decode.d2.loss_mask: 0.2081  decode.d2.loss_dice: 0.2271  decode.d3.loss_cls: 0.0739  decode.d3.loss_mask: 0.2101  decode.d3.loss_dice: 0.2178  decode.d4.loss_cls: 0.0716  decode.d4.loss_mask: 0.2091  decode.d4.loss_dice: 0.2287  decode.d5.loss_cls: 0.0714  decode.d5.loss_mask: 0.2087  decode.d5.loss_dice: 0.2271  decode.d6.loss_cls: 0.0717  decode.d6.loss_mask: 0.2085  decode.d6.loss_dice: 0.2233  decode.d7.loss_cls: 0.0624  decode.d7.loss_mask: 0.2075  decode.d7.loss_dice: 0.2356  decode.d8.loss_cls: 0.0825  decode.d8.loss_mask: 0.2104  decode.d8.loss_dice: 0.2273
07/30 22:11:07 - mmengine - INFO - Iter(train) [45400/80000]  base_lr: 4.7032e-05 lr: 4.7032e-06  eta: 4:12:06  time: 0.4400  data_time: 0.0096  memory: 5322  grad_norm: 48.7378  loss: 5.8983  decode.loss_cls: 0.0755  decode.loss_mask: 0.1816  decode.loss_dice: 0.2500  decode.d0.loss_cls: 1.0482  decode.d0.loss_mask: 0.1937  decode.d0.loss_dice: 0.2517  decode.d1.loss_cls: 0.0744  decode.d1.loss_mask: 0.1900  decode.d1.loss_dice: 0.2394  decode.d2.loss_cls: 0.0745  decode.d2.loss_mask: 0.1792  decode.d2.loss_dice: 0.2489  decode.d3.loss_cls: 0.0490  decode.d3.loss_mask: 0.1824  decode.d3.loss_dice: 0.2565  decode.d4.loss_cls: 0.0622  decode.d4.loss_mask: 0.1806  decode.d4.loss_dice: 0.2275  decode.d5.loss_cls: 0.0513  decode.d5.loss_mask: 0.1793  decode.d5.loss_dice: 0.2483  decode.d6.loss_cls: 0.0559  decode.d6.loss_mask: 0.1798  decode.d6.loss_dice: 0.2483  decode.d7.loss_cls: 0.0484  decode.d7.loss_mask: 0.1788  decode.d7.loss_dice: 0.2504  decode.d8.loss_cls: 0.0623  decode.d8.loss_mask: 0.1805  decode.d8.loss_dice: 0.2500
07/30 22:11:29 - mmengine - INFO - Iter(train) [45450/80000]  base_lr: 4.6971e-05 lr: 4.6971e-06  eta: 4:11:44  time: 0.4399  data_time: 0.0099  memory: 5261  grad_norm: 124.3629  loss: 6.5957  decode.loss_cls: 0.1154  decode.loss_mask: 0.1958  decode.loss_dice: 0.2363  decode.d0.loss_cls: 0.9790  decode.d0.loss_mask: 0.1963  decode.d0.loss_dice: 0.2421  decode.d1.loss_cls: 0.1704  decode.d1.loss_mask: 0.1969  decode.d1.loss_dice: 0.2403  decode.d2.loss_cls: 0.1169  decode.d2.loss_mask: 0.1985  decode.d2.loss_dice: 0.2478  decode.d3.loss_cls: 0.1505  decode.d3.loss_mask: 0.1967  decode.d3.loss_dice: 0.2424  decode.d4.loss_cls: 0.1442  decode.d4.loss_mask: 0.1977  decode.d4.loss_dice: 0.2290  decode.d5.loss_cls: 0.1292  decode.d5.loss_mask: 0.1974  decode.d5.loss_dice: 0.2362  decode.d6.loss_cls: 0.1822  decode.d6.loss_mask: 0.1984  decode.d6.loss_dice: 0.2390  decode.d7.loss_cls: 0.1258  decode.d7.loss_mask: 0.1952  decode.d7.loss_dice: 0.2392  decode.d8.loss_cls: 0.1224  decode.d8.loss_mask: 0.1979  decode.d8.loss_dice: 0.2364
07/30 22:11:51 - mmengine - INFO - Iter(train) [45500/80000]  base_lr: 4.6910e-05 lr: 4.6910e-06  eta: 4:11:22  time: 0.4394  data_time: 0.0099  memory: 5244  grad_norm: 80.6061  loss: 5.4543  decode.loss_cls: 0.0718  decode.loss_mask: 0.1760  decode.loss_dice: 0.2233  decode.d0.loss_cls: 0.8502  decode.d0.loss_mask: 0.1821  decode.d0.loss_dice: 0.2092  decode.d1.loss_cls: 0.0737  decode.d1.loss_mask: 0.1741  decode.d1.loss_dice: 0.1983  decode.d2.loss_cls: 0.0965  decode.d2.loss_mask: 0.1756  decode.d2.loss_dice: 0.2083  decode.d3.loss_cls: 0.0865  decode.d3.loss_mask: 0.1777  decode.d3.loss_dice: 0.2226  decode.d4.loss_cls: 0.0929  decode.d4.loss_mask: 0.1790  decode.d4.loss_dice: 0.1997  decode.d5.loss_cls: 0.0833  decode.d5.loss_mask: 0.1754  decode.d5.loss_dice: 0.2109  decode.d6.loss_cls: 0.0701  decode.d6.loss_mask: 0.1769  decode.d6.loss_dice: 0.2096  decode.d7.loss_cls: 0.0819  decode.d7.loss_mask: 0.1775  decode.d7.loss_dice: 0.2169  decode.d8.loss_cls: 0.0635  decode.d8.loss_mask: 0.1737  decode.d8.loss_dice: 0.2174
07/30 22:12:13 - mmengine - INFO - Iter(train) [45550/80000]  base_lr: 4.6848e-05 lr: 4.6848e-06  eta: 4:11:00  time: 0.4407  data_time: 0.0099  memory: 5246  grad_norm: 47.3589  loss: 7.6150  decode.loss_cls: 0.1498  decode.loss_mask: 0.3110  decode.loss_dice: 0.2549  decode.d0.loss_cls: 0.9394  decode.d0.loss_mask: 0.3064  decode.d0.loss_dice: 0.2427  decode.d1.loss_cls: 0.1731  decode.d1.loss_mask: 0.3055  decode.d1.loss_dice: 0.2310  decode.d2.loss_cls: 0.1204  decode.d2.loss_mask: 0.3043  decode.d2.loss_dice: 0.2479  decode.d3.loss_cls: 0.1127  decode.d3.loss_mask: 0.3083  decode.d3.loss_dice: 0.2237  decode.d4.loss_cls: 0.1052  decode.d4.loss_mask: 0.3131  decode.d4.loss_dice: 0.2516  decode.d5.loss_cls: 0.1464  decode.d5.loss_mask: 0.3156  decode.d5.loss_dice: 0.2231  decode.d6.loss_cls: 0.1057  decode.d6.loss_mask: 0.3100  decode.d6.loss_dice: 0.2270  decode.d7.loss_cls: 0.1416  decode.d7.loss_mask: 0.3103  decode.d7.loss_dice: 0.2472  decode.d8.loss_cls: 0.1347  decode.d8.loss_mask: 0.3131  decode.d8.loss_dice: 0.2391
07/30 22:12:35 - mmengine - INFO - Iter(train) [45600/80000]  base_lr: 4.6787e-05 lr: 4.6787e-06  eta: 4:10:39  time: 0.4406  data_time: 0.0098  memory: 5261  grad_norm: 52.5193  loss: 6.8603  decode.loss_cls: 0.0922  decode.loss_mask: 0.2243  decode.loss_dice: 0.2816  decode.d0.loss_cls: 1.0072  decode.d0.loss_mask: 0.2263  decode.d0.loss_dice: 0.2905  decode.d1.loss_cls: 0.0943  decode.d1.loss_mask: 0.2271  decode.d1.loss_dice: 0.2757  decode.d2.loss_cls: 0.1014  decode.d2.loss_mask: 0.2255  decode.d2.loss_dice: 0.2655  decode.d3.loss_cls: 0.0815  decode.d3.loss_mask: 0.2240  decode.d3.loss_dice: 0.2799  decode.d4.loss_cls: 0.0793  decode.d4.loss_mask: 0.2233  decode.d4.loss_dice: 0.2827  decode.d5.loss_cls: 0.0849  decode.d5.loss_mask: 0.2244  decode.d5.loss_dice: 0.2726  decode.d6.loss_cls: 0.0915  decode.d6.loss_mask: 0.2202  decode.d6.loss_dice: 0.2560  decode.d7.loss_cls: 0.1149  decode.d7.loss_mask: 0.2222  decode.d7.loss_dice: 0.2609  decode.d8.loss_cls: 0.1366  decode.d8.loss_mask: 0.2226  decode.d8.loss_dice: 0.2712
07/30 22:12:57 - mmengine - INFO - Iter(train) [45650/80000]  base_lr: 4.6726e-05 lr: 4.6726e-06  eta: 4:10:17  time: 0.4398  data_time: 0.0097  memory: 5278  grad_norm: 125.7936  loss: 9.2215  decode.loss_cls: 0.1759  decode.loss_mask: 0.2631  decode.loss_dice: 0.3326  decode.d0.loss_cls: 1.1598  decode.d0.loss_mask: 0.2687  decode.d0.loss_dice: 0.3469  decode.d1.loss_cls: 0.2945  decode.d1.loss_mask: 0.2628  decode.d1.loss_dice: 0.3283  decode.d2.loss_cls: 0.2256  decode.d2.loss_mask: 0.2623  decode.d2.loss_dice: 0.3336  decode.d3.loss_cls: 0.2438  decode.d3.loss_mask: 0.2556  decode.d3.loss_dice: 0.3415  decode.d4.loss_cls: 0.2288  decode.d4.loss_mask: 0.2567  decode.d4.loss_dice: 0.3566  decode.d5.loss_cls: 0.2359  decode.d5.loss_mask: 0.2558  decode.d5.loss_dice: 0.3290  decode.d6.loss_cls: 0.2508  decode.d6.loss_mask: 0.2557  decode.d6.loss_dice: 0.3277  decode.d7.loss_cls: 0.1827  decode.d7.loss_mask: 0.2619  decode.d7.loss_dice: 0.3287  decode.d8.loss_cls: 0.2541  decode.d8.loss_mask: 0.2598  decode.d8.loss_dice: 0.3422
07/30 22:13:19 - mmengine - INFO - Iter(train) [45700/80000]  base_lr: 4.6665e-05 lr: 4.6665e-06  eta: 4:09:55  time: 0.4398  data_time: 0.0098  memory: 5261  grad_norm: 33.3048  loss: 5.5662  decode.loss_cls: 0.0061  decode.loss_mask: 0.2537  decode.loss_dice: 0.2150  decode.d0.loss_cls: 0.7944  decode.d0.loss_mask: 0.2576  decode.d0.loss_dice: 0.2142  decode.d1.loss_cls: 0.0092  decode.d1.loss_mask: 0.2534  decode.d1.loss_dice: 0.2132  decode.d2.loss_cls: 0.0087  decode.d2.loss_mask: 0.2574  decode.d2.loss_dice: 0.2162  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.2537  decode.d3.loss_dice: 0.2098  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.2548  decode.d4.loss_dice: 0.2150  decode.d5.loss_cls: 0.0110  decode.d5.loss_mask: 0.2543  decode.d5.loss_dice: 0.2217  decode.d6.loss_cls: 0.0073  decode.d6.loss_mask: 0.2559  decode.d6.loss_dice: 0.2134  decode.d7.loss_cls: 0.0074  decode.d7.loss_mask: 0.2554  decode.d7.loss_dice: 0.2143  decode.d8.loss_cls: 0.0075  decode.d8.loss_mask: 0.2544  decode.d8.loss_dice: 0.2122
07/30 22:13:41 - mmengine - INFO - Iter(train) [45750/80000]  base_lr: 4.6603e-05 lr: 4.6603e-06  eta: 4:09:33  time: 0.4397  data_time: 0.0096  memory: 5261  grad_norm: 70.7979  loss: 7.7028  decode.loss_cls: 0.2227  decode.loss_mask: 0.2634  decode.loss_dice: 0.2373  decode.d0.loss_cls: 0.8584  decode.d0.loss_mask: 0.2742  decode.d0.loss_dice: 0.2376  decode.d1.loss_cls: 0.1851  decode.d1.loss_mask: 0.2654  decode.d1.loss_dice: 0.2366  decode.d2.loss_cls: 0.1625  decode.d2.loss_mask: 0.2642  decode.d2.loss_dice: 0.2374  decode.d3.loss_cls: 0.1735  decode.d3.loss_mask: 0.2657  decode.d3.loss_dice: 0.2381  decode.d4.loss_cls: 0.1837  decode.d4.loss_mask: 0.2645  decode.d4.loss_dice: 0.2398  decode.d5.loss_cls: 0.2113  decode.d5.loss_mask: 0.2651  decode.d5.loss_dice: 0.2371  decode.d6.loss_cls: 0.2274  decode.d6.loss_mask: 0.2619  decode.d6.loss_dice: 0.2339  decode.d7.loss_cls: 0.2413  decode.d7.loss_mask: 0.2646  decode.d7.loss_dice: 0.2354  decode.d8.loss_cls: 0.2176  decode.d8.loss_mask: 0.2640  decode.d8.loss_dice: 0.2332
07/30 22:14:03 - mmengine - INFO - Iter(train) [45800/80000]  base_lr: 4.6542e-05 lr: 4.6542e-06  eta: 4:09:12  time: 0.4400  data_time: 0.0095  memory: 5304  grad_norm: 35.3217  loss: 5.8167  decode.loss_cls: 0.0299  decode.loss_mask: 0.1799  decode.loss_dice: 0.2493  decode.d0.loss_cls: 0.8644  decode.d0.loss_mask: 0.1831  decode.d0.loss_dice: 0.2576  decode.d1.loss_cls: 0.0979  decode.d1.loss_mask: 0.1793  decode.d1.loss_dice: 0.2466  decode.d2.loss_cls: 0.1044  decode.d2.loss_mask: 0.1794  decode.d2.loss_dice: 0.2375  decode.d3.loss_cls: 0.0941  decode.d3.loss_mask: 0.1825  decode.d3.loss_dice: 0.2425  decode.d4.loss_cls: 0.1008  decode.d4.loss_mask: 0.1783  decode.d4.loss_dice: 0.2318  decode.d5.loss_cls: 0.0919  decode.d5.loss_mask: 0.1803  decode.d5.loss_dice: 0.2372  decode.d6.loss_cls: 0.0672  decode.d6.loss_mask: 0.1790  decode.d6.loss_dice: 0.2542  decode.d7.loss_cls: 0.0790  decode.d7.loss_mask: 0.1756  decode.d7.loss_dice: 0.2347  decode.d8.loss_cls: 0.0556  decode.d8.loss_mask: 0.1776  decode.d8.loss_dice: 0.2452
07/30 22:14:25 - mmengine - INFO - Iter(train) [45850/80000]  base_lr: 4.6481e-05 lr: 4.6481e-06  eta: 4:08:50  time: 0.4398  data_time: 0.0098  memory: 5278  grad_norm: 32.5626  loss: 7.6261  decode.loss_cls: 0.1656  decode.loss_mask: 0.2356  decode.loss_dice: 0.2647  decode.d0.loss_cls: 1.0623  decode.d0.loss_mask: 0.2327  decode.d0.loss_dice: 0.2789  decode.d1.loss_cls: 0.1800  decode.d1.loss_mask: 0.2276  decode.d1.loss_dice: 0.2801  decode.d2.loss_cls: 0.1583  decode.d2.loss_mask: 0.2369  decode.d2.loss_dice: 0.2880  decode.d3.loss_cls: 0.1347  decode.d3.loss_mask: 0.2750  decode.d3.loss_dice: 0.2936  decode.d4.loss_cls: 0.1658  decode.d4.loss_mask: 0.2362  decode.d4.loss_dice: 0.2714  decode.d5.loss_cls: 0.1309  decode.d5.loss_mask: 0.2659  decode.d5.loss_dice: 0.2535  decode.d6.loss_cls: 0.1115  decode.d6.loss_mask: 0.2410  decode.d6.loss_dice: 0.2702  decode.d7.loss_cls: 0.1363  decode.d7.loss_mask: 0.2418  decode.d7.loss_dice: 0.2777  decode.d8.loss_cls: 0.1315  decode.d8.loss_mask: 0.2720  decode.d8.loss_dice: 0.3061
07/30 22:14:47 - mmengine - INFO - Iter(train) [45900/80000]  base_lr: 4.6420e-05 lr: 4.6420e-06  eta: 4:08:28  time: 0.4397  data_time: 0.0099  memory: 5261  grad_norm: 41.4904  loss: 6.4830  decode.loss_cls: 0.0497  decode.loss_mask: 0.2377  decode.loss_dice: 0.2840  decode.d0.loss_cls: 0.8026  decode.d0.loss_mask: 0.2404  decode.d0.loss_dice: 0.2828  decode.d1.loss_cls: 0.0726  decode.d1.loss_mask: 0.2360  decode.d1.loss_dice: 0.2766  decode.d2.loss_cls: 0.0724  decode.d2.loss_mask: 0.2384  decode.d2.loss_dice: 0.2798  decode.d3.loss_cls: 0.0542  decode.d3.loss_mask: 0.2369  decode.d3.loss_dice: 0.2781  decode.d4.loss_cls: 0.0588  decode.d4.loss_mask: 0.2401  decode.d4.loss_dice: 0.2806  decode.d5.loss_cls: 0.0588  decode.d5.loss_mask: 0.2380  decode.d5.loss_dice: 0.2769  decode.d6.loss_cls: 0.0532  decode.d6.loss_mask: 0.2361  decode.d6.loss_dice: 0.2710  decode.d7.loss_cls: 0.0511  decode.d7.loss_mask: 0.2351  decode.d7.loss_dice: 0.2835  decode.d8.loss_cls: 0.0525  decode.d8.loss_mask: 0.2357  decode.d8.loss_dice: 0.2696
07/30 22:15:09 - mmengine - INFO - Iter(train) [45950/80000]  base_lr: 4.6358e-05 lr: 4.6358e-06  eta: 4:08:06  time: 0.4402  data_time: 0.0099  memory: 5265  grad_norm: 51.0114  loss: 6.9890  decode.loss_cls: 0.0714  decode.loss_mask: 0.2704  decode.loss_dice: 0.2566  decode.d0.loss_cls: 0.8948  decode.d0.loss_mask: 0.2900  decode.d0.loss_dice: 0.2609  decode.d1.loss_cls: 0.1240  decode.d1.loss_mask: 0.2776  decode.d1.loss_dice: 0.2426  decode.d2.loss_cls: 0.1054  decode.d2.loss_mask: 0.2746  decode.d2.loss_dice: 0.2468  decode.d3.loss_cls: 0.1232  decode.d3.loss_mask: 0.2725  decode.d3.loss_dice: 0.2432  decode.d4.loss_cls: 0.0865  decode.d4.loss_mask: 0.2772  decode.d4.loss_dice: 0.2480  decode.d5.loss_cls: 0.0930  decode.d5.loss_mask: 0.2721  decode.d5.loss_dice: 0.2387  decode.d6.loss_cls: 0.0911  decode.d6.loss_mask: 0.2774  decode.d6.loss_dice: 0.2442  decode.d7.loss_cls: 0.0847  decode.d7.loss_mask: 0.2759  decode.d7.loss_dice: 0.2441  decode.d8.loss_cls: 0.0838  decode.d8.loss_mask: 0.2727  decode.d8.loss_dice: 0.2455
07/30 22:15:31 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 22:15:31 - mmengine - INFO - Iter(train) [46000/80000]  base_lr: 4.6297e-05 lr: 4.6297e-06  eta: 4:07:45  time: 0.4390  data_time: 0.0096  memory: 5265  grad_norm: 62.4999  loss: 7.7798  decode.loss_cls: 0.1353  decode.loss_mask: 0.2782  decode.loss_dice: 0.2841  decode.d0.loss_cls: 0.9819  decode.d0.loss_mask: 0.2877  decode.d0.loss_dice: 0.3119  decode.d1.loss_cls: 0.1283  decode.d1.loss_mask: 0.2793  decode.d1.loss_dice: 0.2614  decode.d2.loss_cls: 0.1547  decode.d2.loss_mask: 0.2774  decode.d2.loss_dice: 0.2886  decode.d3.loss_cls: 0.1525  decode.d3.loss_mask: 0.2762  decode.d3.loss_dice: 0.2669  decode.d4.loss_cls: 0.1028  decode.d4.loss_mask: 0.2762  decode.d4.loss_dice: 0.2932  decode.d5.loss_cls: 0.1144  decode.d5.loss_mask: 0.2747  decode.d5.loss_dice: 0.2683  decode.d6.loss_cls: 0.1092  decode.d6.loss_mask: 0.2764  decode.d6.loss_dice: 0.3036  decode.d7.loss_cls: 0.1090  decode.d7.loss_mask: 0.2823  decode.d7.loss_dice: 0.3083  decode.d8.loss_cls: 0.1406  decode.d8.loss_mask: 0.2818  decode.d8.loss_dice: 0.2748
07/30 22:15:53 - mmengine - INFO - Iter(train) [46050/80000]  base_lr: 4.6236e-05 lr: 4.6236e-06  eta: 4:07:23  time: 0.4392  data_time: 0.0099  memory: 5305  grad_norm: 77.1224  loss: 9.2008  decode.loss_cls: 0.2479  decode.loss_mask: 0.2344  decode.loss_dice: 0.3000  decode.d0.loss_cls: 1.2355  decode.d0.loss_mask: 0.2339  decode.d0.loss_dice: 0.3027  decode.d1.loss_cls: 0.4099  decode.d1.loss_mask: 0.2319  decode.d1.loss_dice: 0.2885  decode.d2.loss_cls: 0.2822  decode.d2.loss_mask: 0.2309  decode.d2.loss_dice: 0.3040  decode.d3.loss_cls: 0.2983  decode.d3.loss_mask: 0.2347  decode.d3.loss_dice: 0.2883  decode.d4.loss_cls: 0.3044  decode.d4.loss_mask: 0.2376  decode.d4.loss_dice: 0.2928  decode.d5.loss_cls: 0.2943  decode.d5.loss_mask: 0.2335  decode.d5.loss_dice: 0.2991  decode.d6.loss_cls: 0.2516  decode.d6.loss_mask: 0.2379  decode.d6.loss_dice: 0.2990  decode.d7.loss_cls: 0.2789  decode.d7.loss_mask: 0.2373  decode.d7.loss_dice: 0.2939  decode.d8.loss_cls: 0.2876  decode.d8.loss_mask: 0.2361  decode.d8.loss_dice: 0.2937
07/30 22:16:15 - mmengine - INFO - Iter(train) [46100/80000]  base_lr: 4.6175e-05 lr: 4.6175e-06  eta: 4:07:01  time: 0.4401  data_time: 0.0096  memory: 5265  grad_norm: 39.7002  loss: 5.2034  decode.loss_cls: 0.0486  decode.loss_mask: 0.1678  decode.loss_dice: 0.2240  decode.d0.loss_cls: 0.9493  decode.d0.loss_mask: 0.1652  decode.d0.loss_dice: 0.2227  decode.d1.loss_cls: 0.0829  decode.d1.loss_mask: 0.1659  decode.d1.loss_dice: 0.2265  decode.d2.loss_cls: 0.0202  decode.d2.loss_mask: 0.1674  decode.d2.loss_dice: 0.2195  decode.d3.loss_cls: 0.0383  decode.d3.loss_mask: 0.1691  decode.d3.loss_dice: 0.2207  decode.d4.loss_cls: 0.0434  decode.d4.loss_mask: 0.1660  decode.d4.loss_dice: 0.2217  decode.d5.loss_cls: 0.0256  decode.d5.loss_mask: 0.1669  decode.d5.loss_dice: 0.2276  decode.d6.loss_cls: 0.0254  decode.d6.loss_mask: 0.1658  decode.d6.loss_dice: 0.2300  decode.d7.loss_cls: 0.0310  decode.d7.loss_mask: 0.1658  decode.d7.loss_dice: 0.2243  decode.d8.loss_cls: 0.0333  decode.d8.loss_mask: 0.1637  decode.d8.loss_dice: 0.2249
07/30 22:16:37 - mmengine - INFO - Iter(train) [46150/80000]  base_lr: 4.6113e-05 lr: 4.6113e-06  eta: 4:06:39  time: 0.4398  data_time: 0.0098  memory: 5246  grad_norm: 103.6760  loss: 6.7264  decode.loss_cls: 0.0494  decode.loss_mask: 0.2636  decode.loss_dice: 0.2649  decode.d0.loss_cls: 0.8630  decode.d0.loss_mask: 0.2553  decode.d0.loss_dice: 0.2590  decode.d1.loss_cls: 0.0991  decode.d1.loss_mask: 0.2587  decode.d1.loss_dice: 0.2610  decode.d2.loss_cls: 0.0854  decode.d2.loss_mask: 0.2590  decode.d2.loss_dice: 0.2692  decode.d3.loss_cls: 0.0869  decode.d3.loss_mask: 0.2604  decode.d3.loss_dice: 0.2711  decode.d4.loss_cls: 0.0525  decode.d4.loss_mask: 0.2674  decode.d4.loss_dice: 0.2788  decode.d5.loss_cls: 0.0427  decode.d5.loss_mask: 0.2623  decode.d5.loss_dice: 0.2670  decode.d6.loss_cls: 0.0371  decode.d6.loss_mask: 0.2553  decode.d6.loss_dice: 0.2892  decode.d7.loss_cls: 0.0375  decode.d7.loss_mask: 0.2593  decode.d7.loss_dice: 0.2801  decode.d8.loss_cls: 0.0529  decode.d8.loss_mask: 0.2623  decode.d8.loss_dice: 0.2760
07/30 22:16:59 - mmengine - INFO - Iter(train) [46200/80000]  base_lr: 4.6052e-05 lr: 4.6052e-06  eta: 4:06:18  time: 0.4413  data_time: 0.0098  memory: 5303  grad_norm: 47.2394  loss: 6.7257  decode.loss_cls: 0.0867  decode.loss_mask: 0.2110  decode.loss_dice: 0.2569  decode.d0.loss_cls: 1.0503  decode.d0.loss_mask: 0.2175  decode.d0.loss_dice: 0.2520  decode.d1.loss_cls: 0.1898  decode.d1.loss_mask: 0.2159  decode.d1.loss_dice: 0.2521  decode.d2.loss_cls: 0.1165  decode.d2.loss_mask: 0.2144  decode.d2.loss_dice: 0.2519  decode.d3.loss_cls: 0.0920  decode.d3.loss_mask: 0.2141  decode.d3.loss_dice: 0.2669  decode.d4.loss_cls: 0.0892  decode.d4.loss_mask: 0.2096  decode.d4.loss_dice: 0.2520  decode.d5.loss_cls: 0.0901  decode.d5.loss_mask: 0.2105  decode.d5.loss_dice: 0.2672  decode.d6.loss_cls: 0.0883  decode.d6.loss_mask: 0.2109  decode.d6.loss_dice: 0.2615  decode.d7.loss_cls: 0.0987  decode.d7.loss_mask: 0.2134  decode.d7.loss_dice: 0.2614  decode.d8.loss_cls: 0.1028  decode.d8.loss_mask: 0.2118  decode.d8.loss_dice: 0.2702
07/30 22:17:21 - mmengine - INFO - Iter(train) [46250/80000]  base_lr: 4.5991e-05 lr: 4.5991e-06  eta: 4:05:56  time: 0.4400  data_time: 0.0096  memory: 5323  grad_norm: 31.1176  loss: 6.3519  decode.loss_cls: 0.0781  decode.loss_mask: 0.1952  decode.loss_dice: 0.2654  decode.d0.loss_cls: 0.9451  decode.d0.loss_mask: 0.1971  decode.d0.loss_dice: 0.2975  decode.d1.loss_cls: 0.1515  decode.d1.loss_mask: 0.1955  decode.d1.loss_dice: 0.2601  decode.d2.loss_cls: 0.0987  decode.d2.loss_mask: 0.1916  decode.d2.loss_dice: 0.2597  decode.d3.loss_cls: 0.0512  decode.d3.loss_mask: 0.1972  decode.d3.loss_dice: 0.2771  decode.d4.loss_cls: 0.0886  decode.d4.loss_mask: 0.1939  decode.d4.loss_dice: 0.2712  decode.d5.loss_cls: 0.0820  decode.d5.loss_mask: 0.1946  decode.d5.loss_dice: 0.2635  decode.d6.loss_cls: 0.0781  decode.d6.loss_mask: 0.1949  decode.d6.loss_dice: 0.2584  decode.d7.loss_cls: 0.0672  decode.d7.loss_mask: 0.1966  decode.d7.loss_dice: 0.2588  decode.d8.loss_cls: 0.0783  decode.d8.loss_mask: 0.1939  decode.d8.loss_dice: 0.2710
07/30 22:17:43 - mmengine - INFO - Iter(train) [46300/80000]  base_lr: 4.5929e-05 lr: 4.5929e-06  eta: 4:05:34  time: 0.4400  data_time: 0.0099  memory: 5265  grad_norm: 57.2661  loss: 8.1722  decode.loss_cls: 0.1133  decode.loss_mask: 0.3223  decode.loss_dice: 0.2561  decode.d0.loss_cls: 1.1726  decode.d0.loss_mask: 0.3317  decode.d0.loss_dice: 0.2481  decode.d1.loss_cls: 0.1414  decode.d1.loss_mask: 0.3266  decode.d1.loss_dice: 0.2687  decode.d2.loss_cls: 0.1431  decode.d2.loss_mask: 0.3186  decode.d2.loss_dice: 0.2469  decode.d3.loss_cls: 0.1205  decode.d3.loss_mask: 0.3194  decode.d3.loss_dice: 0.2689  decode.d4.loss_cls: 0.1474  decode.d4.loss_mask: 0.3219  decode.d4.loss_dice: 0.2554  decode.d5.loss_cls: 0.1277  decode.d5.loss_mask: 0.3243  decode.d5.loss_dice: 0.2539  decode.d6.loss_cls: 0.1297  decode.d6.loss_mask: 0.3206  decode.d6.loss_dice: 0.2607  decode.d7.loss_cls: 0.1472  decode.d7.loss_mask: 0.3229  decode.d7.loss_dice: 0.2490  decode.d8.loss_cls: 0.1369  decode.d8.loss_mask: 0.3184  decode.d8.loss_dice: 0.2583
07/30 22:18:05 - mmengine - INFO - Iter(train) [46350/80000]  base_lr: 4.5868e-05 lr: 4.5868e-06  eta: 4:05:12  time: 0.4409  data_time: 0.0099  memory: 5305  grad_norm: 73.1724  loss: 9.6200  decode.loss_cls: 0.3453  decode.loss_mask: 0.2314  decode.loss_dice: 0.3159  decode.d0.loss_cls: 0.8882  decode.d0.loss_mask: 0.2356  decode.d0.loss_dice: 0.3387  decode.d1.loss_cls: 0.3825  decode.d1.loss_mask: 0.2281  decode.d1.loss_dice: 0.3357  decode.d2.loss_cls: 0.3361  decode.d2.loss_mask: 0.2328  decode.d2.loss_dice: 0.3309  decode.d3.loss_cls: 0.3364  decode.d3.loss_mask: 0.2299  decode.d3.loss_dice: 0.3428  decode.d4.loss_cls: 0.3551  decode.d4.loss_mask: 0.2319  decode.d4.loss_dice: 0.3036  decode.d5.loss_cls: 0.3439  decode.d5.loss_mask: 0.2312  decode.d5.loss_dice: 0.3399  decode.d6.loss_cls: 0.3281  decode.d6.loss_mask: 0.2289  decode.d6.loss_dice: 0.3267  decode.d7.loss_cls: 0.3130  decode.d7.loss_mask: 0.2313  decode.d7.loss_dice: 0.3725  decode.d8.loss_cls: 0.3150  decode.d8.loss_mask: 0.2260  decode.d8.loss_dice: 0.3626
07/30 22:18:27 - mmengine - INFO - Iter(train) [46400/80000]  base_lr: 4.5807e-05 lr: 4.5807e-06  eta: 4:04:51  time: 0.4395  data_time: 0.0099  memory: 5277  grad_norm: 64.1688  loss: 7.3156  decode.loss_cls: 0.1045  decode.loss_mask: 0.2337  decode.loss_dice: 0.2336  decode.d0.loss_cls: 1.0403  decode.d0.loss_mask: 0.2415  decode.d0.loss_dice: 0.2781  decode.d1.loss_cls: 0.1809  decode.d1.loss_mask: 0.2354  decode.d1.loss_dice: 0.2728  decode.d2.loss_cls: 0.1351  decode.d2.loss_mask: 0.2350  decode.d2.loss_dice: 0.2708  decode.d3.loss_cls: 0.1284  decode.d3.loss_mask: 0.2349  decode.d3.loss_dice: 0.2759  decode.d4.loss_cls: 0.1203  decode.d4.loss_mask: 0.2312  decode.d4.loss_dice: 0.2791  decode.d5.loss_cls: 0.1190  decode.d5.loss_mask: 0.2356  decode.d5.loss_dice: 0.2756  decode.d6.loss_cls: 0.1293  decode.d6.loss_mask: 0.2350  decode.d6.loss_dice: 0.2812  decode.d7.loss_cls: 0.1265  decode.d7.loss_mask: 0.2350  decode.d7.loss_dice: 0.2833  decode.d8.loss_cls: 0.1496  decode.d8.loss_mask: 0.2325  decode.d8.loss_dice: 0.2818
07/30 22:18:49 - mmengine - INFO - Iter(train) [46450/80000]  base_lr: 4.5745e-05 lr: 4.5745e-06  eta: 4:04:29  time: 0.4396  data_time: 0.0096  memory: 5305  grad_norm: 40.4414  loss: 6.4001  decode.loss_cls: 0.0432  decode.loss_mask: 0.2378  decode.loss_dice: 0.2572  decode.d0.loss_cls: 0.8920  decode.d0.loss_mask: 0.2403  decode.d0.loss_dice: 0.2562  decode.d1.loss_cls: 0.0924  decode.d1.loss_mask: 0.2414  decode.d1.loss_dice: 0.2657  decode.d2.loss_cls: 0.0706  decode.d2.loss_mask: 0.2417  decode.d2.loss_dice: 0.2630  decode.d3.loss_cls: 0.0654  decode.d3.loss_mask: 0.2385  decode.d3.loss_dice: 0.2579  decode.d4.loss_cls: 0.0527  decode.d4.loss_mask: 0.2362  decode.d4.loss_dice: 0.2476  decode.d5.loss_cls: 0.0640  decode.d5.loss_mask: 0.2425  decode.d5.loss_dice: 0.2566  decode.d6.loss_cls: 0.0483  decode.d6.loss_mask: 0.2384  decode.d6.loss_dice: 0.2594  decode.d7.loss_cls: 0.0546  decode.d7.loss_mask: 0.2396  decode.d7.loss_dice: 0.2551  decode.d8.loss_cls: 0.0514  decode.d8.loss_mask: 0.2368  decode.d8.loss_dice: 0.2538
07/30 22:19:11 - mmengine - INFO - Iter(train) [46500/80000]  base_lr: 4.5684e-05 lr: 4.5684e-06  eta: 4:04:07  time: 0.4391  data_time: 0.0096  memory: 5305  grad_norm: 59.5384  loss: 5.2790  decode.loss_cls: 0.0436  decode.loss_mask: 0.1759  decode.loss_dice: 0.2506  decode.d0.loss_cls: 0.9310  decode.d0.loss_mask: 0.1752  decode.d0.loss_dice: 0.2475  decode.d1.loss_cls: 0.0199  decode.d1.loss_mask: 0.1760  decode.d1.loss_dice: 0.2403  decode.d2.loss_cls: 0.0247  decode.d2.loss_mask: 0.1747  decode.d2.loss_dice: 0.2392  decode.d3.loss_cls: 0.0312  decode.d3.loss_mask: 0.1784  decode.d3.loss_dice: 0.2299  decode.d4.loss_cls: 0.0199  decode.d4.loss_mask: 0.1775  decode.d4.loss_dice: 0.2322  decode.d5.loss_cls: 0.0187  decode.d5.loss_mask: 0.1772  decode.d5.loss_dice: 0.2298  decode.d6.loss_cls: 0.0221  decode.d6.loss_mask: 0.1776  decode.d6.loss_dice: 0.2321  decode.d7.loss_cls: 0.0205  decode.d7.loss_mask: 0.1743  decode.d7.loss_dice: 0.2283  decode.d8.loss_cls: 0.0225  decode.d8.loss_mask: 0.1738  decode.d8.loss_dice: 0.2345
07/30 22:19:33 - mmengine - INFO - Iter(train) [46550/80000]  base_lr: 4.5623e-05 lr: 4.5623e-06  eta: 4:03:45  time: 0.4407  data_time: 0.0098  memory: 5265  grad_norm: 49.6768  loss: 6.0881  decode.loss_cls: 0.1248  decode.loss_mask: 0.1856  decode.loss_dice: 0.2136  decode.d0.loss_cls: 0.9812  decode.d0.loss_mask: 0.1865  decode.d0.loss_dice: 0.2219  decode.d1.loss_cls: 0.1285  decode.d1.loss_mask: 0.1790  decode.d1.loss_dice: 0.2122  decode.d2.loss_cls: 0.1376  decode.d2.loss_mask: 0.1788  decode.d2.loss_dice: 0.2134  decode.d3.loss_cls: 0.1253  decode.d3.loss_mask: 0.1843  decode.d3.loss_dice: 0.2168  decode.d4.loss_cls: 0.1170  decode.d4.loss_mask: 0.1850  decode.d4.loss_dice: 0.2154  decode.d5.loss_cls: 0.1268  decode.d5.loss_mask: 0.1829  decode.d5.loss_dice: 0.2161  decode.d6.loss_cls: 0.1120  decode.d6.loss_mask: 0.1828  decode.d6.loss_dice: 0.2152  decode.d7.loss_cls: 0.1137  decode.d7.loss_mask: 0.1817  decode.d7.loss_dice: 0.2150  decode.d8.loss_cls: 0.1345  decode.d8.loss_mask: 0.1845  decode.d8.loss_dice: 0.2160
07/30 22:19:55 - mmengine - INFO - Iter(train) [46600/80000]  base_lr: 4.5561e-05 lr: 4.5561e-06  eta: 4:03:23  time: 0.4389  data_time: 0.0097  memory: 5265  grad_norm: 154.0585  loss: 7.5280  decode.loss_cls: 0.1770  decode.loss_mask: 0.2014  decode.loss_dice: 0.2737  decode.d0.loss_cls: 0.9403  decode.d0.loss_mask: 0.2024  decode.d0.loss_dice: 0.3053  decode.d1.loss_cls: 0.1962  decode.d1.loss_mask: 0.2011  decode.d1.loss_dice: 0.2662  decode.d2.loss_cls: 0.1926  decode.d2.loss_mask: 0.2002  decode.d2.loss_dice: 0.2781  decode.d3.loss_cls: 0.2248  decode.d3.loss_mask: 0.2001  decode.d3.loss_dice: 0.2656  decode.d4.loss_cls: 0.2419  decode.d4.loss_mask: 0.2011  decode.d4.loss_dice: 0.2820  decode.d5.loss_cls: 0.2055  decode.d5.loss_mask: 0.1982  decode.d5.loss_dice: 0.2713  decode.d6.loss_cls: 0.2126  decode.d6.loss_mask: 0.1978  decode.d6.loss_dice: 0.2656  decode.d7.loss_cls: 0.1964  decode.d7.loss_mask: 0.1984  decode.d7.loss_dice: 0.2672  decode.d8.loss_cls: 0.2003  decode.d8.loss_mask: 0.1965  decode.d8.loss_dice: 0.2682
07/30 22:20:17 - mmengine - INFO - Iter(train) [46650/80000]  base_lr: 4.5500e-05 lr: 4.5500e-06  eta: 4:03:02  time: 0.4406  data_time: 0.0096  memory: 5261  grad_norm: 37.0378  loss: 6.4950  decode.loss_cls: 0.0976  decode.loss_mask: 0.2101  decode.loss_dice: 0.2479  decode.d0.loss_cls: 0.8827  decode.d0.loss_mask: 0.2151  decode.d0.loss_dice: 0.2445  decode.d1.loss_cls: 0.2127  decode.d1.loss_mask: 0.2093  decode.d1.loss_dice: 0.2400  decode.d2.loss_cls: 0.1058  decode.d2.loss_mask: 0.2110  decode.d2.loss_dice: 0.2406  decode.d3.loss_cls: 0.1236  decode.d3.loss_mask: 0.2081  decode.d3.loss_dice: 0.2492  decode.d4.loss_cls: 0.1132  decode.d4.loss_mask: 0.2090  decode.d4.loss_dice: 0.2470  decode.d5.loss_cls: 0.1044  decode.d5.loss_mask: 0.2104  decode.d5.loss_dice: 0.2408  decode.d6.loss_cls: 0.1026  decode.d6.loss_mask: 0.2106  decode.d6.loss_dice: 0.2513  decode.d7.loss_cls: 0.1033  decode.d7.loss_mask: 0.2093  decode.d7.loss_dice: 0.2484  decode.d8.loss_cls: 0.0927  decode.d8.loss_mask: 0.2078  decode.d8.loss_dice: 0.2463
07/30 22:20:39 - mmengine - INFO - Iter(train) [46700/80000]  base_lr: 4.5438e-05 lr: 4.5438e-06  eta: 4:02:40  time: 0.4401  data_time: 0.0098  memory: 5261  grad_norm: 31.6302  loss: 6.1964  decode.loss_cls: 0.0542  decode.loss_mask: 0.2663  decode.loss_dice: 0.2164  decode.d0.loss_cls: 0.7661  decode.d0.loss_mask: 0.2743  decode.d0.loss_dice: 0.2275  decode.d1.loss_cls: 0.0830  decode.d1.loss_mask: 0.2694  decode.d1.loss_dice: 0.2381  decode.d2.loss_cls: 0.0562  decode.d2.loss_mask: 0.2677  decode.d2.loss_dice: 0.2159  decode.d3.loss_cls: 0.0580  decode.d3.loss_mask: 0.2638  decode.d3.loss_dice: 0.2154  decode.d4.loss_cls: 0.0564  decode.d4.loss_mask: 0.2674  decode.d4.loss_dice: 0.2305  decode.d5.loss_cls: 0.0694  decode.d5.loss_mask: 0.2658  decode.d5.loss_dice: 0.2187  decode.d6.loss_cls: 0.0542  decode.d6.loss_mask: 0.2699  decode.d6.loss_dice: 0.2145  decode.d7.loss_cls: 0.0430  decode.d7.loss_mask: 0.2670  decode.d7.loss_dice: 0.2303  decode.d8.loss_cls: 0.0536  decode.d8.loss_mask: 0.2649  decode.d8.loss_dice: 0.2185
07/30 22:21:01 - mmengine - INFO - Iter(train) [46750/80000]  base_lr: 4.5377e-05 lr: 4.5377e-06  eta: 4:02:18  time: 0.4408  data_time: 0.0097  memory: 5278  grad_norm: 87.9064  loss: 6.0247  decode.loss_cls: 0.0797  decode.loss_mask: 0.2144  decode.loss_dice: 0.2118  decode.d0.loss_cls: 0.8609  decode.d0.loss_mask: 0.2170  decode.d0.loss_dice: 0.2222  decode.d1.loss_cls: 0.1050  decode.d1.loss_mask: 0.2160  decode.d1.loss_dice: 0.2177  decode.d2.loss_cls: 0.0960  decode.d2.loss_mask: 0.2117  decode.d2.loss_dice: 0.2195  decode.d3.loss_cls: 0.1055  decode.d3.loss_mask: 0.2158  decode.d3.loss_dice: 0.2214  decode.d4.loss_cls: 0.0706  decode.d4.loss_mask: 0.2115  decode.d4.loss_dice: 0.2156  decode.d5.loss_cls: 0.0743  decode.d5.loss_mask: 0.2143  decode.d5.loss_dice: 0.2178  decode.d6.loss_cls: 0.1062  decode.d6.loss_mask: 0.2124  decode.d6.loss_dice: 0.2148  decode.d7.loss_cls: 0.1026  decode.d7.loss_mask: 0.2129  decode.d7.loss_dice: 0.2105  decode.d8.loss_cls: 0.1176  decode.d8.loss_mask: 0.2112  decode.d8.loss_dice: 0.2180
07/30 22:21:23 - mmengine - INFO - Iter(train) [46800/80000]  base_lr: 4.5316e-05 lr: 4.5316e-06  eta: 4:01:57  time: 0.4402  data_time: 0.0098  memory: 5229  grad_norm: 51.7598  loss: 6.2087  decode.loss_cls: 0.0992  decode.loss_mask: 0.2091  decode.loss_dice: 0.2210  decode.d0.loss_cls: 0.8900  decode.d0.loss_mask: 0.2145  decode.d0.loss_dice: 0.2393  decode.d1.loss_cls: 0.1246  decode.d1.loss_mask: 0.2100  decode.d1.loss_dice: 0.2247  decode.d2.loss_cls: 0.1002  decode.d2.loss_mask: 0.2108  decode.d2.loss_dice: 0.2305  decode.d3.loss_cls: 0.1095  decode.d3.loss_mask: 0.2139  decode.d3.loss_dice: 0.2227  decode.d4.loss_cls: 0.1056  decode.d4.loss_mask: 0.2133  decode.d4.loss_dice: 0.2286  decode.d5.loss_cls: 0.1003  decode.d5.loss_mask: 0.2122  decode.d5.loss_dice: 0.2269  decode.d6.loss_cls: 0.1022  decode.d6.loss_mask: 0.2127  decode.d6.loss_dice: 0.2379  decode.d7.loss_cls: 0.0988  decode.d7.loss_mask: 0.2115  decode.d7.loss_dice: 0.2221  decode.d8.loss_cls: 0.0861  decode.d8.loss_mask: 0.2119  decode.d8.loss_dice: 0.2186
07/30 22:21:45 - mmengine - INFO - Iter(train) [46850/80000]  base_lr: 4.5254e-05 lr: 4.5254e-06  eta: 4:01:35  time: 0.4397  data_time: 0.0099  memory: 5244  grad_norm: 76.4178  loss: 7.5895  decode.loss_cls: 0.1668  decode.loss_mask: 0.2351  decode.loss_dice: 0.2399  decode.d0.loss_cls: 0.9611  decode.d0.loss_mask: 0.2338  decode.d0.loss_dice: 0.2594  decode.d1.loss_cls: 0.1742  decode.d1.loss_mask: 0.2320  decode.d1.loss_dice: 0.2573  decode.d2.loss_cls: 0.1703  decode.d2.loss_mask: 0.2309  decode.d2.loss_dice: 0.2522  decode.d3.loss_cls: 0.1926  decode.d3.loss_mask: 0.2349  decode.d3.loss_dice: 0.2626  decode.d4.loss_cls: 0.1993  decode.d4.loss_mask: 0.2318  decode.d4.loss_dice: 0.2562  decode.d5.loss_cls: 0.1754  decode.d5.loss_mask: 0.2318  decode.d5.loss_dice: 0.2359  decode.d6.loss_cls: 0.2249  decode.d6.loss_mask: 0.2467  decode.d6.loss_dice: 0.2816  decode.d7.loss_cls: 0.2161  decode.d7.loss_mask: 0.2396  decode.d7.loss_dice: 0.2742  decode.d8.loss_cls: 0.1920  decode.d8.loss_mask: 0.2315  decode.d8.loss_dice: 0.2494
07/30 22:22:07 - mmengine - INFO - Iter(train) [46900/80000]  base_lr: 4.5193e-05 lr: 4.5193e-06  eta: 4:01:13  time: 0.4390  data_time: 0.0098  memory: 5261  grad_norm: 35.9324  loss: 6.0623  decode.loss_cls: 0.0910  decode.loss_mask: 0.2072  decode.loss_dice: 0.2146  decode.d0.loss_cls: 0.9146  decode.d0.loss_mask: 0.2106  decode.d0.loss_dice: 0.2213  decode.d1.loss_cls: 0.1626  decode.d1.loss_mask: 0.2063  decode.d1.loss_dice: 0.2144  decode.d2.loss_cls: 0.1327  decode.d2.loss_mask: 0.2024  decode.d2.loss_dice: 0.2165  decode.d3.loss_cls: 0.0772  decode.d3.loss_mask: 0.2139  decode.d3.loss_dice: 0.2206  decode.d4.loss_cls: 0.0922  decode.d4.loss_mask: 0.2096  decode.d4.loss_dice: 0.2154  decode.d5.loss_cls: 0.0801  decode.d5.loss_mask: 0.2042  decode.d5.loss_dice: 0.2178  decode.d6.loss_cls: 0.0961  decode.d6.loss_mask: 0.2066  decode.d6.loss_dice: 0.2195  decode.d7.loss_cls: 0.0791  decode.d7.loss_mask: 0.2070  decode.d7.loss_dice: 0.2137  decode.d8.loss_cls: 0.0877  decode.d8.loss_mask: 0.2098  decode.d8.loss_dice: 0.2177
07/30 22:22:29 - mmengine - INFO - Iter(train) [46950/80000]  base_lr: 4.5131e-05 lr: 4.5131e-06  eta: 4:00:51  time: 0.4394  data_time: 0.0097  memory: 5305  grad_norm: 146.1803  loss: 6.5309  decode.loss_cls: 0.1141  decode.loss_mask: 0.2102  decode.loss_dice: 0.2504  decode.d0.loss_cls: 0.9403  decode.d0.loss_mask: 0.2209  decode.d0.loss_dice: 0.2739  decode.d1.loss_cls: 0.1177  decode.d1.loss_mask: 0.2193  decode.d1.loss_dice: 0.2535  decode.d2.loss_cls: 0.0871  decode.d2.loss_mask: 0.2115  decode.d2.loss_dice: 0.2518  decode.d3.loss_cls: 0.1063  decode.d3.loss_mask: 0.2123  decode.d3.loss_dice: 0.2420  decode.d4.loss_cls: 0.0929  decode.d4.loss_mask: 0.2118  decode.d4.loss_dice: 0.2522  decode.d5.loss_cls: 0.0614  decode.d5.loss_mask: 0.2100  decode.d5.loss_dice: 0.2388  decode.d6.loss_cls: 0.1077  decode.d6.loss_mask: 0.2119  decode.d6.loss_dice: 0.2581  decode.d7.loss_cls: 0.1442  decode.d7.loss_mask: 0.2112  decode.d7.loss_dice: 0.2548  decode.d8.loss_cls: 0.1129  decode.d8.loss_mask: 0.2086  decode.d8.loss_dice: 0.2432
07/30 22:22:51 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250730_164001
07/30 22:22:51 - mmengine - INFO - Iter(train) [47000/80000]  base_lr: 4.5070e-05 lr: 4.5070e-06  eta: 4:00:29  time: 0.4389  data_time: 0.0097  memory: 5305  grad_norm: 64.5783  loss: 8.5050  decode.loss_cls: 0.1118  decode.loss_mask: 0.2848  decode.loss_dice: 0.3214  decode.d0.loss_cls: 1.1154  decode.d0.loss_mask: 0.3076  decode.d0.loss_dice: 0.3373  decode.d1.loss_cls: 0.2164  decode.d1.loss_mask: 0.2917  decode.d1.loss_dice: 0.3320  decode.d2.loss_cls: 0.1654  decode.d2.loss_mask: 0.2864  decode.d2.loss_dice: 0.3197  decode.d3.loss_cls: 0.1743  decode.d3.loss_mask: 0.2753  decode.d3.loss_dice: 0.3133  decode.d4.loss_cls: 0.2062  decode.d4.loss_mask: 0.2738  decode.d4.loss_dice: 0.3118  decode.d5.loss_cls: 0.1438  decode.d5.loss_mask: 0.2848  decode.d5.loss_dice: 0.3134  decode.d6.loss_cls: 0.1024  decode.d6.loss_mask: 0.2843  decode.d6.loss_dice: 0.3101  decode.d7.loss_cls: 0.1111  decode.d7.loss_mask: 0.2845  decode.d7.loss_dice: 0.3165  decode.d8.loss_cls: 0.1060  decode.d8.loss_mask: 0.2823  decode.d8.loss_dice: 0.3209
07/30 22:23:13 - mmengine - INFO - Iter(train) [47050/80000]  base_lr: 4.5008e-05 lr: 4.5008e-06  eta: 4:00:08  time: 0.4400  data_time: 0.0097  memory: 5261  grad_norm: 75.5564  loss: 6.5001  decode.loss_cls: 0.0928  decode.loss_mask: 0.2215  decode.loss_dice: 0.2335  decode.d0.loss_cls: 0.9921  decode.d0.loss_mask: 0.2320  decode.d0.loss_dice: 0.2392  decode.d1.loss_cls: 0.0911  decode.d1.loss_mask: 0.2288  decode.d1.loss_dice: 0.2431  decode.d2.loss_cls: 0.0957  decode.d2.loss_mask: 0.2260  decode.d2.loss_dice: 0.2462  decode.d3.loss_cls: 0.0774  decode.d3.loss_mask: 0.2218  decode.d3.loss_dice: 0.2509  decode.d4.loss_cls: 0.0832  decode.d4.loss_mask: 0.2244  decode.d4.loss_dice: 0.2487  decode.d5.loss_cls: 0.0760  decode.d5.loss_mask: 0.2206  decode.d5.loss_dice: 0.2664  decode.d6.loss_cls: 0.0739  decode.d6.loss_mask: 0.2265  decode.d6.loss_dice: 0.2643  decode.d7.loss_cls: 0.1292  decode.d7.loss_mask: 0.2262  decode.d7.loss_dice: 0.2416  decode.d8.loss_cls: 0.0762  decode.d8.loss_mask: 0.2225  decode.d8.loss_dice: 0.2285
07/30 22:23:35 - mmengine - INFO - Iter(train) [47100/80000]  base_lr: 4.4947e-05 lr: 4.4947e-06  eta: 3:59:46  time: 0.4388  data_time: 0.0096  memory: 5261  grad_norm: 75.4846  loss: 7.3149  decode.loss_cls: 0.1396  decode.loss_mask: 0.2410  decode.loss_dice: 0.2587  decode.d0.loss_cls: 1.0039  decode.d0.loss_mask: 0.2545  decode.d0.loss_dice: 0.3142  decode.d1.loss_cls: 0.1583  decode.d1.loss_mask: 0.2452  decode.d1.loss_dice: 0.2782  decode.d2.loss_cls: 0.1436  decode.d2.loss_mask: 0.2429  decode.d2.loss_dice: 0.2797  decode.d3.loss_cls: 0.1324  decode.d3.loss_mask: 0.2449  decode.d3.loss_dice: 0.2676  decode.d4.loss_cls: 0.1149  decode.d4.loss_mask: 0.2440  decode.d4.loss_dice: 0.2689  decode.d5.loss_cls: 0.1043  decode.d5.loss_mask: 0.2431  decode.d5.loss_dice: 0.2485  decode.d6.loss_cls: 0.1238  decode.d6.loss_mask: 0.2418  decode.d6.loss_dice: 0.2568  decode.d7.loss_cls: 0.1162  decode.d7.loss_mask: 0.2415  decode.d7.loss_dice: 0.2742  decode.d8.loss_cls: 0.1310  decode.d8.loss_mask: 0.2423  decode.d8.loss_dice: 0.2589
07/30 22:23:57 - mmengine - INFO - Iter(train) [47150/80000]  base_lr: 4.4885e-05 lr: 4.4885e-06  eta: 3:59:24  time: 0.4396  data_time: 0.0098  memory: 5265  grad_norm: 28.7378  loss: 6.0626  decode.loss_cls: 0.0395  decode.loss_mask: 0.2241  decode.loss_dice: 0.2609  decode.d0.loss_cls: 0.8010  decode.d0.loss_mask: 0.2239  decode.d0.loss_dice: 0.2593  decode.d1.loss_cls: 0.0779  decode.d1.loss_mask: 0.2246  decode.d1.loss_dice: 0.2531  decode.d2.loss_cls: 0.0416  decode.d2.loss_mask: 0.2230  decode.d2.loss_dice: 0.2689  decode.d3.loss_cls: 0.0401  decode.d3.loss_mask: 0.2208  decode.d3.loss_dice: 0.2592  decode.d4.loss_cls: 0.0383  decode.d4.loss_mask: 0.2236  decode.d4.loss_dice: 0.2608  decode.d5.loss_cls: 0.0369  decode.d5.loss_mask: 0.2239  decode.d5.loss_dice: 0.2546  decode.d6.loss_cls: 0.0624  decode.d6.loss_mask: 0.2211  decode.d6.loss_dice: 0.2577  decode.d7.loss_cls: 0.0642  decode.d7.loss_mask: 0.2248  decode.d7.loss_dice: 0.2542  decode.d8.loss_cls: 0.0410  decode.d8.loss_mask: 0.2226  decode.d8.loss_dice: 0.2585
07/30 22:24:19 - mmengine - INFO - Iter(train) [47200/80000]  base_lr: 4.4824e-05 lr: 4.4824e-06  eta: 3:59:02  time: 0.4400  data_time: 0.0097  memory: 5305  grad_norm: 67.6431  loss: 7.3791  decode.loss_cls: 0.1618  decode.loss_mask: 0.2182  decode.loss_dice: 0.2514  decode.d0.loss_cls: 1.0341  decode.d0.loss_mask: 0.2214  decode.d0.loss_dice: 0.2659  decode.d1.loss_cls: 0.2578  decode.d1.loss_mask: 0.2220  decode.d1.loss_dice: 0.2807  decode.d2.loss_cls: 0.1697  decode.d2.loss_mask: 0.2157  decode.d2.loss_dice: 0.2551  decode.d3.loss_cls: 0.2211  decode.d3.loss_mask: 0.2157  decode.d3.loss_dice: 0.2591  decode.d4.loss_cls: 0.1727  decode.d4.loss_mask: 0.2173  decode.d4.loss_dice: 0.2587  decode.d5.loss_cls: 0.1282  decode.d5.loss_mask: 0.2179  decode.d5.loss_dice: 0.2606  decode.d6.loss_cls: 0.1235  decode.d6.loss_mask: 0.2163  decode.d6.loss_dice: 0.2735  decode.d7.loss_cls: 0.2057  decode.d7.loss_mask: 0.2150  decode.d7.loss_dice: 0.2449  decode.d8.loss_cls: 0.1230  decode.d8.loss_mask: 0.2166  decode.d8.loss_dice: 0.2555
07/30 22:24:41 - mmengine - INFO - Iter(train) [47250/80000]  base_lr: 4.4762e-05 lr: 4.4762e-06  eta: 3:58:41  time: 0.4401  data_time: 0.0099  memory: 5245  grad_norm: 55.0398  loss: 6.0102  decode.loss_cls: 0.0224  decode.loss_mask: 0.2563  decode.loss_dice: 0.2423  decode.d0.loss_cls: 0.8273  decode.d0.loss_mask: 0.2561  decode.d0.loss_dice: 0.2311  decode.d1.loss_cls: 0.0662  decode.d1.loss_mask: 0.2590  decode.d1.loss_dice: 0.2256  decode.d2.loss_cls: 0.0237  decode.d2.loss_mask: 0.2522  decode.d2.loss_dice: 0.2380  decode.d3.loss_cls: 0.0249  decode.d3.loss_mask: 0.2600  decode.d3.loss_dice: 0.2382  decode.d4.loss_cls: 0.0221  decode.d4.loss_mask: 0.2600  decode.d4.loss_dice: 0.2412  decode.d5.loss_cls: 0.0213  decode.d5.loss_mask: 0.2574  decode.d5.loss_dice: 0.2382  decode.d6.loss_cls: 0.0255  decode.d6.loss_mask: 0.2590  decode.d6.loss_dice: 0.2391  decode.d7.loss_cls: 0.0250  decode.d7.loss_mask: 0.2497  decode.d7.loss_dice: 0.2338  decode.d8.loss_cls: 0.0245  decode.d8.loss_mask: 0.2546  decode.d8.loss_dice: 0.2354
07/30 22:25:03 - mmengine - INFO - Iter(train) [47300/80000]  base_lr: 4.4701e-05 lr: 4.4701e-06  eta: 3:58:19  time: 0.4397  data_time: 0.0096  memory: 5304  grad_norm: 28.7144  loss: 5.7761  decode.loss_cls: 0.0482  decode.loss_mask: 0.1897  decode.loss_dice: 0.2256  decode.d0.loss_cls: 0.8749  decode.d0.loss_mask: 0.1903  decode.d0.loss_dice: 0.2206  decode.d1.loss_cls: 0.1072  decode.d1.loss_mask: 0.1887  decode.d1.loss_dice: 0.2185  decode.d2.loss_cls: 0.1054  decode.d2.loss_mask: 0.1899  decode.d2.loss_dice: 0.2202  decode.d3.loss_cls: 0.0972  decode.d3.loss_mask: 0.1895  decode.d3.loss_dice: 0.2232  decode.d4.loss_cls: 0.0980  decode.d4.loss_mask: 0.1898  decode.d4.loss_dice: 0.2250  decode.d5.loss_cls: 0.0429  decode.d5.loss_mask: 0.1930  decode.d5.loss_dice: 0.2303  decode.d6.loss_cls: 0.0886  decode.d6.loss_mask: 0.1883  decode.d6.loss_dice: 0.2171  decode.d7.loss_cls: 0.0772  decode.d7.loss_mask: 0.1912  decode.d7.loss_dice: 0.2201  decode.d8.loss_cls: 0.1079  decode.d8.loss_mask: 0.1857  decode.d8.loss_dice: 0.2321
07/30 22:25:25 - mmengine - INFO - Iter(train) [47350/80000]  base_lr: 4.4639e-05 lr: 4.4639e-06  eta: 3:57:57  time: 0.4398  data_time: 0.0097  memory: 5305  grad_norm: 57.6341  loss: 6.8811  decode.loss_cls: 0.1022  decode.loss_mask: 0.2507  decode.loss_dice: 0.2538  decode.d0.loss_cls: 0.7691  decode.d0.loss_mask: 0.2622  decode.d0.loss_dice: 0.2649  decode.d1.loss_cls: 0.1212  decode.d1.loss_mask: 0.2585  decode.d1.loss_dice: 0.2508  decode.d2.loss_cls: 0.1280  decode.d2.loss_mask: 0.2582  decode.d2.loss_dice: 0.2478  decode.d3.loss_cls: 0.1123  decode.d3.loss_mask: 0.2546  decode.d3.loss_dice: 0.2498  decode.d4.loss_cls: 0.0925  decode.d4.loss_mask: 0.2591  decode.d4.loss_dice: 0.2551  decode.d5.loss_cls: 0.0984  decode.d5.loss_mask: 0.2614  decode.d5.loss_dice: 0.2598  decode.d6.loss_cls: 0.1421  decode.d6.loss_mask: 0.2531  decode.d6.loss_dice: 0.2463  decode.d7.loss_cls: 0.1160  decode.d7.loss_mask: 0.2564  decode.d7.loss_dice: 0.2531  decode.d8.loss_cls: 0.0900  decode.d8.loss_mask: 0.2565  decode.d8.loss_dice: 0.2573
07/30 22:25:47 - mmengine - INFO - Iter(train) [47400/80000]  base_lr: 4.4578e-05 lr: 4.4578e-06  eta: 3:57:35  time: 0.4401  data_time: 0.0097  memory: 5265  grad_norm: 93.9255  loss: 7.9723  decode.loss_cls: 0.2560  decode.loss_mask: 0.2065  decode.loss_dice: 0.2583  decode.d0.loss_cls: 1.0247  decode.d0.loss_mask: 0.2147  decode.d0.loss_dice: 0.2622  decode.d1.loss_cls: 0.2711  decode.d1.loss_mask: 0.2090  decode.d1.loss_dice: 0.2691  decode.d2.loss_cls: 0.2612  decode.d2.loss_mask: 0.2056  decode.d2.loss_dice: 0.2508  decode.d3.loss_cls: 0.2230  decode.d3.loss_mask: 0.2049  decode.d3.loss_dice: 0.2618  decode.d4.loss_cls: 0.2151  decode.d4.loss_mask: 0.2058  decode.d4.loss_dice: 0.2512  decode.d5.loss_cls: 0.2690  decode.d5.loss_mask: 0.2065  decode.d5.loss_dice: 0.2618  decode.d6.loss_cls: 0.2600  decode.d6.loss_mask: 0.2097  decode.d6.loss_dice: 0.2738  decode.d7.loss_cls: 0.2434  decode.d7.loss_mask: 0.2092  decode.d7.loss_dice: 0.2611  decode.d8.loss_cls: 0.2575  decode.d8.loss_mask: 0.2090  decode.d8.loss_dice: 0.2603
07/30 22:26:09 - mmengine - INFO - Iter(train) [47450/80000]  base_lr: 4.4516e-05 lr: 4.4516e-06  eta: 3:57:13  time: 0.4403  data_time: 0.0100  memory: 5229  grad_norm: 122.0693  loss: 7.7476  decode.loss_cls: 0.1810  decode.loss_mask: 0.2635  decode.loss_dice: 0.2539  decode.d0.loss_cls: 0.9701  decode.d0.loss_mask: 0.2373  decode.d0.loss_dice: 0.2782  decode.d1.loss_cls: 0.2449  decode.d1.loss_mask: 0.2365  decode.d1.loss_dice: 0.2584  decode.d2.loss_cls: 0.1971  decode.d2.loss_mask: 0.2365  decode.d2.loss_dice: 0.2618  decode.d3.loss_cls: 0.1619  decode.d3.loss_mask: 0.2354  decode.d3.loss_dice: 0.2635  decode.d4.loss_cls: 0.1589  decode.d4.loss_mask: 0.2343  decode.d4.loss_dice: 0.2681  decode.d5.loss_cls: 0.1620  decode.d5.loss_mask: 0.2370  decode.d5.loss_dice: 0.2630  decode.d6.loss_cls: 0.1957  decode.d6.loss_mask: 0.2356  decode.d6.loss_dice: 0.2661  decode.d7.loss_cls: 0.2322  decode.d7.loss_mask: 0.2339  decode.d7.loss_dice: 0.2733  decode.d8.loss_cls: 0.1657  decode.d8.loss_mask: 0.2657  decode.d8.loss_dice: 0.2761
07/30 22:26:31 - mmengine - INFO - Iter(train) [47500/80000]  base_lr: 4.4455e-05 lr: 4.4455e-06  eta: 3:56:52  time: 0.4410  data_time: 0.0099  memory: 5261  grad_norm: 28.0253  loss: 5.2042  decode.loss_cls: 0.0169  decode.loss_mask: 0.1881  decode.loss_dice: 0.2025  decode.d0.loss_cls: 1.0204  decode.d0.loss_mask: 0.1931  decode.d0.loss_dice: 0.2097  decode.d1.loss_cls: 0.0438  decode.d1.loss_mask: 0.1895  decode.d1.loss_dice: 0.2035  decode.d2.loss_cls: 0.0370  decode.d2.loss_mask: 0.1868  decode.d2.loss_dice: 0.1998  decode.d3.loss_cls: 0.0377  decode.d3.loss_mask: 0.1875  decode.d3.loss_dice: 0.1985  decode.d4.loss_cls: 0.0379  decode.d4.loss_mask: 0.1866  decode.d4.loss_dice: 0.1971  decode.d5.loss_cls: 0.0389  decode.d5.loss_mask: 0.1868  decode.d5.loss_dice: 0.2025  decode.d6.loss_cls: 0.0208  decode.d6.loss_mask: 0.1881  decode.d6.loss_dice: 0.2004  decode.d7.loss_cls: 0.0406  decode.d7.loss_mask: 0.1887  decode.d7.loss_dice: 0.1948  decode.d8.loss_cls: 0.0143  decode.d8.loss_mask: 0.1878  decode.d8.loss_dice: 0.2042
07/30 22:26:53 - mmengine - INFO - Iter(train) [47550/80000]  base_lr: 4.4393e-05 lr: 4.4393e-06  eta: 3:56:30  time: 0.4401  data_time: 0.0097  memory: 5265  grad_norm: 39.8242  loss: 7.4273  decode.loss_cls: 0.1363  decode.loss_mask: 0.2365  decode.loss_dice: 0.2676  decode.d0.loss_cls: 1.0736  decode.d0.loss_mask: 0.2236  decode.d0.loss_dice: 0.2715  decode.d1.loss_cls: 0.2559  decode.d1.loss_mask: 0.2137  decode.d1.loss_dice: 0.2556  decode.d2.loss_cls: 0.1833  decode.d2.loss_mask: 0.2318  decode.d2.loss_dice: 0.2779  decode.d3.loss_cls: 0.1600  decode.d3.loss_mask: 0.2088  decode.d3.loss_dice: 0.2560  decode.d4.loss_cls: 0.1517  decode.d4.loss_mask: 0.2219  decode.d4.loss_dice: 0.2649  decode.d5.loss_cls: 0.1597  decode.d5.loss_mask: 0.2151  decode.d5.loss_dice: 0.2399  decode.d6.loss_cls: 0.1627  decode.d6.loss_mask: 0.2227  decode.d6.loss_dice: 0.2402  decode.d7.loss_cls: 0.1934  decode.d7.loss_mask: 0.2168  decode.d7.loss_dice: 0.2329  decode.d8.loss_cls: 0.1830  decode.d8.loss_mask: 0.2211  decode.d8.loss_dice: 0.2494
07/30 22:27:15 - mmengine - INFO - Iter(train) [47600/80000]  base_lr: 4.4332e-05 lr: 4.4332e-06  eta: 3:56:08  time: 0.4405  data_time: 0.0097  memory: 5279  grad_norm: 46.9247  loss: 7.0821  decode.loss_cls: 0.0348  decode.loss_mask: 0.3049  decode.loss_dice: 0.2743  decode.d0.loss_cls: 0.9643  decode.d0.loss_mask: 0.2965  decode.d0.loss_dice: 0.2695  decode.d1.loss_cls: 0.0950  decode.d1.loss_mask: 0.2959  decode.d1.loss_dice: 0.2696  decode.d2.loss_cls: 0.0303  decode.d2.loss_mask: 0.3066  decode.d2.loss_dice: 0.2732  decode.d3.loss_cls: 0.0233  decode.d3.loss_mask: 0.2988  decode.d3.loss_dice: 0.2699  decode.d4.loss_cls: 0.0870  decode.d4.loss_mask: 0.2937  decode.d4.loss_dice: 0.2729  decode.d5.loss_cls: 0.0322  decode.d5.loss_mask: 0.2994  decode.d5.loss_dice: 0.2766  decode.d6.loss_cls: 0.0261  decode.d6.loss_mask: 0.2976  decode.d6.loss_dice: 0.2752  decode.d7.loss_cls: 0.0375  decode.d7.loss_mask: 0.2954  decode.d7.loss_dice: 0.2741  decode.d8.loss_cls: 0.0388  decode.d8.loss_mask: 0.2985  decode.d8.loss_dice: 0.2702
