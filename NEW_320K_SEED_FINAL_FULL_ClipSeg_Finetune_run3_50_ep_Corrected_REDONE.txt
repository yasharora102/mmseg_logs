==========================================
SLURM_JOB_ID = 2470943
SLURM_NODELIST = gnode074
SLURM_JOB_GPUS = 0
==========================================
wandb: Currently logged in as: yasharora102 to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in /scratch/seg_benchmark/wandb/run-20250806_023318-6uqlruwk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-waterfall-30
wandb: ‚≠êÔ∏è View project at https://wandb.ai/yasharora102/clipseg-finetune
wandb: üöÄ View run at https://wandb.ai/yasharora102/clipseg-finetune/runs/6uqlruwk
Using device: cuda
Loaded 6311 masks with shape (352, 352).
Created 52933 examples from 6311 images.
Traceback (most recent call last):
  File "/home2/yasharora120/segmentation_benchmark/ClipSegV3/train_3.py", line 553, in <module>
    train_and_validate(args)
  File "/home2/yasharora120/segmentation_benchmark/ClipSegV3/train_3.py", line 343, in train_and_validate
    val_ds   = FoodPlateSegDataset(args.val_images,   args.val_masks,   LABEL_TO_NAME, args.image_size)
  File "/home2/yasharora120/segmentation_benchmark/ClipSegV3/train_3.py", line 103, in __init__
    for f in os.listdir(images_dir)
FileNotFoundError: [Errno 2] No such file or directory: '/scratch/seg_benchmark/splits_flat/new_test/images'
Traceback (most recent call last):
  File "/home2/yasharora120/segmentation_benchmark/ClipSegV3/train_3.py", line 553, in <module>
    train_and_validate(args)
  File "/home2/yasharora120/segmentation_benchmark/ClipSegV3/train_3.py", line 343, in train_and_validate
    val_ds   = FoodPlateSegDataset(args.val_images,   args.val_masks,   LABEL_TO_NAME, args.image_size)
  File "/home2/yasharora120/segmentation_benchmark/ClipSegV3/train_3.py", line 103, in __init__
    for f in os.listdir(images_dir)
FileNotFoundError: [Errno 2] No such file or directory: '/scratch/seg_benchmark/splits_flat/new_test/images'
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33msilver-waterfall-30[0m at: [34mhttps://wandb.ai/yasharora102/clipseg-finetune/runs/6uqlruwk[0m
[1;34mwandb[0m: Find logs at: [1;35m../../../../scratch/seg_benchmark/wandb/run-20250806_023318-6uqlruwk/logs[0m
Traceback (most recent call last):
  File "/home2/yasharora120/miniconda3/envs/py310_2/lib/python3.10/site-packages/transformers/utils/hub.py", line 424, in cached_files
    hf_hub_download(
  File "/home2/yasharora120/miniconda3/envs/py310_2/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/home2/yasharora120/miniconda3/envs/py310_2/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/scratch/seg_benchmark/NEW_FULL_Correctlabels/clipseg_finetune_v1_RESIZED_Corrected_FINAL_seg_full_redone/epoch_50'. Use `repo_type` argument if needed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/yasharora120/segmentation_benchmark/ClipSegV3/eval2.py", line 194, in <module>
    main(args)
  File "/home2/yasharora120/segmentation_benchmark/ClipSegV3/eval2.py", line 59, in main
    model = CLIPSegForImageSegmentation.from_pretrained(args.model_path).to(device)
  File "/home2/yasharora120/miniconda3/envs/py310_2/lib/python3.10/site-packages/transformers/modeling_utils.py", line 272, in _wrapper
    return func(*args, **kwargs)
  File "/home2/yasharora120/miniconda3/envs/py310_2/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4134, in from_pretrained
    resolved_config_file = cached_file(
  File "/home2/yasharora120/miniconda3/envs/py310_2/lib/python3.10/site-packages/transformers/utils/hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
  File "/home2/yasharora120/miniconda3/envs/py310_2/lib/python3.10/site-packages/transformers/utils/hub.py", line 470, in cached_files
    resolved_files = [
  File "/home2/yasharora120/miniconda3/envs/py310_2/lib/python3.10/site-packages/transformers/utils/hub.py", line 471, in <listcomp>
    _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision) for filename in full_filenames
  File "/home2/yasharora120/miniconda3/envs/py310_2/lib/python3.10/site-packages/transformers/utils/hub.py", line 134, in _get_cache_file_to_return
    resolved_file = try_to_load_from_cache(path_or_repo_id, full_filename, cache_dir=cache_dir, revision=revision)
  File "/home2/yasharora120/miniconda3/envs/py310_2/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/home2/yasharora120/miniconda3/envs/py310_2/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/scratch/seg_benchmark/NEW_FULL_Correctlabels/clipseg_finetune_v1_RESIZED_Corrected_FINAL_seg_full_redone/epoch_50'. Use `repo_type` argument if needed.
usage: eval2.py [-h] --image_dir IMAGE_DIR --mask_dir MASK_DIR --model_path
                MODEL_PATH --label_map_json LABEL_MAP_JSON
                [--image_size IMAGE_SIZE] [--output_dir OUTPUT_DIR]
                [--num_vis NUM_VIS]
eval2.py: error: unrecognized arguments: _NEW
