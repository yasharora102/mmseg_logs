==========================================
SLURM_JOB_ID = 2465925
SLURM_NODELIST = gnode080
SLURM_JOB_GPUS = 2
==========================================
07/25 16:15:56 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.23 (main, Jun  5 2025, 13:40:20) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 928713336
    GPU 0: NVIDIA GeForce RTX 2080 Ti
    CUDA_HOME: /opt/cuda-12.1/
    NVCC: Cuda compilation tools, release 12.1, V12.1.66
    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
    PyTorch: 2.1.2
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 928713336
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

07/25 16:15:57 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=16, enable=False)
backbone_embed_multi = dict(decay_mult=0.0, lr_mult=0.1)
backbone_norm_multi = dict(decay_mult=0.0, lr_mult=0.1)
crop_size = (
    512,
    1024,
)
custom_keys = dict({
    'absolute_pos_embed':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone':
    dict(decay_mult=1.0, lr_mult=0.1),
    'backbone.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.patch_embed.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.2.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.3.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.4.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.5.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'level_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_feat':
    dict(decay_mult=0.0, lr_mult=1.0),
    'relative_position_bias_table':
    dict(decay_mult=0.0, lr_mult=0.1)
})
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        512,
        1024,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    test_cfg=dict(size_divisor=32),
    type='SegDataPreProcessor')
data_root = '/scratch/seg_benchmark/seg_FULL/'
dataset_type = 'YourDataset_BIG'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False, interval=5000, save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'))
default_scope = 'mmseg'
depths = [
    2,
    2,
    6,
    2,
]
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
img_suffix = '.jpg'
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        attn_drop_rate=0.0,
        depths=[
            2,
            2,
            6,
            2,
        ],
        drop_path_rate=0.3,
        drop_rate=0.0,
        embed_dims=96,
        frozen_stages=-1,
        init_cfg=dict(
            checkpoint=
            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth',
            type='Pretrained'),
        mlp_ratio=4,
        num_heads=[
            3,
            6,
            12,
            24,
        ],
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        patch_norm=True,
        qk_scale=None,
        qkv_bias=True,
        type='SwinTransformer',
        window_size=7,
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            1024,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        test_cfg=dict(size_divisor=32),
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            96,
            192,
            384,
            768,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=57,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 57
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict({
            'absolute_pos_embed':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone':
            dict(decay_mult=1.0, lr_mult=0.1),
            'backbone.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.patch_embed.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.2.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.3.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.4.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.5.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'level_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_feat':
            dict(decay_mult=0.0, lr_mult=1.0),
            'relative_position_bias_table':
            dict(decay_mult=0.0, lr_mult=0.1)
        }),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=80000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth'
resume = False
seg_map_suffix = '.png'
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/seg_benchmark/seg_FULL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2048,
        1024,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(
    max_iters=80000, type='IterBasedTrainLoop', val_interval=80000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        data_prefix=dict(img_path='train/images', seg_map_path='train/masks'),
        data_root='/scratch/seg_benchmark/seg_FULL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                max_size=4096,
                resize_type='ResizeShortestEdge',
                scales=[
                    512,
                    614,
                    716,
                    819,
                    921,
                    1024,
                    1126,
                    1228,
                    1331,
                    1433,
                    1536,
                    1638,
                    1740,
                    1843,
                    1945,
                    2048,
                ],
                type='RandomChoiceResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    512,
                    1024,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        max_size=4096,
        resize_type='ResizeShortestEdge',
        scales=[
            512,
            614,
            716,
            819,
            921,
            1024,
            1126,
            1228,
            1331,
            1433,
            1536,
            1638,
            1740,
            1843,
            1945,
            2048,
        ],
        type='RandomChoiceResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        1024,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/seg_benchmark/seg_FULL/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '/scratch/seg_benchmark/FULL/mask2former_swin_T'

07/25 16:16:07 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
07/25 16:16:07 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:weight_decay=0.05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:decay_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr=1e-05
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr_mult=0.1
07/25 16:16:08 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
07/25 16:16:08 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
07/25 16:16:09 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth
07/25 16:16:10 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
07/25 16:16:10 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
07/25 16:16:10 - mmengine - INFO - Checkpoints will be saved to /scratch/seg_benchmark/FULL/mask2former_swin_T.
/home2/yasharora120/miniconda3/envs/mmseg/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400441250/work/aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
07/25 16:16:51 - mmengine - INFO - Iter(train) [   50/80000]  base_lr: 9.9945e-05 lr: 9.9945e-06  eta: 18:09:04  time: 0.4764  data_time: 0.0098  memory: 8944  grad_norm: 207.0189  loss: 103.9389  decode.loss_cls: 4.1234  decode.loss_mask: 2.2061  decode.loss_dice: 4.2440  decode.d0.loss_cls: 8.2202  decode.d0.loss_mask: 1.9719  decode.d0.loss_dice: 3.7424  decode.d1.loss_cls: 3.9485  decode.d1.loss_mask: 2.0053  decode.d1.loss_dice: 3.7116  decode.d2.loss_cls: 3.6584  decode.d2.loss_mask: 2.0331  decode.d2.loss_dice: 3.7595  decode.d3.loss_cls: 3.5937  decode.d3.loss_mask: 2.1249  decode.d3.loss_dice: 3.7969  decode.d4.loss_cls: 3.8697  decode.d4.loss_mask: 2.0882  decode.d4.loss_dice: 3.8055  decode.d5.loss_cls: 3.9460  decode.d5.loss_mask: 2.2497  decode.d5.loss_dice: 3.9021  decode.d6.loss_cls: 4.0312  decode.d6.loss_mask: 2.0305  decode.d6.loss_dice: 3.9457  decode.d7.loss_cls: 4.0673  decode.d7.loss_mask: 2.1731  decode.d7.loss_dice: 4.1550  decode.d8.loss_cls: 4.1010  decode.d8.loss_mask: 2.2085  decode.d8.loss_dice: 4.2256
07/25 16:17:15 - mmengine - INFO - Iter(train) [  100/80000]  base_lr: 9.9889e-05 lr: 9.9889e-06  eta: 14:24:02  time: 0.4782  data_time: 0.0097  memory: 5900  grad_norm: 261.4317  loss: 79.3249  decode.loss_cls: 3.2770  decode.loss_mask: 1.7737  decode.loss_dice: 2.9983  decode.d0.loss_cls: 8.1441  decode.d0.loss_mask: 1.5255  decode.d0.loss_dice: 2.8056  decode.d1.loss_cls: 3.1797  decode.d1.loss_mask: 1.5287  decode.d1.loss_dice: 2.6387  decode.d2.loss_cls: 3.0600  decode.d2.loss_mask: 1.5352  decode.d2.loss_dice: 2.5614  decode.d3.loss_cls: 3.0742  decode.d3.loss_mask: 1.5065  decode.d3.loss_dice: 2.5159  decode.d4.loss_cls: 3.1166  decode.d4.loss_mask: 1.5835  decode.d4.loss_dice: 2.5416  decode.d5.loss_cls: 3.0992  decode.d5.loss_mask: 1.6389  decode.d5.loss_dice: 2.6105  decode.d6.loss_cls: 3.0845  decode.d6.loss_mask: 1.6360  decode.d6.loss_dice: 2.6835  decode.d7.loss_cls: 3.0727  decode.d7.loss_mask: 1.6860  decode.d7.loss_dice: 2.7245  decode.d8.loss_cls: 3.1358  decode.d8.loss_mask: 1.7455  decode.d8.loss_dice: 2.8418
07/25 16:17:39 - mmengine - INFO - Iter(train) [  150/80000]  base_lr: 9.9832e-05 lr: 9.9832e-06  eta: 13:08:21  time: 0.4800  data_time: 0.0097  memory: 5920  grad_norm: 337.2201  loss: 68.6537  decode.loss_cls: 3.0980  decode.loss_mask: 1.2966  decode.loss_dice: 2.0933  decode.d0.loss_cls: 8.0321  decode.d0.loss_mask: 1.2453  decode.d0.loss_dice: 2.3425  decode.d1.loss_cls: 3.1582  decode.d1.loss_mask: 1.2204  decode.d1.loss_dice: 2.0794  decode.d2.loss_cls: 2.9912  decode.d2.loss_mask: 1.2297  decode.d2.loss_dice: 1.9935  decode.d3.loss_cls: 3.0051  decode.d3.loss_mask: 1.2187  decode.d3.loss_dice: 1.9863  decode.d4.loss_cls: 3.0779  decode.d4.loss_mask: 1.2617  decode.d4.loss_dice: 2.0196  decode.d5.loss_cls: 3.0788  decode.d5.loss_mask: 1.2590  decode.d5.loss_dice: 2.0273  decode.d6.loss_cls: 3.0585  decode.d6.loss_mask: 1.2643  decode.d6.loss_dice: 1.9832  decode.d7.loss_cls: 3.0206  decode.d7.loss_mask: 1.2800  decode.d7.loss_dice: 1.9824  decode.d8.loss_cls: 3.0618  decode.d8.loss_mask: 1.2666  decode.d8.loss_dice: 2.0218
07/25 16:18:03 - mmengine - INFO - Iter(train) [  200/80000]  base_lr: 9.9776e-05 lr: 9.9776e-06  eta: 12:29:59  time: 0.4796  data_time: 0.0096  memory: 5937  grad_norm: 337.1189  loss: 60.1654  decode.loss_cls: 2.8240  decode.loss_mask: 1.0372  decode.loss_dice: 1.8016  decode.d0.loss_cls: 7.8740  decode.d0.loss_mask: 1.0020  decode.d0.loss_dice: 1.9821  decode.d1.loss_cls: 2.7567  decode.d1.loss_mask: 0.9607  decode.d1.loss_dice: 1.7521  decode.d2.loss_cls: 2.6633  decode.d2.loss_mask: 1.0132  decode.d2.loss_dice: 1.6633  decode.d3.loss_cls: 2.7047  decode.d3.loss_mask: 0.9787  decode.d3.loss_dice: 1.6392  decode.d4.loss_cls: 2.6824  decode.d4.loss_mask: 1.0621  decode.d4.loss_dice: 1.6839  decode.d5.loss_cls: 2.7290  decode.d5.loss_mask: 1.0160  decode.d5.loss_dice: 1.6257  decode.d6.loss_cls: 2.7407  decode.d6.loss_mask: 1.0557  decode.d6.loss_dice: 1.6995  decode.d7.loss_cls: 2.7784  decode.d7.loss_mask: 1.0792  decode.d7.loss_dice: 1.7438  decode.d8.loss_cls: 2.8000  decode.d8.loss_mask: 1.0541  decode.d8.loss_dice: 1.7622
07/25 16:18:27 - mmengine - INFO - Iter(train) [  250/80000]  base_lr: 9.9720e-05 lr: 9.9720e-06  eta: 12:06:50  time: 0.4780  data_time: 0.0097  memory: 5919  grad_norm: 366.8703  loss: 56.3486  decode.loss_cls: 2.8312  decode.loss_mask: 0.8138  decode.loss_dice: 1.4793  decode.d0.loss_cls: 7.6339  decode.d0.loss_mask: 0.9352  decode.d0.loss_dice: 1.8767  decode.d1.loss_cls: 2.6480  decode.d1.loss_mask: 0.9474  decode.d1.loss_dice: 1.5888  decode.d2.loss_cls: 2.7534  decode.d2.loss_mask: 0.8768  decode.d2.loss_dice: 1.4414  decode.d3.loss_cls: 2.7527  decode.d3.loss_mask: 0.8318  decode.d3.loss_dice: 1.4151  decode.d4.loss_cls: 2.8831  decode.d4.loss_mask: 0.8046  decode.d4.loss_dice: 1.3845  decode.d5.loss_cls: 2.9259  decode.d5.loss_mask: 0.8332  decode.d5.loss_dice: 1.4045  decode.d6.loss_cls: 2.8128  decode.d6.loss_mask: 0.8604  decode.d6.loss_dice: 1.4609  decode.d7.loss_cls: 2.7714  decode.d7.loss_mask: 0.8311  decode.d7.loss_dice: 1.4322  decode.d8.loss_cls: 2.8328  decode.d8.loss_mask: 0.8304  decode.d8.loss_dice: 1.4554
07/25 16:18:50 - mmengine - INFO - Iter(train) [  300/80000]  base_lr: 9.9664e-05 lr: 9.9664e-06  eta: 11:51:15  time: 0.4778  data_time: 0.0094  memory: 5920  grad_norm: 402.0733  loss: 58.5566  decode.loss_cls: 3.0901  decode.loss_mask: 0.9260  decode.loss_dice: 1.5138  decode.d0.loss_cls: 7.5046  decode.d0.loss_mask: 0.8694  decode.d0.loss_dice: 1.7166  decode.d1.loss_cls: 2.9360  decode.d1.loss_mask: 0.9035  decode.d1.loss_dice: 1.4515  decode.d2.loss_cls: 2.9240  decode.d2.loss_mask: 0.8534  decode.d2.loss_dice: 1.3474  decode.d3.loss_cls: 2.9463  decode.d3.loss_mask: 0.8790  decode.d3.loss_dice: 1.3793  decode.d4.loss_cls: 3.0134  decode.d4.loss_mask: 0.8680  decode.d4.loss_dice: 1.3985  decode.d5.loss_cls: 3.0460  decode.d5.loss_mask: 0.8682  decode.d5.loss_dice: 1.4541  decode.d6.loss_cls: 3.1068  decode.d6.loss_mask: 0.9432  decode.d6.loss_dice: 1.4533  decode.d7.loss_cls: 3.1869  decode.d7.loss_mask: 0.9625  decode.d7.loss_dice: 1.4824  decode.d8.loss_cls: 3.1186  decode.d8.loss_mask: 0.9392  decode.d8.loss_dice: 1.4745
07/25 16:19:14 - mmengine - INFO - Iter(train) [  350/80000]  base_lr: 9.9607e-05 lr: 9.9607e-06  eta: 11:40:02  time: 0.4801  data_time: 0.0095  memory: 5919  grad_norm: 245.4337  loss: 50.0915  decode.loss_cls: 2.8645  decode.loss_mask: 0.6232  decode.loss_dice: 1.0952  decode.d0.loss_cls: 7.3689  decode.d0.loss_mask: 0.6156  decode.d0.loss_dice: 1.4915  decode.d1.loss_cls: 2.6147  decode.d1.loss_mask: 0.6237  decode.d1.loss_dice: 1.1881  decode.d2.loss_cls: 2.6235  decode.d2.loss_mask: 0.6344  decode.d2.loss_dice: 1.0771  decode.d3.loss_cls: 2.7020  decode.d3.loss_mask: 0.6278  decode.d3.loss_dice: 1.1119  decode.d4.loss_cls: 2.8538  decode.d4.loss_mask: 0.6215  decode.d4.loss_dice: 1.1141  decode.d5.loss_cls: 2.8545  decode.d5.loss_mask: 0.6316  decode.d5.loss_dice: 1.0983  decode.d6.loss_cls: 2.8593  decode.d6.loss_mask: 0.6039  decode.d6.loss_dice: 1.1252  decode.d7.loss_cls: 2.8271  decode.d7.loss_mask: 0.6134  decode.d7.loss_dice: 1.0760  decode.d8.loss_cls: 2.8400  decode.d8.loss_mask: 0.6157  decode.d8.loss_dice: 1.0954
07/25 16:19:38 - mmengine - INFO - Iter(train) [  400/80000]  base_lr: 9.9551e-05 lr: 9.9551e-06  eta: 11:31:25  time: 0.4781  data_time: 0.0097  memory: 5919  grad_norm: 337.6378  loss: 46.6612  decode.loss_cls: 2.6449  decode.loss_mask: 0.7921  decode.loss_dice: 0.8438  decode.d0.loss_cls: 7.2394  decode.d0.loss_mask: 0.7957  decode.d0.loss_dice: 1.1968  decode.d1.loss_cls: 2.4531  decode.d1.loss_mask: 0.8310  decode.d1.loss_dice: 0.9738  decode.d2.loss_cls: 2.3469  decode.d2.loss_mask: 0.7785  decode.d2.loss_dice: 0.8912  decode.d3.loss_cls: 2.4119  decode.d3.loss_mask: 0.7751  decode.d3.loss_dice: 0.8601  decode.d4.loss_cls: 2.4829  decode.d4.loss_mask: 0.7424  decode.d4.loss_dice: 0.8486  decode.d5.loss_cls: 2.5954  decode.d5.loss_mask: 0.7693  decode.d5.loss_dice: 0.8426  decode.d6.loss_cls: 2.5578  decode.d6.loss_mask: 0.7178  decode.d6.loss_dice: 0.8325  decode.d7.loss_cls: 2.5565  decode.d7.loss_mask: 0.7408  decode.d7.loss_dice: 0.8797  decode.d8.loss_cls: 2.5424  decode.d8.loss_mask: 0.8195  decode.d8.loss_dice: 0.8989
07/25 16:20:02 - mmengine - INFO - Iter(train) [  450/80000]  base_lr: 9.9495e-05 lr: 9.9495e-06  eta: 11:24:44  time: 0.4780  data_time: 0.0094  memory: 5900  grad_norm: 273.1563  loss: 51.7573  decode.loss_cls: 3.0909  decode.loss_mask: 0.6868  decode.loss_dice: 1.0101  decode.d0.loss_cls: 7.0909  decode.d0.loss_mask: 0.7977  decode.d0.loss_dice: 1.3689  decode.d1.loss_cls: 2.9174  decode.d1.loss_mask: 0.7257  decode.d1.loss_dice: 1.0836  decode.d2.loss_cls: 2.9168  decode.d2.loss_mask: 0.7275  decode.d2.loss_dice: 1.0223  decode.d3.loss_cls: 2.9599  decode.d3.loss_mask: 0.7019  decode.d3.loss_dice: 0.9417  decode.d4.loss_cls: 2.9956  decode.d4.loss_mask: 0.6539  decode.d4.loss_dice: 0.8800  decode.d5.loss_cls: 3.1407  decode.d5.loss_mask: 0.7128  decode.d5.loss_dice: 0.9302  decode.d6.loss_cls: 3.1079  decode.d6.loss_mask: 0.7441  decode.d6.loss_dice: 0.9455  decode.d7.loss_cls: 3.0790  decode.d7.loss_mask: 0.7344  decode.d7.loss_dice: 0.9774  decode.d8.loss_cls: 3.1089  decode.d8.loss_mask: 0.7251  decode.d8.loss_dice: 0.9796
07/25 16:20:26 - mmengine - INFO - Iter(train) [  500/80000]  base_lr: 9.9438e-05 lr: 9.9438e-06  eta: 11:19:25  time: 0.4788  data_time: 0.0093  memory: 5920  grad_norm: 306.8551  loss: 50.4089  decode.loss_cls: 2.8637  decode.loss_mask: 0.6664  decode.loss_dice: 0.9581  decode.d0.loss_cls: 7.0027  decode.d0.loss_mask: 0.8082  decode.d0.loss_dice: 1.4086  decode.d1.loss_cls: 2.7401  decode.d1.loss_mask: 0.7859  decode.d1.loss_dice: 1.1279  decode.d2.loss_cls: 2.6627  decode.d2.loss_mask: 0.7014  decode.d2.loss_dice: 1.0155  decode.d3.loss_cls: 2.6815  decode.d3.loss_mask: 0.6997  decode.d3.loss_dice: 1.0295  decode.d4.loss_cls: 2.7855  decode.d4.loss_mask: 0.7173  decode.d4.loss_dice: 1.0996  decode.d5.loss_cls: 2.9307  decode.d5.loss_mask: 0.7139  decode.d5.loss_dice: 1.1346  decode.d6.loss_cls: 2.9041  decode.d6.loss_mask: 0.7109  decode.d6.loss_dice: 1.1071  decode.d7.loss_cls: 2.9106  decode.d7.loss_mask: 0.6940  decode.d7.loss_dice: 1.0511  decode.d8.loss_cls: 2.8414  decode.d8.loss_mask: 0.6829  decode.d8.loss_dice: 0.9735
07/25 16:20:50 - mmengine - INFO - Iter(train) [  550/80000]  base_lr: 9.9382e-05 lr: 9.9382e-06  eta: 11:15:01  time: 0.4788  data_time: 0.0092  memory: 5900  grad_norm: 317.1851  loss: 46.7088  decode.loss_cls: 2.7423  decode.loss_mask: 0.7047  decode.loss_dice: 0.8987  decode.d0.loss_cls: 6.8300  decode.d0.loss_mask: 0.6820  decode.d0.loss_dice: 1.1503  decode.d1.loss_cls: 2.5805  decode.d1.loss_mask: 0.7220  decode.d1.loss_dice: 0.8932  decode.d2.loss_cls: 2.4383  decode.d2.loss_mask: 0.7561  decode.d2.loss_dice: 0.8839  decode.d3.loss_cls: 2.5831  decode.d3.loss_mask: 0.7360  decode.d3.loss_dice: 0.8747  decode.d4.loss_cls: 2.5406  decode.d4.loss_mask: 0.7365  decode.d4.loss_dice: 0.8568  decode.d5.loss_cls: 2.6769  decode.d5.loss_mask: 0.7635  decode.d5.loss_dice: 0.8542  decode.d6.loss_cls: 2.6645  decode.d6.loss_mask: 0.6872  decode.d6.loss_dice: 0.8345  decode.d7.loss_cls: 2.7110  decode.d7.loss_mask: 0.7130  decode.d7.loss_dice: 0.8660  decode.d8.loss_cls: 2.7522  decode.d8.loss_mask: 0.6915  decode.d8.loss_dice: 0.8847
07/25 16:21:14 - mmengine - INFO - Iter(train) [  600/80000]  base_lr: 9.9326e-05 lr: 9.9326e-06  eta: 11:11:12  time: 0.4796  data_time: 0.0092  memory: 5938  grad_norm: 279.3081  loss: 46.6564  decode.loss_cls: 2.7552  decode.loss_mask: 0.6797  decode.loss_dice: 0.7868  decode.d0.loss_cls: 6.7308  decode.d0.loss_mask: 0.7744  decode.d0.loss_dice: 1.1493  decode.d1.loss_cls: 2.6926  decode.d1.loss_mask: 0.7351  decode.d1.loss_dice: 0.8212  decode.d2.loss_cls: 2.7553  decode.d2.loss_mask: 0.7592  decode.d2.loss_dice: 0.7938  decode.d3.loss_cls: 2.7641  decode.d3.loss_mask: 0.6599  decode.d3.loss_dice: 0.7335  decode.d4.loss_cls: 2.7500  decode.d4.loss_mask: 0.6673  decode.d4.loss_dice: 0.7709  decode.d5.loss_cls: 2.7249  decode.d5.loss_mask: 0.6293  decode.d5.loss_dice: 0.7928  decode.d6.loss_cls: 2.7400  decode.d6.loss_mask: 0.6461  decode.d6.loss_dice: 0.7923  decode.d7.loss_cls: 2.8303  decode.d7.loss_mask: 0.6958  decode.d7.loss_dice: 0.7945  decode.d8.loss_cls: 2.8027  decode.d8.loss_mask: 0.6545  decode.d8.loss_dice: 0.7741
07/25 16:21:38 - mmengine - INFO - Iter(train) [  650/80000]  base_lr: 9.9270e-05 lr: 9.9270e-06  eta: 11:07:56  time: 0.4776  data_time: 0.0092  memory: 5900  grad_norm: 269.2283  loss: 38.0740  decode.loss_cls: 2.1688  decode.loss_mask: 0.5514  decode.loss_dice: 0.6094  decode.d0.loss_cls: 6.5418  decode.d0.loss_mask: 0.6669  decode.d0.loss_dice: 0.9476  decode.d1.loss_cls: 2.1410  decode.d1.loss_mask: 0.6376  decode.d1.loss_dice: 0.6618  decode.d2.loss_cls: 2.0429  decode.d2.loss_mask: 0.5782  decode.d2.loss_dice: 0.6201  decode.d3.loss_cls: 2.1167  decode.d3.loss_mask: 0.5501  decode.d3.loss_dice: 0.6152  decode.d4.loss_cls: 2.1180  decode.d4.loss_mask: 0.5940  decode.d4.loss_dice: 0.6301  decode.d5.loss_cls: 2.1332  decode.d5.loss_mask: 0.6024  decode.d5.loss_dice: 0.6441  decode.d6.loss_cls: 2.1539  decode.d6.loss_mask: 0.5299  decode.d6.loss_dice: 0.5646  decode.d7.loss_cls: 2.1935  decode.d7.loss_mask: 0.5307  decode.d7.loss_dice: 0.5672  decode.d8.loss_cls: 2.1987  decode.d8.loss_mask: 0.5537  decode.d8.loss_dice: 0.6107
07/25 16:22:02 - mmengine - INFO - Iter(train) [  700/80000]  base_lr: 9.9213e-05 lr: 9.9213e-06  eta: 11:05:12  time: 0.4778  data_time: 0.0094  memory: 5900  grad_norm: 270.5434  loss: 39.0440  decode.loss_cls: 2.3582  decode.loss_mask: 0.5092  decode.loss_dice: 0.6001  decode.d0.loss_cls: 6.4714  decode.d0.loss_mask: 0.6558  decode.d0.loss_dice: 0.8654  decode.d1.loss_cls: 2.2663  decode.d1.loss_mask: 0.5996  decode.d1.loss_dice: 0.6508  decode.d2.loss_cls: 2.2393  decode.d2.loss_mask: 0.5423  decode.d2.loss_dice: 0.6002  decode.d3.loss_cls: 2.1963  decode.d3.loss_mask: 0.5987  decode.d3.loss_dice: 0.6387  decode.d4.loss_cls: 2.2556  decode.d4.loss_mask: 0.5503  decode.d4.loss_dice: 0.6143  decode.d5.loss_cls: 2.2776  decode.d5.loss_mask: 0.5641  decode.d5.loss_dice: 0.6086  decode.d6.loss_cls: 2.2901  decode.d6.loss_mask: 0.5588  decode.d6.loss_dice: 0.6077  decode.d7.loss_cls: 2.3014  decode.d7.loss_mask: 0.5282  decode.d7.loss_dice: 0.6237  decode.d8.loss_cls: 2.3092  decode.d8.loss_mask: 0.5423  decode.d8.loss_dice: 0.6197
07/25 16:22:26 - mmengine - INFO - Iter(train) [  750/80000]  base_lr: 9.9157e-05 lr: 9.9157e-06  eta: 11:02:40  time: 0.4787  data_time: 0.0091  memory: 5919  grad_norm: 199.3397  loss: 46.1557  decode.loss_cls: 2.8956  decode.loss_mask: 0.5095  decode.loss_dice: 0.8182  decode.d0.loss_cls: 6.4525  decode.d0.loss_mask: 0.6339  decode.d0.loss_dice: 1.1681  decode.d1.loss_cls: 2.7413  decode.d1.loss_mask: 0.5542  decode.d1.loss_dice: 0.9107  decode.d2.loss_cls: 2.8046  decode.d2.loss_mask: 0.5157  decode.d2.loss_dice: 0.8130  decode.d3.loss_cls: 2.8412  decode.d3.loss_mask: 0.5333  decode.d3.loss_dice: 0.8039  decode.d4.loss_cls: 2.9021  decode.d4.loss_mask: 0.5315  decode.d4.loss_dice: 0.8398  decode.d5.loss_cls: 2.8708  decode.d5.loss_mask: 0.5141  decode.d5.loss_dice: 0.8701  decode.d6.loss_cls: 2.8829  decode.d6.loss_mask: 0.4832  decode.d6.loss_dice: 0.8044  decode.d7.loss_cls: 2.8649  decode.d7.loss_mask: 0.5138  decode.d7.loss_dice: 0.8522  decode.d8.loss_cls: 2.8466  decode.d8.loss_mask: 0.5415  decode.d8.loss_dice: 0.8421
07/25 16:22:50 - mmengine - INFO - Iter(train) [  800/80000]  base_lr: 9.9101e-05 lr: 9.9101e-06  eta: 11:00:22  time: 0.4782  data_time: 0.0092  memory: 5937  grad_norm: 214.1372  loss: 41.5686  decode.loss_cls: 2.6460  decode.loss_mask: 0.4919  decode.loss_dice: 0.7377  decode.d0.loss_cls: 6.3375  decode.d0.loss_mask: 0.5658  decode.d0.loss_dice: 0.9793  decode.d1.loss_cls: 2.5977  decode.d1.loss_mask: 0.4935  decode.d1.loss_dice: 0.7501  decode.d2.loss_cls: 2.5268  decode.d2.loss_mask: 0.4480  decode.d2.loss_dice: 0.6568  decode.d3.loss_cls: 2.5515  decode.d3.loss_mask: 0.4515  decode.d3.loss_dice: 0.6569  decode.d4.loss_cls: 2.5457  decode.d4.loss_mask: 0.4647  decode.d4.loss_dice: 0.6466  decode.d5.loss_cls: 2.5625  decode.d5.loss_mask: 0.4886  decode.d5.loss_dice: 0.6410  decode.d6.loss_cls: 2.6006  decode.d6.loss_mask: 0.4709  decode.d6.loss_dice: 0.6710  decode.d7.loss_cls: 2.5862  decode.d7.loss_mask: 0.5406  decode.d7.loss_dice: 0.7595  decode.d8.loss_cls: 2.5970  decode.d8.loss_mask: 0.4569  decode.d8.loss_dice: 0.6459
07/25 16:23:14 - mmengine - INFO - Iter(train) [  850/80000]  base_lr: 9.9044e-05 lr: 9.9044e-06  eta: 10:58:16  time: 0.4792  data_time: 0.0093  memory: 5937  grad_norm: 228.6188  loss: 42.6591  decode.loss_cls: 2.5529  decode.loss_mask: 0.5467  decode.loss_dice: 0.7024  decode.d0.loss_cls: 6.1293  decode.d0.loss_mask: 0.6820  decode.d0.loss_dice: 1.0717  decode.d1.loss_cls: 2.5468  decode.d1.loss_mask: 0.5615  decode.d1.loss_dice: 0.7586  decode.d2.loss_cls: 2.5665  decode.d2.loss_mask: 0.5034  decode.d2.loss_dice: 0.7086  decode.d3.loss_cls: 2.5508  decode.d3.loss_mask: 0.5412  decode.d3.loss_dice: 0.6874  decode.d4.loss_cls: 2.6573  decode.d4.loss_mask: 0.5642  decode.d4.loss_dice: 0.7183  decode.d5.loss_cls: 2.6088  decode.d5.loss_mask: 0.6042  decode.d5.loss_dice: 0.7620  decode.d6.loss_cls: 2.5963  decode.d6.loss_mask: 0.5800  decode.d6.loss_dice: 0.7239  decode.d7.loss_cls: 2.5920  decode.d7.loss_mask: 0.5901  decode.d7.loss_dice: 0.7028  decode.d8.loss_cls: 2.5836  decode.d8.loss_mask: 0.5771  decode.d8.loss_dice: 0.6886
07/25 16:23:38 - mmengine - INFO - Iter(train) [  900/80000]  base_lr: 9.8988e-05 lr: 9.8988e-06  eta: 10:56:21  time: 0.4800  data_time: 0.0095  memory: 5919  grad_norm: 327.0286  loss: 40.4706  decode.loss_cls: 2.3506  decode.loss_mask: 0.5308  decode.loss_dice: 0.7587  decode.d0.loss_cls: 6.0157  decode.d0.loss_mask: 0.5562  decode.d0.loss_dice: 0.9757  decode.d1.loss_cls: 2.3685  decode.d1.loss_mask: 0.5487  decode.d1.loss_dice: 0.7788  decode.d2.loss_cls: 2.2833  decode.d2.loss_mask: 0.5480  decode.d2.loss_dice: 0.7496  decode.d3.loss_cls: 2.3278  decode.d3.loss_mask: 0.5393  decode.d3.loss_dice: 0.7541  decode.d4.loss_cls: 2.3392  decode.d4.loss_mask: 0.5258  decode.d4.loss_dice: 0.7286  decode.d5.loss_cls: 2.4029  decode.d5.loss_mask: 0.4995  decode.d5.loss_dice: 0.7032  decode.d6.loss_cls: 2.4319  decode.d6.loss_mask: 0.5278  decode.d6.loss_dice: 0.7669  decode.d7.loss_cls: 2.4412  decode.d7.loss_mask: 0.5156  decode.d7.loss_dice: 0.7416  decode.d8.loss_cls: 2.4489  decode.d8.loss_mask: 0.5593  decode.d8.loss_dice: 0.7524
07/25 16:24:02 - mmengine - INFO - Iter(train) [  950/80000]  base_lr: 9.8932e-05 lr: 9.8932e-06  eta: 10:54:37  time: 0.4780  data_time: 0.0091  memory: 5901  grad_norm: 237.8118  loss: 39.8881  decode.loss_cls: 2.5125  decode.loss_mask: 0.5289  decode.loss_dice: 0.6922  decode.d0.loss_cls: 5.9864  decode.d0.loss_mask: 0.5417  decode.d0.loss_dice: 0.8440  decode.d1.loss_cls: 2.4836  decode.d1.loss_mask: 0.4964  decode.d1.loss_dice: 0.6593  decode.d2.loss_cls: 2.4094  decode.d2.loss_mask: 0.4968  decode.d2.loss_dice: 0.6139  decode.d3.loss_cls: 2.4526  decode.d3.loss_mask: 0.4688  decode.d3.loss_dice: 0.6395  decode.d4.loss_cls: 2.4532  decode.d4.loss_mask: 0.4979  decode.d4.loss_dice: 0.6431  decode.d5.loss_cls: 2.4691  decode.d5.loss_mask: 0.5006  decode.d5.loss_dice: 0.6110  decode.d6.loss_cls: 2.4852  decode.d6.loss_mask: 0.4781  decode.d6.loss_dice: 0.6185  decode.d7.loss_cls: 2.4605  decode.d7.loss_mask: 0.4663  decode.d7.loss_dice: 0.6322  decode.d8.loss_cls: 2.5193  decode.d8.loss_mask: 0.5433  decode.d8.loss_dice: 0.6837
07/25 16:24:26 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250725_161554
07/25 16:24:26 - mmengine - INFO - Iter(train) [ 1000/80000]  base_lr: 9.8875e-05 lr: 9.8875e-06  eta: 10:53:10  time: 0.4809  data_time: 0.0095  memory: 5937  grad_norm: 200.8707  loss: 37.5889  decode.loss_cls: 2.2552  decode.loss_mask: 0.5143  decode.loss_dice: 0.6237  decode.d0.loss_cls: 5.8361  decode.d0.loss_mask: 0.5300  decode.d0.loss_dice: 0.9150  decode.d1.loss_cls: 2.3491  decode.d1.loss_mask: 0.5074  decode.d1.loss_dice: 0.7048  decode.d2.loss_cls: 2.2479  decode.d2.loss_mask: 0.4765  decode.d2.loss_dice: 0.6177  decode.d3.loss_cls: 2.2303  decode.d3.loss_mask: 0.4277  decode.d3.loss_dice: 0.6336  decode.d4.loss_cls: 2.1924  decode.d4.loss_mask: 0.4713  decode.d4.loss_dice: 0.6296  decode.d5.loss_cls: 2.2594  decode.d5.loss_mask: 0.4568  decode.d5.loss_dice: 0.6370  decode.d6.loss_cls: 2.3817  decode.d6.loss_mask: 0.4106  decode.d6.loss_dice: 0.5853  decode.d7.loss_cls: 2.3193  decode.d7.loss_mask: 0.4166  decode.d7.loss_dice: 0.5842  decode.d8.loss_cls: 2.3478  decode.d8.loss_mask: 0.4374  decode.d8.loss_dice: 0.5901
07/25 16:24:50 - mmengine - INFO - Iter(train) [ 1050/80000]  base_lr: 9.8819e-05 lr: 9.8819e-06  eta: 10:51:43  time: 0.4811  data_time: 0.0094  memory: 5900  grad_norm: 327.9765  loss: 36.5145  decode.loss_cls: 2.0612  decode.loss_mask: 0.7521  decode.loss_dice: 0.6201  decode.d0.loss_cls: 5.7518  decode.d0.loss_mask: 0.6661  decode.d0.loss_dice: 0.8307  decode.d1.loss_cls: 2.0943  decode.d1.loss_mask: 0.6941  decode.d1.loss_dice: 0.5913  decode.d2.loss_cls: 2.0000  decode.d2.loss_mask: 0.6303  decode.d2.loss_dice: 0.5239  decode.d3.loss_cls: 2.0411  decode.d3.loss_mask: 0.5863  decode.d3.loss_dice: 0.5538  decode.d4.loss_cls: 2.0141  decode.d4.loss_mask: 0.5827  decode.d4.loss_dice: 0.5622  decode.d5.loss_cls: 2.0353  decode.d5.loss_mask: 0.6213  decode.d5.loss_dice: 0.5521  decode.d6.loss_cls: 2.1103  decode.d6.loss_mask: 0.5627  decode.d6.loss_dice: 0.5302  decode.d7.loss_cls: 2.1184  decode.d7.loss_mask: 0.5619  decode.d7.loss_dice: 0.5335  decode.d8.loss_cls: 2.1264  decode.d8.loss_mask: 0.6150  decode.d8.loss_dice: 0.5912
07/25 16:25:14 - mmengine - INFO - Iter(train) [ 1100/80000]  base_lr: 9.8763e-05 lr: 9.8763e-06  eta: 10:50:24  time: 0.4794  data_time: 0.0094  memory: 5919  grad_norm: 254.6870  loss: 34.4325  decode.loss_cls: 1.9632  decode.loss_mask: 0.5422  decode.loss_dice: 0.6094  decode.d0.loss_cls: 5.6050  decode.d0.loss_mask: 0.6233  decode.d0.loss_dice: 0.7445  decode.d1.loss_cls: 1.9232  decode.d1.loss_mask: 0.5098  decode.d1.loss_dice: 0.5810  decode.d2.loss_cls: 1.8891  decode.d2.loss_mask: 0.5524  decode.d2.loss_dice: 0.5377  decode.d3.loss_cls: 1.9024  decode.d3.loss_mask: 0.5641  decode.d3.loss_dice: 0.5584  decode.d4.loss_cls: 1.9894  decode.d4.loss_mask: 0.5669  decode.d4.loss_dice: 0.5888  decode.d5.loss_cls: 1.9565  decode.d5.loss_mask: 0.5430  decode.d5.loss_dice: 0.5704  decode.d6.loss_cls: 1.9108  decode.d6.loss_mask: 0.5378  decode.d6.loss_dice: 0.5520  decode.d7.loss_cls: 1.8940  decode.d7.loss_mask: 0.5539  decode.d7.loss_dice: 0.5705  decode.d8.loss_cls: 1.9043  decode.d8.loss_mask: 0.5546  decode.d8.loss_dice: 0.6338
07/25 16:25:38 - mmengine - INFO - Iter(train) [ 1150/80000]  base_lr: 9.8706e-05 lr: 9.8706e-06  eta: 10:49:10  time: 0.4793  data_time: 0.0097  memory: 5900  grad_norm: 398.5184  loss: 36.8918  decode.loss_cls: 2.3600  decode.loss_mask: 0.5184  decode.loss_dice: 0.4899  decode.d0.loss_cls: 5.6015  decode.d0.loss_mask: 0.5088  decode.d0.loss_dice: 0.7308  decode.d1.loss_cls: 2.3891  decode.d1.loss_mask: 0.4815  decode.d1.loss_dice: 0.4973  decode.d2.loss_cls: 2.3368  decode.d2.loss_mask: 0.4464  decode.d2.loss_dice: 0.4781  decode.d3.loss_cls: 2.3051  decode.d3.loss_mask: 0.5305  decode.d3.loss_dice: 0.4954  decode.d4.loss_cls: 2.3856  decode.d4.loss_mask: 0.4837  decode.d4.loss_dice: 0.4893  decode.d5.loss_cls: 2.3516  decode.d5.loss_mask: 0.4437  decode.d5.loss_dice: 0.4917  decode.d6.loss_cls: 2.3691  decode.d6.loss_mask: 0.5354  decode.d6.loss_dice: 0.5008  decode.d7.loss_cls: 2.3974  decode.d7.loss_mask: 0.4145  decode.d7.loss_dice: 0.5109  decode.d8.loss_cls: 2.3521  decode.d8.loss_mask: 0.4896  decode.d8.loss_dice: 0.5065
07/25 16:26:02 - mmengine - INFO - Iter(train) [ 1200/80000]  base_lr: 9.8650e-05 lr: 9.8650e-06  eta: 10:48:03  time: 0.4797  data_time: 0.0093  memory: 5937  grad_norm: 313.5501  loss: 35.2370  decode.loss_cls: 2.0130  decode.loss_mask: 0.5741  decode.loss_dice: 0.5299  decode.d0.loss_cls: 5.2569  decode.d0.loss_mask: 0.6582  decode.d0.loss_dice: 0.6868  decode.d1.loss_cls: 2.0835  decode.d1.loss_mask: 0.6101  decode.d1.loss_dice: 0.5446  decode.d2.loss_cls: 2.1079  decode.d2.loss_mask: 0.5579  decode.d2.loss_dice: 0.5107  decode.d3.loss_cls: 2.0110  decode.d3.loss_mask: 0.6011  decode.d3.loss_dice: 0.5489  decode.d4.loss_cls: 2.0489  decode.d4.loss_mask: 0.5788  decode.d4.loss_dice: 0.5325  decode.d5.loss_cls: 2.1069  decode.d5.loss_mask: 0.5555  decode.d5.loss_dice: 0.5395  decode.d6.loss_cls: 2.0892  decode.d6.loss_mask: 0.6432  decode.d6.loss_dice: 0.5138  decode.d7.loss_cls: 2.0623  decode.d7.loss_mask: 0.6115  decode.d7.loss_dice: 0.5042  decode.d8.loss_cls: 2.0171  decode.d8.loss_mask: 0.6141  decode.d8.loss_dice: 0.5249
07/25 16:26:26 - mmengine - INFO - Iter(train) [ 1250/80000]  base_lr: 9.8594e-05 lr: 9.8594e-06  eta: 10:46:55  time: 0.4802  data_time: 0.0095  memory: 5901  grad_norm: 258.7925  loss: 33.4777  decode.loss_cls: 1.8148  decode.loss_mask: 0.5379  decode.loss_dice: 0.6746  decode.d0.loss_cls: 5.1644  decode.d0.loss_mask: 0.5399  decode.d0.loss_dice: 0.7544  decode.d1.loss_cls: 1.9248  decode.d1.loss_mask: 0.5103  decode.d1.loss_dice: 0.6198  decode.d2.loss_cls: 1.8920  decode.d2.loss_mask: 0.4519  decode.d2.loss_dice: 0.5555  decode.d3.loss_cls: 1.9047  decode.d3.loss_mask: 0.4612  decode.d3.loss_dice: 0.5814  decode.d4.loss_cls: 1.8950  decode.d4.loss_mask: 0.4687  decode.d4.loss_dice: 0.5755  decode.d5.loss_cls: 1.9436  decode.d5.loss_mask: 0.5114  decode.d5.loss_dice: 0.5614  decode.d6.loss_cls: 1.9813  decode.d6.loss_mask: 0.5352  decode.d6.loss_dice: 0.5640  decode.d7.loss_cls: 1.9798  decode.d7.loss_mask: 0.4479  decode.d7.loss_dice: 0.5856  decode.d8.loss_cls: 1.8864  decode.d8.loss_mask: 0.5004  decode.d8.loss_dice: 0.6538
07/25 16:26:50 - mmengine - INFO - Iter(train) [ 1300/80000]  base_lr: 9.8537e-05 lr: 9.8537e-06  eta: 10:45:51  time: 0.4797  data_time: 0.0095  memory: 5920  grad_norm: 271.4033  loss: 36.3365  decode.loss_cls: 2.1573  decode.loss_mask: 0.5057  decode.loss_dice: 0.5113  decode.d0.loss_cls: 5.1104  decode.d0.loss_mask: 0.6233  decode.d0.loss_dice: 0.7808  decode.d1.loss_cls: 2.3081  decode.d1.loss_mask: 0.5097  decode.d1.loss_dice: 0.5625  decode.d2.loss_cls: 2.3240  decode.d2.loss_mask: 0.5454  decode.d2.loss_dice: 0.5805  decode.d3.loss_cls: 2.1869  decode.d3.loss_mask: 0.5665  decode.d3.loss_dice: 0.5576  decode.d4.loss_cls: 2.1213  decode.d4.loss_mask: 0.5353  decode.d4.loss_dice: 0.5754  decode.d5.loss_cls: 2.1158  decode.d5.loss_mask: 0.5320  decode.d5.loss_dice: 0.5545  decode.d6.loss_cls: 2.2886  decode.d6.loss_mask: 0.5512  decode.d6.loss_dice: 0.6206  decode.d7.loss_cls: 2.2516  decode.d7.loss_mask: 0.5393  decode.d7.loss_dice: 0.5747  decode.d8.loss_cls: 2.1921  decode.d8.loss_mask: 0.5325  decode.d8.loss_dice: 0.5214
07/25 16:27:14 - mmengine - INFO - Iter(train) [ 1350/80000]  base_lr: 9.8481e-05 lr: 9.8481e-06  eta: 10:44:49  time: 0.4801  data_time: 0.0095  memory: 5937  grad_norm: 299.5831  loss: 34.4632  decode.loss_cls: 2.0287  decode.loss_mask: 0.4937  decode.loss_dice: 0.6779  decode.d0.loss_cls: 4.8348  decode.d0.loss_mask: 0.5511  decode.d0.loss_dice: 0.8236  decode.d1.loss_cls: 2.2143  decode.d1.loss_mask: 0.4038  decode.d1.loss_dice: 0.5941  decode.d2.loss_cls: 2.0890  decode.d2.loss_mask: 0.4034  decode.d2.loss_dice: 0.5806  decode.d3.loss_cls: 2.0770  decode.d3.loss_mask: 0.4228  decode.d3.loss_dice: 0.5910  decode.d4.loss_cls: 2.0905  decode.d4.loss_mask: 0.4243  decode.d4.loss_dice: 0.6097  decode.d5.loss_cls: 2.1261  decode.d5.loss_mask: 0.3930  decode.d5.loss_dice: 0.6020  decode.d6.loss_cls: 2.1526  decode.d6.loss_mask: 0.3863  decode.d6.loss_dice: 0.5770  decode.d7.loss_cls: 2.0530  decode.d7.loss_mask: 0.4748  decode.d7.loss_dice: 0.6479  decode.d8.loss_cls: 2.0398  decode.d8.loss_mask: 0.4623  decode.d8.loss_dice: 0.6380
07/25 16:27:38 - mmengine - INFO - Iter(train) [ 1400/80000]  base_lr: 9.8425e-05 lr: 9.8425e-06  eta: 10:43:51  time: 0.4813  data_time: 0.0096  memory: 5937  grad_norm: 378.6375  loss: 31.0121  decode.loss_cls: 1.8271  decode.loss_mask: 0.5037  decode.loss_dice: 0.4251  decode.d0.loss_cls: 4.7506  decode.d0.loss_mask: 0.5742  decode.d0.loss_dice: 0.5975  decode.d1.loss_cls: 2.0022  decode.d1.loss_mask: 0.4801  decode.d1.loss_dice: 0.4485  decode.d2.loss_cls: 1.8375  decode.d2.loss_mask: 0.4918  decode.d2.loss_dice: 0.4172  decode.d3.loss_cls: 1.8499  decode.d3.loss_mask: 0.4709  decode.d3.loss_dice: 0.4188  decode.d4.loss_cls: 1.9318  decode.d4.loss_mask: 0.4488  decode.d4.loss_dice: 0.4098  decode.d5.loss_cls: 1.9184  decode.d5.loss_mask: 0.4577  decode.d5.loss_dice: 0.4159  decode.d6.loss_cls: 1.9558  decode.d6.loss_mask: 0.4304  decode.d6.loss_dice: 0.3989  decode.d7.loss_cls: 1.9025  decode.d7.loss_mask: 0.4523  decode.d7.loss_dice: 0.4416  decode.d8.loss_cls: 1.8964  decode.d8.loss_mask: 0.4318  decode.d8.loss_dice: 0.4249
07/25 16:28:02 - mmengine - INFO - Iter(train) [ 1450/80000]  base_lr: 9.8368e-05 lr: 9.8368e-06  eta: 10:42:58  time: 0.4810  data_time: 0.0093  memory: 5937  grad_norm: 174.2690  loss: 31.0059  decode.loss_cls: 1.9705  decode.loss_mask: 0.3223  decode.loss_dice: 0.4704  decode.d0.loss_cls: 4.6786  decode.d0.loss_mask: 0.3250  decode.d0.loss_dice: 0.6212  decode.d1.loss_cls: 2.0476  decode.d1.loss_mask: 0.3111  decode.d1.loss_dice: 0.4805  decode.d2.loss_cls: 1.9494  decode.d2.loss_mask: 0.3073  decode.d2.loss_dice: 0.5068  decode.d3.loss_cls: 2.0864  decode.d3.loss_mask: 0.3082  decode.d3.loss_dice: 0.4467  decode.d4.loss_cls: 2.0577  decode.d4.loss_mask: 0.3056  decode.d4.loss_dice: 0.4761  decode.d5.loss_cls: 2.0694  decode.d5.loss_mask: 0.3161  decode.d5.loss_dice: 0.4818  decode.d6.loss_cls: 2.0494  decode.d6.loss_mask: 0.2834  decode.d6.loss_dice: 0.4747  decode.d7.loss_cls: 2.0668  decode.d7.loss_mask: 0.3126  decode.d7.loss_dice: 0.4790  decode.d8.loss_cls: 1.9980  decode.d8.loss_mask: 0.3081  decode.d8.loss_dice: 0.4952
07/25 16:28:26 - mmengine - INFO - Iter(train) [ 1500/80000]  base_lr: 9.8312e-05 lr: 9.8312e-06  eta: 10:42:15  time: 0.4792  data_time: 0.0094  memory: 5920  grad_norm: 318.1281  loss: 33.7724  decode.loss_cls: 1.8665  decode.loss_mask: 0.5724  decode.loss_dice: 0.6132  decode.d0.loss_cls: 4.6038  decode.d0.loss_mask: 0.6558  decode.d0.loss_dice: 0.7981  decode.d1.loss_cls: 1.9960  decode.d1.loss_mask: 0.5260  decode.d1.loss_dice: 0.5710  decode.d2.loss_cls: 1.9274  decode.d2.loss_mask: 0.5449  decode.d2.loss_dice: 0.5685  decode.d3.loss_cls: 1.9217  decode.d3.loss_mask: 0.5444  decode.d3.loss_dice: 0.5977  decode.d4.loss_cls: 1.9467  decode.d4.loss_mask: 0.5610  decode.d4.loss_dice: 0.5835  decode.d5.loss_cls: 1.9346  decode.d5.loss_mask: 0.5488  decode.d5.loss_dice: 0.5957  decode.d6.loss_cls: 1.8820  decode.d6.loss_mask: 0.5592  decode.d6.loss_dice: 0.6435  decode.d7.loss_cls: 1.8956  decode.d7.loss_mask: 0.6018  decode.d7.loss_dice: 0.6724  decode.d8.loss_cls: 1.8730  decode.d8.loss_mask: 0.5745  decode.d8.loss_dice: 0.5926
07/25 16:28:50 - mmengine - INFO - Iter(train) [ 1550/80000]  base_lr: 9.8256e-05 lr: 9.8256e-06  eta: 10:41:23  time: 0.4790  data_time: 0.0094  memory: 5937  grad_norm: 357.4797  loss: 32.5094  decode.loss_cls: 1.8051  decode.loss_mask: 0.6136  decode.loss_dice: 0.5842  decode.d0.loss_cls: 4.3898  decode.d0.loss_mask: 0.6863  decode.d0.loss_dice: 0.7094  decode.d1.loss_cls: 1.7664  decode.d1.loss_mask: 0.6110  decode.d1.loss_dice: 0.5774  decode.d2.loss_cls: 1.8064  decode.d2.loss_mask: 0.6221  decode.d2.loss_dice: 0.5524  decode.d3.loss_cls: 1.7423  decode.d3.loss_mask: 0.6672  decode.d3.loss_dice: 0.6032  decode.d4.loss_cls: 1.8113  decode.d4.loss_mask: 0.5891  decode.d4.loss_dice: 0.5229  decode.d5.loss_cls: 1.8681  decode.d5.loss_mask: 0.5653  decode.d5.loss_dice: 0.5374  decode.d6.loss_cls: 1.9089  decode.d6.loss_mask: 0.5271  decode.d6.loss_dice: 0.5116  decode.d7.loss_cls: 1.8444  decode.d7.loss_mask: 0.5913  decode.d7.loss_dice: 0.5307  decode.d8.loss_cls: 1.8257  decode.d8.loss_mask: 0.5789  decode.d8.loss_dice: 0.5597
07/25 16:29:14 - mmengine - INFO - Iter(train) [ 1600/80000]  base_lr: 9.8199e-05 lr: 9.8199e-06  eta: 10:40:33  time: 0.4805  data_time: 0.0092  memory: 5919  grad_norm: 227.7138  loss: 36.0144  decode.loss_cls: 2.3248  decode.loss_mask: 0.5456  decode.loss_dice: 0.6317  decode.d0.loss_cls: 4.4706  decode.d0.loss_mask: 0.5494  decode.d0.loss_dice: 0.7105  decode.d1.loss_cls: 2.3457  decode.d1.loss_mask: 0.5222  decode.d1.loss_dice: 0.5870  decode.d2.loss_cls: 2.2494  decode.d2.loss_mask: 0.5076  decode.d2.loss_dice: 0.5979  decode.d3.loss_cls: 2.2913  decode.d3.loss_mask: 0.4925  decode.d3.loss_dice: 0.5526  decode.d4.loss_cls: 2.2455  decode.d4.loss_mask: 0.4602  decode.d4.loss_dice: 0.5445  decode.d5.loss_cls: 2.2109  decode.d5.loss_mask: 0.5221  decode.d5.loss_dice: 0.5608  decode.d6.loss_cls: 2.1984  decode.d6.loss_mask: 0.5362  decode.d6.loss_dice: 0.5523  decode.d7.loss_cls: 2.2559  decode.d7.loss_mask: 0.5863  decode.d7.loss_dice: 0.6177  decode.d8.loss_cls: 2.2037  decode.d8.loss_mask: 0.5096  decode.d8.loss_dice: 0.6316
07/25 16:29:38 - mmengine - INFO - Iter(train) [ 1650/80000]  base_lr: 9.8143e-05 lr: 9.8143e-06  eta: 10:39:45  time: 0.4809  data_time: 0.0096  memory: 5919  grad_norm: 419.7634  loss: 31.0022  decode.loss_cls: 2.0196  decode.loss_mask: 0.4016  decode.loss_dice: 0.4583  decode.d0.loss_cls: 4.1654  decode.d0.loss_mask: 0.4190  decode.d0.loss_dice: 0.5972  decode.d1.loss_cls: 2.1627  decode.d1.loss_mask: 0.3664  decode.d1.loss_dice: 0.4256  decode.d2.loss_cls: 1.9932  decode.d2.loss_mask: 0.3393  decode.d2.loss_dice: 0.3922  decode.d3.loss_cls: 1.9656  decode.d3.loss_mask: 0.3511  decode.d3.loss_dice: 0.4148  decode.d4.loss_cls: 1.9507  decode.d4.loss_mask: 0.3614  decode.d4.loss_dice: 0.3998  decode.d5.loss_cls: 2.1235  decode.d5.loss_mask: 0.3543  decode.d5.loss_dice: 0.4370  decode.d6.loss_cls: 2.1863  decode.d6.loss_mask: 0.3818  decode.d6.loss_dice: 0.4481  decode.d7.loss_cls: 2.1152  decode.d7.loss_mask: 0.3713  decode.d7.loss_dice: 0.4447  decode.d8.loss_cls: 2.1320  decode.d8.loss_mask: 0.3649  decode.d8.loss_dice: 0.4590
07/25 16:30:02 - mmengine - INFO - Iter(train) [ 1700/80000]  base_lr: 9.8087e-05 lr: 9.8087e-06  eta: 10:38:58  time: 0.4797  data_time: 0.0093  memory: 5937  grad_norm: 360.3744  loss: 31.6161  decode.loss_cls: 1.9659  decode.loss_mask: 0.4703  decode.loss_dice: 0.5855  decode.d0.loss_cls: 4.0063  decode.d0.loss_mask: 0.4669  decode.d0.loss_dice: 0.7036  decode.d1.loss_cls: 1.8757  decode.d1.loss_mask: 0.4161  decode.d1.loss_dice: 0.5443  decode.d2.loss_cls: 1.9608  decode.d2.loss_mask: 0.4097  decode.d2.loss_dice: 0.5555  decode.d3.loss_cls: 1.8562  decode.d3.loss_mask: 0.4098  decode.d3.loss_dice: 0.5532  decode.d4.loss_cls: 1.9365  decode.d4.loss_mask: 0.4141  decode.d4.loss_dice: 0.5564  decode.d5.loss_cls: 1.8823  decode.d5.loss_mask: 0.4523  decode.d5.loss_dice: 0.5778  decode.d6.loss_cls: 1.9107  decode.d6.loss_mask: 0.4893  decode.d6.loss_dice: 0.6328  decode.d7.loss_cls: 1.9445  decode.d7.loss_mask: 0.4730  decode.d7.loss_dice: 0.5749  decode.d8.loss_cls: 1.9544  decode.d8.loss_mask: 0.4552  decode.d8.loss_dice: 0.5822
07/25 16:30:26 - mmengine - INFO - Iter(train) [ 1750/80000]  base_lr: 9.8030e-05 lr: 9.8030e-06  eta: 10:38:14  time: 0.4819  data_time: 0.0097  memory: 5901  grad_norm: 160.0200  loss: 28.6992  decode.loss_cls: 1.7703  decode.loss_mask: 0.4057  decode.loss_dice: 0.4305  decode.d0.loss_cls: 3.8742  decode.d0.loss_mask: 0.4359  decode.d0.loss_dice: 0.5915  decode.d1.loss_cls: 1.8296  decode.d1.loss_mask: 0.4191  decode.d1.loss_dice: 0.4497  decode.d2.loss_cls: 1.7537  decode.d2.loss_mask: 0.4076  decode.d2.loss_dice: 0.4148  decode.d3.loss_cls: 1.7188  decode.d3.loss_mask: 0.4086  decode.d3.loss_dice: 0.4565  decode.d4.loss_cls: 1.7719  decode.d4.loss_mask: 0.4154  decode.d4.loss_dice: 0.4473  decode.d5.loss_cls: 1.7784  decode.d5.loss_mask: 0.4095  decode.d5.loss_dice: 0.4398  decode.d6.loss_cls: 1.8237  decode.d6.loss_mask: 0.4060  decode.d6.loss_dice: 0.4276  decode.d7.loss_cls: 1.8799  decode.d7.loss_mask: 0.4190  decode.d7.loss_dice: 0.4336  decode.d8.loss_cls: 1.8016  decode.d8.loss_mask: 0.4310  decode.d8.loss_dice: 0.4476
07/25 16:30:50 - mmengine - INFO - Iter(train) [ 1800/80000]  base_lr: 9.7974e-05 lr: 9.7974e-06  eta: 10:37:32  time: 0.4828  data_time: 0.0097  memory: 5979  grad_norm: 199.3817  loss: 34.7738  decode.loss_cls: 2.3891  decode.loss_mask: 0.3946  decode.loss_dice: 0.5256  decode.d0.loss_cls: 4.0826  decode.d0.loss_mask: 0.4671  decode.d0.loss_dice: 0.7005  decode.d1.loss_cls: 2.3804  decode.d1.loss_mask: 0.4012  decode.d1.loss_dice: 0.5251  decode.d2.loss_cls: 2.3771  decode.d2.loss_mask: 0.4017  decode.d2.loss_dice: 0.5256  decode.d3.loss_cls: 2.2755  decode.d3.loss_mask: 0.3644  decode.d3.loss_dice: 0.5152  decode.d4.loss_cls: 2.2538  decode.d4.loss_mask: 0.4038  decode.d4.loss_dice: 0.5602  decode.d5.loss_cls: 2.2717  decode.d5.loss_mask: 0.4430  decode.d5.loss_dice: 0.6055  decode.d6.loss_cls: 2.3021  decode.d6.loss_mask: 0.4453  decode.d6.loss_dice: 0.5990  decode.d7.loss_cls: 2.3482  decode.d7.loss_mask: 0.4201  decode.d7.loss_dice: 0.5522  decode.d8.loss_cls: 2.3078  decode.d8.loss_mask: 0.3930  decode.d8.loss_dice: 0.5419
07/25 16:31:15 - mmengine - INFO - Iter(train) [ 1850/80000]  base_lr: 9.7917e-05 lr: 9.7917e-06  eta: 10:36:58  time: 0.4868  data_time: 0.0096  memory: 5937  grad_norm: 206.3358  loss: 27.6452  decode.loss_cls: 1.7094  decode.loss_mask: 0.3481  decode.loss_dice: 0.3774  decode.d0.loss_cls: 3.7548  decode.d0.loss_mask: 0.3518  decode.d0.loss_dice: 0.5124  decode.d1.loss_cls: 2.0057  decode.d1.loss_mask: 0.3292  decode.d1.loss_dice: 0.3791  decode.d2.loss_cls: 1.8737  decode.d2.loss_mask: 0.3439  decode.d2.loss_dice: 0.3923  decode.d3.loss_cls: 1.7998  decode.d3.loss_mask: 0.3497  decode.d3.loss_dice: 0.4293  decode.d4.loss_cls: 1.8077  decode.d4.loss_mask: 0.3267  decode.d4.loss_dice: 0.4075  decode.d5.loss_cls: 1.8885  decode.d5.loss_mask: 0.3263  decode.d5.loss_dice: 0.3999  decode.d6.loss_cls: 1.8386  decode.d6.loss_mask: 0.3150  decode.d6.loss_dice: 0.3961  decode.d7.loss_cls: 1.8285  decode.d7.loss_mask: 0.3408  decode.d7.loss_dice: 0.3720  decode.d8.loss_cls: 1.6969  decode.d8.loss_mask: 0.3568  decode.d8.loss_dice: 0.3871
07/25 16:31:39 - mmengine - INFO - Iter(train) [ 1900/80000]  base_lr: 9.7861e-05 lr: 9.7861e-06  eta: 10:36:19  time: 0.4808  data_time: 0.0096  memory: 5901  grad_norm: 217.8952  loss: 29.7711  decode.loss_cls: 1.9297  decode.loss_mask: 0.4139  decode.loss_dice: 0.4542  decode.d0.loss_cls: 3.5833  decode.d0.loss_mask: 0.4186  decode.d0.loss_dice: 0.5133  decode.d1.loss_cls: 2.0212  decode.d1.loss_mask: 0.3906  decode.d1.loss_dice: 0.4070  decode.d2.loss_cls: 1.9251  decode.d2.loss_mask: 0.3886  decode.d2.loss_dice: 0.4103  decode.d3.loss_cls: 1.9165  decode.d3.loss_mask: 0.4408  decode.d3.loss_dice: 0.4483  decode.d4.loss_cls: 1.9691  decode.d4.loss_mask: 0.4385  decode.d4.loss_dice: 0.4293  decode.d5.loss_cls: 1.9139  decode.d5.loss_mask: 0.4032  decode.d5.loss_dice: 0.4118  decode.d6.loss_cls: 2.0937  decode.d6.loss_mask: 0.4073  decode.d6.loss_dice: 0.4274  decode.d7.loss_cls: 1.9919  decode.d7.loss_mask: 0.3857  decode.d7.loss_dice: 0.4249  decode.d8.loss_cls: 2.0049  decode.d8.loss_mask: 0.4115  decode.d8.loss_dice: 0.3963
07/25 16:32:03 - mmengine - INFO - Iter(train) [ 1950/80000]  base_lr: 9.7805e-05 lr: 9.7805e-06  eta: 10:35:38  time: 0.4814  data_time: 0.0095  memory: 5937  grad_norm: 153.7092  loss: 29.7131  decode.loss_cls: 1.8805  decode.loss_mask: 0.3773  decode.loss_dice: 0.5402  decode.d0.loss_cls: 3.6101  decode.d0.loss_mask: 0.4199  decode.d0.loss_dice: 0.6535  decode.d1.loss_cls: 1.9387  decode.d1.loss_mask: 0.3670  decode.d1.loss_dice: 0.5097  decode.d2.loss_cls: 1.9196  decode.d2.loss_mask: 0.3638  decode.d2.loss_dice: 0.4825  decode.d3.loss_cls: 1.9387  decode.d3.loss_mask: 0.3349  decode.d3.loss_dice: 0.4948  decode.d4.loss_cls: 1.9451  decode.d4.loss_mask: 0.3451  decode.d4.loss_dice: 0.4804  decode.d5.loss_cls: 1.9440  decode.d5.loss_mask: 0.3443  decode.d5.loss_dice: 0.4913  decode.d6.loss_cls: 1.9668  decode.d6.loss_mask: 0.3482  decode.d6.loss_dice: 0.4622  decode.d7.loss_cls: 1.8328  decode.d7.loss_mask: 0.3748  decode.d7.loss_dice: 0.4967  decode.d8.loss_cls: 1.9389  decode.d8.loss_mask: 0.4026  decode.d8.loss_dice: 0.5088
07/25 16:32:27 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250725_161554
07/25 16:32:27 - mmengine - INFO - Iter(train) [ 2000/80000]  base_lr: 9.7748e-05 lr: 9.7748e-06  eta: 10:34:58  time: 0.4803  data_time: 0.0096  memory: 5919  grad_norm: 209.5908  loss: 29.8018  decode.loss_cls: 1.9657  decode.loss_mask: 0.4627  decode.loss_dice: 0.4931  decode.d0.loss_cls: 3.4642  decode.d0.loss_mask: 0.4294  decode.d0.loss_dice: 0.6081  decode.d1.loss_cls: 2.0660  decode.d1.loss_mask: 0.4222  decode.d1.loss_dice: 0.4483  decode.d2.loss_cls: 1.8825  decode.d2.loss_mask: 0.4308  decode.d2.loss_dice: 0.4403  decode.d3.loss_cls: 1.9237  decode.d3.loss_mask: 0.3738  decode.d3.loss_dice: 0.4653  decode.d4.loss_cls: 1.8842  decode.d4.loss_mask: 0.4399  decode.d4.loss_dice: 0.5002  decode.d5.loss_cls: 1.8533  decode.d5.loss_mask: 0.4224  decode.d5.loss_dice: 0.4683  decode.d6.loss_cls: 1.9117  decode.d6.loss_mask: 0.3664  decode.d6.loss_dice: 0.4692  decode.d7.loss_cls: 1.9465  decode.d7.loss_mask: 0.3960  decode.d7.loss_dice: 0.5107  decode.d8.loss_cls: 1.8110  decode.d8.loss_mask: 0.4340  decode.d8.loss_dice: 0.5118
07/25 16:32:51 - mmengine - INFO - Iter(train) [ 2050/80000]  base_lr: 9.7692e-05 lr: 9.7692e-06  eta: 10:34:19  time: 0.4822  data_time: 0.0096  memory: 5919  grad_norm: 167.4537  loss: 26.2336  decode.loss_cls: 1.6207  decode.loss_mask: 0.3207  decode.loss_dice: 0.5248  decode.d0.loss_cls: 3.2024  decode.d0.loss_mask: 0.3348  decode.d0.loss_dice: 0.5645  decode.d1.loss_cls: 1.8877  decode.d1.loss_mask: 0.3041  decode.d1.loss_dice: 0.4750  decode.d2.loss_cls: 1.5999  decode.d2.loss_mask: 0.2981  decode.d2.loss_dice: 0.4284  decode.d3.loss_cls: 1.5815  decode.d3.loss_mask: 0.3055  decode.d3.loss_dice: 0.4816  decode.d4.loss_cls: 1.6295  decode.d4.loss_mask: 0.2991  decode.d4.loss_dice: 0.4706  decode.d5.loss_cls: 1.5891  decode.d5.loss_mask: 0.2964  decode.d5.loss_dice: 0.4553  decode.d6.loss_cls: 1.6273  decode.d6.loss_mask: 0.3033  decode.d6.loss_dice: 0.4621  decode.d7.loss_cls: 1.6588  decode.d7.loss_mask: 0.3102  decode.d7.loss_dice: 0.5274  decode.d8.loss_cls: 1.6351  decode.d8.loss_mask: 0.4088  decode.d8.loss_dice: 0.6309
07/25 16:33:15 - mmengine - INFO - Iter(train) [ 2100/80000]  base_lr: 9.7635e-05 lr: 9.7635e-06  eta: 10:33:47  time: 0.4812  data_time: 0.0094  memory: 5994  grad_norm: 321.9546  loss: 29.7294  decode.loss_cls: 1.7893  decode.loss_mask: 0.4959  decode.loss_dice: 0.5155  decode.d0.loss_cls: 3.2607  decode.d0.loss_mask: 0.5518  decode.d0.loss_dice: 0.6690  decode.d1.loss_cls: 1.8773  decode.d1.loss_mask: 0.4999  decode.d1.loss_dice: 0.5233  decode.d2.loss_cls: 1.7115  decode.d2.loss_mask: 0.4933  decode.d2.loss_dice: 0.5031  decode.d3.loss_cls: 1.7485  decode.d3.loss_mask: 0.5006  decode.d3.loss_dice: 0.5010  decode.d4.loss_cls: 1.7296  decode.d4.loss_mask: 0.4688  decode.d4.loss_dice: 0.5186  decode.d5.loss_cls: 1.7141  decode.d5.loss_mask: 0.5008  decode.d5.loss_dice: 0.5166  decode.d6.loss_cls: 1.8565  decode.d6.loss_mask: 0.5064  decode.d6.loss_dice: 0.5419  decode.d7.loss_cls: 1.8421  decode.d7.loss_mask: 0.4983  decode.d7.loss_dice: 0.5150  decode.d8.loss_cls: 1.8561  decode.d8.loss_mask: 0.4903  decode.d8.loss_dice: 0.5336
07/25 16:33:39 - mmengine - INFO - Iter(train) [ 2150/80000]  base_lr: 9.7579e-05 lr: 9.7579e-06  eta: 10:33:10  time: 0.4810  data_time: 0.0095  memory: 5870  grad_norm: 171.4703  loss: 27.8921  decode.loss_cls: 1.6962  decode.loss_mask: 0.4282  decode.loss_dice: 0.4983  decode.d0.loss_cls: 3.1635  decode.d0.loss_mask: 0.4146  decode.d0.loss_dice: 0.6039  decode.d1.loss_cls: 1.9052  decode.d1.loss_mask: 0.3960  decode.d1.loss_dice: 0.5167  decode.d2.loss_cls: 1.7016  decode.d2.loss_mask: 0.4300  decode.d2.loss_dice: 0.5513  decode.d3.loss_cls: 1.7155  decode.d3.loss_mask: 0.3802  decode.d3.loss_dice: 0.4775  decode.d4.loss_cls: 1.6720  decode.d4.loss_mask: 0.3811  decode.d4.loss_dice: 0.4498  decode.d5.loss_cls: 1.6911  decode.d5.loss_mask: 0.3933  decode.d5.loss_dice: 0.4830  decode.d6.loss_cls: 1.7504  decode.d6.loss_mask: 0.3684  decode.d6.loss_dice: 0.4729  decode.d7.loss_cls: 1.7426  decode.d7.loss_mask: 0.4121  decode.d7.loss_dice: 0.5726  decode.d8.loss_cls: 1.7622  decode.d8.loss_mask: 0.3765  decode.d8.loss_dice: 0.4851
07/25 16:34:03 - mmengine - INFO - Iter(train) [ 2200/80000]  base_lr: 9.7523e-05 lr: 9.7523e-06  eta: 10:32:39  time: 0.4918  data_time: 0.0103  memory: 5920  grad_norm: 163.4067  loss: 31.7304  decode.loss_cls: 2.1034  decode.loss_mask: 0.3703  decode.loss_dice: 0.4514  decode.d0.loss_cls: 3.4697  decode.d0.loss_mask: 0.4413  decode.d0.loss_dice: 0.6325  decode.d1.loss_cls: 2.2486  decode.d1.loss_mask: 0.3928  decode.d1.loss_dice: 0.4329  decode.d2.loss_cls: 2.0995  decode.d2.loss_mask: 0.3891  decode.d2.loss_dice: 0.4417  decode.d3.loss_cls: 2.1366  decode.d3.loss_mask: 0.3850  decode.d3.loss_dice: 0.4509  decode.d4.loss_cls: 2.1563  decode.d4.loss_mask: 0.3916  decode.d4.loss_dice: 0.4609  decode.d5.loss_cls: 2.1614  decode.d5.loss_mask: 0.4367  decode.d5.loss_dice: 0.4810  decode.d6.loss_cls: 2.1818  decode.d6.loss_mask: 0.3919  decode.d6.loss_dice: 0.4662  decode.d7.loss_cls: 2.2388  decode.d7.loss_mask: 0.4222  decode.d7.loss_dice: 0.4743  decode.d8.loss_cls: 2.1811  decode.d8.loss_mask: 0.3987  decode.d8.loss_dice: 0.4417
07/25 16:34:27 - mmengine - INFO - Iter(train) [ 2250/80000]  base_lr: 9.7466e-05 lr: 9.7466e-06  eta: 10:32:00  time: 0.4799  data_time: 0.0094  memory: 5919  grad_norm: 289.8653  loss: 28.9543  decode.loss_cls: 1.9352  decode.loss_mask: 0.3871  decode.loss_dice: 0.4771  decode.d0.loss_cls: 3.1627  decode.d0.loss_mask: 0.3837  decode.d0.loss_dice: 0.5721  decode.d1.loss_cls: 1.9514  decode.d1.loss_mask: 0.3890  decode.d1.loss_dice: 0.4182  decode.d2.loss_cls: 1.8845  decode.d2.loss_mask: 0.3716  decode.d2.loss_dice: 0.4066  decode.d3.loss_cls: 1.9634  decode.d3.loss_mask: 0.3968  decode.d3.loss_dice: 0.4435  decode.d4.loss_cls: 1.9406  decode.d4.loss_mask: 0.3881  decode.d4.loss_dice: 0.4179  decode.d5.loss_cls: 1.9098  decode.d5.loss_mask: 0.3917  decode.d5.loss_dice: 0.4502  decode.d6.loss_cls: 1.9319  decode.d6.loss_mask: 0.3778  decode.d6.loss_dice: 0.4400  decode.d7.loss_cls: 1.9617  decode.d7.loss_mask: 0.3817  decode.d7.loss_dice: 0.4216  decode.d8.loss_cls: 1.9817  decode.d8.loss_mask: 0.3765  decode.d8.loss_dice: 0.4402
07/25 16:34:52 - mmengine - INFO - Iter(train) [ 2300/80000]  base_lr: 9.7410e-05 lr: 9.7410e-06  eta: 10:31:35  time: 0.4997  data_time: 0.0099  memory: 5938  grad_norm: 146.9650  loss: 28.2187  decode.loss_cls: 1.7642  decode.loss_mask: 0.3677  decode.loss_dice: 0.5201  decode.d0.loss_cls: 3.0746  decode.d0.loss_mask: 0.4270  decode.d0.loss_dice: 0.6266  decode.d1.loss_cls: 1.8900  decode.d1.loss_mask: 0.3296  decode.d1.loss_dice: 0.4826  decode.d2.loss_cls: 1.8043  decode.d2.loss_mask: 0.3708  decode.d2.loss_dice: 0.4956  decode.d3.loss_cls: 1.8040  decode.d3.loss_mask: 0.3567  decode.d3.loss_dice: 0.4864  decode.d4.loss_cls: 1.7491  decode.d4.loss_mask: 0.4055  decode.d4.loss_dice: 0.5023  decode.d5.loss_cls: 1.8707  decode.d5.loss_mask: 0.3439  decode.d5.loss_dice: 0.4596  decode.d6.loss_cls: 1.8566  decode.d6.loss_mask: 0.3392  decode.d6.loss_dice: 0.4654  decode.d7.loss_cls: 1.8498  decode.d7.loss_mask: 0.3328  decode.d7.loss_dice: 0.4229  decode.d8.loss_cls: 1.9566  decode.d8.loss_mask: 0.3523  decode.d8.loss_dice: 0.5117
07/25 16:35:17 - mmengine - INFO - Iter(train) [ 2350/80000]  base_lr: 9.7353e-05 lr: 9.7353e-06  eta: 10:31:35  time: 0.5097  data_time: 0.0108  memory: 5919  grad_norm: 267.5214  loss: 28.7374  decode.loss_cls: 1.9135  decode.loss_mask: 0.3608  decode.loss_dice: 0.5626  decode.d0.loss_cls: 3.1508  decode.d0.loss_mask: 0.4345  decode.d0.loss_dice: 0.6663  decode.d1.loss_cls: 2.0042  decode.d1.loss_mask: 0.3252  decode.d1.loss_dice: 0.4641  decode.d2.loss_cls: 1.8950  decode.d2.loss_mask: 0.3329  decode.d2.loss_dice: 0.4596  decode.d3.loss_cls: 1.9285  decode.d3.loss_mask: 0.2978  decode.d3.loss_dice: 0.4298  decode.d4.loss_cls: 1.9188  decode.d4.loss_mask: 0.3698  decode.d4.loss_dice: 0.4665  decode.d5.loss_cls: 1.9037  decode.d5.loss_mask: 0.3114  decode.d5.loss_dice: 0.4589  decode.d6.loss_cls: 1.9435  decode.d6.loss_mask: 0.3032  decode.d6.loss_dice: 0.4414  decode.d7.loss_cls: 1.9974  decode.d7.loss_mask: 0.2855  decode.d7.loss_dice: 0.4258  decode.d8.loss_cls: 1.8625  decode.d8.loss_mask: 0.3226  decode.d8.loss_dice: 0.5009
07/25 16:35:42 - mmengine - INFO - Iter(train) [ 2400/80000]  base_lr: 9.7297e-05 lr: 9.7297e-06  eta: 10:31:29  time: 0.4983  data_time: 0.0101  memory: 5937  grad_norm: 159.9321  loss: 25.7937  decode.loss_cls: 1.5745  decode.loss_mask: 0.3973  decode.loss_dice: 0.4348  decode.d0.loss_cls: 2.9542  decode.d0.loss_mask: 0.4499  decode.d0.loss_dice: 0.5398  decode.d1.loss_cls: 1.6833  decode.d1.loss_mask: 0.4163  decode.d1.loss_dice: 0.4353  decode.d2.loss_cls: 1.5427  decode.d2.loss_mask: 0.4027  decode.d2.loss_dice: 0.4259  decode.d3.loss_cls: 1.5950  decode.d3.loss_mask: 0.3947  decode.d3.loss_dice: 0.4120  decode.d4.loss_cls: 1.5519  decode.d4.loss_mask: 0.3960  decode.d4.loss_dice: 0.4363  decode.d5.loss_cls: 1.6131  decode.d5.loss_mask: 0.3860  decode.d5.loss_dice: 0.4082  decode.d6.loss_cls: 1.6561  decode.d6.loss_mask: 0.3877  decode.d6.loss_dice: 0.4065  decode.d7.loss_cls: 1.6740  decode.d7.loss_mask: 0.3945  decode.d7.loss_dice: 0.4114  decode.d8.loss_cls: 1.5894  decode.d8.loss_mask: 0.3916  decode.d8.loss_dice: 0.4323
07/25 16:36:06 - mmengine - INFO - Iter(train) [ 2450/80000]  base_lr: 9.7241e-05 lr: 9.7241e-06  eta: 10:31:03  time: 0.4907  data_time: 0.0099  memory: 5919  grad_norm: 203.0129  loss: 25.1266  decode.loss_cls: 1.5554  decode.loss_mask: 0.3128  decode.loss_dice: 0.4172  decode.d0.loss_cls: 2.8363  decode.d0.loss_mask: 0.4116  decode.d0.loss_dice: 0.6204  decode.d1.loss_cls: 1.7121  decode.d1.loss_mask: 0.3175  decode.d1.loss_dice: 0.4458  decode.d2.loss_cls: 1.5929  decode.d2.loss_mask: 0.2787  decode.d2.loss_dice: 0.3944  decode.d3.loss_cls: 1.6250  decode.d3.loss_mask: 0.3004  decode.d3.loss_dice: 0.3892  decode.d4.loss_cls: 1.6934  decode.d4.loss_mask: 0.2883  decode.d4.loss_dice: 0.4126  decode.d5.loss_cls: 1.6482  decode.d5.loss_mask: 0.3485  decode.d5.loss_dice: 0.4642  decode.d6.loss_cls: 1.6271  decode.d6.loss_mask: 0.2844  decode.d6.loss_dice: 0.4331  decode.d7.loss_cls: 1.6168  decode.d7.loss_mask: 0.2982  decode.d7.loss_dice: 0.4476  decode.d8.loss_cls: 1.6684  decode.d8.loss_mask: 0.2779  decode.d8.loss_dice: 0.4083
07/25 16:36:31 - mmengine - INFO - Iter(train) [ 2500/80000]  base_lr: 9.7184e-05 lr: 9.7184e-06  eta: 10:30:43  time: 0.4843  data_time: 0.0097  memory: 5919  grad_norm: 289.1448  loss: 29.3380  decode.loss_cls: 1.6538  decode.loss_mask: 0.6056  decode.loss_dice: 0.5881  decode.d0.loss_cls: 2.8227  decode.d0.loss_mask: 0.5423  decode.d0.loss_dice: 0.6673  decode.d1.loss_cls: 1.8002  decode.d1.loss_mask: 0.5520  decode.d1.loss_dice: 0.5421  decode.d2.loss_cls: 1.6199  decode.d2.loss_mask: 0.5385  decode.d2.loss_dice: 0.5348  decode.d3.loss_cls: 1.6843  decode.d3.loss_mask: 0.5459  decode.d3.loss_dice: 0.5204  decode.d4.loss_cls: 1.6463  decode.d4.loss_mask: 0.5296  decode.d4.loss_dice: 0.5417  decode.d5.loss_cls: 1.6623  decode.d5.loss_mask: 0.5438  decode.d5.loss_dice: 0.5899  decode.d6.loss_cls: 1.6769  decode.d6.loss_mask: 0.5438  decode.d6.loss_dice: 0.5806  decode.d7.loss_cls: 1.7473  decode.d7.loss_mask: 0.5717  decode.d7.loss_dice: 0.6008  decode.d8.loss_cls: 1.7541  decode.d8.loss_mask: 0.5447  decode.d8.loss_dice: 0.5864
07/25 16:36:55 - mmengine - INFO - Iter(train) [ 2550/80000]  base_lr: 9.7128e-05 lr: 9.7128e-06  eta: 10:30:18  time: 0.4900  data_time: 0.0099  memory: 5919  grad_norm: 165.8741  loss: 22.8779  decode.loss_cls: 1.4037  decode.loss_mask: 0.3820  decode.loss_dice: 0.4494  decode.d0.loss_cls: 2.5156  decode.d0.loss_mask: 0.4183  decode.d0.loss_dice: 0.5287  decode.d1.loss_cls: 1.4682  decode.d1.loss_mask: 0.3965  decode.d1.loss_dice: 0.4159  decode.d2.loss_cls: 1.3804  decode.d2.loss_mask: 0.3659  decode.d2.loss_dice: 0.3783  decode.d3.loss_cls: 1.4226  decode.d3.loss_mask: 0.3583  decode.d3.loss_dice: 0.4161  decode.d4.loss_cls: 1.3345  decode.d4.loss_mask: 0.3599  decode.d4.loss_dice: 0.3833  decode.d5.loss_cls: 1.2940  decode.d5.loss_mask: 0.3851  decode.d5.loss_dice: 0.4028  decode.d6.loss_cls: 1.2893  decode.d6.loss_mask: 0.3555  decode.d6.loss_dice: 0.4192  decode.d7.loss_cls: 1.3225  decode.d7.loss_mask: 0.3655  decode.d7.loss_dice: 0.4580  decode.d8.loss_cls: 1.4059  decode.d8.loss_mask: 0.3684  decode.d8.loss_dice: 0.4340
07/25 16:37:20 - mmengine - INFO - Iter(train) [ 2600/80000]  base_lr: 9.7071e-05 lr: 9.7071e-06  eta: 10:29:56  time: 0.4917  data_time: 0.0098  memory: 5937  grad_norm: 230.5886  loss: 28.8761  decode.loss_cls: 1.8845  decode.loss_mask: 0.3565  decode.loss_dice: 0.4917  decode.d0.loss_cls: 2.8420  decode.d0.loss_mask: 0.4368  decode.d0.loss_dice: 0.6353  decode.d1.loss_cls: 2.0676  decode.d1.loss_mask: 0.3660  decode.d1.loss_dice: 0.5051  decode.d2.loss_cls: 1.9284  decode.d2.loss_mask: 0.3388  decode.d2.loss_dice: 0.4554  decode.d3.loss_cls: 1.8966  decode.d3.loss_mask: 0.3326  decode.d3.loss_dice: 0.4833  decode.d4.loss_cls: 2.0089  decode.d4.loss_mask: 0.3453  decode.d4.loss_dice: 0.4813  decode.d5.loss_cls: 1.8966  decode.d5.loss_mask: 0.3934  decode.d5.loss_dice: 0.5118  decode.d6.loss_cls: 1.8791  decode.d6.loss_mask: 0.3811  decode.d6.loss_dice: 0.4767  decode.d7.loss_cls: 1.8432  decode.d7.loss_mask: 0.3839  decode.d7.loss_dice: 0.5003  decode.d8.loss_cls: 1.8715  decode.d8.loss_mask: 0.4080  decode.d8.loss_dice: 0.4744
07/25 16:37:44 - mmengine - INFO - Iter(train) [ 2650/80000]  base_lr: 9.7015e-05 lr: 9.7015e-06  eta: 10:29:40  time: 0.4871  data_time: 0.0097  memory: 5919  grad_norm: 138.4237  loss: 23.7343  decode.loss_cls: 1.4435  decode.loss_mask: 0.3560  decode.loss_dice: 0.3943  decode.d0.loss_cls: 2.4642  decode.d0.loss_mask: 0.3966  decode.d0.loss_dice: 0.5169  decode.d1.loss_cls: 1.5940  decode.d1.loss_mask: 0.3321  decode.d1.loss_dice: 0.4147  decode.d2.loss_cls: 1.4850  decode.d2.loss_mask: 0.3789  decode.d2.loss_dice: 0.4230  decode.d3.loss_cls: 1.5826  decode.d3.loss_mask: 0.3452  decode.d3.loss_dice: 0.4210  decode.d4.loss_cls: 1.5126  decode.d4.loss_mask: 0.3244  decode.d4.loss_dice: 0.3841  decode.d5.loss_cls: 1.5066  decode.d5.loss_mask: 0.3242  decode.d5.loss_dice: 0.3861  decode.d6.loss_cls: 1.4721  decode.d6.loss_mask: 0.3481  decode.d6.loss_dice: 0.3699  decode.d7.loss_cls: 1.5742  decode.d7.loss_mask: 0.3237  decode.d7.loss_dice: 0.3951  decode.d8.loss_cls: 1.5449  decode.d8.loss_mask: 0.3494  decode.d8.loss_dice: 0.3709
07/25 16:38:09 - mmengine - INFO - Iter(train) [ 2700/80000]  base_lr: 9.6958e-05 lr: 9.6958e-06  eta: 10:29:24  time: 0.4985  data_time: 0.0102  memory: 5920  grad_norm: 181.6178  loss: 27.1230  decode.loss_cls: 1.7979  decode.loss_mask: 0.2982  decode.loss_dice: 0.4874  decode.d0.loss_cls: 2.6598  decode.d0.loss_mask: 0.3254  decode.d0.loss_dice: 0.6193  decode.d1.loss_cls: 1.8563  decode.d1.loss_mask: 0.2715  decode.d1.loss_dice: 0.4411  decode.d2.loss_cls: 1.8766  decode.d2.loss_mask: 0.2971  decode.d2.loss_dice: 0.4565  decode.d3.loss_cls: 1.8091  decode.d3.loss_mask: 0.2932  decode.d3.loss_dice: 0.4636  decode.d4.loss_cls: 1.7536  decode.d4.loss_mask: 0.2822  decode.d4.loss_dice: 0.4657  decode.d5.loss_cls: 1.8007  decode.d5.loss_mask: 0.3026  decode.d5.loss_dice: 0.4544  decode.d6.loss_cls: 1.8944  decode.d6.loss_mask: 0.3008  decode.d6.loss_dice: 0.5102  decode.d7.loss_cls: 1.9533  decode.d7.loss_mask: 0.3062  decode.d7.loss_dice: 0.4939  decode.d8.loss_cls: 1.8443  decode.d8.loss_mask: 0.3050  decode.d8.loss_dice: 0.5028
07/25 16:38:34 - mmengine - INFO - Iter(train) [ 2750/80000]  base_lr: 9.6902e-05 lr: 9.6902e-06  eta: 10:29:08  time: 0.4972  data_time: 0.0102  memory: 5900  grad_norm: 181.3670  loss: 22.9559  decode.loss_cls: 1.4307  decode.loss_mask: 0.3103  decode.loss_dice: 0.3731  decode.d0.loss_cls: 2.5097  decode.d0.loss_mask: 0.3312  decode.d0.loss_dice: 0.5519  decode.d1.loss_cls: 1.6283  decode.d1.loss_mask: 0.2906  decode.d1.loss_dice: 0.3262  decode.d2.loss_cls: 1.4629  decode.d2.loss_mask: 0.2918  decode.d2.loss_dice: 0.3442  decode.d3.loss_cls: 1.5116  decode.d3.loss_mask: 0.2865  decode.d3.loss_dice: 0.3372  decode.d4.loss_cls: 1.5575  decode.d4.loss_mask: 0.2968  decode.d4.loss_dice: 0.3609  decode.d5.loss_cls: 1.5616  decode.d5.loss_mask: 0.2957  decode.d5.loss_dice: 0.3447  decode.d6.loss_cls: 1.4677  decode.d6.loss_mask: 0.3057  decode.d6.loss_dice: 0.3724  decode.d7.loss_cls: 1.5341  decode.d7.loss_mask: 0.3015  decode.d7.loss_dice: 0.3758  decode.d8.loss_cls: 1.5302  decode.d8.loss_mask: 0.2978  decode.d8.loss_dice: 0.3673
07/25 16:38:59 - mmengine - INFO - Iter(train) [ 2800/80000]  base_lr: 9.6846e-05 lr: 9.6846e-06  eta: 10:29:01  time: 0.4908  data_time: 0.0102  memory: 5979  grad_norm: 117.1638  loss: 23.0526  decode.loss_cls: 1.5354  decode.loss_mask: 0.2847  decode.loss_dice: 0.3170  decode.d0.loss_cls: 2.5921  decode.d0.loss_mask: 0.3066  decode.d0.loss_dice: 0.4490  decode.d1.loss_cls: 1.7274  decode.d1.loss_mask: 0.2755  decode.d1.loss_dice: 0.3326  decode.d2.loss_cls: 1.5278  decode.d2.loss_mask: 0.2709  decode.d2.loss_dice: 0.3228  decode.d3.loss_cls: 1.5481  decode.d3.loss_mask: 0.2707  decode.d3.loss_dice: 0.3156  decode.d4.loss_cls: 1.5124  decode.d4.loss_mask: 0.2770  decode.d4.loss_dice: 0.3297  decode.d5.loss_cls: 1.5475  decode.d5.loss_mask: 0.2721  decode.d5.loss_dice: 0.3272  decode.d6.loss_cls: 1.6885  decode.d6.loss_mask: 0.2736  decode.d6.loss_dice: 0.3333  decode.d7.loss_cls: 1.6427  decode.d7.loss_mask: 0.2653  decode.d7.loss_dice: 0.3354  decode.d8.loss_cls: 1.5294  decode.d8.loss_mask: 0.2999  decode.d8.loss_dice: 0.3425
07/25 16:39:24 - mmengine - INFO - Iter(train) [ 2850/80000]  base_lr: 9.6789e-05 lr: 9.6789e-06  eta: 10:28:50  time: 0.4968  data_time: 0.0103  memory: 5992  grad_norm: 228.9240  loss: 24.9493  decode.loss_cls: 1.4934  decode.loss_mask: 0.4161  decode.loss_dice: 0.4361  decode.d0.loss_cls: 2.5011  decode.d0.loss_mask: 0.4676  decode.d0.loss_dice: 0.5319  decode.d1.loss_cls: 1.6493  decode.d1.loss_mask: 0.4409  decode.d1.loss_dice: 0.4308  decode.d2.loss_cls: 1.5683  decode.d2.loss_mask: 0.4120  decode.d2.loss_dice: 0.4247  decode.d3.loss_cls: 1.4768  decode.d3.loss_mask: 0.3990  decode.d3.loss_dice: 0.4111  decode.d4.loss_cls: 1.5300  decode.d4.loss_mask: 0.4011  decode.d4.loss_dice: 0.4320  decode.d5.loss_cls: 1.5454  decode.d5.loss_mask: 0.4174  decode.d5.loss_dice: 0.4391  decode.d6.loss_cls: 1.5661  decode.d6.loss_mask: 0.3861  decode.d6.loss_dice: 0.4076  decode.d7.loss_cls: 1.6159  decode.d7.loss_mask: 0.4048  decode.d7.loss_dice: 0.4179  decode.d8.loss_cls: 1.4992  decode.d8.loss_mask: 0.4145  decode.d8.loss_dice: 0.4131
07/25 16:39:49 - mmengine - INFO - Iter(train) [ 2900/80000]  base_lr: 9.6733e-05 lr: 9.6733e-06  eta: 10:28:42  time: 0.4982  data_time: 0.0102  memory: 5979  grad_norm: 181.0454  loss: 25.9577  decode.loss_cls: 1.5844  decode.loss_mask: 0.4019  decode.loss_dice: 0.4758  decode.d0.loss_cls: 2.4677  decode.d0.loss_mask: 0.4246  decode.d0.loss_dice: 0.5424  decode.d1.loss_cls: 1.6689  decode.d1.loss_mask: 0.3954  decode.d1.loss_dice: 0.4389  decode.d2.loss_cls: 1.6748  decode.d2.loss_mask: 0.3606  decode.d2.loss_dice: 0.4442  decode.d3.loss_cls: 1.6739  decode.d3.loss_mask: 0.3889  decode.d3.loss_dice: 0.4553  decode.d4.loss_cls: 1.7267  decode.d4.loss_mask: 0.3633  decode.d4.loss_dice: 0.4578  decode.d5.loss_cls: 1.7169  decode.d5.loss_mask: 0.3841  decode.d5.loss_dice: 0.4533  decode.d6.loss_cls: 1.6716  decode.d6.loss_mask: 0.3573  decode.d6.loss_dice: 0.4571  decode.d7.loss_cls: 1.6494  decode.d7.loss_mask: 0.3827  decode.d7.loss_dice: 0.4808  decode.d8.loss_cls: 1.6057  decode.d8.loss_mask: 0.3917  decode.d8.loss_dice: 0.4617
07/25 16:40:14 - mmengine - INFO - Iter(train) [ 2950/80000]  base_lr: 9.6676e-05 lr: 9.6676e-06  eta: 10:28:41  time: 0.5091  data_time: 0.0110  memory: 5900  grad_norm: 228.6992  loss: 21.6980  decode.loss_cls: 1.2292  decode.loss_mask: 0.3776  decode.loss_dice: 0.3576  decode.d0.loss_cls: 2.3374  decode.d0.loss_mask: 0.4138  decode.d0.loss_dice: 0.4381  decode.d1.loss_cls: 1.4323  decode.d1.loss_mask: 0.3798  decode.d1.loss_dice: 0.3754  decode.d2.loss_cls: 1.3728  decode.d2.loss_mask: 0.3842  decode.d2.loss_dice: 0.3779  decode.d3.loss_cls: 1.2952  decode.d3.loss_mask: 0.3777  decode.d3.loss_dice: 0.4011  decode.d4.loss_cls: 1.2272  decode.d4.loss_mask: 0.3643  decode.d4.loss_dice: 0.3717  decode.d5.loss_cls: 1.2751  decode.d5.loss_mask: 0.3648  decode.d5.loss_dice: 0.3655  decode.d6.loss_cls: 1.3599  decode.d6.loss_mask: 0.3793  decode.d6.loss_dice: 0.3810  decode.d7.loss_cls: 1.2679  decode.d7.loss_mask: 0.3785  decode.d7.loss_dice: 0.3628  decode.d8.loss_cls: 1.2776  decode.d8.loss_mask: 0.3862  decode.d8.loss_dice: 0.3861
07/25 16:40:39 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250725_161554
07/25 16:40:39 - mmengine - INFO - Iter(train) [ 3000/80000]  base_lr: 9.6620e-05 lr: 9.6620e-06  eta: 10:28:27  time: 0.4827  data_time: 0.0095  memory: 5919  grad_norm: 332.1281  loss: 21.0521  decode.loss_cls: 1.3469  decode.loss_mask: 0.2515  decode.loss_dice: 0.3771  decode.d0.loss_cls: 2.2064  decode.d0.loss_mask: 0.2639  decode.d0.loss_dice: 0.4104  decode.d1.loss_cls: 1.5162  decode.d1.loss_mask: 0.2546  decode.d1.loss_dice: 0.3791  decode.d2.loss_cls: 1.3337  decode.d2.loss_mask: 0.2471  decode.d2.loss_dice: 0.3495  decode.d3.loss_cls: 1.4160  decode.d3.loss_mask: 0.2480  decode.d3.loss_dice: 0.3455  decode.d4.loss_cls: 1.3910  decode.d4.loss_mask: 0.2589  decode.d4.loss_dice: 0.3523  decode.d5.loss_cls: 1.4071  decode.d5.loss_mask: 0.2497  decode.d5.loss_dice: 0.3465  decode.d6.loss_cls: 1.5347  decode.d6.loss_mask: 0.2437  decode.d6.loss_dice: 0.3518  decode.d7.loss_cls: 1.3687  decode.d7.loss_mask: 0.2518  decode.d7.loss_dice: 0.3815  decode.d8.loss_cls: 1.3997  decode.d8.loss_mask: 0.2360  decode.d8.loss_dice: 0.3327
07/25 16:41:03 - mmengine - INFO - Iter(train) [ 3050/80000]  base_lr: 9.6563e-05 lr: 9.6563e-06  eta: 10:27:50  time: 0.4805  data_time: 0.0097  memory: 5919  grad_norm: 222.7782  loss: 24.2731  decode.loss_cls: 1.5318  decode.loss_mask: 0.3351  decode.loss_dice: 0.3726  decode.d0.loss_cls: 2.5320  decode.d0.loss_mask: 0.3808  decode.d0.loss_dice: 0.5081  decode.d1.loss_cls: 1.7642  decode.d1.loss_mask: 0.3340  decode.d1.loss_dice: 0.3437  decode.d2.loss_cls: 1.5028  decode.d2.loss_mask: 0.3384  decode.d2.loss_dice: 0.3758  decode.d3.loss_cls: 1.6316  decode.d3.loss_mask: 0.3362  decode.d3.loss_dice: 0.3734  decode.d4.loss_cls: 1.5573  decode.d4.loss_mask: 0.3341  decode.d4.loss_dice: 0.3671  decode.d5.loss_cls: 1.5660  decode.d5.loss_mask: 0.3520  decode.d5.loss_dice: 0.3886  decode.d6.loss_cls: 1.7177  decode.d6.loss_mask: 0.3394  decode.d6.loss_dice: 0.3330  decode.d7.loss_cls: 1.5811  decode.d7.loss_mask: 0.3465  decode.d7.loss_dice: 0.3433  decode.d8.loss_cls: 1.6832  decode.d8.loss_mask: 0.3378  decode.d8.loss_dice: 0.3653
07/25 16:41:27 - mmengine - INFO - Iter(train) [ 3100/80000]  base_lr: 9.6507e-05 lr: 9.6507e-06  eta: 10:27:14  time: 0.4794  data_time: 0.0093  memory: 5899  grad_norm: 150.7828  loss: 19.9423  decode.loss_cls: 1.1849  decode.loss_mask: 0.2911  decode.loss_dice: 0.3838  decode.d0.loss_cls: 2.2277  decode.d0.loss_mask: 0.3001  decode.d0.loss_dice: 0.4576  decode.d1.loss_cls: 1.3219  decode.d1.loss_mask: 0.2704  decode.d1.loss_dice: 0.3711  decode.d2.loss_cls: 1.2097  decode.d2.loss_mask: 0.2608  decode.d2.loss_dice: 0.3751  decode.d3.loss_cls: 1.1948  decode.d3.loss_mask: 0.2731  decode.d3.loss_dice: 0.3891  decode.d4.loss_cls: 1.2162  decode.d4.loss_mask: 0.2829  decode.d4.loss_dice: 0.4094  decode.d5.loss_cls: 1.2419  decode.d5.loss_mask: 0.2834  decode.d5.loss_dice: 0.3862  decode.d6.loss_cls: 1.2050  decode.d6.loss_mask: 0.2681  decode.d6.loss_dice: 0.3729  decode.d7.loss_cls: 1.2663  decode.d7.loss_mask: 0.2730  decode.d7.loss_dice: 0.3642  decode.d8.loss_cls: 1.1967  decode.d8.loss_mask: 0.2789  decode.d8.loss_dice: 0.3861
07/25 16:41:51 - mmengine - INFO - Iter(train) [ 3150/80000]  base_lr: 9.6450e-05 lr: 9.6450e-06  eta: 10:26:39  time: 0.4816  data_time: 0.0095  memory: 5979  grad_norm: 158.3546  loss: 26.0535  decode.loss_cls: 1.6044  decode.loss_mask: 0.3496  decode.loss_dice: 0.5044  decode.d0.loss_cls: 2.4610  decode.d0.loss_mask: 0.4079  decode.d0.loss_dice: 0.6043  decode.d1.loss_cls: 2.0276  decode.d1.loss_mask: 0.3211  decode.d1.loss_dice: 0.4640  decode.d2.loss_cls: 1.7213  decode.d2.loss_mask: 0.3270  decode.d2.loss_dice: 0.4400  decode.d3.loss_cls: 1.7077  decode.d3.loss_mask: 0.3230  decode.d3.loss_dice: 0.4667  decode.d4.loss_cls: 1.5969  decode.d4.loss_mask: 0.3332  decode.d4.loss_dice: 0.4683  decode.d5.loss_cls: 1.6543  decode.d5.loss_mask: 0.3379  decode.d5.loss_dice: 0.4848  decode.d6.loss_cls: 1.6299  decode.d6.loss_mask: 0.3404  decode.d6.loss_dice: 0.4915  decode.d7.loss_cls: 1.6601  decode.d7.loss_mask: 0.3314  decode.d7.loss_dice: 0.4636  decode.d8.loss_cls: 1.7253  decode.d8.loss_mask: 0.3625  decode.d8.loss_dice: 0.4435
07/25 16:42:15 - mmengine - INFO - Iter(train) [ 3200/80000]  base_lr: 9.6394e-05 lr: 9.6394e-06  eta: 10:26:02  time: 0.4791  data_time: 0.0095  memory: 5919  grad_norm: 263.6868  loss: 25.7022  decode.loss_cls: 1.5548  decode.loss_mask: 0.3967  decode.loss_dice: 0.4882  decode.d0.loss_cls: 2.3877  decode.d0.loss_mask: 0.4963  decode.d0.loss_dice: 0.6153  decode.d1.loss_cls: 1.6914  decode.d1.loss_mask: 0.3629  decode.d1.loss_dice: 0.4655  decode.d2.loss_cls: 1.6431  decode.d2.loss_mask: 0.3742  decode.d2.loss_dice: 0.4710  decode.d3.loss_cls: 1.6709  decode.d3.loss_mask: 0.3803  decode.d3.loss_dice: 0.4887  decode.d4.loss_cls: 1.5842  decode.d4.loss_mask: 0.3777  decode.d4.loss_dice: 0.4784  decode.d5.loss_cls: 1.5652  decode.d5.loss_mask: 0.3779  decode.d5.loss_dice: 0.4601  decode.d6.loss_cls: 1.5855  decode.d6.loss_mask: 0.4100  decode.d6.loss_dice: 0.4455  decode.d7.loss_cls: 1.5953  decode.d7.loss_mask: 0.3648  decode.d7.loss_dice: 0.4666  decode.d8.loss_cls: 1.6768  decode.d8.loss_mask: 0.3808  decode.d8.loss_dice: 0.4464
07/25 16:42:39 - mmengine - INFO - Iter(train) [ 3250/80000]  base_lr: 9.6337e-05 lr: 9.6337e-06  eta: 10:25:26  time: 0.4791  data_time: 0.0093  memory: 5979  grad_norm: 207.5711  loss: 25.9209  decode.loss_cls: 1.5941  decode.loss_mask: 0.3735  decode.loss_dice: 0.5233  decode.d0.loss_cls: 2.6051  decode.d0.loss_mask: 0.4036  decode.d0.loss_dice: 0.5893  decode.d1.loss_cls: 1.7410  decode.d1.loss_mask: 0.3913  decode.d1.loss_dice: 0.5014  decode.d2.loss_cls: 1.6097  decode.d2.loss_mask: 0.3684  decode.d2.loss_dice: 0.4891  decode.d3.loss_cls: 1.5861  decode.d3.loss_mask: 0.3692  decode.d3.loss_dice: 0.4878  decode.d4.loss_cls: 1.6269  decode.d4.loss_mask: 0.3484  decode.d4.loss_dice: 0.4622  decode.d5.loss_cls: 1.5315  decode.d5.loss_mask: 0.4213  decode.d5.loss_dice: 0.5020  decode.d6.loss_cls: 1.6040  decode.d6.loss_mask: 0.3702  decode.d6.loss_dice: 0.4768  decode.d7.loss_cls: 1.5311  decode.d7.loss_mask: 0.4105  decode.d7.loss_dice: 0.5235  decode.d8.loss_cls: 1.6165  decode.d8.loss_mask: 0.3792  decode.d8.loss_dice: 0.4839
07/25 16:43:03 - mmengine - INFO - Iter(train) [ 3300/80000]  base_lr: 9.6281e-05 lr: 9.6281e-06  eta: 10:24:51  time: 0.4797  data_time: 0.0096  memory: 5900  grad_norm: 218.2228  loss: 22.2514  decode.loss_cls: 1.3922  decode.loss_mask: 0.3761  decode.loss_dice: 0.5001  decode.d0.loss_cls: 2.1562  decode.d0.loss_mask: 0.4219  decode.d0.loss_dice: 0.6113  decode.d1.loss_cls: 1.3409  decode.d1.loss_mask: 0.3631  decode.d1.loss_dice: 0.4397  decode.d2.loss_cls: 1.2866  decode.d2.loss_mask: 0.3435  decode.d2.loss_dice: 0.4400  decode.d3.loss_cls: 1.1860  decode.d3.loss_mask: 0.3653  decode.d3.loss_dice: 0.4133  decode.d4.loss_cls: 1.2144  decode.d4.loss_mask: 0.3752  decode.d4.loss_dice: 0.4744  decode.d5.loss_cls: 1.2238  decode.d5.loss_mask: 0.3876  decode.d5.loss_dice: 0.4886  decode.d6.loss_cls: 1.2805  decode.d6.loss_mask: 0.3692  decode.d6.loss_dice: 0.4410  decode.d7.loss_cls: 1.3309  decode.d7.loss_mask: 0.4088  decode.d7.loss_dice: 0.4746  decode.d8.loss_cls: 1.2998  decode.d8.loss_mask: 0.3922  decode.d8.loss_dice: 0.4541
07/25 16:43:27 - mmengine - INFO - Iter(train) [ 3350/80000]  base_lr: 9.6224e-05 lr: 9.6224e-06  eta: 10:24:16  time: 0.4807  data_time: 0.0095  memory: 5979  grad_norm: 417.7105  loss: 26.6128  decode.loss_cls: 1.6690  decode.loss_mask: 0.3725  decode.loss_dice: 0.4910  decode.d0.loss_cls: 2.7070  decode.d0.loss_mask: 0.3383  decode.d0.loss_dice: 0.5740  decode.d1.loss_cls: 1.9321  decode.d1.loss_mask: 0.3373  decode.d1.loss_dice: 0.4296  decode.d2.loss_cls: 1.7693  decode.d2.loss_mask: 0.3248  decode.d2.loss_dice: 0.4331  decode.d3.loss_cls: 1.7396  decode.d3.loss_mask: 0.3231  decode.d3.loss_dice: 0.4438  decode.d4.loss_cls: 1.7297  decode.d4.loss_mask: 0.3431  decode.d4.loss_dice: 0.4261  decode.d5.loss_cls: 1.7535  decode.d5.loss_mask: 0.3218  decode.d5.loss_dice: 0.4275  decode.d6.loss_cls: 1.7274  decode.d6.loss_mask: 0.3446  decode.d6.loss_dice: 0.4306  decode.d7.loss_cls: 1.8415  decode.d7.loss_mask: 0.3682  decode.d7.loss_dice: 0.4347  decode.d8.loss_cls: 1.7400  decode.d8.loss_mask: 0.3766  decode.d8.loss_dice: 0.4631
07/25 16:43:51 - mmengine - INFO - Iter(train) [ 3400/80000]  base_lr: 9.6168e-05 lr: 9.6168e-06  eta: 10:23:41  time: 0.4790  data_time: 0.0095  memory: 5919  grad_norm: 162.7749  loss: 22.0432  decode.loss_cls: 1.2404  decode.loss_mask: 0.4380  decode.loss_dice: 0.4579  decode.d0.loss_cls: 2.1154  decode.d0.loss_mask: 0.4642  decode.d0.loss_dice: 0.5116  decode.d1.loss_cls: 1.2995  decode.d1.loss_mask: 0.4597  decode.d1.loss_dice: 0.4228  decode.d2.loss_cls: 1.1425  decode.d2.loss_mask: 0.4384  decode.d2.loss_dice: 0.4386  decode.d3.loss_cls: 1.1493  decode.d3.loss_mask: 0.4176  decode.d3.loss_dice: 0.4488  decode.d4.loss_cls: 1.2283  decode.d4.loss_mask: 0.4356  decode.d4.loss_dice: 0.4184  decode.d5.loss_cls: 1.3095  decode.d5.loss_mask: 0.4414  decode.d5.loss_dice: 0.4112  decode.d6.loss_cls: 1.2153  decode.d6.loss_mask: 0.4378  decode.d6.loss_dice: 0.4293  decode.d7.loss_cls: 1.2657  decode.d7.loss_mask: 0.4320  decode.d7.loss_dice: 0.4102  decode.d8.loss_cls: 1.2378  decode.d8.loss_mask: 0.4384  decode.d8.loss_dice: 0.4877
07/25 16:44:15 - mmengine - INFO - Iter(train) [ 3450/80000]  base_lr: 9.6111e-05 lr: 9.6111e-06  eta: 10:23:07  time: 0.4793  data_time: 0.0096  memory: 5919  grad_norm: 180.4867  loss: 20.8086  decode.loss_cls: 1.1781  decode.loss_mask: 0.3389  decode.loss_dice: 0.4047  decode.d0.loss_cls: 2.0434  decode.d0.loss_mask: 0.3513  decode.d0.loss_dice: 0.5001  decode.d1.loss_cls: 1.3914  decode.d1.loss_mask: 0.3084  decode.d1.loss_dice: 0.3728  decode.d2.loss_cls: 1.2906  decode.d2.loss_mask: 0.3264  decode.d2.loss_dice: 0.3891  decode.d3.loss_cls: 1.2463  decode.d3.loss_mask: 0.3059  decode.d3.loss_dice: 0.3467  decode.d4.loss_cls: 1.2702  decode.d4.loss_mask: 0.3178  decode.d4.loss_dice: 0.4033  decode.d5.loss_cls: 1.1469  decode.d5.loss_mask: 0.3388  decode.d5.loss_dice: 0.4134  decode.d6.loss_cls: 1.3369  decode.d6.loss_mask: 0.3321  decode.d6.loss_dice: 0.3988  decode.d7.loss_cls: 1.3122  decode.d7.loss_mask: 0.3182  decode.d7.loss_dice: 0.4361  decode.d8.loss_cls: 1.2749  decode.d8.loss_mask: 0.3200  decode.d8.loss_dice: 0.3952
07/25 16:44:29 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250725_161554
07/25 16:44:39 - mmengine - INFO - Iter(train) [ 3500/80000]  base_lr: 9.6055e-05 lr: 9.6055e-06  eta: 10:22:33  time: 0.4799  data_time: 0.0094  memory: 5919  grad_norm: 152.2319  loss: 21.0169  decode.loss_cls: 1.2663  decode.loss_mask: 0.3644  decode.loss_dice: 0.3702  decode.d0.loss_cls: 2.2269  decode.d0.loss_mask: 0.3005  decode.d0.loss_dice: 0.4080  decode.d1.loss_cls: 1.4182  decode.d1.loss_mask: 0.2730  decode.d1.loss_dice: 0.3511  decode.d2.loss_cls: 1.3404  decode.d2.loss_mask: 0.2756  decode.d2.loss_dice: 0.3512  decode.d3.loss_cls: 1.2661  decode.d3.loss_mask: 0.2914  decode.d3.loss_dice: 0.3593  decode.d4.loss_cls: 1.3034  decode.d4.loss_mask: 0.2734  decode.d4.loss_dice: 0.3720  decode.d5.loss_cls: 1.3187  decode.d5.loss_mask: 0.3193  decode.d5.loss_dice: 0.3983  decode.d6.loss_cls: 1.3389  decode.d6.loss_mask: 0.3442  decode.d6.loss_dice: 0.3955  decode.d7.loss_cls: 1.3711  decode.d7.loss_mask: 0.3526  decode.d7.loss_dice: 0.3616  decode.d8.loss_cls: 1.3247  decode.d8.loss_mask: 0.3238  decode.d8.loss_dice: 0.3568
07/25 16:45:03 - mmengine - INFO - Iter(train) [ 3550/80000]  base_lr: 9.5998e-05 lr: 9.5998e-06  eta: 10:22:02  time: 0.4812  data_time: 0.0095  memory: 5919  grad_norm: 163.0079  loss: 22.7964  decode.loss_cls: 1.3134  decode.loss_mask: 0.4548  decode.loss_dice: 0.4503  decode.d0.loss_cls: 2.1994  decode.d0.loss_mask: 0.4380  decode.d0.loss_dice: 0.5757  decode.d1.loss_cls: 1.3913  decode.d1.loss_mask: 0.3735  decode.d1.loss_dice: 0.4806  decode.d2.loss_cls: 1.2570  decode.d2.loss_mask: 0.4150  decode.d2.loss_dice: 0.4746  decode.d3.loss_cls: 1.3144  decode.d3.loss_mask: 0.4071  decode.d3.loss_dice: 0.4501  decode.d4.loss_cls: 1.2645  decode.d4.loss_mask: 0.4644  decode.d4.loss_dice: 0.4515  decode.d5.loss_cls: 1.3258  decode.d5.loss_mask: 0.4021  decode.d5.loss_dice: 0.4377  decode.d6.loss_cls: 1.2396  decode.d6.loss_mask: 0.4145  decode.d6.loss_dice: 0.4390  decode.d7.loss_cls: 1.2913  decode.d7.loss_mask: 0.4604  decode.d7.loss_dice: 0.4853  decode.d8.loss_cls: 1.2350  decode.d8.loss_mask: 0.4292  decode.d8.loss_dice: 0.4610
07/25 16:45:27 - mmengine - INFO - Iter(train) [ 3600/80000]  base_lr: 9.5942e-05 lr: 9.5942e-06  eta: 10:21:28  time: 0.4790  data_time: 0.0095  memory: 5994  grad_norm: 295.5487  loss: 20.8642  decode.loss_cls: 1.1331  decode.loss_mask: 0.3329  decode.loss_dice: 0.4105  decode.d0.loss_cls: 2.1387  decode.d0.loss_mask: 0.3598  decode.d0.loss_dice: 0.5209  decode.d1.loss_cls: 1.4117  decode.d1.loss_mask: 0.3247  decode.d1.loss_dice: 0.4434  decode.d2.loss_cls: 1.2969  decode.d2.loss_mask: 0.3208  decode.d2.loss_dice: 0.3998  decode.d3.loss_cls: 1.2447  decode.d3.loss_mask: 0.3062  decode.d3.loss_dice: 0.3933  decode.d4.loss_cls: 1.2254  decode.d4.loss_mask: 0.3388  decode.d4.loss_dice: 0.4079  decode.d5.loss_cls: 1.3013  decode.d5.loss_mask: 0.3074  decode.d5.loss_dice: 0.4037  decode.d6.loss_cls: 1.2317  decode.d6.loss_mask: 0.3178  decode.d6.loss_dice: 0.3826  decode.d7.loss_cls: 1.2152  decode.d7.loss_mask: 0.3799  decode.d7.loss_dice: 0.4017  decode.d8.loss_cls: 1.1443  decode.d8.loss_mask: 0.3680  decode.d8.loss_dice: 0.4014
07/25 16:45:51 - mmengine - INFO - Iter(train) [ 3650/80000]  base_lr: 9.5885e-05 lr: 9.5885e-06  eta: 10:20:55  time: 0.4792  data_time: 0.0093  memory: 5937  grad_norm: 168.1437  loss: 21.9965  decode.loss_cls: 1.3436  decode.loss_mask: 0.3109  decode.loss_dice: 0.4413  decode.d0.loss_cls: 2.3441  decode.d0.loss_mask: 0.3324  decode.d0.loss_dice: 0.5281  decode.d1.loss_cls: 1.6089  decode.d1.loss_mask: 0.3122  decode.d1.loss_dice: 0.4405  decode.d2.loss_cls: 1.4127  decode.d2.loss_mask: 0.2913  decode.d2.loss_dice: 0.4105  decode.d3.loss_cls: 1.3386  decode.d3.loss_mask: 0.2915  decode.d3.loss_dice: 0.4158  decode.d4.loss_cls: 1.2945  decode.d4.loss_mask: 0.3001  decode.d4.loss_dice: 0.4204  decode.d5.loss_cls: 1.2915  decode.d5.loss_mask: 0.2989  decode.d5.loss_dice: 0.4439  decode.d6.loss_cls: 1.2555  decode.d6.loss_mask: 0.3011  decode.d6.loss_dice: 0.4286  decode.d7.loss_cls: 1.2942  decode.d7.loss_mask: 0.2967  decode.d7.loss_dice: 0.4347  decode.d8.loss_cls: 1.3795  decode.d8.loss_mask: 0.3030  decode.d8.loss_dice: 0.4315
07/25 16:46:15 - mmengine - INFO - Iter(train) [ 3700/80000]  base_lr: 9.5829e-05 lr: 9.5829e-06  eta: 10:20:22  time: 0.4795  data_time: 0.0092  memory: 5919  grad_norm: 233.7291  loss: 22.6215  decode.loss_cls: 1.3586  decode.loss_mask: 0.3512  decode.loss_dice: 0.4505  decode.d0.loss_cls: 2.2083  decode.d0.loss_mask: 0.3431  decode.d0.loss_dice: 0.5340  decode.d1.loss_cls: 1.5621  decode.d1.loss_mask: 0.3690  decode.d1.loss_dice: 0.4728  decode.d2.loss_cls: 1.3342  decode.d2.loss_mask: 0.3504  decode.d2.loss_dice: 0.4346  decode.d3.loss_cls: 1.2688  decode.d3.loss_mask: 0.3711  decode.d3.loss_dice: 0.4477  decode.d4.loss_cls: 1.3195  decode.d4.loss_mask: 0.3573  decode.d4.loss_dice: 0.4511  decode.d5.loss_cls: 1.3600  decode.d5.loss_mask: 0.3755  decode.d5.loss_dice: 0.4766  decode.d6.loss_cls: 1.3377  decode.d6.loss_mask: 0.3458  decode.d6.loss_dice: 0.4303  decode.d7.loss_cls: 1.3303  decode.d7.loss_mask: 0.3539  decode.d7.loss_dice: 0.4525  decode.d8.loss_cls: 1.3494  decode.d8.loss_mask: 0.3560  decode.d8.loss_dice: 0.4692
07/25 16:46:39 - mmengine - INFO - Iter(train) [ 3750/80000]  base_lr: 9.5772e-05 lr: 9.5772e-06  eta: 10:19:50  time: 0.4790  data_time: 0.0095  memory: 5919  grad_norm: 230.6942  loss: 20.1701  decode.loss_cls: 1.0344  decode.loss_mask: 0.3995  decode.loss_dice: 0.4317  decode.d0.loss_cls: 2.0036  decode.d0.loss_mask: 0.4150  decode.d0.loss_dice: 0.5258  decode.d1.loss_cls: 1.1558  decode.d1.loss_mask: 0.4005  decode.d1.loss_dice: 0.4751  decode.d2.loss_cls: 1.0344  decode.d2.loss_mask: 0.3964  decode.d2.loss_dice: 0.4578  decode.d3.loss_cls: 1.1052  decode.d3.loss_mask: 0.3876  decode.d3.loss_dice: 0.4497  decode.d4.loss_cls: 1.1261  decode.d4.loss_mask: 0.3867  decode.d4.loss_dice: 0.4211  decode.d5.loss_cls: 1.1179  decode.d5.loss_mask: 0.3778  decode.d5.loss_dice: 0.4449  decode.d6.loss_cls: 1.0554  decode.d6.loss_mask: 0.3774  decode.d6.loss_dice: 0.4296  decode.d7.loss_cls: 1.0423  decode.d7.loss_mask: 0.3823  decode.d7.loss_dice: 0.4338  decode.d8.loss_cls: 1.0744  decode.d8.loss_mask: 0.3900  decode.d8.loss_dice: 0.4378
07/25 16:47:03 - mmengine - INFO - Iter(train) [ 3800/80000]  base_lr: 9.5716e-05 lr: 9.5716e-06  eta: 10:19:17  time: 0.4799  data_time: 0.0092  memory: 5919  grad_norm: 171.4220  loss: 22.4861  decode.loss_cls: 1.3162  decode.loss_mask: 0.3795  decode.loss_dice: 0.4324  decode.d0.loss_cls: 2.3599  decode.d0.loss_mask: 0.3955  decode.d0.loss_dice: 0.5269  decode.d1.loss_cls: 1.4473  decode.d1.loss_mask: 0.3874  decode.d1.loss_dice: 0.3878  decode.d2.loss_cls: 1.2713  decode.d2.loss_mask: 0.4365  decode.d2.loss_dice: 0.4433  decode.d3.loss_cls: 1.2511  decode.d3.loss_mask: 0.4371  decode.d3.loss_dice: 0.4327  decode.d4.loss_cls: 1.2343  decode.d4.loss_mask: 0.4362  decode.d4.loss_dice: 0.4268  decode.d5.loss_cls: 1.2063  decode.d5.loss_mask: 0.4355  decode.d5.loss_dice: 0.4164  decode.d6.loss_cls: 1.2244  decode.d6.loss_mask: 0.4534  decode.d6.loss_dice: 0.4242  decode.d7.loss_cls: 1.3507  decode.d7.loss_mask: 0.3725  decode.d7.loss_dice: 0.4021  decode.d8.loss_cls: 1.4220  decode.d8.loss_mask: 0.3628  decode.d8.loss_dice: 0.4136
07/25 16:47:27 - mmengine - INFO - Iter(train) [ 3850/80000]  base_lr: 9.5659e-05 lr: 9.5659e-06  eta: 10:18:44  time: 0.4800  data_time: 0.0095  memory: 5937  grad_norm: 224.3990  loss: 20.9146  decode.loss_cls: 1.1227  decode.loss_mask: 0.3584  decode.loss_dice: 0.4198  decode.d0.loss_cls: 2.1452  decode.d0.loss_mask: 0.3647  decode.d0.loss_dice: 0.4818  decode.d1.loss_cls: 1.2827  decode.d1.loss_mask: 0.3967  decode.d1.loss_dice: 0.4354  decode.d2.loss_cls: 1.1935  decode.d2.loss_mask: 0.3657  decode.d2.loss_dice: 0.4232  decode.d3.loss_cls: 1.2794  decode.d3.loss_mask: 0.3353  decode.d3.loss_dice: 0.3807  decode.d4.loss_cls: 1.2126  decode.d4.loss_mask: 0.3528  decode.d4.loss_dice: 0.4204  decode.d5.loss_cls: 1.1545  decode.d5.loss_mask: 0.3462  decode.d5.loss_dice: 0.4031  decode.d6.loss_cls: 1.2465  decode.d6.loss_mask: 0.4197  decode.d6.loss_dice: 0.4434  decode.d7.loss_cls: 1.2000  decode.d7.loss_mask: 0.3672  decode.d7.loss_dice: 0.4364  decode.d8.loss_cls: 1.1733  decode.d8.loss_mask: 0.3608  decode.d8.loss_dice: 0.3926
07/25 16:47:51 - mmengine - INFO - Iter(train) [ 3900/80000]  base_lr: 9.5603e-05 lr: 9.5603e-06  eta: 10:18:11  time: 0.4778  data_time: 0.0091  memory: 5900  grad_norm: 184.6547  loss: 19.3270  decode.loss_cls: 1.0379  decode.loss_mask: 0.3734  decode.loss_dice: 0.3468  decode.d0.loss_cls: 2.1319  decode.d0.loss_mask: 0.3603  decode.d0.loss_dice: 0.4198  decode.d1.loss_cls: 1.3133  decode.d1.loss_mask: 0.3240  decode.d1.loss_dice: 0.3626  decode.d2.loss_cls: 1.1372  decode.d2.loss_mask: 0.3224  decode.d2.loss_dice: 0.3607  decode.d3.loss_cls: 1.1751  decode.d3.loss_mask: 0.3327  decode.d3.loss_dice: 0.3777  decode.d4.loss_cls: 1.0753  decode.d4.loss_mask: 0.3310  decode.d4.loss_dice: 0.3678  decode.d5.loss_cls: 1.0786  decode.d5.loss_mask: 0.3318  decode.d5.loss_dice: 0.3530  decode.d6.loss_cls: 1.0635  decode.d6.loss_mask: 0.3222  decode.d6.loss_dice: 0.3429  decode.d7.loss_cls: 1.1829  decode.d7.loss_mask: 0.3371  decode.d7.loss_dice: 0.3774  decode.d8.loss_cls: 1.1193  decode.d8.loss_mask: 0.3241  decode.d8.loss_dice: 0.3445
07/25 16:48:15 - mmengine - INFO - Iter(train) [ 3950/80000]  base_lr: 9.5546e-05 lr: 9.5546e-06  eta: 10:17:39  time: 0.4787  data_time: 0.0092  memory: 5900  grad_norm: 167.1447  loss: 21.2085  decode.loss_cls: 1.2386  decode.loss_mask: 0.3363  decode.loss_dice: 0.4937  decode.d0.loss_cls: 2.1116  decode.d0.loss_mask: 0.3065  decode.d0.loss_dice: 0.5085  decode.d1.loss_cls: 1.4989  decode.d1.loss_mask: 0.2841  decode.d1.loss_dice: 0.4077  decode.d2.loss_cls: 1.3066  decode.d2.loss_mask: 0.2688  decode.d2.loss_dice: 0.3946  decode.d3.loss_cls: 1.2807  decode.d3.loss_mask: 0.2658  decode.d3.loss_dice: 0.3936  decode.d4.loss_cls: 1.2610  decode.d4.loss_mask: 0.2711  decode.d4.loss_dice: 0.4014  decode.d5.loss_cls: 1.3297  decode.d5.loss_mask: 0.2809  decode.d5.loss_dice: 0.4314  decode.d6.loss_cls: 1.3324  decode.d6.loss_mask: 0.3093  decode.d6.loss_dice: 0.4102  decode.d7.loss_cls: 1.3343  decode.d7.loss_mask: 0.3055  decode.d7.loss_dice: 0.4287  decode.d8.loss_cls: 1.2762  decode.d8.loss_mask: 0.2909  decode.d8.loss_dice: 0.4495
07/25 16:48:39 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250725_161554
07/25 16:48:39 - mmengine - INFO - Iter(train) [ 4000/80000]  base_lr: 9.5490e-05 lr: 9.5490e-06  eta: 10:17:06  time: 0.4794  data_time: 0.0092  memory: 5937  grad_norm: 212.1593  loss: 18.8915  decode.loss_cls: 1.0234  decode.loss_mask: 0.3071  decode.loss_dice: 0.3816  decode.d0.loss_cls: 2.2188  decode.d0.loss_mask: 0.3941  decode.d0.loss_dice: 0.4631  decode.d1.loss_cls: 1.1901  decode.d1.loss_mask: 0.2978  decode.d1.loss_dice: 0.3342  decode.d2.loss_cls: 1.0979  decode.d2.loss_mask: 0.2934  decode.d2.loss_dice: 0.3576  decode.d3.loss_cls: 1.0866  decode.d3.loss_mask: 0.2970  decode.d3.loss_dice: 0.3427  decode.d4.loss_cls: 1.1207  decode.d4.loss_mask: 0.3248  decode.d4.loss_dice: 0.3522  decode.d5.loss_cls: 1.0750  decode.d5.loss_mask: 0.3161  decode.d5.loss_dice: 0.3458  decode.d6.loss_cls: 1.1524  decode.d6.loss_mask: 0.2907  decode.d6.loss_dice: 0.3392  decode.d7.loss_cls: 1.1247  decode.d7.loss_mask: 0.2891  decode.d7.loss_dice: 0.3409  decode.d8.loss_cls: 1.0831  decode.d8.loss_mask: 0.2967  decode.d8.loss_dice: 0.3548
07/25 16:49:03 - mmengine - INFO - Iter(train) [ 4050/80000]  base_lr: 9.5433e-05 lr: 9.5433e-06  eta: 10:16:36  time: 0.4788  data_time: 0.0093  memory: 5900  grad_norm: 214.7681  loss: 19.8023  decode.loss_cls: 1.1373  decode.loss_mask: 0.3060  decode.loss_dice: 0.4220  decode.d0.loss_cls: 2.0622  decode.d0.loss_mask: 0.3370  decode.d0.loss_dice: 0.5327  decode.d1.loss_cls: 1.2225  decode.d1.loss_mask: 0.3176  decode.d1.loss_dice: 0.4389  decode.d2.loss_cls: 1.1524  decode.d2.loss_mask: 0.3128  decode.d2.loss_dice: 0.4173  decode.d3.loss_cls: 1.0531  decode.d3.loss_mask: 0.3183  decode.d3.loss_dice: 0.4055  decode.d4.loss_cls: 1.0916  decode.d4.loss_mask: 0.3119  decode.d4.loss_dice: 0.4360  decode.d5.loss_cls: 1.1194  decode.d5.loss_mask: 0.3035  decode.d5.loss_dice: 0.4069  decode.d6.loss_cls: 1.1727  decode.d6.loss_mask: 0.3109  decode.d6.loss_dice: 0.4295  decode.d7.loss_cls: 1.1156  decode.d7.loss_mask: 0.3141  decode.d7.loss_dice: 0.4334  decode.d8.loss_cls: 1.1900  decode.d8.loss_mask: 0.3099  decode.d8.loss_dice: 0.4213
07/25 16:49:27 - mmengine - INFO - Iter(train) [ 4100/80000]  base_lr: 9.5377e-05 lr: 9.5377e-06  eta: 10:16:04  time: 0.4783  data_time: 0.0090  memory: 5919  grad_norm: 217.3759  loss: 21.2167  decode.loss_cls: 1.1984  decode.loss_mask: 0.3026  decode.loss_dice: 0.3846  decode.d0.loss_cls: 2.3779  decode.d0.loss_mask: 0.3323  decode.d0.loss_dice: 0.5052  decode.d1.loss_cls: 1.5744  decode.d1.loss_mask: 0.3069  decode.d1.loss_dice: 0.3945  decode.d2.loss_cls: 1.2663  decode.d2.loss_mask: 0.3070  decode.d2.loss_dice: 0.4246  decode.d3.loss_cls: 1.2998  decode.d3.loss_mask: 0.3156  decode.d3.loss_dice: 0.3858  decode.d4.loss_cls: 1.2883  decode.d4.loss_mask: 0.3323  decode.d4.loss_dice: 0.4071  decode.d5.loss_cls: 1.2195  decode.d5.loss_mask: 0.3617  decode.d5.loss_dice: 0.4132  decode.d6.loss_cls: 1.2446  decode.d6.loss_mask: 0.3042  decode.d6.loss_dice: 0.3712  decode.d7.loss_cls: 1.2168  decode.d7.loss_mask: 0.3057  decode.d7.loss_dice: 0.4056  decode.d8.loss_cls: 1.2785  decode.d8.loss_mask: 0.3032  decode.d8.loss_dice: 0.3889
07/25 16:49:51 - mmengine - INFO - Iter(train) [ 4150/80000]  base_lr: 9.5320e-05 lr: 9.5320e-06  eta: 10:15:32  time: 0.4794  data_time: 0.0092  memory: 5979  grad_norm: 153.9748  loss: 14.9678  decode.loss_cls: 0.7883  decode.loss_mask: 0.2385  decode.loss_dice: 0.2733  decode.d0.loss_cls: 1.9258  decode.d0.loss_mask: 0.2445  decode.d0.loss_dice: 0.3583  decode.d1.loss_cls: 1.0167  decode.d1.loss_mask: 0.2354  decode.d1.loss_dice: 0.2874  decode.d2.loss_cls: 0.8729  decode.d2.loss_mask: 0.2410  decode.d2.loss_dice: 0.2911  decode.d3.loss_cls: 0.8742  decode.d3.loss_mask: 0.2474  decode.d3.loss_dice: 0.2883  decode.d4.loss_cls: 0.8253  decode.d4.loss_mask: 0.2322  decode.d4.loss_dice: 0.2855  decode.d5.loss_cls: 0.7990  decode.d5.loss_mask: 0.2466  decode.d5.loss_dice: 0.2775  decode.d6.loss_cls: 0.8617  decode.d6.loss_mask: 0.2425  decode.d6.loss_dice: 0.2764  decode.d7.loss_cls: 0.8281  decode.d7.loss_mask: 0.2344  decode.d7.loss_dice: 0.2710  decode.d8.loss_cls: 0.9005  decode.d8.loss_mask: 0.2334  decode.d8.loss_dice: 0.2706
07/25 16:50:15 - mmengine - INFO - Iter(train) [ 4200/80000]  base_lr: 9.5263e-05 lr: 9.5263e-06  eta: 10:15:02  time: 0.4787  data_time: 0.0092  memory: 5900  grad_norm: 207.9927  loss: 19.3032  decode.loss_cls: 1.0634  decode.loss_mask: 0.3019  decode.loss_dice: 0.3635  decode.d0.loss_cls: 2.1601  decode.d0.loss_mask: 0.3438  decode.d0.loss_dice: 0.4893  decode.d1.loss_cls: 1.2821  decode.d1.loss_mask: 0.3108  decode.d1.loss_dice: 0.3536  decode.d2.loss_cls: 1.1168  decode.d2.loss_mask: 0.3078  decode.d2.loss_dice: 0.3703  decode.d3.loss_cls: 1.0988  decode.d3.loss_mask: 0.3127  decode.d3.loss_dice: 0.3537  decode.d4.loss_cls: 1.0809  decode.d4.loss_mask: 0.3172  decode.d4.loss_dice: 0.3801  decode.d5.loss_cls: 1.1073  decode.d5.loss_mask: 0.3415  decode.d5.loss_dice: 0.3765  decode.d6.loss_cls: 1.1187  decode.d6.loss_mask: 0.3348  decode.d6.loss_dice: 0.3862  decode.d7.loss_cls: 1.1344  decode.d7.loss_mask: 0.3244  decode.d7.loss_dice: 0.3844  decode.d8.loss_cls: 1.1067  decode.d8.loss_mask: 0.3132  decode.d8.loss_dice: 0.3683
07/25 16:50:39 - mmengine - INFO - Iter(train) [ 4250/80000]  base_lr: 9.5207e-05 lr: 9.5207e-06  eta: 10:14:31  time: 0.4793  data_time: 0.0094  memory: 5919  grad_norm: 239.6562  loss: 21.5932  decode.loss_cls: 1.0977  decode.loss_mask: 0.4091  decode.loss_dice: 0.4951  decode.d0.loss_cls: 2.0442  decode.d0.loss_mask: 0.4299  decode.d0.loss_dice: 0.5784  decode.d1.loss_cls: 1.2884  decode.d1.loss_mask: 0.4013  decode.d1.loss_dice: 0.5002  decode.d2.loss_cls: 1.2075  decode.d2.loss_mask: 0.3969  decode.d2.loss_dice: 0.4826  decode.d3.loss_cls: 1.1913  decode.d3.loss_mask: 0.4262  decode.d3.loss_dice: 0.4635  decode.d4.loss_cls: 1.1283  decode.d4.loss_mask: 0.4442  decode.d4.loss_dice: 0.5306  decode.d5.loss_cls: 1.1263  decode.d5.loss_mask: 0.3989  decode.d5.loss_dice: 0.4766  decode.d6.loss_cls: 1.1804  decode.d6.loss_mask: 0.4009  decode.d6.loss_dice: 0.4603  decode.d7.loss_cls: 1.2121  decode.d7.loss_mask: 0.4225  decode.d7.loss_dice: 0.4591  decode.d8.loss_cls: 1.0656  decode.d8.loss_mask: 0.4154  decode.d8.loss_dice: 0.4595
07/25 16:51:03 - mmengine - INFO - Iter(train) [ 4300/80000]  base_lr: 9.5150e-05 lr: 9.5150e-06  eta: 10:14:01  time: 0.4805  data_time: 0.0093  memory: 5900  grad_norm: 204.5740  loss: 20.5661  decode.loss_cls: 1.1104  decode.loss_mask: 0.3237  decode.loss_dice: 0.4426  decode.d0.loss_cls: 2.1854  decode.d0.loss_mask: 0.3206  decode.d0.loss_dice: 0.5362  decode.d1.loss_cls: 1.3527  decode.d1.loss_mask: 0.3004  decode.d1.loss_dice: 0.4660  decode.d2.loss_cls: 1.1802  decode.d2.loss_mask: 0.2862  decode.d2.loss_dice: 0.4204  decode.d3.loss_cls: 1.0938  decode.d3.loss_mask: 0.2906  decode.d3.loss_dice: 0.4529  decode.d4.loss_cls: 1.1311  decode.d4.loss_mask: 0.3169  decode.d4.loss_dice: 0.4897  decode.d5.loss_cls: 1.1413  decode.d5.loss_mask: 0.3288  decode.d5.loss_dice: 0.4980  decode.d6.loss_cls: 1.1751  decode.d6.loss_mask: 0.3310  decode.d6.loss_dice: 0.5025  decode.d7.loss_cls: 1.2057  decode.d7.loss_mask: 0.2972  decode.d7.loss_dice: 0.4838  decode.d8.loss_cls: 1.1882  decode.d8.loss_mask: 0.2828  decode.d8.loss_dice: 0.4317
07/25 16:51:27 - mmengine - INFO - Iter(train) [ 4350/80000]  base_lr: 9.5094e-05 lr: 9.5094e-06  eta: 10:13:34  time: 0.4791  data_time: 0.0094  memory: 5900  grad_norm: 296.0393  loss: 21.7705  decode.loss_cls: 1.1613  decode.loss_mask: 0.4061  decode.loss_dice: 0.4399  decode.d0.loss_cls: 1.9628  decode.d0.loss_mask: 0.5867  decode.d0.loss_dice: 0.6533  decode.d1.loss_cls: 1.2588  decode.d1.loss_mask: 0.4222  decode.d1.loss_dice: 0.4851  decode.d2.loss_cls: 1.2028  decode.d2.loss_mask: 0.4134  decode.d2.loss_dice: 0.4672  decode.d3.loss_cls: 1.1718  decode.d3.loss_mask: 0.4230  decode.d3.loss_dice: 0.4882  decode.d4.loss_cls: 1.1425  decode.d4.loss_mask: 0.4306  decode.d4.loss_dice: 0.4796  decode.d5.loss_cls: 1.1800  decode.d5.loss_mask: 0.4206  decode.d5.loss_dice: 0.4797  decode.d6.loss_cls: 1.1761  decode.d6.loss_mask: 0.4188  decode.d6.loss_dice: 0.4800  decode.d7.loss_cls: 1.1036  decode.d7.loss_mask: 0.4051  decode.d7.loss_dice: 0.4844  decode.d8.loss_cls: 1.1066  decode.d8.loss_mask: 0.4215  decode.d8.loss_dice: 0.4989
07/25 16:51:51 - mmengine - INFO - Iter(train) [ 4400/80000]  base_lr: 9.5037e-05 lr: 9.5037e-06  eta: 10:13:03  time: 0.4794  data_time: 0.0096  memory: 5919  grad_norm: 204.4531  loss: 20.6622  decode.loss_cls: 1.0918  decode.loss_mask: 0.4364  decode.loss_dice: 0.4946  decode.d0.loss_cls: 2.0176  decode.d0.loss_mask: 0.4067  decode.d0.loss_dice: 0.5403  decode.d1.loss_cls: 1.1904  decode.d1.loss_mask: 0.3841  decode.d1.loss_dice: 0.4514  decode.d2.loss_cls: 1.1193  decode.d2.loss_mask: 0.3609  decode.d2.loss_dice: 0.4391  decode.d3.loss_cls: 1.0849  decode.d3.loss_mask: 0.3836  decode.d3.loss_dice: 0.4490  decode.d4.loss_cls: 1.0561  decode.d4.loss_mask: 0.3754  decode.d4.loss_dice: 0.4561  decode.d5.loss_cls: 1.1439  decode.d5.loss_mask: 0.4023  decode.d5.loss_dice: 0.5068  decode.d6.loss_cls: 1.0701  decode.d6.loss_mask: 0.3881  decode.d6.loss_dice: 0.4609  decode.d7.loss_cls: 1.0674  decode.d7.loss_mask: 0.3819  decode.d7.loss_dice: 0.4594  decode.d8.loss_cls: 1.1424  decode.d8.loss_mask: 0.4044  decode.d8.loss_dice: 0.4968
07/25 16:52:15 - mmengine - INFO - Iter(train) [ 4450/80000]  base_lr: 9.4981e-05 lr: 9.4981e-06  eta: 10:12:32  time: 0.4787  data_time: 0.0092  memory: 5900  grad_norm: 214.7457  loss: 19.0129  decode.loss_cls: 1.0669  decode.loss_mask: 0.2983  decode.loss_dice: 0.4642  decode.d0.loss_cls: 1.9269  decode.d0.loss_mask: 0.3259  decode.d0.loss_dice: 0.5629  decode.d1.loss_cls: 1.1907  decode.d1.loss_mask: 0.3071  decode.d1.loss_dice: 0.4530  decode.d2.loss_cls: 1.0224  decode.d2.loss_mask: 0.2982  decode.d2.loss_dice: 0.4251  decode.d3.loss_cls: 0.9890  decode.d3.loss_mask: 0.2945  decode.d3.loss_dice: 0.4088  decode.d4.loss_cls: 1.0668  decode.d4.loss_mask: 0.2921  decode.d4.loss_dice: 0.4342  decode.d5.loss_cls: 1.0408  decode.d5.loss_mask: 0.2966  decode.d5.loss_dice: 0.4067  decode.d6.loss_cls: 1.0870  decode.d6.loss_mask: 0.3006  decode.d6.loss_dice: 0.4179  decode.d7.loss_cls: 1.0827  decode.d7.loss_mask: 0.3020  decode.d7.loss_dice: 0.4267  decode.d8.loss_cls: 1.0853  decode.d8.loss_mask: 0.3017  decode.d8.loss_dice: 0.4381
07/25 16:52:39 - mmengine - INFO - Iter(train) [ 4500/80000]  base_lr: 9.4924e-05 lr: 9.4924e-06  eta: 10:12:02  time: 0.4797  data_time: 0.0091  memory: 6005  grad_norm: 147.8718  loss: 19.4753  decode.loss_cls: 1.1102  decode.loss_mask: 0.2727  decode.loss_dice: 0.3626  decode.d0.loss_cls: 1.9961  decode.d0.loss_mask: 0.2890  decode.d0.loss_dice: 0.4733  decode.d1.loss_cls: 1.3490  decode.d1.loss_mask: 0.2696  decode.d1.loss_dice: 0.4290  decode.d2.loss_cls: 1.2691  decode.d2.loss_mask: 0.2678  decode.d2.loss_dice: 0.4282  decode.d3.loss_cls: 1.1386  decode.d3.loss_mask: 0.2624  decode.d3.loss_dice: 0.3934  decode.d4.loss_cls: 1.1894  decode.d4.loss_mask: 0.2597  decode.d4.loss_dice: 0.4007  decode.d5.loss_cls: 1.1795  decode.d5.loss_mask: 0.2603  decode.d5.loss_dice: 0.3756  decode.d6.loss_cls: 1.1561  decode.d6.loss_mask: 0.2810  decode.d6.loss_dice: 0.4074  decode.d7.loss_cls: 1.1784  decode.d7.loss_mask: 0.2642  decode.d7.loss_dice: 0.3868  decode.d8.loss_cls: 1.1756  decode.d8.loss_mask: 0.2617  decode.d8.loss_dice: 0.3878
07/25 16:53:03 - mmengine - INFO - Iter(train) [ 4550/80000]  base_lr: 9.4867e-05 lr: 9.4867e-06  eta: 10:11:32  time: 0.4803  data_time: 0.0092  memory: 5937  grad_norm: 171.1271  loss: 16.2910  decode.loss_cls: 0.6751  decode.loss_mask: 0.3943  decode.loss_dice: 0.3711  decode.d0.loss_cls: 1.9113  decode.d0.loss_mask: 0.4095  decode.d0.loss_dice: 0.4944  decode.d1.loss_cls: 0.9288  decode.d1.loss_mask: 0.3865  decode.d1.loss_dice: 0.3612  decode.d2.loss_cls: 0.7286  decode.d2.loss_mask: 0.3806  decode.d2.loss_dice: 0.3367  decode.d3.loss_cls: 0.7219  decode.d3.loss_mask: 0.3773  decode.d3.loss_dice: 0.3304  decode.d4.loss_cls: 0.7445  decode.d4.loss_mask: 0.3903  decode.d4.loss_dice: 0.3558  decode.d5.loss_cls: 0.7753  decode.d5.loss_mask: 0.3932  decode.d5.loss_dice: 0.3742  decode.d6.loss_cls: 0.7823  decode.d6.loss_mask: 0.3899  decode.d6.loss_dice: 0.3618  decode.d7.loss_cls: 0.7666  decode.d7.loss_mask: 0.3943  decode.d7.loss_dice: 0.3513  decode.d8.loss_cls: 0.6785  decode.d8.loss_mask: 0.3902  decode.d8.loss_dice: 0.3350
07/25 16:53:27 - mmengine - INFO - Iter(train) [ 4600/80000]  base_lr: 9.4811e-05 lr: 9.4811e-06  eta: 10:11:01  time: 0.4780  data_time: 0.0092  memory: 5937  grad_norm: 159.3034  loss: 14.3156  decode.loss_cls: 0.6772  decode.loss_mask: 0.2919  decode.loss_dice: 0.3289  decode.d0.loss_cls: 1.6853  decode.d0.loss_mask: 0.3031  decode.d0.loss_dice: 0.3948  decode.d1.loss_cls: 0.7755  decode.d1.loss_mask: 0.3066  decode.d1.loss_dice: 0.3408  decode.d2.loss_cls: 0.6691  decode.d2.loss_mask: 0.3012  decode.d2.loss_dice: 0.3473  decode.d3.loss_cls: 0.6439  decode.d3.loss_mask: 0.2923  decode.d3.loss_dice: 0.3359  decode.d4.loss_cls: 0.6612  decode.d4.loss_mask: 0.2900  decode.d4.loss_dice: 0.3255  decode.d5.loss_cls: 0.6994  decode.d5.loss_mask: 0.2845  decode.d5.loss_dice: 0.3119  decode.d6.loss_cls: 0.7390  decode.d6.loss_mask: 0.2867  decode.d6.loss_dice: 0.3296  decode.d7.loss_cls: 0.6258  decode.d7.loss_mask: 0.2947  decode.d7.loss_dice: 0.3382  decode.d8.loss_cls: 0.7909  decode.d8.loss_mask: 0.2926  decode.d8.loss_dice: 0.3518
07/25 16:53:51 - mmengine - INFO - Iter(train) [ 4650/80000]  base_lr: 9.4754e-05 lr: 9.4754e-06  eta: 10:10:31  time: 0.4789  data_time: 0.0093  memory: 5919  grad_norm: 251.5782  loss: 16.7821  decode.loss_cls: 0.8904  decode.loss_mask: 0.2719  decode.loss_dice: 0.3698  decode.d0.loss_cls: 1.8518  decode.d0.loss_mask: 0.2656  decode.d0.loss_dice: 0.3894  decode.d1.loss_cls: 1.0868  decode.d1.loss_mask: 0.2634  decode.d1.loss_dice: 0.3282  decode.d2.loss_cls: 1.0233  decode.d2.loss_mask: 0.2787  decode.d2.loss_dice: 0.3293  decode.d3.loss_cls: 0.9079  decode.d3.loss_mask: 0.2677  decode.d3.loss_dice: 0.3282  decode.d4.loss_cls: 0.9838  decode.d4.loss_mask: 0.2663  decode.d4.loss_dice: 0.3406  decode.d5.loss_cls: 0.8694  decode.d5.loss_mask: 0.2899  decode.d5.loss_dice: 0.3832  decode.d6.loss_cls: 0.9593  decode.d6.loss_mask: 0.2720  decode.d6.loss_dice: 0.3701  decode.d7.loss_cls: 0.8704  decode.d7.loss_mask: 0.2727  decode.d7.loss_dice: 0.4107  decode.d8.loss_cls: 0.9909  decode.d8.loss_mask: 0.2766  decode.d8.loss_dice: 0.3739
07/25 16:54:14 - mmengine - INFO - Iter(train) [ 4700/80000]  base_lr: 9.4698e-05 lr: 9.4698e-06  eta: 10:10:01  time: 0.4789  data_time: 0.0092  memory: 5920  grad_norm: 203.3929  loss: 19.0593  decode.loss_cls: 0.9573  decode.loss_mask: 0.3750  decode.loss_dice: 0.4285  decode.d0.loss_cls: 1.8213  decode.d0.loss_mask: 0.4364  decode.d0.loss_dice: 0.4649  decode.d1.loss_cls: 1.1530  decode.d1.loss_mask: 0.4230  decode.d1.loss_dice: 0.4174  decode.d2.loss_cls: 1.0484  decode.d2.loss_mask: 0.4166  decode.d2.loss_dice: 0.4103  decode.d3.loss_cls: 0.9662  decode.d3.loss_mask: 0.4086  decode.d3.loss_dice: 0.3991  decode.d4.loss_cls: 0.9390  decode.d4.loss_mask: 0.4069  decode.d4.loss_dice: 0.4133  decode.d5.loss_cls: 0.9873  decode.d5.loss_mask: 0.3931  decode.d5.loss_dice: 0.4325  decode.d6.loss_cls: 0.9941  decode.d6.loss_mask: 0.3919  decode.d6.loss_dice: 0.4013  decode.d7.loss_cls: 1.0215  decode.d7.loss_mask: 0.3787  decode.d7.loss_dice: 0.4125  decode.d8.loss_cls: 0.9481  decode.d8.loss_mask: 0.3876  decode.d8.loss_dice: 0.4255
07/25 16:54:38 - mmengine - INFO - Iter(train) [ 4750/80000]  base_lr: 9.4641e-05 lr: 9.4641e-06  eta: 10:09:31  time: 0.4778  data_time: 0.0090  memory: 5937  grad_norm: 244.0080  loss: 20.4115  decode.loss_cls: 0.9254  decode.loss_mask: 0.4326  decode.loss_dice: 0.5185  decode.d0.loss_cls: 2.0651  decode.d0.loss_mask: 0.3832  decode.d0.loss_dice: 0.5863  decode.d1.loss_cls: 1.1321  decode.d1.loss_mask: 0.4296  decode.d1.loss_dice: 0.4913  decode.d2.loss_cls: 1.1032  decode.d2.loss_mask: 0.4135  decode.d2.loss_dice: 0.5098  decode.d3.loss_cls: 0.9596  decode.d3.loss_mask: 0.3905  decode.d3.loss_dice: 0.5174  decode.d4.loss_cls: 0.9700  decode.d4.loss_mask: 0.4627  decode.d4.loss_dice: 0.5302  decode.d5.loss_cls: 0.9858  decode.d5.loss_mask: 0.4163  decode.d5.loss_dice: 0.4966  decode.d6.loss_cls: 1.0594  decode.d6.loss_mask: 0.3812  decode.d6.loss_dice: 0.4852  decode.d7.loss_cls: 1.0140  decode.d7.loss_mask: 0.3806  decode.d7.loss_dice: 0.5023  decode.d8.loss_cls: 0.9702  decode.d8.loss_mask: 0.4107  decode.d8.loss_dice: 0.4881
07/25 16:55:02 - mmengine - INFO - Iter(train) [ 4800/80000]  base_lr: 9.4584e-05 lr: 9.4584e-06  eta: 10:09:01  time: 0.4786  data_time: 0.0093  memory: 5885  grad_norm: 195.0893  loss: 17.7647  decode.loss_cls: 0.9416  decode.loss_mask: 0.3540  decode.loss_dice: 0.3549  decode.d0.loss_cls: 1.9849  decode.d0.loss_mask: 0.3664  decode.d0.loss_dice: 0.4592  decode.d1.loss_cls: 1.0848  decode.d1.loss_mask: 0.3465  decode.d1.loss_dice: 0.3640  decode.d2.loss_cls: 0.9400  decode.d2.loss_mask: 0.3438  decode.d2.loss_dice: 0.3445  decode.d3.loss_cls: 0.9120  decode.d3.loss_mask: 0.3426  decode.d3.loss_dice: 0.3498  decode.d4.loss_cls: 0.9674  decode.d4.loss_mask: 0.3471  decode.d4.loss_dice: 0.3697  decode.d5.loss_cls: 0.9252  decode.d5.loss_mask: 0.3443  decode.d5.loss_dice: 0.3440  decode.d6.loss_cls: 0.9777  decode.d6.loss_mask: 0.3365  decode.d6.loss_dice: 0.3696  decode.d7.loss_cls: 0.9095  decode.d7.loss_mask: 0.3643  decode.d7.loss_dice: 0.3688  decode.d8.loss_cls: 0.9566  decode.d8.loss_mask: 0.3470  decode.d8.loss_dice: 0.3482
07/25 16:55:26 - mmengine - INFO - Iter(train) [ 4850/80000]  base_lr: 9.4528e-05 lr: 9.4528e-06  eta: 10:08:31  time: 0.4801  data_time: 0.0093  memory: 5919  grad_norm: 274.3996  loss: 19.2045  decode.loss_cls: 1.0277  decode.loss_mask: 0.4014  decode.loss_dice: 0.3761  decode.d0.loss_cls: 2.1525  decode.d0.loss_mask: 0.3733  decode.d0.loss_dice: 0.4302  decode.d1.loss_cls: 1.1677  decode.d1.loss_mask: 0.4166  decode.d1.loss_dice: 0.3894  decode.d2.loss_cls: 1.0394  decode.d2.loss_mask: 0.3784  decode.d2.loss_dice: 0.3617  decode.d3.loss_cls: 0.9690  decode.d3.loss_mask: 0.3775  decode.d3.loss_dice: 0.3602  decode.d4.loss_cls: 0.9712  decode.d4.loss_mask: 0.4015  decode.d4.loss_dice: 0.3735  decode.d5.loss_cls: 1.0360  decode.d5.loss_mask: 0.3889  decode.d5.loss_dice: 0.3572  decode.d6.loss_cls: 1.0542  decode.d6.loss_mask: 0.3949  decode.d6.loss_dice: 0.3396  decode.d7.loss_cls: 1.1579  decode.d7.loss_mask: 0.4167  decode.d7.loss_dice: 0.3657  decode.d8.loss_cls: 0.9515  decode.d8.loss_mask: 0.4170  decode.d8.loss_dice: 0.3579
07/25 16:55:50 - mmengine - INFO - Iter(train) [ 4900/80000]  base_lr: 9.4471e-05 lr: 9.4471e-06  eta: 10:08:03  time: 0.4795  data_time: 0.0091  memory: 5937  grad_norm: 257.7148  loss: 16.1052  decode.loss_cls: 0.7384  decode.loss_mask: 0.3739  decode.loss_dice: 0.3318  decode.d0.loss_cls: 1.8608  decode.d0.loss_mask: 0.3330  decode.d0.loss_dice: 0.4433  decode.d1.loss_cls: 0.9541  decode.d1.loss_mask: 0.3502  decode.d1.loss_dice: 0.3311  decode.d2.loss_cls: 0.8284  decode.d2.loss_mask: 0.3662  decode.d2.loss_dice: 0.3297  decode.d3.loss_cls: 0.8160  decode.d3.loss_mask: 0.3193  decode.d3.loss_dice: 0.3334  decode.d4.loss_cls: 0.8825  decode.d4.loss_mask: 0.2835  decode.d4.loss_dice: 0.3281  decode.d5.loss_cls: 0.8591  decode.d5.loss_mask: 0.2527  decode.d5.loss_dice: 0.3094  decode.d6.loss_cls: 0.8324  decode.d6.loss_mask: 0.4027  decode.d6.loss_dice: 0.3349  decode.d7.loss_cls: 0.7392  decode.d7.loss_mask: 0.4046  decode.d7.loss_dice: 0.3337  decode.d8.loss_cls: 0.7114  decode.d8.loss_mask: 0.3900  decode.d8.loss_dice: 0.3316
07/25 16:56:15 - mmengine - INFO - Iter(train) [ 4950/80000]  base_lr: 9.4415e-05 lr: 9.4415e-06  eta: 10:07:37  time: 0.4784  data_time: 0.0093  memory: 5919  grad_norm: 317.9317  loss: 17.0073  decode.loss_cls: 0.7779  decode.loss_mask: 0.4312  decode.loss_dice: 0.3968  decode.d0.loss_cls: 1.6814  decode.d0.loss_mask: 0.3888  decode.d0.loss_dice: 0.4442  decode.d1.loss_cls: 0.9819  decode.d1.loss_mask: 0.3965  decode.d1.loss_dice: 0.3497  decode.d2.loss_cls: 0.8263  decode.d2.loss_mask: 0.4050  decode.d2.loss_dice: 0.3628  decode.d3.loss_cls: 0.8302  decode.d3.loss_mask: 0.4212  decode.d3.loss_dice: 0.3751  decode.d4.loss_cls: 0.8408  decode.d4.loss_mask: 0.4358  decode.d4.loss_dice: 0.3700  decode.d5.loss_cls: 0.7447  decode.d5.loss_mask: 0.4416  decode.d5.loss_dice: 0.3798  decode.d6.loss_cls: 0.7618  decode.d6.loss_mask: 0.4340  decode.d6.loss_dice: 0.3874  decode.d7.loss_cls: 0.7614  decode.d7.loss_mask: 0.4369  decode.d7.loss_dice: 0.4180  decode.d8.loss_cls: 0.6858  decode.d8.loss_mask: 0.4333  decode.d8.loss_dice: 0.4069
07/25 16:56:38 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250725_161554
07/25 16:56:38 - mmengine - INFO - Iter(train) [ 5000/80000]  base_lr: 9.4358e-05 lr: 9.4358e-06  eta: 10:07:07  time: 0.4791  data_time: 0.0094  memory: 5900  grad_norm: 311.6389  loss: 17.5418  decode.loss_cls: 0.8435  decode.loss_mask: 0.3412  decode.loss_dice: 0.3662  decode.d0.loss_cls: 2.0868  decode.d0.loss_mask: 0.3852  decode.d0.loss_dice: 0.4798  decode.d1.loss_cls: 1.1142  decode.d1.loss_mask: 0.3304  decode.d1.loss_dice: 0.3719  decode.d2.loss_cls: 0.8566  decode.d2.loss_mask: 0.3431  decode.d2.loss_dice: 0.3949  decode.d3.loss_cls: 0.8475  decode.d3.loss_mask: 0.3830  decode.d3.loss_dice: 0.4052  decode.d4.loss_cls: 0.8537  decode.d4.loss_mask: 0.3591  decode.d4.loss_dice: 0.3868  decode.d5.loss_cls: 0.8161  decode.d5.loss_mask: 0.3575  decode.d5.loss_dice: 0.3960  decode.d6.loss_cls: 0.9019  decode.d6.loss_mask: 0.3755  decode.d6.loss_dice: 0.4041  decode.d7.loss_cls: 0.9322  decode.d7.loss_mask: 0.3234  decode.d7.loss_dice: 0.3688  decode.d8.loss_cls: 0.8361  decode.d8.loss_mask: 0.3229  decode.d8.loss_dice: 0.3578
07/25 16:56:38 - mmengine - INFO - Saving checkpoint at 5000 iterations
07/25 16:57:05 - mmengine - INFO - Iter(train) [ 5050/80000]  base_lr: 9.4301e-05 lr: 9.4301e-06  eta: 10:07:09  time: 0.4803  data_time: 0.0092  memory: 5920  grad_norm: 176.2715  loss: 17.4649  decode.loss_cls: 0.8213  decode.loss_mask: 0.3237  decode.loss_dice: 0.3885  decode.d0.loss_cls: 1.9768  decode.d0.loss_mask: 0.3388  decode.d0.loss_dice: 0.5064  decode.d1.loss_cls: 1.0764  decode.d1.loss_mask: 0.3249  decode.d1.loss_dice: 0.3928  decode.d2.loss_cls: 0.9479  decode.d2.loss_mask: 0.3429  decode.d2.loss_dice: 0.4035  decode.d3.loss_cls: 0.8760  decode.d3.loss_mask: 0.3319  decode.d3.loss_dice: 0.4106  decode.d4.loss_cls: 0.9190  decode.d4.loss_mask: 0.3134  decode.d4.loss_dice: 0.3902  decode.d5.loss_cls: 0.9462  decode.d5.loss_mask: 0.3172  decode.d5.loss_dice: 0.4064  decode.d6.loss_cls: 0.8364  decode.d6.loss_mask: 0.3281  decode.d6.loss_dice: 0.3880  decode.d7.loss_cls: 0.8729  decode.d7.loss_mask: 0.3210  decode.d7.loss_dice: 0.3876  decode.d8.loss_cls: 0.8499  decode.d8.loss_mask: 0.3320  decode.d8.loss_dice: 0.3942
07/25 16:57:28 - mmengine - INFO - Iter(train) [ 5100/80000]  base_lr: 9.4245e-05 lr: 9.4245e-06  eta: 10:06:39  time: 0.4775  data_time: 0.0094  memory: 5901  grad_norm: 354.8349  loss: 19.4142  decode.loss_cls: 0.9281  decode.loss_mask: 0.4150  decode.loss_dice: 0.4710  decode.d0.loss_cls: 1.8152  decode.d0.loss_mask: 0.4812  decode.d0.loss_dice: 0.5995  decode.d1.loss_cls: 0.9491  decode.d1.loss_mask: 0.4980  decode.d1.loss_dice: 0.5403  decode.d2.loss_cls: 0.8810  decode.d2.loss_mask: 0.4254  decode.d2.loss_dice: 0.4759  decode.d3.loss_cls: 0.7788  decode.d3.loss_mask: 0.4662  decode.d3.loss_dice: 0.4915  decode.d4.loss_cls: 0.9995  decode.d4.loss_mask: 0.4198  decode.d4.loss_dice: 0.4796  decode.d5.loss_cls: 0.9877  decode.d5.loss_mask: 0.4001  decode.d5.loss_dice: 0.4840  decode.d6.loss_cls: 0.8598  decode.d6.loss_mask: 0.4486  decode.d6.loss_dice: 0.4877  decode.d7.loss_cls: 0.8263  decode.d7.loss_mask: 0.4399  decode.d7.loss_dice: 0.5143  decode.d8.loss_cls: 0.9304  decode.d8.loss_mask: 0.4367  decode.d8.loss_dice: 0.4839
07/25 16:57:52 - mmengine - INFO - Iter(train) [ 5150/80000]  base_lr: 9.4188e-05 lr: 9.4188e-06  eta: 10:06:09  time: 0.4774  data_time: 0.0091  memory: 5920  grad_norm: 216.4361  loss: 16.4748  decode.loss_cls: 0.7913  decode.loss_mask: 0.2827  decode.loss_dice: 0.3696  decode.d0.loss_cls: 1.8074  decode.d0.loss_mask: 0.2939  decode.d0.loss_dice: 0.4466  decode.d1.loss_cls: 0.9930  decode.d1.loss_mask: 0.2797  decode.d1.loss_dice: 0.3693  decode.d2.loss_cls: 0.9476  decode.d2.loss_mask: 0.2809  decode.d2.loss_dice: 0.4033  decode.d3.loss_cls: 0.8806  decode.d3.loss_mask: 0.2920  decode.d3.loss_dice: 0.4034  decode.d4.loss_cls: 0.7947  decode.d4.loss_mask: 0.3095  decode.d4.loss_dice: 0.4036  decode.d5.loss_cls: 0.8839  decode.d5.loss_mask: 0.3341  decode.d5.loss_dice: 0.3804  decode.d6.loss_cls: 0.8482  decode.d6.loss_mask: 0.3232  decode.d6.loss_dice: 0.3869  decode.d7.loss_cls: 0.7727  decode.d7.loss_mask: 0.3201  decode.d7.loss_dice: 0.3825  decode.d8.loss_cls: 0.7895  decode.d8.loss_mask: 0.3181  decode.d8.loss_dice: 0.3863
07/25 16:58:16 - mmengine - INFO - Iter(train) [ 5200/80000]  base_lr: 9.4132e-05 lr: 9.4132e-06  eta: 10:05:40  time: 0.4782  data_time: 0.0095  memory: 5919  grad_norm: 151.8609  loss: 12.8637  decode.loss_cls: 0.5620  decode.loss_mask: 0.2287  decode.loss_dice: 0.3224  decode.d0.loss_cls: 1.6600  decode.d0.loss_mask: 0.2369  decode.d0.loss_dice: 0.3890  decode.d1.loss_cls: 0.7540  decode.d1.loss_mask: 0.2342  decode.d1.loss_dice: 0.3463  decode.d2.loss_cls: 0.6760  decode.d2.loss_mask: 0.2474  decode.d2.loss_dice: 0.3700  decode.d3.loss_cls: 0.5423  decode.d3.loss_mask: 0.2395  decode.d3.loss_dice: 0.3328  decode.d4.loss_cls: 0.4991  decode.d4.loss_mask: 0.2472  decode.d4.loss_dice: 0.3688  decode.d5.loss_cls: 0.5921  decode.d5.loss_mask: 0.2425  decode.d5.loss_dice: 0.3493  decode.d6.loss_cls: 0.5456  decode.d6.loss_mask: 0.2461  decode.d6.loss_dice: 0.3611  decode.d7.loss_cls: 0.5113  decode.d7.loss_mask: 0.2469  decode.d7.loss_dice: 0.3780  decode.d8.loss_cls: 0.5529  decode.d8.loss_mask: 0.2378  decode.d8.loss_dice: 0.3434
07/25 16:58:40 - mmengine - INFO - Iter(train) [ 5250/80000]  base_lr: 9.4075e-05 lr: 9.4075e-06  eta: 10:05:10  time: 0.4781  data_time: 0.0093  memory: 5937  grad_norm: 665.4044  loss: 17.9781  decode.loss_cls: 0.7248  decode.loss_mask: 0.4261  decode.loss_dice: 0.5146  decode.d0.loss_cls: 1.8059  decode.d0.loss_mask: 0.4044  decode.d0.loss_dice: 0.5319  decode.d1.loss_cls: 0.8592  decode.d1.loss_mask: 0.4113  decode.d1.loss_dice: 0.5311  decode.d2.loss_cls: 0.7471  decode.d2.loss_mask: 0.3927  decode.d2.loss_dice: 0.5175  decode.d3.loss_cls: 0.7946  decode.d3.loss_mask: 0.3961  decode.d3.loss_dice: 0.4939  decode.d4.loss_cls: 0.7458  decode.d4.loss_mask: 0.4065  decode.d4.loss_dice: 0.5061  decode.d5.loss_cls: 0.8055  decode.d5.loss_mask: 0.4002  decode.d5.loss_dice: 0.5430  decode.d6.loss_cls: 0.7647  decode.d6.loss_mask: 0.4167  decode.d6.loss_dice: 0.5051  decode.d7.loss_cls: 0.7865  decode.d7.loss_mask: 0.4128  decode.d7.loss_dice: 0.4757  decode.d8.loss_cls: 0.6991  decode.d8.loss_mask: 0.4453  decode.d8.loss_dice: 0.5138
07/25 16:59:04 - mmengine - INFO - Iter(train) [ 5300/80000]  base_lr: 9.4018e-05 lr: 9.4018e-06  eta: 10:04:40  time: 0.4782  data_time: 0.0093  memory: 5920  grad_norm: 272.7099  loss: 17.9244  decode.loss_cls: 0.8661  decode.loss_mask: 0.3349  decode.loss_dice: 0.5040  decode.d0.loss_cls: 1.6915  decode.d0.loss_mask: 0.3291  decode.d0.loss_dice: 0.4692  decode.d1.loss_cls: 1.0925  decode.d1.loss_mask: 0.3345  decode.d1.loss_dice: 0.4455  decode.d2.loss_cls: 0.9488  decode.d2.loss_mask: 0.3401  decode.d2.loss_dice: 0.4458  decode.d3.loss_cls: 0.8271  decode.d3.loss_mask: 0.3420  decode.d3.loss_dice: 0.4536  decode.d4.loss_cls: 0.8643  decode.d4.loss_mask: 0.3445  decode.d4.loss_dice: 0.4844  decode.d5.loss_cls: 0.9773  decode.d5.loss_mask: 0.3438  decode.d5.loss_dice: 0.4652  decode.d6.loss_cls: 0.7833  decode.d6.loss_mask: 0.3464  decode.d6.loss_dice: 0.4790  decode.d7.loss_cls: 0.8500  decode.d7.loss_mask: 0.3467  decode.d7.loss_dice: 0.4907  decode.d8.loss_cls: 0.8623  decode.d8.loss_mask: 0.3548  decode.d8.loss_dice: 0.5070
07/25 16:59:28 - mmengine - INFO - Iter(train) [ 5350/80000]  base_lr: 9.3962e-05 lr: 9.3962e-06  eta: 10:04:13  time: 0.4781  data_time: 0.0094  memory: 5919  grad_norm: 159.0889  loss: 16.9283  decode.loss_cls: 0.7975  decode.loss_mask: 0.3407  decode.loss_dice: 0.3570  decode.d0.loss_cls: 1.8896  decode.d0.loss_mask: 0.3764  decode.d0.loss_dice: 0.4483  decode.d1.loss_cls: 1.0592  decode.d1.loss_mask: 0.3122  decode.d1.loss_dice: 0.3370  decode.d2.loss_cls: 0.9209  decode.d2.loss_mask: 0.2935  decode.d2.loss_dice: 0.3492  decode.d3.loss_cls: 0.8615  decode.d3.loss_mask: 0.2956  decode.d3.loss_dice: 0.3297  decode.d4.loss_cls: 0.7856  decode.d4.loss_mask: 0.3282  decode.d4.loss_dice: 0.3857  decode.d5.loss_cls: 0.8572  decode.d5.loss_mask: 0.3420  decode.d5.loss_dice: 0.3960  decode.d6.loss_cls: 0.9212  decode.d6.loss_mask: 0.3201  decode.d6.loss_dice: 0.3933  decode.d7.loss_cls: 0.9751  decode.d7.loss_mask: 0.3077  decode.d7.loss_dice: 0.3534  decode.d8.loss_cls: 0.9108  decode.d8.loss_mask: 0.3112  decode.d8.loss_dice: 0.3724
07/25 16:59:52 - mmengine - INFO - Iter(train) [ 5400/80000]  base_lr: 9.3905e-05 lr: 9.3905e-06  eta: 10:03:44  time: 0.4786  data_time: 0.0093  memory: 5919  grad_norm: 159.5362  loss: 14.3963  decode.loss_cls: 0.7395  decode.loss_mask: 0.3139  decode.loss_dice: 0.3017  decode.d0.loss_cls: 1.6198  decode.d0.loss_mask: 0.3162  decode.d0.loss_dice: 0.3809  decode.d1.loss_cls: 0.8553  decode.d1.loss_mask: 0.3208  decode.d1.loss_dice: 0.3215  decode.d2.loss_cls: 0.6731  decode.d2.loss_mask: 0.3125  decode.d2.loss_dice: 0.3395  decode.d3.loss_cls: 0.6766  decode.d3.loss_mask: 0.2993  decode.d3.loss_dice: 0.3161  decode.d4.loss_cls: 0.6924  decode.d4.loss_mask: 0.2975  decode.d4.loss_dice: 0.2992  decode.d5.loss_cls: 0.7065  decode.d5.loss_mask: 0.3029  decode.d5.loss_dice: 0.3010  decode.d6.loss_cls: 0.7663  decode.d6.loss_mask: 0.3044  decode.d6.loss_dice: 0.3155  decode.d7.loss_cls: 0.6645  decode.d7.loss_mask: 0.3128  decode.d7.loss_dice: 0.3245  decode.d8.loss_cls: 0.7137  decode.d8.loss_mask: 0.3144  decode.d8.loss_dice: 0.2942
07/25 17:00:16 - mmengine - INFO - Iter(train) [ 5450/80000]  base_lr: 9.3848e-05 lr: 9.3848e-06  eta: 10:03:15  time: 0.4777  data_time: 0.0094  memory: 5920  grad_norm: 211.1567  loss: 17.9964  decode.loss_cls: 0.7917  decode.loss_mask: 0.3432  decode.loss_dice: 0.4303  decode.d0.loss_cls: 1.7441  decode.d0.loss_mask: 0.3441  decode.d0.loss_dice: 0.5546  decode.d1.loss_cls: 1.0883  decode.d1.loss_mask: 0.3408  decode.d1.loss_dice: 0.5278  decode.d2.loss_cls: 0.9548  decode.d2.loss_mask: 0.3413  decode.d2.loss_dice: 0.4414  decode.d3.loss_cls: 0.9273  decode.d3.loss_mask: 0.3371  decode.d3.loss_dice: 0.4601  decode.d4.loss_cls: 0.8760  decode.d4.loss_mask: 0.3315  decode.d4.loss_dice: 0.4705  decode.d5.loss_cls: 0.9245  decode.d5.loss_mask: 0.3401  decode.d5.loss_dice: 0.4445  decode.d6.loss_cls: 0.8624  decode.d6.loss_mask: 0.3313  decode.d6.loss_dice: 0.4414  decode.d7.loss_cls: 0.8388  decode.d7.loss_mask: 0.3514  decode.d7.loss_dice: 0.4837  decode.d8.loss_cls: 0.8468  decode.d8.loss_mask: 0.3459  decode.d8.loss_dice: 0.4807
07/25 17:00:40 - mmengine - INFO - Iter(train) [ 5500/80000]  base_lr: 9.3792e-05 lr: 9.3792e-06  eta: 10:02:46  time: 0.4789  data_time: 0.0093  memory: 5900  grad_norm: 245.9534  loss: 19.3510  decode.loss_cls: 1.1474  decode.loss_mask: 0.3387  decode.loss_dice: 0.4679  decode.d0.loss_cls: 1.9515  decode.d0.loss_mask: 0.3309  decode.d0.loss_dice: 0.5271  decode.d1.loss_cls: 1.3090  decode.d1.loss_mask: 0.3102  decode.d1.loss_dice: 0.4010  decode.d2.loss_cls: 1.0795  decode.d2.loss_mask: 0.2962  decode.d2.loss_dice: 0.4398  decode.d3.loss_cls: 0.9774  decode.d3.loss_mask: 0.3139  decode.d3.loss_dice: 0.4237  decode.d4.loss_cls: 0.9827  decode.d4.loss_mask: 0.3086  decode.d4.loss_dice: 0.4485  decode.d5.loss_cls: 1.1593  decode.d5.loss_mask: 0.3326  decode.d5.loss_dice: 0.4373  decode.d6.loss_cls: 1.0249  decode.d6.loss_mask: 0.3345  decode.d6.loss_dice: 0.4296  decode.d7.loss_cls: 1.0535  decode.d7.loss_mask: 0.3091  decode.d7.loss_dice: 0.4321  decode.d8.loss_cls: 0.9792  decode.d8.loss_mask: 0.3517  decode.d8.loss_dice: 0.4531
07/25 17:01:04 - mmengine - INFO - Iter(train) [ 5550/80000]  base_lr: 9.3735e-05 lr: 9.3735e-06  eta: 10:02:17  time: 0.4785  data_time: 0.0093  memory: 5979  grad_norm: 294.1560  loss: 14.1888  decode.loss_cls: 0.6693  decode.loss_mask: 0.3054  decode.loss_dice: 0.3195  decode.d0.loss_cls: 1.6288  decode.d0.loss_mask: 0.3499  decode.d0.loss_dice: 0.4218  decode.d1.loss_cls: 0.6631  decode.d1.loss_mask: 0.3202  decode.d1.loss_dice: 0.3544  decode.d2.loss_cls: 0.6305  decode.d2.loss_mask: 0.3274  decode.d2.loss_dice: 0.3510  decode.d3.loss_cls: 0.6798  decode.d3.loss_mask: 0.3120  decode.d3.loss_dice: 0.3349  decode.d4.loss_cls: 0.6390  decode.d4.loss_mask: 0.3109  decode.d4.loss_dice: 0.3260  decode.d5.loss_cls: 0.6322  decode.d5.loss_mask: 0.3049  decode.d5.loss_dice: 0.3262  decode.d6.loss_cls: 0.6979  decode.d6.loss_mask: 0.3040  decode.d6.loss_dice: 0.3155  decode.d7.loss_cls: 0.7309  decode.d7.loss_mask: 0.3024  decode.d7.loss_dice: 0.3311  decode.d8.loss_cls: 0.6784  decode.d8.loss_mask: 0.3033  decode.d8.loss_dice: 0.3183
07/25 17:01:28 - mmengine - INFO - Iter(train) [ 5600/80000]  base_lr: 9.3678e-05 lr: 9.3678e-06  eta: 10:01:48  time: 0.4768  data_time: 0.0092  memory: 5979  grad_norm: 191.4457  loss: 16.4753  decode.loss_cls: 0.8046  decode.loss_mask: 0.3279  decode.loss_dice: 0.3724  decode.d0.loss_cls: 1.6651  decode.d0.loss_mask: 0.3472  decode.d0.loss_dice: 0.4490  decode.d1.loss_cls: 0.9378  decode.d1.loss_mask: 0.3286  decode.d1.loss_dice: 0.4157  decode.d2.loss_cls: 0.8089  decode.d2.loss_mask: 0.3370  decode.d2.loss_dice: 0.3872  decode.d3.loss_cls: 0.8001  decode.d3.loss_mask: 0.3543  decode.d3.loss_dice: 0.4043  decode.d4.loss_cls: 0.8376  decode.d4.loss_mask: 0.3302  decode.d4.loss_dice: 0.3652  decode.d5.loss_cls: 0.8306  decode.d5.loss_mask: 0.3344  decode.d5.loss_dice: 0.3928  decode.d6.loss_cls: 0.7721  decode.d6.loss_mask: 0.3587  decode.d6.loss_dice: 0.3705  decode.d7.loss_cls: 0.8698  decode.d7.loss_mask: 0.3206  decode.d7.loss_dice: 0.3807  decode.d8.loss_cls: 0.8091  decode.d8.loss_mask: 0.3606  decode.d8.loss_dice: 0.4026
07/25 17:01:52 - mmengine - INFO - Iter(train) [ 5650/80000]  base_lr: 9.3622e-05 lr: 9.3622e-06  eta: 10:01:20  time: 0.4796  data_time: 0.0093  memory: 5919  grad_norm: 159.3848  loss: 12.5747  decode.loss_cls: 0.5605  decode.loss_mask: 0.2567  decode.loss_dice: 0.2718  decode.d0.loss_cls: 1.7638  decode.d0.loss_mask: 0.2806  decode.d0.loss_dice: 0.3540  decode.d1.loss_cls: 0.6481  decode.d1.loss_mask: 0.2615  decode.d1.loss_dice: 0.2833  decode.d2.loss_cls: 0.6309  decode.d2.loss_mask: 0.2587  decode.d2.loss_dice: 0.2861  decode.d3.loss_cls: 0.5756  decode.d3.loss_mask: 0.2557  decode.d3.loss_dice: 0.2854  decode.d4.loss_cls: 0.5532  decode.d4.loss_mask: 0.2533  decode.d4.loss_dice: 0.2791  decode.d5.loss_cls: 0.6068  decode.d5.loss_mask: 0.2578  decode.d5.loss_dice: 0.2758  decode.d6.loss_cls: 0.5674  decode.d6.loss_mask: 0.2677  decode.d6.loss_dice: 0.2860  decode.d7.loss_cls: 0.5855  decode.d7.loss_mask: 0.2602  decode.d7.loss_dice: 0.2797  decode.d8.loss_cls: 0.5896  decode.d8.loss_mask: 0.2581  decode.d8.loss_dice: 0.2817
07/25 17:02:16 - mmengine - INFO - Iter(train) [ 5700/80000]  base_lr: 9.3565e-05 lr: 9.3565e-06  eta: 10:00:54  time: 0.4828  data_time: 0.0094  memory: 5979  grad_norm: 248.4603  loss: 15.0394  decode.loss_cls: 0.6496  decode.loss_mask: 0.3350  decode.loss_dice: 0.3977  decode.d0.loss_cls: 1.9928  decode.d0.loss_mask: 0.3159  decode.d0.loss_dice: 0.4410  decode.d1.loss_cls: 0.7744  decode.d1.loss_mask: 0.2844  decode.d1.loss_dice: 0.3746  decode.d2.loss_cls: 0.7236  decode.d2.loss_mask: 0.2855  decode.d2.loss_dice: 0.3686  decode.d3.loss_cls: 0.6465  decode.d3.loss_mask: 0.3049  decode.d3.loss_dice: 0.3603  decode.d4.loss_cls: 0.6886  decode.d4.loss_mask: 0.3094  decode.d4.loss_dice: 0.3962  decode.d5.loss_cls: 0.5939  decode.d5.loss_mask: 0.2925  decode.d5.loss_dice: 0.3779  decode.d6.loss_cls: 0.6113  decode.d6.loss_mask: 0.3398  decode.d6.loss_dice: 0.3791  decode.d7.loss_cls: 0.6127  decode.d7.loss_mask: 0.3546  decode.d7.loss_dice: 0.4226  decode.d8.loss_cls: 0.6580  decode.d8.loss_mask: 0.3673  decode.d8.loss_dice: 0.3806
07/25 17:02:40 - mmengine - INFO - Iter(train) [ 5750/80000]  base_lr: 9.3508e-05 lr: 9.3508e-06  eta: 10:00:27  time: 0.4811  data_time: 0.0097  memory: 5938  grad_norm: 146.7427  loss: 15.8570  decode.loss_cls: 0.7005  decode.loss_mask: 0.3112  decode.loss_dice: 0.3849  decode.d0.loss_cls: 1.8752  decode.d0.loss_mask: 0.3090  decode.d0.loss_dice: 0.4393  decode.d1.loss_cls: 0.8698  decode.d1.loss_mask: 0.3203  decode.d1.loss_dice: 0.3642  decode.d2.loss_cls: 0.7928  decode.d2.loss_mask: 0.3132  decode.d2.loss_dice: 0.3799  decode.d3.loss_cls: 0.7446  decode.d3.loss_mask: 0.3263  decode.d3.loss_dice: 0.3880  decode.d4.loss_cls: 0.7133  decode.d4.loss_mask: 0.3235  decode.d4.loss_dice: 0.4024  decode.d5.loss_cls: 0.7893  decode.d5.loss_mask: 0.3119  decode.d5.loss_dice: 0.3871  decode.d6.loss_cls: 0.7696  decode.d6.loss_mask: 0.3065  decode.d6.loss_dice: 0.3903  decode.d7.loss_cls: 0.8072  decode.d7.loss_mask: 0.3155  decode.d7.loss_dice: 0.3976  decode.d8.loss_cls: 0.7013  decode.d8.loss_mask: 0.3159  decode.d8.loss_dice: 0.4064
07/25 17:03:04 - mmengine - INFO - Iter(train) [ 5800/80000]  base_lr: 9.3452e-05 lr: 9.3452e-06  eta: 10:00:00  time: 0.4806  data_time: 0.0098  memory: 5919  grad_norm: 124.2678  loss: 12.9787  decode.loss_cls: 0.5341  decode.loss_mask: 0.3121  decode.loss_dice: 0.3280  decode.d0.loss_cls: 1.6148  decode.d0.loss_mask: 0.3103  decode.d0.loss_dice: 0.3988  decode.d1.loss_cls: 0.6112  decode.d1.loss_mask: 0.3230  decode.d1.loss_dice: 0.3271  decode.d2.loss_cls: 0.4784  decode.d2.loss_mask: 0.3214  decode.d2.loss_dice: 0.3192  decode.d3.loss_cls: 0.4698  decode.d3.loss_mask: 0.3186  decode.d3.loss_dice: 0.3372  decode.d4.loss_cls: 0.5229  decode.d4.loss_mask: 0.3214  decode.d4.loss_dice: 0.3386  decode.d5.loss_cls: 0.5706  decode.d5.loss_mask: 0.3167  decode.d5.loss_dice: 0.3294  decode.d6.loss_cls: 0.5389  decode.d6.loss_mask: 0.3169  decode.d6.loss_dice: 0.3308  decode.d7.loss_cls: 0.5139  decode.d7.loss_mask: 0.3130  decode.d7.loss_dice: 0.3592  decode.d8.loss_cls: 0.5679  decode.d8.loss_mask: 0.3088  decode.d8.loss_dice: 0.3257
07/25 17:03:28 - mmengine - INFO - Iter(train) [ 5850/80000]  base_lr: 9.3395e-05 lr: 9.3395e-06  eta: 9:59:33  time: 0.4806  data_time: 0.0095  memory: 5901  grad_norm: 276.0743  loss: 16.6208  decode.loss_cls: 0.7807  decode.loss_mask: 0.3779  decode.loss_dice: 0.4240  decode.d0.loss_cls: 1.5947  decode.d0.loss_mask: 0.3675  decode.d0.loss_dice: 0.4698  decode.d1.loss_cls: 0.9105  decode.d1.loss_mask: 0.3288  decode.d1.loss_dice: 0.4104  decode.d2.loss_cls: 0.7868  decode.d2.loss_mask: 0.3323  decode.d2.loss_dice: 0.4052  decode.d3.loss_cls: 0.7272  decode.d3.loss_mask: 0.3221  decode.d3.loss_dice: 0.4151  decode.d4.loss_cls: 0.7712  decode.d4.loss_mask: 0.3317  decode.d4.loss_dice: 0.4225  decode.d5.loss_cls: 0.7571  decode.d5.loss_mask: 0.3479  decode.d5.loss_dice: 0.4110  decode.d6.loss_cls: 0.8536  decode.d6.loss_mask: 0.3564  decode.d6.loss_dice: 0.4367  decode.d7.loss_cls: 0.8856  decode.d7.loss_mask: 0.3489  decode.d7.loss_dice: 0.4343  decode.d8.loss_cls: 0.8192  decode.d8.loss_mask: 0.3688  decode.d8.loss_dice: 0.4228
07/25 17:03:52 - mmengine - INFO - Iter(train) [ 5900/80000]  base_lr: 9.3338e-05 lr: 9.3338e-06  eta: 9:59:06  time: 0.4818  data_time: 0.0095  memory: 5900  grad_norm: 201.9779  loss: 15.3720  decode.loss_cls: 0.6164  decode.loss_mask: 0.3480  decode.loss_dice: 0.3758  decode.d0.loss_cls: 1.8864  decode.d0.loss_mask: 0.3878  decode.d0.loss_dice: 0.4486  decode.d1.loss_cls: 0.7812  decode.d1.loss_mask: 0.3662  decode.d1.loss_dice: 0.3787  decode.d2.loss_cls: 0.7338  decode.d2.loss_mask: 0.3552  decode.d2.loss_dice: 0.3737  decode.d3.loss_cls: 0.7197  decode.d3.loss_mask: 0.3543  decode.d3.loss_dice: 0.3769  decode.d4.loss_cls: 0.6686  decode.d4.loss_mask: 0.3472  decode.d4.loss_dice: 0.3699  decode.d5.loss_cls: 0.6737  decode.d5.loss_mask: 0.3477  decode.d5.loss_dice: 0.3377  decode.d6.loss_cls: 0.6842  decode.d6.loss_mask: 0.3403  decode.d6.loss_dice: 0.3560  decode.d7.loss_cls: 0.6740  decode.d7.loss_mask: 0.3326  decode.d7.loss_dice: 0.3759  decode.d8.loss_cls: 0.6103  decode.d8.loss_mask: 0.3484  decode.d8.loss_dice: 0.4028
07/25 17:04:16 - mmengine - INFO - Iter(train) [ 5950/80000]  base_lr: 9.3282e-05 lr: 9.3282e-06  eta: 9:58:41  time: 0.4800  data_time: 0.0093  memory: 5901  grad_norm: 225.0861  loss: 13.1781  decode.loss_cls: 0.5325  decode.loss_mask: 0.2857  decode.loss_dice: 0.3470  decode.d0.loss_cls: 1.5273  decode.d0.loss_mask: 0.3228  decode.d0.loss_dice: 0.4405  decode.d1.loss_cls: 0.7166  decode.d1.loss_mask: 0.2909  decode.d1.loss_dice: 0.3243  decode.d2.loss_cls: 0.5763  decode.d2.loss_mask: 0.2935  decode.d2.loss_dice: 0.3195  decode.d3.loss_cls: 0.5117  decode.d3.loss_mask: 0.2979  decode.d3.loss_dice: 0.3308  decode.d4.loss_cls: 0.5184  decode.d4.loss_mask: 0.2983  decode.d4.loss_dice: 0.3382  decode.d5.loss_cls: 0.5511  decode.d5.loss_mask: 0.3074  decode.d5.loss_dice: 0.3469  decode.d6.loss_cls: 0.5742  decode.d6.loss_mask: 0.3025  decode.d6.loss_dice: 0.3346  decode.d7.loss_cls: 0.6276  decode.d7.loss_mask: 0.3008  decode.d7.loss_dice: 0.3596  decode.d8.loss_cls: 0.5452  decode.d8.loss_mask: 0.3032  decode.d8.loss_dice: 0.3528
07/25 17:04:40 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250725_161554
07/25 17:04:40 - mmengine - INFO - Iter(train) [ 6000/80000]  base_lr: 9.3225e-05 lr: 9.3225e-06  eta: 9:58:14  time: 0.4801  data_time: 0.0095  memory: 5938  grad_norm: 180.6797  loss: 13.4746  decode.loss_cls: 0.5033  decode.loss_mask: 0.3394  decode.loss_dice: 0.3604  decode.d0.loss_cls: 1.6448  decode.d0.loss_mask: 0.3670  decode.d0.loss_dice: 0.4339  decode.d1.loss_cls: 0.6695  decode.d1.loss_mask: 0.3192  decode.d1.loss_dice: 0.3257  decode.d2.loss_cls: 0.6514  decode.d2.loss_mask: 0.3273  decode.d2.loss_dice: 0.3147  decode.d3.loss_cls: 0.5519  decode.d3.loss_mask: 0.2982  decode.d3.loss_dice: 0.2981  decode.d4.loss_cls: 0.5582  decode.d4.loss_mask: 0.3006  decode.d4.loss_dice: 0.3090  decode.d5.loss_cls: 0.5657  decode.d5.loss_mask: 0.3060  decode.d5.loss_dice: 0.3214  decode.d6.loss_cls: 0.5647  decode.d6.loss_mask: 0.3191  decode.d6.loss_dice: 0.3418  decode.d7.loss_cls: 0.5960  decode.d7.loss_mask: 0.3179  decode.d7.loss_dice: 0.3290  decode.d8.loss_cls: 0.5811  decode.d8.loss_mask: 0.3179  decode.d8.loss_dice: 0.3411
07/25 17:05:04 - mmengine - INFO - Iter(train) [ 6050/80000]  base_lr: 9.3168e-05 lr: 9.3168e-06  eta: 9:57:47  time: 0.4806  data_time: 0.0093  memory: 5884  grad_norm: 141.7510  loss: 14.9396  decode.loss_cls: 0.7349  decode.loss_mask: 0.3147  decode.loss_dice: 0.3537  decode.d0.loss_cls: 2.0376  decode.d0.loss_mask: 0.3227  decode.d0.loss_dice: 0.3731  decode.d1.loss_cls: 0.9110  decode.d1.loss_mask: 0.3121  decode.d1.loss_dice: 0.3362  decode.d2.loss_cls: 0.6927  decode.d2.loss_mask: 0.3178  decode.d2.loss_dice: 0.3273  decode.d3.loss_cls: 0.7139  decode.d3.loss_mask: 0.2964  decode.d3.loss_dice: 0.3293  decode.d4.loss_cls: 0.6809  decode.d4.loss_mask: 0.3032  decode.d4.loss_dice: 0.3389  decode.d5.loss_cls: 0.6973  decode.d5.loss_mask: 0.3155  decode.d5.loss_dice: 0.3333  decode.d6.loss_cls: 0.6019  decode.d6.loss_mask: 0.3281  decode.d6.loss_dice: 0.3523  decode.d7.loss_cls: 0.6408  decode.d7.loss_mask: 0.3189  decode.d7.loss_dice: 0.3257  decode.d8.loss_cls: 0.6452  decode.d8.loss_mask: 0.3463  decode.d8.loss_dice: 0.3379
07/25 17:05:28 - mmengine - INFO - Iter(train) [ 6100/80000]  base_lr: 9.3112e-05 lr: 9.3112e-06  eta: 9:57:20  time: 0.4798  data_time: 0.0095  memory: 5900  grad_norm: 227.7415  loss: 14.3368  decode.loss_cls: 0.6553  decode.loss_mask: 0.2791  decode.loss_dice: 0.4266  decode.d0.loss_cls: 1.4477  decode.d0.loss_mask: 0.3124  decode.d0.loss_dice: 0.4588  decode.d1.loss_cls: 0.6750  decode.d1.loss_mask: 0.2877  decode.d1.loss_dice: 0.4234  decode.d2.loss_cls: 0.5991  decode.d2.loss_mask: 0.2824  decode.d2.loss_dice: 0.4103  decode.d3.loss_cls: 0.5758  decode.d3.loss_mask: 0.2801  decode.d3.loss_dice: 0.4304  decode.d4.loss_cls: 0.6671  decode.d4.loss_mask: 0.2765  decode.d4.loss_dice: 0.4158  decode.d5.loss_cls: 0.6874  decode.d5.loss_mask: 0.2779  decode.d5.loss_dice: 0.4243  decode.d6.loss_cls: 0.7393  decode.d6.loss_mask: 0.2730  decode.d6.loss_dice: 0.3850  decode.d7.loss_cls: 0.7069  decode.d7.loss_mask: 0.2786  decode.d7.loss_dice: 0.3948  decode.d8.loss_cls: 0.5724  decode.d8.loss_mask: 0.2829  decode.d8.loss_dice: 0.4105
07/25 17:05:52 - mmengine - INFO - Iter(train) [ 6150/80000]  base_lr: 9.3055e-05 lr: 9.3055e-06  eta: 9:56:54  time: 0.4813  data_time: 0.0096  memory: 5979  grad_norm: 125.9557  loss: 12.5486  decode.loss_cls: 0.6042  decode.loss_mask: 0.2585  decode.loss_dice: 0.2969  decode.d0.loss_cls: 1.6928  decode.d0.loss_mask: 0.2709  decode.d0.loss_dice: 0.3168  decode.d1.loss_cls: 0.6958  decode.d1.loss_mask: 0.2403  decode.d1.loss_dice: 0.2788  decode.d2.loss_cls: 0.5950  decode.d2.loss_mask: 0.2288  decode.d2.loss_dice: 0.2584  decode.d3.loss_cls: 0.6049  decode.d3.loss_mask: 0.2316  decode.d3.loss_dice: 0.2614  decode.d4.loss_cls: 0.6182  decode.d4.loss_mask: 0.2361  decode.d4.loss_dice: 0.2629  decode.d5.loss_cls: 0.6389  decode.d5.loss_mask: 0.2361  decode.d5.loss_dice: 0.2706  decode.d6.loss_cls: 0.6101  decode.d6.loss_mask: 0.2371  decode.d6.loss_dice: 0.2714  decode.d7.loss_cls: 0.6175  decode.d7.loss_mask: 0.2410  decode.d7.loss_dice: 0.2902  decode.d8.loss_cls: 0.6271  decode.d8.loss_mask: 0.2510  decode.d8.loss_dice: 0.3054
07/25 17:06:16 - mmengine - INFO - Iter(train) [ 6200/80000]  base_lr: 9.2998e-05 lr: 9.2998e-06  eta: 9:56:27  time: 0.4791  data_time: 0.0094  memory: 5900  grad_norm: 122.1881  loss: 12.4816  decode.loss_cls: 0.4730  decode.loss_mask: 0.3369  decode.loss_dice: 0.3480  decode.d0.loss_cls: 1.3637  decode.d0.loss_mask: 0.3487  decode.d0.loss_dice: 0.3844  decode.d1.loss_cls: 0.4474  decode.d1.loss_mask: 0.3302  decode.d1.loss_dice: 0.3305  decode.d2.loss_cls: 0.5196  decode.d2.loss_mask: 0.3319  decode.d2.loss_dice: 0.3652  decode.d3.loss_cls: 0.4866  decode.d3.loss_mask: 0.3283  decode.d3.loss_dice: 0.3676  decode.d4.loss_cls: 0.4663  decode.d4.loss_mask: 0.3262  decode.d4.loss_dice: 0.3378  decode.d5.loss_cls: 0.4638  decode.d5.loss_mask: 0.3235  decode.d5.loss_dice: 0.3266  decode.d6.loss_cls: 0.4980  decode.d6.loss_mask: 0.3282  decode.d6.loss_dice: 0.3328  decode.d7.loss_cls: 0.4553  decode.d7.loss_mask: 0.3353  decode.d7.loss_dice: 0.3347  decode.d8.loss_cls: 0.5175  decode.d8.loss_mask: 0.3295  decode.d8.loss_dice: 0.3442
07/25 17:06:40 - mmengine - INFO - Iter(train) [ 6250/80000]  base_lr: 9.2942e-05 lr: 9.2942e-06  eta: 9:56:00  time: 0.4796  data_time: 0.0094  memory: 5920  grad_norm: 174.5755  loss: 14.9334  decode.loss_cls: 0.6214  decode.loss_mask: 0.3385  decode.loss_dice: 0.3481  decode.d0.loss_cls: 1.5965  decode.d0.loss_mask: 0.3629  decode.d0.loss_dice: 0.4254  decode.d1.loss_cls: 0.7814  decode.d1.loss_mask: 0.3504  decode.d1.loss_dice: 0.3596  decode.d2.loss_cls: 0.6082  decode.d2.loss_mask: 0.3420  decode.d2.loss_dice: 0.3439  decode.d3.loss_cls: 0.7351  decode.d3.loss_mask: 0.3364  decode.d3.loss_dice: 0.3514  decode.d4.loss_cls: 0.7885  decode.d4.loss_mask: 0.3361  decode.d4.loss_dice: 0.3662  decode.d5.loss_cls: 0.6379  decode.d5.loss_mask: 0.3456  decode.d5.loss_dice: 0.3781  decode.d6.loss_cls: 0.6828  decode.d6.loss_mask: 0.3349  decode.d6.loss_dice: 0.3603  decode.d7.loss_cls: 0.7551  decode.d7.loss_mask: 0.3298  decode.d7.loss_dice: 0.3511  decode.d8.loss_cls: 0.6744  decode.d8.loss_mask: 0.3363  decode.d8.loss_dice: 0.3550
07/25 17:07:04 - mmengine - INFO - Iter(train) [ 6300/80000]  base_lr: 9.2885e-05 lr: 9.2885e-06  eta: 9:55:33  time: 0.4805  data_time: 0.0093  memory: 5899  grad_norm: 208.9386  loss: 15.3261  decode.loss_cls: 0.7905  decode.loss_mask: 0.2876  decode.loss_dice: 0.3588  decode.d0.loss_cls: 1.5973  decode.d0.loss_mask: 0.3704  decode.d0.loss_dice: 0.4576  decode.d1.loss_cls: 0.8458  decode.d1.loss_mask: 0.3177  decode.d1.loss_dice: 0.3941  decode.d2.loss_cls: 0.7796  decode.d2.loss_mask: 0.3102  decode.d2.loss_dice: 0.3788  decode.d3.loss_cls: 0.6437  decode.d3.loss_mask: 0.2879  decode.d3.loss_dice: 0.3816  decode.d4.loss_cls: 0.6642  decode.d4.loss_mask: 0.3209  decode.d4.loss_dice: 0.3770  decode.d5.loss_cls: 0.6408  decode.d5.loss_mask: 0.3896  decode.d5.loss_dice: 0.3975  decode.d6.loss_cls: 0.6462  decode.d6.loss_mask: 0.3950  decode.d6.loss_dice: 0.4191  decode.d7.loss_cls: 0.6646  decode.d7.loss_mask: 0.3618  decode.d7.loss_dice: 0.4238  decode.d8.loss_cls: 0.6909  decode.d8.loss_mask: 0.3248  decode.d8.loss_dice: 0.4081
07/25 17:07:29 - mmengine - INFO - Iter(train) [ 6350/80000]  base_lr: 9.2828e-05 lr: 9.2828e-06  eta: 9:55:06  time: 0.4814  data_time: 0.0096  memory: 5921  grad_norm: 174.9766  loss: 13.4286  decode.loss_cls: 0.6222  decode.loss_mask: 0.2275  decode.loss_dice: 0.2975  decode.d0.loss_cls: 1.9019  decode.d0.loss_mask: 0.2617  decode.d0.loss_dice: 0.4322  decode.d1.loss_cls: 0.8975  decode.d1.loss_mask: 0.2610  decode.d1.loss_dice: 0.3057  decode.d2.loss_cls: 0.7277  decode.d2.loss_mask: 0.2384  decode.d2.loss_dice: 0.3048  decode.d3.loss_cls: 0.6355  decode.d3.loss_mask: 0.2273  decode.d3.loss_dice: 0.2931  decode.d4.loss_cls: 0.6009  decode.d4.loss_mask: 0.2243  decode.d4.loss_dice: 0.2903  decode.d5.loss_cls: 0.6285  decode.d5.loss_mask: 0.2357  decode.d5.loss_dice: 0.2741  decode.d6.loss_cls: 0.6630  decode.d6.loss_mask: 0.2173  decode.d6.loss_dice: 0.2672  decode.d7.loss_cls: 0.7111  decode.d7.loss_mask: 0.2285  decode.d7.loss_dice: 0.3000  decode.d8.loss_cls: 0.6497  decode.d8.loss_mask: 0.2206  decode.d8.loss_dice: 0.2835
07/25 17:07:53 - mmengine - INFO - Iter(train) [ 6400/80000]  base_lr: 9.2771e-05 lr: 9.2771e-06  eta: 9:54:40  time: 0.4799  data_time: 0.0095  memory: 5900  grad_norm: 204.6609  loss: 14.9304  decode.loss_cls: 0.5956  decode.loss_mask: 0.3665  decode.loss_dice: 0.3548  decode.d0.loss_cls: 1.7749  decode.d0.loss_mask: 0.4146  decode.d0.loss_dice: 0.4558  decode.d1.loss_cls: 0.7379  decode.d1.loss_mask: 0.3672  decode.d1.loss_dice: 0.3945  decode.d2.loss_cls: 0.6929  decode.d2.loss_mask: 0.3565  decode.d2.loss_dice: 0.3540  decode.d3.loss_cls: 0.6356  decode.d3.loss_mask: 0.3839  decode.d3.loss_dice: 0.3618  decode.d4.loss_cls: 0.7086  decode.d4.loss_mask: 0.3772  decode.d4.loss_dice: 0.3623  decode.d5.loss_cls: 0.5861  decode.d5.loss_mask: 0.3691  decode.d5.loss_dice: 0.3411  decode.d6.loss_cls: 0.5910  decode.d6.loss_mask: 0.3503  decode.d6.loss_dice: 0.3258  decode.d7.loss_cls: 0.6169  decode.d7.loss_mask: 0.3635  decode.d7.loss_dice: 0.3604  decode.d8.loss_cls: 0.6041  decode.d8.loss_mask: 0.3821  decode.d8.loss_dice: 0.3455
07/25 17:08:17 - mmengine - INFO - Iter(train) [ 6450/80000]  base_lr: 9.2715e-05 lr: 9.2715e-06  eta: 9:54:14  time: 0.4806  data_time: 0.0096  memory: 5920  grad_norm: 192.9940  loss: 15.9576  decode.loss_cls: 0.6256  decode.loss_mask: 0.3793  decode.loss_dice: 0.4292  decode.d0.loss_cls: 1.5777  decode.d0.loss_mask: 0.3792  decode.d0.loss_dice: 0.4946  decode.d1.loss_cls: 0.8077  decode.d1.loss_mask: 0.3792  decode.d1.loss_dice: 0.4382  decode.d2.loss_cls: 0.7453  decode.d2.loss_mask: 0.3742  decode.d2.loss_dice: 0.4483  decode.d3.loss_cls: 0.6694  decode.d3.loss_mask: 0.3857  decode.d3.loss_dice: 0.4202  decode.d4.loss_cls: 0.6515  decode.d4.loss_mask: 0.3879  decode.d4.loss_dice: 0.4368  decode.d5.loss_cls: 0.6210  decode.d5.loss_mask: 0.3830  decode.d5.loss_dice: 0.4445  decode.d6.loss_cls: 0.6859  decode.d6.loss_mask: 0.3868  decode.d6.loss_dice: 0.4209  decode.d7.loss_cls: 0.7335  decode.d7.loss_mask: 0.3812  decode.d7.loss_dice: 0.4086  decode.d8.loss_cls: 0.6441  decode.d8.loss_mask: 0.3804  decode.d8.loss_dice: 0.4379
07/25 17:08:41 - mmengine - INFO - Iter(train) [ 6500/80000]  base_lr: 9.2658e-05 lr: 9.2658e-06  eta: 9:53:48  time: 0.4811  data_time: 0.0096  memory: 5937  grad_norm: 168.4831  loss: 13.0784  decode.loss_cls: 0.4832  decode.loss_mask: 0.3374  decode.loss_dice: 0.3570  decode.d0.loss_cls: 1.5490  decode.d0.loss_mask: 0.4122  decode.d0.loss_dice: 0.4342  decode.d1.loss_cls: 0.6342  decode.d1.loss_mask: 0.2742  decode.d1.loss_dice: 0.3434  decode.d2.loss_cls: 0.5561  decode.d2.loss_mask: 0.2725  decode.d2.loss_dice: 0.3357  decode.d3.loss_cls: 0.4969  decode.d3.loss_mask: 0.3043  decode.d3.loss_dice: 0.3434  decode.d4.loss_cls: 0.5148  decode.d4.loss_mask: 0.2913  decode.d4.loss_dice: 0.3420  decode.d5.loss_cls: 0.5259  decode.d5.loss_mask: 0.3137  decode.d5.loss_dice: 0.3362  decode.d6.loss_cls: 0.5302  decode.d6.loss_mask: 0.3281  decode.d6.loss_dice: 0.3447  decode.d7.loss_cls: 0.5030  decode.d7.loss_mask: 0.3476  decode.d7.loss_dice: 0.3436  decode.d8.loss_cls: 0.4817  decode.d8.loss_mask: 0.3839  decode.d8.loss_dice: 0.3580
07/25 17:09:05 - mmengine - INFO - Iter(train) [ 6550/80000]  base_lr: 9.2601e-05 lr: 9.2601e-06  eta: 9:53:21  time: 0.4813  data_time: 0.0095  memory: 5920  grad_norm: 281.3121  loss: 11.8196  decode.loss_cls: 0.5354  decode.loss_mask: 0.2828  decode.loss_dice: 0.3466  decode.d0.loss_cls: 1.5165  decode.d0.loss_mask: 0.2931  decode.d0.loss_dice: 0.3854  decode.d1.loss_cls: 0.5095  decode.d1.loss_mask: 0.2776  decode.d1.loss_dice: 0.3037  decode.d2.loss_cls: 0.4339  decode.d2.loss_mask: 0.2829  decode.d2.loss_dice: 0.3138  decode.d3.loss_cls: 0.4044  decode.d3.loss_mask: 0.2762  decode.d3.loss_dice: 0.2966  decode.d4.loss_cls: 0.3846  decode.d4.loss_mask: 0.2860  decode.d4.loss_dice: 0.3052  decode.d5.loss_cls: 0.4572  decode.d5.loss_mask: 0.2817  decode.d5.loss_dice: 0.3183  decode.d6.loss_cls: 0.5071  decode.d6.loss_mask: 0.2821  decode.d6.loss_dice: 0.3013  decode.d7.loss_cls: 0.4868  decode.d7.loss_mask: 0.2830  decode.d7.loss_dice: 0.3210  decode.d8.loss_cls: 0.5319  decode.d8.loss_mask: 0.2825  decode.d8.loss_dice: 0.3327
07/25 17:09:29 - mmengine - INFO - Iter(train) [ 6600/80000]  base_lr: 9.2544e-05 lr: 9.2544e-06  eta: 9:52:55  time: 0.4818  data_time: 0.0097  memory: 5920  grad_norm: 157.6468  loss: 13.7537  decode.loss_cls: 0.5319  decode.loss_mask: 0.3315  decode.loss_dice: 0.3395  decode.d0.loss_cls: 1.6984  decode.d0.loss_mask: 0.3650  decode.d0.loss_dice: 0.4555  decode.d1.loss_cls: 0.7469  decode.d1.loss_mask: 0.3329  decode.d1.loss_dice: 0.3639  decode.d2.loss_cls: 0.5436  decode.d2.loss_mask: 0.3231  decode.d2.loss_dice: 0.3531  decode.d3.loss_cls: 0.6348  decode.d3.loss_mask: 0.3078  decode.d3.loss_dice: 0.3321  decode.d4.loss_cls: 0.4992  decode.d4.loss_mask: 0.3115  decode.d4.loss_dice: 0.3365  decode.d5.loss_cls: 0.5438  decode.d5.loss_mask: 0.3152  decode.d5.loss_dice: 0.3509  decode.d6.loss_cls: 0.5592  decode.d6.loss_mask: 0.3139  decode.d6.loss_dice: 0.3499  decode.d7.loss_cls: 0.6040  decode.d7.loss_mask: 0.3168  decode.d7.loss_dice: 0.3394  decode.d8.loss_cls: 0.5870  decode.d8.loss_mask: 0.3260  decode.d8.loss_dice: 0.3406
07/25 17:09:53 - mmengine - INFO - Iter(train) [ 6650/80000]  base_lr: 9.2488e-05 lr: 9.2488e-06  eta: 9:52:28  time: 0.4807  data_time: 0.0096  memory: 5919  grad_norm: 142.7265  loss: 12.1325  decode.loss_cls: 0.5170  decode.loss_mask: 0.2307  decode.loss_dice: 0.3529  decode.d0.loss_cls: 1.4571  decode.d0.loss_mask: 0.2569  decode.d0.loss_dice: 0.4411  decode.d1.loss_cls: 0.5494  decode.d1.loss_mask: 0.2422  decode.d1.loss_dice: 0.3545  decode.d2.loss_cls: 0.5456  decode.d2.loss_mask: 0.2372  decode.d2.loss_dice: 0.3528  decode.d3.loss_cls: 0.4805  decode.d3.loss_mask: 0.2471  decode.d3.loss_dice: 0.3537  decode.d4.loss_cls: 0.4899  decode.d4.loss_mask: 0.2285  decode.d4.loss_dice: 0.3528  decode.d5.loss_cls: 0.4447  decode.d5.loss_mask: 0.2561  decode.d5.loss_dice: 0.3790  decode.d6.loss_cls: 0.4887  decode.d6.loss_mask: 0.2425  decode.d6.loss_dice: 0.3768  decode.d7.loss_cls: 0.4805  decode.d7.loss_mask: 0.2500  decode.d7.loss_dice: 0.3801  decode.d8.loss_cls: 0.5187  decode.d8.loss_mask: 0.2448  decode.d8.loss_dice: 0.3805
07/25 17:10:17 - mmengine - INFO - Iter(train) [ 6700/80000]  base_lr: 9.2431e-05 lr: 9.2431e-06  eta: 9:52:02  time: 0.4812  data_time: 0.0096  memory: 5937  grad_norm: 177.6925  loss: 15.2722  decode.loss_cls: 0.6882  decode.loss_mask: 0.3442  decode.loss_dice: 0.3574  decode.d0.loss_cls: 1.5431  decode.d0.loss_mask: 0.3686  decode.d0.loss_dice: 0.4341  decode.d1.loss_cls: 0.7865  decode.d1.loss_mask: 0.3396  decode.d1.loss_dice: 0.3868  decode.d2.loss_cls: 0.7051  decode.d2.loss_mask: 0.3427  decode.d2.loss_dice: 0.4150  decode.d3.loss_cls: 0.7169  decode.d3.loss_mask: 0.3326  decode.d3.loss_dice: 0.3325  decode.d4.loss_cls: 0.7177  decode.d4.loss_mask: 0.3283  decode.d4.loss_dice: 0.3949  decode.d5.loss_cls: 0.7085  decode.d5.loss_mask: 0.3571  decode.d5.loss_dice: 0.3912  decode.d6.loss_cls: 0.6737  decode.d6.loss_mask: 0.3336  decode.d6.loss_dice: 0.3516  decode.d7.loss_cls: 0.7757  decode.d7.loss_mask: 0.3341  decode.d7.loss_dice: 0.3563  decode.d8.loss_cls: 0.7693  decode.d8.loss_mask: 0.3309  decode.d8.loss_dice: 0.3561
07/25 17:10:41 - mmengine - INFO - Iter(train) [ 6750/80000]  base_lr: 9.2374e-05 lr: 9.2374e-06  eta: 9:51:38  time: 0.4810  data_time: 0.0094  memory: 5919  grad_norm: 113.5532  loss: 10.6289  decode.loss_cls: 0.4353  decode.loss_mask: 0.2695  decode.loss_dice: 0.2798  decode.d0.loss_cls: 1.4015  decode.d0.loss_mask: 0.2710  decode.d0.loss_dice: 0.3495  decode.d1.loss_cls: 0.4395  decode.d1.loss_mask: 0.2595  decode.d1.loss_dice: 0.2845  decode.d2.loss_cls: 0.4167  decode.d2.loss_mask: 0.2597  decode.d2.loss_dice: 0.2875  decode.d3.loss_cls: 0.4027  decode.d3.loss_mask: 0.2585  decode.d3.loss_dice: 0.2719  decode.d4.loss_cls: 0.4097  decode.d4.loss_mask: 0.2577  decode.d4.loss_dice: 0.2994  decode.d5.loss_cls: 0.3762  decode.d5.loss_mask: 0.2597  decode.d5.loss_dice: 0.2646  decode.d6.loss_cls: 0.3636  decode.d6.loss_mask: 0.2621  decode.d6.loss_dice: 0.2911  decode.d7.loss_cls: 0.4065  decode.d7.loss_mask: 0.2571  decode.d7.loss_dice: 0.2919  decode.d8.loss_cls: 0.4231  decode.d8.loss_mask: 0.2690  decode.d8.loss_dice: 0.3100
07/25 17:11:05 - mmengine - INFO - Iter(train) [ 6800/80000]  base_lr: 9.2317e-05 lr: 9.2317e-06  eta: 9:51:12  time: 0.4816  data_time: 0.0096  memory: 5978  grad_norm: 201.6347  loss: 12.7341  decode.loss_cls: 0.5874  decode.loss_mask: 0.2597  decode.loss_dice: 0.3393  decode.d0.loss_cls: 1.7278  decode.d0.loss_mask: 0.2581  decode.d0.loss_dice: 0.3626  decode.d1.loss_cls: 0.7148  decode.d1.loss_mask: 0.2344  decode.d1.loss_dice: 0.3196  decode.d2.loss_cls: 0.5923  decode.d2.loss_mask: 0.2366  decode.d2.loss_dice: 0.3077  decode.d3.loss_cls: 0.5457  decode.d3.loss_mask: 0.2311  decode.d3.loss_dice: 0.3043  decode.d4.loss_cls: 0.5932  decode.d4.loss_mask: 0.2362  decode.d4.loss_dice: 0.3137  decode.d5.loss_cls: 0.5393  decode.d5.loss_mask: 0.2309  decode.d5.loss_dice: 0.3063  decode.d6.loss_cls: 0.5812  decode.d6.loss_mask: 0.2452  decode.d6.loss_dice: 0.3071  decode.d7.loss_cls: 0.6096  decode.d7.loss_mask: 0.2561  decode.d7.loss_dice: 0.3348  decode.d8.loss_cls: 0.5795  decode.d8.loss_mask: 0.2657  decode.d8.loss_dice: 0.3139
07/25 17:11:29 - mmengine - INFO - Iter(train) [ 6850/80000]  base_lr: 9.2261e-05 lr: 9.2261e-06  eta: 9:50:46  time: 0.4810  data_time: 0.0095  memory: 5937  grad_norm: 195.8103  loss: 10.7484  decode.loss_cls: 0.2930  decode.loss_mask: 0.3112  decode.loss_dice: 0.3273  decode.d0.loss_cls: 1.3796  decode.d0.loss_mask: 0.3392  decode.d0.loss_dice: 0.4106  decode.d1.loss_cls: 0.4985  decode.d1.loss_mask: 0.3023  decode.d1.loss_dice: 0.3291  decode.d2.loss_cls: 0.3254  decode.d2.loss_mask: 0.3162  decode.d2.loss_dice: 0.3377  decode.d3.loss_cls: 0.3352  decode.d3.loss_mask: 0.3111  decode.d3.loss_dice: 0.3255  decode.d4.loss_cls: 0.2947  decode.d4.loss_mask: 0.3112  decode.d4.loss_dice: 0.3267  decode.d5.loss_cls: 0.2703  decode.d5.loss_mask: 0.3102  decode.d5.loss_dice: 0.3355  decode.d6.loss_cls: 0.2805  decode.d6.loss_mask: 0.3067  decode.d6.loss_dice: 0.3333  decode.d7.loss_cls: 0.2735  decode.d7.loss_mask: 0.3189  decode.d7.loss_dice: 0.3233  decode.d8.loss_cls: 0.2639  decode.d8.loss_mask: 0.3188  decode.d8.loss_dice: 0.3391
07/25 17:11:53 - mmengine - INFO - Iter(train) [ 6900/80000]  base_lr: 9.2204e-05 lr: 9.2204e-06  eta: 9:50:20  time: 0.4812  data_time: 0.0094  memory: 5919  grad_norm: 217.8803  loss: 15.1115  decode.loss_cls: 0.6996  decode.loss_mask: 0.2958  decode.loss_dice: 0.3997  decode.d0.loss_cls: 1.8143  decode.d0.loss_mask: 0.3231  decode.d0.loss_dice: 0.4818  decode.d1.loss_cls: 0.8274  decode.d1.loss_mask: 0.3364  decode.d1.loss_dice: 0.4106  decode.d2.loss_cls: 0.7068  decode.d2.loss_mask: 0.3063  decode.d2.loss_dice: 0.3873  decode.d3.loss_cls: 0.6862  decode.d3.loss_mask: 0.3015  decode.d3.loss_dice: 0.3793  decode.d4.loss_cls: 0.6614  decode.d4.loss_mask: 0.3081  decode.d4.loss_dice: 0.3717  decode.d5.loss_cls: 0.6295  decode.d5.loss_mask: 0.3111  decode.d5.loss_dice: 0.4336  decode.d6.loss_cls: 0.6112  decode.d6.loss_mask: 0.3015  decode.d6.loss_dice: 0.4086  decode.d7.loss_cls: 0.6184  decode.d7.loss_mask: 0.3035  decode.d7.loss_dice: 0.4011  decode.d8.loss_cls: 0.7008  decode.d8.loss_mask: 0.2958  decode.d8.loss_dice: 0.3991
07/25 17:12:17 - mmengine - INFO - Iter(train) [ 6950/80000]  base_lr: 9.2147e-05 lr: 9.2147e-06  eta: 9:49:54  time: 0.4812  data_time: 0.0095  memory: 5937  grad_norm: 157.4201  loss: 11.8486  decode.loss_cls: 0.5021  decode.loss_mask: 0.2491  decode.loss_dice: 0.2973  decode.d0.loss_cls: 1.4260  decode.d0.loss_mask: 0.2596  decode.d0.loss_dice: 0.3757  decode.d1.loss_cls: 0.6218  decode.d1.loss_mask: 0.2449  decode.d1.loss_dice: 0.3131  decode.d2.loss_cls: 0.5097  decode.d2.loss_mask: 0.2340  decode.d2.loss_dice: 0.2947  decode.d3.loss_cls: 0.5144  decode.d3.loss_mask: 0.2301  decode.d3.loss_dice: 0.2898  decode.d4.loss_cls: 0.5782  decode.d4.loss_mask: 0.2304  decode.d4.loss_dice: 0.2886  decode.d5.loss_cls: 0.5642  decode.d5.loss_mask: 0.2378  decode.d5.loss_dice: 0.2875  decode.d6.loss_cls: 0.5551  decode.d6.loss_mask: 0.2318  decode.d6.loss_dice: 0.3101  decode.d7.loss_cls: 0.5775  decode.d7.loss_mask: 0.2319  decode.d7.loss_dice: 0.2907  decode.d8.loss_cls: 0.5445  decode.d8.loss_mask: 0.2407  decode.d8.loss_dice: 0.3176
07/25 17:12:41 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250725_161554
07/25 17:12:41 - mmengine - INFO - Iter(train) [ 7000/80000]  base_lr: 9.2090e-05 lr: 9.2090e-06  eta: 9:49:28  time: 0.4815  data_time: 0.0096  memory: 5937  grad_norm: 163.6327  loss: 11.8481  decode.loss_cls: 0.4737  decode.loss_mask: 0.2434  decode.loss_dice: 0.3450  decode.d0.loss_cls: 1.4308  decode.d0.loss_mask: 0.2693  decode.d0.loss_dice: 0.4087  decode.d1.loss_cls: 0.5289  decode.d1.loss_mask: 0.2423  decode.d1.loss_dice: 0.3436  decode.d2.loss_cls: 0.4664  decode.d2.loss_mask: 0.2381  decode.d2.loss_dice: 0.3465  decode.d3.loss_cls: 0.4775  decode.d3.loss_mask: 0.2406  decode.d3.loss_dice: 0.3400  decode.d4.loss_cls: 0.5177  decode.d4.loss_mask: 0.2388  decode.d4.loss_dice: 0.3210  decode.d5.loss_cls: 0.5089  decode.d5.loss_mask: 0.2371  decode.d5.loss_dice: 0.3363  decode.d6.loss_cls: 0.5652  decode.d6.loss_mask: 0.2443  decode.d6.loss_dice: 0.3360  decode.d7.loss_cls: 0.5166  decode.d7.loss_mask: 0.2500  decode.d7.loss_dice: 0.3357  decode.d8.loss_cls: 0.4815  decode.d8.loss_mask: 0.2429  decode.d8.loss_dice: 0.3212
07/25 17:13:06 - mmengine - INFO - Iter(train) [ 7050/80000]  base_lr: 9.2034e-05 lr: 9.2034e-06  eta: 9:49:02  time: 0.4815  data_time: 0.0098  memory: 5937  grad_norm: 135.1361  loss: 13.1087  decode.loss_cls: 0.5441  decode.loss_mask: 0.2836  decode.loss_dice: 0.3368  decode.d0.loss_cls: 1.5312  decode.d0.loss_mask: 0.2851  decode.d0.loss_dice: 0.3642  decode.d1.loss_cls: 0.7262  decode.d1.loss_mask: 0.2884  decode.d1.loss_dice: 0.3140  decode.d2.loss_cls: 0.6602  decode.d2.loss_mask: 0.2826  decode.d2.loss_dice: 0.3048  decode.d3.loss_cls: 0.6031  decode.d3.loss_mask: 0.2818  decode.d3.loss_dice: 0.3253  decode.d4.loss_cls: 0.6247  decode.d4.loss_mask: 0.2786  decode.d4.loss_dice: 0.3446  decode.d5.loss_cls: 0.5426  decode.d5.loss_mask: 0.3047  decode.d5.loss_dice: 0.3495  decode.d6.loss_cls: 0.5253  decode.d6.loss_mask: 0.3107  decode.d6.loss_dice: 0.3411  decode.d7.loss_cls: 0.5517  decode.d7.loss_mask: 0.3022  decode.d7.loss_dice: 0.3357  decode.d8.loss_cls: 0.5424  decode.d8.loss_mask: 0.2926  decode.d8.loss_dice: 0.3309
07/25 17:13:30 - mmengine - INFO - Iter(train) [ 7100/80000]  base_lr: 9.1977e-05 lr: 9.1977e-06  eta: 9:48:36  time: 0.4800  data_time: 0.0095  memory: 5937  grad_norm: 170.0202  loss: 13.1910  decode.loss_cls: 0.6393  decode.loss_mask: 0.2684  decode.loss_dice: 0.3052  decode.d0.loss_cls: 1.5143  decode.d0.loss_mask: 0.2790  decode.d0.loss_dice: 0.3698  decode.d1.loss_cls: 0.6872  decode.d1.loss_mask: 0.2657  decode.d1.loss_dice: 0.3297  decode.d2.loss_cls: 0.6445  decode.d2.loss_mask: 0.3054  decode.d2.loss_dice: 0.3192  decode.d3.loss_cls: 0.6161  decode.d3.loss_mask: 0.2715  decode.d3.loss_dice: 0.3239  decode.d4.loss_cls: 0.6457  decode.d4.loss_mask: 0.2907  decode.d4.loss_dice: 0.3392  decode.d5.loss_cls: 0.6410  decode.d5.loss_mask: 0.2617  decode.d5.loss_dice: 0.3205  decode.d6.loss_cls: 0.6060  decode.d6.loss_mask: 0.2590  decode.d6.loss_dice: 0.2923  decode.d7.loss_cls: 0.6441  decode.d7.loss_mask: 0.2581  decode.d7.loss_dice: 0.3046  decode.d8.loss_cls: 0.6193  decode.d8.loss_mask: 0.2646  decode.d8.loss_dice: 0.3051
07/25 17:13:54 - mmengine - INFO - Iter(train) [ 7150/80000]  base_lr: 9.1920e-05 lr: 9.1920e-06  eta: 9:48:10  time: 0.4823  data_time: 0.0097  memory: 5919  grad_norm: 175.5093  loss: 12.0257  decode.loss_cls: 0.4222  decode.loss_mask: 0.2523  decode.loss_dice: 0.3539  decode.d0.loss_cls: 1.6505  decode.d0.loss_mask: 0.2637  decode.d0.loss_dice: 0.4075  decode.d1.loss_cls: 0.5768  decode.d1.loss_mask: 0.2528  decode.d1.loss_dice: 0.3368  decode.d2.loss_cls: 0.5691  decode.d2.loss_mask: 0.2520  decode.d2.loss_dice: 0.3349  decode.d3.loss_cls: 0.5123  decode.d3.loss_mask: 0.2454  decode.d3.loss_dice: 0.3289  decode.d4.loss_cls: 0.5172  decode.d4.loss_mask: 0.2469  decode.d4.loss_dice: 0.3396  decode.d5.loss_cls: 0.4889  decode.d5.loss_mask: 0.2498  decode.d5.loss_dice: 0.3358  decode.d6.loss_cls: 0.4290  decode.d6.loss_mask: 0.2535  decode.d6.loss_dice: 0.3457  decode.d7.loss_cls: 0.4190  decode.d7.loss_mask: 0.2520  decode.d7.loss_dice: 0.3264  decode.d8.loss_cls: 0.4530  decode.d8.loss_mask: 0.2543  decode.d8.loss_dice: 0.3556
07/25 17:14:18 - mmengine - INFO - Iter(train) [ 7200/80000]  base_lr: 9.1863e-05 lr: 9.1863e-06  eta: 9:47:45  time: 0.4808  data_time: 0.0097  memory: 5938  grad_norm: 145.7899  loss: 11.7717  decode.loss_cls: 0.3413  decode.loss_mask: 0.3385  decode.loss_dice: 0.3493  decode.d0.loss_cls: 1.2314  decode.d0.loss_mask: 0.3586  decode.d0.loss_dice: 0.4343  decode.d1.loss_cls: 0.5283  decode.d1.loss_mask: 0.3375  decode.d1.loss_dice: 0.3595  decode.d2.loss_cls: 0.4285  decode.d2.loss_mask: 0.3334  decode.d2.loss_dice: 0.3662  decode.d3.loss_cls: 0.3705  decode.d3.loss_mask: 0.3322  decode.d3.loss_dice: 0.3556  decode.d4.loss_cls: 0.3624  decode.d4.loss_mask: 0.3427  decode.d4.loss_dice: 0.3609  decode.d5.loss_cls: 0.3818  decode.d5.loss_mask: 0.3514  decode.d5.loss_dice: 0.3669  decode.d6.loss_cls: 0.3442  decode.d6.loss_mask: 0.3290  decode.d6.loss_dice: 0.3625  decode.d7.loss_cls: 0.3348  decode.d7.loss_mask: 0.3291  decode.d7.loss_dice: 0.3510  decode.d8.loss_cls: 0.3947  decode.d8.loss_mask: 0.3306  decode.d8.loss_dice: 0.3647
07/25 17:14:42 - mmengine - INFO - Iter(train) [ 7250/80000]  base_lr: 9.1807e-05 lr: 9.1807e-06  eta: 9:47:19  time: 0.4807  data_time: 0.0095  memory: 5937  grad_norm: 135.4280  loss: 12.9757  decode.loss_cls: 0.4528  decode.loss_mask: 0.3663  decode.loss_dice: 0.3648  decode.d0.loss_cls: 1.3991  decode.d0.loss_mask: 0.4112  decode.d0.loss_dice: 0.4121  decode.d1.loss_cls: 0.5320  decode.d1.loss_mask: 0.3673  decode.d1.loss_dice: 0.3696  decode.d2.loss_cls: 0.4400  decode.d2.loss_mask: 0.3644  decode.d2.loss_dice: 0.3398  decode.d3.loss_cls: 0.4054  decode.d3.loss_mask: 0.3752  decode.d3.loss_dice: 0.3483  decode.d4.loss_cls: 0.4614  decode.d4.loss_mask: 0.3764  decode.d4.loss_dice: 0.3482  decode.d5.loss_cls: 0.4868  decode.d5.loss_mask: 0.3620  decode.d5.loss_dice: 0.3586  decode.d6.loss_cls: 0.4812  decode.d6.loss_mask: 0.3631  decode.d6.loss_dice: 0.3575  decode.d7.loss_cls: 0.5011  decode.d7.loss_mask: 0.3724  decode.d7.loss_dice: 0.3533  decode.d8.loss_cls: 0.4887  decode.d8.loss_mask: 0.3677  decode.d8.loss_dice: 0.3489
07/25 17:15:06 - mmengine - INFO - Iter(train) [ 7300/80000]  base_lr: 9.1750e-05 lr: 9.1750e-06  eta: 9:46:54  time: 0.4822  data_time: 0.0096  memory: 5900  grad_norm: 100.2090  loss: 9.5941  decode.loss_cls: 0.2610  decode.loss_mask: 0.2479  decode.loss_dice: 0.2702  decode.d0.loss_cls: 1.4830  decode.d0.loss_mask: 0.2693  decode.d0.loss_dice: 0.3180  decode.d1.loss_cls: 0.4355  decode.d1.loss_mask: 0.2466  decode.d1.loss_dice: 0.2666  decode.d2.loss_cls: 0.3141  decode.d2.loss_mask: 0.2473  decode.d2.loss_dice: 0.2682  decode.d3.loss_cls: 0.2876  decode.d3.loss_mask: 0.2393  decode.d3.loss_dice: 0.2643  decode.d4.loss_cls: 0.3458  decode.d4.loss_mask: 0.2427  decode.d4.loss_dice: 0.2678  decode.d5.loss_cls: 0.3157  decode.d5.loss_mask: 0.2412  decode.d5.loss_dice: 0.2656  decode.d6.loss_cls: 0.2965  decode.d6.loss_mask: 0.2461  decode.d6.loss_dice: 0.2738  decode.d7.loss_cls: 0.2817  decode.d7.loss_mask: 0.2509  decode.d7.loss_dice: 0.2855  decode.d8.loss_cls: 0.3148  decode.d8.loss_mask: 0.2493  decode.d8.loss_dice: 0.2978
slurmstepd: error: *** JOB 2465925 ON gnode080 CANCELLED AT 2025-07-25T17:15:11 ***
